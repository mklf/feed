<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-02-03T01:30:00Z">02-03</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Visualizing Automatic Speech Recognition -- Means for a Better Understanding?. (arXiv:2202.00673v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00673">
<div class="article-summary-box-inner">
<span><p>Automatic speech recognition (ASR) is improving ever more at mimicking human
speech processing. The functioning of ASR, however, remains to a large extent
obfuscated by the complex structure of the deep neural networks (DNNs) they are
based on. In this paper, we show how so-called attribution methods, that we
import from image recognition and suitably adapt to handle audio data, can help
to clarify the working of ASR. Taking DeepSpeech, an end-to-end model for ASR,
as a case study, we show how these techniques help to visualize which features
of the input are the most influential in determining the output. We focus on
three visualization techniques: Layer-wise Relevance Propagation (LRP),
Saliency Maps, and Shapley Additive Explanations (SHAP). We compare these
methods and discuss potential further applications, such as in the detection of
adversarial examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to pronounce as measuring cross lingual joint orthography-phonology complexity. (arXiv:2202.00794v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00794">
<div class="article-summary-box-inner">
<span><p>Recent work has demonstrated that machine learning models allow us to compare
languages by showing how hard each language might be to learn under specific
tasks. Following this line of investigation, we investigate what makes a
language "hard to pronounce" by modelling the task of grapheme-to-phoneme (g2p)
transliteration. By training a character-level transformer model on this task
across 22 languages and measuring the model's proficiency against its grapheme
and phoneme inventories, we show that certain characteristics emerge that
separate easier and harder languages with respect to learning to pronounce.
Namely that the complexity of a languages pronunciation from its orthography is
due to how expressive or simple its grapheme-to-phoneme mapping is. Further
discussion illustrates how future studies should consider relative data
sparsity per language in order to design more fair cross lingual comparison
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disaster Tweets Classification using BERT-Based Language Model. (arXiv:2202.00795v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00795">
<div class="article-summary-box-inner">
<span><p>Social networking services have became an important communication channel in
time of emergency. The aim of this study is to create a machine learning
language model that is able to investigate if a person or area was in danger or
not. The ubiquitousness of smartphones enables people to announce an emergency
they are observing in real-time. Because of this, more agencies are interested
in programmatically monitoring Twitter (i.e. disaster relief organizations and
news agencies). Design a language model that is able to understand and
acknowledge when a disaster is happening based on the social network posts will
become more and more necessary over time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Semi-Supervised Deep Clustering Pipeline for Mining Intentions From Texts. (arXiv:2202.00802v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00802">
<div class="article-summary-box-inner">
<span><p>Mining the latent intentions from large volumes of natural language inputs is
a key step to help data analysts design and refine Intelligent Virtual
Assistants (IVAs) for customer service. To aid data analysts in this task we
present Verint Intent Manager (VIM), an analysis platform that combines
unsupervised and semi-supervised approaches to help analysts quickly surface
and organize relevant user intentions from conversational texts. For the
initial exploration of data we make use of a novel unsupervised and
semi-supervised pipeline that integrates the fine-tuning of high performing
language models, a distributed k-NN graph building method and community
detection techniques for mining the intentions and topics from texts. The
fine-tuning step is necessary because pre-trained language models cannot encode
texts to efficiently surface particular clustering structures when the target
texts are from an unseen domain or the clustering task is not topic detection.
For flexibility we deploy two clustering approaches: where the number of
clusters must be specified and where the number of clusters is detected
automatically with comparable clustering quality but at the expense of
additional computation time. We describe the application and deployment and
demonstrate its performance using BERT on three text mining tasks. Our
experiments show that BERT begins to produce better task-aware representations
using a labeled subset as small as 0.5% of the task data. The clustering
quality exceeds the state-of-the-art results when BERT is fine-tuned with
labeled subsets of only 2.5% of the task data. As deployed in the VIM
application, this flexible clustering pipeline produces high quality results,
improving the performance of data analysts and reducing the time it takes to
surface intentions from customer service data, thereby reducing the time it
takes to build and deploy IVAs in new domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Co-training Improves Prompt-based Learning for Large Language Models. (arXiv:2202.00828v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00828">
<div class="article-summary-box-inner">
<span><p>We demonstrate that co-training (Blum &amp; Mitchell, 1998) can improve the
performance of prompt-based learning by using unlabeled data. While prompting
has emerged as a promising paradigm for few-shot and zero-shot learning, it is
often brittle and requires much larger models compared to the standard
supervised setup. We find that co-training makes it possible to improve the
original prompt model and at the same time learn a smaller, downstream
task-specific model. In the case where we only have partial access to a prompt
model (e.g., output probabilities from GPT-3 (Brown et al., 2020)) we learn a
calibration model over the prompt outputs. When we have full access to the
prompt model's gradients but full finetuning remains prohibitively expensive
(e.g., T0 (Sanh et al., 2021)), we learn a set of soft prompt continuous
vectors to iteratively update the prompt model. We find that models trained in
this manner can significantly improve performance on challenging datasets where
there is currently a large gap between prompt-based learning and
fully-supervised models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Streaming Multi-Talker ASR with Token-Level Serialized Output Training. (arXiv:2202.00842v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00842">
<div class="article-summary-box-inner">
<span><p>This paper proposes a token-level serialized output training (t-SOT), a novel
framework for streaming multi-talker automatic speech recognition (ASR). Unlike
existing streaming multi-talker ASR models using multiple output layers, the
t-SOT model has only a single output layer that generates recognition tokens
(e.g., words, subwords) of multiple speakers in chronological order based on
their emission times. A special token that indicates the change of "virtual"
output channels is introduced to keep track of the overlapping utterances.
Compared to the prior streaming multi-talker ASR models, the t-SOT model has
the advantages of less inference cost and a simpler model architecture.
Moreover, in our experiments with LibriSpeechMix and LibriCSS datasets, the
t-SOT-based transformer transducer model achieves the state-of-the-art word
error rates by a significant margin to the prior results. For non-overlapping
speech, the t-SOT model is on par with a single-talker ASR model in terms of
both accuracy and computational cost, opening the door for deploying one model
for both single- and multi-talker scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Some Reflections on Drawing Causal Inference using Textual Data: Parallels Between Human Subjects and Organized Texts. (arXiv:2202.00848v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00848">
<div class="article-summary-box-inner">
<span><p>We examine the role of textual data as study units when conducting causal
inference by drawing parallels between human subjects and organized texts. %in
human population research. We elaborate on key causal concepts and principles,
and expose some ambiguity and sometimes fallacies. To facilitate better framing
a causal query, we discuss two strategies: (i) shifting from immutable traits
to perceptions of them, and (ii) shifting from some abstract concept/property
to its constituent parts, i.e., adopting a constructivist perspective of an
abstract concept. We hope this article would raise the awareness of the
importance of articulating and clarifying fundamental concepts before delving
into developing methodologies when drawing causal inference using textual data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Longitudinal Dataset of Twitter ISIS Users. (arXiv:2202.00878v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00878">
<div class="article-summary-box-inner">
<span><p>We present a large longitudinal dataset of tweets from two sets of users that
are suspected to be affiliated with ISIS. These sets of users are identified
based on a prior study and a campaign aimed at shutting down ISIS Twitter
accounts. These users have engaged with known ISIS accounts at least once
during 2014-2015 and are still active as of 2021. Some of them have directly
supported the ISIS users and their tweets by retweeting them, and some of the
users that have quoted tweets of ISIS, have uncertain connections to ISIS seed
accounts. This study and the dataset represent a unique approach to analyzing
ISIS data. Although much research exists on ISIS online activities, few studies
have focused on individual accounts. Our approach to validating accounts as
well as developing a framework for differentiating accounts' functionality
(e.g., propaganda versus operational planning) offers a foundation for future
research. We perform some descriptive statistics and preliminary analyses on
our collected data to provide deeper insight and highlight the significance and
practicality of such analyses. We further discuss several cross-disciplinary
potential use cases and research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Detection of Doxing on Twitter. (arXiv:2202.00879v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00879">
<div class="article-summary-box-inner">
<span><p>Doxing refers to the practice of disclosing sensitive personal information
about a person without their consent. This form of cyberbullying is an
unpleasant and sometimes dangerous phenomenon for online social networks.
Although prior work exists on automated identification of other types of
cyberbullying, a need exists for methods capable of detecting doxing on Twitter
specifically. We propose and evaluate a set of approaches for automatically
detecting second- and third-party disclosures on Twitter of sensitive private
information, a subset of which constitutes doxing. We summarize our findings of
common intentions behind doxing episodes and compare nine different approaches
for automated detection based on string-matching and one-hot encoded
heuristics, as well as word and contextualized string embedding representations
of tweets. We identify an approach providing 96.86% accuracy and 97.37% recall
using contextualized string embeddings and conclude by discussing the
practicality of our proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retrieve-and-Fill for Scenario-based Task-Oriented Semantic Parsing. (arXiv:2202.00901v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00901">
<div class="article-summary-box-inner">
<span><p>Task-oriented semantic parsing models have achieved strong results in recent
years, but unfortunately do not strike an appealing balance between model size,
runtime latency, and cross-domain generalizability. We tackle this problem by
introducing scenario-based semantic parsing: a variant of the original task
which first requires disambiguating an utterance's "scenario" (an intent-slot
template with variable leaf spans) before generating its frame, complete with
ontology and utterance tokens. This formulation enables us to isolate
coarse-grained and fine-grained aspects of the task, each of which we solve
with off-the-shelf neural modules, also optimizing for the axes outlined above.
Concretely, we create a Retrieve-and-Fill (RAF) architecture comprised of (1) a
retrieval module which ranks the best scenario given an utterance and (2) a
filling module which imputes spans into the scenario to create the frame. Our
model is modular, differentiable, interpretable, and allows us to garner extra
supervision from scenarios. RAF achieves strong results in high-resource,
low-resource, and multilingual settings, outperforming recent approaches by
wide margins despite, using base pre-trained encoders, small sequence lengths,
and parallel decoding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Knowledge Integration in Language Models with Graph Convolutions. (arXiv:2202.00964v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00964">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (LMs) do not capture factual knowledge very well.
This has led to the development of a number of knowledge integration (KI)
methods which aim to incorporate external knowledge into pretrained LMs. Even
though KI methods show some performance gains over vanilla LMs, the
inner-workings of these methods are not well-understood. For instance, it is
unclear how and what kind of knowledge is effectively integrated into these
models and if such integration may lead to catastrophic forgetting of already
learned knowledge. This paper revisits the KI process in these models with an
information-theoretic view and shows that KI can be interpreted using a graph
convolution operation. We propose a probe model called \textit{Graph
Convolution Simulator} (GCS) for interpreting knowledge-enhanced LMs and
exposing what kind of knowledge is integrated into these models. We conduct
experiments to verify that our GCS can indeed be used to correctly interpret
the KI process, and we use it to analyze two well-known knowledge-enhanced LMs:
ERNIE and K-Adapter, and find that only a small amount of factual knowledge is
integrated in them. We stratify knowledge in terms of various relation types
and find that ERNIE and K-Adapter integrate different kinds of knowledge to
different extent. Our analysis also shows that simply increasing the size of
the KI corpus may not lead to better KI; fundamental advances may be needed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RescoreBERT: Discriminative Speech Recognition Rescoring with BERT. (arXiv:2202.01094v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01094">
<div class="article-summary-box-inner">
<span><p>Second-pass rescoring is an important component in automatic speech
recognition (ASR) systems that is used to improve the outputs from a first-pass
decoder by implementing a lattice rescoring or $n$-best re-ranking. While
pretraining with a masked language model (MLM) objective has received great
success in various natural language understanding (NLU) tasks, it has not
gained traction as a rescoring model for ASR. Specifically, training a
bidirectional model like BERT on a discriminative objective such as minimum WER
(MWER) has not been explored. Here we where show how to train a BERT-based
rescoring model with MWER loss, to incorporate the improvements of a
discriminative loss into fine-tuning of deep bidirectional pretrained models
for ASR. We propose a fusion strategy that incorporates the MLM into the
discriminative training process to effectively distill the knowledge from a
pretrained model. We further propose an alternative discriminative loss. We
name this approach RescoreBERT, and evaluate it on the LibriSpeech corpus, and
it reduces WER by 6.6%/3.4% relative on clean/other test sets over a BERT
baseline without discriminative objective. We also evaluate our method on an
internal dataset from a conversational agent and find that it reduces both
latency and WER (by 3-8% relative) over an LSTM rescoring model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Keyword localisation in untranscribed speech using visually grounded speech models. (arXiv:2202.01107v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01107">
<div class="article-summary-box-inner">
<span><p>Keyword localisation is the task of finding where in a speech utterance a
given query keyword occurs. We investigate to what extent keyword localisation
is possible using a visually grounded speech (VGS) model. VGS models are
trained on unlabelled images paired with spoken captions. These models are
therefore self-supervised -- trained without any explicit textual label or
location information. To obtain training targets, we first tag training images
with soft text labels using a pretrained visual classifier with a fixed
vocabulary. This enables a VGS model to predict the presence of a written
keyword in an utterance, but not its location. We consider four ways to equip
VGS models with localisations capabilities. Two of these -- a saliency approach
and input masking -- can be applied to an arbitrary prediction model after
training, while the other two -- attention and a score aggregation approach --
are incorporated directly into the structure of the model. Masked-based
localisation gives some of the best reported localisation scores from a VGS
model, with an accuracy of 57% when the system knows that a keyword occurs in
an utterance and need to predict its location. In a setting where localisation
is performed after detection, an $F_1$ of 25% is achieved, and in a setting
where a keyword spotting ranking pass is first performed, we get a localisation
P@10 of 32%. While these scores are modest compared to the idealised setting
with unordered bag-of-word-supervision (from transcriptions), these models do
not receive any textual or location supervision. Further analyses show that
these models are limited by the first detection or ranking pass. Moreover,
individual keyword localisation performance is correlated with the tagging
performance from the visual classifier. We also show qualitatively how and
where semantic mistakes occur, e.g. that the model locates surfer when queried
with ocean.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Retrieval-Augmented Text Generation. (arXiv:2202.01110v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01110">
<div class="article-summary-box-inner">
<span><p>Recently, retrieval-augmented text generation attracted increasing attention
of the computational linguistics community. Compared with conventional
generation models, retrieval-augmented text generation has remarkable
advantages and particularly has achieved state-of-the-art performance in many
NLP tasks. This paper aims to conduct a survey about retrieval-augmented text
generation. It firstly highlights the generic paradigm of retrieval-augmented
generation, and then it reviews notable approaches according to different tasks
including dialogue response generation, machine translation, and other
generation tasks. Finally, it points out some important directions on top of
recent methods to facilitate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models Explain Word Reading Times Better Than Empirical Predictability. (arXiv:2202.01128v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01128">
<div class="article-summary-box-inner">
<span><p>Though there is a strong consensus that word length and frequency are the
most important single-word features determining visual-orthographic access to
the mental lexicon, there is less agreement as how to best capture syntactic
and semantic factors. The traditional approach in cognitive reading research
assumes that word predictability from sentence context is best captured by
cloze completion probability (CCP) derived from human performance data. We
review recent research suggesting that probabilistic language models provide
deeper explanations for syntactic and semantic effects than CCP. Then we
compare CCP with (1) Symbolic n-gram models consolidate syntactic and semantic
short-range relations by computing the probability of a word to occur, given
two preceding words. (2) Topic models rely on subsymbolic representations to
capture long-range semantic similarity by word co-occurrence counts in
documents. (3) In recurrent neural networks (RNNs), the subsymbolic units are
trained to predict the next word, given all preceding words in the sentences.
To examine lexical retrieval, these models were used to predict single fixation
durations and gaze durations to capture rapidly successful and standard lexical
access, and total viewing time to capture late semantic integration. The linear
item-level analyses showed greater correlations of all language models with all
eye-movement measures than CCP. Then we examined non-linear relations between
the different types of predictability and the reading times using generalized
additive models. N-gram and RNN probabilities of the present word more
consistently predicted reading performance compared with topic models or CCP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relative Position Prediction as Pre-training for Text Encoders. (arXiv:2202.01145v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01145">
<div class="article-summary-box-inner">
<span><p>Meaning is defined by the company it keeps. However, company is two-fold:
It's based on the identity of tokens and also on their position (topology). We
argue that a position-centric perspective is more general and useful. The
classic MLM and CLM objectives in NLP are easily phrased as position
predictions over the whole vocabulary. Adapting the relative position encoding
paradigm in NLP to create relative labels for self-supervised learning, we seek
to show superior pre-training judged by performance on downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The slurk Interaction Server Framework: Better Data for Better Dialog Models. (arXiv:2202.01155v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01155">
<div class="article-summary-box-inner">
<span><p>This paper presents the slurk software, a lightweight interaction server for
setting up dialog data collections and running experiments. Slurk enables a
multitude of settings including text-based, speech and video interaction
between two or more humans or humans and bots, and a multimodal display area
for presenting shared or private interactive context. The software is
implemented in Python with an HTML and JS frontend that can easily be adapted
to individual needs. It also provides a setup for pairing participants on
common crowdworking platforms such as Amazon Mechanical Turk and some example
bot scripts for common interaction scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Error Correction in ASR using Sequence-to-Sequence Models. (arXiv:2202.01157v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01157">
<div class="article-summary-box-inner">
<span><p>Post-editing in Automatic Speech Recognition (ASR) entails automatically
correcting common and systematic errors produced by the ASR system. The outputs
of an ASR system are largely prone to phonetic and spelling errors. In this
paper, we propose to use a powerful pre-trained sequence-to-sequence model,
BART, further adaptively trained to serve as a denoising model, to correct
errors of such types. The adaptive training is performed on an augmented
dataset obtained by synthetically inducing errors as well as by incorporating
actual errors from an existing ASR system. We also propose a simple approach to
rescore the outputs using word level alignments. Experimental results on
accented speech data demonstrate that our strategy effectively rectifies a
significant number of ASR errors and produces improved WER results when
compared against a competitive baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">L3Cube-MahaCorpus and MahaBERT: Marathi Monolingual Corpus, Marathi BERT Language Models, and Resources. (arXiv:2202.01159v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01159">
<div class="article-summary-box-inner">
<span><p>We present L3Cube-MahaCorpus a Marathi monolingual data set scraped from
different internet sources. We expand the existing Marathi monolingual corpus
with 24.8M sentences and 289M tokens. We further present, MahaBERT, MahaAlBERT,
and MahaRoBerta all BERT-based masked language models, and MahaFT, the fast
text word embeddings both trained on full Marathi corpus with 752M tokens. We
show the effectiveness of these resources on downstream classification and NER
tasks. Marathi is a popular language in India but still lacks these resources.
This work is a step forward in building open resources for the Marathi
language. The data and models are available at
https://github.com/l3cube-pune/MarathiNLP .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Scaling Laws for Routed Language Models. (arXiv:2202.01169v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01169">
<div class="article-summary-box-inner">
<span><p>The performance of a language model has been shown to be effectively modeled
as a power-law in its parameter count. Here we study the scaling behaviors of
Routing Networks: architectures that conditionally use only a subset of their
parameters while processing an input. For these models, parameter count and
computational requirement form two independent axes along which an increase
leads to better performance. In this work we derive and justify scaling laws
defined on these two variables which generalize those known for standard
language models and describe the performance of a wide range of routing
architectures trained via three different techniques. Afterwards we provide two
applications of these laws: first deriving an Effective Parameter Count along
which all models scale at the same rate, and then using the scaling
coefficients to give a quantitative comparison of the three routing techniques
considered. Our analysis derives from an extensive evaluation of Routing
Networks across five orders of magnitude of size, including models with
hundreds of experts and hundreds of billions of parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Epidemic Dreams: Dreaming about health during the COVID-19 pandemic. (arXiv:2202.01176v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01176">
<div class="article-summary-box-inner">
<span><p>The continuity hypothesis of dreams suggests that the content of dreams is
continuous with the dreamer's waking experiences. Given the unprecedented
nature of the experiences during COVID-19, we studied the continuity hypothesis
in the context of the pandemic. We implemented a deep-learning algorithm that
can extract mentions of medical conditions from text and applied it to two
datasets collected during the pandemic: 2,888 dream reports (dreaming life
experiences), and 57M tweets mentioning the pandemic (waking life experiences).
The health expressions common to both sets were typical COVID-19 symptoms
(e.g., cough, fever, and anxiety), suggesting that dreams reflected people's
real-world experiences. The health expressions that distinguished the two sets
reflected differences in thought processes: expressions in waking life
reflected a linear and logical thought process and, as such, described
realistic symptoms or related disorders (e.g., nasal pain, SARS, H1N1); those
in dreaming life reflected a thought process closer to the visual and emotional
spheres and, as such, described either conditions unrelated to the virus (e.g.,
maggots, deformities, snakebites), or conditions of surreal nature (e.g., teeth
falling out, body crumbling into sand). Our results confirm that dream reports
represent an understudied yet valuable source of people's health experiences in
the real world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information Extraction through AI techniques: The KIDs use case at CONSOB. (arXiv:2202.01178v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01178">
<div class="article-summary-box-inner">
<span><p>In this paper we report on the initial activities carried out within a
collaboration between Consob and Sapienza University. We focus on Information
Extraction from documents describing financial instruments. We discuss how we
automate this task, via both rule-based and machine learning-based methods and
provide our first results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Systematic Comparison of Architectures for Document-Level Sentiment Classification. (arXiv:2002.08131v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.08131">
<div class="article-summary-box-inner">
<span><p>Documents are composed of smaller pieces - paragraphs, sentences, and tokens
- that have complex relationships between one another. Sentiment classification
models that take into account the structure inherent in these documents have a
theoretical advantage over those that do not. At the same time, transfer
learning models based on language model pretraining have shown promise for
document classification. However, these two paradigms have not been
systematically compared and it is not clear under which circumstances one
approach is better than the other. In this work we empirically compare
hierarchical models and transfer learning for document-level sentiment
classification. We show that non-trivial hierarchical models outperform
previous baselines and transfer learning on document-level sentiment
classification in five languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Specifying and Interpreting Reinforcement Learning Policies through Simulatable Machine Learning. (arXiv:2101.07140v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07140">
<div class="article-summary-box-inner">
<span><p>Human-AI collaborative policy synthesis is a procedure in which (1) a human
initializes an autonomous agent's behavior, (2) Reinforcement Learning improves
the human specified behavior, and (3) the agent can explain the final optimized
policy to the user. This paradigm leverages human expertise and facilitates a
greater insight into the learned behaviors of an agent. Existing approaches to
enabling collaborative policy specification involve black box methods which are
unintelligible and are not catered towards non-expert end-users. In this paper,
we develop a novel collaborative framework to enable humans to initialize and
interpret an autonomous agent's behavior, rooted in principles of
human-centered design. Through our framework, we enable humans to specify an
initial behavior model in the form of unstructured, natural language, which we
then convert to lexical decision trees. Next, we are able to leverage these
human-specified policies, to warm-start reinforcement learning and further
allow the agent to optimize the policies through reinforcement learning.
Finally, to close the loop on human-specification, we produce explanations of
the final learned policy, in multiple modalities, to provide the user a final
depiction about the learned policy of the agent. We validate our approach by
showing that our model can produce &gt;80% accuracy, and that human-initialized
policies are able to successfully warm-start RL. We then conduct a novel
human-subjects study quantifying the relative subjective and objective benefits
of varying XAI modalities(e.g., Tree, Language, and Program) for explaining
learned policies to end-users, in terms of usability and interpretability and
identify the circumstances that influence these measures. Our findings
emphasize the need for personalized explainable systems that can facilitate
user-centric policy explanations for a variety of end-users.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graph Question Answering using Graph-Pattern Isomorphism. (arXiv:2103.06752v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06752">
<div class="article-summary-box-inner">
<span><p>Knowledge Graph Question Answering (KGQA) systems are based on machine
learning algorithms, requiring thousands of question-answer pairs as training
examples or natural language processing pipelines that need module fine-tuning.
In this paper, we present a novel QA approach, dubbed TeBaQA. Our approach
learns to answer questions based on graph isomorphisms from basic graph
patterns of SPARQL queries. Learning basic graph patterns is efficient due to
the small number of possible patterns. This novel paradigm reduces the amount
of training data necessary to achieve state-of-the-art performance. TeBaQA also
speeds up the domain adaption process by transforming the QA system development
task into a much smaller and easier data compilation task. In our evaluation,
TeBaQA achieves state-of-the-art performance on QALD-8 and delivers comparable
results on QALD-9 and LC-QuAD v1. Additionally, we performed a fine-grained
evaluation on complex queries that deal with aggregation and superlative
questions as well as an ablation study, highlighting future research
challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NodePiece: Compositional and Parameter-Efficient Representations of Large Knowledge Graphs. (arXiv:2106.12144v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12144">
<div class="article-summary-box-inner">
<span><p>Conventional representation learning algorithms for knowledge graphs (KG) map
each entity to a unique embedding vector. Such a shallow lookup results in a
linear growth of memory consumption for storing the embedding matrix and incurs
high computational costs when working with real-world KGs. Drawing parallels
with subword tokenization commonly used in NLP, we explore the landscape of
more parameter-efficient node embedding strategies with possibly sublinear
memory requirements. To this end, we propose NodePiece, an anchor-based
approach to learn a fixed-size entity vocabulary. In NodePiece, a vocabulary of
subword/sub-entity units is constructed from anchor nodes in a graph with known
relation types. Given such a fixed-size vocabulary, it is possible to bootstrap
an encoding and embedding for any entity, including those unseen during
training. Experiments show that NodePiece performs competitively in node
classification, link prediction, and relation prediction tasks while retaining
less than 10% of explicit nodes in a graph as anchors and often having 10x
fewer parameters. To this end, we show that a NodePiece-enabled model
outperforms existing shallow models on a large OGB WikiKG 2 graph having 70x
fewer parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classifying Textual Data with Pre-trained Vision Models through Transfer Learning and Data Transformations. (arXiv:2106.12479v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12479">
<div class="article-summary-box-inner">
<span><p>Knowledge is acquired by humans through experience, and no boundary is set
between the kinds of knowledge or skill levels we can achieve on different
tasks at the same time. When it comes to Neural Networks, that is not the case.
The breakthroughs in the field are extremely task and domain-specific. Vision
and language are dealt with in separate manners, using separate methods and
different datasets. Current text classification methods, mostly rely on
obtaining contextual embeddings for input text samples, then training a
classifier on the embedded dataset. Transfer learning in Language-related tasks
in general, is heavily used in obtaining the contextual text embeddings for the
input samples. In this work, we propose to use the knowledge acquired by
benchmark Vision Models which are trained on ImageNet to help a much smaller
architecture learn to classify text. A data transformation technique is used to
create a new image dataset, where each image represents a sentence embedding
from the last six layers of BERT, projected on a 2D plane using a t-SNE based
method. We trained five models containing early layers sliced from vision
models which are pretrained on ImageNet, on the created image dataset for the
IMDB dataset embedded with the last six layers of BERT. Despite the challenges
posed by the very different datasets, experimental results achieved by this
approach which links large pretrained models on both language and vision, are
very promising, without employing compute resources. Specifically, Sentiment
Analysis is achieved by five different models on the same image dataset
obtained after BERT embeddings are transformed into gray scale images.
</p>
<p>Index Terms: BERT, Convolutional Neural Networks, Domain Adaptation, image
classification, Natural Language Processing, t-SNE, text classification,
Transfer Learning
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Language Model for Efficient Linguistic Steganalysis. (arXiv:2107.12168v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12168">
<div class="article-summary-box-inner">
<span><p>Recent advances in linguistic steganalysis have successively applied CNN,
RNN, GNN and other efficient deep models for detecting secret information in
generative texts. These methods tend to seek stronger feature extractors to
achieve higher steganalysis effects. However, we have found through experiments
that there actually exists significant difference between automatically
generated stego texts and carrier texts in terms of the conditional probability
distribution of individual words. Such kind of difference can be naturally
captured by the language model used for generating stego texts. Through further
experiments, we conclude that this ability can be transplanted to a text
classifier by pre-training and fine-tuning to improve the detection
performance. Motivated by this insight, we propose two methods for efficient
linguistic steganalysis. One is to pre-train a language model based on RNN, and
the other is to pre-train a sequence autoencoder. The results indicate that the
two methods have different degrees of performance gain compared to the randomly
initialized RNN, and the convergence speed is significantly accelerated.
Moreover, our methods achieved the best performance compared to related works,
while providing a solution for real-world scenario where there are more cover
texts than stego texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Efficient DP-SGD Mechanism for Large Scale NLP Models. (arXiv:2107.14586v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14586">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning have drastically improved performance on
many Natural Language Understanding (NLU) tasks. However, the data used to
train NLU models may contain private information such as addresses or phone
numbers, particularly when drawn from human subjects. It is desirable that
underlying models do not expose private information contained in the training
data. Differentially Private Stochastic Gradient Descent (DP-SGD) has been
proposed as a mechanism to build privacy-preserving models. However, DP-SGD can
be prohibitively slow to train. In this work, we propose a more efficient
DP-SGD for training using a GPU infrastructure and apply it to fine-tuning
models based on LSTM and transformer architectures. We report faster training
times, alongside accuracy, theoretical privacy guarantees and success of
Membership inference attacks for our models and observe that fine-tuning with
proposed variant of DP-SGD can yield competitive models without significant
degradation in training time and improvement in privacy protection. We also
make observations such as looser theoretical $\epsilon, \delta$ can translate
into significant practical privacy gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey of Low-Resource Machine Translation. (arXiv:2109.00486v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00486">
<div class="article-summary-box-inner">
<span><p>We present a survey covering the state of the art in low-resource machine
translation research. There are currently around 7000 languages spoken in the
world and almost all language pairs lack significant resources for training
machine translation models. There has been increasing interest in research
addressing the challenge of producing useful translation models when very
little translated training data is available. We present a summary of this
topical research field and provide a description of the techniques evaluated by
researchers in several recent shared tasks in low-resource MT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Unified View of Parameter-Efficient Transfer Learning. (arXiv:2110.04366v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04366">
<div class="article-summary-box-inner">
<span><p>Fine-tuning large pre-trained language models on downstream tasks has become
the de-facto learning paradigm in NLP. However, conventional approaches
fine-tune all the parameters of the pre-trained model, which becomes
prohibitive as the model size and the number of tasks grow. Recent work has
proposed a variety of parameter-efficient transfer learning methods that only
fine-tune a small number of (extra) parameters to attain strong performance.
While effective, the critical ingredients for success and the connections among
the various methods are poorly understood. In this paper, we break down the
design of state-of-the-art parameter-efficient transfer learning methods and
present a unified framework that establishes connections between them.
Specifically, we re-frame them as modifications to specific hidden states in
pre-trained models, and define a set of design dimensions along which different
methods vary, such as the function to compute the modification and the position
to apply the modification. Through comprehensive empirical studies across
machine translation, text summarization, language understanding, and text
classification benchmarks, we utilize the unified view to identify important
design choices in previous methods. Furthermore, our unified framework enables
the transfer of design elements across different approaches, and as a result we
are able to instantiate new parameter-efficient fine-tuning methods that tune
less parameters than previous methods while being more effective, achieving
comparable results to fine-tuning all parameters on all four tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Pretrained Language Models Based Text Generation. (arXiv:2201.05273v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05273">
<div class="article-summary-box-inner">
<span><p>Text Generation aims to produce plausible and readable text in human language
from input data. The resurgence of deep learning has greatly advanced this
field by neural generation models, especially the paradigm of pretrained
language models (PLMs). Grounding text generation on PLMs is seen as a
promising direction in both academia and industry. In this survey, we present
the recent advances achieved in the topic of PLMs for text generation. In
detail, we begin with introducing three key points of applying PLMs to text
generation: 1) how to encode the input data as representations preserving input
semantics which can be fused into PLMs; 2) how to design a universal and
performant architecture of PLMs served as generation models; and 3) how to
optimize PLMs given the reference text and ensure the generated text satisfying
special text properties. Then, we figure out several challenges and future
directions within each key point. Next, we present a summary of various useful
resources and typical text generation applications to work with PLMs. Finally,
we conclude and summarize the contribution of this survey.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Dependencies in Adversarial Attacks on Speech Recognition Systems. (arXiv:2202.00399v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00399">
<div class="article-summary-box-inner">
<span><p>Automatic speech recognition (ASR) systems are ubiquitously present in our
daily devices. They are vulnerable to adversarial attacks, where manipulated
input samples fool the ASR system's recognition. While adversarial examples for
various English ASR systems have already been analyzed, there exists no
inter-language comparative vulnerability analysis. We compare the attackability
of a German and an English ASR system, taking Deepspeech as an example. We
investigate if one of the language models is more susceptible to manipulations
than the other. The results of our experiments suggest statistically
significant differences between English and German in terms of computational
effort necessary for the successful generation of adversarial examples. This
result encourages further research in language-dependent characteristics in the
robustness analysis of ASR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal effect of racial bias in data and machine learning algorithms on user persuasiveness & discriminatory decision making: An Empirical Study. (arXiv:2202.00471v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00471">
<div class="article-summary-box-inner">
<span><p>Language data and models demonstrate various types of bias, be it ethnic,
religious, gender, or socioeconomic. AI/NLP models, when trained on the
racially biased dataset, AI/NLP models instigate poor model explainability,
influence user experience during decision making and thus further magnifies
societal biases, raising profound ethical implications for society. The
motivation of the study is to investigate how AI systems imbibe bias from data
and produce unexplainable discriminatory outcomes and influence an individual's
articulateness of system outcome due to the presence of racial bias features in
datasets. The design of the experiment involves studying the counterfactual
impact of racial bias features present in language datasets and its associated
effect on the model outcome. A mixed research methodology is adopted to
investigate the cross implication of biased model outcome on user experience,
effect on decision-making through controlled lab experimentation. The findings
provide foundation support for correlating the implication of carry-over an
artificial intelligence model solving NLP task due to biased concept presented
in the dataset. Further, the research outcomes justify the negative influence
on users' persuasiveness that leads to alter the decision-making quotient of an
individual when trying to rely on the model outcome to act. The paper bridges
the gap across the harm caused in establishing poor customer trustworthiness
due to an inequitable system design and provides strong support for
researchers, policymakers, and data scientists to build responsible AI
frameworks within organizations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Examining Scaling and Transfer of Language Model Architectures for Machine Translation. (arXiv:2202.00528v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00528">
<div class="article-summary-box-inner">
<span><p>Natural language understanding and generation models follow one of the two
dominant architectural paradigms: language models (LMs) that process
concatenated sequences in a single stack of layers, and encoder-decoder models
(EncDec) that utilize separate layer stacks for input and output processing. In
machine translation, EncDec has long been the favoured approach, but with few
studies investigating the performance of LMs. In this work, we thoroughly
examine the role of several architectural design choices on the performance of
LMs on bilingual, (massively) multilingual and zero-shot translation tasks,
under systematic variations of data conditions and model sizes. Our results
show that: (i) Different LMs have different scaling properties, where
architectural differences often have a significant impact on model performance
at small scales, but the performance gap narrows as the number of parameters
increases, (ii) Several design choices, including causal masking and
language-modeling objectives for the source sequence, have detrimental effects
on translation quality, and (iii) When paired with full-visible masking for
source sequences, LMs could perform on par with EncDec on supervised bilingual
and multilingual translation tasks, and improve greatly on zero-shot directions
by facilitating the reduction of off-target translations.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">A training-free recursive multiresolution framework for diffeomorphic deformable image registration. (arXiv:2202.00675v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00675">
<div class="article-summary-box-inner">
<span><p>Diffeomorphic deformable image registration is one of the crucial tasks in
medical image analysis, which aims to find a unique transformation while
preserving the topology and invertibility of the transformation. Deep
convolutional neural networks (CNNs) have yielded well-suited approaches for
image registration by learning the transformation priors from a large dataset.
The improvement in the performance of these methods is related to their ability
to learn information from several sample medical images that are difficult to
obtain and bias the framework to the specific domain of data. In this paper, we
propose a novel diffeomorphic training-free approach; this is built upon the
principle of an ordinary differential equation.
</p>
<p>Our formulation yields an Euler integration type recursive scheme to estimate
the changes of spatial transformations between the fixed and the moving image
pyramids at different resolutions. The proposed architecture is simple in
design. The moving image is warped successively at each resolution and finally
aligned to the fixed image; this procedure is recursive in a way that at each
resolution, a fully convolutional network (FCN) models a progressive change of
deformation for the current warped image. The entire system is end-to-end and
optimized for each pair of images from scratch. In comparison to learning-based
methods, the proposed method neither requires a dedicated training set nor
suffers from any training bias. We evaluate our method on three cardiac image
datasets. The evaluation results demonstrate that the proposed method achieves
state-of-the-art registration accuracy while maintaining desirable
diffeomorphic properties.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A deep residual learning implementation of Metamorphosis. (arXiv:2202.00676v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00676">
<div class="article-summary-box-inner">
<span><p>In medical imaging, most of the image registration methods implicitly assume
a one-to-one correspondence between the source and target images (i.e.,
diffeomorphism). However, this is not necessarily the case when dealing with
pathological medical images (e.g., presence of a tumor, lesion, etc.). To cope
with this issue, the Metamorphosis model has been proposed. It modifies both
the shape and the appearance of an image to deal with the geometrical and
topological differences. However, the high computational time and load have
hampered its applications so far. Here, we propose a deep residual learning
implementation of Metamorphosis that drastically reduces the computational time
at inference. Furthermore, we also show that the proposed framework can easily
integrate prior knowledge of the localization of topological changes (e.g.,
segmentation masks) that can act as spatial regularization to correctly
disentangle appearance and shape changes. We test our method on the BraTS 2021
dataset, showing that it outperforms current state-of-the-art methods in the
alignment of images with brain tumors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Embarrassingly Simple Consistency Regularization Method for Semi-Supervised Medical Image Segmentation. (arXiv:2202.00677v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00677">
<div class="article-summary-box-inner">
<span><p>The scarcity of pixel-level annotation is a prevalent problem in medical
image segmentation tasks. In this paper, we introduce a novel regularization
strategy involving interpolation-based mixing for semi-supervised medical image
segmentation. The proposed method is a new consistency regularization strategy
that encourages segmentation of interpolation of two unlabelled data to be
consistent with the interpolation of segmentation maps of those data. This
method represents a specific type of data-adaptive regularization paradigm
which aids to minimize the overfitting of labelled data under high confidence
values. The proposed method is advantageous over adversarial and generative
models as it requires no additional computation. Upon evaluation on two
publicly available MRI datasets: ACDC and MMWHS, experimental results
demonstrate the superiority of the proposed method in comparison to existing
semi-supervised models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of Skin Cancer Images using Convolutional Neural Networks. (arXiv:2202.00678v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00678">
<div class="article-summary-box-inner">
<span><p>Skin cancer is the most common human malignancy(American Cancer Society)
which is primarily diagnosed visually, starting with an initial clinical
screening and followed potentially by dermoscopic(related to skin) analysis, a
biopsy and histopathological examination. Skin cancer occurs when errors
(mutations) occur in the DNA of skin cells. The mutations cause the cells to
grow out of control and form a mass of cancer cells. The aim of this study was
to try to classify images of skin lesions with the help of convolutional neural
networks. The deep neural networks show humongous potential for image
classification while taking into account the large variability exhibited by the
environment. Here we trained images based on the pixel values and classified
them on the basis of disease labels. The dataset was acquired from an Open
Source Kaggle Repository(Kaggle Dataset)which itself was acquired from
ISIC(International Skin Imaging Collaboration) Archive. The training was
performed on multiple models accompanied with Transfer Learning. The highest
model accuracy achieved was over 86.65%. The dataset used is publicly available
to ensure credibility and reproducibility of the aforementioned result.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Should I take a walk? Estimating Energy Expenditure from Video Data. (arXiv:2202.00712v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00712">
<div class="article-summary-box-inner">
<span><p>We explore the problem of automatically inferring the amount of kilocalories
used by human during physical activity from his/her video observation. To study
this underresearched task, we introduce Vid2Burn -- an omni-source benchmark
for estimating caloric expenditure from video data featuring both, high- and
low-intensity activities for which we derive energy expenditure annotations
based on models established in medical literature. In practice, a training set
would only cover a certain amount of activity types, and it is important to
validate, if the model indeed captures the essence of energy expenditure,
(e.g., how many and which muscles are involved and how intense they work)
instead of memorizing fixed values of specific activity categories seen during
training. Ideally, the models should look beyond such category-specific biases
and regress the caloric cost in videos depicting activity categories not
explicitly present during training. With this property in mind, Vid2Burn is
accompanied with a cross-category benchmark, where the task is to regress
caloric expenditure for types of physical activities not present during
training. An extensive evaluation of state-of-the-art approaches for video
recognition modified for the energy expenditure estimation task demonstrates
the difficulty of this problem, especially for new activity types at test-time,
marking a new research direction. Dataset and code are available at
https://github.com/KPeng9510/Vid2Burn.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IFOR: Iterative Flow Minimization for Robotic Object Rearrangement. (arXiv:2202.00732v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00732">
<div class="article-summary-box-inner">
<span><p>Accurate object rearrangement from vision is a crucial problem for a wide
variety of real-world robotics applications in unstructured environments. We
propose IFOR, Iterative Flow Minimization for Robotic Object Rearrangement, an
end-to-end method for the challenging problem of object rearrangement for
unknown objects given an RGBD image of the original and final scenes. First, we
learn an optical flow model based on RAFT to estimate the relative
transformation of the objects purely from synthetic data. This flow is then
used in an iterative minimization algorithm to achieve accurate positioning of
previously unseen objects. Crucially, we show that our method applies to
cluttered scenes, and in the real world, while training only on synthetic data.
Videos are available at https://imankgoyal.github.io/ifor.html.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Positive Jacobian: Learn to Postprocess Diffeomorphic Image Registration with Matrix Exponential. (arXiv:2202.00749v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00749">
<div class="article-summary-box-inner">
<span><p>We present a postprocessing layer for deformable image registration to make a
registration field more diffeomorphic by encouraging Jacobians of the
transformation to be positive. Diffeomorphic image registration is important
for medical imaging studies because of the properties like invertibility,
smoothness of the transformation, and topology preservation/non-folding of the
grid. Violation of these properties can lead to destruction of the
neighbourhood and the connectivity of anatomical structures during image
registration. Most of the recent deep learning methods do not explicitly
address this folding problem and try to solve it with a smoothness
regularization on the registration field. In this paper, we propose a
differentiable layer, which takes any registration field as its input, computes
exponential of the Jacobian matrices of the input and reconstructs a new
registration field from the exponentiated Jacobian matrices using Poisson
reconstruction. Our proposed Poisson reconstruction loss enforces positive
Jacobians for the final registration field. Thus, our method acts as a
post-processing layer without any learnable parameters of its own and can be
placed at the end of any deep learning pipeline to form an end-to-end learnable
framework. We show the effectiveness of our proposed method for a popular deep
learning registration method Voxelmorph and evaluate it with a dataset
containing 3D brain MRI scans. Our results show that our post-processing can
effectively decrease the number of non-positive Jacobians by a significant
amount without any noticeable deterioration of the registration accuracy, thus
making the registration field more diffeomorphic. Our code is available online
at
https://github.com/Soumyadeep-Pal/Diffeomorphic-Image-Registration-Postprocess.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ADG-Pose: Automated Dataset Generation for Real-World Human Pose Estimation. (arXiv:2202.00753v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00753">
<div class="article-summary-box-inner">
<span><p>Recent advancements in computer vision have seen a rise in the prominence of
applications using neural networks to understand human poses. However, while
accuracy has been steadily increasing on State-of-the-Art datasets, these
datasets often do not address the challenges seen in real-world applications.
These challenges are dealing with people distant from the camera, people in
crowds, and heavily occluded people. As a result, many real-world applications
have trained on data that does not reflect the data present in deployment,
leading to significant underperformance. This article presents ADG-Pose, a
method for automatically generating datasets for real-world human pose
estimation. These datasets can be customized to determine person distances,
crowdedness, and occlusion distributions. Models trained with our method are
able to perform in the presence of these challenges where those trained on
other datasets fail. Using ADG-Pose, end-to-end accuracy for real-world
skeleton-based action recognition sees a 20% increase on scenes with moderate
distance and occlusion levels, and a 4X increase on distant scenes where other
models failed to perform better than random.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Model for Multi-View Residual Covariances based on Perspective Deformation. (arXiv:2202.00765v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00765">
<div class="article-summary-box-inner">
<span><p>In this work, we derive a model for the covariance of the visual residuals in
multi-view SfM, odometry and SLAM setups. The core of our approach is the
formulation of the residual covariances as a combination of geometric and
photometric noise sources. And our key novel contribution is the derivation of
a term modelling how local 2D patches suffer from perspective deformation when
imaging 3D surfaces around a point. Together, these add up to an efficient and
general formulation which not only improves the accuracy of both feature-based
and direct methods, but can also be used to estimate more accurate measures of
the state entropy and hence better founded point visibility thresholds. We
validate our model with synthetic and real data and integrate it into
photometric and feature-based Bundle Adjustment, improving their accuracy with
a negligible overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Local Feature Matching with Transformers for low-end devices. (arXiv:2202.00770v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00770">
<div class="article-summary-box-inner">
<span><p>LoFTR <a href="/abs/2104.00680">arXiv:2104.00680</a> is an efficient deep learning method for finding
appropriate local feature matches on image pairs. This paper reports on the
optimization of this method to work on devices with low computational
performance and limited memory. The original LoFTR approach is based on a
ResNet <a href="/abs/1512.03385">arXiv:1512.03385</a> head and two modules based on Linear Transformer
<a href="/abs/2006.04768">arXiv:2006.04768</a> architecture. In the presented work, only the coarse-matching
block was left, the number of parameters was significantly reduced, and the
network was trained using a knowledge distillation technique. The comparison
showed that this approach allows to obtain an appropriate feature detection
accuracy for the student model compared to the teacher model in the coarse
matching block, despite the significant reduction of model size. Also, the
paper shows additional steps required to make model compatible with NVIDIA
TensorRT runtime, and shows an approach to optimize training method for low-end
GPUs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerating DNN Training with Structured Data Gradient Pruning. (arXiv:2202.00774v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00774">
<div class="article-summary-box-inner">
<span><p>Weight pruning is a technique to make Deep Neural Network (DNN) inference
more computationally efficient by reducing the number of model parameters over
the course of training. However, most weight pruning techniques generally does
not speed up DNN training and can even require more iterations to reach model
convergence. In this work, we propose a novel Structured Data Gradient Pruning
(SDGP) method that can speed up training without impacting model convergence.
This approach enforces a specific sparsity structure, where only N out of every
M elements in a matrix can be nonzero, making it amenable to hardware
acceleration. Modern accelerators such as the Nvidia A100 GPU support this type
of structured sparsity for 2 nonzeros per 4 elements in a reduction. Assuming
hardware support for 2:4 sparsity, our approach can achieve a 15-25\% reduction
in total training time without significant impact to performance. Source code
and pre-trained models are available at
\url{https://github.com/BradMcDanel/sdgp}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Regularizing Coordinate-MLPs. (arXiv:2202.00790v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00790">
<div class="article-summary-box-inner">
<span><p>We show that typical implicit regularization assumptions for deep neural
networks (for regression) do not hold for coordinate-MLPs, a family of MLPs
that are now ubiquitous in computer vision for representing high-frequency
signals. Lack of such implicit bias disrupts smooth interpolations between
training samples, and hampers generalizing across signal regions with different
spectra. We investigate this behavior through a Fourier lens and uncover that
as the bandwidth of a coordinate-MLP is enhanced, lower frequencies tend to get
suppressed unless a suitable prior is provided explicitly. Based on these
insights, we propose a simple regularization technique that can mitigate the
above problem, which can be incorporated into existing networks without any
architectural modifications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mars Terrain Segmentation with Less Labels. (arXiv:2202.00791v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00791">
<div class="article-summary-box-inner">
<span><p>Planetary rover systems need to perform terrain segmentation to identify
drivable areas as well as identify specific types of soil for sample
collection. The latest Martian terrain segmentation methods rely on supervised
learning which is very data hungry and difficult to train where only a small
number of labeled samples are available. Moreover, the semantic classes are
defined differently for different applications (e.g., rover traversal vs.
geological) and as a result the network has to be trained from scratch each
time, which is an inefficient use of resources. This research proposes a
semi-supervised learning framework for Mars terrain segmentation where a deep
segmentation network trained in an unsupervised manner on unlabeled images is
transferred to the task of terrain segmentation trained on few labeled images.
The network incorporates a backbone module which is trained using a contrastive
loss function and an output atrous convolution module which is trained using a
pixel-wise cross-entropy loss function. Evaluation results using the metric of
segmentation accuracy show that the proposed method with contrastive
pretraining outperforms plain supervised learning by 2%-10%. Moreover, the
proposed model is able to achieve a segmentation accuracy of 91.1% using only
161 training images (1% of the original dataset) compared to 81.9% with plain
supervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Graph Based Neural Network Approach to Immune Profiling of Multiplexed Tissue Samples. (arXiv:2202.00813v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00813">
<div class="article-summary-box-inner">
<span><p>Multiplexed immunofluorescence provides an unprecedented opportunity for
studying specific cell-to-cell and cell microenvironment interactions. We
employ graph neural networks to combine features obtained from tissue
morphology with measurements of protein expression to profile the tumour
microenvironment associated with different tumour stages. Our framework
presents a new approach to analysing and processing these complex
multi-dimensional datasets that overcomes some of the key challenges in
analysing these data and opens up the opportunity to abstract biologically
meaningful interactions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On-Sensor Binarized Fully Convolutional Neural Network with A Pixel Processor Array. (arXiv:2202.00836v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00836">
<div class="article-summary-box-inner">
<span><p>This work presents a method to implement fully convolutional neural networks
(FCNs) on Pixel Processor Array (PPA) sensors, and demonstrates coarse
segmentation and object localisation tasks. We design and train binarized FCN
for both binary weights and activations using batchnorm, group convolution, and
learnable threshold for binarization, producing networks small enough to be
embedded on the focal plane of the PPA, with limited local memory resources,
and using parallel elementary add/subtract, shifting, and bit operations only.
We demonstrate the first implementation of an FCN on a PPA device, performing
three convolution layers entirely in the pixel-level processors. We use this
architecture to demonstrate inference generating heat maps for object
segmentation and localisation at over 280 FPS using the SCAMP-5 PPA vision
chip.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finding Biological Plausibility for Adversarially Robust Features via Metameric Tasks. (arXiv:2202.00838v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00838">
<div class="article-summary-box-inner">
<span><p>Recent work suggests that representations learned by adversarially robust
networks are more human perceptually-aligned than non-robust networks via image
manipulations. Despite appearing closer to human visual perception, it is
unclear if the constraints in robust DNN representations match biological
constraints found in human vision. Human vision seems to rely on
texture-based/summary statistic representations in the periphery, which have
been shown to explain phenomena such as crowding and performance on visual
search tasks. To understand how adversarially robust
optimizations/representations compare to human vision, we performed a
psychophysics experiment using a set of metameric discrimination tasks where we
evaluated how well human observers could distinguish between images synthesized
to match adversarially robust representations compared to non-robust
representations and a texture synthesis model of peripheral vision (Texforms).
We found that the discriminability of robust representation and texture model
images decreased to near chance performance as stimuli were presented farther
in the periphery. Moreover, performance on robust and texture-model images
showed similar trends within participants, while performance on non-robust
representations changed minimally across the visual field. These results
together suggest that (1) adversarially robust representations capture
peripheral computation better than non-robust representations and (2) robust
representations capture peripheral computation similar to current
state-of-the-art texture peripheral vision models. More broadly, our findings
support the idea that localized texture summary statistic representations may
drive human invariance to adversarial perturbations and that the incorporation
of such representations in DNNs could give rise to useful properties like
adversarial robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pose Guided Image Generation from Misaligned Sources via Residual Flow Based Correction. (arXiv:2202.00843v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00843">
<div class="article-summary-box-inner">
<span><p>Generating new images with desired properties (e.g. new view/poses) from
source images has been enthusiastically pursued recently, due to its wide range
of potential applications. One way to ensure high-quality generation is to use
multiple sources with complementary information such as different views of the
same object. However, as source images are often misaligned due to the large
disparities among the camera settings, strong assumptions have been made in the
past with respect to the camera(s) or/and the object in interest, limiting the
application of such techniques. Therefore, we propose a new general approach
which models multiple types of variations among sources, such as view angles,
poses, facial expressions, in a unified framework, so that it can be employed
on datasets of vastly different nature. We verify our approach on a variety of
data including humans bodies, faces, city scenes and 3D objects. Both the
qualitative and quantitative results demonstrate the better performance of our
method than the state of the art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Audio-Visual Separation of Dynamic Sound Sources. (arXiv:2202.00850v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00850">
<div class="article-summary-box-inner">
<span><p>We explore active audio-visual separation for dynamic sound sources, where an
embodied agent moves intelligently in a 3D environment to continuously isolate
the time-varying audio stream being emitted by an object of interest. The agent
hears a mixed stream of multiple time-varying audio sources (e.g., multiple
people conversing and a band playing music at a noisy party). Given a limited
time budget, it needs to extract the target sound using egocentric audio-visual
observations. We propose a reinforcement learning agent equipped with a novel
transformer memory that learns motion policies to control its camera and
microphone to recover the dynamic target audio, improving its own estimates for
past timesteps via self-attention. Using highly realistic acoustic SoundSpaces
simulations in real-world scanned Matterport3D environments, we show that our
model is able to learn efficient behavior to carry out continuous separation of
a time-varying audio target. Project:
https://vision.cs.utexas.edu/projects/active-av-dynamic-separation/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extension -- Adaptive Sampling with Implicit Radiance Field. (arXiv:2202.00855v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00855">
<div class="article-summary-box-inner">
<span><p>This paper aims to explore and summarize the state-of-the-art progress in
Monte Carlo adaptive light field sampling and reconstruction using deep
reinforcement learning, with possible extension to it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoupled IoU Regression for Object Detection. (arXiv:2202.00866v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00866">
<div class="article-summary-box-inner">
<span><p>Non-maximum suppression (NMS) is widely used in object detection pipelines
for removing duplicated bounding boxes. The inconsistency between the
confidence for NMS and the real localization confidence seriously affects
detection performance. Prior works propose to predict Intersection-over-Union
(IoU) between bounding boxes and corresponding ground-truths to improve NMS,
while accurately predicting IoU is still a challenging problem. We argue that
the complex definition of IoU and feature misalignment make it difficult to
predict IoU accurately. In this paper, we propose a novel Decoupled IoU
Regression (DIR) model to handle these problems. The proposed DIR decouples the
traditional localization confidence metric IoU into two new metrics, Purity and
Integrity. Purity reflects the proportion of the object area in the detected
bounding box, and Integrity refers to the completeness of the detected object
area. Separately predicting Purity and Integrity can divide the complex mapping
between the bounding box and its IoU into two clearer mappings and model them
independently. In addition, a simple but effective feature realignment approach
is also introduced to make the IoU regressor work in a hindsight manner, which
can make the target mapping more stable. The proposed DIR can be conveniently
integrated with existing two-stage detectors and significantly improve their
performance. Through a simple implementation of DIR with HTC, we obtain 51.3%
AP on MS COCO benchmark, which outperforms previous methods and achieves
state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automotive Parts Assessment: Applying Real-time Instance-Segmentation Models to Identify Vehicle Parts. (arXiv:2202.00884v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00884">
<div class="article-summary-box-inner">
<span><p>The problem of automated car damage assessment presents a major challenge in
the auto repair and damage assessment industry. The domain has several
application areas ranging from car assessment companies such as car rentals and
body shops to accidental damage assessment for car insurance companies. In
vehicle assessment, the damage can take any form including scratches, minor and
major dents to missing parts. More often, the assessment area has a significant
level of noise such as dirt, grease, oil or rush that makes an accurate
identification challenging. Moreover, the identification of a particular part
is the first step in the repair industry to have an accurate labour and part
assessment where the presence of different car models, shapes and sizes makes
the task even more challenging for a machine-learning model to perform well. To
address these challenges, this research explores and applies various instance
segmentation methodologies to evaluate the best performing models.
</p>
<p>The scope of this work focusses on two genres of real-time instance
segmentation models due to their industrial significance, namely SipMask and
Yolact. These methodologies are evaluated against a previously reported car
parts dataset (DSMLR) and an internally curated dataset extracted from local
car repair workshops. The Yolact-based part localization and segmentation
method performed well when compared to other real-time instance mechanisms with
a mAP of 66.5. For the workshop repair dataset, SipMask++ reported better
accuracies for object detection with a mAP of 57.0 with outcomes for
AP_IoU=.50and AP_IoU=.75 reporting 72.0 and 67.0 respectively while Yolact was
found to be a better performer for AP_s with 44.0 and 2.6 for object detection
and segmentation categories respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate calibration of surround view camera systems from a generalization of the hand eye constraint. (arXiv:2202.00886v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00886">
<div class="article-summary-box-inner">
<span><p>Multi-perspective cameras are quickly gaining importance in many applications
such as smart vehicles and virtual or augmented reality. However, a large
system size or absence of overlap in neighbouring fields-of-view often
complicate their calibration. We present a novel solution which relies on the
availability of an external motion capture system. Our core contribution
consists of an extension to the hand-eye calibration problem which jointly
solves multi-eye-to-base problems in closed form. We furthermore demonstrate
its equivalence to the multi-eye-in-hand problem. The practical validity of our
approach is supported by our experiments, indicating that the method is highly
efficient and accurate, and outperforms existing closed-form alternatives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Video Compression Impact Tracking Accuracy?. (arXiv:2202.00892v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00892">
<div class="article-summary-box-inner">
<span><p>Everyone "knows" that compressing a video will degrade the accuracy of object
tracking. Yet, a literature search on this topic reveals that there is very
little documented evidence for this presumed fact. Part of the reason is that,
until recently, there were no object tracking datasets for uncompressed video,
which made studying the effects of compression on tracking accuracy difficult.
In this paper, using a recently published dataset that contains tracking
annotations for uncompressed videos, we examined the degradation of tracking
accuracy due to video compression using rigorous statistical methods.
Specifically, we examined the impact of quantization parameter (QP) and motion
search range (MSR) on Multiple Object Tracking Accuracy (MOTA). The results
show that QP impacts MOTA at the 95% confidence level, while there is
insufficient evidence to claim that MSR impacts MOTA. Moreover, regression
analysis allows us to derive a quantitative relationship between MOTA and QP
for the specific tracker used in the experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Forgery Detection with Interpretability. (arXiv:2202.00908v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00908">
<div class="article-summary-box-inner">
<span><p>In this work, we present a learning based method focusing on the
convolutional neural network (CNN) architecture to detect these forgeries. We
consider the detection of both copy-move forgeries and inpainting based
forgeries. For these, we synthesize our own large dataset. In addition to
classification, the focus is also on interpretability of the forgery detection.
As the CNN classification yields the image-level label, it is important to
understand if forged region has indeed contributed to the classification. For
this purpose, we demonstrate using the Grad-CAM heatmap, that in various
correctly classified examples, that the forged region is indeed the region
contributing to the classification. Interestingly, this is also applicable for
small forged regions, as is depicted in our results. Such an analysis can also
help in establishing the reliability of the classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CSFlow: Learning Optical Flow via Cross Strip Correlation for Autonomous Driving. (arXiv:2202.00909v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00909">
<div class="article-summary-box-inner">
<span><p>Optical flow estimation is an essential task in self-driving systems, which
helps autonomous vehicles perceive temporal continuity information of
surrounding scenes. The calculation of all-pair correlation plays an important
role in many existing state-of-the-art optical flow estimation methods.
However, the reliance on local knowledge often limits the model's accuracy
under complex street scenes. In this paper, we propose a new deep network
architecture for optical flow estimation in autonomous driving--CSFlow, which
consists of two novel modules: Cross Strip Correlation module (CSC) and
Correlation Regression Initialization module (CRI). CSC utilizes a striping
operation across the target image and the attended image to encode global
context into correlation volumes, while maintaining high efficiency. CRI is
used to maximally exploit the global context for optical flow initialization.
Our method has achieved state-of-the-art accuracy on the public autonomous
driving dataset KITTI-2015. Code is publicly available at
https://github.com/MasterHow/CSFlow.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eikonal Fields for Refractive Novel-View Synthesis. (arXiv:2202.00948v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00948">
<div class="article-summary-box-inner">
<span><p>We tackle the problem of generating novel-view images from collections of 2D
images showing refractive and reflective objects. Current solutions assume
opaque or transparent light transport along straight paths following the
emission-absorption model. Instead, we optimize for a field of 3D-varying Index
of Refraction (IoR) and trace light through it that bends toward the spatial
gradients of said IoR according to the laws of eikonal light transport.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GANSlider: How Users Control Generative Models for Images using Multiple Sliders with and without Feedforward Information. (arXiv:2202.00965v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00965">
<div class="article-summary-box-inner">
<span><p>We investigate how multiple sliders with and without feedforward
visualizations influence users' control of generative models. In an online
study (N=138), we collected a dataset of people interacting with a generative
adversarial network (StyleGAN2) in an image reconstruction task. We found that
more control dimensions (sliders) significantly increase task difficulty and
user actions. Visual feedforward partly mitigates this by enabling more
goal-directed interaction. However, we found no evidence of faster or more
accurate task performance. This indicates a tradeoff between feedforward detail
and implied cognitive costs, such as attention. Moreover, we found that
visualizations alone are not always sufficient for users to understand
individual control dimensions. Our study quantifies fundamental UI design
factors and resulting interaction behavior in this context, revealing
opportunities for improvement in the UI design for interactive applications of
generative models. We close by discussing design directions and further
aspects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DCSAU-Net: A Deeper and More Compact Split-Attention U-Net for Medical Image Segmentation. (arXiv:2202.00972v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00972">
<div class="article-summary-box-inner">
<span><p>Image segmentation is a key step for medical image analysis. Approaches based
on deep neural networks have been introduced and performed more reliable
results than traditional image processing methods. However, many models focus
on one medical image application and still show limited abilities to work with
complex images. In this paper, we propose a novel deeper and more compact
split-attention u-shape network (DCSAU-Net) that extracts useful features using
multi-scale combined split-attention and deeper depthwise convolution. We
evaluate the proposed model on CVC-ClinicDB, 2018 Data Science Bowl, ISIC-2018
and SegPC-2021 datasets. As a result, DCSAU-Net displays better performance
than other state-of-the-art (SOTA) methods in terms of the mean Intersection
over Union (mIoU) and F1-socre. More significantly, the proposed model
demonstrate better segmentation performance on challenging images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dictionary learning for clustering on hyperspectral images. (arXiv:2202.00990v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00990">
<div class="article-summary-box-inner">
<span><p>Dictionary learning and sparse coding have been widely studied as mechanisms
for unsupervised feature learning. Unsupervised learning could bring enormous
benefit to the processing of hyperspectral images and to other remote sensing
data analysis because labelled data are often scarce in this field. We propose
a method for clustering the pixels of hyperspectral images using sparse
coefficients computed from a representative dictionary as features. We show
empirically that the proposed method works more effectively than clustering on
the original pixels. We also demonstrate that our approach, in certain
circumstances, outperforms the clustering results of features extracted using
principal component analysis and non-negative matrix factorisation.
Furthermore, our method is suitable for applications in repetitively clustering
an ever-growing amount of high-dimensional data, which is the case when working
with hyperspectral satellite imagery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient Variance Loss for Structure-Enhanced Image Super-Resolution. (arXiv:2202.00997v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00997">
<div class="article-summary-box-inner">
<span><p>Recent success in the field of single image super-resolution (SISR) is
achieved by optimizing deep convolutional neural networks (CNNs) in the image
space with the L1 or L2 loss. However, when trained with these loss functions,
models usually fail to recover sharp edges present in the high-resolution (HR)
images for the reason that the model tends to give a statistical average of
potential HR solutions. During our research, we observe that gradient maps of
images generated by the models trained with the L1 or L2 loss have
significantly lower variance than the gradient maps of the original
high-resolution images. In this work, we propose to alleviate the above issue
by introducing a structure-enhancing loss function, coined Gradient Variance
(GV) loss, and generate textures with perceptual-pleasant details.
Specifically, during the training of the model, we extract patches from the
gradient maps of the target and generated output, calculate the variance of
each patch and form variance maps for these two images. Further, we minimize
the distance between the computed variance maps to enforce the model to produce
high variance gradient maps that will lead to the generation of high-resolution
images with sharper edges. Experimental results show that the GV loss can
significantly improve both Structure Similarity (SSIM) and peak signal-to-noise
ratio (PSNR) performance of existing image super-resolution (SR) deep learning
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auto-Transfer: Learning to Route Transferrable Representations. (arXiv:2202.01011v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01011">
<div class="article-summary-box-inner">
<span><p>Knowledge transfer between heterogeneous source and target networks and tasks
has received a lot of attention in recent times as large amounts of quality
labelled data can be difficult to obtain in many applications. Existing
approaches typically constrain the target deep neural network (DNN) feature
representations to be close to the source DNNs feature representations, which
can be limiting. We, in this paper, propose a novel adversarial multi-armed
bandit approach which automatically learns to route source representations to
appropriate target representations following which they are combined in
meaningful ways to produce accurate target models. We see upwards of 5%
accuracy improvements compared with the state-of-the-art knowledge transfer
methods on four benchmark (target) image datasets CUB200, Stanford Dogs, MIT67,
and Stanford40 where the source dataset is ImageNet. We qualitatively analyze
the goodness of our transfer scheme by showing individual examples of the
important features our target network focuses on in different layers compared
with the (closest) competitors. We also observe that our improvement over other
methods is higher for smaller target datasets making it an effective tool for
small data applications that may benefit from transfer learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MedNeRF: Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray. (arXiv:2202.01020v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01020">
<div class="article-summary-box-inner">
<span><p>Computed tomography (CT) is an effective medical imaging modality, widely
used in the field of clinical medicine for the diagnosis of various
pathologies. Advances in Multidetector CT imaging technology have enabled
additional functionalities, including generation of thin slice multiplanar
cross-sectional body imaging and 3D reconstructions. However, this involves
patients being exposed to a considerable dose of ionising radiation. Excessive
ionising radiation can lead to deterministic and harmful effects on the body.
This paper proposes a Deep Learning model that learns to reconstruct CT
projections from a few or even a single-view X-ray. This is based on a novel
architecture that builds from neural radiance fields, which learns a continuous
representation of CT scans by disentangling the shape and volumetric depth of
surface and internal anatomical structures from 2D images. Our model is trained
on chest and knee datasets, and we demonstrate qualitative and quantitative
high-fidelity renderings and compare our approach to other recent radiance
field-based methods. Our code and link to our datasets will be available at our
GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MMSys'22 Grand Challenge on AI-based Video Production for Soccer. (arXiv:2202.01031v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01031">
<div class="article-summary-box-inner">
<span><p>Soccer has a considerable market share of the global sports industry, and the
interest in viewing videos from soccer games continues to grow. In this
respect, it is important to provide game summaries and highlights of the main
game events. However, annotating and producing events and summaries often
require expensive equipment and a lot of tedious, cumbersome, manual labor.
Therefore, automating the video production pipeline providing fast game
highlights at a much lower cost is seen as the "holy grail". In this context,
recent developments in Artificial Intelligence (AI) technology have shown great
potential. Still, state-of-the-art approaches are far from being adequate for
practical scenarios that have demanding real-time requirements, as well as
strict performance criteria (where at least the detection of official events
such as goals and cards must be 100% accurate). In addition, event detection
should be thoroughly enhanced by annotation and classification, proper
clipping, generating short descriptions, selecting appropriate thumbnails for
highlight clips, and finally, combining the event highlights into an overall
game summary, similar to what is commonly aired during sports news. Even though
the event tagging operation has by far received the most attention, an
end-to-end video production pipeline also includes various other operations
which serve the overall purpose of automated soccer analysis. This challenge
aims to assist the automation of such a production pipeline using AI. In
particular, we focus on the enhancement operations that take place after an
event has been detected, namely event clipping (Task 1), thumbnail selection
(Task 2), and game summarization (Task 3). Challenge website:
https://mmsys2022.ie/authors/grand-challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image-based Navigation in Real-World Environments via Multiple Mid-level Representations: Fusion Models, Benchmark and Efficient Evaluation. (arXiv:2202.01069v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01069">
<div class="article-summary-box-inner">
<span><p>Navigating complex indoor environments requires a deep understanding of the
space the robotic agent is acting into to correctly inform the navigation
process of the agent towards the goal location. In recent learning-based
navigation approaches, the scene understanding and navigation abilities of the
agent are achieved simultaneously by collecting the required experience in
simulation. Unfortunately, even if simulators represent an efficient tool to
train navigation policies, the resulting models often fail when transferred
into the real world. One possible solution is to provide the navigation model
with mid-level visual representations containing important domain-invariant
properties of the scene. But, what are the best representations that facilitate
the transfer of a model to the real-world? How can they be combined? In this
work we address these issues by proposing a benchmark of Deep Learning
architectures to combine a range of mid-level visual representations, to
perform a PointGoal navigation task following a Reinforcement Learning setup.
All the proposed navigation models have been trained with the Habitat simulator
on a synthetic office environment and have been tested on the same real-world
environment using a real robotic platform. To efficiently assess their
performance in a real context, a validation tool has been proposed to generate
realistic navigation episodes inside the simulator. Our experiments showed that
navigation models can benefit from the multi-modal input and that our
validation tool can provide good estimation of the expected navigation
performance in the real world, while saving time and resources. The acquired
synthetic and real 3D models of the environment, together with the code of our
validation tool built on top of Habitat, are publicly available at the
following link: https://iplab.dmi.unict.it/EmbodiedVN/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unpaired Image Super-Resolution with Optimal Transport Maps. (arXiv:2202.01116v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01116">
<div class="article-summary-box-inner">
<span><p>Real-world image super-resolution (SR) tasks often do not have paired
datasets limiting the application of supervised techniques. As a result, the
tasks are usually approached by unpaired techniques based on Generative
Adversarial Networks (GANs) which yield complex training losses with several
regularization terms such as content and identity losses. We theoretically
investigate the optimization problems which arise in such models and find two
surprising observations. First, the learned SR map is always an optimal
transport (OT) map. Second, we empirically show that the learned map is biased,
i.e., it may not actually transform the distribution of low-resolution images
to high-resolution images. Inspired by these findings, we propose an algorithm
for unpaired SR which learns an unbiased OT map for the perceptual transport
cost. Unlike existing GAN-based alternatives, our algorithm has a simple
optimization objective reducing the neccesity to perform complex hyperparameter
selection and use additional regularizations. At the same time, it provides
nearly state-of-the-art performance on the large-scale unpaired AIM-19 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Eye for an Eye: Defending against Gradient-based Attacks with Gradients. (arXiv:2202.01117v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01117">
<div class="article-summary-box-inner">
<span><p>Deep learning models have been shown to be vulnerable to adversarial attacks.
In particular, gradient-based attacks have demonstrated high success rates
recently. The gradient measures how each image pixel affects the model output,
which contains critical information for generating malicious perturbations. In
this paper, we show that the gradients can also be exploited as a powerful
weapon to defend against adversarial attacks. By using both gradient maps and
adversarial images as inputs, we propose a Two-stream Restoration Network (TRN)
to restore the adversarial images. To optimally restore the perturbed images
with two streams of inputs, a Gradient Map Estimation Mechanism is proposed to
estimate the gradients of adversarial images, and a Fusion Block is designed in
TRN to explore and fuse the information in two streams. Once trained, our TRN
can defend against a wide range of attack methods without significantly
degrading the performance of benign inputs. Also, our method is generalizable,
scalable, and hard to bypass. Experimental results on CIFAR10, SVHN, and
Fashion MNIST demonstrate that our method outperforms state-of-the-art defense
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probabilistically Robust Learning: Balancing Average- and Worst-case Performance. (arXiv:2202.01136v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01136">
<div class="article-summary-box-inner">
<span><p>Many of the successes of machine learning are based on minimizing an averaged
loss function. However, it is well-known that this paradigm suffers from
robustness issues that hinder its applicability in safety-critical domains.
These issues are often addressed by training against worst-case perturbations
of data, a technique known as adversarial training. Although empirically
effective, adversarial training can be overly conservative, leading to
unfavorable trade-offs between nominal performance and robustness. To this end,
in this paper we propose a framework called probabilistic robustness that
bridges the gap between the accurate, yet brittle average case and the robust,
yet conservative worst case by enforcing robustness to most rather than to all
perturbations. From a theoretical point of view, this framework overcomes the
trade-offs between the performance and the sample-complexity of worst-case and
average-case learning. From a practical point of view, we propose a novel
algorithm based on risk-aware optimization that effectively balances average-
and worst-case performance at a considerably lower computational cost relative
to adversarial training. Our results on MNIST, CIFAR-10, and SVHN illustrate
the advantages of this framework on the spectrum from average- to worst-case
robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AntidoteRT: Run-time Detection and Correction of Poison Attacks on Neural Networks. (arXiv:2202.01179v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01179">
<div class="article-summary-box-inner">
<span><p>We study backdoor poisoning attacks against image classification networks,
whereby an attacker inserts a trigger into a subset of the training data, in
such a way that at test time, this trigger causes the classifier to predict
some target class. %There are several techniques proposed in the literature
that aim to detect the attack but only a few also propose to defend against it,
and they typically involve retraining the network which is not always possible
in practice. We propose lightweight automated detection and correction
techniques against poisoning attacks, which are based on neuron patterns mined
from the network using a small set of clean and poisoned test samples with
known labels. The patterns built based on the mis-classified samples are used
for run-time detection of new poisoned inputs. For correction, we propose an
input correction technique that uses a differential analysis to identify the
trigger in the detected poisoned images, which is then reset to a neutral
color. Our detection and correction are performed at run-time and input level,
which is in contrast to most existing work that is focused on offline
model-level defenses. We demonstrate that our technique outperforms existing
defenses such as NeuralCleanse and STRIP on popular benchmarks such as MNIST,
CIFAR-10, and GTSRB against the popular BadNets attack and the more complex
DFST attack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Make Some Noise: Reliable and Efficient Single-Step Adversarial Training. (arXiv:2202.01181v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01181">
<div class="article-summary-box-inner">
<span><p>Recently, Wong et al. showed that adversarial training with single-step FGSM
leads to a characteristic failure mode named catastrophic overfitting (CO), in
which a model becomes suddenly vulnerable to multi-step attacks. They showed
that adding a random perturbation prior to FGSM (RS-FGSM) seemed to be
sufficient to prevent CO. However, Andriushchenko and Flammarion observed that
RS-FGSM still leads to CO for larger perturbations, and proposed an expensive
regularizer (GradAlign) to avoid CO. In this work, we methodically revisit the
role of noise and clipping in single-step adversarial training. Contrary to
previous intuitions, we find that using a stronger noise around the clean
sample combined with not clipping is highly effective in avoiding CO for large
perturbation radii. Based on these observations, we then propose Noise-FGSM
(N-FGSM) that, while providing the benefits of single-step adversarial
training, does not suffer from CO. Empirical analyses on a large suite of
experiments show that N-FGSM is able to match or surpass the performance of
previous single-step methods while achieving a 3$\times$ speed-up.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VOS:Learning What You Don't Know by Virtual Outlier Synthesis. (arXiv:2202.01197v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01197">
<div class="article-summary-box-inner">
<span><p>Out-of-distribution (OOD) detection has received much attention lately due to
its importance in the safe deployment of neural networks. One of the key
challenges is that models lack supervision signals from unknown data, and as a
result, can produce overconfident predictions on OOD data. Previous approaches
rely on real outlier datasets for model regularization, which can be costly and
sometimes infeasible to obtain in practice. In this paper, we present VOS, a
novel framework for OOD detection by adaptively synthesizing virtual outliers
that can meaningfully regularize the model's decision boundary during training.
Specifically, VOS samples virtual outliers from the low-likelihood region of
the class-conditional distribution estimated in the feature space. Alongside,
we introduce a novel unknown-aware training objective, which contrastively
shapes the uncertainty space between the ID data and synthesized outlier data.
VOS achieves state-of-the-art performance on both object detection and image
classification models, reducing the FPR95 by up to 7.87% compared to the
previous best method. Code is available at
https://github.com/deeplearning-wisc/vos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Extraction of Open Space Area from High Resolution Urban Satellite Imagery. (arXiv:1103.4723v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1103.4723">
<div class="article-summary-box-inner">
<span><p>In the 21st century, Aerial and satellite images are information rich. They
are also complex to analyze. For GIS systems, many features require fast and
reliable extraction of open space area from high resolution satellite imagery.
In this paper we will study efficient and reliable automatic extraction
algorithm to find out the open space area from the high resolution urban
satellite imagery. This automatic extraction algorithm uses some filters and
segmentations and grouping is applying on satellite images. And the result
images may use to calculate the total available open space area and the built
up area. It may also use to compare the difference between present and past
open space area using historical urban satellite images of that same projection
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Patch-based Image Denoising Method Using Eigenvectors of the Geodesics' Gramian Matrix. (arXiv:2010.07769v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07769">
<div class="article-summary-box-inner">
<span><p>With the proliferation of sophisticated cameras in modern society, the demand
for accurate and visually pleasing images is increasing. However, the quality
of an image captured by a camera may be degraded by noise. Thus, some
processing of images is required to filter out the noise without losing vital
image features. Even though the current literature offers a variety of
denoising methods, the fidelity and efficacy of their denoising are sometimes
uncertain. Thus, here we propose a novel and computationally efficient image
denoising method that is capable of producing accurate images. To preserve
image smoothness, this method inputs patches partitioned from the image rather
than pixels. Then, it performs denoising on the manifold underlying the
patch-space rather than that in the image domain to better preserve the
features across the whole image. We validate the performance of this method
against benchmark image processing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simplicial Complex Representation Learning. (arXiv:2103.04046v6 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04046">
<div class="article-summary-box-inner">
<span><p>Simplicial complexes form an important class of topological spaces that are
frequently used in many application areas such as computer-aided design,
computer graphics, and simulation. Representation learning on graphs, which are
just 1-d simplicial complexes, has witnessed a great attention in recent years.
However, there has not been enough effort to extend representation learning to
higher dimensional simplicial objects due to the additional complexity these
objects hold, especially when it comes to entire-simplicial complex
representation learning. In this work, we propose a method for simplicial
complex-level representation learning that embeds a simplicial complex to a
universal embedding space in a way that complex-to-complex proximity is
preserved. Our method uses our novel geometric message passing schemes to learn
an entire simplicial complex representation in an end-to-end fashion. We
demonstrate the proposed model on publicly available mesh dataset. To the best
of our knowledge, this work presents the first method for learning simplicial
complex-level representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for fully automatic detection, segmentation, and Gleason Grade estimation of prostate cancer in multiparametric Magnetic Resonance Images. (arXiv:2103.12650v3 [physics.med-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12650">
<div class="article-summary-box-inner">
<span><p>The emergence of multi-parametric magnetic resonance imaging (mpMRI) has had
a profound impact on the diagnosis of prostate cancers (PCa), which is the most
prevalent malignancy in males in the western world, enabling a better selection
of patients for confirmation biopsy. However, analyzing these images is complex
even for experts, hence opening an opportunity for computer-aided diagnosis
systems to seize. This paper proposes a fully automatic system based on Deep
Learning that takes a prostate mpMRI from a PCa-suspect patient and, by
leveraging the Retina U-Net detection framework, locates PCa lesions, segments
them, and predicts their most likely Gleason grade group (GGG). It uses 490
mpMRIs for training/validation, and 75 patients for testing from two different
datasets: ProstateX and IVO (Valencia Oncology Institute Foundation). In the
test set, it achieves an excellent lesion-level AUC/sensitivity/specificity for
the GGG$\geq$2 significance criterion of 0.96/1.00/0.79 for the ProstateX
dataset, and 0.95/1.00/0.80 for the IVO dataset. Evaluated at a patient level,
the results are 0.87/1.00/0.375 in ProstateX, and 0.91/1.00/0.762 in IVO.
Furthermore, on the online ProstateX grand challenge, the model obtained an AUC
of 0.85 (0.87 when trained only on the ProstateX data, tying up with the
original winner of the challenge). For expert comparison, IVO radiologist's
PI-RADS 4 sensitivity/specificity were 0.88/0.56 at a lesion level, and
0.85/0.58 at a patient level. Additional subsystems for automatic prostate
zonal segmentation and mpMRI non-rigid sequence registration were also employed
to produce the final fully automated system. The code for the ProstateX-trained
system has been made openly available at
https://github.com/OscarPellicer/prostate_lesion_detection. We hope that this
will represent a landmark for future research to use, compare and improve upon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Single-Layer Vision Transformers for More Accurate Early Exits with Less Overhead. (arXiv:2105.09121v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09121">
<div class="article-summary-box-inner">
<span><p>Deploying deep learning models in time-critical applications with limited
computational resources, for instance in edge computing systems and IoT
networks, is a challenging task that often relies on dynamic inference methods
such as early exiting. In this paper, we introduce a novel architecture for
early exiting based on the vision transformer architecture, as well as a
fine-tuning strategy that significantly increase the accuracy of early exit
branches compared to conventional approaches while introducing less overhead.
Through extensive experiments on image and audio classification as well as
audiovisual crowd counting, we show that our method works for both
classification and regression problems, and in both single- and multi-modal
settings. Additionally, we introduce a novel method for integrating audio and
visual modalities within early exits in audiovisual data analysis, that can
lead to a more fine-grained dynamic inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Task, Multi-Domain Deep Segmentation with Shared Representations and Contrastive Regularization for Sparse Pediatric Datasets. (arXiv:2105.10310v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10310">
<div class="article-summary-box-inner">
<span><p>Automatic segmentation of magnetic resonance (MR) images is crucial for
morphological evaluation of the pediatric musculoskeletal system in clinical
practice. However, the accuracy and generalization performance of individual
segmentation models are limited due to the restricted amount of annotated
pediatric data. Hence, we propose to train a segmentation model on multiple
datasets, arising from different parts of the anatomy, in a multi-task and
multi-domain learning framework. This approach allows to overcome the inherent
scarcity of pediatric data while benefiting from a more robust shared
representation. The proposed segmentation network comprises shared
convolutional filters, domain-specific batch normalization parameters that
compute the respective dataset statistics and a domain-specific segmentation
layer. Furthermore, a supervised contrastive regularization is integrated to
further improve generalization capabilities, by promoting intra-domain
similarity and impose inter-domain margins in embedded space. We evaluate our
contributions on two pediatric imaging datasets of the ankle and shoulder
joints for bone segmentation. Results demonstrate that the proposed model
outperforms state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. (arXiv:2106.05187v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05187">
<div class="article-summary-box-inner">
<span><p>We present implicit displacement fields, a novel representation for detailed
3D geometry. Inspired by a classic surface deformation technique, displacement
mapping, our method represents a complex surface as a smooth base surface plus
a displacement along the base's normal directions, resulting in a
frequency-based shape decomposition, where the high frequency signal is
constrained geometrically by the low frequency signal. Importantly, this
disentanglement is unsupervised thanks to a tailored architectural design that
has an innate frequency hierarchy by construction. We explore implicit
displacement field surface reconstruction and detail transfer and demonstrate
superior representational power, training stability and generalizability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VidHarm: A Clip Based Dataset for Harmful Content Detection. (arXiv:2106.08323v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08323">
<div class="article-summary-box-inner">
<span><p>Automatically identifying harmful content in video is an important task with
a wide range of applications. However, there is a lack of professionally
labeled open datasets available. In this work VidHarm, an open dataset of 3589
video clips from film trailers annotated by professionals, is presented. An
analysis of the dataset is performed, revealing among other things the relation
between clip and trailer level annotations. Audiovisual models are trained on
the dataset and an in-depth study of modeling choices conducted. The results
show that performance is greatly improved by combining the visual and audio
modality, pre-training on large-scale video recognition datasets, and class
balanced sampling. Lastly, biases of the trained models are investigated using
discrimination probing.
</p>
<p>VidHarm is openly available, and further details are available at this
webpage: \url{https://vidharm.github.io/}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Correspondence Hallucination. (arXiv:2106.09711v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09711">
<div class="article-summary-box-inner">
<span><p>Given a pair of partially overlapping source and target images and a keypoint
in the source image, the keypoint's correspondent in the target image can be
either visible, occluded or outside the field of view. Local feature matching
methods are only able to identify the correspondent's location when it is
visible, while humans can also hallucinate its location when it is occluded or
outside the field of view through geometric reasoning. In this paper, we bridge
this gap by training a network to output a peaked probability distribution over
the correspondent's location, regardless of this correspondent being visible,
occluded, or outside the field of view. We experimentally demonstrate that this
network is indeed able to hallucinate correspondences on pairs of images
captured in scenes that were not seen at training-time. We also apply this
network to an absolute camera pose estimation problem and find it is
significantly more robust than state-of-the-art local feature matching-based
competitors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable Surface Reconstruction with Delaunay-Graph Neural Networks. (arXiv:2107.06130v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06130">
<div class="article-summary-box-inner">
<span><p>We introduce a novel learning-based, visibility-aware, surface reconstruction
method for large-scale, defect-laden point clouds. Our approach can cope with
the scale and variety of point cloud defects encountered in real-life
Multi-View Stereo (MVS) acquisitions. Our method relies on a 3D Delaunay
tetrahedralization whose cells are classified as inside or outside the surface
by a graph neural network and an energy model solvable with a graph cut. Our
model, making use of both local geometric attributes and line-of-sight
visibility information, is able to learn a visibility model from a small amount
of synthetic training data and generalizes to real-life acquisitions. Combining
the efficiency of deep learning methods and the scalability of energy based
models, our approach outperforms both learning and non learning-based
reconstruction algorithms on two publicly available reconstruction benchmarks.
Our code and data is available at https://github.com/raphaelsulzer/dgnn.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Video Captioning with Dynamic Loss Network. (arXiv:2107.11707v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11707">
<div class="article-summary-box-inner">
<span><p>Video captioning is one of the challenging problems at the intersection of
vision and language, having many real-life applications in video retrieval,
video surveillance, assisting visually challenged people, Human-machine
interface, and many more. Recent deep learning based methods have shown
promising results but are still on the lower side than other vision tasks (such
as image classification, object detection). A significant drawback with
existing video captioning methods is that they are optimized over cross-entropy
loss function, which is uncorrelated to the de facto evaluation metrics (BLEU,
METEOR, CIDER, ROUGE). In other words, cross-entropy is not a proper surrogate
of the true loss function for video captioning. To mitigate this, methods like
REINFORCE, Actor-Critic, and Minimum Risk Training (MRT) have been applied but
have limitations and are not very effective. This paper proposes an alternate
solution by introducing a dynamic loss network (DLN), providing an additional
feedback signal that reflects the evaluation metrics directly. Our solution
proves to be more efficient than other solutions and can be easily adapted to
similar tasks. Our results on Microsoft Research Video Description Corpus
(MSVD) and MSR-Video to Text (MSRVTT) datasets outperform previous methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpreting Generative Adversarial Networks for Interactive Image Generation. (arXiv:2108.04896v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04896">
<div class="article-summary-box-inner">
<span><p>Significant progress has been made by the advances in Generative Adversarial
Networks (GANs) for image generation. However, there lacks enough understanding
of how a realistic image is generated by the deep representations of GANs from
a random vector. This chapter gives a summary of recent works on interpreting
deep generative models. The methods are categorized into the supervised, the
unsupervised, and the embedding-guided approaches. We will see how the
human-understandable concepts that emerge in the learned representation can be
identified and used for interactive image generation and editing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Better Loss for Visual-Textual Grounding. (arXiv:2108.05308v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05308">
<div class="article-summary-box-inner">
<span><p>Given a textual phrase and an image, the visual grounding problem is the task
of locating the content of the image referenced by the sentence. It is a
challenging task that has several real-world applications in human-computer
interaction, image-text reference resolution, and video-text reference
resolution. In the last years, several works have addressed this problem by
proposing more and more large and complex models that try to capture
visual-textual dependencies better than before. These models are typically
constituted by two main components that focus on how to learn useful
multi-modal features for grounding and how to improve the predicted bounding
box of the visual mention, respectively. Finding the right learning balance
between these two sub-tasks is not easy, and the current models are not
necessarily optimal with respect to this issue. In this work, we propose a loss
function based on bounding boxes classes probabilities that: (i) improves the
bounding boxes selection; (ii) improves the bounding boxes coordinates
prediction. Our model, although using a simple multi-modal feature fusion
component, is able to achieve a higher accuracy than state-of-the-art models on
two widely adopted datasets, reaching a better learning balance between the two
sub-tasks mentioned above.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simple and Efficient Reconstruction Backbone for Snapshot Compressive Imaging. (arXiv:2108.07739v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07739">
<div class="article-summary-box-inner">
<span><p>The emerging technology of snapshot compressive imaging (SCI) enables
capturing high dimensional (HD) data in an efficient way. It is generally
implemented by two components: an optical encoder that compresses HD signals
into a 2D measurement and an algorithm decoder that retrieves the HD data upon
the hardware-encoded measurement. Over a broad range of SCI applications,
hyperspectral imaging (HSI) and video compressive sensing have received
significant research attention in recent years. Among existing SCI
reconstruction algorithms, deep learning-based methods stand out as their
promising performance and efficient inference. However, the deep reconstruction
network may suffer from overlarge model size and highly-specialized network
design, which inevitably lead to costly training time, high memory usage, and
limited flexibility, thus discouraging the deployments of SCI systems in
practical scenarios. In this paper, we tackle the above challenges by proposing
a simple yet highly efficient reconstruction method, namely stacked residual
network (SRN), by revisiting the residual learning strategy with nested
structures and spatial-invariant property. The proposed SRN empowers
high-fidelity data retrieval with fewer computation operations and negligible
model size compared with existing networks, and also serves as a versatile
backbone applicable for both hyperspectral and video data. Based on the
proposed backbone, we first develop the channel attention enhanced SRN
(CAE-SRN) to explore the spectral inter-dependencies for fine-grained spatial
estimation in HSI. We then employ SRN as a deep denoiser and incorporate it
into a generalized alternating projection (GAP) framework -- resulting in
GAP-SRN -- to handle the video compressive sensing task. Experimental results
demonstrate the state-of-the-art performance, high computational efficiency of
the proposed SRN on two SCI applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DASHA: Decentralized Autofocusing System with Hierarchical Agents. (arXiv:2108.12842v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12842">
<div class="article-summary-box-inner">
<span><p>State-of-the-art object detection models are frequently trained offline using
available datasets, such as ImageNet: large and overly diverse data that are
unbalanced and hard to cluster semantically. This kind of training drops the
object detection performance should the change in illumination, in the
environmental conditions (e.g., rain), or in the lens positioning (out-of-focus
blur) occur. We propose a decentralized hierarchical multi-agent deep
reinforcement learning approach for intelligently controlling the camera and
the lens focusing settings, leading to a significant improvement beyond the
capacity of the popular detection models (YOLO, Faster R-CNN, and Retina are
considered). The algorithm relies on the latent representation of the camera's
stream and, thus, it is the first method to allow a completely no-reference
tuning of the camera, where the system trains itself to auto-focus itself.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SmartDepthSync: Open Source Synchronized Video Recording System of Smartphone RGB and Depth Camera Image Frames with Sub-millisecond Precision. (arXiv:2111.03552v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03552">
<div class="article-summary-box-inner">
<span><p>Nowadays, smartphones can produce a synchronized (synced) stream of
high-quality data, including RGB images, inertial measurements, and other data.
Therefore, smartphones are becoming appealing sensor systems in the robotics
community. Unfortunately, there is still the need for external supporting
sensing hardware, such as a depth camera precisely synced with the smartphone
sensors.
</p>
<p>In this paper, we propose a hardware-software recording system that presents
a heterogeneous structure and contains a smartphone and an external depth
camera for recording visual, depth, and inertial data that are mutually
synchronized. The system is synced at the time and the frame levels: every RGB
image frame from the smartphone camera is exposed at the same moment of time
with a depth camera frame with sub-millisecond precision. We provide a method
and a tool for sync performance evaluation that can be applied to any pair of
depth and RGB cameras. Our system could be replicated, modified, or extended by
employing our open-sourced materials.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Exponentially Tilted Gaussian Prior for Variational Autoencoders. (arXiv:2111.15646v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.15646">
<div class="article-summary-box-inner">
<span><p>An important property for deep neural networks is the ability to perform
robust out-of-distribution detection on previously unseen data. This property
is essential for safety purposes when deploying models for real world
applications. Recent studies show that probabilistic generative models can
perform poorly on this task, which is surprising given that they seek to
estimate the likelihood of training data. To alleviate this issue, we propose
the exponentially tilted Gaussian prior distribution for the Variational
Autoencoder (VAE) which pulls points onto the surface of a hyper-sphere in
latent space. This achieves state-of-the art results on the area under the
curve-receiver operator characteristics metric using just the negative
log-likelihood that the VAE naturally assigns. Because this prior is a simple
modification of the traditional VAE prior, it is faster and easier to implement
than competitive methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A formal approach to good practices in Pseudo-Labeling for Unsupervised Domain Adaptive Re-Identification. (arXiv:2112.12887v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12887">
<div class="article-summary-box-inner">
<span><p>The use of pseudo-labels prevails in order to tackle Unsupervised Domain
Adaptive (UDA) Re-Identification (re-ID) with the best performance. Indeed,
this family of approaches has given rise to several UDA re-ID specific
frameworks, which are effective. In these works, research directions to improve
Pseudo-Labeling UDA re-ID performance are varied and mostly based on intuition
and experiments: refining pseudo-labels, reducing the impact of errors in
pseudo-labels... It can be hard to deduce from them general good practices,
which can be implemented in any Pseudo-Labeling method, to consistently improve
its performance. To address this key question, a new theoretical view on
Pseudo-Labeling UDA re-ID is proposed. The contributions are threefold: (i) A
novel theoretical framework for Pseudo-Labeling UDA re-ID, formalized through a
new general learning upper-bound on the UDA re-ID performance. (ii) General
good practices for Pseudo-Labeling, directly deduced from the interpretation of
the proposed theoretical framework, in order to improve the target re-ID
performance. (iii) Extensive experiments on challenging person and vehicle
cross-dataset re-ID tasks, showing consistent performance improvements for
various state-of-the-art methods and various proposed implementations of good
practices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangled Latent Transformer for Interpretable Monocular Height Estimation. (arXiv:2201.06357v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.06357">
<div class="article-summary-box-inner">
<span><p>Monocular height estimation (MHE) from remote sensing imagery has high
potential in generating 3D city models efficiently for a quick response to
natural disasters. Most existing works pursue higher performance. However,
there is little research exploring the interpretability of MHE networks. In
this paper, we target at exploring how deep neural networks predict height from
a single monocular image. Towards a comprehensive understanding of MHE
networks, we propose to interpret them from multiple levels: 1) Neurons:
unit-level dissection. Exploring the semantic and height selectivity of the
learned internal deep representations; 2) Instances: object-level
interpretation. Studying the effects of different semantic classes, scales, and
spatial contexts on height estimation; 3) Attribution: pixel-level analysis.
Understanding which input pixels are important for the height estimation. Based
on the multi-level interpretation, a disentangled latent Transformer network is
proposed towards a more compact, reliable, and explainable deep model for
monocular height estimation. Furthermore, a novel unsupervised semantic
segmentation task based on height estimation is first introduced in this work.
Additionally, we also construct a new dataset for joint semantic segmentation
and height estimation. Our work provides novel insights for both understanding
and designing MHE models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-aware deep learning methods for robust diabetic retinopathy classification. (arXiv:2201.09042v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09042">
<div class="article-summary-box-inner">
<span><p>Automatic classification of diabetic retinopathy from retinal images has been
widely studied using deep neural networks with impressive results. However,
there is a clinical need for estimation of the uncertainty in the
classifications, a shortcoming of modern neural networks. Recently, approximate
Bayesian deep learning methods have been proposed for the task but the studies
have only considered the binary referable/non-referable diabetic retinopathy
classification applied to benchmark datasets. We present novel results by
systematically investigating a clinical dataset and a clinically relevant
5-class classification scheme, in addition to benchmark datasets and the binary
classification scheme. Moreover, we derive a connection between uncertainty
measures and classifier risk, from which we develop a new uncertainty measure.
We observe that the previously proposed entropy-based uncertainty measure
generalizes to the clinical dataset on the binary classification scheme but not
on the 5-class scheme, whereas our new uncertainty measure generalizes to the
latter case.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks. (arXiv:2201.12179v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12179">
<div class="article-summary-box-inner">
<span><p>Model inversion attacks (MIAs) aim to create synthetic images that reflect
the class-wise characteristics from a target classifier's training data by
exploiting the model's learned knowledge. Previous research has developed
generative MIAs using generative adversarial networks (GANs) as image priors
that are tailored to a specific target model. This makes the attacks time- and
resource-consuming, inflexible, and susceptible to distributional shifts
between datasets. To overcome these drawbacks, we present Plug &amp; Play Attacks
that loosen the dependency between the target model and image prior and enable
the use of a single trained GAN to attack a broad range of targets with only
minor attack adjustments needed. Moreover, we show that powerful MIAs are
possible even with publicly available pre-trained GANs and under strong
distributional shifts, whereas previous approaches fail to produce meaningful
results. Our extensive evaluation confirms the improved robustness and
flexibility of Plug &amp; Play Attacks and their ability to create high-quality
images revealing sensitive class characteristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-paced learning to improve text row detection in historical documents with missing labels. (arXiv:2201.12216v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12216">
<div class="article-summary-box-inner">
<span><p>An important preliminary step of optical character recognition systems is the
detection of text rows. To address this task in the context of historical data
with missing labels, we propose a self-paced learning algorithm capable of
improving the row detection performance. We conjecture that pages with more
ground-truth bounding boxes are less likely to have missing annotations. Based
on this hypothesis, we sort the training examples in descending order with
respect to the number of ground-truth bounding boxes, and organize them into k
batches. Using our self-paced learning method, we train a row detector over k
iterations, progressively adding batches with less ground-truth annotations. At
each iteration, we combine the ground-truth bounding boxes with pseudo-bounding
boxes (bounding boxes predicted by the model itself) using non-maximum
suppression, and we include the resulting annotations at the next training
iteration. We demonstrate that our self-paced learning strategy brings
significant performance gains on two data sets of historical documents,
improving the average precision of YOLOv4 with more than 12% on one data set
and 39% on the other.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The impact of removing head movements on audio-visual speech enhancement. (arXiv:2202.00538v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00538">
<div class="article-summary-box-inner">
<span><p>This paper investigates the impact of head movements on audio-visual speech
enhancement (AVSE). Although being a common conversational feature, head
movements have been ignored by past and recent studies: they challenge today's
learning-based methods as they often degrade the performance of models that are
trained on clean, frontal, and steady face images. To alleviate this problem,
we propose to use robust face frontalization (RFF) in combination with an AVSE
method based on a variational auto-encoder (VAE) model. We briefly describe the
basic ingredients of the proposed pipeline and we perform experiments with a
recently released audio-visual dataset. In the light of these experiments, and
based on three standard metrics, namely STOI, PESQ and SI-SDR, we conclude that
RFF improves the performance of AVSE by a considerable margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPAGHETTI: Editing Implicit Shapes Through Part Aware Generation. (arXiv:2201.13168v1 [cs.GR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.13168">
<div class="article-summary-box-inner">
<span><p>Neural implicit fields are quickly emerging as an attractive representation
for learning based techniques. However, adopting them for 3D shape modeling and
editing is challenging. We introduce a method for $\mathbf{E}$diting
$\mathbf{I}$mplicit $\mathbf{S}$hapes $\mathbf{T}$hrough $\mathbf{P}$art
$\mathbf{A}$ware $\mathbf{G}$enera$\mathbf{T}$ion, permuted in short as
SPAGHETTI. Our architecture allows for manipulation of implicit shapes by means
of transforming, interpolating and combining shape segments together, without
requiring explicit part supervision. SPAGHETTI disentangles shape part
representation into extrinsic and intrinsic geometric information. This
characteristic enables a generative framework with part-level control. The
modeling capabilities of SPAGHETTI are demonstrated using an interactive
graphical interface, where users can directly edit neural implicit shapes.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-02-03 23:05:58.257601442 UTC">2022-02-03 23:05:58 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>