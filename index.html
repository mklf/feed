<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-02-09T01:30:00Z">02-09</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Selecting Seed Words for Wordle using Character Statistics. (arXiv:2202.03457v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03457">
<div class="article-summary-box-inner">
<span><p>Wordle, a word guessing game rose to global popularity in the January of
2022. The goal of the game is to guess a five-letter English word within six
tries. Each try provides the player with hints by means of colour changing
tiles which inform whether or not a given character is part of the solution as
well as, in cases where it is part of the solution, whether or not it is in the
correct placement. Numerous attempts have been made to find the best starting
word and best strategy to solve the daily wordle. This study uses character
statistics of five-letter words to determine the best three starting words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal Spam Detection using Transfer Learning of BERT Model. (arXiv:2202.03480v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03480">
<div class="article-summary-box-inner">
<span><p>Deep learning transformer models become important by training on text data
based on self-attention mechanisms. This manuscript demonstrated a novel
universal spam detection model using pre-trained Google's Bidirectional Encoder
Representations from Transformers (BERT) base uncased models with four datasets
by efficiently classifying ham or spam emails in real-time scenarios. Different
methods for Enron, Spamassain, Lingspam, and Spamtext message classification
datasets, were used to train models individually in which a single model was
obtained with acceptable performance on four datasets. The Universal Spam
Detection Model (USDM) was trained with four datasets and leveraged
hyperparameters from each model. The combined model was finetuned with the same
hyperparameters from these four models separately. When each model using its
corresponding dataset, an F1-score is at and above 0.9 in individual models. An
overall accuracy reached 97%, with an F1 score of 0.96. Research results and
implications were discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Approximation Algorithms for ROUND-UFP and ROUND-SAP. (arXiv:2202.03492v1 [cs.DS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03492">
<div class="article-summary-box-inner">
<span><p>We study ROUND-UFP and ROUND-SAP, two generalizations of the classical BIN
PACKING problem that correspond to the unsplittable flow problem on a path
(UFP) and the storage allocation problem (SAP), respectively. We are given a
path with capacities on its edges and a set of tasks where for each task we are
given a demand and a subpath. In ROUND-UFP, the goal is to find a packing of
all tasks into a minimum number of copies (rounds) of the given path such that
for each copy, the total demand of tasks on any edge does not exceed the
capacity of the respective edge. In ROUND-SAP, the tasks are considered to be
rectangles and the goal is to find a non-overlapping packing of these
rectangles into a minimum number of rounds such that all rectangles lie
completely below the capacity profile of the edges.
</p>
<p>We show that in contrast to BIN PACKING, both the problems do not admit an
asymptotic polynomial-time approximation scheme (APTAS), even when all edge
capacities are equal. However, for this setting, we obtain asymptotic
$(2+\varepsilon)$-approximations for both problems. For the general case, we
obtain an $O(\log\log n)$-approximation algorithm and an
$O(\log\log\frac{1}{\delta})$-approximation under $(1+\delta)$-resource
augmentation for both problems. For the intermediate setting of the no
bottleneck assumption (i.e., the maximum task demand is at most the minimum
edge capacity), we obtain absolute $12$- and asymptotic
$(16+\varepsilon)$-approximation algorithms for ROUND-UFP and ROUND-SAP,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Representation Learning for Speech Using Visual Grounding and Masked Language Modeling. (arXiv:2202.03543v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03543">
<div class="article-summary-box-inner">
<span><p>In this paper, we describe our submissions to the ZeroSpeech 2021 Challenge
and SUPERB benchmark. Our submissions are based on the recently proposed
FaST-VGS model, which is a Transformer-based model that learns to associate raw
speech waveforms with semantically related images, all without the use of any
transcriptions of the speech. Additionally, we introduce a novel extension of
this model, FaST-VGS+, which is learned in a multi-task fashion with a masked
language modeling objective in addition to the visual grounding objective. On
ZeroSpeech 2021, we show that our models perform competitively on the ABX task,
outperform all other concurrent submissions on the Syntactic and Semantic
tasks, and nearly match the best system on the Lexical task. On the SUPERB
benchmark, we show that our models also achieve strong performance, in some
cases even outperforming the popular wav2vec2.0 model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Language Models Learn Position-Role Mappings?. (arXiv:2202.03611v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03611">
<div class="article-summary-box-inner">
<span><p>How is knowledge of position-role mappings in natural language learned? We
explore this question in a computational setting, testing whether a variety of
well-performing pertained language models (BERT, RoBERTa, and DistilBERT)
exhibit knowledge of these mappings, and whether this knowledge persists across
alternations in syntactic, structural, and lexical alternations. In Experiment
1, we show that these neural models do indeed recognize distinctions between
theme and recipient roles in ditransitive constructions, and that these
distinct patterns are shared across construction type. We strengthen this
finding in Experiment 2 by showing that fine-tuning these language models on
novel theme- and recipient-like tokens in one paradigm allows the models to
make correct predictions about their placement in other paradigms, suggesting
that the knowledge of these mappings is shared rather than independently
learned. We do, however, observe some limitations of this generalization when
tasks involve constructions with novel ditransitive verbs, hinting at a degree
of lexical specificity which underlies model performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HistBERT: A Pre-trained Language Model for Diachronic Lexical Semantic Analysis. (arXiv:2202.03612v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03612">
<div class="article-summary-box-inner">
<span><p>Contextualized word embeddings have demonstrated state-of-the-art performance
in various natural language processing tasks including those that concern
historical semantic change. However, language models such as BERT was trained
primarily on contemporary corpus data. To investigate whether training on
historical corpus data improves diachronic semantic analysis, we present a
pre-trained BERT-based language model, HistBERT, trained on the balanced Corpus
of Historical American English. We examine the effectiveness of our approach by
comparing the performance of the original BERT and that of HistBERT, and we
report promising results in word similarity and semantic shift analysis. Our
work suggests that the effectiveness of contextual embeddings in diachronic
semantic analysis is dependent on the temporal profile of the input text and
care should be taken in applying this methodology to study historical semantic
change.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Property-Based Tests in Natural Language. (arXiv:2202.03616v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03616">
<div class="article-summary-box-inner">
<span><p>We consider a new approach to generate tests from natural language. Rather
than relying on machine learning or templated extraction from structured
comments, we propose to apply classic ideas from linguistics to translate
natural-language sentences into executable tests. This paper explores the
application of combinatory categorial grammars (CCGs) to generating
property-based tests. Our prototype is able to generate tests from English
descriptions for each example in a textbook chapter on property-based testing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey of Hallucination in Natural Language Generation. (arXiv:2202.03629v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03629">
<div class="article-summary-box-inner">
<span><p>Natural Language Generation (NLG) has improved exponentially in recent years
thanks to the development of deep learning technologies such as
Transformer-based language models. This advancement has led to more fluent and
coherent natural language generation, naturally leading to development in
downstream tasks such as abstractive summarization, dialogue generation and
data-to-text generation. However, it is also investigated that such generation
includes hallucinated texts, which makes the performances of text generation
fail to meet users' expectations in many real-world scenarios. In order to
address this issue, studies in evaluation and mitigation methods of
hallucinations have been presented in various tasks, but have not been reviewed
in a combined manner. In this survey, we provide a broad overview of the
research progress and challenges in the hallucination problem of NLG. The
survey is organized into two big divisions: (i) a general overview of metrics,
mitigation methods, and future directions; (ii) task-specific research progress
for hallucinations in a large set of downstream tasks: abstractive
summarization, dialogue generation, generative question answering, data-to-text
generation, and machine translation. This survey could facilitate collaborative
efforts among researchers in these tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A two-step approach to leverage contextual data: speech recognition in air-traffic communications. (arXiv:2202.03725v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03725">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Recognition (ASR), as the assistance of speech communication
between pilots and air-traffic controllers, can significantly reduce the
complexity of the task and increase the reliability of transmitted information.
ASR application can lead to a lower number of incidents caused by
misunderstanding and improve air traffic management (ATM) efficiency.
Evidently, high accuracy predictions, especially, of key information, i.e.,
callsigns and commands, are required to minimize the risk of errors. We prove
that combining the benefits of ASR and Natural Language Processing (NLP)
methods to make use of surveillance data (i.e. additional modality) helps to
considerably improve the recognition of callsigns (named entity). In this
paper, we investigate a two-step callsign boosting approach: (1) at the 1 step
(ASR), weights of probable callsign n-grams are reduced in G.fst and/or in the
decoding FST (lattices), (2) at the 2 step (NLP), callsigns extracted from the
improved recognition outputs with Named Entity Recognition (NER) are correlated
with the surveillance data to select the most suitable one. Boosting callsign
n-grams with the combination of ASR and NLP methods eventually leads up to
53.7% of an absolute, or 60.4% of a relative, improvement in callsign
recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic features of object concepts generated with GPT-3. (arXiv:2202.03753v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03753">
<div class="article-summary-box-inner">
<span><p>Semantic features have been playing a central role in investigating the
nature of our conceptual representations. Yet the enormous time and effort
required to empirically sample and norm features from human raters has
restricted their use to a limited set of manually curated concepts. Given
recent promising developments with transformer-based language models, here we
asked whether it was possible to use such models to automatically generate
meaningful lists of properties for arbitrary object concepts and whether these
models would produce features similar to those found in humans. To this end, we
probed a GPT-3 model to generate semantic features for 1,854 objects and
compared automatically-generated features to existing human feature norms.
GPT-3 generated many more features than humans, yet showed a similar
distribution in the types of generated features. Generated feature norms
rivaled human norms in predicting similarity, relatedness, and category
membership, while variance partitioning demonstrated that these predictions
were driven by similar variance in humans and GPT-3. Together, these results
highlight the potential of large language models to capture important facets of
human knowledge and yield a new approach for automatically generating
interpretable feature sets, thus drastically expanding the potential use of
semantic features in psychological and linguistic studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Structure with Undirected Neural Networks. (arXiv:2202.03760v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03760">
<div class="article-summary-box-inner">
<span><p>Neural networks are powerful function estimators, leading to their status as
a paradigm of choice for modeling structured data. However, unlike other
structured representations that emphasize the modularity of the problem --
e.g., factor graphs -- neural networks are usually monolithic mappings from
inputs to outputs, with a fixed computation order. This limitation prevents
them from capturing different directions of computation and interaction between
the modeled variables.
</p>
<p>In this paper, we combine the representational strengths of factor graphs and
of neural networks, proposing undirected neural networks (UNNs): a flexible
framework for specifying computations that can be performed in any order. For
particular choices, our proposed models subsume and extend many existing
architectures: feed-forward, recurrent, self-attention networks, auto-encoders,
and networks with implicit layers. We demonstrate the effectiveness of
undirected neural architectures, both unstructured and structured, on a range
of tasks: tree-constrained dependency parsing, convolutional image
classification, and sequence completion with attention. By varying the
computation order, we show how a single UNN can be used both as a classifier
and a prototype generator, and how it can fill in missing parts of an input
sequence, making them a promising field for further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Multi-Token Fairness in Text Classification. (arXiv:2202.03792v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03792">
<div class="article-summary-box-inner">
<span><p>The counterfactual token generation has been limited to perturbing only a
single token in texts that are generally short and single sentences. These
tokens are often associated with one of many sensitive attributes. With limited
counterfactuals generated, the goal to achieve invariant nature for machine
learning classification models towards any sensitive attribute gets bounded,
and the formulation of Counterfactual Fairness gets narrowed. In this paper, we
overcome these limitations by solving root problems and opening bigger domains
for understanding. We have curated a resource of sensitive tokens and their
corresponding perturbation tokens, even extending the support beyond
traditionally used sensitive attributes like \textit{Age}, \textit{Gender}, and
\textit{Race} to \textit{Nationality}, \textit{Disability}, and
\textit{Religion}. The concept of Counterfactual Generation has been extended
to multi-token support valid over all forms of texts and documents. We define
the method of generating counterfactuals by perturbing multiple sensitive
tokens as \textbf{Counterfactual Multi-token Generation}. The method has been
conceptualized to showcase significant performance improvement over
single-token methods and validated over multiple benchmark datasets. The
emendation in counterfactual generation propagates in achieving improved
\textbf{Counterfactual Multi-token Fairness}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What are the best systems? New perspectives on NLP Benchmarking. (arXiv:2202.03799v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03799">
<div class="article-summary-box-inner">
<span><p>In Machine Learning, a benchmark refers to an ensemble of datasets associated
with one or multiple metrics together with a way to aggregate different systems
performances. They are instrumental in (i) assessing the progress of new
methods along different axes and (ii) selecting the best systems for practical
use. This is particularly the case for NLP with the development of large
pre-trained models (e.g. GPT, BERT) that are expected to generalize well on a
variety of tasks. While the community mainly focused on developing new datasets
and metrics, there has been little interest in the aggregation procedure, which
is often reduced to a simple average over various performance measures.
However, this procedure can be problematic when the metrics are on a different
scale, which may lead to spurious conclusions. This paper proposes a new
procedure to rank systems based on their performance across different tasks.
Motivated by the social choice theory, the final system ordering is obtained
through aggregating the rankings induced by each task and is theoretically
grounded. We conduct extensive numerical experiments (on over 270k scores) to
assess the soundness of our approach both on synthetic and real scores (e.g.
GLUE, EXTREM, SEVAL, TAC, FLICKR). In particular, we show that our method
yields different conclusions on state-of-the-art systems than the
mean-aggregation procedure while being both more reliable and robust.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TimeLMs: Diachronic Language Models from Twitter. (arXiv:2202.03829v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03829">
<div class="article-summary-box-inner">
<span><p>Despite its importance, the time variable has been largely neglected in the
NLP and language model literature. In this paper, we present TimeLMs, a set of
language models specialized on diachronic Twitter data. We show that a
continual learning strategy contributes to enhancing Twitter-based language
models' capacity to deal with future and out-of-distribution tweets, while
making them competitive with standardized and more monolithic benchmarks. We
also perform a number of qualitative analyses showing how they cope with trends
and peaks in activity involving specific named entities or concept drift.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable N-gram Objective on Abstractive Summarization. (arXiv:2202.04003v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04003">
<div class="article-summary-box-inner">
<span><p>ROUGE is a standard automatic evaluation metric based on n-grams for
sequence-to-sequence tasks, while cross-entropy loss is an essential objective
of neural network language model that optimizes at a unigram level. We present
differentiable n-gram objectives, attempting to alleviate the discrepancy
between training criterion and evaluating criterion. The objective maximizes
the probabilistic weight of matched sub-sequences, and the novelty of our work
is the objective weights the matched sub-sequences equally and does not ceil
the number of matched sub-sequences by the ground truth count of n-grams in
reference sequence. We jointly optimize cross-entropy loss and the proposed
objective, providing decent ROUGE score enhancement over abstractive
summarization dataset CNN/DM and XSum, outperforming alternative n-gram
objectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating question answering and text-to-SQL in Portuguese. (arXiv:2202.04048v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04048">
<div class="article-summary-box-inner">
<span><p>Deep learning transformers have drastically improved systems that
automatically answer questions in natural language. However, different
questions demand different answering techniques; here we propose, build and
validate an architecture that integrates different modules to answer two
distinct kinds of queries. Our architecture takes a free-form natural language
text and classifies it to send it either to a Neural Question Answering
Reasoner or a Natural Language parser to SQL. We implemented a complete system
for the Portuguese language, using some of the main tools available for the
language and translating training and testing datasets. Experiments show that
our system selects the appropriate answering method with high accuracy (over
99\%), thus validating a modular question answering strategy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generative Transformers. (arXiv:2202.04053v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04053">
<div class="article-summary-box-inner">
<span><p>Generating images from textual descriptions has gained a lot of attention.
Recently, DALL-E, a multimodal transformer language model, and its variants
have shown high-quality text-to-image generation capabilities with a simple
architecture and training objective, powered by large-scale training data and
computation. However, despite the interesting image generation results, there
has not been a detailed analysis on how to evaluate such models. In this work,
we investigate the reasoning capabilities and social biases of such
text-to-image generative transformers in detail. First, we measure four visual
reasoning skills: object recognition, object counting, color recognition, and
spatial relation understanding. For this, we propose PaintSkills, a diagnostic
dataset and evaluation toolkit that measures these four visual reasoning
skills. Second, we measure the text alignment and quality of the generated
images based on pretrained image captioning, image-text retrieval, and image
classification models. Third, we assess social biases in the models. For this,
we suggest evaluation of gender and racial biases of text-to-image generation
models based on a pretrained image-text retrieval model and human evaluation.
In our experiments, we show that recent text-to-image models perform better in
recognizing and counting objects than recognizing colors and understanding
spatial relations, while there exists a large gap between model performances
and oracle accuracy on all skills. Next, we demonstrate that recent
text-to-image models learn specific gender/racial biases from web image-text
pairs. We also show that our automatic evaluations of visual reasoning skills
and gender bias are highly correlated with human judgments. We hope our work
will help guide future progress in improving text-to-image models on visual
reasoning skills and social biases. Code and data at:
https://github.com/j-min/DallEval
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">X-Class: Text Classification with Extremely Weak Supervision. (arXiv:2010.12794v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12794">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore text classification with extremely weak
supervision, i.e., only relying on the surface text of class names. This is a
more challenging setting than the seed-driven weak supervision, which allows a
few seed words per class. We opt to attack this problem from a representation
learning perspective -- ideal document representations should lead to nearly
the same results between clustering and the desired classification. In
particular, one can classify the same corpus differently (e.g., based on topics
and locations), so document representations should be adaptive to the given
class names. We propose a novel framework X-Class to realize the adaptive
representations. Specifically, we first estimate class representations by
incrementally adding the most similar word to each class until inconsistency
arises. Following a tailored mixture of class attention mechanisms, we obtain
the document representation via a weighted average of contextualized word
representations. With the prior of each document assigned to its nearest class,
we then cluster and align the documents to classes. Finally, we pick the most
confident documents from each cluster to train a text classifier. Extensive
experiments demonstrate that X-Class can rival and even outperform seed-driven
weakly supervised methods on 7 benchmark datasets. Our dataset and code are
released at https://github.com/ZihanWangKi/XClass/ .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"Average" Approximates "First Principal Component"? An Empirical Analysis on Representations from Neural Language Models. (arXiv:2104.08673v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08673">
<div class="article-summary-box-inner">
<span><p>Contextualized representations based on neural language models have furthered
the state of the art in various NLP tasks. Despite its great success, the
nature of such representations remains a mystery. In this paper, we present an
empirical property of these representations -- "average" approximates "first
principal component". Specifically, experiments show that the average of these
representations shares almost the same direction as the first principal
component of the matrix whose columns are these representations. We believe
this explains why the average representation is always a simple yet strong
baseline. Our further examinations show that this property also holds in more
challenging scenarios, for example, when the representations are from a model
right after its random initialization. Therefore, we conjecture that this
property is intrinsic to the distribution of representations and not
necessarily related to the input structure. We realize that these
representations empirically follow a normal distribution for each dimension,
and by assuming this is true, we demonstrate that the empirical property can be
in fact derived mathematically.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Noised Consistency Training for Text Summarization. (arXiv:2105.13635v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13635">
<div class="article-summary-box-inner">
<span><p>Neural abstractive summarization methods often require large quantities of
labeled training data. However, labeling large amounts of summarization data is
often prohibitive due to time, financial, and expertise constraints, which has
limited the usefulness of summarization systems to practical applications. In
this paper, we argue that this limitation can be overcome by a semi-supervised
approach: consistency training which is to leverage large amounts of unlabeled
data to improve the performance of supervised learning over a small corpus. The
consistency regularization semi-supervised learning can regularize model
predictions to be invariant to small noise applied to input articles. By adding
noised unlabeled corpus to help regularize consistency training, this framework
obtains comparative performance without using the full dataset. In particular,
we have verified that leveraging large amounts of unlabeled data decently
improves the performance of supervised learning over an insufficient labeled
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Sexism Detection with Multilingual Transformer Models. (arXiv:2106.04908v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04908">
<div class="article-summary-box-inner">
<span><p>Sexism has become an increasingly major problem on social networks during the
last years. The first shared task on sEXism Identification in Social neTworks
(EXIST) at IberLEF 2021 is an international competition in the field of Natural
Language Processing (NLP) with the aim to automatically identify sexism in
social media content by applying machine learning methods. Thereby sexism
detection is formulated as a coarse (binary) classification problem and a
fine-grained classification task that distinguishes multiple types of sexist
content (e.g., dominance, stereotyping, and objectification). This paper
presents the contribution of the AIT_FHSTP team at the EXIST2021 benchmark for
both tasks. To solve the tasks we applied two multilingual transformer models,
one based on multilingual BERT and one based on XLM-R. Our approach uses two
different strategies to adapt the transformers to the detection of sexist
content: first, unsupervised pre-training with additional data and second,
supervised fine-tuning with additional and augmented data. For both tasks our
best model is XLM-R with unsupervised pre-training on the EXIST data and
additional datasets and fine-tuning on the provided dataset. The best run for
the binary classification (task 1) achieves a macro F1-score of 0.7752 and
scores 5th rank in the benchmark; for the multiclass classification (task 2)
our best submission scores 6th rank with a macro F1-score of 0.5589.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Conditional End-to-End ASR with CTC and Multi-Granular Subword Units. (arXiv:2110.04109v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04109">
<div class="article-summary-box-inner">
<span><p>In end-to-end automatic speech recognition (ASR), a model is expected to
implicitly learn representations suitable for recognizing a word-level
sequence. However, the huge abstraction gap between input acoustic signals and
output linguistic tokens makes it challenging for a model to learn the
representations. In this work, to promote the word-level representation
learning in end-to-end ASR, we propose a hierarchical conditional model that is
based on connectionist temporal classification (CTC). Our model is trained by
auxiliary CTC losses applied to intermediate layers, where the vocabulary size
of each target subword sequence is gradually increased as the layer becomes
close to the word-level output. Here, we make each level of sequence prediction
explicitly conditioned on the previous sequences predicted at lower levels.
With the proposed approach, we expect the proposed model to learn the
word-level representations effectively by exploiting a hierarchy of linguistic
structures. Experimental results on LibriSpeech-{100h, 960h} and TEDLIUM2
demonstrate that the proposed model improves over a standard CTC-based model
and other competitive models from prior work. We further analyze the results to
confirm the effectiveness of the intended representation learning with our
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Would Jiminy Cricket Do? Towards Agents That Behave Morally. (arXiv:2110.13136v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13136">
<div class="article-summary-box-inner">
<span><p>When making everyday decisions, people are guided by their conscience, an
internal sense of right and wrong. By contrast, artificial agents are currently
not endowed with a moral sense. As a consequence, they may learn to behave
immorally when trained on environments that ignore moral concerns, such as
violent video games. With the advent of generally capable agents that pretrain
on many environments, it will become necessary to mitigate inherited biases
from environments that teach immoral behavior. To facilitate the development of
agents that avoid causing wanton harm, we introduce Jiminy Cricket, an
environment suite of 25 text-based adventure games with thousands of diverse,
morally salient scenarios. By annotating every possible game state, the Jiminy
Cricket environments robustly evaluate whether agents can act morally while
maximizing reward. Using models with commonsense moral knowledge, we create an
elementary artificial conscience that assesses and guides agents. In extensive
experiments, we find that the artificial conscience approach can steer agents
towards moral behavior without sacrificing performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Funnelling: Ensemble Learning and Heterogeneous Document Embeddings for Cross-Lingual Text Classification. (arXiv:2110.14764v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14764">
<div class="article-summary-box-inner">
<span><p>\emph{Funnelling} (Fun) is a recently proposed method for cross-lingual text
classification (CLTC) based on a two-tier learning ensemble for heterogeneous
transfer learning (HTL). In this ensemble method, 1st-tier classifiers, each
working on a different and language-dependent feature space, return a vector of
calibrated posterior probabilities (with one dimension for each class) for each
document, and the final classification decision is taken by a metaclassifier
that uses this vector as its input. The metaclassifier can thus exploit
class-class correlations, and this (among other things) gives Fun an edge over
CLTC systems in which these correlations cannot be brought to bear. In this
paper we describe \emph{Generalized Funnelling} (gFun), a generalization of Fun
consisting of an HTL architecture in which 1st-tier components can be arbitrary
\emph{view-generating functions}, i.e., language-dependent functions that each
produce a language-independent representation ("view") of the (monolingual)
document. We describe an instance of gFun in which the metaclassifier receives
as input a vector of calibrated posterior probabilities (as in Fun) aggregated
to other embedded representations that embody other types of correlations, such
as word-class correlations (as encoded by \emph{Word-Class Embeddings}),
word-word correlations (as encoded by \emph{Multilingual Unsupervised or
Supervised Embeddings}), and word-context correlations (as encoded by
\emph{multilingual BERT}). We show that this instance of \textsc{gFun}
substantially improves over Fun and over state-of-the-art baselines, by
reporting experimental results obtained on two large, standard datasets for
multilingual multilabel text classification. Our code that implements gFun is
publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Enactivist account of Mind Reading in Natural Language Understanding. (arXiv:2111.06179v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.06179">
<div class="article-summary-box-inner">
<span><p>In this paper we apply our understanding of the radical enactivist agenda to
the classic AI-hard problem of Natural Language Understanding. When Turing
devised his famous test the assumption was that a computer could use language
and the challenge would be to mimic human intelligence. It turned out playing
chess and formal logic were easy compared to understanding what people say. The
techniques of good old-fashioned AI (GOFAI) assume symbolic representation is
the core of reasoning and by that paradigm human communication consists of
transferring representations from one mind to another. However, one finds that
representations appear in another's mind, without appearing in the intermediary
language. People communicate by mind reading it seems. Systems with speech
interfaces such as Alexa and Siri are of course common, but they are limited.
Rather than adding mind reading skills, we introduced a "cheat" that enabled
our systems to fake it. The cheat is simple and only slightly interesting to
computer scientists and not at all interesting to philosophers. However,
reading about the enactivist idea that we "directly perceive" the intentions of
others, our cheat took on a new light and in this paper look again at how
natural language understanding might actually work between humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving language models by retrieving from trillions of tokens. (arXiv:2112.04426v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04426">
<div class="article-summary-box-inner">
<span><p>We enhance auto-regressive language models by conditioning on document chunks
retrieved from a large corpus, based on local similarity with preceding tokens.
With a $2$ trillion token database, our Retrieval-Enhanced Transformer (RETRO)
obtains comparable performance to GPT-3 and Jurassic-1 on the Pile, despite
using 25$\times$ fewer parameters. After fine-tuning, RETRO performance
translates to downstream knowledge-intensive tasks such as question answering.
RETRO combines a frozen Bert retriever, a differentiable encoder and a chunked
cross-attention mechanism to predict tokens based on an order of magnitude more
data than what is typically consumed during training. We typically train RETRO
from scratch, yet can also rapidly RETROfit pre-trained transformers with
retrieval and still achieve good performance. Our work opens up new avenues for
improving language models through explicit memory at unprecedented scale.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Black-Box Tuning for Language-Model-as-a-Service. (arXiv:2201.03514v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03514">
<div class="article-summary-box-inner">
<span><p>Extremely large pre-trained language models (PTMs) such as GPT-3 are usually
released as a service. It allows users to design task-specific prompts to query
the PTMs through some black-box APIs. In such a scenario, which we call
Language-Model-as-a-Service (LMaaS), the gradients of PTMs are usually
unavailable. Can we optimize the task prompts by only accessing the model
inference APIs? This paper proposes the black-box tuning framework to optimize
the continuous prompt prepended to the input text via derivative-free
optimization. Instead of optimizing in the original high-dimensional prompt
space, which is intractable for traditional derivative-free optimization, we
perform optimization in a randomly generated subspace due to the low intrinsic
dimensionality of large PTMs. The experimental results show that the black-box
tuning with RoBERTa on a few labeled samples not only significantly outperforms
manual prompt and GPT-3's in-context learning, but also surpasses the
gradient-based counterparts, i.e. prompt tuning and full model tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evidence-aware Fake News Detection with Graph Neural Networks. (arXiv:2201.06885v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.06885">
<div class="article-summary-box-inner">
<span><p>The prevalence and perniciousness of fake news has been a critical issue on
the Internet, which stimulates the development of automatic fake news detection
in turn. In this paper, we focus on the evidence-based fake news detection,
where several evidences are utilized to probe the veracity of news (i.e., a
claim). Most previous methods first employ sequential models to embed the
semantic information and then capture the claim-evidence interaction based on
different attention mechanisms. Despite their effectiveness, they still suffer
from two main weaknesses. Firstly, due to the inherent drawbacks of sequential
models, they fail to integrate the relevant information that is scattered far
apart in evidences for veracity checking. Secondly, they neglect much redundant
information contained in evidences that may be useless or even harmful. To
solve these problems, we propose a unified Graph-based sEmantic sTructure
mining framework, namely GET in short. Specifically, different from the
existing work that treats claims and evidences as sequences, we model them as
graph-structured data and capture the long-distance semantic dependency among
dispersed relevant snippets via neighborhood propagation. After obtaining
contextual semantic information, our model reduces information redundancy by
performing graph structure learning. Finally, the fine-grained semantic
representations are fed into the downstream claim-evidence interaction module
for predictions. Comprehensive experiments have demonstrated the superiority of
GET over the state-of-the-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Learning Over Multiple Domains in Natural Language Tasks. (arXiv:2202.00254v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00254">
<div class="article-summary-box-inner">
<span><p>Studies of active learning traditionally assume the target and source data
stem from a single domain. However, in realistic applications, practitioners
often require active learning with multiple sources of out-of-distribution
data, where it is unclear a priori which data sources will help or hurt the
target domain. We survey a wide variety of techniques in active learning (AL),
domain shift detection (DS), and multi-domain sampling to examine this
challenging setting for question answering and sentiment analysis. We ask (1)
what family of methods are effective for this task? And, (2) what properties of
selected examples and domains achieve strong results? Among 18 acquisition
functions from 4 families of methods, we find H-Divergence methods, and
particularly our proposed variant DAL-E, yield effective results, averaging
2-3% improvements over the random baseline. We also show the importance of a
diverse allocation of domains, as well as room-for-improvement of existing
methods on both domain and example selection. Our findings yield the first
comprehensive analysis of both existing and novel methods for practitioners
faced with multi-domain active learning for natural language tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Aspect-Based Sentiment Analysis. (arXiv:2202.01924v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01924">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis (ABSA) typically requires in-domain annotated
data for supervised training/fine-tuning. It is a big challenge to scale ABSA
to a large number of new domains. This paper aims to train a unified model that
can perform zero-shot ABSA without using any annotated data for a new domain.
We propose a method called contrastive post-training on review Natural Language
Inference (CORN). Later ABSA tasks can be cast into NLI for zero-shot transfer.
We evaluate CORN on ABSA tasks, ranging from aspect extraction (AE), aspect
sentiment classification (ASC), to end-to-end aspect-based sentiment analysis
(E2E ABSA), which show ABSA can be conducted without any human annotated ABSA
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer. (arXiv:2202.02113v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02113">
<div class="article-summary-box-inner">
<span><p>Knowledge graph completion aims to address the problem of extending a KG with
missing triples. In this paper, we provide an approach GenKGC, which converts
knowledge graph completion to sequence-to-sequence generation task with the
pre-trained language model. We further introduce relation-guided demonstration
and entity-aware hierarchical decoding for better representation learning and
fast inference. Experimental results on three datasets show that our approach
can obtain better or comparable performance than baselines and achieve faster
inference speed compared with previous methods with pre-trained language
models. We also release a new large-scale Chinese knowledge graph dataset
AliopenKG500 for research purpose. Code and datasets are available in
https://github.com/zjunlp/PromptKGC/tree/main/GenKGC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEAPMood: Light and Efficient Architecture to Predict Mood with Genetic Algorithm driven Hyperparameter Tuning. (arXiv:2202.02522v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02522">
<div class="article-summary-box-inner">
<span><p>Accurate and automatic detection of mood serves as a building block for use
cases like user profiling which in turn power applications such as advertising,
recommendation systems, and many more. One primary source indicative of an
individual's mood is textual data. While there has been extensive research on
emotion recognition, the field of mood prediction has been barely explored. In
addition, very little work is done in the area of on-device inferencing, which
is highly important from the user privacy point of view. In this paper, we
propose for the first time, an on-device deep learning approach for mood
prediction from textual data, LEAPMood. We use a novel on-device
deployment-focused objective function for hyperparameter tuning based on the
Genetic Algorithm (GA) and optimize the parameters concerning both performance
and size. LEAPMood consists of Emotion Recognition in Conversion (ERC) as the
first building block followed by mood prediction using K-means clustering. We
show that using a combination of character embedding, phonetic hashing, and
attention along with Conditional Random Fields (CRF), results in a performance
closely comparable to that of the current State-Of-the-Art with a significant
reduction in model size (&gt; 90%) for the task of ERC. We achieve a Micro F1
score of 62.05% with a memory footprint of a mere 1.67MB on the DailyDialog
dataset. Furthermore, we curate a dataset for the task of mood prediction
achieving a Macro F1-score of 72.12% with LEAPMood.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Moving Other Way: Exploring Word Mover Distance Extensions. (arXiv:2202.03119v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03119">
<div class="article-summary-box-inner">
<span><p>The word mover's distance (WMD) is a popular semantic similarity metric for
two texts. This position paper studies several possible extensions of WMD. We
experiment with the frequency of words in the corpus as a weighting factor and
the geometry of the word vector space. We validate possible extensions of WMD
on six document classification datasets. Some proposed extensions show better
results in terms of the k-nearest neighbor classification error than WMD.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Backdoor Defense via Decoupling the Training Process. (arXiv:2202.03423v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03423">
<div class="article-summary-box-inner">
<span><p>Recent studies have revealed that deep neural networks (DNNs) are vulnerable
to backdoor attacks, where attackers embed hidden backdoors in the DNN model by
poisoning a few training samples. The attacked model behaves normally on benign
samples, whereas its prediction will be maliciously changed when the backdoor
is activated. We reveal that poisoned samples tend to cluster together in the
feature space of the attacked DNN model, which is mostly due to the end-to-end
supervised training paradigm. Inspired by this observation, we propose a novel
backdoor defense via decoupling the original end-to-end training process into
three stages. Specifically, we first learn the backbone of a DNN model via
\emph{self-supervised learning} based on training samples without their labels.
The learned backbone will map samples with the same ground-truth label to
similar locations in the feature space. Then, we freeze the parameters of the
learned backbone and train the remaining fully connected layers via standard
training with all (labeled) training samples. Lastly, to further alleviate
side-effects of poisoned samples in the second stage, we remove labels of some
`low-credible' samples determined based on the learned model and conduct a
\emph{semi-supervised fine-tuning} of the whole model. Extensive experiments on
multiple benchmark datasets and DNN models verify that the proposed defense is
effective in reducing backdoor threats while preserving high accuracy in
predicting benign samples. Our code is available at
\url{https://github.com/SCLBD/DBD}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Performance Evaluation of Infrared Image Enhancement Techniques. (arXiv:2202.03427v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03427">
<div class="article-summary-box-inner">
<span><p>Infrared (IR) images are widely used in many fields such as medical imaging,
object tracking, astronomy and military purposes for securing borders. Infrared
images can be captured day or night based on the type of capturing device. The
capturing devices use electromagnetic radiation with longer wavelengths. There
are several types of IR radiation based on the range of wavelength and
corresponding frequency. Due to noising and other artifacts, IR images are not
clearly visible. In this paper, we present a complete up-todate survey on IR
imaging enhancement techniques. The survey includes IR radiation types and
devices and existing IR datasets. The survey covers spatial enhancement
techniques, frequency-domain based enhancement techniques and Deep
learning-based techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Topology-Attention ConvLSTM Network and Its Application to EM Images. (arXiv:2202.03430v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03430">
<div class="article-summary-box-inner">
<span><p>Structural accuracy of segmentation is important for finescale structures in
biomedical images. We propose a novel TopologyAttention ConvLSTM Network
(TACNet) for 3D image segmentation in order to achieve high structural accuracy
for 3D segmentation tasks. Specifically, we propose a Spatial
Topology-Attention (STA) module to process a 3D image as a stack of 2D image
slices and adopt ConvLSTM to leverage contextual structure information from
adjacent slices. In order to effectively transfer topology-critical information
across slices, we propose an Iterative-Topology Attention (ITA) module that
provides a more stable topology-critical map for segmentation. Quantitative and
qualitative results show that our proposed method outperforms various baselines
in terms of topology-aware evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inference of captions from histopathological patches. (arXiv:2202.03432v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03432">
<div class="article-summary-box-inner">
<span><p>Computational histopathology has made significant strides in the past few
years, slowly getting closer to clinical adoption. One area of benefit would be
the automatic generation of diagnostic reports from H\&amp;E-stained whole slide
images which would further increase the efficiency of the pathologists' routine
diagnostic workflows. In this study, we compiled a dataset (PatchGastricADC22)
of histopathological captions of stomach adenocarcinoma endoscopic biopsy
specimens, which we extracted from diagnostic reports and paired with patches
extracted from the associated whole slide images. The dataset contains a
variety of gastric adenocarcinoma subtypes. We trained a baseline
attention-based model to predict the captions from features extracted from the
patches and obtained promising results. We make the captioned dataset of 262K
patches publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Coarse-to-fine Morphological Approach With Knowledge-based Rules and Self-adapting Correction for Lung Nodules Segmentation. (arXiv:2202.03433v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03433">
<div class="article-summary-box-inner">
<span><p>The segmentation module which precisely outlines the nodules is a crucial
step in a computer-aided diagnosis(CAD) system. The most challenging part of
such a module is how to achieve high accuracy of the segmentation, especially
for the juxtapleural, non-solid and small nodules. In this research, we present
a coarse-to-fine methodology that greatly improves the thresholding method
performance with a novel self-adapting correction algorithm and effectively
removes noisy pixels with well-defined knowledge-based principles. Compared
with recent strong morphological baselines, our algorithm, by combining dataset
features, achieves state-of-the-art performance on both the public LIDC-IDRI
dataset (DSC 0.699) and our private LC015 dataset (DSC 0.760) which closely
approaches the SOTA deep learning-based models' performances. Furthermore,
unlike most available morphological methods that can only segment the isolated
and well-circumscribed nodules accurately, the precision of our method is
totally independent of the nodule type or diameter, proving its applicability
and generality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal data generation with a deep metric variational autoencoder. (arXiv:2202.03434v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03434">
<div class="article-summary-box-inner">
<span><p>We present a deep metric variational autoencoder for multi-modal data
generation. The variational autoencoder employs triplet loss in the latent
space, which allows for conditional data generation by sampling in the latent
space within each class cluster. The approach is evaluated on a multi-modal
dataset consisting of otoscopy images of the tympanic membrane with
corresponding wideband tympanometry measurements. The modalities in this
dataset are correlated, as they represent different aspects of the state of the
middle ear, but they do not present a direct pixel-to-pixel correlation. The
approach shows promising results for the conditional generation of pairs of
images and tympanograms, and will allow for efficient data augmentation of data
from multi-modal sources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PatClArC: Using Pattern Concept Activation Vectors for Noise-Robust Model Debugging. (arXiv:2202.03482v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03482">
<div class="article-summary-box-inner">
<span><p>State-of-the-art machine learning models are commonly (pre-)trained on large
benchmark datasets. These often contain biases, artifacts, or errors that have
remained unnoticed in the data collection process and therefore fail in
representing the real world truthfully. This can cause models trained on these
datasets to learn undesired behavior based upon spurious correlations, e.g.,
the existence of a copyright tag in an image. Concept Activation Vectors (CAV)
have been proposed as a tool to model known concepts in latent space and have
been used for concept sensitivity testing and model correction. Specifically,
class artifact compensation (ClArC) corrects models using CAVs to represent
data artifacts in feature space linearly. Modeling CAVs with filters of linear
models, however, causes a significant influence of the noise portion within the
data, as recent work proposes the unsuitability of linear model filters to find
the signal direction in the input, which can be avoided by instead using
patterns. In this paper we propose Pattern Concept Activation Vectors (PCAV)
for noise-robust concept representations in latent space. We demonstrate that
pattern-based artifact modeling has beneficial effects on the application of
CAVs as a means to remove influence of confounding features from models via the
ClArC framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Random Ferns for Semantic Segmentation of PolSAR Images. (arXiv:2202.03498v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03498">
<div class="article-summary-box-inner">
<span><p>Random Ferns -- as a less known example of Ensemble Learning -- have been
successfully applied in many Computer Vision applications ranging from keypoint
matching to object detection. This paper extends the Random Fern framework to
the semantic segmentation of polarimetric synthetic aperture radar images. By
using internal projections that are defined over the space of Hermitian
matrices, the proposed classifier can be directly applied to the polarimetric
covariance matrices without the need to explicitly compute predefined image
features. Furthermore, two distinct optimization strategies are proposed: The
first based on pre-selection and grouping of internal binary features before
the creation of the classifier; and the second based on iteratively improving
the properties of a given Random Fern. Both strategies are able to boost the
performance by filtering features that are either redundant or have a low
information content and by grouping correlated features to best fulfill the
independence assumptions made by the Random Fern classifier. Experiments show
that results can be achieved that are similar to a more complex Random Forest
model and competitive to a deep learning baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scribble-based Boundary-aware Network for Weakly Supervised Salient Object Detection in Remote Sensing Images. (arXiv:2202.03501v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03501">
<div class="article-summary-box-inner">
<span><p>Existing CNNs-based salient object detection (SOD) heavily depends on the
large-scale pixel-level annotations, which is labor-intensive, time-consuming,
and expensive. By contrast, the sparse annotations become appealing to the
salient object detection community. However, few efforts are devoted to
learning salient object detection from sparse annotations, especially in the
remote sensing field. In addition, the sparse annotation usually contains
scanty information, which makes it challenging to train a well-performing
model, resulting in its performance largely lagging behind the fully-supervised
models. Although some SOD methods adopt some prior cues to improve the
detection performance, they usually lack targeted discrimination of object
boundaries and thus provide saliency maps with poor boundary localization. To
this end, in this paper, we propose a novel weakly-supervised salient object
detection framework to predict the saliency of remote sensing images from
sparse scribble annotations. To implement it, we first construct the
scribble-based remote sensing saliency dataset by relabelling an existing
large-scale SOD dataset with scribbles, namely S-EOR dataset. After that, we
present a novel scribble-based boundary-aware network (SBA-Net) for remote
sensing salient object detection. Specifically, we design a boundary-aware
module (BAM) to explore the object boundary semantics, which is explicitly
supervised by the high-confidence object boundary (pseudo) labels generated by
the boundary label generation (BLG) module, forcing the model to learn features
that highlight the object structure and thus boosting the boundary localization
of objects. Then, the boundary semantics are integrated with high-level
features to guide the salient object detection under the supervision of
scribble labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrated Multiscale Domain Adaptive YOLO. (arXiv:2202.03527v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03527">
<div class="article-summary-box-inner">
<span><p>The area of domain adaptation has been instrumental in addressing the domain
shift problem encountered by many applications. This problem arises due to the
difference between the distributions of source data used for training in
comparison with target data used during realistic testing scenarios. In this
paper, we introduce a novel MultiScale Domain Adaptive YOLO (MS-DAYOLO)
framework that employs multiple domain adaptation paths and corresponding
domain classifiers at different scales of the recently introduced YOLOv4 object
detector. Building on our baseline multiscale DAYOLO framework, we introduce
three novel deep learning architectures for a Domain Adaptation Network (DAN)
that generates domain-invariant features. In particular, we propose a
Progressive Feature Reduction (PFR), a Unified Classifier (UC), and an
Integrated architecture. We train and test our proposed DAN architectures in
conjunction with YOLOv4 using popular datasets. Our experiments show
significant improvements in object detection performance when training YOLOv4
using the proposed MS-DAYOLO architectures and when tested on target data for
autonomous driving applications. Moreover, MS-DAYOLO framework achieves an
order of magnitude real-time speed improvement relative to Faster R-CNN
solutions while providing comparable object detection performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MINER: Multiscale Implicit Neural Representations. (arXiv:2202.03532v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03532">
<div class="article-summary-box-inner">
<span><p>We introduce a new neural signal representation designed for the efficient
high-resolution representation of large-scale signals. The key innovation in
our multiscale implicit neural representation (MINER) is an internal
representation via a Laplacian pyramid, which provides a sparse multiscale
representation of the signal that captures orthogonal parts of the signal
across scales. We leverage the advantages of the Laplacian pyramid by
representing small disjoint patches of the pyramid at each scale with a tiny
MLP. This enables the capacity of the network to adaptively increase from
coarse to fine scales, and only represent parts of the signal with strong
signal energy. The parameters of each MLP are optimized from coarse-to-fine
scale which results in faster approximations at coarser scales, thereby
ultimately an extremely fast training process. We apply MINER to a range of
large-scale signal representation tasks, including gigapixel images and very
large point clouds, and demonstrate that it requires fewer than 25% of the
parameters, 33% of the memory footprint, and 10% of the computation time of
competing techniques such as ACORN to reach the same representation error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SliTraNet: Automatic Detection of Slide Transitions in Lecture Videos using Convolutional Neural Networks. (arXiv:2202.03540v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03540">
<div class="article-summary-box-inner">
<span><p>With the increasing number of online learning material in the web, search for
specific content in lecture videos can be time consuming. Therefore, automatic
slide extraction from the lecture videos can be helpful to give a brief
overview of the main content and to support the students in their studies. For
this task, we propose a deep learning method to detect slide transitions in
lectures videos. We first process each frame of the video by a heuristic-based
approach using a 2-D convolutional neural network to predict transition
candidates. Then, we increase the complexity by employing two 3-D convolutional
neural networks to refine the transition candidates. Evaluation results
demonstrate the effectiveness of our method in finding slide transitions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Representation Learning for Speech Using Visual Grounding and Masked Language Modeling. (arXiv:2202.03543v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03543">
<div class="article-summary-box-inner">
<span><p>In this paper, we describe our submissions to the ZeroSpeech 2021 Challenge
and SUPERB benchmark. Our submissions are based on the recently proposed
FaST-VGS model, which is a Transformer-based model that learns to associate raw
speech waveforms with semantically related images, all without the use of any
transcriptions of the speech. Additionally, we introduce a novel extension of
this model, FaST-VGS+, which is learned in a multi-task fashion with a masked
language modeling objective in addition to the visual grounding objective. On
ZeroSpeech 2021, we show that our models perform competitively on the ABX task,
outperform all other concurrent submissions on the Syntactic and Semantic
tasks, and nearly match the best system on the Lexical task. On the SUPERB
benchmark, we show that our models also achieve strong performance, in some
cases even outperforming the popular wav2vec2.0 model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LwPosr: Lightweight Efficient Fine-Grained Head Pose Estimation. (arXiv:2202.03544v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03544">
<div class="article-summary-box-inner">
<span><p>This paper presents a lightweight network for head pose estimation (HPE)
task. While previous approaches rely on convolutional neural networks, the
proposed network \textit{LwPosr} uses mixture of depthwise separable
convolutional (DSC) and transformer encoder layers which are structured in two
streams and three stages to provide fine-grained regression for predicting head
poses. The quantitative and qualitative demonstration is provided to show that
the proposed network is able to learn head poses efficiently while using less
parameter space. Extensive ablations are conducted using three open-source
datasets namely 300W-LP, AFLW2000, and BIWI datasets. To our knowledge, (1)
\textit{LwPosr} is the lightest network proposed for estimating head poses
compared to both keypoints-based and keypoints-free approaches; (2) it sets a
benchmark for both overperforming the previous lightweight network on mean
absolute error and on reducing number of parameters; (3) it is first of its
kind to use mixture of DSCs and transformer encoders for HPE. This approach is
suitable for mobile devices which require lightweight networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HeadPosr: End-to-end Trainable Head Pose Estimation using Transformer Encoders. (arXiv:2202.03548v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03548">
<div class="article-summary-box-inner">
<span><p>In this paper, HeadPosr is proposed to predict the head poses using a single
RGB image. \textit{HeadPosr} uses a novel architecture which includes a
transformer encoder. In concrete, it consists of: (1) backbone; (2) connector;
(3) transformer encoder; (4) prediction head. The significance of using a
transformer encoder for HPE is studied. An extensive ablation study is
performed on varying the (1) number of encoders; (2) number of heads; (3)
different position embeddings; (4) different activations; (5) input channel
size, in a transformer used in HeadPosr. Further studies on using: (1)
different backbones, (2) using different learning rates are also shown. The
elaborated experiments and ablations studies are conducted using three
different open-source widely used datasets for HPE, i.e., 300W-LP, AFLW2000,
and BIWI datasets. Experiments illustrate that \textit{HeadPosr} outperforms
all the state-of-art methods including both the landmark-free and the others
based on using landmark or depth estimation on the AFLW2000 dataset and BIWI
datasets when trained with 300W-LP. It also outperforms when averaging the
results from the compared datasets, hence setting a benchmark for the problem
of HPE, also demonstrating the effectiveness of using transformers over the
state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aladdin: Joint Atlas Building and Diffeomorphic Registration Learning with Pairwise Alignment. (arXiv:2202.03563v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03563">
<div class="article-summary-box-inner">
<span><p>Atlas building and image registration are important tasks for medical image
analysis. Once one or multiple atlases from an image population have been
constructed, commonly (1) images are warped into an atlas space to study
intra-subject or inter-subject variations or (2) a possibly probabilistic atlas
is warped into image space to assign anatomical labels. Atlas estimation and
nonparametric transformations are computationally expensive as they usually
require numerical optimization. Additionally, previous approaches for atlas
building often define similarity measures between a fuzzy atlas and each
individual image, which may cause alignment difficulties because a fuzzy atlas
does not exhibit clear anatomical structures in contrast to the individual
images. This work explores using a convolutional neural network (CNN) to
jointly predict the atlas and a stationary velocity field (SVF)
parameterization for diffeomorphic image registration with respect to the
atlas. Our approach does not require affine pre-registrations and utilizes
pairwise image alignment losses to increase registration accuracy. We evaluate
our model on 3D knee magnetic resonance images (MRI) from the OAI-ZIB dataset.
Our results show that the proposed framework achieves better performance than
other state-of-the-art image registration algorithms, allows for end-to-end
training, and for fast inference at test time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate super-resolution low-field brain MRI. (arXiv:2202.03564v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03564">
<div class="article-summary-box-inner">
<span><p>The recent introduction of portable, low-field MRI (LF-MRI) into the clinical
setting has the potential to transform neuroimaging. However, LF-MRI is limited
by lower resolution and signal-to-noise ratio, leading to incomplete
characterization of brain regions. To address this challenge, recent advances
in machine learning facilitate the synthesis of higher resolution images
derived from one or multiple lower resolution scans. Here, we report the
extension of a machine learning super-resolution (SR) algorithm to synthesize 1
mm isotropic MPRAGE-like scans from LF-MRI T1-weighted and T2-weighted
sequences. Our initial results on a paired dataset of LF and high-field (HF,
1.5T-3T) clinical scans show that: (i) application of available automated
segmentation tools directly to LF-MRI images falters; but (ii) segmentation
tools succeed when applied to SR images with high correlation to gold standard
measurements from HF-MRI (e.g., r = 0.85 for hippocampal volume, r = 0.84 for
the thalamus, r = 0.92 for the whole cerebrum). This work demonstrates
proof-of-principle post-processing image enhancement from lower resolution
LF-MRI sequences. These results lay the foundation for future work to enhance
the detection of normal and abnormal image findings at LF and ultimately
improve the diagnostic performance of LF-MRI. Our tools are publicly available
on FreeSurfer (surfer.nmr.mgh.harvard.edu/).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phase-Stretch Adaptive Gradient-Field Extractor (PAGE). (arXiv:2202.03570v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03570">
<div class="article-summary-box-inner">
<span><p>Phase-Stretch Adaptive Gradient-Field Extractor (PAGE) is an edge detection
algorithm that is inspired by physics of electromagnetic diffraction and
dispersion. A computational imaging algorithm, it identifies edges, their
orientations and sharpness in a digital image where the image brightness
changes abruptly. Edge detection is a basic operation performed by the eye and
is crucial to visual perception. PAGE embeds an original image into a set of
feature maps that can be used for object representation and classification. The
algorithm performs exceptionally well as an edge and texture extractor in low
light level and low contrast images. This manuscript is prepared to support the
open-source code which is being simultaneously made available within the GitHub
repository https://github.com/JalaliLabUCLA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Metal Artifact Reduction with Intra-Oral Scan Data for 3D Low Dose Maxillofacial CBCT Modeling. (arXiv:2202.03571v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03571">
<div class="article-summary-box-inner">
<span><p>Low-dose dental cone beam computed tomography (CBCT) has been increasingly
used for maxillofacial modeling. However, the presence of metallic inserts,
such as implants, crowns, and dental filling, causes severe streaking and
shading artifacts in a CBCT image and loss of the morphological structures of
the teeth, which consequently prevents accurate segmentation of bones. A
two-stage metal artifact reduction method is proposed for accurate 3D low-dose
maxillofacial CBCT modeling, where a key idea is to utilize explicit tooth
shape prior information from intra-oral scan data whose acquisition does not
require any extra radiation exposure. In the first stage, an image-to-image
deep learning network is employed to mitigate metal-related artifacts. To
improve the learning ability, the proposed network is designed to take
advantage of the intra-oral scan data as side-inputs and perform multi-task
learning of auxiliary tooth segmentation. In the second stage, a 3D
maxillofacial model is constructed by segmenting the bones from the dental CBCT
image corrected in the first stage. For accurate bone segmentation, weighted
thresholding is applied, wherein the weighting region is determined depending
on the geometry of the intra-oral scan data. Because acquiring a paired
training dataset of metal-artifact-free and metal artifact-affected dental CBCT
images is challenging in clinical practice, an automatic method of generating a
realistic dataset according to the CBCT physics model is introduced. Numerical
simulations and clinical experiments show the feasibility of the proposed
method, which takes advantage of tooth surface information from intra-oral scan
data in 3D low dose maxillofacial CBCT modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Prediction Problem Archive. (arXiv:2202.03574v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03574">
<div class="article-summary-box-inner">
<span><p>Structured prediction problems are one of the fundamental tools in machine
learning. In order to facilitate algorithm development for their numerical
solution, we collect in one place a large number of datasets in easy to read
formats for a diverse set of problem classes. We provide archival links to
datasets, description of the considered problems and problem formats, and a
short summary of problem characteristics including size, number of instances
etc. For reference we also give a non-exhaustive selection of algorithms
proposed in the literature for their solution. We hope that this central
repository will make benchmarking and comparison to established works easier.
We welcome submission of interesting new datasets and algorithms for inclusion
in our archive.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations. (arXiv:2202.03576v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03576">
<div class="article-summary-box-inner">
<span><p>Owing much to the revolution of information technology, the recent progress
of deep learning benefits incredibly from the vastly enhanced access to data
available in various digital formats. However, in certain scenarios, people may
not want their data being used for training commercial models and thus studied
how to attack the learnability of deep learning models. Previous works on
learnability attack only consider the goal of preventing unauthorized
exploitation on the specific dataset but not the process of restoring the
learnability for authorized cases. To tackle this issue, this paper introduces
and investigates a new concept called "learnability lock" for controlling the
model's learnability on a specific dataset with a special key. In particular,
we propose adversarial invertible transformation, that can be viewed as a
mapping from image to image, to slightly modify data samples so that they
become "unlearnable" by machine learning models with negligible loss of visual
features. Meanwhile, one can unlock the learnability of the dataset and train
models normally using the corresponding key. The proposed learnability lock
leverages class-wise perturbation that applies a universal transformation
function on data samples of the same label. This ensures that the learnability
can be easily restored with a simple inverse transformation while remaining
difficult to be detected or reverse-engineered. We empirically demonstrate the
success and practicability of our method on visual classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Label Classification of Thoracic Diseases using Dense Convolutional Network on Chest Radiographs. (arXiv:2202.03583v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03583">
<div class="article-summary-box-inner">
<span><p>Chest X-ray images are one of the most common medical diagnosis techniques to
identify different thoracic diseases. However, identification of pathologies in
X-ray images requires skilled manpower and are often cited as a time-consuming
task with varied level of interpretation, particularly in cases where the
identification of disease only by images is difficult for human eyes. With
recent achievements of deep learning in image classification, its application
in disease diagnosis has been widely explored. This research project presents a
multi-label disease diagnosis model of chest x-rays. Using Dense Convolutional
Neural Network (DenseNet), the diagnosis system was able to obtain high
classification predictions. The model obtained the highest AUC score of 0.896
for condition Cardiomegaly and the lowest AUC score for Nodule, 0.655. The
model also localized the parts of the chest radiograph that indicated the
presence of each pathology using GRADCAM, thus contributing to the model
interpretability of a deep learning algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fair SA: Sensitivity Analysis for Fairness in Face Recognition. (arXiv:2202.03586v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03586">
<div class="article-summary-box-inner">
<span><p>As the use of deep learning in high impact domains becomes ubiquitous, it is
increasingly important to assess the resilience of models. One such high impact
domain is that of face recognition, with real world applications involving
images affected by various degradations, such as motion blur or high exposure.
Moreover, images captured across different attributes, such as gender and race,
can also challenge the robustness of a face recognition algorithm. While
traditional summary statistics suggest that the aggregate performance of face
recognition models has continued to improve, these metrics do not directly
measure the robustness or fairness of the models. Visual Psychophysics
Sensitivity Analysis (VPSA) [1] provides a way to pinpoint the individual
causes of failure by way of introducing incremental perturbations in the data.
However, perturbations may affect subgroups differently. In this paper, we
propose a new fairness evaluation based on robustness in the form of a generic
framework that extends VPSA. With this framework, we can analyze the ability of
a model to perform fairly for different subgroups of a population affected by
perturbations, and pinpoint the exact failure modes for a subgroup by measuring
targeted robustness. With the increasing focus on the fairness of models, we
use face recognition as an example application of our framework and propose to
compactly visualize the fairness analysis of a model via AUC matrices. We
analyze the performance of common face recognition models and empirically show
that certain subgroups are at a disadvantage when images are perturbed, thereby
uncovering trends that were not visible using the model's performance on
subgroups without perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model and predict age and sex in healthy subjects using brain white matter features: A deep learning approach. (arXiv:2202.03595v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03595">
<div class="article-summary-box-inner">
<span><p>The human brain's white matter (WM) structure is of immense interest to the
scientific community. Diffusion MRI gives a powerful tool to describe the brain
WM structure noninvasively. To potentially enable monitoring of age-related
changes and investigation of sex-related brain structure differences on the
mapping between the brain connectome and healthy subjects' age and sex, we
extract fiber-cluster-based diffusion features and predict sex and age with a
novel ensembled neural network classifier. We conduct experiments on the Human
Connectome Project (HCP) young adult dataset and show that our model achieves
94.82% accuracy in sex prediction and 2.51 years MAE in age prediction. We also
show that the fractional anisotropy (FA) is the most predictive of sex, while
the number of fibers is the most predictive of age and the combination of
different features can improve the model performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MOST-Net: A Memory Oriented Style Transfer Network for Face Sketch Synthesis. (arXiv:2202.03596v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03596">
<div class="article-summary-box-inner">
<span><p>Face sketch synthesis has been widely used in multi-media entertainment and
law enforcement. Despite the recent developments in deep neural networks,
accurate and realistic face sketch synthesis is still a challenging task due to
the diversity and complexity of human faces. Current image-to-image
translation-based face sketch synthesis frequently encounters over-fitting
problems when it comes to small-scale datasets. To tackle this problem, we
present an end-to-end Memory Oriented Style Transfer Network (MOST-Net) for
face sketch synthesis which can produce high-fidelity sketches with limited
data. Specifically, an external self-supervised dynamic memory module is
introduced to capture the domain alignment knowledge in the long term. In this
way, our proposed model could obtain the domain-transfer ability by
establishing the durable relationship between faces and corresponding sketches
on the feature level. Furthermore, we design a novel Memory Refinement Loss (MR
Loss) for feature alignment in the memory module, which enhances the accuracy
of memory slots in an unsupervised manner. Extensive experiments on the CUFS
and the CUFSF datasets show that our MOST-Net achieves state-of-the-art
performance, especially in terms of the Structural Similarity Index(SSIM).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Scene BERT: Improving object detection by searching for challenging groups of data. (arXiv:2202.03651v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03651">
<div class="article-summary-box-inner">
<span><p>Modern computer vision applications rely on learning-based perception modules
parameterized with neural networks for tasks like object detection. These
modules frequently have low expected error overall but high error on atypical
groups of data due to biases inherent in the training process. In building
autonomous vehicles (AV), this problem is an especially important challenge
because their perception modules are crucial to the overall system performance.
After identifying failures in AV, a human team will comb through the associated
data to group perception failures that share common causes. More data from
these groups is then collected and annotated before retraining the model to fix
the issue. In other words, error groups are found and addressed in hindsight.
Our main contribution is a pseudo-automatic method to discover such groups in
foresight by performing causal interventions on simulated scenes. To keep our
interventions on the data manifold, we utilize masked language models. We
verify that the prioritized groups found via intervention are challenging for
the object detector and show that retraining with data collected from these
groups helps inordinately compared to adding more IID data. We also plan to
release software to run interventions in simulated scenes, which we hope will
benefit the causality community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Understand Masked Autoencoders. (arXiv:2202.03670v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03670">
<div class="article-summary-box-inner">
<span><p>"Masked Autoencoders (MAE) Are Scalable Vision Learners" revolutionizes the
self-supervised learning that not only achieves the state-of-the-art for image
pretraining, but also is a milestone that bridged the gap between the visual
and linguistic masked autoencoding (BERT-style) pretrainings. However, to our
knowledge, to date there are no theoretical perspectives to explain the
powerful expressivity of MAE. In this paper, we, for the first time, propose a
unified theoretical framework that provides a mathematical understanding for
MAE. Particularly, we explain the patch-based attention approaches of MAE using
an integral kernel under a non-overlapping domain decomposition setting. To
help the researchers to further grasp the main reasons of the great success of
MAE, based on our framework, we contribute five questions and answer them by
insights from operator theory with mathematical rigor.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CAD-RADS Scoring using Deep Learning and Task-Specific Centerline Labeling. (arXiv:2202.03671v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03671">
<div class="article-summary-box-inner">
<span><p>With coronary artery disease (CAD) persisting to be one of the leading causes
of death worldwide, interest in supporting physicians with algorithms to speed
up and improve diagnosis is high. In clinical practice, the severeness of CAD
is often assessed with a coronary CT angiography (CCTA) scan and manually
graded with the CAD-Reporting and Data System (CAD-RADS) score. The clinical
questions this score assesses are whether patients have CAD or not (rule-out)
and whether they have severe CAD or not (hold-out). In this work, we reach new
state-of-the-art performance for automatic CAD-RADS scoring. We propose using
severity-based label encoding, test time augmentation (TTA) and model
ensembling for a task-specific deep learning architecture. Furthermore, we
introduce a novel task- and model-specific, heuristic coronary segment
labeling, which subdivides coronary trees into consistent parts across
patients. It is fast, robust, and easy to implement. We were able to raise the
previously reported area under the receiver operating characteristic curve
(AUC) from 0.914 to 0.942 in the rule-out and from 0.921 to 0.950 in the
hold-out task respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trained Model in Supervised Deep Learning is a Conditional Risk Minimizer. (arXiv:2202.03674v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03674">
<div class="article-summary-box-inner">
<span><p>We proved that a trained model in supervised deep learning minimizes the
conditional risk for each input (Theorem 2.1). This property provided insights
into the behavior of trained models and established a connection between
supervised and unsupervised learning in some cases. In addition, when the
labels are intractable but can be written as a conditional risk minimizer, we
proved an equivalent form of the original supervised learning problem with
accessible labels (Theorem 2.2). We demonstrated that many existing works, such
as Noise2Score, Noise2Noise and score function estimation can be explained by
our theorem. Moreover, we derived a property of classification problem with
noisy labels using Theorem 2.1 and validated it using MNIST dataset.
Furthermore, We proposed a method to estimate uncertainty in image
super-resolution based on Theorem 2.2 and validated it using ImageNet dataset.
Our code is available on github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Image Descriptor with Aggregated Semantic Skeleton Representation for Long-term Visual Place Recognition. (arXiv:2202.03677v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03677">
<div class="article-summary-box-inner">
<span><p>In a Simultaneous Localization and Mapping (SLAM) system, a loop-closure can
eliminate accumulated errors, which is accomplished by Visual Place Recognition
(VPR), a task that retrieves the current scene from a set of pre-stored
sequential images through matching specific scene-descriptors. In urban scenes,
the appearance variation caused by seasons and illumination has brought great
challenges to the robustness of scene descriptors. Semantic segmentation images
can not only deliver the shape information of objects but also their categories
and spatial relations that will not be affected by the appearance variation of
the scene. Innovated by the Vector of Locally Aggregated Descriptor (VLAD), in
this paper, we propose a novel image descriptor with aggregated semantic
skeleton representation (SSR), dubbed SSR-VLAD, for the VPR under drastic
appearance-variation of environments. The SSR-VLAD of one image aggregates the
semantic skeleton features of each category and encodes the spatial-temporal
distribution information of the image semantic information. We conduct a series
of experiments on three public datasets of challenging urban scenes. Compared
with four state-of-the-art VPR methods- CoHOG, NetVLAD, LOST-X, and
Region-VLAD, VPR by matching SSR-VLAD outperforms those methods and maintains
competitive real-time performance at the same time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quality Metric Guided Portrait Line Drawing Generation from Unpaired Training Data. (arXiv:2202.03678v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03678">
<div class="article-summary-box-inner">
<span><p>Face portrait line drawing is a unique style of art which is highly abstract
and expressive. However, due to its high semantic constraints, many existing
methods learn to generate portrait drawings using paired training data, which
is costly and time-consuming to obtain. In this paper, we propose a novel
method to automatically transform face photos to portrait drawings using
unpaired training data with two new features; i.e., our method can (1) learn to
generate high quality portrait drawings in multiple styles using a single
network and (2) generate portrait drawings in a "new style" unseen in the
training data. To achieve these benefits, we (1) propose a novel quality metric
for portrait drawings which is learned from human perception, and (2) introduce
a quality loss to guide the network toward generating better looking portrait
drawings. We observe that existing unpaired translation methods such as
CycleGAN tend to embed invisible reconstruction information indiscriminately in
the whole drawings due to significant information imbalance between the photo
and portrait drawing domains, which leads to important facial features missing.
To address this problem, we propose a novel asymmetric cycle mapping that
enforces the reconstruction information to be visible and only embedded in the
selected facial regions. Along with localized discriminators for important
facial regions, our method well preserves all important facial features in the
generated drawings. Generator dissection further explains that our model learns
to incorporate face semantic information during drawing generation. Extensive
experiments including a user study show that our model outperforms
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Inter-Channel Correlation for Diversity-preserved KnowledgeDistillation. (arXiv:2202.03680v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03680">
<div class="article-summary-box-inner">
<span><p>Knowledge Distillation has shown very promising abil-ity in transferring
learned representation from the largermodel (teacher) to the smaller one
(student).Despitemany efforts, prior methods ignore the important role
ofretaining inter-channel correlation of features, leading tothe lack of
capturing intrinsic distribution of the featurespace and sufficient diversity
properties of features in theteacher network.To solve the issue, we propose
thenovel Inter-Channel Correlation for Knowledge Distillation(ICKD), with which
the diversity and homology of the fea-ture space of the student network can
align with that ofthe teacher network. The correlation between these
twochannels is interpreted as diversity if they are irrelevantto each other,
otherwise homology. Then the student isrequired to mimic the correlation within
its own embed-ding space. In addition, we introduce the grid-level
inter-channel correlation, making it capable of dense predictiontasks.
Extensive experiments on two vision tasks, includ-ing ImageNet classification
and Pascal VOC segmentation,demonstrate the superiority of our ICKD, which
consis-tently outperforms many existing methods, advancing thestate-of-the-art
in the fields of Knowledge Distillation. Toour knowledge, we are the first
method based on knowl-edge distillation boosts ResNet18 beyond 72% Top-1
ac-curacy on ImageNet classification. Code is available
at:https://github.com/ADLab-AutoDrive/ICKD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Network Comparison Study of Deep Activation Feature Discriminability with Novel Objects. (arXiv:2202.03695v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03695">
<div class="article-summary-box-inner">
<span><p>Feature extraction has always been a critical component of the computer
vision field. More recently, state-of-the-art computer visions algorithms have
incorporated Deep Neural Networks (DNN) in feature extracting roles, creating
Deep Convolutional Activation Features (DeCAF). The transferability of DNN
knowledge domains has enabled the wide use of pretrained DNN feature extraction
for applications with novel object classes, especially those with limited
training data. This study analyzes the general discriminability of novel object
visual appearances encoded into the DeCAF space of six of the leading visual
recognition DNN architectures. The results of this study characterize the
Mahalanobis distances and cosine similarities between DeCAF object manifolds
across two visual object tracking benchmark data sets. The backgrounds
surrounding each object are also included as an object classes in the manifold
analysis, providing a wider range of novel classes. This study found that
different network architectures led to different network feature focuses that
must to be considered in the network selection process. These results are
generated from the VOT2015 and UAV123 benchmark data sets; however, the
proposed methods can be applied to efficiently compare estimated network
performance characteristics for any labeled visual data set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Paced Imbalance Rectification for Class Incremental Learning. (arXiv:2202.03703v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03703">
<div class="article-summary-box-inner">
<span><p>Exemplar-based class-incremental learning is to recognize new classes while
not forgetting old ones, whose samples can only be saved in limited memory. The
ratio fluctuation of new samples to old exemplars, which is caused by the
variation of memory capacity at different environments, will bring challenges
to stabilize the incremental optimization process. To address this problem, we
propose a novel self-paced imbalance rectification scheme, which dynamically
maintains the incremental balance during the representation learning phase.
Specifically, our proposed scheme consists of a frequency compensation strategy
that adjusts the logits margin between old and new classes with the
corresponding number ratio to strengthen the expression ability of the old
classes, and an inheritance transfer strategy to reduce the representation
confusion by estimating the similarity of different classes in the old
embedding space. Furthermore, a chronological attenuation mechanism is proposed
to mitigate the repetitive optimization of the older classes at multiple
step-wise increments. Extensive experiments on three benchmarks demonstrate
stable incremental performance, significantly outperforming the
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What's Cracking? A Review and Analysis of Deep Learning Methods for Structural Crack Segmentation, Detection and Quantification. (arXiv:2202.03714v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03714">
<div class="article-summary-box-inner">
<span><p>Surface cracks are a very common indicator of potential structural faults.
Their early detection and monitoring is an important factor in structural
health monitoring. Left untreated, they can grow in size over time and require
expensive repairs or maintenance. With recent advances in computer vision and
deep learning algorithms, the automatic detection and segmentation of cracks
for this monitoring process have become a major topic of interest. This review
aims to give researchers an overview of the published work within the field of
crack analysis algorithms that make use of deep learning. It outlines the
various tasks that are solved through applying computer vision algorithms to
surface cracks in a structural health monitoring setting and also provides
in-depth reviews of recent fully, semi and unsupervised approaches that perform
crack classification, detection, segmentation and quantification. Additionally,
this review also highlights popular datasets used for cracks and the metrics
that are used to evaluate the performance of those algorithms. Finally,
potential research gaps are outlined and further research directions are
provided.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Binary Neural Networks as a general-propose compute paradigm for on-device computer vision. (arXiv:2202.03716v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03716">
<div class="article-summary-box-inner">
<span><p>For binary neural networks (BNNs) to become the mainstream on-device computer
vision algorithm, they must achieve a superior speed-vs-accuracy tradeoff than
8-bit quantization and establish a similar degree of general applicability in
vision tasks. To this end, we propose a BNN framework comprising 1) a
minimalistic inference scheme for hardware-friendliness, 2) an
over-parameterized training scheme for high accuracy, and 3) a simple procedure
to adapt to different vision tasks. The resultant framework overtakes 8-bit
quantization in the speed-vs-accuracy tradeoff for classification, detection,
segmentation, super-resolution and matching: our BNNs not only retain the
accuracy levels of their 8-bit baselines but also showcase 1.3-2.4$\times$
faster FPS on mobile CPUs. Similar conclusions can be drawn for prototypical
systolic-array-based AI accelerators, where our BNNs promise 2.8-7$\times$
fewer execution cycles than 8-bit and 2.1-2.7$\times$ fewer cycles than
alternative BNN designs. These results suggest that the time for large-scale
BNN adoption could be upon us.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hair Color Digitization through Imaging and Deep Inverse Graphics. (arXiv:2202.03723v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03723">
<div class="article-summary-box-inner">
<span><p>Hair appearance is a complex phenomenon due to hair geometry and how the
light bounces on different hair fibers. For this reason, reproducing a specific
hair color in a rendering environment is a challenging task that requires
manual work and expert knowledge in computer graphics to tune the result
visually. While current hair capture methods focus on hair shape estimation
many applications could benefit from an automated method for capturing the
appearance of a physical hair sample, from augmented/virtual reality to hair
dying development. Building on recent advances in inverse graphics and material
capture using deep neural networks, we introduce a novel method for hair color
digitization. Our proposed pipeline allows capturing the color appearance of a
physical hair sample and renders synthetic images of hair with a similar
appearance, simulating different hair styles and/or lighting environments.
Since rendering realistic hair images requires path-tracing rendering, the
conventional inverse graphics approach based on differentiable rendering is
untractable. Our method is based on the combination of a controlled imaging
device, a path-tracing renderer, and an inverse graphics model based on
self-supervised machine learning, which does not require to use differentiable
rendering to be trained. We illustrate the performance of our hair digitization
method on both real and synthetic images and show that our approach can
accurately capture and render hair color.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Navigating to Objects in Unseen Environments by Distance Prediction. (arXiv:2202.03735v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03735">
<div class="article-summary-box-inner">
<span><p>Object Goal Navigation (ObjectNav) task is to navigate an agent to an object
instance in unseen environments. The traditional navigation paradigm plans the
shortest path on a pre-built map. Inspired by this, we propose an object goal
navigation framework, which could directly perform path planning based on an
estimated distance map. Specifically, our model takes a birds-eye-view semantic
map as input, and estimates the distance from the map cells to the target
object based on the learned prior knowledge. With the estimated distance map,
the agent could explore the environment and navigate to the target objects
based on either human-designed or learned navigation policy. Empirical results
in visually realistic simulation environments show that the proposed method
outperforms a wide range of baselines on success rate and efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Breast Cancer Screening Techniques: Thermography and Electrical Impedance Tomography. (arXiv:2202.03737v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03737">
<div class="article-summary-box-inner">
<span><p>Breast cancer is a disease that threatens many women's life, thus, early and
accurate detection plays a key role in reducing the mortality rate. Mammography
stands as the reference technique for breast cancer screening; nevertheless,
many countries still lack access to mammograms due to economic, social, and
cultural issues. Last advances in computational tools, infrared cameras, and
devices for bio-impedance quantification allowed the development of parallel
techniques like thermography, infrared imaging, and electrical impedance
tomography, these being faster, reliable and cheaper. In the last decades,
these have been considered as complement procedures for breast cancer
diagnosis, where many studies concluded that false positive and false negative
rates are greatly reduced. This work aims to review the last breakthroughs
about the three above-mentioned techniques describing the benefits of mixing
several computational skills to obtain a better global performance. In
addition, we provide a comparison between several machine learning techniques
applied to breast cancer diagnosis going from logistic regression, decision
trees, and random forest to artificial, deep, and convolutional neural
networks. Finally, it is mentioned several recommendations for 3D breast
simulations, pre-processing techniques, biomedical devices in the research
field, prediction of tumor location and size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistency-Regularized Region-Growing Network for Semantic Segmentation of Urban Scenes with Point-Level Annotations. (arXiv:2202.03740v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03740">
<div class="article-summary-box-inner">
<span><p>Deep learning algorithms have obtained great success in semantic segmentation
of very high-resolution (VHR) images. Nevertheless, training these models
generally requires a large amount of accurate pixel-wise annotations, which is
very laborious and time-consuming to collect. To reduce the annotation burden,
this paper proposes a consistency-regularized region-growing network (CRGNet)
to achieve semantic segmentation of VHR images with point-level annotations.
The key idea of CRGNet is to iteratively select unlabeled pixels with high
confidence to expand the annotated area from the original sparse points.
However, since there may exist some errors and noises in the expanded
annotations, directly learning from them may mislead the training of the
network. To this end, we further propose the consistency regularization
strategy, where a base classifier and an expanded classifier are employed.
Specifically, the base classifier is supervised by the original sparse
annotations, while the expanded classifier aims to learn from the expanded
annotations generated by the base classifier with the region-growing mechanism.
The consistency regularization is thereby achieved by minimizing the
discrepancy between the predictions from both the base and the expanded
classifiers. We find such a simple regularization strategy is yet very useful
to control the quality of the region-growing mechanism. Extensive experiments
on two benchmark datasets demonstrate that the proposed CRGNet significantly
outperforms the existing state-of-the-art methods. Codes and pre-trained models
will be available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">STC: Spatio-Temporal Contrastive Learning for Video Instance Segmentation. (arXiv:2202.03747v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03747">
<div class="article-summary-box-inner">
<span><p>Video Instance Segmentation (VIS) is a task that simultaneously requires
classification, segmentation, and instance association in a video. Recent VIS
approaches rely on sophisticated pipelines to achieve this goal, including
RoI-related operations or 3D convolutions. In contrast, we present a simple and
efficient single-stage VIS framework based on the instance segmentation method
CondInst by adding an extra tracking head. To improve instance association
accuracy, a novel bi-directional spatio-temporal contrastive learning strategy
for tracking embedding across frames is proposed. Moreover, an instance-wise
temporal consistency scheme is utilized to produce temporally coherent results.
Experiments conducted on the YouTube-VIS-2019, YouTube-VIS-2021, and OVIS-2021
datasets validate the effectiveness and efficiency of the proposed method. We
hope the proposed framework can serve as a simple and strong alternative for
many other instance-level video association tasks. Code will be made available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Addressing Data Scarcity in Multimodal User State Recognition by Combining Semi-Supervised and Supervised Learning. (arXiv:2202.03775v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03775">
<div class="article-summary-box-inner">
<span><p>Detecting mental states of human users is crucial for the development of
cooperative and intelligent robots, as it enables the robot to understand the
user's intentions and desires. Despite their importance, it is difficult to
obtain a large amount of high quality data for training automatic recognition
algorithms as the time and effort required to collect and label such data is
prohibitively high. In this paper we present a multimodal machine learning
approach for detecting dis-/agreement and confusion states in a human-robot
interaction environment, using just a small amount of manually annotated data.
We collect a data set by conducting a human-robot interaction study and develop
a novel preprocessing pipeline for our machine learning approach. By combining
semi-supervised and supervised architectures, we are able to achieve an average
F1-score of 81.1\% for dis-/agreement detection with a small amount of labeled
data and a large unlabeled data set, while simultaneously increasing the
robustness of the model compared to the supervised approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SCR: Smooth Contour Regression with Geometric Priors. (arXiv:2202.03784v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03784">
<div class="article-summary-box-inner">
<span><p>While object detection methods traditionally make use of pixel-level masks or
bounding boxes, alternative representations such as polygons or active contours
have recently emerged. Among them, methods based on the regression of Fourier
or Chebyshev coefficients have shown high potential on freeform objects. By
defining object shapes as polar functions, they are however limited to
star-shaped domains. We address this issue with SCR: a method that captures
resolution-free object contours as complex periodic functions. The method
offers a good compromise between accuracy and compactness thanks to the design
of efficient geometric shape priors. We benchmark SCR on the popular COCO 2017
instance segmentation dataset, and show its competitiveness against existing
algorithms in the field. In addition, we design a compact version of our
network, which we benchmark on embedded hardware with a wide range of power
targets, achieving up to real-time performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the Structure Space. (arXiv:2202.03800v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03800">
<div class="article-summary-box-inner">
<span><p>Face clustering has attracted rising research interest recently to take
advantage of massive amounts of face images on the web. State-of-the-art
performance has been achieved by Graph Convolutional Networks (GCN) due to
their powerful representation capacity. However, existing GCN-based methods
build face graphs mainly according to kNN relations in the feature space, which
may lead to a lot of noise edges connecting two faces of different classes. The
face features will be polluted when messages pass along these noise edges, thus
degrading the performance of GCNs. In this paper, a novel algorithm named
Ada-NETS is proposed to cluster faces by constructing clean graphs for GCNs. In
Ada-NETS, each face is transformed to a new structure space, obtaining robust
features by considering face features of the neighbour images. Then, an
adaptive neighbour discovery strategy is proposed to determine a proper number
of edges connecting to each face image. It significantly reduces the noise
edges while maintaining the good ones to build a graph with clean yet rich
edges for GCNs to cluster faces. Experiments on multiple public clustering
datasets show that Ada-NETS significantly outperforms current state-of-the-art
methods, proving its superiority and generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Plug-in Module for Fine-Grained Visual Classification. (arXiv:2202.03822v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03822">
<div class="article-summary-box-inner">
<span><p>Visual classification can be divided into coarse-grained and fine-grained
classification. Coarse-grained classification represents categories with a
large degree of dissimilarity, such as the classification of cats and dogs,
while fine-grained classification represents classifications with a large
degree of similarity, such as cat species, bird species, and the makes or
models of vehicles. Unlike coarse-grained visual classification, fine-grained
visual classification often requires professional experts to label data, which
makes data more expensive. To meet this challenge, many approaches propose to
automatically find the most discriminative regions and use local features to
provide more precise features. These approaches only require image-level
annotations, thereby reducing the cost of annotation. However, most of these
methods require two- or multi-stage architectures and cannot be trained
end-to-end. Therefore, we propose a novel plug-in module that can be integrated
to many common backbones, including CNN-based or Transformer-based networks to
provide strongly discriminative regions. The plugin module can output
pixel-level feature maps and fuse filtered features to enhance fine-grained
visual classification. Experimental results show that the proposed plugin
module outperforms state-of-the-art approaches and significantly improves the
accuracy to 92.77\% and 92.83\% on CUB200-2011 and NABirds, respectively. We
have released our source code in Github
https://github.com/chou141253/FGVC-PIM.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Pitfalls of Using the Residual Error as Anomaly Score. (arXiv:2202.03826v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03826">
<div class="article-summary-box-inner">
<span><p>Many current state-of-the-art methods for anomaly localization in medical
images rely on calculating a residual image between a potentially anomalous
input image and its "healthy" reconstruction. As the reconstruction of the
unseen anomalous region should be erroneous, this yields large residuals as a
score to detect anomalies in medical images. However, this assumption does not
take into account residuals resulting from imperfect reconstructions of the
machine learning models used. Such errors can easily overshadow residuals of
interest and therefore strongly question the use of residual images as scoring
function. Our work explores this fundamental problem of residual images in
detail. We theoretically define the problem and thoroughly evaluate the
influence of intensity and texture of anomalies against the effect of imperfect
reconstructions in a series of experiments. Code and experiments are available
under https://github.com/FeliMe/residual-score-pitfalls
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Multi-Task Learning Framework of Real-Time Drone Supervision for Crowd Counting. (arXiv:2202.03843v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03843">
<div class="article-summary-box-inner">
<span><p>In this paper, a novel Unified Multi-Task Learning Framework of Real-Time
Drone Supervision for Crowd Counting (MFCC) is proposed, which utilizes an
image fusion network architecture to fuse images from the visible and thermal
infrared image, and a crowd counting network architecture to estimate the
density map. The purpose of our framework is to fuse two modalities, including
visible and thermal infrared images captured by drones in real-time, that
exploit the complementary information to accurately count the dense population
and then automatically guide the flight of the drone to supervise the dense
crowd. To this end, we propose the unified multi-task learning framework for
crowd counting for the first time and re-design the unified training loss
functions to align the image fusion network and crowd counting network. We also
design the Assisted Learning Module (ALM) to fuse the density map feature to
the image fusion encoder process for learning the counting features. To improve
the accuracy, we propose the Extensive Context Extraction Module (ECEM) that is
based on a dense connection architecture to encode multi-receptive-fields
contextual information and apply the Multi-domain Attention Block (MAB) for
concerning the head region in the drone view. Finally, we apply the prediction
map to automatically guide the drones to supervise the dense crowd. The
experimental results on the DroneRGBT dataset show that, compared with the
existing methods, ours has comparable results on objective evaluations and an
easier training process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Class Density and Dataset Quality in High-Dimensional, Unstructured Data. (arXiv:2202.03856v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03856">
<div class="article-summary-box-inner">
<span><p>We provide a definition for class density that can be used to measure the
aggregate similarity of the samples within each of the classes in a
high-dimensional, unstructured dataset. We then put forth several candidate
methods for calculating class density and analyze the correlation between the
values each method produces with the corresponding individual class test
accuracies achieved on a trained model. Additionally, we propose a definition
for dataset quality for high-dimensional, unstructured data and show that those
datasets that met a certain quality threshold (experimentally demonstrated to
be &gt; 10 for the datasets studied) were candidates for eliding redundant data
based on the individual class densities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Optical Flow with Adaptive Graph Reasoning. (arXiv:2202.03857v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03857">
<div class="article-summary-box-inner">
<span><p>Estimating per-pixel motion between video frames, known as optical flow, is a
long-standing problem in video understanding and analysis. Most contemporary
optical flow techniques largely focus on addressing the cross-image matching
with feature similarity, with few methods considering how to explicitly reason
over the given scene for achieving a holistic motion understanding. In this
work, taking a fresh perspective, we introduce a novel graph-based approach,
called adaptive graph reasoning for optical flow (AGFlow), to emphasize the
value of scene/context information in optical flow. Our key idea is to decouple
the context reasoning from the matching procedure, and exploit scene
information to effectively assist motion estimation by learning to reason over
the adaptive graph. The proposed AGFlow can effectively exploit the context
information and incorporate it within the matching procedure, producing more
robust and accurate results. On both Sintel clean and final passes, our AGFlow
achieves the best accuracy with EPE of 1.43 and 2.47 pixels, outperforming
state-of-the-art approaches by 11.2% and 13.6%, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mapping DNN Embedding Manifolds for Network Generalization Prediction. (arXiv:2202.03868v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03868">
<div class="article-summary-box-inner">
<span><p>Understanding Deep Neural Network (DNN) performance in changing conditions is
essential for deploying DNNs in safety critical applications with unconstrained
environments, e.g., perception for self-driving vehicles or medical image
analysis. Recently, the task of Network Generalization Prediction (NGP) has
been proposed to predict how a DNN will generalize in a new operating domain.
Previous NGP approaches have relied on labeled metadata and known distributions
for the new operating domains. In this study, we propose the first NGP approach
that predicts DNN performance based solely on how unlabeled images from an
external operating domain map in the DNN embedding space. We demonstrate this
technique for pedestrian, melanoma, and animal classification tasks and show
state of the art NGP in 13 of 15 NGP tasks without requiring domain knowledge.
Additionally, we show that our NGP embedding maps can be used to identify
misclassified images when the DNN performance is poor.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BIQ2021: A Large-Scale Blind Image Quality Assessment Database. (arXiv:2202.03879v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03879">
<div class="article-summary-box-inner">
<span><p>The assessment of the perceptual quality of digital images is becoming
increasingly important as a result of the widespread use of digital multimedia
devices. Smartphones and high-speed internet are just two examples of
technologies that have multiplied the amount of multimedia content available.
Thus, obtaining a representative dataset, which is required for objective
quality assessment training, is a significant challenge. The Blind Image
Quality Assessment Database, BIQ2021, is presented in this article. By
selecting images with naturally occurring distortions and reliable labeling,
the dataset addresses the challenge of obtaining representative images for
no-reference image quality assessment. The dataset consists of three sets of
images: those taken without the intention of using them for image quality
assessment, those taken with intentionally introduced natural distortions, and
those taken from an open-source image-sharing platform. It is attempted to
maintain a diverse collection of images from various devices, containing a
variety of different types of objects and varying degrees of foreground and
background information. To obtain reliable scores, these images are
subjectively scored in a laboratory environment using a single stimulus method.
The database contains information about subjective scoring, human subject
statistics, and the standard deviation of each image. The dataset's Mean
Opinion Scores (MOS) make it useful for assessing visual quality. Additionally,
the proposed database is used to evaluate existing blind image quality
assessment approaches, and the scores are analyzed using Pearson and Spearman's
correlation coefficients. The image database and MOS are freely available for
use and benchmarking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLPU: A Geometric Approach For Lidar Pointcloud Upsampling. (arXiv:2202.03901v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03901">
<div class="article-summary-box-inner">
<span><p>In autonomous driving, lidar is inherent for the understanding of the 3D
environment. Lidar sensors vary in vertical resolutions, where a denser
pointcloud depicts a more detailed environment, albeit at a significantly
higher cost. Pointcloud upsampling predicts high-resolution pointclouds from
sparser ones to bridge this performance gap at a lower cost. Although many
upsampling frameworks have achieved a robust performance, a fair comparison is
difficult as they were tested on different datasets and metrics. In this work,
we first conduct a consistent comparative study to benchmark the existing
algorithms on the KITTI dataset. Then, we observe that there are three common
factors that hinder the performance: an inefficient data representation, a
small receptive field, and low-frequency losses. By leveraging the scene
geometry, a new self-supervised geometric lidar pointcloud upsampling (GLPU)
framework is proposed to address the aforementioned limitations. Our
experiments demonstrate the effectiveness and superior performance of GLPU
compared to other techniques on the KITTI benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Edge-based fever screening system over private 5G. (arXiv:2202.03917v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03917">
<div class="article-summary-box-inner">
<span><p>Edge computing and 5G have made it possible to perform analytics closer to
the source of data and achieve super-low latency response times, which is not
possible with centralized cloud deployment. In this paper, we present a novel
fever-screening system, which uses edge machine learning techniques and
leverages private 5G to accurately identify and screen individuals with fever
in real-time. Particularly, we present deep-learning based novel techniques for
fusion and alignment of cross-spectral visual and thermal data streams at the
edge. Our novel Cross-Spectral Generative Adversarial Network (CS-GAN)
synthesizes visual images that have the key, representative object level
features required to uniquely associate objects across visual and thermal
spectrum. Two key features of CS-GAN are a novel, feature-preserving loss
function that results in high-quality pairing of corresponding cross-spectral
objects, and dual bottleneck residual layers with skip connections (a new,
network enhancement) to not only accelerate real-time inference, but to also
speed up convergence during model training at the edge. To the best of our
knowledge, this is the first technique that leverages 5G networks and limited
edge resources to enable real-time feature-level association of objects in
visual and thermal streams (30 ms per full HD frame on an Intel Core i7-8650
4-core, 1.9GHz mobile processor). To the best of our knowledge, this is also
the first system to achieve real-time operation, which has enabled fever
screening of employees and guests in arenas, theme parks, airports and other
critical facilities. By leveraging edge computing and 5G, our fever screening
system is able to achieve 98.5% accuracy and is able to process about 5X more
people when compared to a centralized cloud deployment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">If a Human Can See It, So Should Your System: Reliability Requirements for Machine Vision Components. (arXiv:2202.03930v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03930">
<div class="article-summary-box-inner">
<span><p>Machine Vision Components (MVC) are becoming safety-critical. Assuring their
quality, including safety, is essential for their successful deployment.
Assurance relies on the availability of precisely specified and, ideally,
machine-verifiable requirements. MVCs with state-of-the-art performance rely on
machine learning (ML) and training data but largely lack such requirements.
</p>
<p>In this paper, we address the need for defining machine-verifiable
reliability requirements for MVCs against transformations that simulate the
full range of realistic and safety-critical changes in the environment. Using
human performance as a baseline, we define reliability requirements as: 'if the
changes in an image do not affect a human's decision, neither should they
affect the MVC's.' To this end, we provide: (1) a class of safety-related image
transformations; (2) reliability requirement classes to specify
correctness-preservation and prediction-preservation for MVCs; (3) a method to
instantiate machine-verifiable requirements from these requirements classes
using human performance experiment data; (4) human performance experiment data
for image recognition involving eight commonly used transformations, from about
2000 human participants; and (5) a method for automatically checking whether an
MVC satisfies our requirements. Further, we show that our reliability
requirements are feasible and reusable by evaluating our methods on 13
state-of-the-art pre-trained image classification models. Finally, we
demonstrate that our approach detects reliability gaps in MVCs that other
existing methods are unable to detect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Social-DualCVAE: Multimodal Trajectory Forecasting Based on Social Interactions Pattern Aware and Dual Conditional Variational Auto-Encoder. (arXiv:2202.03954v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03954">
<div class="article-summary-box-inner">
<span><p>Pedestrian trajectory forecasting is a fundamental task in multiple utility
areas, such as self-driving, autonomous robots, and surveillance systems. The
future trajectory forecasting is multi-modal, influenced by physical
interaction with scene contexts and intricate social interactions among
pedestrians. The mainly existing literature learns representations of social
interactions by deep learning networks, while the explicit interaction patterns
are not utilized. Different interaction patterns, such as following or
collision avoiding, will generate different trends of next movement, thus, the
awareness of social interaction patterns is important for trajectory
forecasting. Moreover, the social interaction patterns are privacy concerned or
lack of labels. To jointly address the above issues, we present a social-dual
conditional variational auto-encoder (Social-DualCVAE) for multi-modal
trajectory forecasting, which is based on a generative model conditioned not
only on the past trajectories but also the unsupervised classification of
interaction patterns. After generating the category distribution of the
unlabeled social interaction patterns, DualCVAE, conditioned on the past
trajectories and social interaction pattern, is proposed for multi-modal
trajectory prediction by latent variables estimating. A variational bound is
derived as the minimization objective during training. The proposed model is
evaluated on widely used trajectory benchmarks and outperforms the prior
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bingham Policy Parameterization for 3D Rotations in Reinforcement Learning. (arXiv:2202.03957v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03957">
<div class="article-summary-box-inner">
<span><p>We propose a new policy parameterization for representing 3D rotations during
reinforcement learning. Today in the continuous control reinforcement learning
literature, many stochastic policy parameterizations are Gaussian. We argue
that universally applying a Gaussian policy parameterization is not always
desirable for all environments. One such case in particular where this is true
are tasks that involve predicting a 3D rotation output, either in isolation, or
coupled with translation as part of a full 6D pose output. Our proposed Bingham
Policy Parameterization (BPP) models the Bingham distribution and allows for
better rotation (quaternion) prediction over a Gaussian policy parameterization
in a range of reinforcement learning tasks. We evaluate BPP on the rotation
Wahba problem task, as well as a set of vision-based next-best pose robot
manipulation tasks from RLBench. We hope that this paper encourages more
research into developing other policy parameterization that are more suited for
particular environments, rather than always assuming Gaussian.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty Modeling for Out-of-Distribution Generalization. (arXiv:2202.03958v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03958">
<div class="article-summary-box-inner">
<span><p>Though remarkable progress has been achieved in various vision tasks, deep
neural networks still suffer obvious performance degradation when tested in
out-of-distribution scenarios. We argue that the feature statistics (mean and
standard deviation), which carry the domain characteristics of the training
data, can be properly manipulated to improve the generalization ability of deep
learning models. Common methods often consider the feature statistics as
deterministic values measured from the learned features and do not explicitly
consider the uncertain statistics discrepancy caused by potential domain shifts
during testing. In this paper, we improve the network generalization ability by
modeling the uncertainty of domain shifts with synthesized feature statistics
during training. Specifically, we hypothesize that the feature statistic, after
considering the potential uncertainties, follows a multivariate Gaussian
distribution. Hence, each feature statistic is no longer a deterministic value,
but a probabilistic point with diverse distribution possibilities. With the
uncertain feature statistics, the models can be trained to alleviate the domain
perturbations and achieve better robustness against potential domain shifts.
Our method can be readily integrated into networks without additional
parameters. Extensive experiments demonstrate that our proposed method
consistently improves the network generalization ability on multiple vision
tasks, including image classification, semantic segmentation, and instance
retrieval. The code will be released soon at
https://github.com/lixiaotong97/DSU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Contrastive Learning for Cross-domain Hyperspectral Image Representation. (arXiv:2202.03968v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03968">
<div class="article-summary-box-inner">
<span><p>Recently, self-supervised learning has attracted attention due to its
remarkable ability to acquire meaningful representations for classification
tasks without using semantic labels. This paper introduces a self-supervised
learning framework suitable for hyperspectral images that are inherently
challenging to annotate. The proposed framework architecture leverages
cross-domain CNN, allowing for learning representations from different
hyperspectral images with varying spectral characteristics and no pixel-level
annotation. In the framework, cross-domain representations are learned via
contrastive learning where neighboring spectral vectors in the same image are
clustered together in a common representation space encompassing multiple
hyperspectral images. In contrast, spectral vectors in different hyperspectral
images are separated into distinct clusters in the space. To verify that the
learned representation through contrastive learning is effectively transferred
into a downstream task, we perform a classification task on hyperspectral
images. The experimental results demonstrate the advantage of the proposed
self-supervised representation over models trained from scratch or other
transfer learning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation by Test-Time Optimization (TTO) for CBCT-based Adaptive Radiation Therapy. (arXiv:2202.03978v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03978">
<div class="article-summary-box-inner">
<span><p>Online adaptive radiotherapy (ART) requires accurate and efficient
auto-segmentation of target volumes and organs-at-risk (OARs) in mostly
cone-beam computed tomography (CBCT) images. Propagating expert-drawn contours
from the pre-treatment planning CT (pCT) through traditional or deep learning
(DL) based deformable image registration (DIR) can achieve improved results in
many situations. Typical DL-based DIR models are population based, that is,
trained with a dataset for a population of patients, so they may be affected by
the generalizability problem. In this paper, we propose a method called
test-time optimization (TTO) to refine a pre-trained DL-based DIR population
model, first for each individual test patient, and then progressively for each
fraction of online ART treatment. Our proposed method is less susceptible to
the generalizability problem, and thus can improve overall performance of
different DL-based DIR models by improving model accuracy, especially for
outliers. Our experiments used data from 239 patients with head and neck
squamous cell carcinoma to test the proposed method. Firstly, we trained a
population model with 200 patients, and then applied TTO to the remaining 39
test patients by refining the trained population model to obtain 39
individualized models. We compared each of the individualized models with the
population model in terms of segmentation accuracy. The number of patients with
at least 0.05 DSC improvement or 2 mm HD95 improvement by TTO averaged over the
17 selected structures for the state-of-the-art architecture Voxelmorph is 10
out of 39 test patients. The average time for deriving the individualized model
using TTO from the pre-trained population model is approximately four minutes.
When adapting the individualized model to a later fraction of the same patient,
the average time is reduced to about one minute and the accuracy is slightly
improved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Equivariance versus Augmentation for Spherical Images. (arXiv:2202.03990v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03990">
<div class="article-summary-box-inner">
<span><p>We analyze the role of rotational equivariance in convolutional neural
networks (CNNs) applied to spherical images. We compare the performance of the
group equivariant networks known as S2CNNs and standard non-equivariant CNNs
trained with an increasing amount of data augmentation. The chosen
architectures can be considered baseline references for the respective design
paradigms. Our models are trained and evaluated on single or multiple items
from the MNIST or FashionMNIST dataset projected onto the sphere. For the task
of image classification, which is inherently rotationally invariant, we find
that by considerably increasing the amount of data augmentation and the size of
the networks, it is possible for the standard CNNs to reach at least the same
performance as the equivariant network. In contrast, for the inherently
equivariant task of semantic segmentation, the non-equivariant networks are
consistently outperformed by the equivariant networks with significantly fewer
parameters. We also analyze and compare the inference latency and training
times of the different networks, enabling detailed tradeoff considerations
between equivariant architectures and data augmentation for practical problems.
The equivariant spherical networks used in the experiments will be made
available at https://github.com/JanEGerken/sem_seg_s2cnn .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Results and findings of the 2021 Image Similarity Challenge. (arXiv:2202.04007v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04007">
<div class="article-summary-box-inner">
<span><p>The 2021 Image Similarity Challenge introduced a dataset to serve as a new
benchmark to evaluate recent image copy detection methods. There were 200
participants to the competition. This paper presents a quantitative and
qualitative analysis of the top submissions. It appears that the most difficult
image transformations involve either severe image crops or hiding into
unrelated images, combined with local pixel perturbations. The key algorithmic
elements in the winning submissions are: training on strong augmentations,
self-supervised learning, score normalization, explicit overlay detection, and
global descriptor matching followed by pairwise image comparison.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NEWSKVQA: Knowledge-Aware News Video Question Answering. (arXiv:2202.04015v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04015">
<div class="article-summary-box-inner">
<span><p>Answering questions in the context of videos can be helpful in video
indexing, video retrieval systems, video summarization, learning management
systems and surveillance video analysis. Although there exists a large body of
work on visual question answering, work on video question answering (1) is
limited to domains like movies, TV shows, gameplay, or human activity, and (2)
is mostly based on common sense reasoning. In this paper, we explore a new
frontier in video question answering: answering knowledge-based questions in
the context of news videos. To this end, we curate a new dataset of 12K news
videos spanning across 156 hours with 1M multiple-choice question-answer pairs
covering 8263 unique entities. We make the dataset publicly available. Using
this dataset, we propose a novel approach, NEWSKVQA (Knowledge-Aware News Video
Question Answering) which performs multi-modal inferencing over textual
multiple-choice questions, videos, their transcripts and knowledge base, and
presents a strong baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Contrastive Learning for Volcanic Unrest Detection. (arXiv:2202.04030v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04030">
<div class="article-summary-box-inner">
<span><p>Ground deformation measured from Interferometric Synthetic Aperture Radar
(InSAR) data is considered a sign of volcanic unrest, statistically linked to a
volcanic eruption. Recent studies have shown the potential of using Sentinel-1
InSAR data and supervised deep learning (DL) methods for the detection of
volcanic deformation signals, towards global volcanic hazard mitigation.
However, detection accuracy is compromised from the lack of labelled data and
class imbalance. To overcome this, synthetic data are typically used for
finetuning DL models pre-trained on the ImageNet dataset. This approach suffers
from poor generalisation on real InSAR data. This letter proposes the use of
self-supervised contrastive learning to learn quality visual representations
hidden in unlabeled InSAR data. Our approach, based on the SimCLR framework,
provides a solution that does not require a specialized architecture nor a
large labelled or synthetic dataset. We show that our self-supervised pipeline
achieves higher accuracy with respect to the state-of-the-art methods, and
shows excellent generalisation even for out-of-distribution test data. Finally,
we showcase the effectiveness of our approach for detecting the unrest episodes
preceding the recent Icelandic Fagradalsfjall volcanic eruption.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Residual Aligned: Gradient Optimization for Non-Negative Image Synthesis. (arXiv:2202.04036v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04036">
<div class="article-summary-box-inner">
<span><p>In this work, we address an important problem of optical see through (OST)
augmented reality: non-negative image synthesis. Most of the image generation
methods fail under this condition, since they assume full control over each
pixel and cannot create darker pixels by adding light. In order to solve the
non-negative image generation problem in AR image synthesis, prior works have
attempted to utilize optical illusion to simulate human vision but fail to
preserve lightness constancy well under situations such as high dynamic range.
In our paper, we instead propose a method that is able to preserve lightness
constancy at a local level, thus capturing high frequency details. Compared
with existing work, our method shows strong performance in image-to-image
translation tasks, particularly in scenarios such as large scale images, high
resolution images, and high dynamic range image transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Conditioned Generative Adversarial Networks for Image Editing. (arXiv:2202.04040v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04040">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GANs) are susceptible to bias, learned from
either the unbalanced data, or through mode collapse. The networks focus on the
core of the data distribution, leaving the tails - or the edges of the
distribution - behind. We argue that this bias is responsible not only for
fairness concerns, but that it plays a key role in the collapse of
latent-traversal editing methods when deviating away from the distribution's
core. Building on this observation, we outline a method for mitigating
generative bias through a self-conditioning process, where distances in the
latent-space of a pre-trained generator are used to provide initial labels for
the data. By fine-tuning the generator on a re-sampled distribution drawn from
these self-labeled data, we force the generator to better contend with rare
semantic attributes and enable more realistic generation of these properties.
We compare our models to a wide range of latent editing methods, and show that
by alleviating the bias they achieve finer semantic control and better identity
preservation through a wider range of transformations. Our code and models will
be available at https://github.com/yzliu567/sc-gan
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decision boundaries and convex hulls in the feature space that deep learning functions learn from images. (arXiv:2202.04052v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04052">
<div class="article-summary-box-inner">
<span><p>The success of deep neural networks in image classification and learning can
be partly attributed to the features they extract from images. It is often
speculated about the properties of a low-dimensional manifold that models
extract and learn from images. However, there is not sufficient understanding
about this low-dimensional space based on theory or empirical evidence. For
image classification models, their last hidden layer is the one where images of
each class is separated from other classes and it also has the least number of
features. Here, we develop methods and formulations to study that feature space
for any model. We study the partitioning of the domain in feature space,
identify regions guaranteed to have certain classifications, and investigate
its implications for the pixel space. We observe that geometric arrangements of
decision boundaries in feature space is significantly different compared to
pixel space, providing insights about adversarial vulnerabilities, image
morphing, extrapolation, ambiguity in classification, and the mathematical
understanding of image classification models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generative Transformers. (arXiv:2202.04053v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04053">
<div class="article-summary-box-inner">
<span><p>Generating images from textual descriptions has gained a lot of attention.
Recently, DALL-E, a multimodal transformer language model, and its variants
have shown high-quality text-to-image generation capabilities with a simple
architecture and training objective, powered by large-scale training data and
computation. However, despite the interesting image generation results, there
has not been a detailed analysis on how to evaluate such models. In this work,
we investigate the reasoning capabilities and social biases of such
text-to-image generative transformers in detail. First, we measure four visual
reasoning skills: object recognition, object counting, color recognition, and
spatial relation understanding. For this, we propose PaintSkills, a diagnostic
dataset and evaluation toolkit that measures these four visual reasoning
skills. Second, we measure the text alignment and quality of the generated
images based on pretrained image captioning, image-text retrieval, and image
classification models. Third, we assess social biases in the models. For this,
we suggest evaluation of gender and racial biases of text-to-image generation
models based on a pretrained image-text retrieval model and human evaluation.
In our experiments, we show that recent text-to-image models perform better in
recognizing and counting objects than recognizing colors and understanding
spatial relations, while there exists a large gap between model performances
and oracle accuracy on all skills. Next, we demonstrate that recent
text-to-image models learn specific gender/racial biases from web image-text
pairs. We also show that our automatic evaluations of visual reasoning skills
and gender bias are highly correlated with human judgments. We hope our work
will help guide future progress in improving text-to-image models on visual
reasoning skills and social biases. Code and data at:
https://github.com/j-min/DallEval
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flexibly Regularized Mixture Models and Application to Image Segmentation. (arXiv:1905.10629v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10629">
<div class="article-summary-box-inner">
<span><p>Probabilistic finite mixture models are widely used for unsupervised
clustering. These models can often be improved by adapting them to the topology
of the data. For instance, in order to classify spatially adjacent data points
similarly, it is common to introduce a Laplacian constraint on the posterior
probability that each data point belongs to a class. Alternatively, the mixing
probabilities can be treated as free parameters, while assuming Gauss-Markov or
more complex priors to regularize those mixing probabilities. However, these
approaches are constrained by the shape of the prior and often lead to
complicated or intractable inference. Here, we propose a new parametrization of
the Dirichlet distribution to flexibly regularize the mixing probabilities of
over-parametrized mixture distributions. Using the Expectation-Maximization
algorithm, we show that our approach allows us to define any linear update rule
for the mixing probabilities, including spatial smoothing regularization as a
special case. We then show that this flexible design can be extended to share
class information between multiple mixture models. We apply our algorithm to
artificial and natural image segmentation tasks, and we provide quantitative
and qualitative comparison of the performance of Gaussian and Student-t
mixtures on the Berkeley Segmentation Dataset. We also demonstrate how to
propagate class information across the layers of deep convolutional neural
networks in a probabilistically optimal way, suggesting a new interpretation
for feedback signals in biological visual systems. Our flexible approach can be
easily generalized to adapt probabilistic mixture models to arbitrary data
topologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Out-of-Distribution Detection for Real-World Settings. (arXiv:1911.11132v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.11132">
<div class="article-summary-box-inner">
<span><p>Detecting out-of-distribution examples is important for safety-critical
machine learning applications such as detecting novel biological phenomena and
self-driving cars. However, existing research mainly focuses on simple
small-scale settings. To set the stage for more realistic out-of-distribution
detection, we depart from small-scale settings and explore large-scale
multiclass and multi-label settings with high-resolution images and thousands
of classes. To make future work in real-world settings possible, we create new
benchmarks for three large-scale settings. To test ImageNet multiclass anomaly
detectors, we introduce the Species dataset containing over 700,000 images and
over a thousand anomalous species. We leverage ImageNet-21K to evaluate PASCAL
VOC and COCO multilabel anomaly detectors. Third, we introduce a new benchmark
for anomaly segmentation by introducing a segmentation benchmark with road
anomalies. We conduct extensive experiments in these more realistic settings
for out-of-distribution detection and find that a surprisingly simple detector
based on the maximum logit outperforms prior methods in all the large-scale
multi-class, multi-label, and segmentation tasks, establishing a simple new
baseline for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parameter-Free Style Projection for Arbitrary Style Transfer. (arXiv:2003.07694v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.07694">
<div class="article-summary-box-inner">
<span><p>Arbitrary image style transfer is a challenging task which aims to stylize a
content image conditioned on arbitrary style images. In this task the
feature-level content-style transformation plays a vital role for proper fusion
of features. Existing feature transformation algorithms often suffer from loss
of content or style details, non-natural stroke patterns, and unstable
training. To mitigate these issues, this paper proposes a new feature-level
style transformation technique, named Style Projection, for parameter-free,
fast, and effective content-style transformation. This paper further presents a
real-time feed-forward model to leverage Style Projection for arbitrary image
style transfer, which includes a regularization term for matching the semantics
between input contents and stylized outputs. Extensive qualitative analysis,
quantitative evaluation, and user study have demonstrated the effectiveness and
efficiency of the proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse-RS: a versatile framework for query-efficient sparse black-box adversarial attacks. (arXiv:2006.12834v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12834">
<div class="article-summary-box-inner">
<span><p>We propose a versatile framework based on random search, Sparse-RS, for
score-based sparse targeted and untargeted attacks in the black-box setting.
Sparse-RS does not rely on substitute models and achieves state-of-the-art
success rate and query efficiency for multiple sparse attack models:
$l_0$-bounded perturbations, adversarial patches, and adversarial frames. The
$l_0$-version of untargeted Sparse-RS outperforms all black-box and even all
white-box attacks for different models on MNIST, CIFAR-10, and ImageNet.
Moreover, our untargeted Sparse-RS achieves very high success rates even for
the challenging settings of $20\times20$ adversarial patches and $2$-pixel wide
adversarial frames for $224\times224$ images. Finally, we show that Sparse-RS
can be applied to generate targeted universal adversarial patches where it
significantly outperforms the existing approaches. The code of our framework is
available at https://github.com/fra31/sparse-rs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive Update Guided Interdependent Networks for Single Image Dehazing. (arXiv:2008.01701v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01701">
<div class="article-summary-box-inner">
<span><p>Images with haze of different varieties often pose a significant challenge to
dehazing. Therefore, guidance by estimates of haze parameters related to its
variety would be beneficial and they should be progressively updated along with
iterative haze reduction to allow optimal dehazing. To this end, we propose a
multi-network dehazing framework containing novel interdependent dehazing and
haze parameter updater networks that operate within a unique iterative
mechanism. The haze parameters, transmission map and atmospheric light, are
first estimated using specific convolutional networks allowing color cast
handling. The estimated parameters are then used as priors in our dehazing
module, where the estimates are progressively updated by novel convolutional
networks using the iterative mechanism. The updating takes place jointly with
progressive dehazing by a convolutional network that invokes inter-iteration
dependencies. The joint updating and dehazing within the iterative mechanism
gradually modify the haze parameter estimates toward achieving optimal
dehazing. Through ablation studies, our iterative dehazing framework is shown
to be more effective than the use of conventional LSTM based recurrence,
image-to-image mapping and haze model based estimation. Our dehazing framework
is qualitatively and quantitatively found to outperform the state-of-the-art on
synthetic and real-world hazy images of several datasets with varied hazy
conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pose Estimation for Robot Manipulators via Keypoint Optimization and Sim-to-Real Transfer. (arXiv:2010.08054v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08054">
<div class="article-summary-box-inner">
<span><p>Keypoint detection is an essential building block for many robotic
applications like motion capture and pose estimation. Historically, keypoints
are detected using uniquely engineered markers such as checkerboards or
fiducials. More recently, deep learning methods have been explored as they have
the ability to detect user-defined keypoints in a marker-less manner. However,
different manually selected keypoints can have uneven performance when it comes
to detection and localization. An example of this can be found on symmetric
robotic tools where DNN detectors cannot solve the correspondence problem
correctly. In this work, we propose a new and autonomous way to define the
keypoint locations that overcomes these challenges. The approach involves
finding the optimal set of keypoints on robotic manipulators for robust visual
detection and localization. Using a robotic simulator as a medium, our
algorithm utilizes synthetic data for DNN training, and the proposed algorithm
is used to optimize the selection of keypoints through an iterative approach.
The results show that when using the optimized keypoints, the detection
performance of the DNNs improved significantly. We further use the optimized
keypoints for real robotic applications by using domain randomization to bridge
the reality gap between the simulator and the physical world. The physical
world experiments show how the proposed method can be applied to the
wide-breadth of robotic applications that require visual feedback, such as
camera-to-robot calibration, robotic tool tracking, and end-effector pose
estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SelfVoxeLO: Self-supervised LiDAR Odometry with Voxel-based Deep Neural Networks. (arXiv:2010.09343v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09343">
<div class="article-summary-box-inner">
<span><p>Recent learning-based LiDAR odometry methods have demonstrated their
competitiveness. However, most methods still face two substantial challenges:
1) the 2D projection representation of LiDAR data cannot effectively encode 3D
structures from the point clouds; 2) the needs for a large amount of labeled
data for training limit the application scope of these methods. In this paper,
we propose a self-supervised LiDAR odometry method, dubbed SelfVoxeLO, to
tackle these two difficulties. Specifically, we propose a 3D convolution
network to process the raw LiDAR data directly, which extracts features that
better encode the 3D geometric patterns. To suit our network to self-supervised
learning, we design several novel loss functions that utilize the inherent
properties of LiDAR point clouds. Moreover, an uncertainty-aware mechanism is
incorporated in the loss functions to alleviate the interference of moving
objects/noises. We evaluate our method's performances on two large-scale
datasets, i.e., KITTI and Apollo-SouthBay. Our method outperforms
state-of-the-art unsupervised methods by 27%/32% in terms of
translational/rotational errors on the KITTI dataset and also performs well on
the Apollo-SouthBay dataset. By including more unlabelled training data, our
method can further improve performance comparable to the supervised methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Super-Resolution of Real-World Faces. (arXiv:2011.02427v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02427">
<div class="article-summary-box-inner">
<span><p>Real low-resolution (LR) face images contain degradations which are too
varied and complex to be captured by known downsampling kernels and
signal-independent noises. So, in order to successfully super-resolve real
faces, a method needs to be robust to a wide range of noise, blur, compression
artifacts etc. Some of the recent works attempt to model these degradations
from a dataset of real images using a Generative Adversarial Network (GAN).
They generate synthetically degraded LR images and use them with corresponding
real high-resolution(HR) image to train a super-resolution (SR) network using a
combination of a pixel-wise loss and an adversarial loss. In this paper, we
propose a two module super-resolution network where the feature extractor
module extracts robust features from the LR image, and the SR module generates
an HR estimate using only these robust features. We train a degradation GAN to
convert bicubically downsampled clean images to real degraded images, and
interpolate between the obtained degraded LR image and its clean LR
counterpart. This interpolated LR image is then used along with it's
corresponding HR counterpart to train the super-resolution network from end to
end. Entropy Regularized Wasserstein Divergence is used to force the encoded
features learnt from the clean and degraded images to closely resemble those
extracted from the interpolated image to ensure robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LCDNet: Deep Loop Closure Detection and Point Cloud Registration for LiDAR SLAM. (arXiv:2103.05056v4 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05056">
<div class="article-summary-box-inner">
<span><p>Loop closure detection is an essential component of Simultaneous Localization
and Mapping (SLAM) systems, which reduces the drift accumulated over time. Over
the years, several deep learning approaches have been proposed to address this
task, however their performance has been subpar compared to handcrafted
techniques, especially while dealing with reverse loops. In this paper, we
introduce the novel LCDNet that effectively detects loop closures in LiDAR
point clouds by simultaneously identifying previously visited places and
estimating the 6-DoF relative transformation between the current scan and the
map. LCDNet is composed of a shared encoder, a place recognition head that
extracts global descriptors, and a relative pose head that estimates the
transformation between two point clouds. We introduce a novel relative pose
head based on the unbalanced optimal transport theory that we implement in a
differentiable manner to allow for end-to-end training. Extensive evaluations
of LCDNet on multiple real-world autonomous driving datasets show that our
approach outperforms state-of-the-art loop closure detection and point cloud
registration techniques by a large margin, especially while dealing with
reverse loops. Moreover, we integrate our proposed loop closure detection
approach into a LiDAR SLAM library to provide a complete mapping system and
demonstrate the generalization ability using different sensor setup in an
unseen city.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine learning method for light field refocusing. (arXiv:2103.16020v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16020">
<div class="article-summary-box-inner">
<span><p>Light field imaging introduced the capability to refocus an image after
capturing. Currently there are two popular methods for refocusing,
shift-and-sum and Fourier slice methods. Neither of these two methods can
refocus the light field in real-time without any pre-processing. In this paper
we introduce a machine learning based refocusing technique that is capable of
extracting 16 refocused images with refocusing parameters of
\alpha=0.125,0.250,0.375,...,2.0 in real-time. We have trained our network,
which is called RefNet, in two experiments. Once using the Fourier slice method
as the training -- i.e., "ground truth" -- data and another using the
shift-and-sum method as the training data. We showed that in both cases, not
only is the RefNet method at least 134x faster than previous approaches, but
also the color prediction of RefNet is superior to both Fourier slice and
shift-and-sum methods while having similar depth of field and focus distance
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fracture Detection in Wrist X-ray Images Using Deep Learning-Based Object Detection Models. (arXiv:2111.07355v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.07355">
<div class="article-summary-box-inner">
<span><p>Hospitals, especially their emergency services, receive a high number of
wrist fracture cases. For correct diagnosis and proper treatment of these,
images obtained from various medical equipment must be viewed by physicians,
along with the patients medical records and physical examination. The aim of
this study is to perform fracture detection by use of deep learning on wrist
Xray images to support physicians in the diagnosis of these fractures,
particularly in the emergency services. Using SABL, RegNet, RetinaNet, PAA,
Libra R_CNN, FSAF, Faster R_CNN, Dynamic R_CNN and DCN deep learning based
object detection models with various backbones, 20 different fracture detection
procedures were performed on Gazi University Hospitals dataset of wrist Xray
images. To further improve these procedures, five different ensemble models
were developed and then used to reform an ensemble model to develop a unique
detection model, wrist fracture detection_combo (WFD_C). From 26 different
models for fracture detection, the highest detection result obtained was 0.8639
average precision (AP50) in the WFD-C model. Huawei Turkey R&amp;D Center supports
this study within the scope of the ongoing cooperation project coded 071813
between Gazi University, Huawei and Medskor. Code is available at
https://github.com/fatihuysal88/wrist-d
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low Precision Decentralized Distributed Training over IID and non-IID Data. (arXiv:2111.09389v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09389">
<div class="article-summary-box-inner">
<span><p>Decentralized distributed learning is the key to enabling large-scale machine
learning (training) on the edge devices utilizing private user-generated local
data, without relying on the cloud. However, the practical realization of such
on-device training is limited by the communication and compute bottleneck. In
this paper, we propose and show the convergence of low precision decentralized
training that aims to reduce the computational complexity and communication
cost of decentralized training. Many feedback-based compression techniques have
been proposed in the literature to reduce communication costs. To the best of
our knowledge, there is no work that applies and shows compute efficient
training techniques such quantization, pruning, etc., for peer-to-peer
decentralized learning setups. Since real-world applications have a significant
skew in the data distribution, we design "Range-EvoNorm" as the normalization
activation layer which is better suited for low precision training over non-IID
data. Moreover, we show that the proposed low precision training can be used in
synergy with other communication compression methods decreasing the
communication cost further. Our experiments indicate that 8-bit decentralized
training has minimal accuracy loss compared to its full precision counterpart
even with non-IID data. However, when low precision training is accompanied by
communication compression through sparsification we observe a 1-2% drop in
accuracy. The proposed low precision decentralized training decreases
computational complexity, memory usage, and communication cost by 4x and
compute energy by a factor of ~20x, while trading off less than a $1\%$
accuracy for both IID and non-IID data. In particular, with higher skew values,
we observe an increase in accuracy (by ~ 0.5%) with low precision training,
indicating the regularization effect of the quantization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Probability Estimation. (arXiv:2111.10734v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.10734">
<div class="article-summary-box-inner">
<span><p>Reliable probability estimation is of crucial importance in many real-world
applications where there is inherent uncertainty, such as weather forecasting,
medical prognosis, or collision avoidance in autonomous vehicles.
Probability-estimation models are trained on observed outcomes (e.g. whether it
has rained or not, or whether a patient has died or not), because the
ground-truth probabilities of the events of interest are typically unknown. The
problem is therefore analogous to binary classification, with the important
difference that the objective is to estimate probabilities rather than
predicting the specific outcome. The goal of this work is to investigate
probability estimation from high-dimensional data using deep neural networks.
There exist several methods to improve the probabilities generated by these
models but they mostly focus on classification problems where the probabilities
are related to model uncertainty. In the case of problems with inherent
uncertainty, it is challenging to evaluate performance without access to
ground-truth probabilities. To address this, we build a synthetic dataset to
study and compare different computable metrics. We evaluate existing methods on
the synthetic data as well as on three real-world probability estimation tasks,
all of which involve inherent uncertainty. We also give a theoretical analysis
of a model for high-dimensional probability estimation which reproduces several
of the phenomena evinced in our experiments. Finally, we propose a new method
for probability estimation using neural networks, which modifies the training
process to promote output probabilities that are consistent with empirical
probabilities computed from the data. The method outperforms existing
approaches on most metrics on the simulated as well as real-world data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HPRN: Holistic Prior-embedded Relation Network for Spectral Super-Resolution. (arXiv:2112.14608v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.14608">
<div class="article-summary-box-inner">
<span><p>Spectral super-resolution (SSR) refers to the hyperspectral image (HSI)
recovery from an RGB counterpart. Due to the one-to-many nature of the SSR
problem, a single RGB image can be reprojected to many HSIs. The key to tackle
this ill-posed problem is to plug into multi-source prior information such as
the natural spatial context-prior of RGB images, deep feature-prior or inherent
statistical-prior of HSIs, etc., so as to effectively alleviate the degree of
ill-posedness. However, most current approaches only consider the general and
limited priors in their customized convolutional neural networks (CNNs), which
leads to the inability to guarantee the confidence and fidelity of
reconstructed spectra. In this paper, we propose a novel holistic
prior-embedded relation network (HPRN) to integrate comprehensive priors to
regularize and optimize the solution space of SSR. Basically, the core
framework is delicately assembled by several multi-residual relation blocks
(MRBs) that fully facilitate the transmission and utilization of the
low-frequency content prior of RGBs. Innovatively, the semantic prior of RGB
inputs is introduced to mark category attributes, and a semantic-driven spatial
relation module (SSRM) is invented to perform the feature aggregation of
clustered similar range for refining recovered characteristics. Additionally,
we develop a transformer-based channel relation module (TCRM), which breaks the
habit of employing scalars as the descriptors of channel-wise relations in the
previous deep feature-prior, and replaces them with certain vectors to make the
mapping function more robust and smoother. In order to maintain the
mathematical correlation and spectral consistency between hyperspectral bands,
the second-order prior constraints (SOPC) are incorporated into the loss
function to guide the HSI reconstruction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniFormer: Unified Transformer for Efficient Spatiotemporal Representation Learning. (arXiv:2201.04676v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04676">
<div class="article-summary-box-inner">
<span><p>It is a challenging task to learn rich and multi-scale spatiotemporal
semantics from high-dimensional videos, due to large local redundancy and
complex global dependency between video frames. The recent advances in this
research have been mainly driven by 3D convolutional neural networks and vision
transformers. Although 3D convolution can efficiently aggregate local context
to suppress local redundancy from a small 3D neighborhood, it lacks the
capability to capture global dependency because of the limited receptive field.
Alternatively, vision transformers can effectively capture long-range
dependency by self-attention mechanism, while having the limitation on reducing
local redundancy with blind similarity comparison among all the tokens in each
layer. Based on these observations, we propose a novel Unified transFormer
(UniFormer) which seamlessly integrates merits of 3D convolution and
spatiotemporal self-attention in a concise transformer format, and achieves a
preferable balance between computation and accuracy. Different from traditional
transformers, our relation aggregator can tackle both spatiotemporal redundancy
and dependency, by learning local and global token affinity respectively in
shallow and deep layers. We conduct extensive experiments on the popular video
benchmarks, e.g., Kinetics-400, Kinetics-600, and Something-Something V1&amp;V2.
With only ImageNet-1K pretraining, our UniFormer achieves 82.9%/84.8% top-1
accuracy on Kinetics-400/Kinetics-600, while requiring 10x fewer GFLOPs than
other state-of-the-art methods. For Something-Something V1 and V2, our
UniFormer achieves new state-of-the-art performances of 60.9% and 71.2% top-1
accuracy respectively. Code is available at
https://github.com/Sense-X/UniFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explore the Expression: Facial Expression Generation using Auxiliary Classifier Generative Adversarial Network. (arXiv:2201.09061v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09061">
<div class="article-summary-box-inner">
<span><p>Facial expressions are a form of non-verbal communication that humans perform
seamlessly for meaningful transfer of information. Most of the literature
addresses the facial expression recognition aspect however, with the advent of
Generative Models, it has become possible to explore the affect space in
addition to mere classification of a set of expressions. In this article, we
propose a generative model architecture which robustly generates a set of
facial expressions for multiple character identities and explores the
possibilities of generating complex expressions by combining the simple ones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR. (arXiv:2201.12329v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12329">
<div class="article-summary-box-inner">
<span><p>We present in this paper a novel query formulation using dynamic anchor boxes
for DETR (DEtection TRansformer) and offer a deeper understanding of the role
of queries in DETR. This new formulation directly uses box coordinates as
queries in Transformer decoders and dynamically updates them layer-by-layer.
Using box coordinates not only helps using explicit positional priors to
improve the query-to-feature similarity and eliminate the slow training
convergence issue in DETR, but also allows us to modulate the positional
attention map using the box width and height information. Such a design makes
it clear that queries in DETR can be implemented as performing soft ROI pooling
layer-by-layer in a cascade manner. As a result, it leads to the best
performance on MS-COCO benchmark among the DETR-like detection models under the
same setting, e.g., AP 45.7\% using ResNet50-DC5 as backbone trained in 50
epochs. We also conducted extensive experiments to confirm our analysis and
verify the effectiveness of our methods. Code is available at
\url{https://github.com/SlongLiu/DAB-DETR}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scale-arbitrary Invertible Image Downscaling. (arXiv:2201.12576v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12576">
<div class="article-summary-box-inner">
<span><p>Downscaling is indispensable when distributing high-resolution (HR) images
over the Internet to fit the displays of various resolutions, while upscaling
is also necessary when users want to see details of the distributed images.
Recent invertible image downscaling methods jointly model these two problems
and achieve significant improvements. However, they only consider fixed integer
scale factors that cannot meet the requirement of conveniently fitting the
displays of various resolutions in real-world applications. In this paper, we
propose a scale-Arbitrary Invertible image Downscaling Network (AIDN), to
natively downscale HR images with arbitrary scale factors for fitting various
target resolutions. Meanwhile, the HR information is embedded in the downscaled
low-resolution (LR) counterparts in a nearly imperceptible form such that our
AIDN can also restore the original HR images solely from the LR images. The key
to supporting arbitrary scale factors is our proposed Conditional Resampling
Module (CRM) that conditions the downscaling/upscaling kernels and sampling
locations on both scale factors and image content. Extensive experimental
results demonstrate that our AIDN achieves top performance for invertible
downscaling with both arbitrary integer and non-integer scale factors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmenting Novelty Search with a Surrogate Model to Engineer Meta-Diversity in Ensembles of Classifiers. (arXiv:2201.12896v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12896">
<div class="article-summary-box-inner">
<span><p>Using Neuroevolution combined with Novelty Search to promote behavioural
diversity is capable of constructing high-performing ensembles for
classification. However, using gradient descent to train evolved architectures
during the search can be computationally prohibitive. Here we propose a method
to overcome this limitation by using a surrogate model which estimates the
behavioural distance between two neural network architectures required to
calculate the sparseness term in Novelty Search. We demonstrate a speedup of 10
times over previous work and significantly improve on previous reported results
on three benchmark datasets from Computer Vision -- CIFAR-10, CIFAR-100, and
SVHN. This results from the expanded architecture search space facilitated by
using a surrogate. Our method represents an improved paradigm for implementing
horizontal scaling of learning algorithms by making an explicit search for
diversity considerably more tractable for the same bounded resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extension: Adaptive Sampling with Implicit Radiance Field. (arXiv:2202.00855v3 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00855">
<div class="article-summary-box-inner">
<span><p>This manuscript discusses the extension of adaptive light field sampling with
implicit radiance fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate calibration of multi-perspective cameras from a generalization of the hand-eye constraint. (arXiv:2202.00886v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00886">
<div class="article-summary-box-inner">
<span><p>Multi-perspective cameras are quickly gaining importance in many applications
such as smart vehicles and virtual or augmented reality. However, a large
system size or absence of overlap in neighbouring fields-of-view often
complicate their calibration. We present a novel solution which relies on the
availability of an external motion capture system. Our core contribution
consists of an extension to the hand-eye calibration problem which jointly
solves multi-eye-to-base problems in closed form. We furthermore demonstrate
its equivalence to the multi-eye-in-hand problem. The practical validity of our
approach is supported by our experiments, indicating that the method is highly
efficient and accurate, and outperforms existing closed-form alternatives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Edge-Selective Feature Weaving for Point Cloud Matching. (arXiv:2202.02149v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02149">
<div class="article-summary-box-inner">
<span><p>This paper tackles the problem of accurately matching the points of two 3D
point clouds. Most conventional methods improve their performance by extracting
representative features from each point via deep-learning-based algorithms. On
the other hand, the correspondence calculation between the extracted features
has not been examined in depth, and non-trainable algorithms (e.g. the Sinkhorn
algorithm) are frequently applied. As a result, the extracted features may be
forcibly fitted to a non-trainable algorithm. Furthermore, the extracted
features frequently contain stochastically unavoidable errors, which degrades
the matching accuracy. In this paper, instead of using a non-trainable
algorithm, we propose a differentiable matching network that can be jointly
optimized with the feature extraction procedure. Our network first constructs
graphs with edges connecting the points of each point cloud and then extracts
discriminative edge features by using two main components: a shared set-encoder
and an edge-selective cross-concatenation. These components enable us to
symmetrically consider two point clouds and to extract discriminative edge
features, respectively. By using the extracted discriminative edge features,
our network can accurately calculate the correspondence between points. Our
experimental results show that the proposed network can significantly improve
the performance of point cloud matching. Our code is available at
https://github.com/yanarin/ESFW
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PrivPAS: A real time Privacy-Preserving AI System and applied ethics. (arXiv:2202.02524v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02524">
<div class="article-summary-box-inner">
<span><p>With 3.78 billion social media users worldwide in 2021 (48% of the human
population), almost 3 billion images are shared daily. At the same time, a
consistent evolution of smartphone cameras has led to a photography explosion
with 85% of all new pictures being captured using smartphones. However, lately,
there has been an increased discussion of privacy concerns when a person being
photographed is unaware of the picture being taken or has reservations about
the same being shared. These privacy violations are amplified for people with
disabilities, who may find it challenging to raise dissent even if they are
aware. Such unauthorized image captures may also be misused to gain sympathy by
third-party organizations, leading to a privacy breach. Privacy for people with
disabilities has so far received comparatively less attention from the AI
community. This motivates us to work towards a solution to generate
privacy-conscious cues for raising awareness in smartphone users of any
sensitivity in their viewfinder content. To this end, we introduce PrivPAS (A
real time Privacy-Preserving AI System) a novel framework to identify sensitive
content. Additionally, we curate and annotate a dataset to identify and
localize accessibility markers and classify whether an image is sensitive to a
featured subject with a disability. We demonstrate that the proposed
lightweight architecture, with a memory footprint of a mere 8.49MB, achieves a
high mAP of 89.52% on resource-constrained devices. Furthermore, our pipeline,
trained on face anonymized data, achieves an F1-score of 73.1%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLPanoDepth: Global-to-Local Panoramic Depth Estimation. (arXiv:2202.02796v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02796">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a learning-based method for predicting dense depth
values of a scene from a monocular omnidirectional image. An omnidirectional
image has a full field-of-view, providing much more complete descriptions of
the scene than perspective images. However, fully-convolutional networks that
most current solutions rely on fail to capture rich global contexts from the
panorama. To address this issue and also the distortion of equirectangular
projection in the panorama, we propose Cubemap Vision Transformers (CViT), a
new transformer-based architecture that can model long-range dependencies and
extract distortion-free global features from the panorama. We show that cubemap
vision transformers have a global receptive field at every stage and can
provide globally coherent predictions for spherical signals. To preserve
important local features, we further design a convolution-based branch in our
pipeline (dubbed GLPanoDepth) and fuse global features from cubemap vision
transformers at multiple scales. This global-to-local strategy allows us to
fully exploit useful global and local features in the panorama, achieving
state-of-the-art performance in panoramic depth estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Imposing Temporal Consistency on Deep Monocular Body Shape and Pose Estimation. (arXiv:2202.03074v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03074">
<div class="article-summary-box-inner">
<span><p>Accurate and temporally consistent modeling of human bodies is essential for
a wide range of applications, including character animation, understanding
human social behavior and AR/VR interfaces. Capturing human motion accurately
from a monocular image sequence is still challenging and the modeling quality
is strongly influenced by the temporal consistency of the captured body motion.
Our work presents an elegant solution for the integration of temporal
constraints in the fitting process. This does not only increase temporal
consistency but also robustness during the optimization. In detail, we derive
parameters of a sequence of body models, representing shape and motion of a
person, including jaw poses, facial expressions, and finger poses. We optimize
these parameters over the complete image sequence, fitting one consistent body
shape while imposing temporal consistency on the body motion, assuming linear
body joint trajectories over a short time. Our approach enables the derivation
of realistic 3D body models from image sequences, including facial expression
and articulated hands. In extensive experiments, we show that our approach
results in accurately estimated body shape and motion, also for challenging
movements and poses. Further, we apply it to the special application of sign
language analysis, where accurate and temporal consistent motion modelling is
essential, and show that the approach is well-suited for this kind of
application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Long-Term Person Re-Identification with Clothes Change. (arXiv:2202.03087v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03087">
<div class="article-summary-box-inner">
<span><p>We investigate unsupervised person re-identification (Re-ID) with clothes
change, a new challenging problem with more practical usability and scalability
to real-world deployment. Most existing re-id methods artificially assume the
clothes of every single person to be stationary across space and time. This
condition is mostly valid for short-term re-id scenarios since an average
person would often change the clothes even within a single day. To alleviate
this assumption, several recent works have introduced the clothes change facet
to re-id, with a focus on supervised learning person identity discriminative
representation with invariance to clothes changes. Taking a step further
towards this long-term re-id direction, we further eliminate the requirement of
person identity labels, as they are significantly more expensive and more
tedious to annotate in comparison to short-term person re-id datasets. Compared
to conventional unsupervised short-term re-id, this new problem is drastically
more challenging as different people may have similar clothes whilst the same
person can wear multiple suites of clothes over different locations and times
with very distinct appearance. To overcome such obstacles, we introduce a novel
Curriculum Person Clustering (CPC) method that can adaptively regulate the
unsupervised clustering criterion according to the clustering confidence.
Experiments on three long-term person re-id datasets show that our CPC
outperforms SOTA unsupervised re-id methods and even closely matches the
supervised re-id models.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-02-09 23:06:46.346806079 UTC">2022-02-09 23:06:46 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>