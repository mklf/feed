<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-06-29T01:30:00Z">06-29</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Text Classification via Test-Time Augmentation. (arXiv:2206.13607v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13607">
<div class="article-summary-box-inner">
<span><p>Test-time augmentation -- the aggregation of predictions across transformed
examples of test inputs -- is an established technique to improve the
performance of image classification models. Importantly, TTA can be used to
improve model performance post-hoc, without additional training. Although
test-time augmentation (TTA) can be applied to any data modality, it has seen
limited adoption in NLP due in part to the difficulty of identifying
label-preserving transformations. In this paper, we present augmentation
policies that yield significant accuracy improvements with language models. A
key finding is that augmentation policy design -- for instance, the number of
samples generated from a single, non-deterministic augmentation -- has a
considerable impact on the benefit of TTA. Experiments across a binary
classification task and dataset show that test-time augmentation can deliver
consistent improvements over current state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Wav2Vec-Aug: Improved self-supervised training with limited data. (arXiv:2206.13654v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13654">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) of speech representations has received much
attention over the last few years but most work has focused on languages and
domains with an abundance of unlabeled data. However, for many languages there
is a shortage even in the unlabeled data which limits the effectiveness of SSL.
In this work, we focus on the problem of applying SSL to domains with limited
available data by leveraging data augmentation for Wav2Vec 2.0 pretraining.
Further, we propose improvements to each component of the model which result in
a combined relative word error rate (WER) improvement of up to 13% compared to
Wav2Vec 2.0 on Librispeech test-clean / other.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Kwame for Science: An AI Teaching Assistant for Science Education in West Africa. (arXiv:2206.13703v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13703">
<div class="article-summary-box-inner">
<span><p>Africa has a high student-to-teacher ratio which limits students' access to
teachers. Consequently, students struggle to get answers to their questions. In
this work, we extended Kwame, our previous AI teaching assistant, adapted it
for science education, and deployed it as a web app. Kwame for Science answers
questions of students based on the Integrated Science subject of the West
African Senior Secondary Certificate Examination (WASSCE). Kwame for Science is
a Sentence-BERT-based question-answering web app that displays 3 paragraphs as
answers along with a confidence score in response to science questions.
Additionally, it displays the top 5 related past exam questions and their
answers in addition to the 3 paragraphs. Our preliminary evaluation of the
Kwame for Science with a 2.5-week real-world deployment showed a top 3 accuracy
of 87.5% (n=56) with 190 users across 11 countries. Kwame for Science will
enable the delivery of scalable, cost-effective, and quality remote education
to millions of people across Africa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Fine-Grained Entity Typing with Automatic Label Interpretation and Instance Generation. (arXiv:2206.13746v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13746">
<div class="article-summary-box-inner">
<span><p>We study the problem of few-shot Fine-grained Entity Typing (FET), where only
a few annotated entity mentions with contexts are given for each entity type.
Recently, prompt-based tuning has demonstrated superior performance to standard
fine-tuning in few-shot scenarios by formulating the entity type classification
task as a ''fill-in-the-blank'' problem. This allows effective utilization of
the strong language modeling capability of Pre-trained Language Models (PLMs).
Despite the success of current prompt-based tuning approaches, two major
challenges remain: (1) the verbalizer in prompts is either manually designed or
constructed from external knowledge bases, without considering the target
corpus and label hierarchy information, and (2) current approaches mainly
utilize the representation power of PLMs, but have not explored their
generation power acquired through extensive general-domain pre-training. In
this work, we propose a novel framework for few-shot FET consisting of two
modules: (1) an entity type label interpretation module automatically learns to
relate type labels to the vocabulary by jointly leveraging few-shot instances
and the label hierarchy, and (2) a type-based contextualized instance generator
produces new instances based on given instances to enlarge the training set for
better generalization. On three benchmark datasets, our model outperforms
existing methods by significant margins. Code can be found at
https://github.com/teapot123/Fine-Grained-Entity-Typing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phrase Mining. (arXiv:2206.13748v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13748">
<div class="article-summary-box-inner">
<span><p>Extracting frequent words from a collection of texts is performed on a great
scale in many subjects. Extracting phrases, on the other hand, is not commonly
done due to inherent complications when extracting phrases, the most
significant complication being that of double-counting, where words or phrases
are counted when they appear inside longer phrases that themselves are also
counted. Several papers have been written on phrase mining that describe
solutions to this issue; however, they either require a list of so-called
quality phrases to be available to the extracting process, or they require
human interaction to identify those quality phrases during the process. We
present a method that eliminates double-counting without the need to identify
lists of quality phrases. In the context of a set of texts, we define a
principal phrase as a phrase that does not cross punctuation marks, does not
start with a stop word, with the exception of the stop words "not" and "no",
does not end with a stop word, is frequent within those texts without being
double counted, and is meaningful to the user. Our method can identify such
principal phrases independently without human input, and enables their
extraction from any texts. An R package called phm has been developed that
implements this method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Multi-view Rule Discovery for Weakly-Supervised Compatible Products Prediction. (arXiv:2206.13749v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13749">
<div class="article-summary-box-inner">
<span><p>On e-commerce platforms, predicting if two products are compatible with each
other is an important functionality to achieve trustworthy product
recommendation and search experience for consumers. However, accurately
predicting product compatibility is difficult due to the heterogeneous product
data and the lack of manually curated training data. We study the problem of
discovering effective labeling rules that can enable weakly-supervised product
compatibility prediction. We develop AMRule, a multi-view rule discovery
framework that can (1) adaptively and iteratively discover novel rulers that
can complement the current weakly-supervised model to improve compatibility
prediction; (2) discover interpretable rules from both structured attribute
tables and unstructured product descriptions. AMRule adaptively discovers
labeling rules from large-error instances via a boosting-style strategy, the
high-quality rules can remedy the current model's weak spots and refine the
model iteratively. For rule discovery from structured product attributes, we
generate composable high-order rules from decision trees; and for rule
discovery from unstructured product descriptions, we generate prompt-based
rules from a pre-trained language model. Experiments on 4 real-world datasets
show that AMRule outperforms the baselines by 5.98% on average and improves
rule quality and rule proposal efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Impact of Noises in Crowd-Sourced Data for Speech Translation. (arXiv:2206.13756v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13756">
<div class="article-summary-box-inner">
<span><p>Training speech translation (ST) models requires large and high-quality
datasets. MuST-C is one of the most widely used ST benchmark datasets. It
contains around 400 hours of speech-transcript-translation data for each of the
eight translation directions. This dataset passes several quality-control
filters during creation. However, we find that MuST-C still suffers from three
major quality issues: audio-text misalignment, inaccurate translation, and
unnecessary speaker's name. What are the impacts of these data quality issues
for model development and evaluation? In this paper, we propose an automatic
method to fix or filter the above quality issues, using English-German (En-De)
translation as an example. Our experiments show that ST models perform better
on clean test sets, and the rank of proposed models remains consistent across
different test sets. Besides, simply removing misaligned data points from the
training set does not lead to a better ST model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flexible text generation for counterfactual fairness probing. (arXiv:2206.13757v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13757">
<div class="article-summary-box-inner">
<span><p>A common approach for testing fairness issues in text-based classifiers is
through the use of counterfactuals: does the classifier output change if a
sensitive attribute in the input is changed? Existing counterfactual generation
methods typically rely on wordlists or templates, producing simple
counterfactuals that don't take into account grammar, context, or subtle
sensitive attribute references, and could miss issues that the wordlist
creators had not considered. In this paper, we introduce a task for generating
counterfactuals that overcomes these shortcomings, and demonstrate how large
language models (LLMs) can be leveraged to make progress on this task. We show
that this LLM-based method can produce complex counterfactuals that existing
methods cannot, comparing the performance of various counterfactual generation
methods on the Civil Comments dataset and showing their value in evaluating a
toxicity classifier.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CC-Riddle: A Question Answering Dataset of Chinese Character Riddles. (arXiv:2206.13778v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13778">
<div class="article-summary-box-inner">
<span><p>Chinese character riddle is a challenging riddle game which takes a single
character as the solution. The riddle describes the pronunciation, shape and
meaning of the solution character with rhetoric techniques. In this paper, we
propose a Chinese character riddle dataset covering the majority of common
simplified Chinese characters by crawling riddles from the Web and generating
brand new ones. In the generation stage, we provide the Chinese phonetic
alphabet, decomposition and explanation of the solution character for the
generation model and get multiple riddle descriptions for each tested
character. Then the generated riddles are manually filtered and the final
dataset, CC-Riddle is composed of both human-written riddles and filtered
generated riddles. Furthermore, we build a character riddle QA system based on
our dataset and find that the existing models struggle to solve such tricky
questions. CC-Riddle is now publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dependency Parsing with Backtracking using Deep Reinforcement Learning. (arXiv:2206.13914v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13914">
<div class="article-summary-box-inner">
<span><p>Greedy algorithms for NLP such as transition based parsing are prone to error
propagation. One way to overcome this problem is to allow the algorithm to
backtrack and explore an alternative solution in cases where new evidence
contradicts the solution explored so far. In order to implement such a
behavior, we use reinforcement learning and let the algorithm backtrack in
cases where such an action gets a better reward than continuing to explore the
current solution. We test this idea on both POS tagging and dependency parsing
and show that backtracking is an effective means to fight against error
propagation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long Range Language Modeling via Gated State Spaces. (arXiv:2206.13947v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13947">
<div class="article-summary-box-inner">
<span><p>State space models have shown to be effective at modeling long range
dependencies, specially on sequence classification tasks. In this work we focus
on autoregressive sequence modeling over English books, Github source code and
ArXiv mathematics articles. Based on recent developments around the
effectiveness of gated activation functions, we propose a new layer named Gated
State Space (GSS) and show that it trains significantly faster than the
diagonal version of S4 (i.e. DSS) on TPUs, is fairly competitive with several
well-tuned Transformer-based baselines and exhibits zero-shot generalization to
longer inputs while being straightforward to implement. Finally, we show that
leveraging self-attention to model local dependencies improves the performance
of GSS even further.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysis of Individual Conversational Volatility in Tandem Telecollaboration for Second Language Learning. (arXiv:2206.13965v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13965">
<div class="article-summary-box-inner">
<span><p>Second language learning can be enabled by tandem collaboration where
students are grouped into video conference calls while learning the native
language of other student(s) on the calls. This places students in an online
environment where the more outgoing can actively contribute and engage in
dialogue while those more shy and unsure of their second language skills can
sit back and coast through the calls. We have built and deployed the L2L system
which records timings of conversational utterances from all participants in a
call. We generate visualisations including participation rates and timelines
for each student in each call and present these on a dashboard. We have
recently developed a measure called personal conversational volatility for how
dynamic has been each student's contribution to the dialogue in each call. We
present an analysis of conversational volatility measures for a sample of 19
individual English-speaking students from our University who are learning
Frenchm, in each of 86 tandem telecollaboration calls over one teaching
semester. Our analysis shows there is a need to look into the nature of the
interactions and see if the choices of discussion topics assigned to them were
too difficult for some students and that may have influenced their engagement
in some way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MACSA: A Multimodal Aspect-Category Sentiment Analysis Dataset with Multimodal Fine-grained Aligned Annotations. (arXiv:2206.13969v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13969">
<div class="article-summary-box-inner">
<span><p>Multimodal fine-grained sentiment analysis has recently attracted increasing
attention due to its broad applications. However, the existing multimodal
fine-grained sentiment datasets most focus on annotating the fine-grained
elements in text but ignore those in images, which leads to the fine-grained
elements in visual content not receiving the full attention they deserve. In
this paper, we propose a new dataset, the Multimodal Aspect-Category Sentiment
Analysis (MACSA) dataset, which contains more than 21K text-image pairs. The
dataset provides fine-grained annotations for both textual and visual content
and firstly uses the aspect category as the pivot to align the fine-grained
elements between the two modalities. Based on our dataset, we propose the
Multimodal ACSA task and a multimodal graph-based aligned model (MGAM), which
adopts a fine-grained cross-modal fusion method. Experimental results show that
our method can facilitate the baseline comparison for future research on this
corpus. We will make the dataset and code publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Generator-Ranker Learning for Natural Language Generation. (arXiv:2206.13974v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13974">
<div class="article-summary-box-inner">
<span><p>Due to exposure bias, most existing natural language generation (NLG) models
trained by maximizing the likelihood objective predict poor text results during
the inference stage. In this paper, to tackle this problem, we revisit the
generate-then-rank framework and propose a joint generator-ranker (JGR)
training algorithm for text generation tasks. In JGR, the generator model is
trained by maximizing two objectives: the likelihood of the training corpus and
the expected reward given by the ranker model. Meanwhile, the ranker model
takes input samples from the generator model and learns to distinguish good
samples from the generation pool. The generator and ranker models are
alternately optimized till convergence. In the empirical study, the proposed
JGR model achieves new state-of-the-art performance on five public benchmarks
covering three popular generation tasks: summarization, question generation,
and response generation. We will make code, data, and models available at
https://github.com/microsoft/AdvNLG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label-enhanced Prototypical Network with Contrastive Learning for Multi-label Few-shot Aspect Category Detection. (arXiv:2206.13980v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13980">
<div class="article-summary-box-inner">
<span><p>Multi-label aspect category detection allows a given review sentence to
contain multiple aspect categories, which is shown to be more practical in
sentiment analysis and attracting increasing attention. As annotating large
amounts of data is time-consuming and labor-intensive, data scarcity occurs
frequently in real-world scenarios, which motivates multi-label few-shot aspect
category detection. However, research on this problem is still in infancy and
few methods are available. In this paper, we propose a novel label-enhanced
prototypical network (LPN) for multi-label few-shot aspect category detection.
The highlights of LPN can be summarized as follows. First, it leverages label
description as auxiliary knowledge to learn more discriminative prototypes,
which can retain aspect-relevant information while eliminating the harmful
effect caused by irrelevant aspects. Second, it integrates with contrastive
learning, which encourages that the sentences with the same aspect label are
pulled together in embedding space while simultaneously pushing apart the
sentences with different aspect labels. In addition, it introduces an adaptive
multi-label inference module to predict the aspect count in the sentence, which
is simple yet effective. Extensive experimental results on three datasets
demonstrate that our proposed model LPN can consistently achieve
state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hybrid Ensemble for Fake News Detection: An attempt. (arXiv:2206.13981v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13981">
<div class="article-summary-box-inner">
<span><p>Fake News Detection has been a challenging problem in the field of Machine
Learning. Researchers have approached it via several techniques using old
Statistical Classification models and modern Deep Learning. Today, with the
growing amount of data, developments in the field of NLP and ML, and an
increase in the computation power at disposal, there are infinite permutations
and combinations to approach this problem from a different perspective. In this
paper, we try different methods to tackle Fake News, and try to build, and
propose the possibilities of a Hybrid Ensemble combining the classical Machine
Learning techniques with the modern Deep Learning Approaches
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Proposed Bi-LSTM Method to Fake News Detection. (arXiv:2206.13982v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13982">
<div class="article-summary-box-inner">
<span><p>Recent years have seen an explosion in social media usage, allowing people to
connect with others. Since the appearance of platforms such as Facebook and
Twitter, such platforms influence how we speak, think, and behave. This problem
negatively undermines confidence in content because of the existence of fake
news. For instance, false news was a determining factor in influencing the
outcome of the U.S. presidential election and other sites. Because this
information is so harmful, it is essential to make sure we have the necessary
tools to detect and resist it. We applied Bidirectional Long Short-Term Memory
(Bi-LSTM) to determine if the news is false or real in order to showcase this
study. A number of foreign websites and newspapers were used for data
collection. After creating &amp; running the model, the work achieved 84% model
accuracy and 62.0 F1-macro scores with training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SINC: Service Information Augmented Open-Domain Conversation. (arXiv:2206.14000v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14000">
<div class="article-summary-box-inner">
<span><p>Generative open-domain dialogue systems can benefit from external knowledge,
but the lack of external knowledge resources and the difficulty in finding
relevant knowledge limit the development of this technology. To this end, we
propose a knowledge-driven dialogue task using dynamic service information.
Specifically, we use a large number of service APIs that can provide high
coverage and spatiotemporal sensitivity as external knowledge sources. The
dialogue system generates queries to request external services along with user
information, get the relevant knowledge, and generate responses based on this
knowledge. To implement this method, we collect and release the first open
domain Chinese service knowledge dialogue dataset DuSinc. At the same time, we
construct a baseline model PLATO-SINC, which realizes the automatic utilization
of service information for dialogue. Both automatic evaluation and human
evaluation show that our proposed new method can significantly improve the
effect of open-domain conversation, and the session-level overall score in
human evaluation is improved by 59.29% compared with the dialogue pre-training
model PLATO-2. The dataset and benchmark model will be open sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Proton: Probing Schema Linking Information from Pre-trained Language Models for Text-to-SQL Parsing. (arXiv:2206.14017v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14017">
<div class="article-summary-box-inner">
<span><p>The importance of building text-to-SQL parsers which can be applied to new
databases has long been acknowledged, and a critical step to achieve this goal
is schema linking, i.e., properly recognizing mentions of unseen columns or
tables when generating SQLs. In this work, we propose a novel framework to
elicit relational structures from large-scale pre-trained language models
(PLMs) via a probing procedure based on Poincar\'e distance metric, and use the
induced relations to augment current graph-based parsers for better schema
linking. Compared with commonly-used rule-based methods for schema linking, we
found that probing relations can robustly capture semantic correspondences,
even when surface forms of mentions and entities differ. Moreover, our probing
procedure is entirely unsupervised and requires no additional parameters.
Extensive experiments show that our framework sets new state-of-the-art
performance on three benchmarks. We empirically verify that our probing
procedure can indeed find desired relational structures through qualitative
analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bengali Common Voice Speech Dataset for Automatic Speech Recognition. (arXiv:2206.14053v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14053">
<div class="article-summary-box-inner">
<span><p>Bengali is one of the most spoken languages in the world with over 300
million speakers globally. Despite its popularity, research into the
development of Bengali speech recognition systems is hindered due to the lack
of diverse open-source datasets. As a way forward, we have crowdsourced the
Bengali Common Voice Speech Dataset, which is a sentence-level automatic speech
recognition corpus. Collected on the Mozilla Common Voice platform, the dataset
is part of an ongoing campaign that has led to the collection of over 400 hours
of data in 2 months and is growing rapidly. Our analysis shows that our dataset
has more speaker, phoneme, and environmental diversity compared to the OpenSLR
Bengali ASR dataset, the largest existing open-source Bengali speech dataset.
We present insights obtained from the dataset and discuss key linguistic
challenges that need to be addressed in future versions. Additionally, we
report the current performance of a few Automatic Speech Recognition (ASR)
algorithms and set a benchmark for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Lexical Gender Inference: A Scalable Methodology using Online Databases. (arXiv:2206.14055v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14055">
<div class="article-summary-box-inner">
<span><p>This paper presents a new method for automatically detecting words with
lexical gender in large-scale language datasets. Currently, the evaluation of
gender bias in natural language processing relies on manually compiled lexicons
of gendered expressions, such as pronouns ('he', 'she', etc.) and nouns with
lexical gender ('mother', 'boyfriend', 'policewoman', etc.). However, manual
compilation of such lists can lead to static information if they are not
periodically updated and often involve value judgments by individual annotators
and researchers. Moreover, terms not included in the list fall out of the range
of analysis. To address these issues, we devised a scalable, dictionary-based
method to automatically detect lexical gender that can provide a dynamic,
up-to-date analysis with high coverage. Our approach reaches over 80% accuracy
in determining the lexical gender of nouns retrieved randomly from a Wikipedia
sample and when testing on a list of gendered words used in previous research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Placing (Historical) Facts on a Timeline: A Classification cum Coref Resolution Approach. (arXiv:2206.14089v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14089">
<div class="article-summary-box-inner">
<span><p>A timeline provides one of the most effective ways to visualize the important
historical facts that occurred over a period of time, presenting the insights
that may not be so apparent from reading the equivalent information in textual
form. By leveraging generative adversarial learning for important sentence
classification and by assimilating knowledge based tags for improving the
performance of event coreference resolution we introduce a two staged system
for event timeline generation from multiple (historical) text documents. We
demonstrate our results on two manually annotated historical text documents.
Our results can be extremely helpful for historians, in advancing research in
history and in understanding the socio-political landscape of a country as
reflected in the writings of famous personas.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simplifying Dataflow Dialogue Design. (arXiv:2206.14125v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14125">
<div class="article-summary-box-inner">
<span><p>In \citep{andreas2020task-oriented}, a dataflow (DF) based dialogue system
was introduced, showing clear advantages compared to many commonly used current
systems. This was accompanied by the release of SMCalFlow, a practically
relevant, manually annotated dataset, more detailed and much larger than any
comparable dialogue dataset. Despite these remarkable contributions, the
community has not shown further interest in this direction. What are the
reasons for this lack of interest? And how can the community be encouraged to
engage in research in this direction?
</p>
<p>One explanation may be the perception that this approach is too complex -
both the the annotation and the system. This paper argues that this perception
is wrong: 1) Suggestions for a simplified format for the annotation of the
dataset are presented, 2) An implementation of the DF execution engine is
released\footnote{https://github.com/telepathylabsai/OpenDF}, which can serve
as a sandbox allowing researchers to easily implement, and experiment with, new
DF dialogue designs. The hope is that these contributions will help engage more
practitioners in exploring new ideas and designs for DF based dialogue systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Question Personalization in an Intelligent Tutoring System. (arXiv:2206.14145v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14145">
<div class="article-summary-box-inner">
<span><p>This paper investigates personalization in the field of intelligent tutoring
systems (ITS). We hypothesize that personalization in the way questions are
asked improves student learning outcomes. Previous work on dialogue-based ITS
personalization has yet to address question phrasing. We show that generating
versions of the questions suitable for students at different levels of subject
proficiency improves student learning gains, using variants written by a domain
expert and an experimental A/B test. This insight demonstrates that the
linguistic realization of questions in an ITS affects the learning outcomes for
students.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Creation and Analysis of an International Corpus of Privacy Laws. (arXiv:2206.14169v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14169">
<div class="article-summary-box-inner">
<span><p>The landscape of privacy laws and regulations around the world is complex and
ever-changing. National and super-national laws, agreements, decrees, and other
government-issued rules form a patchwork that companies must follow to operate
internationally. To examine the status and evolution of this patchwork, we
introduce the Government Privacy Instructions Corpus, or GPI Corpus, of 1,043
privacy laws, regulations, and guidelines, covering 182 jurisdictions. This
corpus enables a large-scale quantitative and qualitative examination of legal
foci on privacy. We examine the temporal distribution of when GPIs were created
and illustrate the dramatic increase in privacy legislation over the past 50
years, although a finer-grained examination reveals that the rate of increase
varies depending on the personal data types that GPIs address. Our exploration
also demonstrates that most privacy laws respectively address relatively few
personal data types, showing that comprehensive privacy legislation remains
rare. Additionally, topic modeling results show the prevalence of common themes
in GPIs, such as finance, healthcare, and telecommunications. Finally, we
release the corpus to the research community to promote further study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The NLP Sandbox: an efficient model-to-data system to enable federated and unbiased evaluation of clinical NLP models. (arXiv:2206.14181v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14181">
<div class="article-summary-box-inner">
<span><p>Objective The evaluation of natural language processing (NLP) models for
clinical text de-identification relies on the availability of clinical notes,
which is often restricted due to privacy concerns. The NLP Sandbox is an
approach for alleviating the lack of data and evaluation frameworks for NLP
models by adopting a federated, model-to-data approach. This enables unbiased
federated model evaluation without the need for sharing sensitive data from
multiple institutions. Materials and Methods We leveraged the Synapse
collaborative framework, containerization software, and OpenAPI generator to
build the NLP Sandbox (nlpsandbox.io). We evaluated two state-of-the-art NLP
de-identification focused annotation models, Philter and NeuroNER, using data
from three institutions. We further validated model performance using data from
an external validation site. Results We demonstrated the usefulness of the NLP
Sandbox through de-identification clinical model evaluation. The external
developer was able to incorporate their model into the NLP Sandbox template and
provide user experience feedback. Discussion We demonstrated the feasibility of
using the NLP Sandbox to conduct a multi-site evaluation of clinical text
de-identification models without the sharing of data. Standardized model and
data schemas enable smooth model transfer and implementation. To generalize the
NLP Sandbox, work is required on the part of data owners and model developers
to develop suitable and standardized schemas and to adapt their data or model
to fit the schemas. Conclusions The NLP Sandbox lowers the barrier to utilizing
clinical data for NLP model evaluation and facilitates federated, multi-site,
unbiased evaluation of NLP models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cooperative Self-training of Machine Reading Comprehension. (arXiv:2103.07449v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07449">
<div class="article-summary-box-inner">
<span><p>Pretrained language models have significantly improved the performance of
downstream language understanding tasks, including extractive question
answering, by providing high-quality contextualized word embeddings. However,
training question answering models still requires large amounts of annotated
data for specific domains. In this work, we propose a cooperative self-training
framework, RGX, for automatically generating more non-trivial question-answer
pairs to improve model performance. RGX is built upon a masked answer
extraction task with an interactive learning environment containing an answer
entity Recognizer, a question Generator, and an answer eXtractor. Given a
passage with a masked entity, the generator generates a question around the
entity, and the extractor is trained to extract the masked entity with the
generated question and raw texts. The framework allows the training of question
generation and answering models on any text corpora without annotation.
Experiment results show that RGX outperforms the state-of-the-art (SOTA)
pretrained language models and transfer learning approaches on standard
question-answering benchmarks, and yields the new SOTA performance under given
model size and transfer learning settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Attribution in Dialogue Systems: The BEGIN Benchmark. (arXiv:2105.00071v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00071">
<div class="article-summary-box-inner">
<span><p>Knowledge-grounded dialogue systems powered by large language models often
generate responses that, while fluent, are not attributable to a relevant
source of information. Progress towards models that do not exhibit this issue
requires evaluation metrics that can quantify its prevalence. To this end, we
introduce the Benchmark for Evaluation of Grounded INteraction (BEGIN),
comprised of 12k dialogue turns generated by neural dialogue systems trained on
three knowledge-grounded dialogue corpora. We collect human annotations
assessing the extent to which the models' responses can be attributed to the
given background information. We then use BEGIN to analyze eight evaluation
metrics. We find that these metrics rely on spurious correlations, do not
reliably distinguish attributable abstractive responses from unattributable
ones, and perform substantially worse when the knowledge source is longer. Our
findings underscore the need for more sophisticated and robust evaluation
metrics for knowledge-grounded dialogue. We make BEGIN publicly available at
https://github.com/google/BEGIN-dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">gaBERT -- an Irish Language Model. (arXiv:2107.12930v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12930">
<div class="article-summary-box-inner">
<span><p>The BERT family of neural language models have become highly popular due to
their ability to provide sequences of text with rich context-sensitive token
encodings which are able to generalise well to many NLP tasks. We introduce
gaBERT, a monolingual BERT model for the Irish language. We compare our gaBERT
model to multilingual BERT and the monolingual Irish WikiBERT, and we show that
gaBERT provides better representations for a downstream parsing task. We also
show how different filtering criteria, vocabulary size and the choice of
subword tokenisation model affect downstream performance. We compare the
results of fine-tuning a gaBERT model with an mBERT model for the task of
identifying verbal multiword expressions, and show that the fine-tuned gaBERT
model also performs better at this task. We release gaBERT and related code to
the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimpleTRON: Simple Transformer with O(N) Complexity. (arXiv:2111.15588v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.15588">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose that the dot product pairwise matching attention
layer, which is widely used in Transformer-based models, is redundant for the
model performance. Attention, in its original formulation, has to be seen
rather as a human-level tool to explore and/or visualize relevancy scores in
sequential data. However, the way how it is constructed leads to significant
computational complexity. Instead, we present SimpleTRON: Simple Transformer
with O(N) Complexity, a simple and fast alternative without any approximation
that, unlike other approximation models, does not have any architecture-related
overhead and therefore can be seen as a purely linear Transformer-like model.
This architecture, to the best of our knowledge, outperforms existing
sub-quadratic attention approximation models on several tasks from the
Long-Range Arena benchmark. Moreover, we show, that SimpleTRON can benefit from
weight transfer from pretrained large language models, as its parameters can be
fully transferable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"Stop Asian Hate!" : Refining Detection of Anti-Asian Hate Speech During the COVID-19 Pandemic. (arXiv:2112.02265v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.02265">
<div class="article-summary-box-inner">
<span><p>Content warning: This work displays examples of explicit and/or strongly
offensive language. Fueled by a surge of anti-Asian xenophobia and prejudice
during the COVID-19 pandemic, many have taken to social media to express these
negative sentiments. Identifying these posts is crucial for moderation and
understanding the nature of hate in online spaces. In this paper, we create and
annotate a corpus of tweets to explore anti-Asian hate speech with a finer
level of granularity. Our analysis reveals that this emergent form of hate
speech often eludes established approaches. To address this challenge, we
develop a model and an accompanied efficient training regimen that incorporates
agreement between annotators. Our approach produces up to 8.8% improvement in
macro F1 scores over a strong established baseline, indicating its
effectiveness even in settings where consensus among annotators is low. We
demonstrate that we are able to identify hate speech that is systematically
missed by established hate speech detectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting potentially harmful and protective suicide-related content on twitter: A machine learning approach. (arXiv:2112.04796v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04796">
<div class="article-summary-box-inner">
<span><p>Research shows that exposure to suicide-related news media content is
associated with suicide rates, with some content characteristics likely having
harmful and others potentially protective effects. Although good evidence
exists for a few selected characteristics, systematic large scale
investigations are missing in general, and in particular for social media data.
We apply machine learning methods to classify large quantities of Twitter data
according to a novel annotation scheme that distinguishes 12 categories of
suicide-related tweets. We then trained a benchmark of machine learning models
including a majority classifier, an approach based on word frequency (TF-IDF
with a linear SVM) and two state-of-the-art deep learning models (BERT, XLNet).
The two deep learning models achieved the best performance in two
classification tasks: In the first task, we classified six main content
categories, including personal stories about either suicidal ideation and
attempts or coping, calls for action intending to spread either problem
awareness or prevention-related information, reporting of suicide cases, and
other tweets irrelevant to these categories. The deep learning models reached
accuracy scores above 73% on average across the six categories, and F1-scores
in between 0.70 and 0.85 for all but the suicidal ideation and attempts
category (0.51-0.55). In the second task, separating tweets referring to actual
suicide from off-topic tweets, they correctly labeled around 88% of tweets,
with BERT achieving F1-scores of 0.93 and 0.74 for the two categories,
respectively. These classification performances are comparable to the
state-of-the-art on similar tasks. By making data labeling more efficient, this
work has enabled large-scale investigations on harmful and protective
associations of social media content with suicide rates and help-seeking
behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What do Large Language Models Learn about Scripts?. (arXiv:2112.13834v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13834">
<div class="article-summary-box-inner">
<span><p>Script Knowledge (Schank and Abelson, 1975) has long been recognized as
crucial for language understanding as it can help in filling in unstated
information in a narrative. However, such knowledge is expensive to produce
manually and difficult to induce from text due to reporting bias (Gordon and
Van Durme, 2013). In this work, we are interested in the scientific question of
whether explicit script knowledge is present and accessible through pre-trained
generative language models (LMs). To this end, we introduce the task of
generating full event sequence descriptions (ESDs) given a scenario in the form
of natural language prompts. In zero-shot probing experiments, we find that
generative LMs produce poor ESDs with mostly omitted, irrelevant, repeated or
misordered events. To address this, we propose a pipeline-based script
induction framework (SIF) which can generate good quality ESDs for unseen
scenarios (e.g., bake a cake). SIF is a two-staged framework that fine-tunes LM
on a small set of ESD examples in the first stage. In the second stage, ESD
generated for an unseen scenario is post-processed using RoBERTa-based models
to filter irrelevant events, remove repetitions, and reorder the temporally
misordered events. Through automatic and manual evaluations, we demonstrate
that SIF yields substantial improvements ($1$-$3$ BLUE points) over a
fine-tuned LM. However, manual analysis shows that there is great room for
improvement, offering a new research direction for inducing script knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Semantic Embeddings for Ontology Subsumption Prediction. (arXiv:2202.09791v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09791">
<div class="article-summary-box-inner">
<span><p>Automating ontology curation is a crucial task in knowledge engineering.
Prediction by machine learning techniques such as semantic embedding is a
promising direction, but the relevant research is still preliminary. In this
paper, we present a class subsumption prediction method named BERTSubs, which
uses the pre-trained language model BERT to compute contextual embeddings of
the class labels and customized input templates to incorporate contexts of
surrounding classes. The evaluation on two large-scale real-world ontologies
has shown its better performance than the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-constraint Optimal Transport for Entity Alignment with Dangling Cases. (arXiv:2203.05744v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.05744">
<div class="article-summary-box-inner">
<span><p>Entity alignment (EA) merges knowledge graphs (KGs) by identifying the
equivalent entities in different graphs, which can effectively enrich knowledge
representations of KGs. However, in practice, different KGs often include
dangling entities whose counterparts cannot be found in the other graph, which
limits the performance of EA methods. To improve EA with dangling entities, we
propose an unsupervised method called Semi-constraint Optimal Transport for
Entity Alignment in Dangling cases (SoTead). Our main idea is to model the
entity alignment between two KGs as an optimal transport problem from one KG's
entities to the others. First, we set pseudo entity pairs between KGs based on
pretrained word embeddings. Then, we conduct contrastive metric learning to
obtain the transport cost between each entity pair. Finally, we introduce a
virtual entity for each KG to "align" the dangling entities from the other KGs,
which relaxes the optimization constraints and leads to a semi-constraint
optimal transport. In the experimental part, we first show the superiority of
SoTead on a commonly-used entity alignment dataset. Besides, to analyze the
ability for dangling entity detection with other baselines, we construct a
medical cross-lingual knowledge graph dataset, MedED, where our SoTead also
reaches state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mcBERT: Momentum Contrastive Learning with BERT for Zero-Shot Slot Filling. (arXiv:2203.12940v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12940">
<div class="article-summary-box-inner">
<span><p>Zero-shot slot filling has received considerable attention to cope with the
problem of limited available data for the target domain. One of the important
factors in zero-shot learning is to make the model learn generalized and
reliable representations. For this purpose, we present mcBERT, which stands for
momentum contrastive learning with BERT, to develop a robust zero-shot slot
filling model. mcBERT uses BERT to initialize the two encoders, the query
encoder and key encoder, and is trained by applying momentum contrastive
learning. Our experimental results on the SNIPS benchmark show that mcBERT
substantially outperforms the previous models, recording a new
state-of-the-art. Besides, we also show that each component composing mcBERT
contributes to the performance improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging unsupervised and weakly-supervised data to improve direct speech-to-speech translation. (arXiv:2203.13339v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.13339">
<div class="article-summary-box-inner">
<span><p>End-to-end speech-to-speech translation (S2ST) without relying on
intermediate text representations is a rapidly emerging frontier of research.
Recent works have demonstrated that the performance of such direct S2ST systems
is approaching that of conventional cascade S2ST when trained on comparable
datasets. However, in practice, the performance of direct S2ST is bounded by
the availability of paired S2ST training data. In this work, we explore
multiple approaches for leveraging much more widely available unsupervised and
weakly-supervised speech and text data to improve the performance of direct
S2ST based on Translatotron 2. With our most effective approaches, the average
translation quality of direct S2ST on 21 language pairs on the CVSS-C corpus is
improved by +13.6 BLEU (or +113% relatively), as compared to the previous
state-of-the-art trained without additional data. The improvements on
low-resource language are even more significant (+398% relatively on average).
Our comparative studies suggest future research directions for S2ST and speech
representation learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Rare Word Recognition with LM-aware MWER Training. (arXiv:2204.07553v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07553">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) significantly improve the recognition accuracy of
end-to-end (E2E) models on words rarely seen during training, when used in
either the shallow fusion or the rescoring setups. In this work, we introduce
LMs in the learning of hybrid autoregressive transducer (HAT) models in the
discriminative training framework, to mitigate the training versus inference
gap regarding the use of LMs. For the shallow fusion setup, we use LMs during
both hypotheses generation and loss computation, and the LM-aware MWER-trained
model achieves 10\% relative improvement over the model trained with standard
MWER on voice search test sets containing rare words. For the rescoring setup,
we learn a small neural module to generate per-token fusion weights in a
data-dependent manner. This model achieves the same rescoring WER as regular
MWER-trained model, but without the need for sweeping fusion weights.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UTNLP at SemEval-2022 Task 6: A Comparative Analysis of Sarcasm Detection Using Generative-based and Mutation-based Data Augmentation. (arXiv:2204.08198v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08198">
<div class="article-summary-box-inner">
<span><p>Sarcasm is a term that refers to the use of words to mock, irritate, or amuse
someone. It is commonly used on social media. The metaphorical and creative
nature of sarcasm presents a significant difficulty for sentiment analysis
systems based on affective computing. The methodology and results of our team,
UTNLP, in the SemEval-2022 shared task 6 on sarcasm detection are presented in
this paper. We put different models, and data augmentation approaches to the
test and report on which one works best. The tests begin with traditional
machine learning models and progress to transformer-based and attention-based
models. We employed data augmentation based on data mutation and data
generation. Using RoBERTa and mutation-based data augmentation, our best
approach achieved an F1-sarcastic of 0.38 in the competition's evaluation
phase. After the competition, we fixed our model's flaws and achieved an
F1-sarcastic of 0.414.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Unintended Memorization in Language-Model-Fused ASR. (arXiv:2204.09606v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.09606">
<div class="article-summary-box-inner">
<span><p>End-to-end (E2E) models are often being accompanied by language models (LMs)
via shallow fusion for boosting their overall quality as well as recognition of
rare words. At the same time, several prior works show that LMs are susceptible
to unintentionally memorizing rare or unique sequences in the training data. In
this work, we design a framework for detecting memorization of random textual
sequences (which we call canaries) in the LM training data when one has only
black-box (query) access to LM-fused speech recognizer, as opposed to direct
access to the LM. On a production-grade Conformer RNN-T E2E model fused with a
Transformer LM, we show that detecting memorization of singly-occurring
canaries from the LM training data of 300M examples is possible. Motivated to
protect privacy, we also show that such memorization gets significantly reduced
by per-example gradient-clipped LM training without compromising overall
quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Neural Open Information Extraction: Current Status and Future Directions. (arXiv:2205.11725v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11725">
<div class="article-summary-box-inner">
<span><p>Open Information Extraction (OpenIE) facilitates domain-independent discovery
of relational facts from large corpora. The technique well suits many
open-world natural language understanding scenarios, such as automatic
knowledge base construction, open-domain question answering, and explicit
reasoning. Thanks to the rapid development in deep learning technologies,
numerous neural OpenIE architectures have been proposed and achieve
considerable performance improvement. In this survey, we provide an extensive
overview of the-state-of-the-art neural OpenIE models, their key design
decisions, strengths and weakness. Then, we discuss limitations of current
solutions and the open issues in OpenIE problem itself. Finally we list recent
trends that could help expand its scope and applicability, setting up promising
directions for future research in OpenIE. To our best knowledge, this paper is
the first review on this specific topic.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-based computer-aided diagnostic system of chest digital tomography synthesis: Demonstrating comparative advantage with X-ray-based AI systems. (arXiv:2206.13504v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13504">
<div class="article-summary-box-inner">
<span><p>Compared with chest X-ray (CXR) imaging, which is a single image projected
from the front of the patient, chest digital tomosynthesis (CDTS) imaging can
be more advantageous for lung lesion detection because it acquires multiple
images projected from multiple angles of the patient. Various clinical
comparative analysis and verification studies have been reported to demonstrate
this, but there were no artificial intelligence (AI)-based comparative analysis
studies. Existing AI-based computer-aided detection (CAD) systems for lung
lesion diagnosis have been developed mainly based on CXR images; however,
CAD-based on CDTS, which uses multi-angle images of patients in various
directions, has not been proposed and verified for its usefulness compared to
CXR-based counterparts. This study develops/tests a CDTS-based AI CAD system to
detect lung lesions to demonstrate performance improvements compared to
CXR-based AI CAD. We used multiple projection images as input for the
CDTS-based AI model and a single-projection image as input for the CXR-based AI
model to fairly compare and evaluate the performance between models. The
proposed CDTS-based AI CAD system yielded sensitivities of 0.782 and 0.785 and
accuracies of 0.895 and 0.837 for the performance of detecting tuberculosis and
pneumonia, respectively, against normal subjects. These results show higher
performance than sensitivities of 0.728 and 0.698 and accuracies of 0.874 and
0.826 for detecting tuberculosis and pneumonia through the CXR-based AI CAD,
which only uses a single projection image in the frontal direction. We found
that CDTS-based AI CAD improved the sensitivity of tuberculosis and pneumonia
by 5.4% and 8.7% respectively, compared to CXR-based AI CAD without loss of
accuracy. Therefore, we comparatively prove that CDTS-based AI CAD technology
can improve performance more than CXR, enhancing the clinical applicability of
CDTS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning-Based Defect Classification and Detection in SEM Images. (arXiv:2206.13505v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13505">
<div class="article-summary-box-inner">
<span><p>This proposes a novel ensemble deep learning-based model to accurately
classify, detect and localize different defect categories for aggressive
pitches and thin resists (High NA applications).In particular, we train
RetinaNet models using different ResNet, VGGNet architectures as backbone and
present the comparison between the accuracies of these models and their
performance analysis on SEM images with different types of defect patterns such
as bridge, break and line collapses. Finally, we propose a preference-based
ensemble strategy to combine the output predictions from different models in
order to achieve better performance on classification and detection of defects.
As CDSEM images inherently contain a significant level of noise, detailed
feature information is often shadowed by noise. For certain resist profiles,
the challenge is also to differentiate between a microbridge, footing, break,
and zones of probable breaks. Therefore, we have applied an unsupervised
machine learning model to denoise the SEM images to remove the False-Positive
defects and optimize the effect of stochastic noise on structured pixels for
better metrology and enhanced defect inspection. We repeated the defect
inspection step with the same trained model and performed a comparative
analysis for "robustness" and "accuracy" metric with conventional approach for
both noisy/denoised image pair. The proposed ensemble method demonstrates
improvement of the average precision metric (mAP) of the most difficult defect
classes. In this work we have developed a novel robust supervised deep learning
training scheme to accurately classify as well as localize different defect
types in SEM images with high degree of accuracy. Our proposed approach
demonstrates its effectiveness both quantitatively and qualitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tensor Recovery Based on A Novel Non-convex Function Minimax Logarithmic Concave Penalty Function. (arXiv:2206.13506v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13506">
<div class="article-summary-box-inner">
<span><p>Non-convex relaxation methods have been widely used in tensor recovery
problems, and compared with convex relaxation methods, can achieve better
recovery results. In this paper, a new non-convex function, Minimax Logarithmic
Concave Penalty (MLCP) function, is proposed, and some of its intrinsic
properties are analyzed, among which it is interesting to find that the
Logarithmic function is an upper bound of the MLCP function. The proposed
function is generalized to tensor cases, yielding tensor MLCP and weighted
tensor $L\gamma$-norm. Consider that its explicit solution cannot be obtained
when applying it directly to the tensor recovery problem. Therefore, the
corresponding equivalence theorems to solve such problem are given, namely,
tensor equivalent MLCP theorem and equivalent weighted tensor $L\gamma$-norm
theorem. In addition, we propose two EMLCP-based models for classic tensor
recovery problems, namely low-rank tensor completion (LRTC) and tensor robust
principal component analysis (TRPCA), and design proximal alternate
linearization minimization (PALM) algorithms to solve them individually.
Furthermore, based on the Kurdyka-{\L}ojasiwicz property, it is proved that the
solution sequence of the proposed algorithm has finite length and converges to
the critical point globally. Finally, Extensive experiments show that proposed
algorithm achieve good results, and it is confirmed that the MLCP function is
indeed better than the Logarithmic function in the minimization problem, which
is consistent with the analysis of theoretical properties.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parameter-Efficient Image-to-Video Transfer Learning. (arXiv:2206.13559v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13559">
<div class="article-summary-box-inner">
<span><p>Capitalizing on large pre-trained models for various downstream tasks of
interest have recently emerged with promising performance. Due to the
ever-growing model size, the standard full fine-tuning based task adaptation
strategy becomes prohibitively costly in terms of model training and storage.
This has led to a new research direction in parameter-efficient transfer
learning. However, existing attempts typically focus on downstream tasks from
the same modality (e.g., image understanding) of the pre-trained model. This
creates a limit because in some specific modalities, (e.g., video
understanding) such a strong pre-trained model with sufficient knowledge is
less or not available. In this work, we investigate such a novel cross-modality
transfer learning setting, namely parameter-efficient image-to-video transfer
learning. To solve this problem, we propose a new Spatio-Temporal Adapter
(ST-Adapter) for parameter-efficient fine-tuning per video task. With a
built-in spatio-temporal reasoning capability in a compact design, ST-Adapter
enables a pre-trained image model without temporal knowledge to reason about
dynamic video content at a small (~8%) per-task parameter cost, requiring
approximately 20 times fewer updated parameters compared to previous work.
Extensive experiments on video action recognition tasks show that our
ST-Adapter can match or even outperform the strong full fine-tuning strategy
and state-of-the-art video models, whilst enjoying the advantage of parameter
efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A View Independent Classification Framework for Yoga Postures. (arXiv:2206.13577v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13577">
<div class="article-summary-box-inner">
<span><p>Yoga is a globally acclaimed and widely recommended practice for a healthy
living. Maintaining correct posture while performing a Yogasana is of utmost
importance. In this work, we employ transfer learning from Human Pose
Estimation models for extracting 136 key-points spread all over the body to
train a Random Forest classifier which is used for estimation of the Yogasanas.
The results are evaluated on an in-house collected extensive yoga video
database of 51 subjects recorded from 4 different camera angles. We propose a 3
step scheme for evaluating the generalizability of a Yoga classifier by testing
it on 1) unseen frames, 2) unseen subjects, and 3) unseen camera angles. We
argue that for most of the applications, validation accuracies on unseen
subjects and unseen camera angles would be most important. We empirically
analyze over three public datasets, the advantage of transfer learning and the
possibilities of target leakage. We further demonstrate that the classification
accuracies critically depend on the cross validation method employed and can
often be misleading. To promote further research, we have made key-points
dataset and code publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuRIS: Neural Reconstruction of Indoor Scenes Using Normal Priors. (arXiv:2206.13597v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13597">
<div class="article-summary-box-inner">
<span><p>Reconstructing 3D indoor scenes from 2D images is an important task in many
computer vision and graphics applications. A main challenge in this task is
that large texture-less areas in typical indoor scenes make existing methods
struggle to produce satisfactory reconstruction results. We propose a new
method, named NeuRIS, for high quality reconstruction of indoor scenes. The key
idea of NeuRIS is to integrate estimated normal of indoor scenes as a prior in
a neural rendering framework for reconstructing large texture-less shapes and,
importantly, to do this in an adaptive manner to also enable the reconstruction
of irregular shapes with fine details. Specifically, we evaluate the
faithfulness of the normal priors on-the-fly by checking the multi-view
consistency of reconstruction during the optimization process. Only the normal
priors accepted as faithful will be utilized for 3D reconstruction, which
typically happens in the regions of smooth shapes possibly with weak texture.
However, for those regions with small objects or thin structures, for which the
normal priors are usually unreliable, we will only rely on visual features of
the input images, since such regions typically contain relatively rich visual
features (e.g., shade changes and boundary contours). Extensive experiments
show that NeuRIS significantly outperforms the state-of-the-art methods in
terms of reconstruction quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing Annotation Need in Self-Explanatory Models for Lung Nodule Diagnosis. (arXiv:2206.13608v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13608">
<div class="article-summary-box-inner">
<span><p>Feature-based self-explanatory methods explain their classification in terms
of human-understandable features. In the medical imaging community, this
semantic matching of clinical knowledge adds significantly to the
trustworthiness of the AI. However, the cost of additional annotation of
features remains a pressing issue. We address this problem by proposing
cRedAnno, a data-/annotation-efficient self-explanatory approach for lung
nodule diagnosis. cRedAnno considerably reduces the annotation need by
introducing self-supervised contrastive learning to alleviate the burden of
learning most parameters from annotation, replacing end-to-end training with
two-stage training. When training with hundreds of nodule samples and only 1%
of their annotations, cRedAnno achieves competitive accuracy in predicting
malignancy, meanwhile significantly surpassing most previous works in
predicting nodule attributes. Visualisation of the learned space further
indicates that the correlation between the clustering of malignancy and nodule
attributes coincides with clinical knowledge. Our complete code is open-source
available: https://github.com/ludles/credanno.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flexible-Rate Learned Hierarchical Bi-Directional Video Compression With Motion Refinement and Frame-Level Bit Allocation. (arXiv:2206.13613v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13613">
<div class="article-summary-box-inner">
<span><p>This paper presents improvements and novel additions to our recent work on
end-to-end optimized hierarchical bi-directional video compression to further
advance the state-of-the-art in learned video compression. As an improvement,
we combine motion estimation and prediction modules and compress refined
residual motion vectors for improved rate-distortion performance. As novel
addition, we adapted the gain unit proposed for image compression to
flexible-rate video compression in two ways: first, the gain unit enables a
single encoder model to operate at multiple rate-distortion operating points;
second, we exploit the gain unit to control bit allocation among intra-coded
vs. bi-directionally coded frames by fine tuning corresponding models for truly
flexible-rate learned video coding. Experimental results demonstrate that we
obtain state-of-the-art rate-distortion performance exceeding those of all
prior art in learned video coding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Patch Selection for Melanoma Classification. (arXiv:2206.13626v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13626">
<div class="article-summary-box-inner">
<span><p>In medical image processing, the most important information is often located
on small parts of the image. Patch-based approaches aim at using only the most
relevant parts of the image. Finding ways to automatically select the patches
is a challenge. In this paper, we investigate two criteria to choose patches:
entropy and a spectral similarity criterion. We perform experiments at
different levels of patch size. We train a Convolutional Neural Network on the
subsets of patches and analyze the training time. We find that, in addition to
requiring less preprocessing time, the classifiers trained on the datasets of
patches selected based on entropy converge faster than on those selected based
on the spectral similarity criterion and, furthermore, lead to higher accuracy.
Moreover, patches of high entropy lead to faster convergence and better
accuracy than patches of low entropy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-scale Network with Attentional Multi-resolution Fusion for Point Cloud Semantic Segmentation. (arXiv:2206.13628v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13628">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a comprehensive point cloud semantic segmentation
network that aggregates both local and global multi-scale information. First,
we propose an Angle Correlation Point Convolution (ACPConv) module to
effectively learn the local shapes of points. Second, based upon ACPConv, we
introduce a local multi-scale split (MSS) block that hierarchically connects
features within one single block and gradually enlarges the receptive field
which is beneficial for exploiting the local context. Third, inspired by HRNet
which has excellent performance on 2D image vision tasks, we build an HRNet
customized for point cloud to learn global multi-scale context. Lastly, we
introduce a point-wise attention fusion approach that fuses multi-resolution
predictions and further improves point cloud semantic segmentation performance.
Our experimental results and ablations on several benchmark datasets show that
our proposed method is effective and able to achieve state-of-the-art
performances compared to existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward an ImageNet Library of Functions for Global Optimization Benchmarking. (arXiv:2206.13630v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13630">
<div class="article-summary-box-inner">
<span><p>Knowledge of search-landscape features of BlackBox Optimization (BBO)
problems offers valuable information in light of the Algorithm Selection and/or
Configuration problems. Exploratory Landscape Analysis (ELA) models have gained
success in identifying predefined human-derived features and in facilitating
portfolio selectors to address those challenges. Unlike ELA approaches, the
current study proposes to transform the identification problem into an image
recognition problem, with a potential to detect conception-free, machine-driven
landscape features. To this end, we introduce the notion of Landscape Images,
which enables us to generate imagery instances per a benchmark function, and
then target the classification challenge over a diverse generalized dataset of
functions. We address it as a supervised multi-class image recognition problem
and apply basic artificial neural network models to solve it. The efficacy of
our approach is numerically validated on the noise free BBOB and IOHprofiler
benchmarking suites. This evident successful learning is another step toward
automated feature extraction and local structure deduction of BBO problems. By
using this definition of landscape images, and by capitalizing on existing
capabilities of image recognition algorithms, we foresee the construction of an
ImageNet-like library of functions for training generalized detectors that rely
on machine-driven features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Omni-Seg+: A Scale-aware Dynamic Network for Pathological Image Segmentation. (arXiv:2206.13632v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13632">
<div class="article-summary-box-inner">
<span><p>Comprehensive semantic segmentation on renal pathological images is
challenging due to the heterogeneous scales of the objects. For example, on a
whole slide image (WSI), the cross-sectional areas of glomeruli can be 64 times
larger than that of the peritubular capillaries, making it impractical to
segment both objects on the same patch, at the same scale. To handle this
scaling issue, prior studies have typically trained multiple segmentation
networks in order to match the optimal pixel resolution of heterogeneous tissue
types. This multi-network solution is resource-intensive and fails to model the
spatial relationship between tissue types. In this paper, we propose the
Omni-Seg+ network, a scale-aware dynamic neural network that achieves
multi-object (six tissue types) and multi-scale (5X to 40X scale) pathological
image segmentation via a single neural network. The contribution of this paper
is three-fold: (1) a novel scale-aware controller is proposed to generalize the
dynamic neural network from single-scale to multi-scale; (2) semi-supervised
consistency regularization of pseudo-labels is introduced to model the
inter-scale correlation of unannotated tissue types into a single end-to-end
learning paradigm; and (3) superior scale-aware generalization is evidenced by
directly applying a model trained on human kidney images to mouse kidney
images, without retraining. By learning from ~150,000 human pathological image
patches from six tissue types at three different resolutions, our approach
achieved superior segmentation performance according to human visual assessment
and evaluation of image-omics (i.e., spatial transcriptomics). The official
implementation is available at https://github.com/ddrrnn123/Omni-Seg.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature Refinement to Improve High Resolution Image Inpainting. (arXiv:2206.13644v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13644">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the problem of degradation in inpainting quality of
neural networks operating at high resolutions. Inpainting networks are often
unable to generate globally coherent structures at resolutions higher than
their training set. This is partially attributed to the receptive field
remaining static, despite an increase in image resolution. Although downscaling
the image prior to inpainting produces coherent structure, it inherently lacks
detail present at higher resolutions. To get the best of both worlds, we
optimize the intermediate featuremaps of a network by minimizing a multiscale
consistency loss at inference. This runtime optimization improves the
inpainting results and establishes a new state-of-the-art for high resolution
inpainting. Code is available at:
https://github.com/geomagical/lama-with-refiner/tree/refinement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Many Events do You Need? Event-based Visual Place Recognition Using Sparse But Varying Pixels. (arXiv:2206.13673v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13673">
<div class="article-summary-box-inner">
<span><p>Event cameras continue to attract interest due to desirable characteristics
such as high dynamic range, low latency, virtually no motion blur, and high
energy efficiency. One of the potential applications of event camera research
lies in visual place recognition for robot localization, where a query
observation has to be matched to the corresponding reference place in the
database. In this letter, we explore the distinctiveness of event streams from
a small subset of pixels (in the tens or hundreds). We demonstrate that the
absolute difference in the number of events at those pixel locations
accumulated into event frames can be sufficient for the place recognition task,
when pixels that display large variations in the reference set are used. Using
such sparse (over image coordinates) but varying (variance over the number of
events per pixel location) pixels enables frequent and computationally cheap
updates of the location estimates. Furthermore, when event frames contain a
constant number of events, our method takes full advantage of the event-driven
nature of the sensory stream and displays promising robustness to changes in
velocity. We evaluate our proposed approach on the Brisbane-Event-VPR dataset
in an outdoor driving scenario, as well as the newly contributed indoor
QCR-Event-VPR dataset that was captured with a DAVIS346 camera mounted on a
mobile robotic platform. Our results show that our approach achieves
competitive performance when compared to several baseline methods on those
datasets, and is particularly well suited for compute- and energy-constrained
platforms such as interplanetary rovers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Global-Scale Crowd+AI Techniques to Map and Assess Sidewalks for People with Disabilities. (arXiv:2206.13677v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13677">
<div class="article-summary-box-inner">
<span><p>There is a lack of data on the location, condition, and accessibility of
sidewalks across the world, which not only impacts where and how people travel
but also fundamentally limits interactive mapping tools and urban analytics. In
this paper, we describe initial work in semi-automatically building a sidewalk
network topology from satellite imagery using hierarchical multi-scale
attention models, inferring surface materials from street-level images using
active learning-based semantic segmentation, and assessing sidewalk condition
and accessibility features using Crowd+AI. We close with a call to create a
database of labeled satellite and streetscape scenes for sidewalks and sidewalk
accessibility issues along with standardized benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">POEM: Out-of-Distribution Detection with Posterior Sampling. (arXiv:2206.13687v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13687">
<div class="article-summary-box-inner">
<span><p>Out-of-distribution (OOD) detection is indispensable for machine learning
models deployed in the open world. Recently, the use of an auxiliary outlier
dataset during training (also known as outlier exposure) has shown promising
performance. As the sample space for potential OOD data can be prohibitively
large, sampling informative outliers is essential. In this work, we propose a
novel posterior sampling-based outlier mining framework, POEM, which
facilitates efficient use of outlier data and promotes learning a compact
decision boundary between ID and OOD data for improved detection. We show that
POEM establishes state-of-the-art performance on common benchmarks. Compared to
the current best method that uses a greedy sampling strategy, POEM improves the
relative performance by 42.0% and 24.2% (FPR95) on CIFAR-10 and CIFAR-100,
respectively. We further provide theoretical insights on the effectiveness of
POEM for OOD detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Third Place Solution for CVPR2022 AVA Accessibility Vision and Autonomy Challenge. (arXiv:2206.13718v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13718">
<div class="article-summary-box-inner">
<span><p>The goal of AVA challenge is to provide vision-based benchmarks and methods
relevant to accessibility. In this paper, we introduce the technical details of
our submission to the CVPR2022 AVA Challenge. Firstly, we conducted some
experiments to help employ proper model and data augmentation strategy for this
task. Secondly, an effective training strategy was applied to improve the
performance. Thirdly, we integrated the results from two different segmentation
frameworks to improve the performance further. Experimental results demonstrate
that our approach can achieve a competitive result on the AVA test set.
Finally, our approach achieves 63.008\%AP@0.50:0.95 on the test set of CVPR2022
AVA Challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting R-CNN: Reweighting R-CNN Samples by RPN's Error for Underwater Object Detection. (arXiv:2206.13728v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13728">
<div class="article-summary-box-inner">
<span><p>Complicated underwater environments bring new challenges to object detection,
such as unbalanced light conditions, low contrast, occlusion, and mimicry of
aquatic organisms. Under these circumstances, the objects captured by the
underwater camera will become vague, and the generic detectors often fail on
these vague objects. This work aims to solve the problem from two perspectives:
uncertainty modeling and hard example mining. We propose a two-stage underwater
detector named boosting R-CNN, which comprises three key components. First, a
new region proposal network named RetinaRPN is proposed, which provides
high-quality proposals and considers objectness and IoU prediction for
uncertainty to model the object prior probability. Second, the probabilistic
inference pipeline is introduced to combine the first-stage prior uncertainty
and the second-stage classification score to model the final detection score.
Finally, we propose a new hard example mining method named boosting
reweighting. Specifically, when the region proposal network miscalculates the
object prior probability for a sample, boosting reweighting will increase the
classification loss of the sample in the R-CNN head during training, while
reducing the loss of easy samples with accurately estimated priors. Thus, a
robust detection head in the second stage can be obtained. During the inference
stage, the R-CNN has the capability to rectify the error of the first stage to
improve the performance. Comprehensive experiments on two underwater datasets
and two generic object detection datasets demonstrate the effectiveness and
robustness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Survey on Deep Gait Recognition: Algorithms, Datasets and Challenges. (arXiv:2206.13732v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13732">
<div class="article-summary-box-inner">
<span><p>Gait recognition aims at identifying a person at a distance through visual
cameras. With the emergence of deep learning, significant advancements in gait
recognition have achieved inspiring success in many scenarios by utilizing deep
learning techniques. Nevertheless, the increasing need for video surveillance
introduces more challenges, including robust recognition under various
variances, modeling motion information in gait sequences, unfair performance
comparison due to protocol variances, biometrics security, and privacy
prevention. This paper provides a comprehensive survey of deep learning for
gait recognition. We first present the odyssey of gait recognition from
traditional algorithms to deep models, providing explicit knowledge of the
whole workflow of a gait recognition system. Then deep learning for gait
recognition is discussed from the perspective of deep representations and
architecture with an in-depth summary. Specifically, deep gait representations
are categorized into static and dynamic features, while deep architectures
include single-stream and multi-stream architecture. Following our proposed
taxonomy with novelty, it can be beneficial for providing inspiration and
promoting the perception of deep gait recognition. Besides, we also present a
comprehensive summary of all vision-based gait datasets and the performance
analysis. Finally, the article discusses some open issues with significant
potential prospects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Consistency for Single Domain Generalization in Medical Image Segmentation. (arXiv:2206.13737v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13737">
<div class="article-summary-box-inner">
<span><p>An organ segmentation method that can generalize to unseen contrasts and
scanner settings can significantly reduce the need for retraining of deep
learning models. Domain Generalization (DG) aims to achieve this goal. However,
most DG methods for segmentation require training data from multiple domains
during training. We propose a novel adversarial domain generalization method
for organ segmentation trained on data from a \emph{single} domain. We
synthesize the new domains via learning an adversarial domain synthesizer (ADS)
and presume that the synthetic domains cover a large enough area of plausible
distributions so that unseen domains can be interpolated from synthetic
domains. We propose a mutual information regularizer to enforce the semantic
consistency between images from the synthetic domains, which can be estimated
by patch-level contrastive learning. We evaluate our method for various organ
segmentation for unseen modalities, scanning protocols, and scanner sites.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAN-based Super-Resolution and Segmentation of Retinal Layers in Optical coherence tomography Scans. (arXiv:2206.13740v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13740">
<div class="article-summary-box-inner">
<span><p>In this paper, we design a Generative Adversarial Network (GAN)-based
solution for super-resolution and segmentation of optical coherence tomography
(OCT) scans of the retinal layers. OCT has been identified as a non-invasive
and inexpensive modality of imaging to discover potential biomarkers for the
diagnosis and progress determination of neurodegenerative diseases, such as
Alzheimer's Disease (AD). Current hypotheses presume the thickness of the
retinal layers, which are analyzable within OCT scans, can be effective
biomarkers. As a logical first step, this work concentrates on the challenging
task of retinal layer segmentation and also super-resolution for higher clarity
and accuracy. We propose a GAN-based segmentation model and evaluate
incorporating popular networks, namely, U-Net and ResNet, in the GAN
architecture with additional blocks of transposed convolution and sub-pixel
convolution for the task of upscaling OCT images from low to high resolution by
a factor of four. We also incorporate the Dice loss as an additional
reconstruction loss term to improve the performance of this joint optimization
task. Our best model configuration empirically achieved the Dice coefficient of
0.867 and mIOU of 0.765.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Multi-Object Tracking with Differentiable Pose Estimation. (arXiv:2206.13785v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13785">
<div class="article-summary-box-inner">
<span><p>We propose a novel approach for joint 3D multi-object tracking and
reconstruction from RGB-D sequences in indoor environments. To this end, we
detect and reconstruct objects in each frame while predicting dense
correspondences mappings into a normalized object space. We leverage those
correspondences to inform a graph neural network to solve for the optimal,
temporally-consistent 7-DoF pose trajectories of all objects. The novelty of
our method is two-fold: first, we propose a new graph-based approach for
differentiable pose estimation over time to learn optimal pose trajectories;
second, we present a joint formulation of reconstruction and pose estimation
along the time axis for robust and geometrically consistent multi-object
tracking. In order to validate our approach, we introduce a new synthetic
dataset comprising 2381 unique indoor sequences with a total of 60k rendered
RGB-D images for multi-object tracking with moving objects and camera positions
derived from the synthetic 3D-FRONT dataset. We demonstrate that our method
improves the accumulated MOTA score for all test sequences by 24.8% over
existing state-of-the-art methods. In several ablations on synthetic and
real-world sequences, we show that our graph-based, fully end-to-end-learnable
approach yields a significant boost in tracking performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FedRare: Federated Learning with Intra- and Inter-Client Contrast for Effective Rare Disease Classification. (arXiv:2206.13803v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13803">
<div class="article-summary-box-inner">
<span><p>Federated learning (FL), enabling different medical institutions or clients
to train a model collaboratively without data privacy leakage, has drawn great
attention in medical imaging communities recently. Though inter-client data
heterogeneity has been thoroughly studied, the class imbalance problem due to
the existence of rare diseases still is under-explored. In this paper, we
propose a novel FL framework FedRare for medical image classification
especially on dealing with data heterogeneity with the existence of rare
diseases. In FedRare, each client trains a model locally to extract
highly-separable latent features for classification via intra-client supervised
contrastive learning. Considering the limited data on rare diseases, we build
positive sample queues for augmentation (i.e. data re-sampling). The server in
FedRare would collect the latent features from clients and automatically select
the most reliable latent features as guidance sent back to clients. Then, each
client is jointly trained by an inter-client contrastive loss to align its
latent features to the federated latent features of full classes. In this way,
the parameter/feature variances across clients are effectively minimized,
leading to better convergence and performance improvements. Experimental
results on the publicly-available dataset for skin lesion diagnosis demonstrate
FedRare's superior performance. Under the 10-client federated setting where
four clients have no rare disease samples, FedRare achieves an average increase
of 9.60% and 5.90% in balanced accuracy compared to the baseline framework
FedAvg and the state-of-the-art approach FedIRM respectively. Considering the
board existence of rare diseases in clinical scenarios, we believe FedRare
would benefit future FL framework design for medical image classification. The
source code of this paper is publicly available at
https://github.com/wnn2000/FedRare.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Forgery Analysis of Vision Transformers and CNNs for Deepfake Image Detection. (arXiv:2206.13829v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13829">
<div class="article-summary-box-inner">
<span><p>Deepfake Generation Techniques are evolving at a rapid pace, making it
possible to create realistic manipulated images and videos and endangering the
serenity of modern society. The continual emergence of new and varied
techniques brings with it a further problem to be faced, namely the ability of
deepfake detection models to update themselves promptly in order to be able to
identify manipulations carried out using even the most recent methods. This is
an extremely complex problem to solve, as training a model requires large
amounts of data, which are difficult to obtain if the deepfake generation
method is too recent. Moreover, continuously retraining a network would be
unfeasible. In this paper, we ask ourselves if, among the various deep learning
techniques, there is one that is able to generalise the concept of deepfake to
such an extent that it does not remain tied to one or more specific deepfake
generation methods used in the training set. We compared a Vision Transformer
with an EfficientNetV2 on a cross-forgery context based on the ForgeryNet
dataset. From our experiments, It emerges that EfficientNetV2 has a greater
tendency to specialize often obtaining better results on training methods while
Vision Transformers exhibit a superior generalization ability that makes them
more competent even on images generated with new methodologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When the Sun Goes Down: Repairing Photometric Losses for All-Day Depth Estimation. (arXiv:2206.13850v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13850">
<div class="article-summary-box-inner">
<span><p>Self-supervised deep learning methods for joint depth and ego-motion
estimation can yield accurate trajectories without needing ground-truth
training data. However, as they typically use photometric losses, their
performance can degrade significantly when the assumptions these losses make
(e.g. temporal illumination consistency, a static scene, and the absence of
noise and occlusions) are violated. This limits their use for e.g. nighttime
sequences, which tend to contain many point light sources (including on dynamic
objects) and low signal-to-noise ratio (SNR) in darker image regions. In this
paper, we show how to use a combination of three techniques to allow the
existing photometric losses to work for both day and nighttime images. First,
we introduce a per-pixel neural intensity transformation to compensate for the
light changes that occur between successive frames. Second, we predict a
per-pixel residual flow map that we use to correct the reprojection
correspondences induced by the estimated ego-motion and depth from the
networks. And third, we denoise the training images to improve the robustness
and accuracy of our approach. These changes allow us to train a single model
for both day and nighttime images without needing separate encoders or extra
feature networks like existing methods. We perform extensive experiments and
ablation studies on the challenging Oxford RobotCar dataset to demonstrate the
efficacy of our approach for both day and nighttime sequences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate and Real-time Pseudo Lidar Detection: Is Stereo Neural Network Really Necessary?. (arXiv:2206.13858v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13858">
<div class="article-summary-box-inner">
<span><p>The proposal of Pseudo-Lidar representation has significantly narrowed the
gap between visual-based and active Lidar-based 3D object detection. However,
current researches exclusively focus on pushing the accuracy improvement of
Pseudo-Lidar by taking the advantage of complex and time-consuming neural
networks. Seldom explore the profound characteristics of Pseudo-Lidar
representation to obtain the promoting opportunities. In this paper, we dive
deep into the pseudo Lidar representation and argue that the performance of 3D
object detection is not fully dependent on the high precision stereo depth
estimation. We demonstrate that even for the unreliable depth estimation, with
proper data processing and refining, it can achieve comparable 3D object
detection accuracy. With this finding, we further show the possibility that
utilizing fast but inaccurate stereo matching algorithms in the Pseudo-Lidar
system to achieve low latency responsiveness. In the experiments, we develop a
system with a less powerful stereo matching predictor and adopt the proposed
refinement schemes to improve the accuracy. The evaluation on the KITTI
benchmark shows that the presented system achieves competitive accuracy to the
state-of-the-art approaches with only 23 ms computing, showing it is a suitable
candidate for deploying to real car-hold applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling Embedding Spaces with Minimal Distributional Assumptions. (arXiv:2206.13872v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13872">
<div class="article-summary-box-inner">
<span><p>Interest in understanding and factorizing learned embedding spaces is
growing. For instance, recent concept-based explanation techniques analyze a
machine learning model in terms of interpretable latent components. Such
components have to be discovered in the model's embedding space, e.g., through
independent component analysis (ICA) or modern disentanglement learning
techniques. While these unsupervised approaches offer a sound formal framework,
they either require access to a data generating function or impose rigid
assumptions on the data distribution, such as independence of components, that
are often violated in practice. In this work, we link conceptual explainability
for vision models with disentanglement learning and ICA. This enables us to
provide first theoretical results on how components can be identified without
requiring any distributional assumptions. From these insights, we derive the
disjoint attributions (DA) concept discovery method that is applicable to a
broader class of problems than current approaches but yet possesses a formal
identifiability guarantee. In an extensive comparison against component
analysis and over 300 state-of-the-art disentanglement models, DA stably
maintains superior performance, even under varying distributions and
correlation strengths.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Worst Case Visual Localization Coverage via Place-specific Sub-selection in Multi-camera Systems. (arXiv:2206.13883v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13883">
<div class="article-summary-box-inner">
<span><p>6-DoF visual localization systems utilize principled approaches rooted in 3D
geometry to perform accurate camera pose estimation of images to a map. Current
techniques use hierarchical pipelines and learned 2D feature extractors to
improve scalability and increase performance. However, despite gains in typical
recall@0.25m type metrics, these systems still have limited utility for
real-world applications like autonomous vehicles because of their `worst' areas
of performance - the locations where they provide insufficient recall at a
certain required error tolerance. Here we investigate the utility of using
`place specific configurations', where a map is segmented into a number of
places, each with its own configuration for modulating the pose estimation
step, in this case selecting a camera within a multi-camera system. On the Ford
AV benchmark dataset, we demonstrate substantially improved worst-case
localization performance compared to using off-the-shelf pipelines - minimizing
the percentage of the dataset which has low recall at a certain error
tolerance, as well as improved overall localization performance. Our proposed
approach is particularly applicable to the crowdsharing model of autonomous
vehicle deployment, where a fleet of AVs are regularly traversing a known
route.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating near-infrared facial expression datasets with dimensional affect labels. (arXiv:2206.13887v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13887">
<div class="article-summary-box-inner">
<span><p>Facial expression analysis has long been an active research area of computer
vision. Traditional methods mainly analyse images for prototypical discrete
emotions; as a result, they do not provide an accurate depiction of the complex
emotional states in humans. Furthermore, illumination variance remains a
challenge for face analysis in the visible light spectrum. To address these
issues, we propose using a dimensional model based on valence and arousal to
represent a wider range of emotions, in combination with near infra-red (NIR)
imagery, which is more robust to illumination changes. Since there are no
existing NIR facial expression datasets with valence-arousal labels available,
we present two complementary data augmentation methods (face morphing and
CycleGAN approach) to create NIR image datasets with dimensional emotion labels
from existing categorical and/or visible-light datasets. Our experiments show
that these generated NIR datasets are comparable to existing datasets in terms
of data quality and baseline prediction performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AS-IntroVAE: Adversarial Similarity Distance Makes Robust IntroVAE. (arXiv:2206.13903v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13903">
<div class="article-summary-box-inner">
<span><p>Recently, introspective models like IntroVAE and S-IntroVAE have excelled in
image generation and reconstruction tasks. The principal characteristic of
introspective models is the adversarial learning of VAE, where the encoder
attempts to distinguish between the real and the fake (i.e., synthesized)
images. However, due to the unavailability of an effective metric to evaluate
the difference between the real and the fake images, the posterior collapse and
the vanishing gradient problem still exist, reducing the fidelity of the
synthesized images. In this paper, we propose a new variation of IntroVAE
called Adversarial Similarity Distance Introspective Variational Autoencoder
(AS-IntroVAE). We theoretically analyze the vanishing gradient problem and
construct a new Adversarial Similarity Distance (AS-Distance) using the
2-Wasserstein distance and the kernel trick. With weight annealing on
AS-Distance and KL-Divergence, the AS-IntroVAE are able to generate stable and
high-quality images. The posterior collapse problem is addressed by making
per-batch attempts to transform the image so that it better fits the prior
distribution in the latent space. Compared with the per-image approach, this
strategy fosters more diverse distributions in the latent space, allowing our
model to produce images of great diversity. Comprehensive experiments on
benchmark datasets demonstrate the effectiveness of AS-IntroVAE on image
generation and reconstruction tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discrete Morse Sandwich: Fast Computation of Persistence Diagrams for Scalar Data -- An Algorithm and A Benchmark. (arXiv:2206.13932v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13932">
<div class="article-summary-box-inner">
<span><p>This paper introduces an efficient algorithm for persistence diagram
computation, given an input piecewise linear scalar field f defined on a
d-dimensional simplicial complex K, with $d \leq 3$. Our method extends the
seminal "PairCells" algorithm by introducing three main accelerations. First,
we express this algorithm within the setting of discrete Morse theory, which
considerably reduces the number of input simplices to consider. Second, we
introduce a stratification approach to the problem, that we call "sandwiching".
Specifically, minima-saddle persistence pairs ($D_0(f)$) and saddle-maximum
persistence pairs ($D_{d-1}(f)$) are efficiently computed by respectively
processing with a Union-Find the unstable sets of 1-saddles and the stable sets
of (d-1)-saddles. This fast processing of the dimensions 0 and (d-1) further
reduces, and drastically, the number of critical simplices to consider for the
computation of $D_1(f)$, the intermediate layer of the sandwich. Third, we
document several performance improvements via shared-memory parallelism. We
provide an open-source implementation of our algorithm for reproducibility
purposes. We also contribute a reproducible benchmark package, which exploits
three-dimensional data from a public repository and compares our algorithm to a
variety of publicly available implementations. Extensive experiments indicate
that our algorithm improves by two orders of magnitude the time performance of
the seminal "PairCells" algorithm it extends. Moreover, it also improves memory
footprint and time performance over a selection of 14 competing approaches,
with a substantial gain over the fastest available approaches, while producing
a strictly identical output. We illustrate the utility of our contributions
with an application to the fast and robust extraction of persistent
1-dimensional generators on surfaces, volume data and high-dimensional point
clouds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustifying Vision Transformer without Retraining from Scratch by Test-Time Class-Conditional Feature Alignment. (arXiv:2206.13951v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13951">
<div class="article-summary-box-inner">
<span><p>Vision Transformer (ViT) is becoming more popular in image processing.
Specifically, we investigate the effectiveness of test-time adaptation (TTA) on
ViT, a technique that has emerged to correct its prediction during test-time by
itself. First, we benchmark various test-time adaptation approaches on ViT-B16
and ViT-L16. It is shown that the TTA is effective on ViT and the
prior-convention (sensibly selecting modulation parameters) is not necessary
when using proper loss function. Based on the observation, we propose a new
test-time adaptation method called class-conditional feature alignment (CFA),
which minimizes both the class-conditional distribution differences and the
whole distribution differences of the hidden representation between the source
and target in an online manner. Experiments of image classification tasks on
common corruption (CIFAR-10-C, CIFAR-100-C, and ImageNet-C) and domain
adaptation (digits datasets and ImageNet-Sketch) show that CFA stably
outperforms the existing baselines on various datasets. We also verify that CFA
is model agnostic by experimenting on ResNet, MLP-Mixer, and several ViT
variants (ViT-AugReg, DeiT, and BeiT). Using BeiT backbone, CFA achieves 19.8%
top-1 error rate on ImageNet-C, outperforming the existing test-time adaptation
baseline 44.0%. This is a state-of-the-art result among TTA methods that do not
need to alter training phase.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Prior Learning via Neural Architecture Search for Blind Face Restoration. (arXiv:2206.13962v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13962">
<div class="article-summary-box-inner">
<span><p>Blind Face Restoration (BFR) aims to recover high-quality face images from
low-quality ones and usually resorts to facial priors for improving restoration
performance. However, current methods still suffer from two major difficulties:
1) how to derive a powerful network architecture without extensive hand tuning;
2) how to capture complementary information from multiple facial priors in one
network to improve restoration performance. To this end, we propose a Face
Restoration Searching Network (FRSNet) to adaptively search the suitable
feature extraction architecture within our specified search space, which can
directly contribute to the restoration quality. On the basis of FRSNet, we
further design our Multiple Facial Prior Searching Network (MFPSNet) with a
multi-prior learning scheme. MFPSNet optimally extracts information from
diverse facial priors and fuses the information into image features, ensuring
that both external guidance and internal features are reserved. In this way,
MFPSNet takes full advantage of semantic-level (parsing maps), geometric-level
(facial heatmaps), reference-level (facial dictionaries) and pixel-level
(degraded images) information and thus generates faithful and realistic images.
Quantitative and qualitative experiments show that MFPSNet performs favorably
on both synthetic and real-world datasets against the state-of-the-art BFR
methods. The codes are publicly available at:
https://github.com/YYJ1anG/MFPSNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Primitive Graph Learning for Unified Vector Mapping. (arXiv:2206.13963v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13963">
<div class="article-summary-box-inner">
<span><p>Large-scale vector mapping is important for transportation, city planning,
and survey and census. We propose GraphMapper, a unified framework for
end-to-end vector map extraction from satellite images. Our key idea is a novel
unified representation of shapes of different topologies named "primitive
graph", which is a set of shape primitives and their pairwise relationship
matrix. Then, we convert vector shape prediction, regularization, and topology
reconstruction into a unique primitive graph learning problem. Specifically,
GraphMapper is a generic primitive graph learning network based on global shape
context modelling through multi-head-attention. An embedding space sorting
method is developed for accurate primitive relationship modelling. We
empirically demonstrate the effectiveness of GraphMapper on two challenging
mapping tasks, building footprint regularization and road network topology
reconstruction. Our model outperforms state-of-the-art methods by 8-10% in both
tasks on public benchmarks. All code will be publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Gait Representation from Massive Unlabelled Walking Videos: A Benchmark. (arXiv:2206.13964v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13964">
<div class="article-summary-box-inner">
<span><p>Gait depicts individuals' unique and distinguishing walking patterns and has
become one of the most promising biometric features for human identification.
As a fine-grained recognition task, gait recognition is easily affected by many
factors and usually requires a large amount of completely annotated data that
is costly and insatiable. This paper proposes a large-scale self-supervised
benchmark for gait recognition with contrastive learning, aiming to learn the
general gait representation from massive unlabelled walking videos for
practical applications via offering informative walking priors and diverse
real-world variations. Specifically, we collect a large-scale unlabelled gait
dataset GaitLU-1M consisting of 1.02M walking sequences and propose a
conceptually simple yet empirically powerful baseline model GaitSSB.
Experimentally, we evaluate the pre-trained model on four widely-used gait
benchmarks, CASIA-B, OU-MVLP, GREW and Gait3D with or without transfer
learning. The unsupervised results are comparable to or even better than the
early model-based and GEI-based methods. After transfer learning, our method
outperforms existing methods by a large margin in most cases. Theoretically, we
discuss the critical issues for gait-specific contrastive framework and present
some insights for further study. As far as we know, GaitLU-1M is the first
large-scale unlabelled gait dataset, and GaitSSB is the first method that
achieves remarkable unsupervised results on the aforementioned benchmarks. The
source code of GaitSSB will be integrated into OpenGait which is available at
https://github.com/ShiqiYu/OpenGait.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information Entropy Initialized Concrete Autoencoder for Optimal Sensor Placement and Reconstruction of Geophysical Fields. (arXiv:2206.13968v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13968">
<div class="article-summary-box-inner">
<span><p>We propose a new approach to the optimal placement of sensors for the problem
of reconstructing geophysical fields from sparse measurements. Our method
consists of two stages. In the first stage, we estimate the variability of the
physical field as a function of spatial coordinates by approximating its
information entropy through the Conditional PixelCNN network. To calculate the
entropy, a new ordering of a two-dimensional data array (spiral ordering) is
proposed, which makes it possible to obtain the entropy of a physical field
simultaneously for several spatial scales. In the second stage, the entropy of
the physical field is used to initialize the distribution of optimal sensor
locations. This distribution is further optimized with the Concrete Autoencoder
architecture with the straight-through gradient estimator and adversarial loss
to simultaneously minimize the number of sensors and maximize reconstruction
accuracy. Our method scales linearly with data size, unlike commonly used
Principal Component Analysis. We demonstrate our method on the two examples:
(a) temperature and (b) salinity fields around the Barents Sea and the Svalbard
group of islands. For these examples, we compute the reconstruction error of
our method and a few baselines. We test our approach against two baselines (1)
PCA with QR factorization and (2) climatology. We find out that the obtained
optimal sensor locations have clear physical interpretation and correspond to
the boundaries between sea currents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Increasing Confidence in Adversarial Robustness Evaluations. (arXiv:2206.13991v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13991">
<div class="article-summary-box-inner">
<span><p>Hundreds of defenses have been proposed to make deep neural networks robust
against minimal (adversarial) input perturbations. However, only a handful of
these defenses held up their claims because correctly evaluating robustness is
extremely challenging: Weak attacks often fail to find adversarial examples
even if they unknowingly exist, thereby making a vulnerable network look
robust. In this paper, we propose a test to identify weak attacks, and thus
weak defense evaluations. Our test slightly modifies a neural network to
guarantee the existence of an adversarial example for every sample.
Consequentially, any correct attack must succeed in breaking this modified
network. For eleven out of thirteen previously-published defenses, the original
evaluation of the defense fails our test, while stronger attacks that break
these defenses pass it. We hope that attack unit tests - such as ours - will be
a major component in future robustness evaluations and increase confidence in
an empirical field that is currently riddled with skepticism.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting tiny objects in aerial images: A normalized Wasserstein distance and a new benchmark. (arXiv:2206.13996v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13996">
<div class="article-summary-box-inner">
<span><p>Tiny object detection (TOD) in aerial images is challenging since a tiny
object only contains a few pixels. State-of-the-art object detectors do not
provide satisfactory results on tiny objects due to the lack of supervision
from discriminative features. Our key observation is that the Intersection over
Union (IoU) metric and its extensions are very sensitive to the location
deviation of the tiny objects, which drastically deteriorates the quality of
label assignment when used in anchor-based detectors. To tackle this problem,
we propose a new evaluation metric dubbed Normalized Wasserstein Distance (NWD)
and a new RanKing-based Assigning (RKA) strategy for tiny object detection. The
proposed NWD-RKA strategy can be easily embedded into all kinds of anchor-based
detectors to replace the standard IoU threshold-based one, significantly
improving label assignment and providing sufficient supervision information for
network training. Tested on four datasets, NWD-RKA can consistently improve
tiny object detection performance by a large margin. Besides, observing
prominent noisy labels in the Tiny Object Detection in Aerial Images (AI-TOD)
dataset, we are motivated to meticulously relabel it and release AI-TOD-v2 and
its corresponding benchmark. In AI-TOD-v2, the missing annotation and location
error problems are considerably mitigated, facilitating more reliable training
and validation processes. Embedding NWD-RKA into DetectoRS, the detection
performance achieves 4.3 AP points improvement over state-of-the-art
competitors on AI-TOD-v2. Datasets, codes, and more visualizations are
available at: https://chasel-tsui.github.io/AI-TOD-v2/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Show Me Your Face, And I'll Tell You How You Speak. (arXiv:2206.14009v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14009">
<div class="article-summary-box-inner">
<span><p>When we speak, the prosody and content of the speech can be inferred from the
movement of our lips. In this work, we explore the task of lip to speech
synthesis, i.e., learning to generate speech given only the lip movements of a
speaker where we focus on learning accurate lip to speech mappings for multiple
speakers in unconstrained, large vocabulary settings. We capture the speaker's
voice identity through their facial characteristics, i.e., age, gender,
ethnicity and condition them along with the lip movements to generate speaker
identity aware speech. To this end, we present a novel method "Lip2Speech",
with key design choices to achieve accurate lip to speech synthesis in
unconstrained scenarios. We also perform various experiments and extensive
evaluation using quantitative, qualitative metrics and human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Taxonomy and evolution predicting using deep learning in images. (arXiv:2206.14011v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14011">
<div class="article-summary-box-inner">
<span><p>Molecular and morphological characters, as important parts of biological
taxonomy, are contradictory but need to be integrated. Organism's image
recognition and bioinformatics are emerging and hot problems nowadays but with
a gap between them. In this work, a multi-branching recognition framework
mediated by genetic information bridges this barrier, which establishes the
link between macro-morphology and micro-molecular information of mushrooms. The
novel multi-perspective structure is proposed to fuse the feature images from
three branching models, which significantly improves the accuracy of
recognition by about 10% and up to more than 90%. Further, genetic information
is implemented to the mushroom image recognition task by using genetic distance
embeddings as the representation space for predicting image distance and
species identification. Semantic overfitting of traditional classification
tasks and the granularity of fine-grained image recognition are also discussed
in depth for the first time. The generalizability of the model was investigated
in fine-grained scenarios using zero-shot learning tasks, which could predict
the taxonomic and evolutionary information of unseen samples. We presented the
first method to map images to DNA, namely used an encoder mapping image to
genetic distances, and then decoded DNA through a pre-trained decoder, where
the total test accuracy on 37 species for DNA prediction is 87.45%. This study
creates a novel recognition framework by systematically studying the mushroom
image recognition problem, bridging the gap between macroscopic biological
information and microscopic molecular information, which will provide a new
reference for intelligent biometrics in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Adversarial Examples for Location Privacy Protection. (arXiv:2206.14020v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14020">
<div class="article-summary-box-inner">
<span><p>We have investigated a new application of adversarial examples, namely
location privacy protection against landmark recognition systems. We introduce
mask-guided multimodal projected gradient descent (MM-PGD), in which
adversarial examples are trained on different deep models. Image contents are
protected by analyzing the properties of regions to identify the ones most
suitable for blending in adversarial examples. We investigated two region
identification strategies: class activation map-based MM-PGD, in which the
internal behaviors of trained deep models are targeted; and human-vision-based
MM-PGD, in which regions that attract less human attention are targeted.
Experiments on the Places365 dataset demonstrated that these strategies are
potentially effective in defending against black-box landmark recognition
systems without the need for much image manipulation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Neural Networks pruning via the Structured Perspective Regularization. (arXiv:2206.14056v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14056">
<div class="article-summary-box-inner">
<span><p>In Machine Learning, Artificial Neural Networks (ANNs) are a very powerful
tool, broadly used in many applications. Often, the selected (deep)
architectures include many layers, and therefore a large amount of parameters,
which makes training, storage and inference expensive. This motivated a stream
of research about compressing the original networks into smaller ones without
excessively sacrificing performances. Among the many proposed compression
approaches, one of the most popular is \emph{pruning}, whereby entire elements
of the ANN (links, nodes, channels, \ldots) and the corresponding weights are
deleted. Since the nature of the problem is inherently combinatorial (what
elements to prune and what not), we propose a new pruning method based on
Operational Research tools. We start from a natural Mixed-Integer-Programming
model for the problem, and we use the Perspective Reformulation technique to
strengthen its continuous relaxation. Projecting away the indicator variables
from this reformulation yields a new regularization term, which we call the
Structured Perspective Regularization, that leads to structured pruning of the
initial architecture. We test our method on some ResNet architectures applied
to CIFAR-10, CIFAR-100 and ImageNet datasets, obtaining competitive
performances w.r.t.~the state of the art for structured pruning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual Learning with Transformers for Image Classification. (arXiv:2206.14085v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14085">
<div class="article-summary-box-inner">
<span><p>In many real-world scenarios, data to train machine learning models become
available over time. However, neural network models struggle to continually
learn new concepts without forgetting what has been learnt in the past. This
phenomenon is known as catastrophic forgetting and it is often difficult to
prevent due to practical constraints, such as the amount of data that can be
stored or the limited computation sources that can be used. Moreover, training
large neural networks, such as Transformers, from scratch is very costly and
requires a vast amount of training data, which might not be available in the
application domain of interest. A recent trend indicates that dynamic
architectures based on an expansion of the parameters can reduce catastrophic
forgetting efficiently in continual learning, but this needs complex tuning to
balance the growing number of parameters and barely share any information
across tasks. As a result, they struggle to scale to a large number of tasks
without significant overhead. In this paper, we validate in the computer vision
domain a recent solution called Adaptive Distillation of Adapters (ADA), which
is developed to perform continual learning using pre-trained Transformers and
Adapters on text classification tasks. We empirically demonstrate on different
classification tasks that this method maintains a good predictive performance
without retraining the model or increasing the number of model parameters over
the time. Besides it is significantly faster at inference time compared to the
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RevBiFPN: The Fully Reversible Bidirectional Feature Pyramid Network. (arXiv:2206.14098v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14098">
<div class="article-summary-box-inner">
<span><p>This work introduces the RevSilo, the first reversible module for
bidirectional multi-scale feature fusion. Like other reversible methods,
RevSilo eliminates the need to store hidden activations by recomputing them.
Existing reversible methods, however, do not apply to multi-scale feature
fusion and are therefore not applicable to a large class of networks.
Bidirectional multi-scale feature fusion promotes local and global coherence
and has become a de facto design principle for networks targeting spatially
sensitive tasks e.g. HRNet and EfficientDet. When paired with high-resolution
inputs, these networks achieve state-of-the-art results across various computer
vision tasks, but training them requires substantial accelerator memory for
saving large, multi-resolution activations. These memory requirements cap
network size and limit progress. Using reversible recomputation, the RevSilo
alleviates memory issues while still operating across resolution scales.
Stacking RevSilos, we create RevBiFPN, a fully reversible bidirectional feature
pyramid network. For classification, RevBiFPN is competitive with networks such
as EfficientNet while using up to 19.8x lesser training memory. When fine-tuned
on COCO, RevBiFPN provides up to a 2.5% boost in AP over HRNet using fewer MACs
and a 2.4x reduction in training-time memory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous Driving. (arXiv:2206.14116v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14116">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) is an emerging technique that has been
successfully employed to train convolutional neural networks (CNNs) and graph
neural networks (GNNs) for more transferable, generalizable, and robust
representation learning. However its potential in motion forecasting for
autonomous driving has rarely been explored. In this study, we report the first
systematic exploration and assessment of incorporating self-supervision into
motion forecasting. We first propose to investigate four novel self-supervised
learning tasks for motion forecasting with theoretical rationale and
quantitative and qualitative comparisons on the challenging large-scale
Argoverse dataset. Secondly, we point out that our auxiliary SSL-based learning
setup not only outperforms forecasting methods which use transformers,
complicated fusion mechanisms and sophisticated online dense goal candidate
optimization algorithms in terms of performance accuracy, but also has low
inference time and architectural complexity. Lastly, we conduct several
experiments to understand why SSL improves motion forecasting. Code is
open-sourced at \url{https://github.com/AutoVision-cloud/SSL-Lanes}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">aSTDP: A More Biologically Plausible Learning. (arXiv:2206.14137v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14137">
<div class="article-summary-box-inner">
<span><p>Spike-timing dependent plasticity in biological neural networks has been
proven to be important during biological learning process. On the other hand,
artificial neural networks use a different way to learn, such as
Back-Propagation or Contrastive Hebbian Learning. In this work we introduce
approximate STDP, a new neural networks learning framework more similar to the
biological learning process. It uses only STDP rules for supervised and
unsupervised learning, every neuron distributed learn patterns and don' t need
a global loss or other supervised information. We also use a numerical way to
approximate the derivatives of each neuron in order to better use SDTP learning
and use the derivatives to set a target for neurons to accelerate training and
testing process. The framework can make predictions or generate patterns in one
model without additional configuration. Finally, we verified our framework on
MNIST dataset for classification and generation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visualizing and Alleviating the Effect of Radial Distortion on Camera Calibration Using Principal Lines. (arXiv:2206.14164v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14164">
<div class="article-summary-box-inner">
<span><p>Preparing appropriate images for camera calibration is crucial to obtain
accurate results. In this paper, new suggestions for preparing such data to
alleviate the adverse effect of radial distortion for a calibration procedure
using principal lines are developed through the investigations of: (i)
identifying directions of checkerboard movements in an image which will result
in maximum (and minimum) influence on the calibration results, and (ii)
inspecting symmetry and monotonicity of such effect in (i) using the above
principal lines. Accordingly, it is suggested that the estimation of principal
point should based on linearly independent pairs of nearly parallel principal
lines, with a member in each pair corresponds to a near 180-degree rotation (in
the image plane) of the other. Experimental results show that more robust and
consistent calibration results for the foregoing estimation can actually be
obtained, compared with the renowned algebraic methods which estimate
distortion parameters explicitly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-Resolution Virtual Try-On with Misalignment and Occlusion-Handled Conditions. (arXiv:2206.14180v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14180">
<div class="article-summary-box-inner">
<span><p>Image-based virtual try-on aims to synthesize an image of a person wearing a
given clothing item. To solve the task, the existing methods warp the clothing
item to fit the person's body and generate the segmentation map of the person
wearing the item, before fusing the item with the person. However, when the
warping and the segmentation generation stages operate individually without
information exchange, the misalignment between the warped clothes and the
segmentation map occurs, which leads to the artifacts in the final image. The
information disconnection also causes excessive warping near the clothing
regions occluded by the body parts, so called pixel-squeezing artifacts. To
settle the issues, we propose a novel try-on condition generator as a unified
module of the two stages (i.e., warping and segmentation generation stages). A
newly proposed feature fusion block in the condition generator implements the
information exchange, and the condition generator does not create any
misalignment or pixel-squeezing artifacts. We also introduce discriminator
rejection that filters out the incorrect segmentation map predictions and
assures the performance of virtual try-on frameworks. Experiments on a
high-resolution dataset demonstrate that our model successfully handles the
misalignment and the occlusion, and significantly outperforms the baselines.
Code is available at https://github.com/sangyun884/HR-VITON.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pedestrian 3D Bounding Box Prediction. (arXiv:2206.14195v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14195">
<div class="article-summary-box-inner">
<span><p>Safety is still the main issue of autonomous driving, and in order to be
globally deployed, they need to predict pedestrians' motions sufficiently in
advance. While there is a lot of research on coarse-grained (human center
prediction) and fine-grained predictions (human body keypoints prediction), we
focus on 3D bounding boxes, which are reasonable estimates of humans without
modeling complex motion details for autonomous vehicles. This gives the
flexibility to predict in longer horizons in real-world settings. We suggest
this new problem and present a simple yet effective model for pedestrians' 3D
bounding box prediction. This method follows an encoder-decoder architecture
based on recurrent neural networks, and our experiments show its effectiveness
in both the synthetic (JTA) and real-world (NuScenes) datasets. The learned
representation has useful information to enhance the performance of other
tasks, such as action anticipation. Our code is available online:
https://github.com/vita-epfl/bounding-box-prediction
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Impacts from Datasets to Monocular Depth Estimation (MDE) Models with MineNavi. (arXiv:2008.08454v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08454">
<div class="article-summary-box-inner">
<span><p>Current computer vision tasks based on deep learning require a huge amount of
data with annotations for model training or testing, especially in some dense
estimation tasks, such as optical flow segmentation and depth estimation. In
practice, manual labeling for dense estimation tasks is very difficult or even
impossible, and the scenes of the dataset are often restricted to a small
range, which dramatically limits the development of the community. To overcome
this deficiency, we propose a synthetic dataset generation method to obtain the
expandable dataset without burdensome manual workforce. By this method, we
construct a dataset called MineNavi containing video footages from
first-perspective-view of the aircraft matched with accurate ground truth for
depth estimation in aircraft navigation application. We also provide
quantitative experiments to prove that pre-training via our MineNavi dataset
can improve the performance of depth estimation model and speed up the
convergence of the model on real scene data. Since the synthetic dataset has a
similar effect to the real-world dataset in the training process of deep model,
we also provide additional experiments with monocular depth estimation method
to demonstrate the impact of various factors in our dataset such as lighting
conditions and motion mode.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Variational Network Toward Blind Image Restoration. (arXiv:2008.10796v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10796">
<div class="article-summary-box-inner">
<span><p>Blind image restoration (IR) is a common yet challenging problem in computer
vision. Classical model-based methods and recent deep learning (DL)-based
methods represent two different methodologies for this problem, each with their
own merits and drawbacks. In this paper, we propose a novel blind image
restoration method, aiming to integrate both the advantages of them.
Specifically, we construct a general Bayesian generative model for the blind
IR, which explicitly depicts the degradation process. In this proposed model, a
pixel-wise non-i.i.d. Gaussian distribution is employed to fit the image noise.
It is with more flexibility than the simple i.i.d. Gaussian or Laplacian
distributions as adopted in most of conventional methods, so as to handle more
complicated noise types contained in the image degradation. To solve the model,
we design a variational inference algorithm where all the expected posteriori
distributions are parameterized as deep neural networks to increase their model
capability. Notably, such an inference algorithm induces a unified framework to
jointly deal with the tasks of degradation estimation and image restoration.
Further, the degradation information estimated in the former task is utilized
to guide the latter IR process. Experiments on two typical blind IR tasks,
namely image denoising and super-resolution, demonstrate that the proposed
method achieves superior performance over current state-of-the-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Image Destruction: Vulnerability of Deep Image-to-Image Models against Adversarial Attacks. (arXiv:2104.15022v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.15022">
<div class="article-summary-box-inner">
<span><p>Recently, the vulnerability of deep image classification models to
adversarial attacks has been investigated. However, such an issue has not been
thoroughly studied for image-to-image tasks that take an input image and
generate an output image (e.g., colorization, denoising, deblurring, etc.) This
paper presents comprehensive investigations into the vulnerability of deep
image-to-image models to adversarial attacks. For five popular image-to-image
tasks, 16 deep models are analyzed from various standpoints such as output
quality degradation due to attacks, transferability of adversarial examples
across different tasks, and characteristics of perturbations. We show that
unlike image classification tasks, the performance degradation on
image-to-image tasks largely differs depending on various factors, e.g., attack
methods and task objectives. In addition, we analyze the effectiveness of
conventional defense methods used for classification models in improving the
robustness of the image-to-image models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated triaging of head MRI examinations using convolutional neural networks. (arXiv:2106.08176v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08176">
<div class="article-summary-box-inner">
<span><p>The growing demand for head magnetic resonance imaging (MRI) examinations,
along with a global shortage of radiologists, has led to an increase in the
time taken to report head MRI scans around the world. For many neurological
conditions, this delay can result in increased morbidity and mortality. An
automated triaging tool could reduce reporting times for abnormal examinations
by identifying abnormalities at the time of imaging and prioritizing the
reporting of these scans. In this work, we present a convolutional neural
network for detecting clinically-relevant abnormalities in
$\text{T}_2$-weighted head MRI scans. Using a validated neuroradiology report
classifier, we generated a labelled dataset of 43,754 scans from two large UK
hospitals for model training, and demonstrate accurate classification (area
under the receiver operating curve (AUC) = 0.943) on a test set of 800 scans
labelled by a team of neuroradiologists. Importantly, when trained on scans
from only a single hospital the model generalized to scans from the other
hospital ($\Delta$AUC $\leq$ 0.02). A simulation study demonstrated that our
model would reduce the mean reporting time for abnormal examinations from 28
days to 14 days and from 9 days to 5 days at the two hospitals, demonstrating
feasibility for use in a clinical triage environment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows. (arXiv:2108.05015v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05015">
<div class="article-summary-box-inner">
<span><p>Different from visible cameras which record intensity images frame by frame,
the biologically inspired event camera produces a stream of asynchronous and
sparse events with much lower latency. In practice, the visible cameras can
better perceive texture details and slow motion, while event cameras can be
free from motion blurs and have a larger dynamic range which enables them to
work well under fast motion and low illumination. Therefore, the two sensors
can cooperate with each other to achieve more reliable object tracking. In this
work, we propose a large-scale Visible-Event benchmark (termed VisEvent) due to
the lack of a realistic and scaled dataset for this task. Our dataset consists
of 820 video pairs captured under low illumination, high speed, and background
clutter scenarios, and it is divided into a training and a testing subset, each
of which contains 500 and 320 videos, respectively. Based on VisEvent, we
transform the event flows into event images and construct more than 30 baseline
methods by extending current single-modality trackers into dual-modality
versions. More importantly, we further build a simple but effective tracking
algorithm by proposing a cross-modality transformer, to achieve more effective
feature fusion between visible and event data. Extensive experiments on the
proposed VisEvent dataset, FE108, and two simulated datasets (i.e., OTB-DVS and
VOT-DVS), validated the effectiveness of our model. The dataset and source code
have been released at our project page:
\url{https://sites.google.com/view/viseventtrack/}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporal Action Segmentation with High-level Complex Activity Labels. (arXiv:2108.06706v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06706">
<div class="article-summary-box-inner">
<span><p>The temporal action segmentation task segments videos temporally and predicts
action labels for all frames. Fully supervising such a segmentation model
requires dense frame-wise action annotations, which are expensive and tedious
to collect.
</p>
<p>This work is the first to propose a Constituent Action Discovery (CAD)
framework that only requires the video-wise high-level complex activity label
as supervision for temporal action segmentation. The proposed approach
automatically discovers constituent video actions using an activity
classification task. Specifically, we define a finite number of latent action
prototypes to construct video-level dual representations with which these
prototypes are learned collectively through the activity classification
training. This setting endows our approach with the capability to discover
potentially shared actions across multiple complex activities.
</p>
<p>Due to the lack of action-level supervision, we adopt the Hungarian matching
algorithm to relate latent action prototypes to ground truth semantic classes
for evaluation. We show that with the high-level supervision, the Hungarian
matching can be extended from the existing video and activity levels to the
global level. The global-level matching allows for action sharing across
activities, which has never been considered in the literature before. Extensive
experiments demonstrate that our discovered actions can help perform temporal
action segmentation and activity recognition tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Generalization for Medical Image Segmentation via Hierarchical Consistency Regularization. (arXiv:2109.05742v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05742">
<div class="article-summary-box-inner">
<span><p>Modern deep neural networks struggle to transfer knowledge and generalize
across diverse domains when deployed to real-world applications. Currently,
domain generalization (DG) is introduced to learn a universal representation
from multiple domains to improve the network generalization ability on unseen
domains. However, previous DG methods only focus on the data-level consistency
scheme without considering the synergistic regularization among different
consistency schemes. In this paper, we present a novel Hierarchical Consistency
framework for Domain Generalization (HCDG) by integrating Extrinsic Consistency
and Intrinsic Consistency synergistically. Particularly, for the Extrinsic
Consistency, we leverage the knowledge across multiple source domains to
enforce data-level consistency. To better enhance such consistency, we design a
novel Amplitude Gaussian-mixing strategy into Fourier-based data augmentation
called DomainUp. For the Intrinsic Consistency, we perform task-level
consistency for the same instance under the dual-task scenario. We evaluate the
proposed HCDG framework on two medical image segmentation tasks, i.e., optic
cup/disc segmentation on fundus images and prostate MRI segmentation. Extensive
experimental results manifest the effectiveness and versatility of our HCDG
framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepStroke: An Efficient Stroke Screening Framework for Emergency Rooms with Multimodal Adversarial Deep Learning. (arXiv:2109.12065v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12065">
<div class="article-summary-box-inner">
<span><p>In an emergency room (ER) setting, stroke triage or screening is a common
challenge. A quick CT is usually done instead of MRI due to MRI's slow
throughput and high cost. Clinical tests are commonly referred to during the
process, but the misdiagnosis rate remains high. We propose a novel multimodal
deep learning framework, DeepStroke, to achieve computer-aided stroke presence
assessment by recognizing patterns of minor facial muscles incoordination and
speech inability for patients with suspicion of stroke in an acute setting. Our
proposed DeepStroke takes one-minute facial video data and audio data readily
available during stroke triage for local facial paralysis detection and global
speech disorder analysis. Transfer learning was adopted to reduce
face-attribute biases and improve generalizability. We leverage a multi-modal
lateral fusion to combine the low- and high-level features and provide mutual
regularization for joint training. Novel adversarial training is introduced to
obtain identity-free and stroke-discriminative features. Experiments on our
video-audio dataset with actual ER patients show that DeepStroke outperforms
state-of-the-art models and achieves better performance than both a triage team
and ER doctors, attaining a 10.94% higher sensitivity and maintaining 7.37%
higher accuracy than traditional stroke triage when specificity is aligned.
Meanwhile, each assessment can be completed in less than six minutes,
demonstrating the framework's great potential for clinical translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fire Together Wire Together: A Dynamic Pruning Approach with Self-Supervised Mask Prediction. (arXiv:2110.08232v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08232">
<div class="article-summary-box-inner">
<span><p>Dynamic model pruning is a recent direction that allows for the inference of
a different sub-network for each input sample during deployment. However,
current dynamic methods rely on learning a continuous channel gating through
regularization by inducing sparsity loss. This formulation introduces
complexity in balancing different losses (e.g task loss, regularization loss).
In addition, regularization based methods lack transparent tradeoff
hyperparameter selection to realize computational budget. Our contribution is
two-fold: 1) decoupled task and pruning training. 2) Simple hyperparameter
selection that enables FLOPs reduction estimation before training. Inspired by
the Hebbian theory in Neuroscience: "neurons that fire together wire together",
we propose to predict a mask to process k filters in a layer based on the
activation of its previous layer. We pose the problem as a self-supervised
binary classification problem. Each mask predictor module is trained to predict
if the log-likelihood for each filter in the current layer belongs to the top-k
activated filters. The value k is dynamically estimated for each input based on
a novel criterion using the mass of heatmaps. We show experiments on several
neural architectures, such as VGG, ResNet and MobileNet on CIFAR and ImageNet
datasets. On CIFAR, we reach similar accuracy to SOTA methods with 15% and 24%
higher FLOPs reduction. Similarly in ImageNet, we achieve lower drop in
accuracy with up to 13% improvement in FLOPs reduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tracking Blobs in the Turbulent Edge Plasma of a Tokamak Fusion Device. (arXiv:2111.08570v2 [physics.plasm-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08570">
<div class="article-summary-box-inner">
<span><p>The analysis of turbulence in plasmas is fundamental in fusion research.
Despite extensive progress in theoretical modeling in the past 15 years, we
still lack a complete and consistent understanding of turbulence in magnetic
confinement devices, such as tokamaks. Experimental studies are challenging due
to the diverse processes that drive the high-speed dynamics of turbulent
phenomena. This work presents a novel application of motion tracking to
identify and track turbulent filaments in fusion plasmas, called blobs, in a
high-frequency video obtained from Gas Puff Imaging diagnostics. We compare
four baseline methods (RAFT, GMA, Flow Walk, and Mask R-CNN) trained on
synthetic data and then test on synthetic and real-world data obtained from
plasmas in the Tokamak `a Configuration Variable (TCV). The blob regime
identified from an analysis of blob trajectories agrees with state-of-the-art
conditional averaging methods for each of the baseline methods employed, giving
confidence in the accuracy of these techniques. High entry barriers
traditionally limit tokamak plasma research to a small community of researchers
in the field. By making a dataset and benchmark publicly available, we hope to
open the field to a broad community in science and engineering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation. (arXiv:2111.12707v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12707">
<div class="article-summary-box-inner">
<span><p>Estimating 3D human poses from monocular videos is a challenging task due to
depth ambiguity and self-occlusion. Most existing works attempt to solve both
issues by exploiting spatial and temporal relationships. However, those works
ignore the fact that it is an inverse problem where multiple feasible solutions
(i.e., hypotheses) exist. To relieve this limitation, we propose a
Multi-Hypothesis Transformer (MHFormer) that learns spatio-temporal
representations of multiple plausible pose hypotheses. In order to effectively
model multi-hypothesis dependencies and build strong relationships across
hypothesis features, the task is decomposed into three stages: (i) Generate
multiple initial hypothesis representations; (ii) Model self-hypothesis
communication, merge multiple hypotheses into a single converged representation
and then partition it into several diverged hypotheses; (iii) Learn
cross-hypothesis communication and aggregate the multi-hypothesis features to
synthesize the final 3D pose. Through the above processes, the final
representation is enhanced and the synthesized pose is much more accurate.
Extensive experiments show that MHFormer achieves state-of-the-art results on
two challenging datasets: Human3.6M and MPI-INF-3DHP. Without bells and
whistles, its performance surpasses the previous best result by a large margin
of 3% on Human3.6M. Code and models are available at
\url{https://github.com/Vegetebird/MHFormer}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anisotropic mesh adaptation for region-based segmentation accounting for image spatial information. (arXiv:2112.10138v2 [math.NA] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10138">
<div class="article-summary-box-inner">
<span><p>A finite element-based image segmentation strategy enhanced by an anisotropic
mesh adaptation procedure is presented. The methodology relies on a split
Bregman algorithm for the minimisation of a region-based energy functional and
on an anisotropic recovery-based error estimate to drive mesh adaptation. More
precisely, a Bayesian energy functional is considered to account for image
spatial information, ensuring that the methodology is able to identify
inhomogeneous spatial patterns in complex images. In addition, the anisotropic
mesh adaptation guarantees a sharp detection of the interface between
background and foreground of the image, with a reduced number of degrees of
freedom. The resulting split-adapt Bregman algorithm is tested on a set of real
images showing the accuracy and robustness of the method, even in the presence
of Gaussian, salt and pepper and speckle noise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuralTailor: Reconstructing Sewing Pattern Structures from 3D Point Clouds of Garments. (arXiv:2201.13063v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.13063">
<div class="article-summary-box-inner">
<span><p>The fields of SocialVR, performance capture, and virtual try-on are often
faced with a need to faithfully reproduce real garments in the virtual world.
One critical task is the disentanglement of the intrinsic garment shape from
deformations due to fabric properties, physical forces, and contact with the
body. We propose to use a garment sewing pattern, a realistic and compact
garment descriptor, to facilitate the intrinsic garment shape estimation.
Another major challenge is a high diversity of shapes and designs in the
domain. The most common approach for Deep Learning on 3D garments is to build
specialized models for individual garments or garment types. We argue that
building a unified model for various garment designs has the benefit of
generalization to novel garment types, hence covering a larger design domain
than individual models would. We introduce NeuralTailor, a novel architecture
based on point-level attention for set regression with variable cardinality,
and apply it to the task of reconstructing 2D garment sewing patterns from the
3D point could garment models. Our experiments show that NeuralTailor
successfully reconstructs sewing patterns and generalizes to garment types with
pattern topologies unseen during training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Graph Convolutional Networks for Weakly Supervised Anomaly Detection in Videos. (arXiv:2202.06503v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.06503">
<div class="article-summary-box-inner">
<span><p>For weakly supervised anomaly detection, most existing work is limited to the
problem of inadequate video representation due to the inability of modeling
long-term contextual information. To solve this, we propose a novel weakly
supervised adaptive graph convolutional network (WAGCN) to model the complex
contextual relationship among video segments. By which, we fully consider the
influence of other video segments on the current one when generating the
anomaly probability score for each segment. Firstly, we combine the temporal
consistency as well as feature similarity of video segments to construct a
global graph, which makes full use of the association information among
spatial-temporal features of anomalous events in videos. Secondly, we propose a
graph learning layer in order to break the limitation of setting topology
manually, which can extract graph adjacency matrix based on data adaptively and
effectively. Extensive experiments on two public datasets (i.e., UCF-Crime
dataset and ShanghaiTech dataset) demonstrate the effectiveness of our approach
which achieves state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perceived Overlap: A Prerequisite for VAE Disentanglement. (arXiv:2202.13341v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.13341">
<div class="article-summary-box-inner">
<span><p>Learning disentangled representations with variational autoencoders (VAEs) is
often attributed to the regularisation component of the loss. In this work, we
highlight the interaction between data and the reconstruction term of the loss
as the main contributor to disentanglement in VAEs. We note that standardised
benchmark datasets are constructed in ways that are conducive to learning what
appear to be disentangled representations. We design an intuitive adversarial
dataset that exploits this mechanism to break existing state-of-the-art
disentanglement frameworks. Finally, we supply a solution that enables
disentanglement by modifying the reconstruction loss, affecting how VAEs
perceive distances between data points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Smoothness and Class-Separation for Semi-supervised Medical Image Segmentation. (arXiv:2203.01324v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01324">
<div class="article-summary-box-inner">
<span><p>Semi-supervised segmentation remains challenging in medical imaging since the
amount of annotated medical data is often scarce and there are many blurred
pixels near the adhesive edges or in the low-contrast regions. To address the
issues, we advocate to firstly constrain the consistency of pixels with and
without strong perturbations to apply a sufficient smoothness constraint and
further encourage the class-level separation to exploit the low-entropy
regularization for the model training. Particularly, in this paper, we propose
the SS-Net for semi-supervised medical image segmentation tasks, via exploring
the pixel-level smoothness and inter-class separation at the same time. The
pixel-level smoothness forces the model to generate invariant results under
adversarial perturbations. Meanwhile, the inter-class separation encourages
individual class features should approach their corresponding high-quality
prototypes, in order to make each class distribution compact and separate
different classes. We evaluated our SS-Net against five recent methods on the
public LA and ACDC datasets. Extensive experimental results under two
semi-supervised settings demonstrate the superiority of our proposed SS-Net
model, achieving new state-of-the-art (SOTA) performance on both datasets. The
code is available at https://github.com/ycwu1997/SS-Net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Region Proposal Rectification Towards Robust Instance Segmentation of Biological Images. (arXiv:2203.02846v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.02846">
<div class="article-summary-box-inner">
<span><p>Top-down instance segmentation framework has shown its superiority in object
detection compared to the bottom-up framework. While it is efficient in
addressing over-segmentation, top-down instance segmentation suffers from
over-crop problem. However, a complete segmentation mask is crucial for
biological image analysis as it delivers important morphological properties
such as shapes and volumes. In this paper, we propose a region proposal
rectification (RPR) module to address this challenging incomplete segmentation
problem. In particular, we offer a progressive ROIAlign module to introduce
neighbor information into a series of ROIs gradually. The ROI features are fed
into an attentive feed-forward network (FFN) for proposal box regression. With
additional neighbor information, the proposed RPR module shows significant
improvement in correction of region proposal locations and thereby exhibits
favorable instance segmentation performances on three biological image datasets
compared to state-of-the-art baseline methods. Experimental results demonstrate
that the proposed RPR module is effective in both anchor-based and anchor-free
top-down instance segmentation approaches, suggesting the proposed method can
be applied to general top-down instance segmentation of biological images. Code
is available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cartoon-texture evolution for two-region image segmentation. (arXiv:2203.03513v2 [math.NA] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03513">
<div class="article-summary-box-inner">
<span><p>Two-region image segmentation is the process of dividing an image into two
regions of interest, i.e., the foreground and the background. To this aim, Chan
et al. [Chan, Esedo\=glu, Nikolova, SIAM Journal on Applied Mathematics 66(5),
1632-1648, 2006] designed a model well suited for smooth images. One drawback
of this model is that it may produce a bad segmentation when the image contains
oscillatory components. Based on a cartoon-texture decomposition of the image
to be segmented, we propose a new model that is able to produce an accurate
segmentation of images also containing noise or oscillatory information like
texture. The novel model leads to a non-smooth constrained optimization problem
which we solve by means of the ADMM method. The convergence of the numerical
scheme is also proved. Several experiments on smooth, noisy, and textural
images show the effectiveness of the proposed model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stepwise Feature Fusion: Local Guides Global. (arXiv:2203.03635v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03635">
<div class="article-summary-box-inner">
<span><p>Colonoscopy, currently the most efficient and recognized colon polyp
detection technology, is necessary for early screening and prevention of
colorectal cancer. However, due to the varying size and complex morphological
features of colonic polyps as well as the indistinct boundary between polyps
and mucosa, accurate segmentation of polyps is still challenging. Deep learning
has become popular for accurate polyp segmentation tasks with excellent
results. However, due to the structure of polyps image and the varying shapes
of polyps, it easy for existing deep learning models to overfitting the current
dataset. As a result, the model may not process unseen colonoscopy data. To
address this, we propose a new State-Of-The-Art model for medical image
segmentation, the SSFormer, which uses a pyramid Transformer encoder to improve
the generalization ability of models. Specifically, our proposed Progressive
Locality Decoder can be adapted to the pyramid Transformer backbone to
emphasize local features and restrict attention dispersion. The SSFormer
achieves statet-of-the-art performance in both learning and generalization
assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Synthetic-to-Real Domain Adaptation using Contrastive Unpaired Translation. (arXiv:2203.09454v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09454">
<div class="article-summary-box-inner">
<span><p>The usefulness of deep learning models in robotics is largely dependent on
the availability of training data. Manual annotation of training data is often
infeasible. Synthetic data is a viable alternative, but suffers from domain
gap. We propose a multi-step method to obtain training data without manual
annotation effort: From 3D object meshes, we generate images using a modern
synthesis pipeline. We utilize a state-of-the-art image-to-image translation
method to adapt the synthetic images to the real domain, minimizing the domain
gap in a learned manner. The translation network is trained from unpaired
images, i.e. just requires an un-annotated collection of real images. The
generated and refined images can then be used to train deep learning models for
a particular task. We also propose and evaluate extensions to the translation
method that further increase performance, such as patch-based training, which
shortens training time and increases global consistency. We evaluate our method
and demonstrate its effectiveness on two robotic datasets. We finally give
insight into the learned refinement operations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CaRTS: Causality-driven Robot Tool Segmentation from Vision and Kinematics Data. (arXiv:2203.09475v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09475">
<div class="article-summary-box-inner">
<span><p>Vision-based segmentation of the robotic tool during robot-assisted surgery
enables downstream applications, such as augmented reality feedback, while
allowing for inaccuracies in robot kinematics. With the introduction of deep
learning, many methods were presented to solve instrument segmentation directly
and solely from images. While these approaches made remarkable progress on
benchmark datasets, fundamental challenges pertaining to their robustness
remain. We present CaRTS, a causality-driven robot tool segmentation algorithm,
that is designed based on a complementary causal model of the robot tool
segmentation task. Rather than directly inferring segmentation masks from
observed images, CaRTS iteratively aligns tool models with image observations
by updating the initially incorrect robot kinematic parameters through forward
kinematics and differentiable rendering to optimize image feature similarity
end-to-end. We benchmark CaRTS with competing techniques on both synthetic as
well as real data from the dVRK, generated in precisely controlled scenarios to
allow for counterfactual synthesis. On training-domain test data, CaRTS
achieves a Dice score of 93.4 that is preserved well (Dice score of 91.8) when
tested on counterfactually altered test data, exhibiting low brightness, smoke,
blood, and altered background patterns. This compares favorably to Dice scores
of 95.0 and 86.7, respectively, of the SOTA image-based method. Future work
will involve accelerating CaRTS to achieve video framerate and estimating the
impact occlusion has in practice. Despite these limitations, our results are
promising: In addition to achieving high segmentation accuracy, CaRTS provides
estimates of the true robot kinematics, which may benefit applications such as
force estimation. Code is available at: https://github.com/hding2455/CaRTS
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhanced Neck Feature Representation for Object Detection in Aerial Images. (arXiv:2204.02033v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02033">
<div class="article-summary-box-inner">
<span><p>Object detection in aerial images is a fundamental research topic in the
geoscience and remote sensing domain. However, the advanced approaches on this
topic mainly focus on designing the elaborate backbones or head networks but
ignore neck networks. In this letter, we first underline the importance of the
neck network in object detection from the perspective of information
bottleneck. Then, to alleviate the information deficiency problem in the
current approaches, we propose a global semantic network (GSNet), which acts as
a bridge from the backbone network to the head network in a bidirectional
global pattern. Compared to the existing approaches, our model can capture the
rich and enhanced image features with less computational costs. Besides, we
further propose a feature fusion refinement module (FRM) for different levels
of features, which are suffering from the problem of semantic gap in feature
fusion. To demonstrate the effectiveness and efficiency of our approach,
experiments are carried out on two challenging and representative aerial image
datasets (i.e., DOTA and HRSC2016). Experimental results in terms of accuracy
and complexity validate the superiority of our method. The code has been
open-sourced at GSNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Generalizable Dexterous Manipulation from Human Grasp Affordance. (arXiv:2204.02320v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02320">
<div class="article-summary-box-inner">
<span><p>Dexterous manipulation with a multi-finger hand is one of the most
challenging problems in robotics. While recent progress in imitation learning
has largely improved the sample efficiency compared to Reinforcement Learning,
the learned policy can hardly generalize to manipulate novel objects, given
limited expert demonstrations. In this paper, we propose to learn dexterous
manipulation using large-scale demonstrations with diverse 3D objects in a
category, which are generated from a human grasp affordance model. This
generalizes the policy to novel object instances within the same category. To
train the policy, we propose a novel imitation learning objective jointly with
a geometric representation learning objective using our demonstrations. By
experimenting with relocating diverse objects in simulation, we show that our
approach outperforms baselines with a large margin when manipulating novel
objects. We also ablate the importance on 3D object representation learning for
manipulation. We include videos, code, and additional information on the
project website - https://kristery.github.io/ILAD/ .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor Detection. (arXiv:2204.11515v3 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11515">
<div class="article-summary-box-inner">
<span><p>In recent years, rumors have had a devastating impact on society, making
rumor detection a significant challenge. However, the studies on rumor
detection ignore the intense emotions of images in the rumor content. This
paper verifies that the image emotion improves the rumor detection efficiency.
A Multimodal Dual Emotion feature in rumor detection, which consists of visual
and textual emotions, is proposed. To the best of our knowledge, this is the
first study which uses visual emotion in rumor detection. The experiments on
real datasets verify that the proposed features outperform the state-of-the-art
sentiment features, and can be extended in rumor detectors while improving
their performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-level Consistency Learning for Semi-supervised Domain Adaptation. (arXiv:2205.04066v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.04066">
<div class="article-summary-box-inner">
<span><p>Semi-supervised domain adaptation (SSDA) aims to apply knowledge learned from
a fully labeled source domain to a scarcely labeled target domain. In this
paper, we propose a Multi-level Consistency Learning (MCL) framework for SSDA.
Specifically, our MCL regularizes the consistency of different views of target
domain samples at three levels: (i) at inter-domain level, we robustly and
accurately align the source and target domains using a prototype-based optimal
transport method that utilizes the pros and cons of different views of target
samples; (ii) at intra-domain level, we facilitate the learning of both
discriminative and compact target feature representations by proposing a novel
class-wise contrastive clustering loss; (iii) at sample level, we follow
standard practice and improve the prediction accuracy by conducting a
consistency-based self-training. Empirically, we verified the effectiveness of
our MCL framework on three popular SSDA benchmarks, i.e., VisDA2017, DomainNet,
and Office-Home datasets, and the experimental results demonstrate that our MCL
framework achieves the state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting the Updates of a Pre-trained Model for Few-shot Learning. (arXiv:2205.07874v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07874">
<div class="article-summary-box-inner">
<span><p>Most of the recent few-shot learning algorithms are based on transfer
learning, where a model is pre-trained using a large amount of source data, and
the pre-trained model is updated using a small amount of target data afterward.
In transfer-based few-shot learning, sophisticated pre-training methods have
been widely studied for universal and improved representation. However, there
is little study on updating pre-trained models for few-shot learning. In this
paper, we compare the two popular updating methods, fine-tuning (i.e., updating
the entire network) and linear probing (i.e., updating only the linear
classifier), considering the distribution shift between the source and target
data. We find that fine-tuning is better than linear probing as the number of
samples increases, regardless of distribution shift. Next, we investigate the
effectiveness and ineffectiveness of data augmentation when pre-trained models
are fine-tuned. Our fundamental analyses demonstrate that careful
considerations of the details about updating pre-trained models are required
for better few-shot performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Subcellular Protein Localisation in the Human Protein Atlas using Ensembles of Diverse Deep Architectures. (arXiv:2205.09841v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09841">
<div class="article-summary-box-inner">
<span><p>Automated visual localisation of subcellular proteins can accelerate our
understanding of cell function in health and disease. Despite recent advances
in machine learning (ML), humans still attain superior accuracy by using
diverse visual cues. We show how this gap can be narrowed by addressing three
key aspects: (i) automated improvement of cell annotation quality, (ii) new
Deep Neural Network (DNN) architectures supporting unbalanced and noisy data,
and (iii) informed selection and fusion of multiple &amp; diverse machine learning
models. We introduce a new ``AI-trains-AI'' method for improving the quality of
weak labels and propose novel DNN architectures exploiting wavelet filters and
Weibull activations. We also explore key factors in the multi-DNN ensembling
process by analysing correlations between image-level and cell-level
predictions. Finally, in the context of the Human Protein Atlas, we demonstrate
that our system achieves state-of-the-art performance in the multi-label
single-cell classification of protein localisation patterns, while
strengthening generalisation ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiview Textured Mesh Recovery by Differentiable Rendering. (arXiv:2205.12468v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12468">
<div class="article-summary-box-inner">
<span><p>Although having achieved the promising results on shape and color recovery
through self-supervision, the multi-layer perceptrons-based methods usually
suffer from heavy computational cost on learning the deep implicit surface
representation. Since rendering each pixel requires a forward network
inference, it is very computational intensive to synthesize a whole image. To
tackle these challenges, we propose an effective coarse-to-fine approach to
recover the textured mesh from multi-views in this paper. Specifically, a
differentiable Poisson Solver is employed to represent the object's shape,
which is able to produce topology-agnostic and watertight surfaces. To account
for depth information, we optimize the shape geometry by minimizing the
differences between the rendered mesh and the predicted depth from multi-view
stereo. In contrast to the implicit neural representation on shape and color,
we introduce a physically based inverse rendering scheme to jointly estimate
the environment lighting and object's reflectance, which is able to render the
high resolution image at real-time. The texture of the reconstructed mesh is
interpolated from a learnable dense texture grid. We have conducted the
extensive experiments on several multi-view stereo datasets, whose promising
results demonstrate the efficacy of our proposed approach. The code is
available at https://github.com/l1346792580123/diff.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GIT: A Generative Image-to-text Transformer for Vision and Language. (arXiv:2205.14100v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14100">
<div class="article-summary-box-inner">
<span><p>In this paper, we design and train a Generative Image-to-text Transformer,
GIT, to unify vision-language tasks such as image/video captioning and question
answering. While generative models provide a consistent network architecture
between pre-training and fine-tuning, existing work typically contains complex
structures (uni/multi-modal encoder/decoder) and depends on external modules
such as object detectors/taggers and optical character recognition (OCR). In
GIT, we simplify the architecture as one image encoder and one text decoder
under a single language modeling task. We also scale up the pre-training data
and the model size to boost the model performance. Without bells and whistles,
our GIT establishes new state of the arts on 12 challenging benchmarks with a
large margin. For instance, our model surpasses the human performance for the
first time on TextCaps (138.2 vs. 125.5 in CIDEr). Furthermore, we present a
new scheme of generation-based image classification and scene text recognition,
achieving decent performance on standard benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01612">
<div class="article-summary-box-inner">
<span><p>We introduce OmniXAI (short for Omni eXplainable AI), an open-source Python
library of eXplainable AI (XAI), which offers omni-way explainable AI
capabilities and various interpretable machine learning techniques to address
the pain points of understanding and interpreting the decisions made by machine
learning (ML) in practice. OmniXAI aims to be a one-stop comprehensive library
that makes explainable AI easy for data scientists, ML researchers and
practitioners who need explanation for various types of data, models and
explanation methods at different stages of ML process (data exploration,
feature engineering, model development, evaluation, and decision-making, etc).
In particular, our library includes a rich family of explanation methods
integrated in a unified interface, which supports multiple data types (tabular
data, images, texts, time-series), multiple types of ML models (traditional ML
in Scikit-learn and deep learning models in PyTorch/TensorFlow), and a range of
diverse explanation methods including "model-specific" and "model-agnostic"
ones (such as feature-attribution explanation, counterfactual explanation,
gradient-based explanation, etc). For practitioners, the library provides an
easy-to-use unified interface to generate the explanations for their
applications by only writing a few lines of codes, and also a GUI dashboard for
visualization of different explanations for more insights about decisions. In
this technical report, we present OmniXAI's design principles, system
architectures, and major functionalities, and also demonstrate several example
use cases across different types of data, tasks, and models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empirical Study of Quality Image Assessment for Synthesis of Fetal Head Ultrasound Imaging with DCGANs. (arXiv:2206.01731v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01731">
<div class="article-summary-box-inner">
<span><p>In this work, we present an empirical study of DCGANs, including
hyperparameter heuristics and image quality assessment, as a way to address the
scarcity of datasets to investigate fetal head ultrasound. We present
experiments to show the impact of different image resolutions, epochs, dataset
size input, and learning rates for quality image assessment on four metrics:
mutual information (MI), Fr\'echet inception distance (FID),
peak-signal-to-noise ratio (PSNR), and local binary pattern vector (LBPv). The
results show that FID and LBPv have stronger relationship with clinical image
quality scores. The resources to reproduce this work are available at
\url{https://github.com/budai4medtech/miua2022}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuralODF: Learning Omnidirectional Distance Fields for 3D Shape Representation. (arXiv:2206.05837v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05837">
<div class="article-summary-box-inner">
<span><p>In visual computing, 3D geometry is represented in many different forms
including meshes, point clouds, voxel grids, level sets, and depth images. Each
representation is suited for different tasks thus making the transformation of
one representation into another (forward map) an important and common problem.
We propose Omnidirectional Distance Fields (ODFs), a new 3D shape
representation that encodes geometry by storing the depth to the object's
surface from any 3D position in any viewing direction. Since rays are the
fundamental unit of an ODF, it can be used to easily transform to and from
common 3D representations like meshes or point clouds. Different from level set
methods that are limited to representing closed surfaces, ODFs are unsigned and
can thus model open surfaces (e.g., garments). We demonstrate that ODFs can be
effectively learned with a neural network (NeuralODF) despite the inherent
discontinuities at occlusion boundaries. We also introduce efficient forward
mapping algorithms for transforming ODFs to and from common 3D representations.
Specifically, we introduce an efficient Jumping Cubes algorithm for generating
meshes from ODFs. Experiments demonstrate that NeuralODF can learn to capture
high-quality shape by overfitting to a single object, and also learn to
generalize on common shape categories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmented Imagefication: A Data-driven Fault Detection Method for Aircraft Air Data Sensors. (arXiv:2206.09055v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09055">
<div class="article-summary-box-inner">
<span><p>In this paper, a novel data-driven approach named Augmented Imagefication for
Fault detection (FD) of aircraft air data sensors (ADS) is proposed.
Exemplifying the FD problem of aircraft air data sensors, an online FD scheme
on edge device based on deep neural network (DNN) is developed. First, the
aircraft inertial reference unit measurements is adopted as equivalent inputs,
which is scalable to different aircraft/flight cases. Data associated with 6
different aircraft/flight conditions are collected to provide diversity
(scalability) in the training/testing database. Then Augmented Imagefication is
proposed for the DNN-based prediction of flying conditions. The raw data are
reshaped as a grayscale image for convolutional operation, and the necessity of
augmentation is analyzed and pointed out. Different kinds of augmented method,
i.e. Flip, Repeat, Tile and their combinations are discussed, the result shows
that the All Repeat operation in both axes of image matrix leads to the best
performance of DNN. The interpretability of DNN is studied based on Grad-CAM,
which provide a better understanding and further solidifies the robustness of
DNN. Next the DNN model, VGG-16 with augmented imagefication data is optimized
for mobile hardware deployment. After pruning of DNN, a lightweight model
(98.79% smaller than original VGG-16) with high accuracy (slightly up by 0.27%)
and fast speed (time delay is reduced by 87.54%) is obtained. And the
hyperparameters optimization of DNN based on TPE is implemented and the best
combination of hyperparameters is determined (learning rate 0.001, iterative
epochs 600, and batch size 100 yields the highest accuracy at 0.987). Finally,
a online FD deployment based on edge device, Jetson Nano, is developed and the
real time monitoring of aircraft is achieved. We believe that this method is
instructive for addressing the FD problems in other similar fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Training with Autoencoders for Visual Anomaly Detection. (arXiv:2206.11723v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11723">
<div class="article-summary-box-inner">
<span><p>Deep convolutional autoencoders provide an effective tool for learning
non-linear dimensionality reduction in an unsupervised way. Recently, they have
been used for the task of anomaly detection in the visual domain. By optimising
for the reconstruction error using anomaly-free examples, the common belief is
that a trained network will have difficulties to reconstruct anomalous parts
during the test phase. This is usually done by controlling the capacity of the
network by either reducing the size of the bottleneck layer or enforcing
sparsity constraints on its activations. However, neither of these techniques
does explicitly penalise reconstruction of anomalous signals often resulting in
a poor detection. We tackle this problem by adapting a self-supervised learning
regime which allows to use discriminative information during training while
regularising the model to focus on the data manifold by means of a modified
reconstruction error resulting in an accurate detection. Unlike related
approaches, the inference of the proposed method during training and prediction
is very efficient processing the whole input image in one single step. Our
experiments on the MVTec Anomaly Detection dataset demonstrate high recognition
and localisation performance of the proposed method. On the texture-subset, in
particular, our approach consistently outperforms a bunch of recent anomaly
detection methods by a big margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DDPM-CD: Remote Sensing Change Detection using Denoising Diffusion Probabilistic Models. (arXiv:2206.11892v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11892">
<div class="article-summary-box-inner">
<span><p>Human civilization has an increasingly powerful influence on the earth
system, and earth observations are an invaluable tool for assessing and
mitigating the negative impacts. To this end, observing precisely defined
changes on Earth's surface is essential, and we propose an effective way to
achieve this goal. Notably, our change detection (CD)/ segmentation method
proposes a novel way to incorporate the millions of off-the-shelf, unlabeled,
remote sensing images available through different earth observation programs
into the training process through denoising diffusion probabilistic models. We
first leverage the information from these off-the-shelf, uncurated, and
unlabeled remote sensing images by using a pre-trained denoising diffusion
probabilistic model and then employ the multi-scale feature representations
from the diffusion model decoder to train a lightweight CD classifier to detect
precise changes. The experiments performed on four publically available CD
datasets show that the proposed approach achieves remarkably better results
than the state-of-the-art methods in F1, IoU, and overall accuracy. Code and
pre-trained models are available at: https://github.com/wgcban/ddpm-cd
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Your Sparse Neural Network Better with Any Mask. (arXiv:2206.12755v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12755">
<div class="article-summary-box-inner">
<span><p>Pruning large neural networks to create high-quality, independently trainable
sparse masks, which can maintain similar performance to their dense
counterparts, is very desirable due to the reduced space and time complexity.
As research effort is focused on increasingly sophisticated pruning methods
that leads to sparse subnetworks trainable from the scratch, we argue for an
orthogonal, under-explored theme: improving training techniques for pruned
sub-networks, i.e. sparse training. Apart from the popular belief that only the
quality of sparse masks matters for sparse training, in this paper we
demonstrate an alternative opportunity: one can carefully customize the sparse
training techniques to deviate from the default dense network training
protocols, consisting of introducing ``ghost" neurons and skip connections at
the early stage of training, and strategically modifying the initialization as
well as labels. Our new sparse training recipe is generally applicable to
improving training from scratch with various sparse masks. By adopting our
newly curated techniques, we demonstrate significant performance gains across
various popular datasets (CIFAR-10, CIFAR-100, TinyImageNet), architectures
(ResNet-18/32/104, Vgg16, MobileNet), and sparse mask options (lottery ticket,
SNIP/GRASP, SynFlow, or even randomly pruning), compared to the default
training protocols, especially at high sparsity levels. Code is at
https://github.com/VITA-Group/ToST
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Aesthetics Assessment Using Graph Attention Network. (arXiv:2206.12869v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12869">
<div class="article-summary-box-inner">
<span><p>Aspect ratio and spatial layout are two of the principal factors determining
the aesthetic value of a photograph. But, incorporating these into the
traditional convolution-based frameworks for the task of image aesthetics
assessment is problematic. The aspect ratio of the photographs gets distorted
while they are resized/cropped to a fixed dimension to facilitate training
batch sampling. On the other hand, the convolutional filters process
information locally and are limited in their ability to model the global
spatial layout of a photograph. In this work, we present a two-stage framework
based on graph neural networks and address both these problems jointly. First,
we propose a feature-graph representation in which the input image is modelled
as a graph, maintaining its original aspect ratio and resolution. Second, we
propose a graph neural network architecture that takes this feature-graph and
captures the semantic relationship between the different regions of the input
image using visual attention. Our experiments show that the proposed framework
advances the state-of-the-art results in aesthetic score regression on the
Aesthetic Visual Analysis (AVA) benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Strategy Optimized Pix2pix Approach for SAR-to-Optical Image Translation Task. (arXiv:2206.13042v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13042">
<div class="article-summary-box-inner">
<span><p>This technical report summarizes the analysis and approach on the
image-to-image translation task in the Multimodal Learning for Earth and
Environment Challenge (MultiEarth 2022). In terms of strategy optimization,
cloud classification is utilized to filter optical images with dense cloud
coverage to aid the supervised learning alike approach. The commonly used
pix2pix framework with a few optimizations is applied to build the model. A
weighted combination of mean squared error and mean absolute error is
incorporated in the loss function. As for evaluation, peak to signal ratio and
structural similarity were both considered in our preliminary analysis. Lastly,
our method achieved the second place with a final error score of 0.0412. The
results indicate great potential towards SAR-to-optical translation in remote
sensing tasks, specifically for the support of long-term environmental
monitoring and protection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound Videos. (arXiv:2206.13318v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13318">
<div class="article-summary-box-inner">
<span><p>Ultrasound examination is widely used in the clinical diagnosis of thyroid
nodules (benign/malignant). However, the accuracy relies heavily on radiologist
experience. Although deep learning techniques have been investigated for
thyroid nodules recognition. Current solutions are mainly based on static
ultrasound images, with limited temporal information used and inconsistent with
clinical diagnosis. This paper proposes a novel method for the automated
recognition of thyroid nodules through an exhaustive exploration of ultrasound
videos and key-frames. We first propose a detection-localization framework to
automatically identify the clinical key-frames with typical nodules in each
ultrasound video. Based on the localized key-frames, we develop a key-frame
guided video classification model for thyroid nodule recognition. Besides, we
introduce motion attention module to help network focus on significant frames
in an ultrasound video, which is consistent with clinical diagnosis. The
proposed thyroid nodule recognition framework is validated on clinically
collected ultrasound videos, demonstrating superior performance compared with
other state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Structured Prediction for Facial Landmark Detection. (arXiv:2010.09035v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09035">
<div class="article-summary-box-inner">
<span><p>Existing deep learning based facial landmark detection methods have achieved
excellent performance. These methods, however, do not explicitly embed the
structural dependencies among landmark points. They hence cannot preserve the
geometric relationships between landmark points or generalize well to
challenging conditions or unseen data. This paper proposes a method for deep
structured facial landmark detection based on combining a deep Convolutional
Network with a Conditional Random Field. We demonstrate its superior
performance to existing state-of-the-art techniques in facial landmark
detection, especially a better generalization ability on challenging datasets
that include large pose and occlusion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learn Fast, Segment Well: Fast Object Segmentation Learning on the iCub Robot. (arXiv:2206.13462v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13462">
<div class="article-summary-box-inner">
<span><p>The visual system of a robot has different requirements depending on the
application: it may require high accuracy or reliability, be constrained by
limited resources or need fast adaptation to dynamically changing environments.
In this work, we focus on the instance segmentation task and provide a
comprehensive study of different techniques that allow adapting an object
segmentation model in presence of novel objects or different domains. We
propose a pipeline for fast instance segmentation learning designed for robotic
applications where data come in stream. It is based on an hybrid method
leveraging on a pre-trained CNN for feature extraction and fast-to-train
Kernel-based classifiers. We also propose a training protocol that allows to
shorten the training time by performing feature extraction during the data
acquisition. We benchmark the proposed pipeline on two robotics datasets and we
deploy it on a real robot, i.e. the iCub humanoid. To this aim, we adapt our
method to an incremental setting in which novel objects are learned on-line by
the robot. The code to reproduce the experiments is publicly available on
GitHub.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-06-29 23:08:14.670082634 UTC">2022-06-29 23:08:14 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>