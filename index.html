<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-12-23T01:30:00Z">12-23</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Science of Human-AI Decision Making: A Survey of Empirical Studies. (arXiv:2112.11471v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11471">
<div class="article-summary-box-inner">
<span><p>As AI systems demonstrate increasingly strong predictive performance, their
adoption has grown in numerous domains. However, in high-stakes domains such as
criminal justice and healthcare, full automation is often not desirable due to
safety, ethical, and legal concerns, yet fully manual approaches can be
inaccurate and time consuming. As a result, there is growing interest in the
research community to augment human decision making with AI assistance. Besides
developing AI technologies for this purpose, the emerging field of human-AI
decision making must embrace empirical approaches to form a foundational
understanding of how humans interact and work with AI to make decisions. To
invite and help structure research efforts towards a science of understanding
and improving human-AI decision making, we survey recent literature of
empirical human-subject studies on this topic. We summarize the study design
choices made in over 100 papers in three important aspects: (1) decision tasks,
(2) AI models and AI assistance elements, and (3) evaluation metrics. For each
aspect, we summarize current trends, discuss gaps in current practices of the
field, and make a list of recommendations for future research. Our survey
highlights the need to develop common frameworks to account for the design and
research spaces of human-AI decision making, so that researchers can make
rigorous choices in study design, and the research community can build on each
other's work and produce generalizable scientific knowledge. We also hope this
survey will serve as a bridge for HCI and AI communities to work together to
mutually shape the empirical science and computational technologies for
human-AI decision making.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LSH methods for data deduplication in a Wikipedia artificial dataset. (arXiv:2112.11478v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11478">
<div class="article-summary-box-inner">
<span><p>This paper illustrates locality sensitive hasing (LSH) models for the
identification and removal of nearly redundant data in a text dataset. To
evaluate the different models, we create an artificial dataset for data
deduplication using English Wikipedia articles. Area-Under-Curve (AUC) over 0.9
were observed for most models, with the best model reaching 0.96. Deduplication
enables more effective model training by preventing the model from learning a
distribution that differs from the real one as a result of the repeated data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AtteSTNet -- An attention and subword tokenization based approach for code-switched Hindi-English hate speech detection. (arXiv:2112.11479v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11479">
<div class="article-summary-box-inner">
<span><p>Recent advancements in technology have led to a boost in social media usage
which has ultimately led to large amounts of user-generated data which also
includes hateful and offensive speech. The language used in social media is
often a combination of English and the native language in the region. In India,
Hindi is used predominantly and is often code-switched with English, giving
rise to the Hinglish (Hindi+English) language. Various approaches have been
made in the past to classify the code-mixed Hinglish hate speech using
different machine learning and deep learning-based techniques. However, these
techniques make use of recurrence on convolution mechanisms which are
computationally expensive and have high memory requirements. Past techniques
also make use of complex data processing making the existing techniques very
complex and non-sustainable to change in data. We propose a much simpler
approach which is not only at par with these complex networks but also exceeds
performance with the use of subword tokenization algorithms like BPE and
Unigram along with multi-head attention-based technique giving an accuracy of
87.41% and F1 score of 0.851 on standard datasets. Efficient use of BPE and
Unigram algorithms help handle the non-conventional Hinglish vocabulary making
our technique simple, efficient and sustainable to use in the real world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Compression of Natural Language Models. (arXiv:2112.11480v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11480">
<div class="article-summary-box-inner">
<span><p>Deep neural networks are effective feature extractors but they are
prohibitively large for deployment scenarios. Due to the huge number of
parameters, interpretability of parameters in different layers is not
straight-forward. This is why neural networks are sometimes considered black
boxes. Although simpler models are easier to explain, finding them is not easy.
If found, a sparse network that can fit to a data from scratch would help to
interpret parameters of a neural network. To this end, lottery ticket
hypothesis states that typical dense neural networks contain a small sparse
sub-network that can be trained to a reach similar test accuracy in an equal
number of steps. The goal of this work is to assess whether such a trainable
subnetwork exists for natural language models (NLM)s. To achieve this goal we
will review state-of-the-art compression techniques such as quantization,
knowledge distillation, and pruning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translating Human Mobility Forecasting through Natural Language Generation. (arXiv:2112.11481v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11481">
<div class="article-summary-box-inner">
<span><p>Existing human mobility forecasting models follow the standard design of the
time-series prediction model which takes a series of numerical values as input
to generate a numerical value as a prediction. Although treating this as a
regression problem seems straightforward, incorporating various contextual
information such as the semantic category information of each Place-of-Interest
(POI) is a necessary step, and often the bottleneck, in designing an effective
mobility prediction model. As opposed to the typical approach, we treat
forecasting as a translation problem and propose a novel forecasting through a
language generation pipeline. The paper aims to address the human mobility
forecasting problem as a language translation task in a sequence-to-sequence
manner. A mobility-to-language template is first introduced to describe the
numerical mobility data as natural language sentences. The core intuition of
the human mobility forecasting translation task is to convert the input
mobility description sentences into a future mobility description from which
the prediction target can be obtained. Under this pipeline, a two-branch
network, SHIFT (Translating Human Mobility Forecasting), is designed.
Specifically, it consists of one main branch for language generation and one
auxiliary branch to directly learn mobility patterns. During the training, we
develop a momentum mode for better connecting and training the two branches.
Extensive experiments on three real-world datasets demonstrate that the
proposed SHIFT is effective and presents a new revolutionary approach to
forecasting human mobility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">English2Gbe: A multilingual machine translation model for {Fon/Ewe}Gbe. (arXiv:2112.11482v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11482">
<div class="article-summary-box-inner">
<span><p>Language is an essential factor of emancipation. Unfortunately, most of the
more than 2,000 African languages are low-resourced. The community has recently
used machine translation to revive and strengthen several African languages.
However, the trained models are often bilingual, resulting in a potentially
exponential number of models to train and maintain to cover all possible
translation directions. Additionally, bilingual models do not leverage the
similarity between some of the languages. Consequently, multilingual neural
machine translation (NMT) is gaining considerable interest, especially for
low-resourced languages. Nevertheless, its adoption by the community is still
limited. This paper introduces English2Gbe, a multilingual NMT model capable of
translating from English to Ewe or Fon. Using the BLEU, CHRF, and TER scores
computed with the Sacrebleu (Post, 2018) package for reproducibility, we show
that English2Gbe outperforms bilingual models (English to Ewe and English to
Fon) and gives state-of-the-art results on the JW300 benchmark for Fon
established by Nekoto et al. (2020). We hope this work will contribute to the
massive adoption of Multilingual models inside the community. Our code is made
accessible from Github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BACON: Deep-Learning Powered AI for Poetry Generation with Author Linguistic Style Transfer. (arXiv:2112.11483v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11483">
<div class="article-summary-box-inner">
<span><p>This paper describes BACON, a basic prototype of an automatic poetry
generator with author linguistic style transfer. It combines concepts and
techniques from finite state machinery, probabilistic models, artificial neural
networks and deep learning, to write original poetry with rich
aesthetic-qualities in the style of any given author. Extrinsic evaluation of
the output generated by BACON shows that participants were unable to tell the
difference between human and AI-generated poems in any statistically
significant way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence Embeddings and High-speed Similarity Search for Fast Computer Assisted Annotation of Legal Documents. (arXiv:2112.11494v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11494">
<div class="article-summary-box-inner">
<span><p>Human-performed annotation of sentences in legal documents is an important
prerequisite to many machine learning based systems supporting legal tasks.
Typically, the annotation is done sequentially, sentence by sentence, which is
often time consuming and, hence, expensive. In this paper, we introduce a
proof-of-concept system for annotating sentences "laterally." The approach is
based on the observation that sentences that are similar in meaning often have
the same label in terms of a particular type system. We use this observation in
allowing annotators to quickly view and annotate sentences that are
semantically similar to a given sentence, across an entire corpus of documents.
Here, we present the interface of the system and empirically evaluate the
approach. The experiments show that lateral annotation has the potential to
make the annotation process quicker and more consistent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixed Precision of Quantization of Transformer Language Models for Speech Recognition. (arXiv:2112.11540v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11540">
<div class="article-summary-box-inner">
<span><p>State-of-the-art neural language models represented by Transformers are
becoming increasingly complex and expensive for practical applications. Low-bit
deep neural network quantization techniques provides a powerful solution to
dramatically reduce their model size. Current low-bit quantization methods are
based on uniform precision and fail to account for the varying performance
sensitivity at different parts of the system to quantization errors. To this
end, novel mixed precision DNN quantization methods are proposed in this paper.
The optimal local precision settings are automatically learned using two
techniques. The first is based on a quantization sensitivity metric in the form
of Hessian trace weighted quantization perturbation. The second is based on
mixed precision Transformer architecture search. Alternating direction methods
of multipliers (ADMM) are used to efficiently train mixed precision quantized
DNN systems. Experiments conducted on Penn Treebank (PTB) and a Switchboard
corpus trained LF-MMI TDNN system suggest the proposed mixed precision
Transformer quantization techniques achieved model size compression ratios of
up to 16 times over the full precision baseline with no recognition performance
degradation. When being used to compress a larger full precision Transformer LM
with more layers, overall word error rate (WER) reductions up to 1.7% absolute
(18% relative) were obtained.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diformer: Directional Transformer for Neural Machine Translation. (arXiv:2112.11632v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11632">
<div class="article-summary-box-inner">
<span><p>Autoregressive (AR) and Non-autoregressive (NAR) models have their own
superiority on the performance and latency, combining them into one model may
take advantage of both. Current combination frameworks focus more on the
integration of multiple decoding paradigms with a unified generative model,
e.g. Masked Language Model. However, the generalization can be harmful to the
performance due to the gap between training objective and inference. In this
paper, we aim to close the gap by preserving the original objective of AR and
NAR under a unified framework. Specifically, we propose the Directional
Transformer (Diformer) by jointly modelling AR and NAR into three generation
directions (left-to-right, right-to-left and straight) with a newly introduced
direction variable, which works by controlling the prediction of each token to
have specific dependencies under that direction. The unification achieved by
direction successfully preserves the original dependency assumption used in AR
and NAR, retaining both generalization and performance. Experiments on 4 WMT
benchmarks demonstrate that Diformer outperforms current united-modelling works
with more than 1.5 BLEU points for both AR and NAR decoding, and is also
competitive to the state-of-the-art independent AR and NAR models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistency and Coherence from Points of Contextual Similarity. (arXiv:2112.11638v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11638">
<div class="article-summary-box-inner">
<span><p>Factual consistency is one of important summary evaluation dimensions,
especially as summary generation becomes more fluent and coherent. The ESTIME
measure, recently proposed specifically for factual consistency, achieves high
correlations with human expert scores both for consistency and fluency, while
in principle being restricted to evaluating such text-summary pairs that have
high dictionary overlap. This is not a problem for current styles of
summarization, but it may become an obstacle for future summarization systems,
or for evaluating arbitrary claims against the text. In this work we generalize
the method, making it applicable to any text-summary pairs. As ESTIME uses
points of contextual similarity, it provides insights into usefulness of
information taken from different BERT layers. We observe that useful
information exists in almost all of the layers except the several lowest ones.
For consistency and fluency - qualities focused on local text details - the
most useful layers are close to the top (but not at the top); for coherence and
relevance we found a more complicated and interesting picture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Distillation Mixup Training for Non-autoregressive Neural Machine Translation. (arXiv:2112.11640v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11640">
<div class="article-summary-box-inner">
<span><p>Recently, non-autoregressive (NAT) models predict outputs in parallel,
achieving substantial improvements in generation speed compared to
autoregressive (AT) models. While performing worse on raw data, most NAT models
are trained as student models on distilled data generated by AT teacher models,
which is known as sequence-level Knowledge Distillation. An effective training
strategy to improve the performance of AT models is Self-Distillation Mixup
(SDM) Training, which pre-trains a model on raw data, generates distilled data
by the pre-trained model itself and finally re-trains a model on the
combination of raw data and distilled data. In this work, we aim to view SDM
for NAT models, but find directly adopting SDM to NAT models gains no
improvements in terms of translation quality. Through careful analysis, we
observe the invalidation is correlated to Modeling Diversity and Confirmation
Bias between the AT teacher model and the NAT student models. Based on these
findings, we propose an enhanced strategy named SDMRT by adding two stages to
classic SDM: one is Pre-Rerank on self-distilled data, the other is Fine-Tune
on Filtered teacher-distilled data. Our results outperform baselines by 0.6 to
1.2 BLEU on multiple NAT models. As another bonus, for Iterative Refinement NAT
models, our methods can outperform baselines within half iteration number,
which means 2X acceleration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint-training on Symbiosis Networks for Deep Nueral Machine Translation models. (arXiv:2112.11642v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11642">
<div class="article-summary-box-inner">
<span><p>Deep encoders have been proven to be effective in improving neural machine
translation (NMT) systems, but it reaches the upper bound of translation
quality when the number of encoder layers exceeds 18. Worse still, deeper
networks consume a lot of memory, making it impossible to train efficiently. In
this paper, we present Symbiosis Networks, which include a full network as the
Symbiosis Main Network (M-Net) and another shared sub-network with the same
structure but less layers as the Symbiotic Sub Network (S-Net). We adopt
Symbiosis Networks on Transformer-deep (m-n) architecture and define a
particular regularization loss $\mathcal{L}_{\tau}$ between the M-Net and S-Net
in NMT. We apply joint-training on the Symbiosis Networks and aim to improve
the M-Net performance. Our proposed training strategy improves Transformer-deep
(12-6) by 0.61, 0.49 and 0.69 BLEU over the baselines under classic training on
WMT'14 EN-&gt;DE, DE-&gt;EN and EN-&gt;FR tasks. Furthermore, our Transformer-deep
(12-6) even outperforms classic Transformer-deep (18-6).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Should Pre-Trained Language Models Be Fine-Tuned Towards Adversarial Robustness?. (arXiv:2112.11668v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11668">
<div class="article-summary-box-inner">
<span><p>The fine-tuning of pre-trained language models has a great success in many
NLP fields. Yet, it is strikingly vulnerable to adversarial examples, e.g.,
word substitution attacks using only synonyms can easily fool a BERT-based
sentiment analysis model. In this paper, we demonstrate that adversarial
training, the prevalent defense technique, does not directly fit a conventional
fine-tuning scenario, because it suffers severely from catastrophic forgetting:
failing to retain the generic and robust linguistic features that have already
been captured by the pre-trained model. In this light, we propose Robust
Informative Fine-Tuning (RIFT), a novel adversarial fine-tuning method from an
information-theoretical perspective. In particular, RIFT encourages an
objective model to retain the features learned from the pre-trained model
throughout the entire fine-tuning process, whereas a conventional one only uses
the pre-trained weights for initialization. Experimental results show that RIFT
consistently outperforms the state-of-the-arts on two popular NLP tasks:
sentiment analysis and natural language inference, under different attacks
across various pre-trained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptation with Pre-trained Transformers for Query Focused Abstractive Text Summarization. (arXiv:2112.11670v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11670">
<div class="article-summary-box-inner">
<span><p>The Query Focused Text Summarization (QFTS) task aims at building systems
that generate the summary of the text document(s) based on the given query. A
key challenge in addressing this task is the lack of large labeled data for
training the summarization model. In this paper, we address this challenge by
exploring a series of domain adaptation techniques. Given the recent success of
pre-trained transformer models in a wide range of natural language processing
tasks, we utilize such models to generate abstractive summaries for the QFTS
task for both single-document and multi-document scenarios. For domain
adaptation, we apply a variety of techniques using pre-trained
transformer-based summarization models including transfer learning, weakly
supervised learning, and distant supervision. Extensive experiments on six
datasets show that our proposed approach is very effective in generating
abstractive summaries for the QFTS task while setting a new state-of-the-art
result in several datasets across a set of automatic and human evaluation
metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hybrid Curriculum Learning for Emotion Recognition in Conversation. (arXiv:2112.11718v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11718">
<div class="article-summary-box-inner">
<span><p>Emotion recognition in conversation (ERC) aims to detect the emotion label
for each utterance. Motivated by recent studies which have proven that feeding
training examples in a meaningful order rather than considering them randomly
can boost the performance of models, we propose an ERC-oriented hybrid
curriculum learning framework. Our framework consists of two curricula: (1)
conversation-level curriculum (CC); and (2) utterance-level curriculum (UC). In
CC, we construct a difficulty measurer based on "emotion shift" frequency
within a conversation, then the conversations are scheduled in an "easy to
hard" schema according to the difficulty score returned by the difficulty
measurer. For UC, it is implemented from an emotion-similarity perspective,
which progressively strengthens the model's ability in identifying the
confusing emotions. With the proposed model-agnostic hybrid curriculum learning
strategy, we observe significant performance boosts over a wide range of
existing ERC models and we are able to achieve new state-of-the-art results on
four public ERC datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Natural Language Generation. (arXiv:2112.11739v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11739">
<div class="article-summary-box-inner">
<span><p>This paper offers a comprehensive review of the research on Natural Language
Generation (NLG) over the past two decades, especially in relation to
data-to-text generation and text-to-text generation deep learning methods, as
well as new applications of NLG technology. This survey aims to (a) give the
latest synthesis of deep learning research on the NLG core tasks, as well as
the architectures adopted in the field; (b) detail meticulously and
comprehensively various NLG tasks and datasets, and draw attention to the
challenges in NLG evaluation, focusing on different evaluation methods and
their relationships; (c) highlight some future emphasis and relatively recent
research issues that arise due to the increasing synergy between NLG and other
artificial intelligence areas, such as computer vision, text and computational
creativity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Label Dependence-aware Sequence Generation Model for Multi-level Implicit Discourse Relation Recognition. (arXiv:2112.11740v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11740">
<div class="article-summary-box-inner">
<span><p>Implicit discourse relation recognition (IDRR) is a challenging but crucial
task in discourse analysis. Most existing methods train multiple models to
predict multi-level labels independently, while ignoring the dependence between
hierarchically structured labels. In this paper, we consider multi-level IDRR
as a conditional label sequence generation task and propose a Label
Dependence-aware Sequence Generation Model (LDSGM) for it. Specifically, we
first design a label attentive encoder to learn the global representation of an
input instance and its level-specific contexts, where the label dependence is
integrated to obtain better label embeddings. Then, we employ a label sequence
decoder to output the predicted labels in a top-down manner, where the
predicted higher-level labels are directly used to guide the label prediction
at the current level. We further develop a mutual learning enhanced training
method to exploit the label dependence in a bottomup direction, which is
captured by an auxiliary decoder introduced during training. Experimental
results on the PDTB dataset show that our model achieves the state-of-the-art
performance on multi-level IDRR. We will release our code at
https://github.com/nlpersECJTU/LDSGM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Theoretical Complexity and Boolean Satisfiability. (arXiv:2112.11769v1 [cs.CC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11769">
<div class="article-summary-box-inner">
<span><p>Theoretical complexity is a vital subfield of computer science that enables
us to mathematically investigate computation and answer many interesting
queries about the nature of computational problems. It provides theoretical
tools to assess time and space requirements of computations along with
assessing the difficultly of problems - classifying them accordingly. It also
garners at its core one of the most important problems in mathematics, namely,
the $\textbf{P vs. NP}$ millennium problem. In essence, this problem asks
whether solution and verification reside on two different levels of difficulty.
In this thesis, we introduce some of the most central concepts in the Theory of
Computing, giving an overview of how computation can be abstracted using Turing
machines. Further, we introduce the two most famous problem complexity classes
$\textbf{P}$ and $\textbf{NP}$ along with the relationship between them. In
addition, we explicate the concept of problem reduction and how it is an
essential tool for making hardness comparisons between different problems.
Later, we present the problem of Boolean Satisfiability (SAT) which lies at the
center of NP-complete problems. We then explore some of its tractable as well
as intractable variants such as Horn-SAT and 3-SAT, respectively. Last but not
least, we establish polynomial-time reductions from 3-SAT to some of the famous
NP-complete graph problems, namely, Clique Finding, Hamiltonian Cycle Finding,
and 3-Coloring.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Importance of the Current Input in Sequence Modeling. (arXiv:2112.11776v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11776">
<div class="article-summary-box-inner">
<span><p>The last advances in sequence modeling are mainly based on deep learning
approaches. The current state of the art involves the use of variations of the
standard LSTM architecture, combined with several tricks that improve the final
prediction rates of the trained neural networks. However, in some cases, these
adaptations might be too much tuned to the particular problems being addressed.
In this article, we show that a very simple idea, to add a direct connection
between the input and the output, skipping the recurrent module, leads to an
increase of the prediction accuracy in sequence modeling problems related to
natural language processing. Experiments carried out on different problems show
that the addition of this kind of connection to a recurrent network always
improves the results, regardless of the architecture and training-specific
details. When this idea is introduced into the models that lead the field, the
resulting networks achieve a new state-of-the-art perplexity in language
modeling problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">STEREO: Scientific Text Reuse in Open Access Publications. (arXiv:2112.11800v1 [cs.DL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11800">
<div class="article-summary-box-inner">
<span><p>We present the Webis-STEREO-21 dataset, a massive collection of Scientific
Text Reuse in Open-access publications. It contains more than 91 million cases
of reused text passages found in 4.2 million unique open-access publications.
Featuring a high coverage of scientific disciplines and varieties of reuse, as
well as comprehensive metadata to contextualize each case, our dataset
addresses the most salient shortcomings of previous ones on scientific writing.
Webis-STEREO-21 allows for tackling a wide range of research questions from
different scientific backgrounds, facilitating both qualitative and
quantitative analysis of the phenomenon as well as a first-time grounding on
the base rate of text reuse in scientific publications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Analysis of memes for sentiment extraction. (arXiv:2112.11850v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11850">
<div class="article-summary-box-inner">
<span><p>Memes are one of the most ubiquitous forms of social media communication. The
study and processing of memes, which are intrinsically multimedia, is a popular
topic right now. The study presented in this research is based on the Memotion
dataset, which involves categorising memes based on irony, comedy, motivation,
and overall-sentiment. Three separate innovative transformer-based techniques
have been developed, and their outcomes have been thoroughly reviewed.The best
algorithm achieved a macro F1 score of 0.633 for humour classification, 0.55
for motivation classification, 0.61 for sarcasm classification, and 0.575 for
overall sentiment of the meme out of all our techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Multi-hop Question Answering over Knowledge Base. (arXiv:2112.11909v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11909">
<div class="article-summary-box-inner">
<span><p>Previous work on Chinese Knowledge Base Question Answering has been
restricted due to the lack of complex Chinese semantic parsing dataset and the
exponentially growth of searching space with the length of relation paths. This
paper proposes an efficient pipeline method equipped with a pre-trained
language model and a strategy to construct artificial training samples, which
only needs small amount of data but performs well on open-domain complex
Chinese Question Answering task. Besides, By adopting a Beam Search algorithm
based on a language model marking scores for candidate query tuples, we
decelerate the growing relation paths when generating multi-hop query paths.
Finally, we evaluate our model on CCKS2019 Complex Question Answering via
Knowledge Base task and achieves F1-score of 62.55\% on the test dataset.
Moreover when training with only 10\% data, our model can still achieves
F1-score of 58.54\%. The result shows the capability of our model to process
KBQA task and the advantage in few-shot learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Interactive Language Modeling. (arXiv:2112.11911v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11911">
<div class="article-summary-box-inner">
<span><p>Interaction between caregivers and children plays a critical role in human
language acquisition and development. Given this observation, it is remarkable
that explicit interaction plays little to no role in artificial language
modeling -- which also targets the acquisition of human language, yet by
artificial models. Moreover, an interactive approach to language modeling has
the potential to make language models substantially more versatile and to
considerably impact downstream applications. Motivated by these considerations,
we pioneer the space of interactive language modeling. As a first contribution
we present a road map in which we detail the steps that need to be taken
towards interactive language modeling. We then lead by example and take the
first steps on this road map, showing the initial feasibility of our approach.
As such, this work aims to be the start of a larger research agenda on
interactive language modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trees in transformers: a theoretical analysis of the Transformer's ability to represent trees. (arXiv:2112.11913v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11913">
<div class="article-summary-box-inner">
<span><p>Transformer networks are the de facto standard architecture in natural
language processing. To date, there are no theoretical analyses of the
Transformer's ability to capture tree structures. We focus on the ability of
Transformer networks to learn tree structures that are important for tree
transduction problems. We first analyze the theoretical capability of the
standard Transformer architecture to learn tree structures given enumeration of
all possible tree backbones, which we define as trees without labels. We then
prove that two linear layers with ReLU activation function can recover any tree
backbone from any two nonzero, linearly independent starting backbones. This
implies that a Transformer can learn tree structures well in theory. We conduct
experiments with synthetic data and find that the standard Transformer achieves
similar accuracy compared to a Transformer where tree position information is
explicitly encoded, albeit with slower convergence. This confirms empirically
that Transformers can learn tree structures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assisted Text Annotation Using Active Learning to Achieve High Quality with Little Effort. (arXiv:2112.11914v1 [cs.DL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11914">
<div class="article-summary-box-inner">
<span><p>Large amounts of annotated data have become more important than ever,
especially since the rise of deep learning techniques. However, manual
annotations are costly. We propose a tool that enables researchers to create
large, high-quality, annotated datasets with only a few manual annotations,
thus strongly reducing annotation cost and effort. For this purpose, we combine
an active learning (AL) approach with a pre-trained language model to
semi-automatically identify annotation categories in the given text documents.
To highlight our research direction's potential, we evaluate the approach on
the task of identifying frames in news articles. Our preliminary results show
that employing AL strongly reduces the number of annotations for correct
classification of even these complex and subtle frames. On the framing dataset,
the AL approach needs only 16.3\% of the annotations to reach the same
performance as a model trained on the full dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Product Copywriting for E-Commerce. (arXiv:2112.11915v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11915">
<div class="article-summary-box-inner">
<span><p>Product copywriting is a critical component of e-commerce recommendation
platforms. It aims to attract users' interest and improve user experience by
highlighting product characteristics with textual descriptions. In this paper,
we report our experience deploying the proposed Automatic Product Copywriting
Generation (APCG) system into the JD.com e-commerce product recommendation
platform. It consists of two main components: 1) natural language generation,
which is built from a transformer-pointer network and a pre-trained
sequence-to-sequence model based on millions of training data from our in-house
platform; and 2) copywriting quality control, which is based on both automatic
evaluation and human screening. For selected domains, the models are trained
and updated daily with the updated training data. In addition, the model is
also used as a real-time writing assistant tool on our live broadcast platform.
The APCG system has been deployed in JD.com since Feb 2021. By Sep 2021, it has
generated 2.53 million product descriptions, and improved the overall averaged
click-through rate (CTR) and the Conversion Rate (CVR) by 4.22% and 3.61%,
compared to baselines, respectively on a year-on-year basis. The accumulated
Gross Merchandise Volume (GMV) made by our system is improved by 213.42%,
compared to the number in Feb 2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ALP: Data Augmentation using Lexicalized PCFGs for Few-Shot Text Classification. (arXiv:2112.11916v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11916">
<div class="article-summary-box-inner">
<span><p>Data augmentation has been an important ingredient for boosting performances
of learned models. Prior data augmentation methods for few-shot text
classification have led to great performance boosts. However, they have not
been designed to capture the intricate compositional structure of natural
language. As a result, they fail to generate samples with plausible and diverse
sentence structures. Motivated by this, we present the data Augmentation using
Lexicalized Probabilistic context-free grammars (ALP) that generates augmented
samples with diverse syntactic structures with plausible grammar. The
lexicalized PCFG parse trees consider both the constituents and dependencies to
produce a syntactic frame that maximizes a variety of word choices in a
syntactically preservable manner without specific domain experts. Experiments
on few-shot text classification tasks demonstrate that ALP enhances many
state-of-the-art classification methods. As a second contribution, we delve
into the train-val splitting methodologies when a data augmentation method
comes into play. We argue empirically that the traditional splitting of
training and validation sets is sub-optimal compared to our novel
augmentation-based splitting strategies that further expand the training split
with the same number of labeled data. Taken together, our contributions on the
data augmentation strategies yield a strong training recipe for few-shot text
classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CRASS: A Novel Data Set and Benchmark to Test Counterfactual Reasoning of Large Language Models. (arXiv:2112.11941v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11941">
<div class="article-summary-box-inner">
<span><p>We introduce the CRASS (counterfactual reasoning assessment) data set and
benchmark utilizing questionized counterfactual conditionals as a novel and
powerful tool to evaluate large language models. We present the data set design
and benchmark as well as the accompanying API that supports scoring against a
crowd-validated human baseline. We test six state-of-the-art models against our
benchmark. Our results show that it poses a valid challenge for these models
and opens up considerable room for their improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text is no more Enough! A Benchmark for Profile-based Spoken Language Understanding. (arXiv:2112.11953v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11953">
<div class="article-summary-box-inner">
<span><p>Current researches on spoken language understanding (SLU) heavily are limited
to a simple setting: the plain text-based SLU that takes the user utterance as
input and generates its corresponding semantic frames (e.g., intent and slots).
Unfortunately, such a simple setting may fail to work in complex real-world
scenarios when an utterance is semantically ambiguous, which cannot be achieved
by the text-based SLU models. In this paper, we first introduce a new and
important task, Profile-based Spoken Language Understanding (ProSLU), which
requires the model that not only relies on the plain text but also the
supporting profile information to predict the correct intents and slots. To
this end, we further introduce a large-scale human-annotated Chinese dataset
with over 5K utterances and their corresponding supporting profile information
(Knowledge Graph (KG), User Profile (UP), Context Awareness (CA)). In addition,
we evaluate several state-of-the-art baseline models and explore a multi-level
knowledge adapter to effectively incorporate profile information. Experimental
results reveal that all existing text-based SLU models fail to work when the
utterances are semantically ambiguous and our proposed framework can
effectively fuse the supporting information for sentence-level intent detection
and token-level slot filling. Finally, we summarize key challenges and provide
new points for future directions, which hopes to facilitate the research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Educator-focused Automated Scoring Systems for Reading and Writing. (arXiv:2112.11973v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11973">
<div class="article-summary-box-inner">
<span><p>This paper presents methods for improving automated essay scoring with
techniques that address the computational trade-offs of self-attention and
document length. To make Automated Essay Scoring (AES) more useful to
practitioners, researchers must overcome the challenges of data and label
availability, authentic and extended writing, domain scoring, prompt and source
variety, and transfer learning. This paper addresses these challenges using
neural network models by employing techniques that preserve essay length as an
important feature without increasing model training costs. It introduces
techniques for minimizing classification loss on ordinal labels using
multi-objective learning, capturing semantic information across the entire
essay using sentence embeddings to use transformer architecture across
arbitrarily long documents, the use of such models for transfer learning,
automated hyperparameter generation based on prompt-corpus metadata, and, most
importantly, the use of semantic information to provide meaningful insights
into student reading through analysis of passage-dependent writing resulting in
state-of-the-art results for various essay tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantifying Gender Biases Towards Politicians on Reddit. (arXiv:2112.12014v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12014">
<div class="article-summary-box-inner">
<span><p>Despite attempts to increase gender parity in politics, global efforts have
struggled to ensure equal female representation. This is likely tied to
implicit gender biases against women in authority. In this work, we present a
comprehensive study of gender biases that appear in online political
discussion. To this end, we collect 10 million comments on Reddit in
conversations about male and female politicians, which enables an exhaustive
study of automatic gender bias detection. We address not only misogynistic
language, but also benevolent sexism in the form of seemingly positive
attitudes examining both sentiment and dominance attributed to female
politicians. Finally, we conduct a multi-faceted study of gender bias towards
politicians investigating both linguistic and extra-linguistic cues. We assess
5 different types of gender bias, evaluating coverage, combinatorial, nominal,
sentimental and lexical biases extant in social media language and discourse.
Overall, we find that, contrary to previous research, coverage and sentiment
biases suggest equal public interest in female politicians. However, the
results of the nominal and lexical analyses suggest this interest is not as
professional or respectful as that expressed about male politicians. Female
politicians are often named by their first names and are described in relation
to their body, clothing, or family; this is a treatment that is not similarly
extended to men. On the now banned far-right subreddits, this disparity is
greatest, though differences in gender biases still appear in the right and
left-leaning subreddits. We release the curated dataset to the public for
future studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VoiceMoji: A Novel On-Device Pipeline for Seamless Emoji Insertion in Dictation. (arXiv:2112.12028v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12028">
<div class="article-summary-box-inner">
<span><p>Most of the speech recognition systems recover only words in the speech and
fail to capture emotions. Users have to manually add emoji(s) in text for
adding tone and making communication fun. Though there is much work done on
punctuation addition on transcribed speech, the area of emotion addition is
untouched. In this paper, we propose a novel on-device pipeline to enrich the
voice input experience. It involves, given a blob of transcribed text,
intelligently processing and identifying structure where emoji insertion makes
sense. Moreover, it includes semantic text analysis to predict emoji for each
of the sub-parts for which we propose a novel architecture Attention-based Char
Aware (ACA) LSTM which handles Out-Of-Vocabulary (OOV) words as well. All these
tasks are executed completely on-device and hence can aid on-device dictation
systems. To the best of our knowledge, this is the first work that shows how to
add emoji(s) in the transcribed text. We demonstrate that our components
achieve comparable results to previous neural approaches for punctuation
addition and emoji prediction with 80% fewer parameters. Overall, our proposed
model has a very small memory footprint of a mere 4MB to suit on-device
deployment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Cross-Modality Semantic Correlation Learning Model for Multimodal Summarization. (arXiv:2112.12072v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12072">
<div class="article-summary-box-inner">
<span><p>Multimodal summarization with multimodal output (MSMO) generates a summary
with both textual and visual content. Multimodal news report contains
heterogeneous contents, which makes MSMO nontrivial. Moreover, it is observed
that different modalities of data in the news report correlate hierarchically.
Traditional MSMO methods indistinguishably handle different modalities of data
by learning a representation for the whole data, which is not directly
adaptable to the heterogeneous contents and hierarchical correlation. In this
paper, we propose a hierarchical cross-modality semantic correlation learning
model (HCSCL) to learn the intra- and inter-modal correlation existing in the
multimodal data. HCSCL adopts a graph network to encode the intra-modal
correlation. Then, a hierarchical fusion framework is proposed to learn the
hierarchical correlation between text and images. Furthermore, we construct a
new dataset with relevant image annotation and image object label information
to provide the supervision information for the learning procedure. Extensive
experiments on the dataset show that HCSCL significantly outperforms the
baseline methods in automatic summarization metrics and fine-grained diversity
tests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reevaluating Adversarial Examples in Natural Language. (arXiv:2004.14174v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.14174">
<div class="article-summary-box-inner">
<span><p>State-of-the-art attacks on NLP models lack a shared definition of a what
constitutes a successful attack. We distill ideas from past work into a unified
framework: a successful natural language adversarial example is a perturbation
that fools the model and follows some linguistic constraints. We then analyze
the outputs of two state-of-the-art synonym substitution attacks. We find that
their perturbations often do not preserve semantics, and 38% introduce
grammatical errors. Human surveys reveal that to successfully preserve
semantics, we need to significantly increase the minimum cosine similarities
between the embeddings of swapped words and between the sentence encodings of
original and perturbed sentences.With constraints adjusted to better preserve
semantics and grammaticality, the attack success rate drops by over 70
percentage points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Text Classification: From Shallow to Deep Learning. (arXiv:2008.00364v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00364">
<div class="article-summary-box-inner">
<span><p>Text classification is the most fundamental and essential task in natural
language processing. The last decade has seen a surge of research in this area
due to the unprecedented success of deep learning. Numerous methods, datasets,
and evaluation metrics have been proposed in the literature, raising the need
for a comprehensive and updated survey. This paper fills the gap by reviewing
the state-of-the-art approaches from 1961 to 2021, focusing on models from
traditional models to deep learning. We create a taxonomy for text
classification according to the text involved and the models used for feature
extraction and classification. We then discuss each of these categories in
detail, dealing with both the technical developments and benchmark datasets
that support tests of predictions. A comprehensive comparison between different
techniques, as well as identifying the pros and cons of various evaluation
metrics are also provided in this survey. Finally, we conclude by summarizing
key implications, future research directions, and the challenges facing the
research area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Understanding for Field and Service Robots in a Priori Unknown Environments. (arXiv:2105.10396v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10396">
<div class="article-summary-box-inner">
<span><p>Contemporary approaches to perception, planning, estimation, and control have
allowed robots to operate robustly as our remote surrogates in uncertain,
unstructured environments. This progress now creates an opportunity for robots
to operate not only in isolation, but also with and alongside humans in our
complex environments. Realizing this opportunity requires an efficient and
flexible medium through which humans can communicate with collaborative robots.
Natural language provides one such medium, and through significant progress in
statistical methods for natural-language understanding, robots are now able to
interpret a diverse array of free-form commands. However, most contemporary
approaches require a detailed, prior spatial-semantic map of the robot's
environment that models the space of possible referents of an utterance.
Consequently, these methods fail when robots are deployed in new, previously
unknown, or partially-observed environments, particularly when mental models of
the environment differ between the human operator and the robot. This paper
provides a comprehensive description of a novel learning framework that allows
field and service robots to interpret and correctly execute natural-language
instructions in a priori unknown, unstructured environments. Integral to our
approach is its use of language as a "sensor" -- inferring spatial,
topological, and semantic information implicit in the utterance and then
exploiting this information to learn a distribution over a latent environment
model. We incorporate this distribution in a probabilistic, language grounding
model and infer a distribution over a symbolic representation of the robot's
action space. We use imitation learning to identify a belief-space policy that
reasons over the environment and behavior distributions. We evaluate our
framework through a variety navigation and mobile-manipulation experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Annotation Curricula to Implicitly Train Non-Expert Annotators. (arXiv:2106.02382v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02382">
<div class="article-summary-box-inner">
<span><p>Annotation studies often require annotators to familiarize themselves with
the task, its annotation scheme, and the data domain. This can be overwhelming
in the beginning, mentally taxing, and induce errors into the resulting
annotations; especially in citizen science or crowd sourcing scenarios where
domain expertise is not required and only annotation guidelines are provided.
To alleviate these issues, we propose annotation curricula, a novel approach to
implicitly train annotators. Our goal is to gradually introduce annotators into
the task by ordering instances that are annotated according to a learning
curriculum. To do so, we first formalize annotation curricula for sentence- and
paragraph-level annotation tasks, define an ordering strategy, and identify
well-performing heuristics and interactively trained models on three existing
English datasets. We then conduct a user study with 40 voluntary participants
who are asked to identify the most fitting misconception for English tweets
about the Covid-19 pandemic. Our results show that using a simple heuristic to
order instances can already significantly reduce the total annotation time
while preserving a high annotation quality. Annotation curricula thus can
provide a novel way to improve data collection. To facilitate future research,
we further share our code and data consisting of 2,400 annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SEOVER: Sentence-level Emotion Orientation Vector based Conversation Emotion Recognition Model. (arXiv:2106.08785v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08785">
<div class="article-summary-box-inner">
<span><p>For the task of conversation emotion recognition, recent works focus on
speaker relationship modeling but ignore the role of utterance's emotional
tendency.In this paper, we propose a new expression paradigm of sentence-level
emotion orientation vector to model the potential correlation of emotions
between sentence vectors. Based on it, we design an emotion recognition model,
which extracts the sentence-level emotion orientation vectors from the language
model and jointly learns from the dialogue sentiment analysis model and
extracted sentence-level emotion orientation vectors to identify the speaker's
emotional orientation during the conversation. We conduct experiments on two
benchmark datasets and compare them with the five baseline models.The
experimental results show that our model has better performance on all data
sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reinforcement Learning-based Dialogue Guided Event Extraction to Exploit Argument Relations. (arXiv:2106.12384v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12384">
<div class="article-summary-box-inner">
<span><p>Event extraction is a fundamental task for natural language processing.
Finding the roles of event arguments like event participants is essential for
event extraction. However, doing so for real-life event descriptions is
challenging because an argument's role often varies in different contexts.
While the relationship and interactions between multiple arguments are useful
for settling the argument roles, such information is largely ignored by
existing approaches. This paper presents a better approach for event extraction
by explicitly utilizing the relationships of event arguments. We achieve this
through a carefully designed task-oriented dialogue system. To model the
argument relation, we employ reinforcement learning and incremental learning to
extract multiple arguments via a multi-turned, iterative process. Our approach
leverages knowledge of the already extracted arguments of the same sentence to
determine the role of arguments that would be difficult to decide individually.
It then uses the newly obtained information to improve the decisions of
previously extracted arguments. This two-way feedback process allows us to
exploit the argument relations to effectively settle argument roles, leading to
better sentence understanding and event extraction. Experimental results show
that our approach consistently outperforms seven state-of-the-art event
extraction methods for the classification of events and argument role and
argument identification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Compact Survey on Event Extraction: Approaches and Applications. (arXiv:2107.02126v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02126">
<div class="article-summary-box-inner">
<span><p>Event extraction is a critical technique to apprehend the essential content
of events promptly. With the rapid development of deep learning technology,
event extraction technology based on deep learning has become a research
hotspot. Numerous methods, datasets, and evaluation metrics have been proposed
in the literature, raising the need for a comprehensive and updated survey.
This paper fills the gap by reviewing the state-of-the-art approaches, focusing
on deep learning-based models. We summarize the task definition, paradigm, and
models of event extraction and then discuss each of these in detail. We
introduce benchmark datasets that support tests of predictions and evaluation
metrics. A comprehensive comparison between different techniques is also
provided in this survey. Finally, we conclude by summarizing future research
directions facing the research area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Brazilian Portuguese Speech Recognition Using Wav2vec 2.0. (arXiv:2107.11414v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11414">
<div class="article-summary-box-inner">
<span><p>Deep learning techniques have been shown to be efficient in various tasks,
especially in the development of speech recognition systems, that is, systems
that aim to transcribe an audio sentence in a sequence of written words.
Despite the progress in the area, speech recognition can still be considered
difficult, especially for languages lacking available data, such as Brazilian
Portuguese (BP). In this sense, this work presents the development of an public
Automatic Speech Recognition (ASR) system using only open available audio data,
from the fine-tuning of the Wav2vec 2.0 XLSR-53 model pre-trained in many
languages, over BP data. The final model presents an average word error rate of
12.4% over 7 different datasets (10.5% when applying a language model).
According to our knowledge, the obtained error is the lowest among open
end-to-end (E2E) ASR models for BP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond NED: Fast and Effective Search Space Reduction for Complex Question Answering over Knowledge Bases. (arXiv:2108.08597v6 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08597">
<div class="article-summary-box-inner">
<span><p>Answering complex questions over knowledge bases (KB-QA) faces huge input
data with billions of facts, involving millions of entities and thousands of
predicates. For efficiency, QA systems first reduce the answer search space by
identifying a set of facts that is likely to contain all answers and relevant
cues. The most common technique or doing this is to apply named entity
disambiguation (NED) systems to the question, and retrieve KB facts for the
disambiguated entities. This work presents CLOCQ, an efficient method that
prunes irrelevant parts of the search space using KB-aware signals. CLOCQ uses
a top-k query processor over score-ordered lists of KB items that combine
signals about lexical matching, relevance to the question, coherence among
candidate items, and connectivity in the KB graph. Experiments with two recent
QA benchmarks for complex questions demonstrate the superiority of CLOCQ over
state-of-the-art baselines with respect to answer presence, size of the search
space, and runtimes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Unified View of Parameter-Efficient Transfer Learning. (arXiv:2110.04366v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04366">
<div class="article-summary-box-inner">
<span><p>Fine-tuning large pre-trained language models on downstream tasks has become
the de-facto learning paradigm in NLP. However, conventional approaches
fine-tune all the parameters of the pre-trained model, which becomes
prohibitive as the model size and the number of tasks grow. Recent work has
proposed a variety of parameter-efficient transfer learning methods that only
fine-tune a small number of (extra) parameters to attain strong performance.
While effective, the critical ingredients for success and the connections among
the various methods are poorly understood. In this paper, we break down the
design of state-of-the-art parameter-efficient transfer learning methods and
present a unified framework that establishes connections between them.
Specifically, we re-frame them as modifications to specific hidden states in
pre-trained models, and define a set of design dimensions along which different
methods vary, such as the function to compute the modification and the position
to apply the modification. Through comprehensive empirical studies across
machine translation, text summarization, language understanding, and text
classification benchmarks, we utilize the unified view to identify important
design choices in previous methods. Furthermore, our unified framework enables
the transfer of design elements across different approaches, and as a result we
are able to instantiate new parameter-efficient fine-tuning methods that tune
less parameters than previous methods while being more effective, achieving
comparable results to fine-tuning all parameters on all four tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConE: Cone Embeddings for Multi-Hop Reasoning over Knowledge Graphs. (arXiv:2110.13715v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13715">
<div class="article-summary-box-inner">
<span><p>Query embedding (QE) -- which aims to embed entities and first-order logical
(FOL) queries in low-dimensional spaces -- has shown great power in multi-hop
reasoning over knowledge graphs. Recently, embedding entities and queries with
geometric shapes becomes a promising direction, as geometric shapes can
naturally represent answer sets of queries and logical relationships among
them. However, existing geometry-based models have difficulty in modeling
queries with negation, which significantly limits their applicability. To
address this challenge, we propose a novel query embedding model, namely Cone
Embeddings (ConE), which is the first geometry-based QE model that can handle
all the FOL operations, including conjunction, disjunction, and negation.
Specifically, ConE represents entities and queries as Cartesian products of
two-dimensional cones, where the intersection and union of cones naturally
model the conjunction and disjunction operations. By further noticing that the
closure of complement of cones remains cones, we design geometric complement
operators in the embedding space for the negation operations. Experiments
demonstrate that ConE significantly outperforms existing state-of-the-art
methods on benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing. (arXiv:2110.13900v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13900">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) achieves great success in speech recognition,
while limited exploration has been attempted for other speech processing tasks.
As speech signal contains multi-faceted information including speaker identity,
paralinguistics, spoken content, etc., learning universal representations for
all speech tasks is challenging. In this paper, we propose a new pre-trained
model, WavLM, to solve full-stack downstream speech tasks. WavLM extends HuBERT
framework to denoising masked speech modeling, where the target is to predict
pseudo-labels of simulated noisy speech on masked regions. The simulated speech
is created by adding additional noise or speech from other utterances on the
original speech. The denoising masked speech modeling tasks aim to improve the
model robustness to complex acoustic environments and the preservation of
speaker identity. We scale up the training dataset from 60k hours to 94k hours.
WavLM Large achieves state-of-the-art performance on the SUPERB benchmark, and
brings significant improvements for various speech processing tasks on their
representative benchmarks. The code and pretrained models are available at
https://aka.ms/wavlm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Building ASR Systems for the Next Billion Users. (arXiv:2111.03945v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03945">
<div class="article-summary-box-inner">
<span><p>Recent methods in speech and language technology pretrain very LARGE models
which are fine-tuned for specific tasks. However, the benefits of such LARGE
models are often limited to a few resource rich languages of the world. In this
work, we make multiple contributions towards building ASR systems for low
resource languages from the Indian subcontinent. First, we curate 17,000 hours
of raw speech data for 40 Indian languages from a wide variety of domains
including education, news, technology, and finance. Second, using this raw
speech data we pretrain several variants of wav2vec style models for 40 Indian
languages. Third, we analyze the pretrained models to find key features:
codebook vectors of similar sounding phonemes are shared across languages,
representations across layers are discriminative of the language family, and
attention heads often pay attention within small local windows. Fourth, we
fine-tune this model for downstream ASR for 9 languages and obtain
state-of-the-art results on 3 public datasets, including on very low-resource
languages such as Sinhala and Nepali. Our work establishes that multilingual
pretraining is an effective strategy for building ASR systems for the
linguistically diverse speakers of the Indian subcontinent. Our code, data and
models are available publicly at https://indicnlp.ai4bharat.org/indicwav2vec/
and we hope they will help advance research in ASR for Indic languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterizing and addressing the issue of oversmoothing in neural autoregressive sequence modeling. (arXiv:2112.08914v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08914">
<div class="article-summary-box-inner">
<span><p>Neural autoregressive sequence models smear the probability among many
possible sequences including degenerate ones, such as empty or repetitive
sequences. In this work, we tackle one specific case where the model assigns a
high probability to unreasonably short sequences. We define the oversmoothing
rate to quantify this issue. After confirming the high degree of oversmoothing
in neural machine translation, we propose to explicitly minimize the
oversmoothing rate during training. We conduct a set of experiments to study
the effect of the proposed regularization on both model distribution and
decoding performance. We use a neural machine translation task as the testbed
and consider three different datasets of varying size. Our experiments reveal
three major findings. First, we can control the oversmoothing rate of the model
by tuning the strength of the regularization. Second, by enhancing the
oversmoothing loss contribution, the probability and the rank of &lt;eos&gt; token
decrease heavily at positions where it is not supposed to be. Third, the
proposed regularization impacts the outcome of beam search especially when a
large beam is used. The degradation of translation quality (measured in BLEU)
with a large beam significantly lessens with lower oversmoothing rate, but the
degradation compared to smaller beam sizes remains to exist. From these
observations, we conclude that the high degree of oversmoothing is the main
reason behind the degenerate case of overly probable short sequences in a
neural autoregressive model.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Teacher-Student Architecture for Mixed Supervised Lung Tumor Segmentation. (arXiv:2112.11541v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11541">
<div class="article-summary-box-inner">
<span><p>Purpose: Automating tasks such as lung tumor localization and segmentation in
radiological images can free valuable time for radiologists and other clinical
personnel. Convolutional neural networks may be suited for such tasks, but
require substantial amounts of labeled data to train. Obtaining labeled data is
a challenge, especially in the medical domain. Methods: This paper investigates
the use of a teacher-student design to utilize datasets with different types of
supervision to train an automatic model performing pulmonary tumor segmentation
on computed tomography images. The framework consists of two models: the
student that performs end-to-end automatic tumor segmentation and the teacher
that supplies the student additional pseudo-annotated data during training.
Results: Using only a small proportion of semantically labeled data and a large
number of bounding box annotated data, we achieved competitive performance
using a teacher-student design. Models trained on larger amounts of semantic
annotations did not perform better than those trained on teacher-annotated
data. Conclusions: Our results demonstrate the potential of utilizing
teacher-student designs to reduce the annotation load, as less supervised
annotation schemes may be performed, without any real degradation in
segmentation accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MIA-Former: Efficient and Robust Vision Transformers via Multi-grained Input-Adaptation. (arXiv:2112.11542v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11542">
<div class="article-summary-box-inner">
<span><p>ViTs are often too computationally expensive to be fitted onto real-world
resource-constrained devices, due to (1) their quadratically increased
complexity with the number of input tokens and (2) their overparameterized
self-attention heads and model depth. In parallel, different images are of
varied complexity and their different regions can contain various levels of
visual information, indicating that treating all regions/tokens equally in
terms of model complexity is unnecessary while such opportunities for trimming
down ViTs' complexity have not been fully explored. To this end, we propose a
Multi-grained Input-adaptive Vision Transformer framework dubbed MIA-Former
that can input-adaptively adjust the structure of ViTs at three
coarse-to-fine-grained granularities (i.e., model depth and the number of model
heads/tokens). In particular, our MIA-Former adopts a low-cost network trained
with a hybrid supervised and reinforcement training method to skip unnecessary
layers, heads, and tokens in an input adaptive manner, reducing the overall
computational cost. Furthermore, an interesting side effect of our MIA-Former
is that its resulting ViTs are naturally equipped with improved robustness
against adversarial attacks over their static counterparts, because
MIA-Former's multi-grained dynamic control improves the model diversity similar
to the effect of ensemble and thus increases the difficulty of adversarial
attacks against all its sub-models. Extensive experiments and ablation studies
validate that the proposed MIA-Former framework can effectively allocate
computation budgets adaptive to the difficulty of input images meanwhile
increase robustness, achieving state-of-the-art (SOTA) accuracy-efficiency
trade-offs, e.g., 20% computation savings with the same or even a higher
accuracy compared with SOTA dynamic transformer models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-time Street Human Motion Capture. (arXiv:2112.11543v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11543">
<div class="article-summary-box-inner">
<span><p>In recent years, motion capture technology using computers has developed
rapidly. Because of its high efficiency and excellent performance, it replaces
many traditional methods and is being widely used in many fields. Our project
is about street scene video human motion capturing and analysis. The primary
goal of the project is to capture the human motion in a video and use the
motion information for 3D animation (human) in real-time. We applied a neural
network for motion capture and implement it in the unity under a street view
scene. By analyzing the motion data, we will have a better estimation of the
street condition, which is useful for other high-tech applications such as
self-driving cars.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decompose the Sounds and Pixels, Recompose the Events. (arXiv:2112.11547v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11547">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a framework centering around a novel architecture
called the Event Decomposition Recomposition Network (EDRNet) to tackle the
Audio-Visual Event (AVE) localization problem in the supervised and weakly
supervised settings. AVEs in the real world exhibit common unravelling patterns
(termed as Event Progress Checkpoints (EPC)), which humans can perceive through
the cooperation of their auditory and visual senses. Unlike earlier methods
which attempt to recognize entire event sequences, the EDRNet models EPCs and
inter-EPC relationships using stacked temporal convolutions. Based on the
postulation that EPC representations are theoretically consistent for an event
category, we introduce the State Machine Based Video Fusion, a novel
augmentation technique that blends source videos using different EPC template
sequences. Additionally, we design a new loss function called the
Land-Shore-Sea loss to compactify continuous foreground and background
representations. Lastly, to alleviate the issue of confusing events during weak
supervision, we propose a prediction stabilization method called Bag to
Instance Label Correction. Experiments on the AVE dataset show that our
collective framework outperforms the state-of-the-art by a sizable margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distribution-aware Margin Calibration for Semantic Segmentation in Images. (arXiv:2112.11554v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11554">
<div class="article-summary-box-inner">
<span><p>The Jaccard index, also known as Intersection-over-Union (IoU), is one of the
most critical evaluation metrics in image semantic segmentation. However,
direct optimization of IoU score is very difficult because the learning
objective is neither differentiable nor decomposable. Although some algorithms
have been proposed to optimize its surrogates, there is no guarantee provided
for the generalization ability. In this paper, we propose a margin calibration
method, which can be directly used as a learning objective, for an improved
generalization of IoU over the data-distribution, underpinned by a rigid lower
bound. This scheme theoretically ensures a better segmentation performance in
terms of IoU score. We evaluated the effectiveness of the proposed margin
calibration method on seven image datasets, showing substantial improvements in
IoU score over other learning objectives using deep segmentation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anomaly Clustering: Grouping Images into Coherent Clusters of Anomaly Types. (arXiv:2112.11573v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11573">
<div class="article-summary-box-inner">
<span><p>We introduce anomaly clustering, whose goal is to group data into
semantically coherent clusters of anomaly types. This is different from anomaly
detection, whose goal is to divide anomalies from normal data. Unlike
object-centered image clustering applications, anomaly clustering is
particularly challenging as anomalous patterns are subtle and local. We present
a simple yet effective clustering framework using a patch-based pretrained deep
embeddings and off-the-shelf clustering methods. We define a distance function
between images, each of which is represented as a bag of embeddings, by the
Euclidean distance between weighted averaged embeddings. The weight defines the
importance of instances (i.e., patch embeddings) in the bag, which may
highlight defective regions. We compute weights in an unsupervised way or in a
semi-supervised way if labeled normal data is available. Extensive experimental
studies show the effectiveness of the proposed clustering framework along with
a novel distance function upon existing multiple instance or deep clustering
frameworks. Overall, our framework achieves 0.451 and 0.674 normalized mutual
information scores on MVTec object and texture categories and further improve
with a few labeled normal data (0.577, 0.669), far exceeding the baselines
(0.244, 0.273) or state-of-the-art deep clustering methods (0.176, 0.277).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaptPose: Cross-Dataset Adaptation for 3D Human Pose Estimation by Learnable Motion Generation. (arXiv:2112.11593v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11593">
<div class="article-summary-box-inner">
<span><p>This paper addresses the problem of cross-dataset generalization of 3D human
pose estimation models. Testing a pre-trained 3D pose estimator on a new
dataset results in a major performance drop. Previous methods have mainly
addressed this problem by improving the diversity of the training data. We
argue that diversity alone is not sufficient and that the characteristics of
the training data need to be adapted to those of the new dataset such as camera
viewpoint, position, human actions, and body size. To this end, we propose
AdaptPose, an end-to-end framework that generates synthetic 3D human motions
from a source dataset and uses them to fine-tune a 3D pose estimator. AdaptPose
follows an adversarial training scheme. From a source 3D pose the generator
generates a sequence of 3D poses and a camera orientation that is used to
project the generated poses to a novel view. Without any 3D labels or camera
information AdaptPose successfully learns to create synthetic 3D poses from the
target dataset while only being trained on 2D poses. In experiments on the
Human3.6M, MPI-INF-3DHP, 3DPW, and Ski-Pose datasets our method outperforms
previous work in cross-dataset evaluations by 14% and previous semi-supervised
learning methods that use partial 3D annotations by 16%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EyePAD++: A Distillation-based approach for joint Eye Authentication and Presentation Attack Detection using Periocular Images. (arXiv:2112.11610v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11610">
<div class="article-summary-box-inner">
<span><p>A practical eye authentication (EA) system targeted for edge devices needs to
perform authentication and be robust to presentation attacks, all while
remaining compute and latency efficient. However, existing eye-based frameworks
a) perform authentication and Presentation Attack Detection (PAD) independently
and b) involve significant pre-processing steps to extract the iris region.
Here, we introduce a joint framework for EA and PAD using periocular images.
While a deep Multitask Learning (MTL) network can perform both the tasks, MTL
suffers from the forgetting effect since the training datasets for EA and PAD
are disjoint. To overcome this, we propose Eye Authentication with PAD
(EyePAD), a distillation-based method that trains a single network for EA and
PAD while reducing the effect of forgetting. To further improve the EA
performance, we introduce a novel approach called EyePAD++ that includes
training an MTL network on both EA and PAD data, while distilling the
`versatility' of the EyePAD network through an additional distillation step.
Our proposed methods outperform the SOTA in PAD and obtain near-SOTA
performance in eye-to-eye verification, without any pre-processing. We also
demonstrate the efficacy of EyePAD and EyePAD++ in user-to-user verification
with PAD across network backbones and image quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MOSAIC: Mobile Segmentation via decoding Aggregated Information and encoded Context. (arXiv:2112.11623v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11623">
<div class="article-summary-box-inner">
<span><p>We present a next-generation neural network architecture, MOSAIC, for
efficient and accurate semantic image segmentation on mobile devices. MOSAIC is
designed using commonly supported neural operations by diverse mobile hardware
platforms for flexible deployment across various mobile platforms. With a
simple asymmetric encoder-decoder structure which consists of an efficient
multi-scale context encoder and a light-weight hybrid decoder to recover
spatial details from aggregated information, MOSAIC achieves new
state-of-the-art performance while balancing accuracy and computational cost.
Deployed on top of a tailored feature extraction backbone based on a searched
classification network, MOSAIC achieves a 5% absolute accuracy gain surpassing
the current industry standard MLPerf models and state-of-the-art architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Convolutional neural network based on transfer learning for breast cancer screening. (arXiv:2112.11629v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11629">
<div class="article-summary-box-inner">
<span><p>Breast cancer is the most common cancer in the world and the most prevalent
cause of death among women worldwide. Nevertheless, it is also one of the most
treatable malignancies if detected early. In this paper, a deep convolutional
neural network-based algorithm is proposed to aid in accurately identifying
breast cancer from ultrasonic images. In this algorithm, several neural
networks are fused in a parallel architecture to perform the classification
process and the voting criteria are applied in the final classification
decision between the candidate object classes where the output of each neural
network is representing a single vote. Several experiments were conducted on
the breast ultrasound dataset consisting of 537 Benign, 360 malignant, and 133
normal images. These experiments show an optimistic result and a capability of
the proposed model to outperform many state-of-the-art algorithms on several
measures. Using k-fold cross-validation and a bagging classifier ensemble, we
achieved an accuracy of 99.5% and a sensitivity of 99.6%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JoJoGAN: One Shot Face Stylization. (arXiv:2112.11641v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11641">
<div class="article-summary-box-inner">
<span><p>While there have been recent advances in few-shot image stylization, these
methods fail to capture stylistic details that are obvious to humans. Details
such as the shape of the eyes, the boldness of the lines, are especially
difficult for a model to learn, especially so under a limited data setting. In
this work, we aim to perform one-shot image stylization that gets the details
right. Given a reference style image, we approximate paired real data using GAN
inversion and finetune a pretrained StyleGAN using that approximate paired
data. We then encourage the StyleGAN to generalize so that the learned style
can be applied to all other images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Credibility Scoring Metrics of Perception Systems for Autonomous Driving. (arXiv:2112.11643v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11643">
<div class="article-summary-box-inner">
<span><p>Autonomous and semi-autonomous vehicles' perception algorithms can encounter
situations with erroneous object detection, such as misclassification of
objects on the road, which can lead to safety violations and potentially fatal
consequences. While there has been substantial work in the robustness of object
detection algorithms and online metric learning, there is little research on
benchmarking scoring metrics to determine any possible indicators of potential
misclassification. An emphasis is put on exploring the potential of taking
these scoring metrics online in order to allow the AV to make perception-based
decisions given real-time constraints. In this work, we explore which, if any,
metrics act as online indicators of when perception algorithms and object
detectors are failing. Our work provides insight on better design principles
and characteristics of online metrics to accurately evaluate the credibility of
object detectors. Our approach employs non-adversarial and realistic
perturbations to images, on which we evaluate various quantitative metrics. We
found that offline metrics can be designed to account for real-world
corruptions such as poor weather conditions and that the analysis of such
metrics can provide a segue into designing online metrics. This is a clear next
step as it can allow for error-free autonomous vehicle perception and safer
time-critical and safety-critical decision-making.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAN Based Boundary Aware Classifier for Detecting Out-of-distribution Samples. (arXiv:2112.11648v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11648">
<div class="article-summary-box-inner">
<span><p>This paper focuses on the problem of detecting out-of-distribution (ood)
samples with neural nets. In image recognition tasks, the trained classifier
often gives high confidence score for input images which are remote from the
in-distribution (id) data, and this has greatly limited its application in real
world. For alleviating this problem, we propose a GAN based boundary aware
classifier (GBAC) for generating a closed hyperspace which only contains most
id data. Our method is based on the fact that the traditional neural net
seperates the feature space as several unclosed regions which are not suitable
for ood detection. With GBAC as an auxiliary module, the ood data distributed
outside the closed hyperspace will be assigned with much lower score, allowing
more effective ood detection while maintaining the classification performance.
Moreover, we present a fast sampling method for generating hard ood
representations which lie on the boundary of pre-mentioned closed hyperspace.
Experiments taken on several datasets and neural net architectures promise the
effectiveness of GBAC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ghost-dil-NetVLAD: A Lightweight Neural Network for Visual Place Recognition. (arXiv:2112.11679v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11679">
<div class="article-summary-box-inner">
<span><p>Visual place recognition (VPR) is a challenging task with the unbalance
between enormous computational cost and high recognition performance. Thanks to
the practical feature extraction ability of the lightweight convolution neural
networks (CNNs) and the train-ability of the vector of locally aggregated
descriptors (VLAD) layer, we propose a lightweight weakly supervised end-to-end
neural network consisting of a front-ended perception model called GhostCNN and
a learnable VLAD layer as a back-end. GhostCNN is based on Ghost modules that
are lightweight CNN-based architectures. They can generate redundant feature
maps using linear operations instead of the traditional convolution process,
making a good trade-off between computation resources and recognition accuracy.
To enhance our proposed lightweight model further, we add dilated convolutions
to the Ghost module to get features containing more spatial semantic
information, improving accuracy. Finally, rich experiments conducted on a
commonly used public benchmark and our private dataset validate that the
proposed neural network reduces the FLOPs and parameters of VGG16-NetVLAD by
99.04% and 80.16%, respectively. Besides, both models achieve similar accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cost Aggregation Is All You Need for Few-Shot Segmentation. (arXiv:2112.11685v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11685">
<div class="article-summary-box-inner">
<span><p>We introduce a novel cost aggregation network, dubbed Volumetric Aggregation
with Transformers (VAT), to tackle the few-shot segmentation task by using both
convolutions and transformers to efficiently handle high dimensional
correlation maps between query and support. In specific, we propose our encoder
consisting of volume embedding module to not only transform the correlation
maps into more tractable size but also inject some convolutional inductive bias
and volumetric transformer module for the cost aggregation. Our encoder has a
pyramidal structure to let the coarser level aggregation to guide the finer
level and enforce to learn complementary matching scores. We then feed the
output into our affinity-aware decoder along with the projected feature maps
for guiding the segmentation process. Combining these components, we conduct
experiments to demonstrate the effectiveness of the proposed method, and our
method sets a new state-of-the-art for all the standard benchmarks in few-shot
segmentation task. Furthermore, we find that the proposed method attains
state-of-the-art performance even for the standard benchmarks in semantic
correspondence task although not specifically designed for this task. We also
provide an extensive ablation study to validate our architectural choices. The
trained weights and codes are available at: https://seokju-cho.github.io/VAT/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Centroid Representation Network for Domain Adaptive Person Re-ID. (arXiv:2112.11689v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11689">
<div class="article-summary-box-inner">
<span><p>Recently, many approaches tackle the Unsupervised Domain Adaptive person
re-identification (UDA re-ID) problem through pseudo-label-based contrastive
learning. During training, a uni-centroid representation is obtained by simply
averaging all the instance features from a cluster with the same pseudo label.
However, a cluster may contain images with different identities (label noises)
due to the imperfect clustering results, which makes the uni-centroid
representation inappropriate. In this paper, we present a novel Multi-Centroid
Memory (MCM) to adaptively capture different identity information within the
cluster. MCM can effectively alleviate the issue of label noises by selecting
proper positive/negative centroids for the query image. Moreover, we further
propose two strategies to improve the contrastive learning process. First, we
present a Domain-Specific Contrastive Learning (DSCL) mechanism to fully
explore intradomain information by comparing samples only from the same domain.
Second, we propose Second-Order Nearest Interpolation (SONI) to obtain abundant
and informative negative samples. We integrate MCM, DSCL, and SONI into a
unified framework named Multi-Centroid Representation Network (MCRN). Extensive
experiments demonstrate the superiority of MCRN over state-of-the-art
approaches on multiple UDA re-ID tasks and fully unsupervised re-ID tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLEVR3D: Compositional Language and Elementary Visual Reasoning for Question Answering in 3D Real-World Scenes. (arXiv:2112.11691v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11691">
<div class="article-summary-box-inner">
<span><p>3D scene understanding is a relatively emerging research field. In this
paper, we introduce the Visual Question Answering task in 3D real-world scenes
(VQA-3D), which aims to answer all possible questions given a 3D scene. To
tackle this problem, the first VQA-3D dataset, namely CLEVR3D, is proposed,
which contains 60K questions in 1,129 real-world scenes. Specifically, we
develop a question engine leveraging 3D scene graph structures to generate
diverse reasoning questions, covering the questions of objects' attributes
(i.e., size, color, and material) and their spatial relationships. Built upon
this dataset, we further design the first VQA-3D baseline model, TransVQA3D.
The TransVQA3D model adopts well-designed Transformer architectures to achieve
superior VQA-3D performance, compared with the pure language baseline and
previous 3D reasoning methods directly applied to 3D scenarios. Experimental
results verify that taking VQA-3D as an auxiliary task can boost the
performance of 3D scene understanding, including scene graph analysis for the
node-wise classification and whole-graph recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Object Detection: A Survey. (arXiv:2112.11699v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11699">
<div class="article-summary-box-inner">
<span><p>Humans are able to learn to recognize new objects even from a few examples.
In contrast, training deep-learning-based object detectors requires huge
amounts of annotated data. To avoid the need to acquire and annotate these huge
amounts of data, few-shot object detection aims to learn from few object
instances of new categories in the target domain. In this survey, we provide an
overview of the state of the art in few-shot object detection. We categorize
approaches according to their training scheme and architectural layout. For
each type of approaches, we describe the general realization as well as
concepts to improve the performance on novel categories. Whenever appropriate,
we give short takeaways regarding these concepts in order to highlight the best
ideas. Eventually, we introduce commonly used datasets and their evaluation
protocols and analyze reported benchmark results. As a result, we emphasize
common challenges in evaluation and identify the most promising current trends
in this emerging field of few-shot object detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Contrast for Image Regression in Computer-Aided Disease Assessment. (arXiv:2112.11700v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11700">
<div class="article-summary-box-inner">
<span><p>Image regression tasks for medical applications, such as bone mineral density
(BMD) estimation and left-ventricular ejection fraction (LVEF) prediction, play
an important role in computer-aided disease assessment. Most deep regression
methods train the neural network with a single regression loss function like
MSE or L1 loss. In this paper, we propose the first contrastive learning
framework for deep image regression, namely AdaCon, which consists of a feature
learning branch via a novel adaptive-margin contrastive loss and a regression
prediction branch. Our method incorporates label distance relationships as part
of the learned feature representations, which allows for better performance in
downstream regression tasks. Moreover, it can be used as a plug-and-play module
to improve performance of existing regression methods. We demonstrate the
effectiveness of AdaCon on two medical image regression tasks, ie, bone mineral
density estimation from X-ray images and left-ventricular ejection fraction
prediction from echocardiogram videos. AdaCon leads to relative improvements of
3.3% and 5.9% in MAE over state-of-the-art BMD estimation and LVEF prediction
methods, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entropy Regularized Iterative Weighted Shrinkage-Thresholding Algorithm (ERIWSTA): An Application to CT Image Restoration. (arXiv:2112.11706v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11706">
<div class="article-summary-box-inner">
<span><p>The iterative weighted shrinkage-thresholding algorithm (IWSTA) has shown
superiority to the classic unweighted iterative shrinkage-thresholding
algorithm (ISTA) for solving linear inverse problems, which address the
attributes differently. This paper proposes a new entropy regularized IWSTA
(ERIWSTA) that adds an entropy regularizer to the cost function to measure the
uncertainty of the weights to stimulate attributes to participate in problem
solving. Then, the weights are solved with a Lagrange multiplier method to
obtain a simple iterative update. The weights can be explained as the
probability of the contribution of an attribute to the problem solution.
Experimental results on CT image restoration show that the proposed method has
better performance in terms of convergence speed and restoration accuracy than
the existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fusion of medical imaging and electronic health records with attention and multi-head machanisms. (arXiv:2112.11710v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11710">
<div class="article-summary-box-inner">
<span><p>Doctors often make diagonostic decisions based on patient's image scans, such
as magnetic resonance imaging (MRI), and patient's electronic health records
(EHR) such as age, gender, blood pressure and so on. Despite a lot of automatic
methods have been proposed for either image or text analysis in computer vision
or natural language research areas, much fewer studies have been developed for
the fusion of medical image and EHR data for medical problems. Among existing
early or intermediate fusion methods, concatenation of features from both
modalities is still a mainstream. For a better exploiting of image and EHR
data, we propose a multi-modal attention module which use EHR data to help the
selection of important regions during image feature extraction process
conducted by traditional CNN. Moreover, we propose to incorporate multi-head
machnism to gated multimodal unit (GMU) to make it able to parallelly fuse
image and EHR features in different subspaces. With the help of the two
modules, existing CNN architecture can be enhanced using both modalities.
Experiments on predicting Glasgow outcome scale (GOS) of intracerebral
hemorrhage patients and classifying Alzheimer's Disease showed the proposed
method can automatically focus on task-related areas and achieve better results
by making better use of image and EHR features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-Accuracy RGB-D Face Recognition via Segmentation-Aware Face Depth Estimation and Mask-Guided Attention Network. (arXiv:2112.11713v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11713">
<div class="article-summary-box-inner">
<span><p>Deep learning approaches have achieved highly accurate face recognition by
training the models with very large face image datasets. Unlike the
availability of large 2D face image datasets, there is a lack of large 3D face
datasets available to the public. Existing public 3D face datasets were usually
collected with few subjects, leading to the over-fitting problem. This paper
proposes two CNN models to improve the RGB-D face recognition task. The first
is a segmentation-aware depth estimation network, called DepthNet, which
estimates depth maps from RGB face images by including semantic segmentation
information for more accurate face region localization. The other is a novel
mask-guided RGB-D face recognition model that contains an RGB recognition
branch, a depth map recognition branch, and an auxiliary segmentation mask
branch with a spatial attention module. Our DepthNet is used to augment a large
2D face image dataset to a large RGB-D face dataset, which is used for training
an accurate RGB-D face recognition model. Furthermore, the proposed mask-guided
RGB-D face recognition model can fully exploit the depth map and segmentation
mask information and is more robust against pose variation than previous
methods. Our experimental results show that DepthNet can produce more reliable
depth maps from face images with the segmentation mask. Our mask-guided face
recognition model outperforms state-of-the-art methods on several public 3D
face datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing radiologists' gaze and saliency maps generated by interpretability methods for chest x-rays. (arXiv:2112.11716v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11716">
<div class="article-summary-box-inner">
<span><p>The interpretability of medical image analysis models is considered a key
research field. We use a dataset of eye-tracking data from five radiologists to
compare the outputs of interpretability methods against the heatmaps
representing where radiologists looked. We conduct a class-independent analysis
of the saliency maps generated by two methods selected from the literature:
Grad-CAM and attention maps from an attention-gated model. For the comparison,
we use shuffled metrics, which avoid biases from fixation locations. We achieve
scores comparable to an interobserver baseline in one shuffled metric,
highlighting the potential of saliency maps from Grad-CAM to mimic a
radiologist's attention over an image. We also divide the dataset into subsets
to evaluate in which cases similarities are higher.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Local Optimality for Video Steganalysis in Motion Vector Domain. (arXiv:2112.11729v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11729">
<div class="article-summary-box-inner">
<span><p>The local optimality of motion vectors (MVs) is an intrinsic property in
video coding, and any modifications to the MVs will inevitably destroy this
optimality, making it a sensitive indicator of steganography in the MV domain.
Thus the local optimality is commonly used to design steganalytic features, and
the estimation for local optimality has become a top priority in video
steganalysis. However, the local optimality in existing works is often
estimated inaccurately or using an unreasonable assumption, limiting its
capability in steganalysis. In this paper, we propose to estimate the local
optimality in a more reasonable and comprehensive fashion, and generalize the
concept of local optimality in two aspects. First, the local optimality
measured in a rate-distortion sense is jointly determined by MV and predicted
motion vector (PMV), and the variability of PMV will affect the estimation for
local optimality. Hence we generalize the local optimality from a static
estimation to a dynamic one. Second, the PMV is a special case of MV, and can
also reflect the embedding traces in MVs. So we generalize the local optimality
from the MV domain to the PMV domain. Based on the two generalizations of local
optimality, we construct new types of steganalytic features and also propose
feature symmetrization rules to reduce feature dimension. Extensive experiments
performed on three databases demonstrate the effectiveness of the proposed
features, which achieve state-of-the-art in both accuracy and robustness in
various conditions, including cover source mismatch, video prediction methods,
video codecs, and video resolutions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple and Effective Balance of Contrastive Losses. (arXiv:2112.11743v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11743">
<div class="article-summary-box-inner">
<span><p>Contrastive losses have long been a key ingredient of deep metric learning
and are now becoming more popular due to the success of self-supervised
learning. Recent research has shown the benefit of decomposing such losses into
two sub-losses which act in a complementary way when learning the
representation network: a positive term and an entropy term. Although the
overall loss is thus defined as a combination of two terms, the balance of
these two terms is often hidden behind implementation details and is largely
ignored and sub-optimal in practice. In this work, we approach the balance of
contrastive losses as a hyper-parameter optimization problem, and propose a
coordinate descent-based search method that efficiently find the
hyper-parameters that optimize evaluation performance. In the process, we
extend existing balance analyses to the contrastive margin loss, include batch
size in the balance, and explain how to aggregate loss elements from the batch
to maintain near-optimal performance over a larger range of batch sizes.
Extensive experiments with benchmarks from deep metric learning and
self-supervised learning show that optimal hyper-parameters are found faster
with our method than with other common search methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Class-aware Sounding Objects Localization via Audiovisual Correspondence. (arXiv:2112.11749v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11749">
<div class="article-summary-box-inner">
<span><p>Audiovisual scenes are pervasive in our daily life. It is commonplace for
humans to discriminatively localize different sounding objects but quite
challenging for machines to achieve class-aware sounding objects localization
without category annotations, i.e., localizing the sounding object and
recognizing its category. To address this problem, we propose a two-stage
step-by-step learning framework to localize and recognize sounding objects in
complex audiovisual scenarios using only the correspondence between audio and
vision. First, we propose to determine the sounding area via coarse-grained
audiovisual correspondence in the single source cases. Then visual features in
the sounding area are leveraged as candidate object representations to
establish a category-representation object dictionary for expressive visual
character extraction. We generate class-aware object localization maps in
cocktail-party scenarios and use audiovisual correspondence to suppress silent
areas by referring to this dictionary. Finally, we employ category-level
audiovisual consistency as the supervision to achieve fine-grained audio and
sounding object distribution alignment. Experiments on both realistic and
synthesized videos show that our model is superior in localizing and
recognizing objects as well as filtering out silent ones. We also transfer the
learned audiovisual network into the unsupervised object detection task,
obtaining reasonable performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Inter-frequency Guidance of Image for Lightweight Gaussian Denoising. (arXiv:2112.11779v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11779">
<div class="article-summary-box-inner">
<span><p>Image denoising is of vital importance in many imaging or computer vision
related areas. With the convolutional neural networks showing strong capability
in computer vision tasks, the performance of image denoising has also been
brought up by CNN based methods. Though CNN based image denoisers show
promising results on this task, most of the current CNN based methods try to
learn the mapping from noisy image to clean image directly, which lacks the
explicit exploration of prior knowledge of images and noises. Natural images
are observed to obey the reciprocal power law, implying the low-frequency band
of image tend to occupy most of the energy. Thus in the condition of AGWN
(additive gaussian white noise) deterioration, low-frequency band tend to
preserve a higher PSNR than high-frequency band. Considering the spatial
morphological consistency of different frequency bands, low-frequency band with
more fidelity can be used as a guidance to refine the more contaminated
high-frequency bands. Based on this thought, we proposed a novel network
architecture denoted as IGNet, in order to refine the frequency bands from low
to high in a progressive manner. Firstly, it decomposes the feature maps into
high- and low-frequency subbands using DWT (discrete wavelet transform)
iteratively, and then each low band features are used to refine the high band
features. Finally, the refined feature maps are processed by a decoder to
recover the clean result. With this design, more inter-frequency prior and
information are utilized, thus the model size can be lightened while still
perserves competitive results. Experiments on several public datasets show that
our model obtains competitive performance comparing with other state-of-the-art
methods yet with a lightweight structure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BEVDet: High-performance Multi-camera 3D Object Detection in Bird-Eye-View. (arXiv:2112.11790v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11790">
<div class="article-summary-box-inner">
<span><p>Autonomous driving perceives the surrounding environment for decision making,
which is one of the most complicated scenes for visual perception. The great
power of paradigm innovation in solving the 2D object detection task inspires
us to seek an elegant, feasible, and scalable paradigm for pushing the
performance boundary in this area. To this end, we contribute the BEVDet
paradigm in this paper. BEVDet is developed by following the principle of
detecting the 3D objects in Bird-Eye-View (BEV), where route planning can be
handily performed. In this paradigm, four kinds of modules are conducted in
succession with different roles: an image-view encoder for encoding feature in
image view, a view transformer for feature transformation from image view to
BEV, a BEV encoder for further encoding feature in BEV, and a task-specific
head for predicting the targets in BEV. We merely reuse the existing modules
for constructing BEVDet and make it feasible for multi-camera 3D object
detection by constructing an exclusive data augmentation strategy. The proposed
paradigm works well in multi-camera 3D object detection and offers a good
trade-off between computing budget and performance. BEVDet with 704x256 (1/8 of
the competitors) image size scores 29.4% mAP and 38.4% NDS on the nuScenes val
set, which is comparable with FCOS3D (i.e., 2008.2 GFLOPs, 1.7 FPS, 29.5% mAP
and 37.2% NDS), while requires merely 12% computing budget of 239.4 GFLOPs and
runs 4.3 times faster. Scaling up the input size to 1408x512, BEVDet scores
34.9% mAP, and 41.7% NDS, which requires just 601.4 GFLOPs and significantly
suppresses FCOS3D by 5.4% mAP and 4.5% NDS. The superior performance of BEVDet
tells the magic of paradigm innovation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles. (arXiv:2112.11798v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11798">
<div class="article-summary-box-inner">
<span><p>As autonomous vehicles and autonomous racing rise in popularity, so does the
need for faster and more accurate detectors. While our naked eyes are able to
extract contextual information almost instantly, even from far away, image
resolution and computational resources limitations make detecting smaller
objects (that is, objects that occupy a small pixel area in the input image) a
genuinely challenging task for machines and a wide-open research field. This
study explores how the popular YOLOv5 object detector can be modified to
improve its performance in detecting smaller objects, with a particular
application in autonomous racing. To achieve this, we investigate how replacing
certain structural elements of the model (as well as their connections and
other parameters) can affect performance and inference time. In doing so, we
propose a series of models at different scales, which we name `YOLO-Z', and
which display an improvement of up to 6.9% in mAP when detecting smaller
objects at 50% IOU, at the cost of just a 3ms increase in inference time
compared to the original YOLOv5. Our objective is to inform future research on
the potential of adjusting a popular detector such as YOLOv5 to address
specific tasks and provide insights on how specific changes can impact small
object detection. Such findings, applied to the broader context of autonomous
vehicles, could increase the amount of contextual information available to such
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Binary Image Skeletonization Using 2-Stage U-Net. (arXiv:2112.11824v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11824">
<div class="article-summary-box-inner">
<span><p>Object Skeletonization is the process of extracting skeletal, line-like
representations of shapes. It provides a very useful tool for geometric shape
understanding and minimal shape representation. It also has a wide variety of
applications, most notably in anatomical research and activity detection.
Several mathematical algorithmic approaches have been developed to solve this
problem, and some of them have been proven quite robust. However, a lesser
amount of attention has been invested into deep learning solutions for it. In
this paper, we use a 2-stage variant of the famous U-Net architecture to split
the problem space into two sub-problems: shape minimization and corrective
skeleton thinning. Our model produces results that are visually much better
than the baseline SkelNetOn model. We propose a new metric, M-CCORR, based on
normalized correlation coefficients as an alternative to F1 for this challenge
as it solves the problem of class imbalance, managing to recognize skeleton
similarity without suffering from F1's over-sensitivity to pixel-shifts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep learning for brain metastasis detection and segmentation in longitudinal MRI data. (arXiv:2112.11833v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11833">
<div class="article-summary-box-inner">
<span><p>Brain metastases occur frequently in patients with metastatic cancer. Early
and accurate detection of brain metastases is very essential for treatment
planning and prognosis in radiation therapy. To improve brain metastasis
detection performance with deep learning, a custom detection loss called
volume-level sensitivity-specificity (VSS) is proposed, which rates individual
metastasis detection sensitivity and specificity in (sub-)volume levels. As
sensitivity and precision are always a trade-off in a metastasis level, either
a high sensitivity or a high precision can be achieved by adjusting the weights
in the VSS loss without decline in dice score coefficient for segmented
metastases. To reduce metastasis-like structures being detected as false
positive metastases, a temporal prior volume is proposed as an additional input
of the neural network. Our proposed VSS loss improves the sensitivity of brain
metastasis detection, increasing the sensitivity from 86.7% to 95.5%.
Alternatively, it improves the precision from 68.8% to 97.8%. With the
additional temporal prior volume, about 45% of the false positive metastases
are reduced in the high sensitivity model and the precision reaches 99.6% for
the high specificity model. The mean dice coefficient for all metastases is
about 0.81. With the ensemble of the high sensitivity and high specificity
models, on average only 1.5 false positive metastases per patient needs further
check, while the majority of true positive metastases are confirmed. The
ensemble learning is able to distinguish high confidence true positive
metastases from metastases candidates that require special expert review or
further follow-up, being particularly well-fit to the requirements of expert
support in real clinical practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bottom-up approaches for multi-person pose estimation and it's applications: A brief review. (arXiv:2112.11834v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11834">
<div class="article-summary-box-inner">
<span><p>Human Pose Estimation (HPE) is one of the fundamental problems in computer
vision. It has applications ranging from virtual reality, human behavior
analysis, video surveillance, anomaly detection, self-driving to medical
assistance. The main objective of HPE is to obtain the person's posture from
the given input. Among different paradigms for HPE, one paradigm is called
bottom-up multi-person pose estimation. In the bottom-up approach, initially,
all the key points of the targets are detected, and later in the optimization
stage, the detected key points are associated with the corresponding targets.
This review paper discussed the recent advancements in bottom-up approaches for
the HPE and listed the possible high-quality datasets used to train the models.
Additionally, a discussion of the prominent bottom-up approaches and their
quantitative results on the standard performance matrices are given. Finally,
the limitations of the existing methods are highlighted, and guidelines of the
future research directions are given.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Discriminative Single-Shot Segmentation Network for Visual Object Tracking. (arXiv:2112.11846v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11846">
<div class="article-summary-box-inner">
<span><p>Template-based discriminative trackers are currently the dominant tracking
paradigm due to their robustness, but are restricted to bounding box tracking
and a limited range of transformation models, which reduces their localization
accuracy. We propose a discriminative single-shot segmentation tracker -- D3S2,
which narrows the gap between visual object tracking and video object
segmentation. A single-shot network applies two target models with
complementary geometric properties, one invariant to a broad range of
transformations, including non-rigid deformations, the other assuming a rigid
object to simultaneously achieve robust online target segmentation. The overall
tracking reliability is further increased by decoupling the object and feature
scale estimation. Without per-dataset finetuning, and trained only for
segmentation as the primary output, D3S2 outperforms all published trackers on
the recent short-term tracking benchmark VOT2020 and performs very close to the
state-of-the-art trackers on the GOT-10k, TrackingNet, OTB100 and LaSoT. D3S2
outperforms the leading segmentation tracker SiamMask on video object
segmentation benchmarks and performs on par with top video object segmentation
algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Analysis of memes for sentiment extraction. (arXiv:2112.11850v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11850">
<div class="article-summary-box-inner">
<span><p>Memes are one of the most ubiquitous forms of social media communication. The
study and processing of memes, which are intrinsically multimedia, is a popular
topic right now. The study presented in this research is based on the Memotion
dataset, which involves categorising memes based on irony, comedy, motivation,
and overall-sentiment. Three separate innovative transformer-based techniques
have been developed, and their outcomes have been thoroughly reviewed.The best
algorithm achieved a macro F1 score of 0.633 for humour classification, 0.55
for motivation classification, 0.61 for sarcasm classification, and 0.575 for
overall sentiment of the meme out of all our techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geodesic squared exponential kernel for non-rigid shape registration. (arXiv:2112.11853v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11853">
<div class="article-summary-box-inner">
<span><p>This work addresses the problem of non-rigid registration of 3D scans, which
is at the core of shape modeling techniques. Firstly, we propose a new kernel
based on geodesic distances for the Gaussian Process Morphable Models (GPMMs)
framework. The use of geodesic distances into the kernel makes it more adapted
to the topological and geometric characteristics of the surface and leads to
more realistic deformations around holes and curved areas. Since the kernel
possesses hyperparameters we have optimized them for the task of face
registration on the FaceWarehouse dataset. We show that the Geodesic squared
exponential kernel performs significantly better than state of the art kernels
for the task of face registration on all the 20 expressions of the
FaceWarehouse dataset. Secondly, we propose a modification of the loss function
used in the non-rigid ICP registration algorithm, that allows to weight the
correspondences according to the confidence given to them. As a use case, we
show that we can make the registration more robust to outliers in the 3D scans,
such as non-skin parts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Font Generation with Weakly Supervised Localized Representations. (arXiv:2112.11895v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11895">
<div class="article-summary-box-inner">
<span><p>Automatic few-shot font generation aims to solve a well-defined, real-world
problem because manual font designs are expensive and sensitive to the
expertise of designers. Existing methods learn to disentangle style and content
elements by developing a universal style representation for each font style.
However, this approach limits the model in representing diverse local styles,
because it is unsuitable for complicated letter systems, for example, Chinese,
whose characters consist of a varying number of components (often called
"radical") -- with a highly complex structure. In this paper, we propose a
novel font generation method that learns localized styles, namely
component-wise style representations, instead of universal styles. The proposed
style representations enable the synthesis of complex local details in text
designs. However, learning component-wise styles solely from a few reference
glyphs is infeasible when a target script has a large number of components, for
example, over 200 for Chinese. To reduce the number of required reference
glyphs, we represent component-wise styles by a product of component and style
factors, inspired by low-rank matrix factorization. Owing to the combination of
strong representation and a compact factorization strategy, our method shows
remarkably better few-shot font generation results (with only eight reference
glyphs) than other state-of-the-art methods. Moreover, strong locality
supervision, for example, location of each component, skeleton, or strokes, was
not utilized. The source code is available at https://github.com/clovaai/lffont
and https://github.com/clovaai/fewshot-font-generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Learning and Self-Supervised Pretraining for Real World Image Translation. (arXiv:2112.11929v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11929">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning, in particular enabled by hardware advances
and big data, have provided impressive results across a wide range of
computational problems such as computer vision, natural language, or
reinforcement learning. Many of these improvements are however constrained to
problems with large-scale curated data-sets which require a lot of human labor
to gather. Additionally, these models tend to generalize poorly under both
slight distributional shifts and low-data regimes. In recent years, emerging
fields such as meta-learning or self-supervised learning have been closing the
gap between proof-of-concept results and real-life applications of machine
learning by extending deep-learning to the semi-supervised and few-shot
domains. We follow this line of work and explore spatio-temporal structure in a
recently introduced image-to-image translation problem in order to: i)
formulate a novel multi-task few-shot image generation benchmark and ii)
explore data augmentations in contrastive pre-training for image translation
downstream tasks. We present several baselines for the few-shot problem and
discuss trade-offs between different approaches. Our code is available at
https://github.com/irugina/meta-image-translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Page Segmentation using Visual Adjacency Analysis. (arXiv:2112.11975v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11975">
<div class="article-summary-box-inner">
<span><p>Page segmentation is a web page analysis process that divides a page into
cohesive segments, such as sidebars, headers, and footers. Current page
segmentation approaches use either the DOM, textual content, or rendering style
information of the page. However, these approaches have a number of drawbacks,
such as a large number of parameters and rigid assumptions about the page,
which negatively impact their segmentation accuracy. We propose a novel page
segmentation approach based on visual analysis of localized adjacency regions.
It combines DOM attributes and visual analysis to build features of a given
page and guide an unsupervised clustering. We evaluate our approach on 35
real-world web pages, and examine the effectiveness and efficiency of
segmentation. The results show that, compared with state-of-the-art, our
approach achieves an average of 156% increase in precision and 249% improvement
in F-measure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Estimation of Anthropometric Human Body Measurements. (arXiv:2112.11992v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11992">
<div class="article-summary-box-inner">
<span><p>Research tasks related to human body analysis have been drawing a lot of
attention in computer vision area over the last few decades, considering its
potential benefits on our day-to-day life. Anthropometry is a field defining
physical measures of a human body size, form, and functional capacities.
Specifically, the accurate estimation of anthropometric body measurements from
visual human body data is one of the challenging problems, where the solution
would ease many different areas of applications, including ergonomics, garment
manufacturing, etc. This paper formulates a research in the field of deep
learning and neural networks, to tackle the challenge of body measurements
estimation from various types of visual input data (such as 2D images or 3D
point clouds). Also, we deal with the lack of real human data annotated with
ground truth body measurements required for training and evaluation, by
generating a synthetic dataset of various human body shapes and performing a
skeleton-driven annotation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DA-FDFtNet: Dual Attention Fake Detection Fine-tuning Network to Detect Various AI-Generated Fake Images. (arXiv:2112.12001v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12001">
<div class="article-summary-box-inner">
<span><p>Due to the advancement of Generative Adversarial Networks (GAN),
Autoencoders, and other AI technologies, it has been much easier to create fake
images such as "Deepfakes". More recent research has introduced few-shot
learning, which uses a small amount of training data to produce fake images and
videos more effectively. Therefore, the ease of generating manipulated images
and the difficulty of distinguishing those images can cause a serious threat to
our society, such as propagating fake information. However, detecting realistic
fake images generated by the latest AI technology is challenging due to the
reasons mentioned above. In this work, we propose Dual Attention Fake Detection
Fine-tuning Network (DA-FDFtNet) to detect the manipulated fake face images
from the real face data. Our DA-FDFtNet integrates the pre-trained model with
Fine-Tune Transformer, MBblockV3, and a channel attention module to improve the
performance and robustness across different types of fake images. In
particular, Fine-Tune Transformer consists of multiple numbers of an
image-based self-attention module and a down-sampling layer. The channel
attention module is also connected with the pre-trained model to capture the
fake images feature space. We experiment with our DA-FDFtNet with the
FaceForensics++ dataset and various GAN-generated datasets, and we show that
our approach outperforms the previous baseline models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Looking Beyond Corners: Contrastive Learning of Visual Representations for Keypoint Detection and Description Extraction. (arXiv:2112.12002v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12002">
<div class="article-summary-box-inner">
<span><p>Learnable keypoint detectors and descriptors are beginning to outperform
classical hand-crafted feature extraction methods. Recent studies on
self-supervised learning of visual representations have driven the increasing
performance of learnable models based on deep networks. By leveraging
traditional data augmentations and homography transformations, these networks
learn to detect corners under adverse conditions such as extreme illumination
changes. However, their generalization capabilities are limited to corner-like
features detected a priori by classical methods or synthetically generated
data.
</p>
<p>In this paper, we propose the Correspondence Network (CorrNet) that learns to
detect repeatable keypoints and to extract discriminative descriptions via
unsupervised contrastive learning under spatial constraints. Our experiments
show that CorrNet is not only able to detect low-level features such as
corners, but also high-level features that represent similar objects present in
a pair of input images through our proposed joint guided backpropagation of
their latent space. Our approach obtains competitive results under viewpoint
changes and achieves state-of-the-art performance under illumination changes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Barely-Supervised Learning: Semi-Supervised Learning with very few labeled images. (arXiv:2112.12004v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12004">
<div class="article-summary-box-inner">
<span><p>This paper tackles the problem of semi-supervised learning when the set of
labeled samples is limited to a small number of images per class, typically
less than 10, problem that we refer to as barely-supervised learning. We
analyze in depth the behavior of a state-of-the-art semi-supervised method,
FixMatch, which relies on a weakly-augmented version of an image to obtain
supervision signal for a more strongly-augmented version. We show that it
frequently fails in barely-supervised scenarios, due to a lack of training
signal when no pseudo-label can be predicted with high confidence. We propose a
method to leverage self-supervised methods that provides training signal in the
absence of confident pseudo-labels. We then propose two methods to refine the
pseudo-label selection process which lead to further improvements. The first
one relies on a per-sample history of the model predictions, akin to a voting
scheme. The second iteratively updates class-dependent confidence thresholds to
better explore classes that are under-represented in the pseudo-labels. Our
experiments show that our approach performs significantly better on STL-10 in
the barely-supervised regime, e.g. with 4 or 8 labeled images per class.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Community Detection in Medical Image Datasets: Using Wavelets and Spectral Methods. (arXiv:2112.12021v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12021">
<div class="article-summary-box-inner">
<span><p>Medical image datasets can have large number of images representing patients
with different health conditions and various disease severity. When dealing
with raw unlabeled image datasets, the large number of samples often makes it
hard for experts and non-experts to understand the variety of images present in
a dataset. Supervised learning methods rely on labeled images which requires a
considerable effort by medical experts to first understand the communities of
images present in the data and then labeling the images. Here, we propose an
algorithm to facilitate the automatic identification of communities in medical
image datasets. We further explain that such analysis can also be insightful in
a supervised setting, when the images are already labeled. Such insights are
useful because in reality, health and disease severity can be considered a
continuous spectrum, and within each class, there usually are finer communities
worthy of investigation, especially when they have similarities to communities
in other classes. In our approach, we use wavelet decomposition of images in
tandem with spectral methods. We show that the eigenvalues of a graph Laplacian
can reveal the number of notable communities in an image dataset. In our
experiments, we use a dataset of images labeled with different conditions for
COVID patients. We detect 25 communities in the dataset and then observe that
only 6 of those communities contain patients with pneumonia. We also
investigate the contents of a colorectal cancer histopathology dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning and Crafting for the Wide Multiple Baseline Stereo. (arXiv:2112.12027v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12027">
<div class="article-summary-box-inner">
<span><p>This thesis introduces the wide multiple baseline stereo (WxBS) problem.
WxBS, a generalization of the standard wide baseline stereo problem, considers
the matching of images that simultaneously differ in more than one image
acquisition factor such as viewpoint, illumination, sensor type, or where
object appearance changes significantly, e.g., over time. A new dataset with
the ground truth, evaluation metric and baselines has been introduced.
</p>
<p>The thesis presents the following improvements of the WxBS pipeline. (i) A
loss function, called HardNeg, for learning a local image descriptor that
relies on hard negative mining within a mini-batch and on the maximization of
the distance between the closest positive and the closest negative patches.
(ii) The descriptor trained with the HardNeg loss, called HardNet, is compact
and shows state-of-the-art performance in standard matching, patch verification
and retrieval benchmarks. (iii) A method for learning the affine shape,
orientation, and potentially other parameters related to geometric and
appearance properties of local features. (iv) A tentative correspondences
generation strategy which generalizes the standard first to second closest
distance ratio is presented. The selection strategy, which shows performance
superior to the standard method, is applicable to either hard-engineered
descriptors like SIFT, LIOP, and MROGH or deeply learned like HardNet. (v) A
feedback loop is introduced for the two-view matching problem, resulting in
MODS -- matching with on-demand view synthesis -- algorithm. MODS is an
algorithm that handles a viewing angle difference even larger than the previous
state-of-the-art ASIFT algorithm, without a significant increase of
computational cost over "standard" wide and narrow baseline approaches. Last,
but not least, a comprehensive benchmark for local features and robust
estimation algorithms is introduced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-View Partial (MVP) Point Cloud Challenge 2021 on Completion and Registration: Methods and Results. (arXiv:2112.12053v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12053">
<div class="article-summary-box-inner">
<span><p>As real-scanned point clouds are mostly partial due to occlusions and
viewpoints, reconstructing complete 3D shapes based on incomplete observations
becomes a fundamental problem for computer vision. With a single incomplete
point cloud, it becomes the partial point cloud completion problem. Given
multiple different observations, 3D reconstruction can be addressed by
performing partial-to-partial point cloud registration. Recently, a large-scale
Multi-View Partial (MVP) point cloud dataset has been released, which consists
of over 100,000 high-quality virtual-scanned partial point clouds. Based on the
MVP dataset, this paper reports methods and results in the Multi-View Partial
Point Cloud Challenge 2021 on Completion and Registration. In total, 128
participants registered for the competition, and 31 teams made valid
submissions. The top-ranked solutions will be analyzed, and then we will
discuss future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Models for Visual Sentiment Analysis of Disaster-related Multimedia Content. (arXiv:2112.12060v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12060">
<div class="article-summary-box-inner">
<span><p>This paper presents a solutions for the MediaEval 2021 task namely "Visual
Sentiment Analysis: A Natural Disaster Use-case". The task aims to extract and
classify sentiments perceived by viewers and the emotional message conveyed by
natural disaster-related images shared on social media. The task is composed of
three sub-tasks including, one single label multi-class image classification
task, and, two multi-label multi-class image classification tasks, with
different sets of labels. In our proposed solutions, we rely mainly on two
different state-of-the-art models namely, Inception-v3 and VggNet-19,
pre-trained on ImageNet, which are fine-tuned for each of the three task using
different strategies. Overall encouraging results are obtained on all the three
tasks. On the single-label classification task (i.e. Task 1), we obtained the
weighted average F1-scores of 0.540 and 0.526 for the Inception-v3 and
VggNet-19 based solutions, respectively. On the multi-label classification
i.e., Task 2 and Task 3, the weighted F1-score of our Inception-v3 based
solutions was 0.572 and 0.516, respectively. Similarly, the weighted F1-score
of our VggNet-19 based solution on Task 2 and Task 3 was 0.584 and 0.495,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Single-Target License Plate Detection with Attention. (arXiv:2112.12070v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12070">
<div class="article-summary-box-inner">
<span><p>With the development of deep learning, Neural Network is commonly adopted to
the License Plate Detection (LPD) task and achieves much better performance and
precision, especially CNN-based networks can achieve state of the art
RetinaNet[1]. For a single object detection task such as LPD, modified general
object detection would be time-consuming, unable to cope with complex scenarios
and a cumbersome weights file that is too hard to deploy on the embedded
device.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Cross-Modality Semantic Correlation Learning Model for Multimodal Summarization. (arXiv:2112.12072v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12072">
<div class="article-summary-box-inner">
<span><p>Multimodal summarization with multimodal output (MSMO) generates a summary
with both textual and visual content. Multimodal news report contains
heterogeneous contents, which makes MSMO nontrivial. Moreover, it is observed
that different modalities of data in the news report correlate hierarchically.
Traditional MSMO methods indistinguishably handle different modalities of data
by learning a representation for the whole data, which is not directly
adaptable to the heterogeneous contents and hierarchical correlation. In this
paper, we propose a hierarchical cross-modality semantic correlation learning
model (HCSCL) to learn the intra- and inter-modal correlation existing in the
multimodal data. HCSCL adopts a graph network to encode the intra-modal
correlation. Then, a hierarchical fusion framework is proposed to learn the
hierarchical correlation between text and images. Furthermore, we construct a
new dataset with relevant image annotation and image object label information
to provide the supervision information for the learning procedure. Extensive
experiments on the dataset show that HCSCL significantly outperforms the
baseline methods in automatic summarization metrics and fine-grained diversity
tests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two Stream Network for Stroke Detection in Table Tennis. (arXiv:2112.12073v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12073">
<div class="article-summary-box-inner">
<span><p>This paper presents a table tennis stroke detection method from videos. The
method relies on a two-stream Convolutional Neural Network processing in
parallel the RGB Stream and its computed optical flow. The method has been
developed as part of the MediaEval 2021 benchmark for the Sport task. Our
contribution did not outperform the provided baseline on the test set but has
performed the best among the other participants with regard to the mAP metric.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatio-Temporal CNN baseline method for the Sports Video Task of MediaEval 2021 benchmark. (arXiv:2112.12074v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12074">
<div class="article-summary-box-inner">
<span><p>This paper presents the baseline method proposed for the Sports Video task
part of the MediaEval 2021 benchmark. This task proposes a stroke detection and
a stroke classification subtasks. This baseline addresses both subtasks. The
spatio-temporal CNN architecture and the training process of the model are
tailored according to the addressed subtask. The method has the purpose of
helping the participants to solve the task and is not meant to reach
stateof-the-art performance. Still, for the detection task, the baseline is
performing better than the other participants, which stresses the difficulty of
such a task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deeper Learning with CoLU Activation. (arXiv:2112.12078v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12078">
<div class="article-summary-box-inner">
<span><p>In neural networks, non-linearity is introduced by activation functions. One
commonly used activation function is Rectified Linear Unit (ReLU). ReLU has
been a popular choice as an activation but has flaws. State-of-the-art
functions like Swish and Mish are now gaining attention as a better choice as
they combat many flaws presented by other activation functions. CoLU is an
activation function similar to Swish and Mish in properties. It is defined as
f(x)=x/(1-xe^-(x+e^x)). It is smooth, continuously differentiable, unbounded
above, bounded below, non-saturating, and non-monotonic. Based on experiments
done with CoLU with different activation functions, it is observed that CoLU
usually performs better than other functions on deeper neural networks. While
training different neural networks on MNIST on an incrementally increasing
number of convolutional layers, CoLU retained the highest accuracy for more
layers. On a smaller network with 8 convolutional layers, CoLU had the highest
mean accuracy, closely followed by ReLU. On VGG-13 trained on Fashion-MNIST,
CoLU had a 4.20% higher accuracy than Mish and 3.31% higher accuracy than ReLU.
On ResNet-9 trained on Cifar-10, CoLU had 0.05% higher accuracy than Swish,
0.09% higher accuracy than Mish, and 0.29% higher accuracy than ReLU. It is
observed that activation functions may behave better than other activation
functions based on different factors including the number of layers, types of
layers, number of parameters, learning rate, optimizer, etc. Further research
can be done on these factors and activation functions for more optimal
activation functions and more knowledge on their behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Adaptive Noise Covariance Matrices Estimation and Filtering Method: Application to Multi-Object Tracking. (arXiv:2112.12082v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12082">
<div class="article-summary-box-inner">
<span><p>Kalman filters are widely used for object tracking, where process and
measurement noise are usually considered accurately known and constant.
However, the exact known and constant assumptions do not always hold in
practice. For example, when lidar is used to track noncooperative targets, the
measurement noise is different under different distances and weather
conditions. In addition, the process noise changes with the object's motion
state, especially when the tracking object is a pedestrian, and the process
noise changes more frequently. This paper proposes a new
estimation-calibration-correction closed-loop estimation method to estimate the
Kalman filter process and measurement noise covariance matrices online. First,
we decompose the noise covariance matrix into an element distribution matrix
and noise intensity and improve the Sage filter to estimate the element
distribution matrix. Second, we propose a calibration method to accurately
diagnose the noise intensity deviation. We then propose a correct method to
adaptively correct the noise intensity online. Third, under the assumption that
the system is detectable, the unbiased and convergence of the proposed method
is mathematically proven. Simulation results prove the effectiveness and
reliability of the proposed method. Finally, we apply the proposed method to
multiobject tracking of lidar and evaluate it on the official KITTI server. The
proposed method on the KITTI pedestrian multiobject tracking leaderboard
(<a href="http://www.cvlibs.net/datasets">this http URL</a> /kitti/eval_tracking.php) surpasses all
existing methods using lidar, proving the feasibility of the method in
practical applications. This work provides a new way to improve the performance
of the Kalman filter and multiobject tracking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Input-Specific Robustness Certification for Randomized Smoothing. (arXiv:2112.12084v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12084">
<div class="article-summary-box-inner">
<span><p>Although randomized smoothing has demonstrated high certified robustness and
superior scalability to other certified defenses, the high computational
overhead of the robustness certification bottlenecks the practical
applicability, as it depends heavily on the large sample approximation for
estimating the confidence interval. In existing works, the sample size for the
confidence interval is universally set and agnostic to the input for
prediction. This Input-Agnostic Sampling (IAS) scheme may yield a poor Average
Certified Radius (ACR)-runtime trade-off which calls for improvement. In this
paper, we propose Input-Specific Sampling (ISS) acceleration to achieve the
cost-effectiveness for robustness certification, in an adaptive way of reducing
the sampling size based on the input characteristic. Furthermore, our method
universally controls the certified radius decline from the ISS sample size
reduction. The empirical results on CIFAR-10 and ImageNet show that ISS can
speed up the certification by more than three times at a limited cost of 0.05
certified radius. Meanwhile, ISS surpasses IAS on the average certified radius
across the extensive hyperparameter settings. Specifically, ISS achieves
ACR=0.958 on ImageNet ($\sigma=1.0$) in 250 minutes, compared to ACR=0.917 by
IAS under the same condition. We release our code in
\url{https://github.com/roy-ch/Input-Specific-Certification}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved skin lesion recognition by a Self-Supervised Curricular Deep Learning approach. (arXiv:2112.12086v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12086">
<div class="article-summary-box-inner">
<span><p>State-of-the-art deep learning approaches for skin lesion recognition often
require pretraining on larger and more varied datasets, to overcome the
generalization limitations derived from the reduced size of the skin lesion
imaging datasets. ImageNet is often used as the pretraining dataset, but its
transferring potential is hindered by the domain gap between the source dataset
and the target dermatoscopic scenario. In this work, we introduce a novel
pretraining approach that sequentially trains a series of Self-Supervised
Learning pretext tasks and only requires the unlabeled skin lesion imaging
data. We present a simple methodology to establish an ordering that defines a
pretext task curriculum. For the multi-class skin lesion classification
problem, and ISIC-2019 dataset, we provide experimental evidence showing that:
i) a model pretrained by a curriculum of pretext tasks outperforms models
pretrained by individual pretext tasks, and ii) a model pretrained by the
optimal pretext task curriculum outperforms a model pretrained on ImageNet. We
demonstrate that this performance gain is related to the fact that the
curriculum of pretext tasks better focuses the attention of the final model on
the skin lesion. Beyond performance improvement, this strategy allows for a
large reduction in the training time with respect to ImageNet pretraining,
which is especially advantageous for network architectures tailored for a
specific problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reflash Dropout in Image Super-Resolution. (arXiv:2112.12089v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12089">
<div class="article-summary-box-inner">
<span><p>Dropout is designed to relieve the overfitting problem in high-level vision
tasks but is rarely applied in low-level vision tasks, like image
super-resolution (SR). As a classic regression problem, SR exhibits a different
behaviour as high-level tasks and is sensitive to the dropout operation.
However, in this paper, we show that appropriate usage of dropout benefits SR
networks and improves the generalization ability. Specifically, dropout is
better embedded at the end of the network and is significantly helpful for the
multi-degradation settings. This discovery breaks our common sense and inspires
us to explore its working mechanism. We further use two analysis tools -- one
is from recent network interpretation works, and the other is specially
designed for this task. The analysis results provide side proofs to our
experimental findings and show us a new perspective to understand SR networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NICE-SLAM: Neural Implicit Scalable Encoding for SLAM. (arXiv:2112.12130v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12130">
<div class="article-summary-box-inner">
<span><p>Neural implicit representations have recently shown encouraging results in
various domains, including promising progress in simultaneous localization and
mapping (SLAM). Nevertheless, existing methods produce over-smoothed scene
reconstructions and have difficulty scaling up to large scenes. These
limitations are mainly due to their simple fully-connected network architecture
that does not incorporate local information in the observations. In this paper,
we present NICE-SLAM, a dense SLAM system that incorporates multi-level local
information by introducing a hierarchical scene representation. Optimizing this
representation with pre-trained geometric priors enables detailed
reconstruction on large indoor scenes. Compared to recent neural implicit SLAM
systems, our approach is more scalable, efficient, and robust. Experiments on
five challenging datasets demonstrate competitive results of NICE-SLAM in both
mapping and tracking quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Deep Neural Networks be Converted to Ultra Low-Latency Spiking Neural Networks?. (arXiv:2112.12133v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12133">
<div class="article-summary-box-inner">
<span><p>Spiking neural networks (SNNs), that operate via binary spikes distributed
over time, have emerged as a promising energy efficient ML paradigm for
resource-constrained devices. However, the current state-of-the-art (SOTA) SNNs
require multiple time steps for acceptable inference accuracy, increasing
spiking activity and, consequently, energy consumption. SOTA training
strategies for SNNs involve conversion from a non-spiking deep neural network
(DNN). In this paper, we determine that SOTA conversion strategies cannot yield
ultra low latency because they incorrectly assume that the DNN and SNN
pre-activation values are uniformly distributed. We propose a new training
algorithm that accurately captures these distributions, minimizing the error
between the DNN and converted SNN. The resulting SNNs have ultra low latency
and high activation sparsity, yielding significant improvements in compute
efficiency. In particular, we evaluate our framework on image recognition tasks
from CIFAR-10 and CIFAR-100 datasets on several VGG and ResNet architectures.
We obtain top-1 accuracy of 64.19% with only 2 time steps on the CIFAR-100
dataset with ~159.2x lower compute energy compared to an iso-architecture
standard DNN. Compared to other SOTA SNN models, our models perform inference
2.5-8x faster (i.e., with fewer time steps).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal 3D Human Pose Estimation with 2D Weak Supervision in Autonomous Driving. (arXiv:2112.12141v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12141">
<div class="article-summary-box-inner">
<span><p>3D human pose estimation (HPE) in autonomous vehicles (AV) differs from other
use cases in many factors, including the 3D resolution and range of data,
absence of dense depth maps, failure modes for LiDAR, relative location between
the camera and LiDAR, and a high bar for estimation accuracy. Data collected
for other use cases (such as virtual reality, gaming, and animation) may
therefore not be usable for AV applications. This necessitates the collection
and annotation of a large amount of 3D data for HPE in AV, which is
time-consuming and expensive. In this paper, we propose one of the first
approaches to alleviate this problem in the AV setting. Specifically, we
propose a multi-modal approach which uses 2D labels on RGB images as weak
supervision to perform 3D HPE. The proposed multi-modal architecture
incorporates LiDAR and camera inputs with an auxiliary segmentation branch. On
the Waymo Open Dataset, our approach achieves a 22% relative improvement over
camera-only 2D HPE baseline, and 6% improvement over LiDAR-only model. Finally,
careful ablation studies and parts based analysis illustrate the advantages of
each of our contributions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-Vocabulary Image Segmentation. (arXiv:2112.12143v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12143">
<div class="article-summary-box-inner">
<span><p>We design an open-vocabulary image segmentation model to organize an image
into meaningful regions indicated by arbitrary texts. We identify that recent
open-vocabulary models can not localize visual concepts well despite
recognizing what are in an image. We argue that these models miss an important
step of visual grouping, which organizes pixels into groups before learning
visual-semantic alignments. We propose OpenSeg to address the above issue.
First, it learns to propose segmentation masks for possible organizations. Then
it learns visual-semantic alignments by aligning each word in a caption to one
or a few predicted masks. We find the mask representations are the key to
support learning from captions, making it possible to scale up the dataset and
vocabulary sizes. Our work is the first to perform zero-shot transfer on
holdout segmentation datasets. We set up two strong baselines by applying class
activation maps or fine-tuning with pixel-wise labels on a pre-trained ALIGN
model. OpenSeg outperforms these baselines by 3.4 mIoU on PASCAL-Context (459
classes) and 2.7 mIoU on ADE-20k (847 classes).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HAD-GAN: A Human-perception Auxiliary Defense GAN to Defend Adversarial Examples. (arXiv:1909.07558v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.07558">
<div class="article-summary-box-inner">
<span><p>Adversarial examples reveal the vulnerability and unexplained nature of
neural networks. Studying the defense of adversarial examples is of
considerable practical importance. Most adversarial examples that misclassify
networks are often undetectable by humans. In this paper, we propose a defense
model to train the classifier into a human-perception classification model with
shape preference. The proposed model comprising a texture transfer network
(TTN) and an auxiliary defense generative adversarial networks (GAN) is called
Human-perception Auxiliary Defense GAN (HAD-GAN). The TTN is used to extend the
texture samples of a clean image and helps classifiers focus on its shape. GAN
is utilized to form a training framework for the model and generate the
necessary images. A series of experiments conducted on MNIST, Fashion-MNIST and
CIFAR10 show that the proposed model outperforms the state-of-the-art defense
methods for network robustness. The model also demonstrates a significant
improvement on defense capability of adversarial examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aerial Images Processing for Car Detection using Convolutional Neural Networks: Comparison between Faster R-CNN and YoloV3. (arXiv:1910.07234v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.07234">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the problem of car detection from aerial images
using Convolutional Neural Networks (CNN). This problem presents additional
challenges as compared to car (or any object) detection from ground images
because features of vehicles from aerial images are more difficult to discern.
To investigate this issue, we assess the performance of two state-of-the-art
CNN algorithms, namely Faster R-CNN, which is the most popular region-based
algorithm, and YOLOv3, which is known to be the fastest detection algorithm. We
analyze two datasets with different characteristics to check the impact of
various factors, such as UAV's altitude, camera resolution, and object size. A
total of 39 training experiments were conducted to account for the effect of
different hyperparameter values. The objective of this work is to conduct the
most robust and exhaustive comparison between these two cutting-edge algorithms
on the specific domain of aerial images. By using a variety of metrics, we show
that YOLOv3 yields better performance in most configurations, except that it
exhibits a lower recall and less confident detections when object sizes and
scales in the testing dataset differ largely from those in the training
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ocular Recognition Databases and Competitions: A Survey. (arXiv:1911.09646v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.09646">
<div class="article-summary-box-inner">
<span><p>The use of the iris and periocular region as biometric traits has been
extensively investigated, mainly due to the singularity of the iris features
and the use of the periocular region when the image resolution is not
sufficient to extract iris information. In addition to providing information
about an individual's identity, features extracted from these traits can also
be explored to obtain other information such as the individual's gender, the
influence of drug use, the use of contact lenses, spoofing, among others. This
work presents a survey of the databases created for ocular recognition,
detailing their protocols and how their images were acquired. We also describe
and discuss the most popular ocular recognition competitions (contests),
highlighting the submitted algorithms that achieved the best results using only
iris trait and also fusing iris and periocular region information. Finally, we
describe some relevant works applying deep learning techniques to ocular
recognition and point out new challenges and future directions. Considering
that there are a large number of ocular databases, and each one is usually
designed for a specific problem, we believe this survey can provide a broad
overview of the challenges in ocular biometrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Little Bit More: Bitplane-Wise Bit-Depth Recovery. (arXiv:2005.01091v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01091">
<div class="article-summary-box-inner">
<span><p>Imaging sensors digitize incoming scene light at a dynamic range of 10--12
bits (i.e., 1024--4096 tonal values). The sensor image is then processed
onboard the camera and finally quantized to only 8 bits (i.e., 256 tonal
values) to conform to prevailing encoding standards. There are a number of
important applications, such as high-bit-depth displays and photo editing,
where it is beneficial to recover the lost bit depth. Deep neural networks are
effective at this bit-depth reconstruction task. Given the quantized
low-bit-depth image as input, existing deep learning methods employ a
single-shot approach that attempts to either (1) directly estimate the
high-bit-depth image, or (2) directly estimate the residual between the high-
and low-bit-depth images. In contrast, we propose a training and inference
strategy that recovers the residual image bitplane-by-bitplane. Our
bitplane-wise learning framework has the advantage of allowing for multiple
levels of supervision during training and is able to obtain state-of-the-art
results using a simple network architecture. We test our proposed method
extensively on several image datasets and demonstrate an improvement from 0.5dB
to 2.3dB PSNR over prior methods depending on the quantization level.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medical Image Segmentation Using Deep Learning: A Survey. (arXiv:2009.13120v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13120">
<div class="article-summary-box-inner">
<span><p>Deep learning has been widely used for medical image segmentation and a large
number of papers has been presented recording the success of deep learning in
the field. In this paper, we present a comprehensive thematic survey on medical
image segmentation using deep learning techniques. This paper makes two
original contributions. Firstly, compared to traditional surveys that directly
divide literatures of deep learning on medical image segmentation into many
groups and introduce literatures in detail for each group, we classify
currently popular literatures according to a multi-level structure from coarse
to fine. Secondly, this paper focuses on supervised and weakly supervised
learning approaches, without including unsupervised approaches since they have
been introduced in many old surveys and they are not popular currently. For
supervised learning approaches, we analyze literatures in three aspects: the
selection of backbone networks, the design of network blocks, and the
improvement of loss functions. For weakly supervised learning approaches, we
investigate literature according to data augmentation, transfer learning, and
interactive segmentation, separately. Compared to existing surveys, this survey
classifies the literatures very differently from before and is more convenient
for readers to understand the relevant rationale and will guide them to think
of appropriate improvements in medical image segmentation based on deep
learning approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sampling possible reconstructions of undersampled acquisitions in MR imaging. (arXiv:2010.00042v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00042">
<div class="article-summary-box-inner">
<span><p>Undersampling the k-space during MR acquisitions saves time, however results
in an ill-posed inversion problem, leading to an infinite set of images as
possible solutions. Traditionally, this is tackled as a reconstruction problem
by searching for a single "best" image out of this solution set according to
some chosen regularization or prior. This approach, however, misses the
possibility of other solutions and hence ignores the uncertainty in the
inversion process. In this paper, we propose a method that instead returns
multiple images which are possible under the acquisition model and the chosen
prior to capture the uncertainty in the inversion process. To this end, we
introduce a low dimensional latent space and model the posterior distribution
of the latent vectors given the acquisition data in k-space, from which we can
sample in the latent space and obtain the corresponding images. We use a
variational autoencoder for the latent model and the Metropolis adjusted
Langevin algorithm for the sampling. We evaluate our method on two datasets;
with images from the Human Connectome Project and in-house measured multi-coil
images. We compare to five alternative methods. Results indicate that the
proposed method produces images that match the measured k-space data better
than the alternatives, while showing realistic structural variability.
Furthermore, in contrast to the compared methods, the proposed method yields
higher uncertainty in the undersampled phase encoding direction, as expected.
</p>
<p>Keywords: Magnetic Resonance image reconstruction, uncertainty estimation,
inverse problems, sampling, MCMC, deep learning, unsupervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ensemble and Random Collaborative Representation-Based Anomaly Detector for Hyperspectral Imagery. (arXiv:2101.01976v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01976">
<div class="article-summary-box-inner">
<span><p>In recent years, hyperspectral anomaly detection (HAD) has become an active
topic and plays a significant role in military and civilian fields. As a
classic HAD method, the collaboration representation-based detector (CRD) has
attracted extensive attention and in-depth research. Despite the good
performance of the CRD method, its computational cost mainly arising from the
sliding dual window strategy is too high for wide applications. Moreover, it
takes multiple repeated tests to determine the size of the dual window, which
needs to be reset once the dataset changes and cannot be identified in advance
with prior knowledge. To alleviate this problem, we proposed a novel ensemble
and random collaborative representation-based detector (ERCRD) for HAD, which
comprises two closely related stages. Firstly, we process the random
sub-sampling on CRD (RCRD) to gain several detection results instead of the
sliding dual window strategy, which significantly reduces the computational
complexity and makes it more feasible in practical applications. Secondly,
ensemble learning is employed to refine the multiple results of RCRD, which act
as various "experts" providing abundant complementary information to better
target different anomalies. Such two stages form an organic and theoretical
detector, which can not only improve the accuracy and stability of HAD methods
but also enhance its generalization ability. Experiments on four real
hyperspectral datasets exhibit the accuracy and efficiency of this proposed
ERCRD method compared with ten state-of-the-art HAD methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Open Domain Adaptation for Sketch-to-Photo Synthesis. (arXiv:2104.05703v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05703">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore open-domain sketch-to-photo translation, which aims
to synthesize a realistic photo from a freehand sketch with its class label,
even if the sketches of that class are missing in the training data. It is
challenging due to the lack of training supervision and the large geometric
distortion between the freehand sketch and photo domains. To synthesize the
absent freehand sketches from photos, we propose a framework that jointly
learns sketch-to-photo and photo-to-sketch generation. However, the generator
trained from fake sketches might lead to unsatisfying results when dealing with
sketches of missing classes, due to the domain gap between synthesized sketches
and real ones. To alleviate this issue, we further propose a simple yet
effective open-domain sampling and optimization strategy to "fool" the
generator into treating fake sketches as real ones. Our method takes advantage
of the learned sketch-to-photo and photo-to-sketch mapping of in-domain data
and generalizes it to the open-domain classes. We validate our method on the
Scribble and SketchyCOCO datasets. Compared with the recent competing methods,
our approach shows impressive results in synthesizing realistic color, texture,
and maintaining the geometric composition for various categories of open-domain
sketches. Our code is available at https://github.com/Mukosame/AODA
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Log-Determinant Divergences for Positive Definite Matrices. (arXiv:2104.06461v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06461">
<div class="article-summary-box-inner">
<span><p>Representations in the form of Symmetric Positive Definite (SPD) matrices
have been popularized in a variety of visual learning applications due to their
demonstrated ability to capture rich second-order statistics of visual data.
There exist several similarity measures for comparing SPD matrices with
documented benefits. However, selecting an appropriate measure for a given
problem remains a challenge and in most cases, is the result of a
trial-and-error process. In this paper, we propose to learn similarity measures
in a data-driven manner. To this end, we capitalize on the \alpha\beta-log-det
divergence, which is a meta-divergence parametrized by scalars \alpha and
\beta, subsuming a wide family of popular information divergences on SPD
matrices for distinct and discrete values of these parameters. Our key idea is
to cast these parameters in a continuum and learn them from data. We
systematically extend this idea to learn vector-valued parameters, thereby
increasing the expressiveness of the underlying non-linear measure. We conjoin
the divergence learning problem with several standard tasks in machine
learning, including supervised discriminative dictionary learning and
unsupervised SPD matrix clustering. We present Riemannian gradient descent
schemes for optimizing our formulations efficiently, and show the usefulness of
our method on eight standard computer vision tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overcoming the Distance Estimation Bottleneck in Estimating Animal Abundance with Camera Traps. (arXiv:2105.04244v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04244">
<div class="article-summary-box-inner">
<span><p>The biodiversity crisis is still accelerating, despite increasing efforts by
the international community. Estimating animal abundance is of critical
importance to assess, for example, the consequences of land-use change and
invasive species on community composition, or the effectiveness of conservation
interventions. Various approaches have been developed to estimate abundance of
unmarked animal populations. Whereas these approaches differ in methodological
details, they all require the estimation of the effective area surveyed in
front of a camera trap. Until now camera-to-animal distance measurements are
derived by laborious, manual and subjective estimation methods. To overcome
this distance estimation bottleneck, this study proposes an automatized
pipeline utilizing monocular depth estimation and depth image calibration
methods. We are able to reduce the manual effort required by a factor greater
than 21 and provide our system at
https://timm.haucke.xyz/publications/distance-estimation-animal-abundance
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SHD360: A Benchmark Dataset for Salient Human Detection in 360{\deg} Videos. (arXiv:2105.11578v7 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11578">
<div class="article-summary-box-inner">
<span><p>Salient human detection (SHD) in dynamic 360{\deg} immersive videos is of
great importance for various applications such as robotics, inter-human and
human-object interaction in augmented reality. However, 360{\deg} video SHD has
been seldom discussed in the computer vision community due to a lack of
datasets with large-scale omnidirectional videos and rich annotations. To this
end, we propose SHD360, the first 360{\deg} video SHD dataset which contains
various real-life daily scenes. Since so far there is no method proposed for
360{\deg} image/video SHD, we systematically benchmark 11 representative
state-of-the-art salient object detection (SOD) approaches on our SHD360, and
explore key issues derived from extensive experimenting results. We hope our
proposed dataset and benchmark could serve as a good starting point for
advancing human-centric researches towards 360{\deg} panoramic data. The
dataset is available at https://github.com/PanoAsh/SHD360.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination. (arXiv:2106.01970v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01970">
<div class="article-summary-box-inner">
<span><p>We address the problem of recovering the shape and spatially-varying
reflectance of an object from multi-view images (and their camera poses) of an
object illuminated by one unknown lighting condition. This enables the
rendering of novel views of the object under arbitrary environment lighting and
editing of the object's material properties. The key to our approach, which we
call Neural Radiance Factorization (NeRFactor), is to distill the volumetric
geometry of a Neural Radiance Field (NeRF) [Mildenhall et al. 2020]
representation of the object into a surface representation and then jointly
refine the geometry while solving for the spatially-varying reflectance and
environment lighting. Specifically, NeRFactor recovers 3D neural fields of
surface normals, light visibility, albedo, and Bidirectional Reflectance
Distribution Functions (BRDFs) without any supervision, using only a
re-rendering loss, simple smoothness priors, and a data-driven BRDF prior
learned from real-world BRDF measurements. By explicitly modeling light
visibility, NeRFactor is able to separate shadows from albedo and synthesize
realistic soft or hard shadows under arbitrary lighting conditions. NeRFactor
is able to recover convincing 3D models for free-viewpoint relighting in this
challenging and underconstrained capture setup for both synthetic and real
scenes. Qualitative and quantitative experiments show that NeRFactor
outperforms classic and deep learning-based state of the art across various
tasks. Our videos, code, and data are available at
people.csail.mit.edu/xiuming/projects/nerfactor/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long Short-Term Transformer for Online Action Detection. (arXiv:2107.03377v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03377">
<div class="article-summary-box-inner">
<span><p>We present Long Short-term TRansformer (LSTR), a temporal modeling algorithm
for online action detection, which employs a long- and short-term memory
mechanism to model prolonged sequence data. It consists of an LSTR encoder that
dynamically leverages coarse-scale historical information from an extended
temporal window (e.g., 2048 frames spanning of up to 8 minutes), together with
an LSTR decoder that focuses on a short time window (e.g., 32 frames spanning 8
seconds) to model the fine-scale characteristics of the data. Compared to prior
work, LSTR provides an effective and efficient method to model long videos with
fewer heuristics, which is validated by extensive empirical analysis. LSTR
achieves state-of-the-art performance on three standard online action detection
benchmarks, THUMOS'14, TVSeries, and HACS Segment. Code has been made available
at: https://xumingze0308.github.io/projects/lstr
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Numerical Networks for Natura 2000 habitats classification by satellite images. (arXiv:2108.04327v2 [math.NA] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04327">
<div class="article-summary-box-inner">
<span><p>Natural numerical networks are introduced as a new classification algorithm
based on the numerical solution of nonlinear partial differential equations of
forward-backward diffusion type on complete graphs. The proposed natural
numerical network is applied to open important environmental and nature
conservation task, the automated identification of protected habitats by using
satellite images. In the natural numerical network, the forward diffusion
causes the movement of points in a feature space toward each other. The
opposite effect, keeping the points away from each other, is caused by backward
diffusion. This yields the desired classification. The natural numerical
network contains a few parameters that are optimized in the learning phase of
the method. After learning parameters and optimizing the topology of the
network graph, classification necessary for habitat identification is
performed. A relevancy map for each habitat is introduced as a tool for
validating the classification and finding new Natura 2000 habitat appearances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RVMDE: Radar Validated Monocular Depth Estimation for Robotics. (arXiv:2109.05265v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05265">
<div class="article-summary-box-inner">
<span><p>Stereoscopy exposits a natural perception of distance in a scene, and its
manifestation in 3D world understanding is an intuitive phenomenon. However, an
innate rigid calibration of binocular vision sensors is crucial for accurate
depth estimation. Alternatively, a monocular camera alleviates the limitation
at the expense of accuracy in estimating depth, and the challenge exacerbates
in harsh environmental conditions. Moreover, an optical sensor often fails to
acquire vital signals in harsh environments, and radar is used instead, which
gives coarse but more accurate signals. This work explores the utility of
coarse signals from radar when fused with fine-grained data from a monocular
camera for depth estimation in harsh environmental conditions. A variant of
feature pyramid network (FPN) extensively operates on fine-grained image
features at multiple scales with a fewer number of parameters. FPN feature maps
are fused with sparse radar features extracted with a Convolutional neural
network. The concatenated hierarchical features are used to predict the depth
with ordinal regression. We performed experiments on the nuScenes dataset, and
the proposed architecture stays on top in quantitative evaluations with reduced
parameters and faster inference. The depth estimation results suggest that the
proposed techniques can be used as an alternative to stereo depth estimation in
critical applications in robotics and self-driving cars. The source code will
be available in the following: \url{https://github.com/MI-Hussain/RVMDE}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learn to Ignore: Domain Adaptation for Multi-Site MRI Analysis. (arXiv:2110.06803v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06803">
<div class="article-summary-box-inner">
<span><p>Limited availability of large image datasets is a major issue in the
development of accurate and generalizable machine learning methods in medicine.
The limitations in the amount of data are mainly due to the use of different
acquisition protocols, different hardware, and data privacy. At the same time,
training a classification model on a small dataset leads to a poor
generalization quality of the model. To overcome this issue, a combination of
various image datasets of different provenance is often used, e.g., multi-site
studies. However, if an additional dataset does not include all classes of the
task, the learning of the classification model can be biased to the device or
place of acquisition.
</p>
<p>This is especially the case for Magnetic Resonance (MR) images, where
different MR scanners introduce a bias that limits the performance of the
model. In this paper, we present a novel method that learns to ignore the
scanner-related features present in the images, while learning features
relevant for the classification task. We focus on a real-world scenario, where
only a small dataset provides images of all classes. We exploit this
circumstance by introducing specific additional constraints on the latent
space, which lead the focus on disease-related rather than scanner-specific
features. Our method Learn to Ignore outperforms state-of-the-art domain
adaptation methods on a multi-site MRI dataset on a classification task between
Multiple Sclerosis patients and healthy subjects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Algorithmic encoding of protected characteristics and its implications on performance disparities. (arXiv:2110.14755v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14755">
<div class="article-summary-box-inner">
<span><p>It has been rightfully emphasized that the use of AI for clinical decision
making could amplify health disparities. A machine learning model may pick up
undesirable correlations, for example, between a patient's racial identity and
clinical outcome. Such correlations are often present in (historical) data used
for model development. There has been an increase in studies reporting biases
in disease detection models. Besides the scarcity of data from underserved
populations, very little is known about how these biases are encoded and how
one may reduce or even remove disparate performance. There are concerns that an
algorithm may recognize patient characteristics such as biological sex or
racial identity, and then directly or indirectly use this information when
making predictions. But it remains unclear how we can establish whether such
information is actually used. This article aims to shed some light on these
issues by exploring methodology allowing intuitive inspections of the inner
working of machine learning models for image-based detection of disease. We
also investigate how to address performance disparities and find automatic
threshold selection to be an effective yet questionable technique, resulting in
models with comparable true and false positive rates across subgroups. Our
findings call for further research to better understand the underlying causes
of performance disparities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Developing a Novel Approach for Periapical Dental Radiographs Segmentation. (arXiv:2111.07156v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.07156">
<div class="article-summary-box-inner">
<span><p>Image processing techniques has been widely used in dental researches such as
human identification and forensic dentistry, teeth numbering, dental carries
detection and periodontal disease analysis. One of the most challenging parts
in dental imaging is teeth segmentation and how to separate them from each
other. In this paper, an automated method for teeth segmentation of Periapical
dental x-ray images which contain at least one root-canalled tooth is proposed.
The result of this approach can be used as an initial step in bone lesion
detection. The proposed algorithm is made of two stages. The first stage is
pre-processing. The second and main part of this algorithm calculated rotation
degree and uses the integral projection method for tooth isolation.
Experimental results show that this algorithm is robust and achieves high
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Representing Prior Knowledge Using Randomly, Weighted Feature Networks for Visual Relationship Detection. (arXiv:2111.10686v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.10686">
<div class="article-summary-box-inner">
<span><p>The single-hidden-layer Randomly Weighted Feature Network (RWFN) introduced
by Hong and Pavlic (2021) was developed as an alternative to neural tensor
network approaches for relational learning tasks. Its relatively small
footprint combined with the use of two randomized input projections -- an
insect-brain-inspired input representation and random Fourier features -- allow
it to achieve rich expressiveness for relational learning with relatively low
training cost. In particular, when Hong and Pavlic compared RWFN to Logic
Tensor Networks (LTNs) for Semantic Image Interpretation (SII) tasks to extract
structured semantic descriptions from images, they showed that the RWFN
integration of the two hidden, randomized representations better captures
relationships among inputs with a faster training process even though it uses
far fewer learnable parameters. In this paper, we use RWFNs to perform Visual
Relationship Detection (VRD) tasks, which are more challenging SII tasks. A
zero-shot learning approach is used with RWFN that can exploit similarities
with other seen relationships and background knowledge -- expressed with
logical constraints between subjects, relations, and objects -- to achieve the
ability to predict triples that do not appear in the training set. The
experiments on the Visual Relationship Dataset to compare the performance
between RWFNs and LTNs, one of the leading Statistical Relational Learning
frameworks, show that RWFNs outperform LTNs for the predicate-detection task
while using fewer number of adaptable parameters (1:56 ratio). Furthermore,
background knowledge represented by RWFNs can be used to alleviate the
incompleteness of training sets even though the space complexity of RWFNs is
much smaller than LTNs (1:27 ratio).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Adversarial Networks with Conditional Neural Movement Primitives for An Interactive Generative Drawing Tool. (arXiv:2111.14934v2 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.14934">
<div class="article-summary-box-inner">
<span><p>Sketches are abstract representations of visual perception and visuospatial
construction. In this work, we proposed a new framework, Generative Adversarial
Networks with Conditional Neural Movement Primitives (GAN-CNMP), that
incorporates a novel adversarial loss on CNMP to increase sketch smoothness and
consistency. Through the experiments, we show that our model can be trained
with few unlabeled samples, can construct distributions automatically in the
latent space, and produces better results than the base model in terms of shape
consistency and smoothness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MultiPath++: Efficient Information Fusion and Trajectory Aggregation for Behavior Prediction. (arXiv:2111.14973v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.14973">
<div class="article-summary-box-inner">
<span><p>Predicting the future behavior of road users is one of the most challenging
and important problems in autonomous driving. Applying deep learning to this
problem requires fusing heterogeneous world state in the form of rich
perception signals and map information, and inferring highly multi-modal
distributions over possible futures. In this paper, we present MultiPath++, a
future prediction model that achieves state-of-the-art performance on popular
benchmarks. MultiPath++ improves the MultiPath architecture by revisiting many
design choices. The first key design difference is a departure from dense
image-based encoding of the input world state in favor of a sparse encoding of
heterogeneous scene elements: MultiPath++ consumes compact and efficient
polylines to describe road features, and raw agent state information directly
(e.g., position, velocity, acceleration). We propose a context-aware fusion of
these elements and develop a reusable multi-context gating fusion component.
Second, we reconsider the choice of pre-defined, static anchors, and develop a
way to learn latent anchor embeddings end-to-end in the model. Lastly, we
explore ensembling and output aggregation techniques -- common in other ML
domains -- and find effective variants for our probabilistic multimodal output
representation. We perform an extensive ablation on these design choices, and
show that our proposed model achieves state-of-the-art performance on the
Argoverse Motion Forecasting Competition and the Waymo Open Dataset Motion
Prediction Challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Superpixel-Based Building Damage Detection from Post-earthquake Very High Resolution Imagery Using Deep Neural Networks. (arXiv:2112.04744v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04744">
<div class="article-summary-box-inner">
<span><p>Building damage detection after natural disasters like earthquakes is crucial
for initiating effective emergency response actions. Remotely sensed very high
spatial resolution (VHR) imagery can provide vital information due to their
ability to map the affected buildings with high geometric precision. Many
approaches have been developed to detect damaged buildings due to earthquakes.
However, little attention has been paid to exploiting rich features represented
in VHR images using Deep Neural Networks (DNN). This paper presents a novel
superpixel based approach combining DNN and a modified segmentation method, to
detect damaged buildings from VHR imagery. Firstly, a modified Fast Scanning
and Adaptive Merging method is extended to create initial over-segmentation.
Secondly, the segments are merged based on the Region Adjacent Graph (RAG),
considered an improved semantic similarity criterion composed of Local Binary
Patterns (LBP) texture, spectral, and shape features. Thirdly, a pre-trained
DNN using Stacked Denoising Auto-Encoders called SDAE-DNN is presented, to
exploit the rich semantic features for building damage detection. Deep-layer
feature abstraction of SDAE-DNN could boost detection accuracy through learning
more intrinsic and discriminative features, which outperformed other methods
using state-of-the-art alternative classifiers. We demonstrate the feasibility
and effectiveness of our method using a subset of WorldView-2 imagery, in the
complex urban areas of Bhaktapur, Nepal, which was affected by the Nepal
Earthquake of April 25, 2015.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Locally Shifted Attention With Early Global Integration. (arXiv:2112.05080v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.05080">
<div class="article-summary-box-inner">
<span><p>Recent work has shown the potential of transformers for computer vision
applications. An image is first partitioned into patches, which are then used
as input tokens for the attention mechanism. Due to the expensive quadratic
cost of the attention mechanism, either a large patch size is used, resulting
in coarse-grained global interactions, or alternatively, attention is applied
only on a local region of the image, at the expense of long-range interactions.
In this work, we propose an approach that allows for both coarse global
interactions and fine-grained local interactions already at early layers of a
vision transformer.
</p>
<p>At the core of our method is the application of local and global attention
layers. In the local attention layer, we apply attention to each patch and its
local shifts, resulting in virtually located local patches, which are not bound
to a single, specific location. These virtually located patches are then used
in a global attention layer. The separation of the attention layer into local
and global counterparts allows for a low computational cost in the number of
patches, while still supporting data-dependent localization already at the
first layer, as opposed to the static positioning in other visual transformers.
Our method is shown to be superior to both convolutional and transformer-based
methods for image classification on CIFAR10, CIFAR100, and ImageNet. Code is
available at: https://github.com/shellysheynin/Locally-SAG-Transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Minimal Misalignment at Minimal Cost in One-Stage and Anchor-Free Object Detection. (arXiv:2112.08902v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08902">
<div class="article-summary-box-inner">
<span><p>Common object detection models consist of classification and regression
branches, due to different task drivers, these two branches have different
sensibility to the features from the same scale level and the same spatial
location. The point-based prediction method, which is based on the assumption
that the high classification confidence point has the high regression quality,
leads to the misalignment problem. Our analysis shows, the problem is further
composed of scale misalignment and spatial misalignment specifically. We aim to
resolve the phenomenon at minimal cost: a minor adjustment of the head network
and a new label assignment method replacing the rigid one. Our experiments show
that, compared to the baseline FCOS, a one-stage and anchor-free object
detection model, our model consistently get around 3 AP improvement with
different backbones, demonstrating both simplicity and efficiency of our
method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Animation with Keypoint Mask. (arXiv:2112.10457v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10457">
<div class="article-summary-box-inner">
<span><p>Motion transfer is the task of synthesizing future video frames of a single
source image according to the motion from a given driving video. In order to
solve it, we face the challenging complexity of motion representation and the
unknown relations between the driving video and the source image. Despite its
difficulty, this problem attracted great interests from researches at the
recent years, with gradual improvements. The goal is often thought as the
decoupling of motion and appearance, which is may be solved by extracting the
motion from keypoint movement. We chose to tackle the generic, unsupervised
setting, where we need to apply animation to any arbitrary object, without any
domain specific model for the structure of the input. In this work, we extract
the structure from a keypoint heatmap, without an explicit motion
representation. Then, the structures from the image and the video are extracted
to warp the image according to the video, by a deep generator. We suggest two
variants of the structure from different steps in the keypoint module, and show
superior qualitative pose and quantitative scores.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-user Oriented Live Free-viewpoint Video Streaming System Based On View Interpolation. (arXiv:2112.10603v2 [cs.MM] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10603">
<div class="article-summary-box-inner">
<span><p>As an important application form of immersive multimedia services,
free-viewpoint video(FVV) enables users with great immersive experience by
strong interaction. However, the computational complexity of virtual view
synthesis algorithms poses a significant challenge to the real-time performance
of an FVV system. Furthermore, the individuality of user interaction makes it
difficult to serve multiple users simultaneously for a system with conventional
architecture. In this paper, we novelly introduce a CNN-based view
interpolation algorithm to synthesis dense virtual views in real time. Based on
this, we also build an end-to-end live free-viewpoint system with a multi-user
oriented streaming strategy. Our system can utilize a single edge server to
serve multiple users at the same time without having to bring a large view
synthesis load on the client side. We analyze the whole system and show that
our approaches give the user a pleasant immersive experience, in terms of both
visual quality and latency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models. (arXiv:2112.10741v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10741">
<div class="article-summary-box-inner">
<span><p>Diffusion models have recently been shown to generate high-quality synthetic
images, especially when paired with a guidance technique to trade off diversity
for fidelity. We explore diffusion models for the problem of text-conditional
image synthesis and compare two different guidance strategies: CLIP guidance
and classifier-free guidance. We find that the latter is preferred by human
evaluators for both photorealism and caption similarity, and often produces
photorealistic samples. Samples from a 3.5 billion parameter text-conditional
diffusion model using classifier-free guidance are favored by human evaluators
to those from DALL-E, even when the latter uses expensive CLIP reranking.
Additionally, we find that our models can be fine-tuned to perform image
inpainting, enabling powerful text-driven image editing. We train a smaller
model on a filtered dataset and release the code and weights at
https://github.com/openai/glide-text2im.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Semantic Transfer for Multi-Label Recognition with Partial Labels. (arXiv:2112.10941v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10941">
<div class="article-summary-box-inner">
<span><p>Multi-label image recognition is a fundamental yet practical task because
real-world images inherently possess multiple semantic labels. However, it is
difficult to collect large-scale multi-label annotations due to the complexity
of both the input images and output label spaces. To reduce the annotation
cost, we propose a structured semantic transfer (SST) framework that enables
training multi-label recognition models with partial labels, i.e., merely some
labels are known while other labels are missing (also called unknown labels)
per image. The framework consists of two complementary transfer modules that
explore within-image and cross-image semantic correlations to transfer
knowledge of known labels to generate pseudo labels for unknown labels.
Specifically, an intra-image semantic transfer module learns image-specific
label co-occurrence matrix and maps the known labels to complement unknown
labels based on this matrix. Meanwhile, a cross-image transfer module learns
category-specific feature similarities and helps complement unknown labels with
high similarities. Finally, both known and generated labels are used to train
the multi-label recognition models. Extensive experiments on the Microsoft
COCO, Visual Genome and Pascal VOC datasets show that the proposed SST
framework obtains superior performance over current state-of-the-art
algorithms. Codes are available at https://github.com/HCPLab-SYSU/HCP-MLR-PL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalizing Interactive Backpropagating Refinement for Dense Prediction. (arXiv:2112.10969v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10969">
<div class="article-summary-box-inner">
<span><p>As deep neural networks become the state-of-the-art approach in the field of
computer vision for dense prediction tasks, many methods have been developed
for automatic estimation of the target outputs given the visual inputs.
Although the estimation accuracy of the proposed automatic methods continues to
improve, interactive refinement is oftentimes necessary for further correction.
Recently, feature backpropagating refinement scheme (f-BRS) has been proposed
for the task of interactive segmentation, which enables efficient optimization
of a small set of auxiliary variables inserted into the pretrained network to
produce object segmentation that better aligns with user inputs. However, the
proposed auxiliary variables only contain channel-wise scale and bias, limiting
the optimization to global refinement only. In this work, in order to
generalize backpropagating refinement for a wide range of dense prediction
tasks, we introduce a set of G-BRS (Generalized Backpropagating Refinement
Scheme) layers that enable both global and localized refinement for the
following tasks: interactive segmentation, semantic segmentation, image matting
and monocular depth estimation. Experiments on SBD, Cityscapes, Mapillary
Vista, Composition-1k and NYU-Depth-V2 show that our method can successfully
generalize and significantly improve performance of existing pretrained
state-of-the-art models with only a few clicks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Projected Sliced Wasserstein Autoencoder-based Hyperspectral Images Anomaly Detection. (arXiv:2112.11243v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11243">
<div class="article-summary-box-inner">
<span><p>Anomaly detection (AD) has been an active research area in various domains.
Yet, the increasing data scale, complexity, and dimension turn the traditional
methods into challenging. Recently, the deep generative model, such as the
variational autoencoder (VAE), has sparked a renewed interest in the AD
problem. However, the probability distribution divergence used as the
regularization is too strong, which causes the model cannot capture the
manifold of the true data. In this paper, we propose the Projected Sliced
Wasserstein (PSW) autoencoder-based anomaly detection method. Rooted in the
optimal transportation, the PSW distance is a weaker distribution measure
compared with $f$-divergence. In particular, the computation-friendly
eigen-decomposition method is leveraged to find the principal component for
slicing the high-dimensional data. In this case, the Wasserstein distance can
be calculated with the closed-form, even the prior distribution is not
Gaussian. Comprehensive experiments conducted on various real-world
hyperspectral anomaly detection benchmarks demonstrate the superior performance
of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-Fidelity Point Cloud Completion with Low-Resolution Recovery and Noise-Aware Upsampling. (arXiv:2112.11271v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11271">
<div class="article-summary-box-inner">
<span><p>Completing an unordered partial point cloud is a challenging task. Existing
approaches that rely on decoding a latent feature to recover the complete
shape, often lead to the completed point cloud being over-smoothing, losing
details, and noisy. Instead of decoding a whole shape, we propose to decode and
refine a low-resolution (low-res) point cloud first, and then performs a
patch-wise noise-aware upsampling rather than interpolating the whole sparse
point cloud at once, which tends to lose details. Regarding the possibility of
lacking details of the initially decoded low-res point cloud, we propose an
iterative refinement to recover the geometric details and a symmetrization
process to preserve the trustworthy information from the input partial point
cloud. After obtaining a sparse and complete point cloud, we propose a
patch-wise upsampling strategy. Patch-based upsampling allows to better recover
fine details unlike decoding a whole shape, however, the existing upsampling
methods are not applicable to completion task due to the data discrepancy
(i.e., input sparse data here is not from ground-truth). Therefore, we propose
a patch extraction approach to generate training patch pairs between the sparse
and ground-truth point clouds, and an outlier removal step to suppress the
noisy points from the sparse point cloud. Together with the low-res recovery,
our whole method is able to achieve high-fidelity point cloud completion.
Comprehensive evaluations are provided to demonstrate the effectiveness of the
proposed method and its individual components.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PrimSeq: a deep learning-based pipeline to quantitate rehabilitation training. (arXiv:2112.11330v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11330">
<div class="article-summary-box-inner">
<span><p>Stroke rehabilitation seeks to increase neuroplasticity through the repeated
practice of functional motions, but may have minimal impact on recovery because
of insufficient repetitions. The optimal training content and quantity are
currently unknown because no practical tools exist to measure them. Here, we
present PrimSeq, a pipeline to classify and count functional motions trained in
stroke rehabilitation. Our approach integrates wearable sensors to capture
upper-body motion, a deep learning model to predict motion sequences, and an
algorithm to tally motions. The trained model accurately decomposes
rehabilitation activities into component functional motions, outperforming
competitive machine learning methods. PrimSeq furthermore quantifies these
motions at a fraction of the time and labor costs of human experts. We
demonstrate the capabilities of PrimSeq in previously unseen stroke patients
with a range of upper extremity motor impairment. We expect that these advances
will support the rigorous measurement required for quantitative dosing trials
in stroke rehabilitation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Based 3D Point Cloud Regression for Estimating Forest Biomass. (arXiv:2112.11335v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11335">
<div class="article-summary-box-inner">
<span><p>Knowledge of forest biomass stocks and their development is important for
implementing effective climate change mitigation measures. It is needed for
studying the processes driving af-, re-, and deforestation and is a
prerequisite for carbon-accounting. Remote sensing using airborne LiDAR can be
used to measure vegetation biomass at large scale. We present deep learning
systems for predicting wood volume, above-ground biomass (AGB), and
subsequently carbon directly from 3D LiDAR point cloud data. We devise
different neural network architectures for point cloud regression and evaluate
them on remote sensing data of areas for which AGB estimates have been obtained
from field measurements in a national forest inventory. Our adaptation of
Minkowski convolutional neural networks for regression gave the best results.
The deep neural networks produced significantly more accurate wood volume, AGB,
and carbon estimates compared to state-of-the-art approaches operating on basic
statistics of the point clouds, and we expect this finding to have a strong
impact on LiDAR-based analyses of terrestrial ecosystem dynamics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation. (arXiv:2112.11427v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11427">
<div class="article-summary-box-inner">
<span><p>We introduce a high resolution, 3D-consistent image and shape generation
technique which we call StyleSDF. Our method is trained on single-view RGB data
only, and stands on the shoulders of StyleGAN2 for image generation, while
solving two main challenges in 3D-aware GANs: 1) high-resolution,
view-consistent generation of the RGB images, and 2) detailed 3D shape. We
achieve this by merging a SDF-based 3D representation with a style-based 2D
generator. Our 3D implicit network renders low-resolution feature maps, from
which the style-based network generates view-consistent, 1024x1024 images.
Notably, our SDF-based 3D modeling defines detailed 3D surfaces, leading to
consistent volume rendering. Our method shows higher quality results compared
to state of the art in terms of visual and geometric quality.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-12-23 23:07:27.226712104 UTC">2021-12-23 23:07:27 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>