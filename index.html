<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-06-22T01:30:00Z">06-22</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Putting GPT-3's Creativity to the (Alternative Uses) Test. (arXiv:2206.08932v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08932">
<div class="article-summary-box-inner">
<span><p>AI large language models have (co-)produced amazing written works from
newspaper articles to novels and poetry. These works meet the standards of the
standard definition of creativity: being original and useful, and sometimes
even the additional element of surprise. But can a large language model
designed to predict the next text fragment provide creative, out-of-the-box,
responses that still solve the problem at hand? We put Open AI's generative
natural language model, GPT-3, to the test. Can it provide creative solutions
to one of the most commonly used tests in creativity research? We assessed
GPT-3's creativity on Guilford's Alternative Uses Test and compared its
performance to previously collected human responses on expert ratings of
originality, usefulness and surprise of responses, flexibility of each set of
ideas as well as an automated method to measure creativity based on the
semantic distance between a response and the AUT object in question. Our
results show that -- on the whole -- humans currently outperform GPT-3 when it
comes to creative output. But, we believe it is only a matter of time before
GPT-3 catches up on this particular task. We discuss what this work reveals
about human and AI creativity, creativity testing and our definition of
creativity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making first order linear logic a generating grammar. (arXiv:2206.08955v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08955">
<div class="article-summary-box-inner">
<span><p>It is known that different categorial grammars have surface representation in
a fragment of first order multiplicative linear logic. We show that the
fragment of interest is equivalent to the recently introduced {\it extended
tensor type calculus}. This provides the former not only with some alternative
syntax and intuitive geometric representation, but also with an intrinsic
deductive system, which has been absent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BN-HTRd: A Benchmark Dataset for Document Level Offline Bangla Handwritten Text Recognition (HTR) and Line Segmentation. (arXiv:2206.08977v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08977">
<div class="article-summary-box-inner">
<span><p>We introduce a new dataset for offline Handwritten Text Recognition (HTR)
from images of Bangla scripts comprising words, lines, and document-level
annotations. The BN-HTRd dataset is based on the BBC Bangla News corpus, meant
to act as ground truth texts. These texts were subsequently used to generate
the annotations that were filled out by people with their handwriting. Our
dataset includes 788 images of handwritten pages produced by approximately 150
different writers. It can be adopted as a basis for various handwriting
classification tasks such as end-to-end document recognition, word-spotting,
word or line segmentation, and so on. We also propose a scheme to segment
Bangla handwritten document images into corresponding lines in an unsupervised
manner. Our line segmentation approach takes care of the variability involved
in different writing styles, accurately segmenting complex handwritten text
lines of curvilinear nature. Along with a bunch of pre-processing and
morphological operations, both Hough line and circle transforms were employed
to distinguish different linear components. In order to arrange those
components into their corresponding lines, we followed an unsupervised
clustering approach. The average success rate of our segmentation technique is
81.57% in terms of FM metrics (similar to F-measure) with a mean Average
Precision (mAP) of 0.547.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Deep Multi-layered Dialectal Language Analysis: A Case Study of African-American English. (arXiv:2206.08978v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08978">
<div class="article-summary-box-inner">
<span><p>Currently, natural language processing (NLP) models proliferate language
discrimination leading to potentially harmful societal impacts as a result of
biased outcomes. For example, part-of-speech taggers trained on Mainstream
American English (MAE) produce non-interpretable results when applied to
African American English (AAE) as a result of language features not seen during
training. In this work, we incorporate a human-in-the-loop paradigm to gain a
better understanding of AAE speakers' behavior and their language use, and
highlight the need for dialectal language inclusivity so that native AAE
speakers can extensively interact with NLP systems while reducing feelings of
disenfranchisement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks. (arXiv:2206.09059v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09059">
<div class="article-summary-box-inner">
<span><p>Current state-of-the-art vision-and-language models are evaluated on tasks
either individually or in a multi-task setting, overlooking the challenges of
continually learning (CL) tasks as they arrive. Existing CL benchmarks have
facilitated research on task adaptation and mitigating "catastrophic
forgetting", but are limited to vision-only and language-only tasks. We present
CLiMB, a benchmark to study the challenge of learning multimodal tasks in a CL
setting, and to systematically evaluate how upstream continual learning can
rapidly generalize to new multimodal and unimodal tasks. CLiMB includes
implementations of several CL algorithms and a modified Vision-Language
Transformer (ViLT) model that can be deployed on both multimodal and unimodal
tasks. We find that common CL methods can help mitigate forgetting during
multimodal task learning, but do not enable cross-task knowledge transfer. We
envision that CLiMB will facilitate research on a new class of CL algorithms
for this challenging multimodal setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Making the Most of BERT in Neural Machine Translation. (arXiv:1908.05672v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.05672">
<div class="article-summary-box-inner">
<span><p>GPT-2 and BERT demonstrate the effectiveness of using pre-trained language
models (LMs) on various natural language processing tasks. However, LM
fine-tuning often suffers from catastrophic forgetting when applied to
resource-rich tasks. In this work, we introduce a concerted training framework
(CTNMT) that is the key to integrate the pre-trained LMs to neural machine
translation (NMT). Our proposed CTNMT consists of three techniques: a)
asymptotic distillation to ensure that the NMT model can retain the previous
pre-trained knowledge; b) a dynamic switching gate to avoid catastrophic
forgetting of pre-trained knowledge; and c) a strategy to adjust the learning
paces according to a scheduled policy. Our experiments in machine translation
show CTNMT gains of up to 3 BLEU score on the WMT14 English-German language
pair which even surpasses the previous state-of-the-art pre-training aided NMT
by 1.4 BLEU score. While for the large WMT14 English-French task with 40
millions of sentence-pairs, our base model still significantly improves upon
the state-of-the-art Transformer big model by more than 1 BLEU score. The code
and model can be downloaded from https://github.com/bytedance/neurst/
tree/master/examples/ctnmt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Higher Criticism for Discriminating Word-Frequency Tables and Testing Authorship. (arXiv:1911.01208v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.01208">
<div class="article-summary-box-inner">
<span><p>We adapt the Higher Criticism (HC) goodness-of-fit test to measure the
closeness between word-frequency tables. We apply this measure to authorship
attribution challenges, where the goal is to identify the author of a document
using other documents whose authorship is known. The method is simple yet
performs well without handcrafting and tuning; reporting accuracy at the state
of the art level in various current challenges. As an inherent side effect, the
HC calculation identifies a subset of discriminating words. In practice, the
identified words have low variance across documents belonging to a corpus of
homogeneous authorship. We conclude that in comparing the similarity of a new
document and a corpus of a single author, HC is mostly affected by words
characteristic of the author and is relatively unaffected by topic structure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recipes for Adapting Pre-trained Monolingual and Multilingual Models to Machine Translation. (arXiv:2004.14911v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.14911">
<div class="article-summary-box-inner">
<span><p>There has been recent success in pre-training on monolingual data and
fine-tuning on Machine Translation (MT), but it remains unclear how to best
leverage a pre-trained model for a given MT task. This paper investigates the
benefits and drawbacks of freezing parameters, and adding new ones, when
fine-tuning a pre-trained model on MT. We focus on 1) Fine-tuning a model
trained only on English monolingual data, BART. 2) Fine-tuning a model trained
on monolingual data from 25 languages, mBART. For BART we get the best
performance by freezing most of the model parameters, and adding extra
positional embeddings. For mBART we match or outperform the performance of
naive fine-tuning for most language pairs with the encoder, and most of the
decoder, frozen. The encoder-decoder attention parameters are most important to
fine-tune. When constraining ourselves to an out-of-domain training set for
Vietnamese to English we see the largest improvements over the fine-tuning
baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parsing with Multilingual BERT, a Small Corpus, and a Small Treebank. (arXiv:2009.14124v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14124">
<div class="article-summary-box-inner">
<span><p>Pretrained multilingual contextual representations have shown great success,
but due to the limits of their pretraining data, their benefits do not apply
equally to all language varieties. This presents a challenge for language
varieties unfamiliar to these models, whose labeled \emph{and unlabeled} data
is too limited to train a monolingual model effectively. We propose the use of
additional language-specific pretraining and vocabulary augmentation to adapt
multilingual models to low-resource settings. Using dependency parsing of four
diverse low-resource language varieties as a case study, we show that these
methods significantly improve performance over baselines, especially in the
lowest-resource cases, and demonstrate the importance of the relationship
between such models' pretraining data and target language varieties.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Style Transfer: A Review and Experimental Evaluation. (arXiv:2010.12742v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12742">
<div class="article-summary-box-inner">
<span><p>The stylistic properties of text have intrigued computational linguistics
researchers in recent years. Specifically, researchers have investigated the
Text Style Transfer (TST) task, which aims to change the stylistic properties
of the text while retaining its style independent content. Over the last few
years, many novel TST algorithms have been developed, while the industry has
leveraged these algorithms to enable exciting TST applications. The field of
TST research has burgeoned because of this symbiosis. This article aims to
provide a comprehensive review of recent research efforts on text style
transfer. More concretely, we create a taxonomy to organize the TST models and
provide a comprehensive summary of the state of the art. We review the existing
evaluation methodologies for TST tasks and conduct a large-scale
reproducibility study where we experimentally benchmark 19 state-of-the-art TST
algorithms on two publicly available datasets. Finally, we expand on current
trends and provide new perspectives on the new and exciting developments in the
TST field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FGNET-RH: Fine-Grained Named Entity Typing via Refinement in Hyperbolic Space. (arXiv:2101.11212v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11212">
<div class="article-summary-box-inner">
<span><p>Fine-Grained Named Entity Typing (FG-NET) aims at classifying the entity
mentions into a wide range of entity types (usually hundreds) depending upon
the context. While distant supervision is the most common way to acquire
supervised training data, it brings in label noise, as it assigns type labels
to the entity mentions irrespective of mentions context. In attempts to deal
with the label noise, leading research on the FG-NET assumes that the
fine-grained entity typing data possesses a euclidean nature, which restraints
the ability of the existing models in combating the label noise. Given the fact
that the fine-grained type hierarchy exhibits a hierarchical structure, it
makes hyperbolic space a natural choice to model the FG-NET data. In this
research, we propose FGNET-RH, a novel framework that benefits from the
hyperbolic geometry in combination with the graph structures to perform entity
typing in a performance-enhanced fashion. FGNET-RH initially uses LSTM networks
to encode the mention in relation with its context, later it forms a graph to
distill/refine the mention encodings in the hyperbolic space. Finally, the
refined mention encoding is used for entity typing. Experimentation using
different benchmark datasets shows that FGNET-RH improves the performance on
FG-NET by up to 3.5-% in terms of strict accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Specializing Multilingual Language Models: An Empirical Study. (arXiv:2106.09063v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09063">
<div class="article-summary-box-inner">
<span><p>Pretrained multilingual language models have become a common tool in
transferring NLP capabilities to low-resource languages, often with
adaptations. In this work, we study the performance, extensibility, and
interaction of two such adaptations: vocabulary augmentation and script
transliteration. Our evaluations on part-of-speech tagging, universal
dependency parsing, and named entity recognition in nine diverse low-resource
languages uphold the viability of these approaches while raising new questions
around how to optimally adapt multilingual models to low-resource settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Similarity of Sentence Representations in Multilingual LMs: Resolving Conflicting Literature and Case Study of Baltic Languages. (arXiv:2109.01207v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01207">
<div class="article-summary-box-inner">
<span><p>Low-resource languages, such as Baltic languages, benefit from Large
Multilingual Models (LMs) that possess remarkable cross-lingual transfer
performance capabilities. This work is an interpretation and analysis study
into cross-lingual representations of Multilingual LMs. Previous works
hypothesized that these LMs internally project representations of different
languages into a shared cross-lingual space. However, the literature produced
contradictory results. In this paper, we revisit the prior work claiming that
"BERT is not an Interlingua" and show that different languages do converge to a
shared space in such language models with another choice of pooling strategy or
similarity index. Then, we perform cross-lingual representational analysis for
the two most popular multilingual LMs employing 378 pairwise language
comparisons. We discover that while most languages share joint cross-lingual
space, some do not. However, we observe that Baltic languages do belong to that
shared space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Retriever-Ranker for dense text retrieval. (arXiv:2110.03611v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03611">
<div class="article-summary-box-inner">
<span><p>Current dense text retrieval models face two typical challenges. First, they
adopt a siamese dual-encoder architecture to encode queries and documents
independently for fast indexing and searching, while neglecting the
finer-grained term-wise interactions. This results in a sub-optimal recall
performance. Second, their model training highly relies on a negative sampling
technique to build up the negative documents in their contrastive losses. To
address these challenges, we present Adversarial Retriever-Ranker (AR2), which
consists of a dual-encoder retriever plus a cross-encoder ranker. The two
models are jointly optimized according to a minimax adversarial objective: the
retriever learns to retrieve negative documents to cheat the ranker, while the
ranker learns to rank a collection of candidates including both the
ground-truth and the retrieved ones, as well as providing progressive direct
feedback to the dual-encoder retriever. Through this adversarial game, the
retriever gradually produces harder negative documents to train a better
ranker, whereas the cross-encoder ranker provides progressive feedback to
improve retriever. We evaluate AR2 on three benchmarks. Experimental results
show that AR2 consistently and significantly outperforms existing dense
retriever methods and achieves new state-of-the-art results on all of them.
This includes the improvements on Natural Questions R@5 to 77.9%(+2.1%),
TriviaQA R@5 to 78.2%(+1.4), and MS-MARCO MRR@10 to 39.5%(+1.3%). Code and
models are available at https://github.com/microsoft/AR2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Voice Conversion Can Improve ASR in Very Low-Resource Settings. (arXiv:2111.02674v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02674">
<div class="article-summary-box-inner">
<span><p>Voice conversion (VC) could be used to improve speech recognition systems in
low-resource languages by using it to augment limited training data. However,
VC has not been widely used for this purpose because of practical issues such
as compute speed and limitations when converting to and from unseen speakers.
Moreover, it is still unclear whether a VC model trained on one well-resourced
language can be applied to speech from another low-resource language for the
aim of data augmentation. In this work we assess whether a VC system can be
used cross-lingually to improve low-resource speech recognition. We combine
several recent techniques to design and train a practical VC system in English,
and then use this system to augment data for training speech recognition models
in several low-resource languages. When using a sensible amount of VC augmented
data, speech recognition performance is improved in all four low-resource
languages considered. We also show that VC-based augmentation is superior to
SpecAugment (a widely used signal processing augmentation method) in the
low-resource languages considered.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-TTS: Meta-Learning for Few-Shot Speaker Adaptive Text-to-Speech. (arXiv:2111.04040v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.04040">
<div class="article-summary-box-inner">
<span><p>Personalizing a speech synthesis system is a highly desired application,
where the system can generate speech with the user's voice with rare enrolled
recordings. There are two main approaches to build such a system in recent
works: speaker adaptation and speaker encoding. On the one hand, speaker
adaptation methods fine-tune a trained multi-speaker text-to-speech (TTS) model
with few enrolled samples. However, they require at least thousands of
fine-tuning steps for high-quality adaptation, making it hard to apply on
devices. On the other hand, speaker encoding methods encode enrollment
utterances into a speaker embedding. The trained TTS model can synthesize the
user's speech conditioned on the corresponding speaker embedding. Nevertheless,
the speaker encoder suffers from the generalization gap between the seen and
unseen speakers.
</p>
<p>In this paper, we propose applying a meta-learning algorithm to the speaker
adaptation method. More specifically, we use Model Agnostic Meta-Learning
(MAML) as the training algorithm of a multi-speaker TTS model, which aims to
find a great meta-initialization to adapt the model to any few-shot speaker
adaptation tasks quickly. Therefore, we can also adapt the meta-trained TTS
model to unseen speakers efficiently. Our experiments compare the proposed
method (Meta-TTS) with two baselines: a speaker adaptation method baseline and
a speaker encoding method baseline. The evaluation results show that Meta-TTS
can synthesize high speaker-similarity speech from few enrollment samples with
fewer adaptation steps than the speaker adaptation baseline and outperforms the
speaker encoding baseline under the same training scheme. When the speaker
encoder of the baseline is pre-trained with extra 8371 speakers of data,
Meta-TTS can still outperform the baseline on LibriTTS dataset and achieve
comparable results on VCTK dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlling Conditional Language Models without Catastrophic Forgetting. (arXiv:2112.00791v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00791">
<div class="article-summary-box-inner">
<span><p>Machine learning is shifting towards general-purpose pretrained generative
models, trained in a self-supervised manner on large amounts of data, which can
then be applied to solve a large number of tasks. However, due to their generic
training methodology, these models often fail to meet some of the downstream
requirements (e.g., hallucinations in abstractive summarization or style
violations in code generation). This raises the important question of how to
adapt pre-trained generative models to meet all requirements without destroying
their general capabilities ("catastrophic forgetting"). Recent work has
proposed to solve this problem by representing task-specific requirements
through energy-based models (EBMs) and approximating these EBMs using
distributional policy gradients (DPG). Despite its effectiveness, this approach
is however limited to unconditional distributions. In this paper, we extend DPG
to conditional tasks by proposing Conditional DPG (CDPG). We evaluate CDPG on
four different control objectives across three tasks (translation,
summarization and code generation) and two pretrained models (T5 and GPT-Neo).
Our results show that fine-tuning using CDPG robustly moves these pretrained
models closer towards meeting control objectives and -- in contrast with
baseline approaches -- does not result in catastrophic forgetting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CRASS: A Novel Data Set and Benchmark to Test Counterfactual Reasoning of Large Language Models. (arXiv:2112.11941v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11941">
<div class="article-summary-box-inner">
<span><p>We introduce the CRASS (counterfactual reasoning assessment) data set and
benchmark utilizing questionized counterfactual conditionals as a novel and
powerful tool to evaluate large language models. We present the data set design
and benchmark that supports scoring against a crowd-validated human baseline.
We test six state-of-the-art models against our benchmark. Our results show
that it poses a valid challenge for these models and opens up considerable room
for their improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making sense of electrical vehicle discussions using sentiment analysis on closely related news and user comments. (arXiv:2112.12327v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12327">
<div class="article-summary-box-inner">
<span><p>We used a token-wise and document-wise sentiment analysis using both
unsupervised and supervised models applied to both news and user reviews
dataset. And our token-wise sentiment analysis found a statistically
significant difference in sentiment between the two groups (both of which were
very large N), our document-wise supervised sentiment analysis found no
significant difference in sentiment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TiltedBERT: Resource Adjustable Version of BERT. (arXiv:2201.03327v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03327">
<div class="article-summary-box-inner">
<span><p>In this paper, a novel adjustable fine-tuning method is proposed that
improves the inference time of BERT model on downstream tasks. The proposed
method detects the more important word vectors in each layer by the proposed
Attention Context Contribution (ACC) metric and eliminates the less important
word vectors by the proposed strategy. In the TiltedBERT method the model
learns to work with a considerably lower number of Floating Point Operations
(FLOPs) than the original BERTbase model. The proposed method does not need
training from scratch, and it can be generalized to other transformer-based
models. The extensive experiments show that the word vectors in higher layers
have less contribution that can be eliminated and improve the inference time.
Experimental results on extensive sentiment analysis, classification and
regression datasets, and benchmarks like IMDB and GLUE showed that TiltedBERT
is effective in various datasets. TiltedBERT improves the inference time of
BERTbase up to 4.8 times with less than 0.75% accuracy drop on average. After
the fine-tuning by the offline-tuning property, the inference time of the model
can be adjusted for a wide range of Tilt-Rate selections. Also, A mathematical
speedup analysis is proposed to estimate TiltedBERT method's speedup
accurately. With the help of this analysis, a proper Tilt-Rate value can be
selected before fine-tuning and during offline-tuning phases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TYPIC: A Corpus of Template-Based Diagnostic Comments on Argumentation. (arXiv:2201.06674v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.06674">
<div class="article-summary-box-inner">
<span><p>Providing feedback on the argumentation of the learner is essential for
developing critical thinking skills, however, it requires a lot of time and
effort. To mitigate the overload on teachers, we aim to automate a process of
providing feedback, especially giving diagnostic comments which point out the
weaknesses inherent in the argumentation. It is recommended to give specific
diagnostic comments so that learners can recognize the diagnosis without
misinterpretation. However, it is not obvious how the task of providing
specific diagnostic comments should be formulated. We present a formulation of
the task as template selection and slot filling to make an automatic evaluation
easier and the behavior of the model more tractable. The key to the formulation
is the possibility of creating a template set that is sufficient for practical
use. In this paper, we define three criteria that a template set should
satisfy: expressiveness, informativeness, and uniqueness, and verify the
feasibility of creating a template set that satisfies these criteria as a first
trial. We will show that it is feasible through an annotation study that
converts diagnostic comments given in a text to a template format. The corpus
used in the annotation study is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis. (arXiv:2201.08277v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08277">
<div class="article-summary-box-inner">
<span><p>Sentiment analysis is one of the most widely studied applications in NLP, but
most work focuses on languages with large amounts of data. We introduce the
first large-scale human-annotated Twitter sentiment dataset for the four most
widely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and
Yor\`ub\'a ) consisting of around 30,000 annotated tweets per language (and
14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed
tweets. We propose text collection, filtering, processing and labeling methods
that enable us to create datasets for these low-resource languages. We evaluate
a rangeof pre-trained models and transfer strategies on the dataset. We find
that language-specific models and language-adaptivefine-tuning generally
perform best. We release the datasets, trained models, sentiment lexicons, and
code to incentivizeresearch on sentiment analysis in under-represented
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bias in Automated Speaker Recognition. (arXiv:2201.09486v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09486">
<div class="article-summary-box-inner">
<span><p>Automated speaker recognition uses data processing to identify speakers by
their voice. Today, automated speaker recognition is deployed on billions of
smart devices and in services such as call centres. Despite their wide-scale
deployment and known sources of bias in related domains like face recognition
and natural language processing, bias in automated speaker recognition has not
been studied systematically. We present an in-depth empirical and analytical
study of bias in the machine learning development workflow of speaker
verification, a voice biometric and core task in automated speaker recognition.
Drawing on an established framework for understanding sources of harm in
machine learning, we show that bias exists at every development stage in the
well-known VoxCeleb Speaker Recognition Challenge, including data generation,
model building, and implementation. Most affected are female speakers and
non-US nationalities, who experience significant performance degradation.
Leveraging the insights from our findings, we make practical recommendations
for mitigating bias in automated speaker recognition, and outline future
research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linear Adversarial Concept Erasure. (arXiv:2201.12091v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12091">
<div class="article-summary-box-inner">
<span><p>Modern neural models trained on textual data rely on pre-trained
representations that emerge without direct supervision. As these
representations are increasingly being used in real-world applications, the
inability to \emph{control} their content becomes an increasingly important
problem.
</p>
<p>We formulate the problem of identifying and erasing a linear subspace that
corresponds to a given concept, in order to prevent linear predictors from
recovering the concept. We model this problem as a constrained, linear minimax
game, and show that existing solutions are generally not optimal for this task.
We derive a closed-form solution for certain objectives, and propose a convex
relaxation, R-LACE, that works well for others. When evaluated in the context
of binary gender removal, the method recovers a low-dimensional subspace whose
removal mitigates bias by intrinsic and extrinsic evaluation. We show that the
method -- despite being linear -- is highly expressive, effectively mitigating
bias in deep nonlinear classifiers while maintaining tractability and
interpretability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuraHealth: An Automated Screening Pipeline to Detect Undiagnosed Cognitive Impairment in Electronic Health Records with Deep Learning and Natural Language Processing. (arXiv:2202.00478v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00478">
<div class="article-summary-box-inner">
<span><p>Dementia related cognitive impairment (CI) is a neurodegenerative disorder,
affecting over 55 million people worldwide and growing rapidly at the rate of
one new case every 3 seconds. 75% cases go undiagnosed globally with up to 90%
in low-and-middle-income countries, leading to an estimated annual worldwide
cost of USD 1.3 trillion, forecasted to reach 2.8 trillion by 2030. With no
cure, a recurring failure of clinical trials, and a lack of early diagnosis,
the mortality rate is 100%. Information in electronic health records (EHR) can
provide vital clues for early detection of CI, but a manual review by experts
is tedious and error prone. Several computational methods have been proposed,
however, they lack an enhanced understanding of the linguistic context in
complex language structures of EHR. Therefore, I propose a novel and more
accurate framework, NeuraHealth, to identify patients who had no earlier
diagnosis. In NeuraHealth, using patient EHR from Mass General Brigham BioBank,
I fine-tuned a bi-directional attention-based deep learning natural language
processing model to classify sequences. The sequence predictions were used to
generate structured features as input for a patient level regularized logistic
regression model. This two-step framework creates high dimensionality,
outperforming all existing state-of-the-art computational methods as well as
clinical methods. Further, I integrate the models into a real-world product, a
web app, to create an automated EHR screening pipeline for scalable and
high-speed discovery of undetected CI in EHR, making early diagnosis viable in
medical facilities and in regions with scarce health services.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VLP: A Survey on Vision-Language Pre-training. (arXiv:2202.09061v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09061">
<div class="article-summary-box-inner">
<span><p>In the past few years, the emergence of pre-training models has brought
uni-modal fields such as computer vision (CV) and natural language processing
(NLP) to a new era. Substantial works have shown they are beneficial for
downstream uni-modal tasks and avoid training a new model from scratch. So can
such pre-trained models be applied to multi-modal tasks? Researchers have
explored this problem and made significant progress. This paper surveys recent
advances and new frontiers in vision-language pre-training (VLP), including
image-text and video-text pre-training. To give readers a better overall grasp
of VLP, we first review its recent advances from five aspects: feature
extraction, model architecture, pre-training objectives, pre-training datasets,
and downstream tasks. Then, we summarize the specific VLP models in detail.
Finally, we discuss the new frontiers in VLP. To the best of our knowledge,
this is the first survey on VLP. We hope that this survey can shed light on
future research in the VLP field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Base Question Answering by Case-based Reasoning over Subgraphs. (arXiv:2202.10610v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10610">
<div class="article-summary-box-inner">
<span><p>Question answering (QA) over knowledge bases (KBs) is challenging because of
the diverse, essentially unbounded, types of reasoning patterns needed.
However, we hypothesize in a large KB, reasoning patterns required to answer a
query type reoccur for various entities in their respective subgraph
neighborhoods. Leveraging this structural similarity between local
neighborhoods of different subgraphs, we introduce a semiparametric model
(CBR-SUBG) with (i) a nonparametric component that for each query, dynamically
retrieves other similar $k$-nearest neighbor (KNN) training queries along with
query-specific subgraphs and (ii) a parametric component that is trained to
identify the (latent) reasoning patterns from the subgraphs of KNN queries and
then apply them to the subgraph of the target query. We also propose an
adaptive subgraph collection strategy to select a query-specific compact
subgraph, allowing us to scale to full Freebase KB containing billions of
facts. We show that CBR-SUBG can answer queries requiring subgraph reasoning
patterns and performs competitively with the best models on several KBQA
benchmarks. Our subgraph collection strategy also produces more compact
subgraphs (e.g. 55\% reduction in size for WebQSP while increasing answer
recall by 4.85\%)\footnote{Code, model, and subgraphs are available at
\url{https://github.com/rajarshd/CBR-SUBG}}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DUAL: Discrete Spoken Unit Adaptive Learning for Textless Spoken Question Answering. (arXiv:2203.04911v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.04911">
<div class="article-summary-box-inner">
<span><p>Spoken Question Answering (SQA) is to find the answer from a spoken document
given a question, which is crucial for personal assistants when replying to the
queries from the users. Existing SQA methods all rely on Automatic Speech
Recognition (ASR) transcripts. Not only does ASR need to be trained with
massive annotated data that are time and cost-prohibitive to collect for
low-resourced languages, but more importantly, very often the answers to the
questions include name entities or out-of-vocabulary words that cannot be
recognized correctly. Also, ASR aims to minimize recognition errors equally
over all words, including many function words irrelevant to the SQA task.
Therefore, SQA without ASR transcripts (textless) is always highly desired,
although known to be very difficult.
</p>
<p>This work proposes Discrete Spoken Unit Adaptive Learning (DUAL), leveraging
unlabeled data for pre-training and fine-tuned by the SQA downstream task. The
time intervals of spoken answers can be directly predicted from spoken
documents. We also release a new SQA benchmark corpus, NMSQA, for data with
more realistic scenarios. We empirically showed that DUAL yields results
comparable to those obtained by cascading ASR and text QA model and robust to
real-world data. Our code and model will be open-sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A$^3$T: Alignment-Aware Acoustic and Text Pretraining for Speech Synthesis and Editing. (arXiv:2203.09690v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09690">
<div class="article-summary-box-inner">
<span><p>Recently, speech representation learning has improved many speech-related
tasks such as speech recognition, speech classification, and speech-to-text
translation. However, all the above tasks are in the direction of speech
understanding, but for the inverse direction, speech synthesis, the potential
of representation learning is yet to be realized, due to the challenging nature
of generating high-quality speech. To address this problem, we propose our
framework, Alignment-Aware Acoustic-Text Pretraining (A$^3$T), which
reconstructs masked acoustic signals with text input and acoustic-text
alignment during training. In this way, the pretrained model can generate high
quality reconstructed spectrogram, which can be applied to the speech editing
and unseen speaker TTS directly. Experiments show A$^3$T outperforms SOTA
models on speech editing, and improves multi-speaker speech synthesis without
the external speaker verification model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Listen, Adapt, Better WER: Source-free Single-utterance Test-time Adaptation for Automatic Speech Recognition. (arXiv:2203.14222v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.14222">
<div class="article-summary-box-inner">
<span><p>Although deep learning-based end-to-end Automatic Speech Recognition (ASR)
has shown remarkable performance in recent years, it suffers severe performance
regression on test samples drawn from different data distributions. Test-time
Adaptation (TTA), previously explored in the computer vision area, aims to
adapt the model trained on source domains to yield better predictions for test
samples, often out-of-domain, without accessing the source data. Here, we
propose the Single-Utterance Test-time Adaptation (SUTA) framework for ASR,
which is the first TTA study on ASR to our best knowledge. The single-utterance
TTA is a more realistic setting that does not assume test data are sampled from
identical distribution and does not delay on-demand inference due to
pre-collection for the batch of adaptation data. SUTA consists of unsupervised
objectives with an efficient adaptation strategy. Empirical results demonstrate
that SUTA effectively improves the performance of the source ASR model
evaluated on multiple out-of-domain target corpora and in-domain test samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LightHuBERT: Lightweight and Configurable Speech Representation Learning with Once-for-All Hidden-Unit BERT. (arXiv:2203.15610v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.15610">
<div class="article-summary-box-inner">
<span><p>Self-supervised speech representation learning has shown promising results in
various speech processing tasks. However, the pre-trained models, e.g., HuBERT,
are storage-intensive Transformers, limiting their scope of applications under
low-resource settings. To this end, we propose LightHuBERT, a once-for-all
Transformer compression framework, to find the desired architectures
automatically by pruning structured parameters. More precisely, we create a
Transformer-based supernet that is nested with thousands of weight-sharing
subnets and design a two-stage distillation strategy to leverage the
contextualized latent representations from HuBERT. Experiments on automatic
speech recognition (ASR) and the SUPERB benchmark show the proposed LightHuBERT
enables over $10^9$ architectures concerning the embedding dimension, attention
dimension, head number, feed-forward network ratio, and network depth.
LightHuBERT outperforms the original HuBERT on ASR and five SUPERB tasks with
the HuBERT size, achieves comparable performance to the teacher model in most
tasks with a reduction of 29% parameters, and obtains a $3.5\times$ compression
ratio in three SUPERB tasks, e.g., automatic speaker verification, keyword
spotting, and intent classification, with a slight accuracy loss. The code and
pre-trained models are available at
https://github.com/mechanicalsea/lighthubert.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling the Impacts of Language and Channel Variability on Speech Separation Networks. (arXiv:2203.16040v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16040">
<div class="article-summary-box-inner">
<span><p>Because the performance of speech separation is excellent for speech in which
two speakers completely overlap, research attention has been shifted to dealing
with more realistic scenarios. However, domain mismatch between training/test
situations due to factors, such as speaker, content, channel, and environment,
remains a severe problem for speech separation. Speaker and environment
mismatches have been studied in the existing literature. Nevertheless, there
are few studies on speech content and channel mismatches. Moreover, the impacts
of language and channel in these studies are mostly tangled. In this study, we
create several datasets for various experiments. The results show that the
impacts of different languages are small enough to be ignored compared to the
impacts of different channels. In our experiments, training on data recorded by
Android phones leads to the best generalizability. Moreover, we provide a new
solution for channel mismatch by evaluating projection, where the channel
similarity can be measured and used to effectively select additional training
data to improve the performance of in-the-wild test data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distributed Transition Systems with Tags for Privacy Analysis. (arXiv:2204.02602v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02602">
<div class="article-summary-box-inner">
<span><p>We present a logical framework that formally models how a given private
information P stored on a given database D, can get captured progressively, by
an agent/adversary querying the database repeatedly. Named DLTTS (Distributed
Labeled Tagged Transition System), the framework borrows ideas from several
domains: Probabilistic Automata of Segala, Probabilistic Concurrent Systems,
and Probabilistic labelled transition systems. To every node on a DLTTS is
attached a tag that represents the 'current' knowledge of the adversary,
acquired from the responses of the answering mechanism of the DBMS to his/her
queries, at the nodes traversed earlier, along any given run; this knowledge is
completed at the same node, with further relational deductions, possibly in
combination with 'public' information from other databases given in advance. A
'blackbox' mechanism is also part of a DLTTS, and it is meant as an oracle; its
role is to tell if the private information has been deduced by the adversary at
the current node, and if so terminate the run. An additional special feature is
that the blackbox also gives information on how 'close', or how 'far', the
knowledge of the adversary is, from the private information P , at the current
node. A metric is defined for that purpose, on the set of all 'type compatible'
tuples from the given database, the data themselves being typed with the
headers of the base. Despite the transition systems flavor of our framework,
this metric is not 'behavioral' in the sense presented in some other works. It
is exclusively database oriented, and allows to define new notions of adjacency
and of indistinguishabilty between databases, more generally than those usually
based on the Hamming metric (and a restricted notion of adjacency). Examples
are given all along to illustrate how our framework works.
</p>
<p>Keywords:Database, Privacy, Transition System, Probability, Distribution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BioRED: A Rich Biomedical Relation Extraction Dataset. (arXiv:2204.04263v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04263">
<div class="article-summary-box-inner">
<span><p>Automated relation extraction (RE) from biomedical literature is critical for
many downstream text mining applications in both research and real-world
settings. However, most existing benchmarking datasets for bio-medical RE only
focus on relations of a single type (e.g., protein-protein interactions) at the
sentence level, greatly limiting the development of RE systems in biomedicine.
In this work, we first review commonly used named entity recognition (NER) and
RE datasets. Then we present BioRED, a first-of-its-kind biomedical RE corpus
with multiple entity types (e.g., gene/protein, disease, chemical) and relation
pairs (e.g., gene-disease; chemical-chemical) at the document level, on a set
of 600 PubMed abstracts. Further, we label each relation as describing either a
novel finding or previously known background knowledge, enabling automated
algorithms to differentiate between novel and background information. We assess
the utility of BioRED by benchmarking several existing state-of-the-art
methods, including BERT-based models, on the NER and RE tasks. Our results show
that while existing approaches can reach high performance on the NER task
(F-score of 89.3%), there is much room for improvement for the RE task,
especially when extracting novel relations (F-score of 47.7%). Our experiments
also demonstrate that such a rich dataset can successfully facilitate the
development of more accurate, efficient, and robust RE systems for biomedicine.
The BioRED dataset and annotation guideline are freely available at
https://ftp.ncbi.nlm.nih.gov/pub/lu/BioRED/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models. (arXiv:2204.08790v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08790">
<div class="article-summary-box-inner">
<span><p>Learning visual representations from natural language supervision has
recently shown great promise in a number of pioneering works. In general, these
language-augmented visual models demonstrate strong transferability to a
variety of datasets and tasks. However, it remains challenging to evaluate the
transferablity of these models due to the lack of easy-to-use evaluation
toolkits and public benchmarks. To tackle this, we build ELEVATER (Evaluation
of Language-augmented Visual Task-level Transfer), the first benchmark and
toolkit for evaluating(pre-trained) language-augmented visual models. ELEVATER
is composed of three components. (i) Datasets. As downstream evaluation suites,
it consists of 20 image classification datasets and 35 object detection
datasets, each of which is augmented with external knowledge. (ii) Toolkit. An
automatic hyper-parameter tuning toolkit is developed to facilitate model
evaluation on downstream tasks. (iii) Metrics. A variety of evaluation metrics
are used to measure sample-efficiency (zero-shot and few-shot) and
parameter-efficiency (linear probing and full model fine-tuning). We publicly
release ELEVATER at https://computer-vision-in-the-wild.github.io/ELEVATER/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OPT: Open Pre-trained Transformer Language Models. (arXiv:2205.01068v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01068">
<div class="article-summary-box-inner">
<span><p>Large language models, which are often trained for hundreds of thousands of
compute days, have shown remarkable capabilities for zero- and few-shot
learning. Given their computational cost, these models are difficult to
replicate without significant capital. For the few that are available through
APIs, no access is granted to the full model weights, making them difficult to
study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only
pre-trained transformers ranging from 125M to 175B parameters, which we aim to
fully and responsibly share with interested researchers. We show that OPT-175B
is comparable to GPT-3, while requiring only 1/7th the carbon footprint to
develop. We are also releasing our logbook detailing the infrastructure
challenges we faced, along with code for experimenting with all of the released
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterizing Multi-Domain False News and Underlying User Effects on Chinese Weibo. (arXiv:2205.03068v2 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03068">
<div class="article-summary-box-inner">
<span><p>False news that spreads on social media has proliferated over the past years
and has led to multi-aspect threats in the real world. While there are studies
of false news on specific domains (like politics or health care), little work
is found comparing false news across domains. In this article, we investigate
false news across nine domains on Weibo, the largest Twitter-like social media
platform in China, from 2009 to 2019. The newly collected data comprise 44,728
posts in the nine domains, published by 40,215 users, and reposted over 3.4
million times. Based on the distributions and spreads of the multi-domain
dataset, we observe that false news in domains that are close to daily life
like health and medicine generated more posts but diffused less effectively
than those in other domains like politics, and that political false news had
the most effective capacity for diffusion. The widely diffused false news posts
on Weibo were associated strongly with certain types of users -- by gender,
age, etc. Further, these posts provoked strong emotions in the reposts and
diffused further with the active engagement of false-news starters. Our
findings have the potential to help design false news detection systems in
suspicious news discovery, veracity prediction, and display and explanation.
The comparison of the findings on Weibo with those of existing work
demonstrates nuanced patterns, suggesting the need for more research on data
from diverse platforms, countries, or languages to tackle the global issue of
false news. The code and new anonymized dataset are available at
https://github.com/ICTMCG/Characterizing-Weibo-Multi-Domain-False-News.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangled Learning of Stance and Aspect Topics for Vaccine Attitude Detection in Social Media. (arXiv:2205.03296v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03296">
<div class="article-summary-box-inner">
<span><p>Building models to detect vaccine attitudes on social media is challenging
because of the composite, often intricate aspects involved, and the limited
availability of annotated data. Existing approaches have relied heavily on
supervised training that requires abundant annotations and pre-defined aspect
categories. Instead, with the aim of leveraging the large amount of unannotated
data now available on vaccination, we propose a novel semi-supervised approach
for vaccine attitude detection, called VADet. A variational autoencoding
architecture based on language models is employed to learn from unlabelled data
the topical information of the domain. Then, the model is fine-tuned with a few
manually annotated examples of user attitudes. We validate the effectiveness of
VADet on our annotated data and also on an existing vaccination corpus
annotated with opinions on vaccines. Our results show that VADet is able to
learn disentangled stance and aspect topics, and outperforms existing
aspect-based sentiment analysis models on both stance detection and tweet
clustering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniMorph 4.0: Universal Morphology. (arXiv:2205.03608v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03608">
<div class="article-summary-box-inner">
<span><p>The Universal Morphology (UniMorph) project is a collaborative effort
providing broad-coverage instantiated normalized morphological inflection
tables for hundreds of diverse world languages. The project comprises two major
thrusts: a language-independent feature schema for rich morphological
annotation and a type-level resource of annotated data in diverse languages
realizing that schema. This paper presents the expansions and improvements made
on several fronts over the last couple of years (since McCarthy et al. (2020)).
Collaborative efforts by numerous linguists have added 67 new languages,
including 30 endangered languages. We have implemented several improvements to
the extraction pipeline to tackle some issues, e.g. missing gender and macron
information. We have also amended the schema to use a hierarchical structure
that is needed for morphological phenomena like multiple-argument agreement and
case stacking, while adding some missing morphological features to make the
schema more inclusive. In light of the last UniMorph release, we also augmented
the database with morpheme segmentation for 16 languages. Lastly, this new
release makes a push towards inclusion of derivational morphology in UniMorph
by enriching the data and annotation schema with instances representing
derivational processes from MorphyNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Improved Zero-shot Voice Conversion with Conditional DSVAE. (arXiv:2205.05227v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05227">
<div class="article-summary-box-inner">
<span><p>Disentangling content and speaking style information is essential for
zero-shot non-parallel voice conversion (VC). Our previous study investigated a
novel framework with disentangled sequential variational autoencoder (DSVAE) as
the backbone for information decomposition. We have demonstrated that
simultaneous disentangling content embedding and speaker embedding from one
utterance is feasible for zero-shot VC. In this study, we continue the
direction by raising one concern about the prior distribution of content branch
in the DSVAE baseline. We find the random initialized prior distribution will
force the content embedding to reduce the phonetic-structure information during
the learning process, which is not a desired property. Here, we seek to achieve
a better content embedding with more phonetic information preserved. We propose
conditional DSVAE, a new model that enables content bias as a condition to the
prior modeling and reshapes the content embedding sampled from the posterior
distribution. In our experiment on the VCTK dataset, we demonstrate that
content embeddings derived from the conditional DSVAE overcome the randomness
and achieve a much better phoneme classification accuracy, a stabilized
vocalization and a better zero-shot VC performance compared with the
competitive DSVAE baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Zero-shot Common Sense from Large Language Models for Robot 3D Scene Understanding. (arXiv:2206.04585v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04585">
<div class="article-summary-box-inner">
<span><p>Semantic 3D scene understanding is a problem of critical importance in
robotics. While significant advances have been made in simultaneous
localization and mapping algorithms, robots are still far from having the
common sense knowledge about household objects and their locations of an
average human. We introduce a novel method for leveraging common sense embedded
within large language models for labelling rooms given the objects contained
within. This algorithm has the added benefits of (i) requiring no task-specific
pre-training (operating entirely in the zero-shot regime) and (ii) generalizing
to arbitrary room and object labels, including previously-unseen ones -- both
of which are highly desirable traits in robotic scene understanding algorithms.
The proposed algorithm operates on 3D scene graphs produced by modern spatial
perception systems, and we hope it will pave the way to more generalizable and
scalable high-level 3D scene understanding for robotics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solution of DeBERTaV3 on CommonsenseQA. (arXiv:2206.05033v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05033">
<div class="article-summary-box-inner">
<span><p>We report the performance of DeBERTaV3 on CommonsenseQA in this report. We
simply formalize the answer selection as a text classification for DeBERTaV3.
The strong natural language inference ability of DeBERTaV3 helps its single and
ensemble model set the new (w/o external knowledge) state-of-the-art on
CommonsenseQA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">REKnow: Enhanced Knowledge for Joint Entity and Relation Extraction. (arXiv:2206.05123v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05123">
<div class="article-summary-box-inner">
<span><p>Relation extraction is an important but challenging task that aims to extract
all hidden relational facts from the text. With the development of deep
language models, relation extraction methods have achieved good performance on
various benchmarks. However, we observe two shortcomings of previous methods:
first, there is no unified framework that works well under various relation
extraction settings; second, effectively utilizing external knowledge as
background information is absent. In this work, we propose a knowledge-enhanced
generative model to mitigate these two issues. Our generative model is a
unified framework to sequentially generate relational triplets under various
relation extraction settings and explicitly utilizes relevant knowledge from
Knowledge Graph (KG) to resolve ambiguities. Our model achieves superior
performance on multiple benchmarks and settings, including WebNLG, NYT10, and
TACRED.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AHD ConvNet for Speech Emotion Classification. (arXiv:2206.05286v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05286">
<div class="article-summary-box-inner">
<span><p>Accomplishments in the field of artificial intelligence are utilized in the
advancement of computing and making of intelligent machines for facilitating
mankind and improving user experience. Emotions are rudimentary for people,
affecting thinking and ordinary exercises like correspondence, learning and
direction. Speech emotion recognition is domain of interest in this regard and
in this work, we propose a novel mel spectrogram learning approach in which our
model uses the datapoints to learn emotions from the given wav form voice notes
in the popular CREMA-D dataset. Our model uses log mel-spectrogram as feature
with number of mels = 64. It took less training time compared to other
approaches used to address the problem of emotion speech recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Over-Generation Cannot Be Rewarded: Length-Adaptive Average Lagging for Simultaneous Speech Translation. (arXiv:2206.05807v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05807">
<div class="article-summary-box-inner">
<span><p>Simultaneous speech translation (SimulST) systems aim at generating their
output with the lowest possible latency, which is normally computed in terms of
Average Lagging (AL). In this paper we highlight that, despite its widespread
adoption, AL provides underestimated scores for systems that generate longer
predictions compared to the corresponding references. We also show that this
problem has practical relevance, as recent SimulST systems have indeed a
tendency to over-generate. As a solution, we propose LAAL (Length-Adaptive
Average Lagging), a modified version of the metric that takes into account the
over-generation phenomenon and allows for unbiased evaluation of both
under-/over-generating systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition. (arXiv:2206.08317v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08317">
<div class="article-summary-box-inner">
<span><p>Transformers have recently dominated the ASR field. Although able to yield
good performance, they involve an autoregressive (AR) decoder to generate
tokens one by one, which is computationally inefficient. To speed up inference,
non-autoregressive (NAR) methods, e.g. single-step NAR, were designed, to
enable parallel generation. However, due to an independence assumption within
the output tokens, performance of single-step NAR is inferior to that of AR
models, especially with a large-scale corpus. There are two challenges to
improving single-step NAR: Firstly to accurately predict the number of output
tokens and extract hidden variables; secondly, to enhance modeling of
interdependence between output tokens. To tackle both challenges, we propose a
fast and accurate parallel transformer, termed Paraformer. This utilizes a
continuous integrate-and-fire based predictor to predict the number of tokens
and generate hidden variables. A glancing language model (GLM) sampler then
generates semantic embeddings to enhance the NAR decoder's ability to model
context interdependence. Finally, we design a strategy to generate negative
samples for minimum word error rate training to further improve performance.
Experiments using the public AISHELL-1, AISHELL-2 benchmark, and an
industrial-level 20,000 hour task demonstrate that the proposed Paraformer can
attain comparable performance to the state-of-the-art AR transformer, with more
than 10x speedup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Hate Intensity of Twitter Conversation Threads. (arXiv:2206.08406v2 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08406">
<div class="article-summary-box-inner">
<span><p>Tweets are the most concise form of communication in online social media,
wherein a single tweet has the potential to make or break the discourse of the
conversation. Online hate speech is more accessible than ever, and stifling its
propagation is of utmost importance for social media companies and users for
congenial communication. Most of the research barring a recent few has focused
on classifying an individual tweet regardless of the tweet thread/context
leading up to that point. One of the classical approaches to curb hate speech
is to adopt a reactive strategy after the hate speech postage. The ex-post
facto strategy results in neglecting subtle posts that do not show the
potential to instigate hate speech on their own but may portend in the
subsequent discussion ensuing in the post's replies. In this paper, we propose
DRAGNET++, which aims to predict the intensity of hatred that a tweet can bring
in through its reply chain in the future. It uses the semantic and propagating
structure of the tweet threads to maximize the contextual information leading
up to and the fall of hate intensity at each subsequent tweet. We explore three
publicly available Twitter datasets -- Anti-Racism contains the reply tweets of
a collection of social media discourse on racist remarks during US political
and Covid-19 background; Anti-Social presents a dataset of 40 million tweets
amidst the COVID-19 pandemic on anti-social behaviours; and Anti-Asian presents
Twitter datasets collated based on anti-Asian behaviours during COVID-19
pandemic. All the curated datasets consist of structural graph information of
the Tweet threads. We show that DRAGNET++ outperforms all the state-of-the-art
baselines significantly. It beats the best baseline by an 11% margin on the
Person correlation coefficient and a decrease of 25% on RMSE for the
Anti-Racism dataset with a similar performance on the other two datasets.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Simultaneous Bone and Shadow Segmentation Network using Task Correspondence Consistency. (arXiv:2206.08936v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08936">
<div class="article-summary-box-inner">
<span><p>Segmenting both bone surface and the corresponding acoustic shadow are
fundamental tasks in ultrasound (US) guided orthopedic procedures. However,
these tasks are challenging due to minimal and blurred bone surface response in
US images, cross-machine discrepancy, imaging artifacts, and low
signal-to-noise ratio. Notably, bone shadows are caused by a significant
acoustic impedance mismatch between the soft tissue and bone surfaces. To
leverage this mutual information between these highly related tasks, we propose
a single end-to-end network with a shared transformer-based encoder and task
independent decoders for simultaneous bone and shadow segmentation. To share
complementary features, we propose a cross task feature transfer block which
learns to transfer meaningful features from decoder of shadow segmentation to
that of bone segmentation and vice-versa. We also introduce a correspondence
consistency loss which makes sure that network utilizes the inter-dependency
between the bone surface and its corresponding shadow to refine the
segmentation. Validation against expert annotations shows that the method
outperforms the previous state-of-the-art for both bone surface and shadow
segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CMT-DeepLab: Clustering Mask Transformers for Panoptic Segmentation. (arXiv:2206.08948v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08948">
<div class="article-summary-box-inner">
<span><p>We propose Clustering Mask Transformer (CMT-DeepLab), a transformer-based
framework for panoptic segmentation designed around clustering. It rethinks the
existing transformer architectures used in segmentation and detection;
CMT-DeepLab considers the object queries as cluster centers, which fill the
role of grouping the pixels when applied to segmentation. The clustering is
computed with an alternating procedure, by first assigning pixels to the
clusters by their feature affinity, and then updating the cluster centers and
pixel features. Together, these operations comprise the Clustering Mask
Transformer (CMT) layer, which produces cross-attention that is denser and more
consistent with the final segmentation task. CMT-DeepLab improves the
performance over prior art significantly by 4.4% PQ, achieving a new
state-of-the-art of 55.7% PQ on the COCO test-dev set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intra-Instance VICReg: Bag of Self-Supervised Image Patch Embedding. (arXiv:2206.08954v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08954">
<div class="article-summary-box-inner">
<span><p>Recently, self-supervised learning (SSL) has achieved tremendous empirical
advancements in learning image representation. However, our understanding and
knowledge of the representation are still limited. This work shows that the
success of the SOTA siamese-network-based SSL approaches is primarily based on
learning a representation of image patches. Particularly, we show that when we
learn a representation only for fixed-scale image patches and aggregate
different patch representations linearly for an image (instance), it can
achieve on par or even better results than the baseline methods on several
benchmarks. Further, we show that the patch representation aggregation can also
improve various SOTA baseline methods by a large margin. We also establish a
formal connection between the SSL objective and the image patches co-occurrence
statistics modeling, which supplements the prevailing invariance perspective.
By visualizing the nearest neighbors of different image patches in the
embedding space and projection space, we show that while the projection has
more invariance, the embedding space tends to preserve more equivariance and
locality. Finally, we propose a hypothesis for the future direction based on
the discovery of this work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KitBit: A New AI Model for Solving Intelligence Tests and Numerical Series. (arXiv:2206.08965v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08965">
<div class="article-summary-box-inner">
<span><p>The resolution of intelligence tests, in particular numerical sequences, has
been of great interest in the evaluation of AI systems. We present a new
computational model called KitBit that uses a reduced set of algorithms and
their combinations to build a predictive model that finds the underlying
pattern in numerical sequences, such as those included in IQ tests and others
of much greater complexity. We present the fundamentals of the model and its
application in different cases. First, the system is tested on a set of number
series used in IQ tests collected from various sources. Next, our model is
successfully applied on the sequences used to evaluate the models reported in
the literature. In both cases, the system is capable of solving these types of
problems in less than a second using standard computing power. Finally,
KitBit's algorithms have been applied for the first time to the complete set of
entire sequences of the well-known OEIS database. We find a pattern in the form
of a list of algorithms and predict the following terms in the largest number
of series to date. These results demonstrate the potential of KitBit to solve
complex problems that could be represented numerically.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MultiEarth 2022 -- The Champion Solution for the Matrix Completion Challenge via Multimodal Regression and Generation. (arXiv:2206.08970v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08970">
<div class="article-summary-box-inner">
<span><p>Earth observation satellites have been continuously monitoring the earth
environment for years at different locations and spectral bands with different
modalities. Due to complex satellite sensing conditions (e.g., weather, cloud,
atmosphere, orbit), some observations for certain modalities, bands, locations,
and times may not be available. The MultiEarth Matrix Completion Challenge in
CVPR 2022 [1] provides the multimodal satellite data for addressing such data
sparsity challenges with the Amazon Rainforest as the region of interest. This
work proposes an adaptive real-time multimodal regression and generation
framework and achieves superior performance on unseen test queries in this
challenge with an LPIPS of 0.2226, a PSNR of 123.0372, and an SSIM of 0.6347.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BN-HTRd: A Benchmark Dataset for Document Level Offline Bangla Handwritten Text Recognition (HTR) and Line Segmentation. (arXiv:2206.08977v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08977">
<div class="article-summary-box-inner">
<span><p>We introduce a new dataset for offline Handwritten Text Recognition (HTR)
from images of Bangla scripts comprising words, lines, and document-level
annotations. The BN-HTRd dataset is based on the BBC Bangla News corpus, meant
to act as ground truth texts. These texts were subsequently used to generate
the annotations that were filled out by people with their handwriting. Our
dataset includes 788 images of handwritten pages produced by approximately 150
different writers. It can be adopted as a basis for various handwriting
classification tasks such as end-to-end document recognition, word-spotting,
word or line segmentation, and so on. We also propose a scheme to segment
Bangla handwritten document images into corresponding lines in an unsupervised
manner. Our line segmentation approach takes care of the variability involved
in different writing styles, accurately segmenting complex handwritten text
lines of curvilinear nature. Along with a bunch of pre-processing and
morphological operations, both Hough line and circle transforms were employed
to distinguish different linear components. In order to arrange those
components into their corresponding lines, we followed an unsupervised
clustering approach. The average success rate of our segmentation technique is
81.57% in terms of FM metrics (similar to F-measure) with a mean Average
Precision (mAP) of 0.547.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-scale Super-resolution Magnetic Resonance Spectroscopic Imaging with Adjustable Sharpness. (arXiv:2206.08984v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08984">
<div class="article-summary-box-inner">
<span><p>Magnetic Resonance Spectroscopic Imaging (MRSI) is a valuable tool for
studying metabolic activities in the human body, but the current applications
are limited to low spatial resolutions. The existing deep learning-based MRSI
super-resolution methods require training a separate network for each upscaling
factor, which is time-consuming and memory inefficient. We tackle this
multi-scale super-resolution problem using a Filter Scaling strategy that
modulates the convolution filters based on the upscaling factor, such that a
single network can be used for various upscaling factors. Observing that each
metabolite has distinct spatial characteristics, we also modulate the network
based on the specific metabolite. Furthermore, our network is conditioned on
the weight of adversarial loss so that the perceptual sharpness of the
super-resolved metabolic maps can be adjusted within a single network. We
incorporate these network conditionings using a novel Multi-Conditional Module.
The experiments were carried out on a 1H-MRSI dataset from 15 high-grade glioma
patients. Results indicate that the proposed network achieves the best
performance among several multi-scale super-resolution methods and can provide
super-resolved metabolic maps with adjustable sharpness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransResU-Net: Transformer based ResU-Net for Real-Time Colonoscopy Polyp Segmentation. (arXiv:2206.08985v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08985">
<div class="article-summary-box-inner">
<span><p>Colorectal cancer (CRC) is one of the most common causes of cancer and
cancer-related mortality worldwide. Performing colon cancer screening in a
timely fashion is the key to early detection. Colonoscopy is the primary
modality used to diagnose colon cancer. However, the miss rate of polyps,
adenomas and advanced adenomas remains significantly high. Early detection of
polyps at the precancerous stage can help reduce the mortality rate and the
economic burden associated with colorectal cancer. Deep learning-based
computer-aided diagnosis (CADx) system may help gastroenterologists to identify
polyps that may otherwise be missed, thereby improving the polyp detection
rate. Additionally, CADx system could prove to be a cost-effective system that
improves long-term colorectal cancer prevention. In this study, we proposed a
deep learning-based architecture for automatic polyp segmentation, called
Transformer ResU-Net (TransResU-Net). Our proposed architecture is built upon
residual blocks with ResNet-50 as the backbone and takes the advantage of
transformer self-attention mechanism as well as dilated convolution(s). Our
experimental results on two publicly available polyp segmentation benchmark
datasets showed that TransResU-Net obtained a highly promising dice score and a
real-time speed. With high efficacy in our performance metrics, we concluded
that TransResU-Net could be a strong benchmark for building a real-time polyp
detection system for the early diagnosis, treatment, and prevention of
colorectal cancer. The source code of the proposed TransResU-Net is publicly
available at https://github.com/nikhilroxtomar/TransResUNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shadows Shed Light on 3D Objects. (arXiv:2206.08990v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08990">
<div class="article-summary-box-inner">
<span><p>3D reconstruction is a fundamental problem in computer vision, and the task
is especially challenging when the object to reconstruct is partially or fully
occluded. We introduce a method that uses the shadows cast by an unobserved
object in order to infer the possible 3D volumes behind the occlusion. We
create a differentiable image formation model that allows us to jointly infer
the 3D shape of an object, its pose, and the position of a light source. Since
the approach is end-to-end differentiable, we are able to integrate learned
priors of object geometry in order to generate realistic 3D shapes of different
object categories. Experiments and visualizations show that the method is able
to generate multiple possible solutions that are consistent with the
observation of the shadow. Our approach works even when the position of the
light source and object pose are both unknown. Our approach is also robust to
real-world images where ground-truth shadow mask is unknown.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Group Synchronization via Quadratic Programming. (arXiv:2206.08994v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08994">
<div class="article-summary-box-inner">
<span><p>We propose a novel quadratic programming formulation for estimating the
corruption levels in group synchronization, and use these estimates to solve
this problem. Our objective function exploits the cycle consistency of the
group and we thus refer to our method as detection and estimation of structural
consistency (DESC). This general framework can be extended to other algebraic
and geometric structures. Our formulation has the following advantages: it can
tolerate corruption as high as the information-theoretic bound, it does not
require a good initialization for the estimates of group elements, it has a
simple interpretation, and under some mild conditions the global minimum of our
objective function exactly recovers the corruption levels. We demonstrate the
competitive accuracy of our approach on both synthetic and real data
experiments of rotation averaging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diffusion models as plug-and-play priors. (arXiv:2206.09012v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09012">
<div class="article-summary-box-inner">
<span><p>We consider the problem of inferring high-dimensional data $\mathbf{x}$ in a
model that consists of a prior $p(\mathbf{x})$ and an auxiliary constraint
$c(\mathbf{x},\mathbf{y})$. In this paper, the prior is an independently
trained denoising diffusion generative model. The auxiliary constraint is
expected to have a differentiable form, but can come from diverse sources. The
possibility of such inference turns diffusion models into plug-and-play
modules, thereby allowing a range of potential applications in adapting models
to new domains and tasks, such as conditional generation or image segmentation.
The structure of diffusion models allows us to perform approximate inference by
iterating differentiation through the fixed denoising network enriched with
different amounts of noise at each step. Considering many noised versions of
$\mathbf{x}$ in evaluation of its fitness is a novel search mechanism that may
lead to new algorithms for solving combinatorial optimization problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Landscape Learning for Neural Network Inversion. (arXiv:2206.09027v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09027">
<div class="article-summary-box-inner">
<span><p>Many machine learning methods operate by inverting a neural network at
inference time, which has become a popular technique for solving inverse
problems in computer vision, robotics, and graphics. However, these methods
often involve gradient descent through a highly non-convex loss landscape,
causing the optimization process to be unstable and slow. We introduce a method
that learns a loss landscape where gradient descent is efficient, bringing
massive improvement and acceleration to the inversion process. We demonstrate
this advantage on a number of methods for both generative and discriminative
tasks, including GAN inversion, adversarial defense, and 3D human pose
reconstruction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stop Overcomplicating Selective Classification: Use Max-Logit. (arXiv:2206.09034v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09034">
<div class="article-summary-box-inner">
<span><p>We tackle the problem of Selective Classification where the goal is to
achieve the best performance on the desired coverages of the dataset. Recent
state-of-the-art selective methods come with architectural changes either via
introducing a separate selection head or an extra abstention logit. In this
paper, we present surprising results for Selective Classification by confirming
that the superior performance of state-of-the-art methods is owed to training a
more generalizable classifier; however, their selection mechanism is
suboptimal. We argue that the selection mechanism should be rooted in the
objective function instead of a separately calculated score. Accordingly, in
this paper, we motivate an alternative selection strategy that is based on the
cross entropy loss for the classification settings, namely, max of the logits.
Our proposed selection strategy achieves better results by a significant
margin, consistently, across all coverages and all datasets, without any
additional computation. Finally, inspired by our superior selection mechanism,
we propose to further regularize the objective function with
entropy-minimization. Our proposed max-logit selection with the modified loss
function achieves new state-of-the-art results for Selective Classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Validation of Vector Data using Oblique Images. (arXiv:2206.09038v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09038">
<div class="article-summary-box-inner">
<span><p>Oblique images are aerial photographs taken at oblique angles to the earth's
surface. Projections of vector and other geospatial data in these images depend
on camera parameters, positions of the geospatial entities, surface terrain,
occlusions, and visibility. This paper presents a robust and scalable algorithm
to detect inconsistencies in vector data using oblique images. The algorithm
uses image descriptors to encode the local appearance of a geospatial entity in
images. These image descriptors combine color, pixel-intensity gradients,
texture, and steerable filter responses. A Support Vector Machine classifier is
trained to detect image descriptors that are not consistent with underlying
vector data, digital elevation maps, building models, and camera parameters. In
this paper, we train the classifier on visible road segments and non-road data.
Thereafter, the trained classifier detects inconsistencies in vectors, which
include both occluded and misaligned road segments. The consistent road
segments validate our vector, DEM, and 3-D model data for those areas while
inconsistent segments point out errors. We further show that a search for
descriptors that are consistent with visible road segments in the neighborhood
of a misaligned road yields the desired road alignment that is consistent with
pixels in the image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmented Imagefication: A Data-driven Fault Detection Method for Aircraft Air Data Sensors. (arXiv:2206.09055v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09055">
<div class="article-summary-box-inner">
<span><p>In this paper, a novel data-driven approach named Augmented Imagefication for
Fault detection (FD) of aircraft air data sensors (ADS) is proposed.
Exemplifying the FD problem of aircraft air data sensors, an online FD scheme
on edge device based on deep neural network (DNN) is developed. First, the
aircraft inertial reference unit measurements is adopted as equivalent inputs,
which is scalable to different aircraft/flight cases. Data associated with 6
different aircraft/flight conditions are collected to provide diversity
(scalability) in the training/testing database. Then Augmented Imagefication is
proposed for the DNN-based prediction of flying conditions. The raw data are
reshaped as a grayscale image for convolutional operation, and the necessity of
augmentation is analyzed and pointed out. Different kinds of augmented method,
i.e. Flip, Repeat, Tile and their combinations are discussed, the result shows
that the All Repeat operation in both axes of image matrix leads to the best
performance of DNN. The interpretability of DNN is studied based on Grad-CAM,
which provide a better understanding and further solidifies the robustness of
DNN. Next the DNN model, VGG-16 with augmented imagefication data is optimized
for mobile hardware deployment. After pruning of DNN, a lightweight model
(98.79% smaller than original VGG-16) with high accuracy (slightly up by 0.27%)
and fast speed (time delay is reduced by 87.54%) is obtained. And the
hyperparameters optimization of DNN based on TPE is implemented and the best
combination of hyperparameters is determined (learning rate 0.001, iterative
epochs 600, and batch size 100 yields the highest accuracy at 0.987). Finally,
a online FD deployment based on edge device, Jetson Nano, is developed and the
real time monitoring of aircraft is achieved. We believe that this method is
instructive for addressing the FD problems in other similar fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks. (arXiv:2206.09059v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09059">
<div class="article-summary-box-inner">
<span><p>Current state-of-the-art vision-and-language models are evaluated on tasks
either individually or in a multi-task setting, overlooking the challenges of
continually learning (CL) tasks as they arrive. Existing CL benchmarks have
facilitated research on task adaptation and mitigating "catastrophic
forgetting", but are limited to vision-only and language-only tasks. We present
CLiMB, a benchmark to study the challenge of learning multimodal tasks in a CL
setting, and to systematically evaluate how upstream continual learning can
rapidly generalize to new multimodal and unimodal tasks. CLiMB includes
implementations of several CL algorithms and a modified Vision-Language
Transformer (ViLT) model that can be deployed on both multimodal and unimodal
tasks. We find that common CL methods can help mitigate forgetting during
multimodal task learning, but do not enable cross-task knowledge transfer. We
envision that CLiMB will facilitate research on a new class of CL algorithms
for this challenging multimodal setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Design of Supervision-Scalable Learning Systems: Methodology and Performance Benchmarking. (arXiv:2206.09061v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09061">
<div class="article-summary-box-inner">
<span><p>The design of robust learning systems that offer stable performance under a
wide range of supervision degrees is investigated in this work. We choose the
image classification problem as an illustrative example and focus on the design
of modularized systems that consist of three learning modules: representation
learning, feature learning and decision learning. We discuss ways to adjust
each module so that the design is robust with respect to different training
sample numbers. Based on these ideas, we propose two families of learning
systems. One adopts the classical histogram of oriented gradients (HOG)
features while the other uses successive-subspace-learning (SSL) features. We
test their performance against LeNet-5, which is an end-to-end optimized neural
network, for MNIST and Fashion-MNIST datasets. The number of training samples
per image class goes from the extremely weak supervision condition (i.e., 1
labeled sample per class) to the strong supervision condition (i.e., 4096
labeled sample per class) with gradual transition in between (i.e., $2^n$,
$n=0, 1, \cdots, 12$). Experimental results show that the two families of
modularized learning systems have more robust performance than LeNet-5. They
both outperform LeNet-5 by a large margin for small $n$ and have performance
comparable with that of LeNet-5 for large $n$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Free-form Lesion Synthesis Using a Partial Convolution Generative Adversarial Network for Enhanced Deep Learning Liver Tumor Segmentation. (arXiv:2206.09065v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09065">
<div class="article-summary-box-inner">
<span><p>Automatic deep learning segmentation models has been shown to improve both
the segmentation efficiency and the accuracy. However, training a robust
segmentation model requires considerably large labeled training samples, which
may be impractical. This study aimed to develop a deep learning framework for
generating synthetic lesions that can be used to enhance network training. The
lesion synthesis network is a modified generative adversarial network (GAN).
Specifically, we innovated a partial convolution strategy to construct an
Unet-like generator. The discriminator is designed using Wasserstein GAN with
gradient penalty and spectral normalization. A mask generation method based on
principal component analysis was developed to model various lesion shapes. The
generated masks are then converted into liver lesions through a lesion
synthesis network. The lesion synthesis framework was evaluated for lesion
textures, and the synthetic lesions were used to train a lesion segmentation
network to further validate the effectiveness of this framework. All the
networks are trained and tested on the public dataset from LITS. The synthetic
lesions generated by the proposed approach have very similar histogram
distributions compared to the real lesions for the two employed texture
parameters, GLCM-energy and GLCM-correlation. The Kullback-Leibler divergence
of GLCM-energy and GLCM-correlation were 0.01 and 0.10, respectively. Including
the synthetic lesions in the tumor segmentation network improved the
segmentation dice performance of U-Net significantly from 67.3% to 71.4%
(p&lt;0.05). Meanwhile, the volume precision and sensitivity improve from 74.6% to
76.0% (p=0.23) and 66.1% to 70.9% (p&lt;0.01), respectively. The synthetic data
significantly improves the segmentation performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-based Dynamic Subspace Learners for Medical Image Analysis. (arXiv:2206.09068v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09068">
<div class="article-summary-box-inner">
<span><p>Learning similarity is a key aspect in medical image analysis, particularly
in recommendation systems or in uncovering the interpretation of anatomical
data in images. Most existing methods learn such similarities in the embedding
space over image sets using a single metric learner. Images, however, have a
variety of object attributes such as color, shape, or artifacts. Encoding such
attributes using a single metric learner is inadequate and may fail to
generalize. Instead, multiple learners could focus on separate aspects of these
attributes in subspaces of an overarching embedding. This, however, implies the
number of learners to be found empirically for each new dataset. This work,
Dynamic Subspace Learners, proposes to dynamically exploit multiple learners by
removing the need of knowing apriori the number of learners and aggregating new
subspace learners during training. Furthermore, the visual interpretability of
such subspace learning is enforced by integrating an attention module into our
method. This integrated attention mechanism provides a visual insight of
discriminative image features that contribute to the clustering of image sets
and a visual explanation of the embedding features. The benefits of our
attention-based dynamic subspace learners are evaluated in the application of
image clustering, image retrieval, and weakly supervised segmentation. Our
method achieves competitive results with the performances of multiple learners
baselines and significantly outperforms the classification network in terms of
clustering and retrieval scores on three different public benchmark datasets.
Moreover, our attention maps offer a proxy-labels, which improves the
segmentation accuracy up to 15% in Dice scores when compared to
state-of-the-art interpretation techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SiamVGG: Visual Tracking using Deeper Siamese Networks. (arXiv:1902.02804v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1902.02804">
<div class="article-summary-box-inner">
<span><p>Recently, we have seen a rapid development of Deep Neural Network (DNN) based
visual tracking solutions. Some trackers combine the DNN-based solutions with
Discriminative Correlation Filters (DCF) to extract semantic features and
successfully deliver the state-of-the-art tracking accuracy. However, these
solutions are highly compute-intensive, which require long processing time,
resulting unsecured real-time performance. To deliver both high accuracy and
reliable real-time performance, we propose a novel tracker called SiamVGG. It
combines a Convolutional Neural Network (CNN) backbone and a cross-correlation
operator, and takes advantage of the features from exemplary images for more
accurate object tracking.
</p>
<p>The architecture of SiamVGG is customized from VGG-16, with the parameters
shared by both exemplary images and desired input video frames.
</p>
<p>We demonstrate the proposed SiamVGG on OTB-2013/50/100 and VOT 2015/2016/2017
datasets with the state-of-the-art accuracy while maintaining a decent
real-time performance of 50 FPS running on a GTX 1080Ti. Our design can achieve
2% higher Expected Average Overlap (EAO) compared to the ECO and C-COT in
VOT2017 Challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HERS: Homomorphically Encrypted Representation Search. (arXiv:2003.12197v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.12197">
<div class="article-summary-box-inner">
<span><p>We present a method to search for a probe (or query) image representation
against a large gallery in the encrypted domain. We require that the probe and
gallery images be represented in terms of a fixed-length representation, which
is typical for representations obtained from learned networks. Our encryption
scheme is agnostic to how the fixed-length representation is obtained and can
therefore be applied to any fixed-length representation in any application
domain. Our method, dubbed HERS (Homomorphically Encrypted Representation
Search), operates by (i) compressing the representation towards its estimated
intrinsic dimensionality with minimal loss of accuracy (ii) encrypting the
compressed representation using the proposed fully homomorphic encryption
scheme, and (iii) efficiently searching against a gallery of encrypted
representations directly in the encrypted domain, without decrypting them.
Numerical results on large galleries of face, fingerprint, and object datasets
such as ImageNet show that, for the first time, accurate and fast image search
within the encrypted domain is feasible at scale (500 seconds; $275\times$
speed up over state-of-the-art for encrypted search against a gallery of 100
million). Code is available at
https://github.com/human-analysis/hers-encrypted-image-search
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SS-IL: Separated Softmax for Incremental Learning. (arXiv:2003.13947v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.13947">
<div class="article-summary-box-inner">
<span><p>We consider class incremental learning (CIL) problem, in which a learning
agent continuously learns new classes from incrementally arriving training data
batches and aims to predict well on all the classes learned so far. The main
challenge of the problem is the catastrophic forgetting, and for the
exemplar-memory based CIL methods, it is generally known that the forgetting is
commonly caused by the classification score bias that is injected due to the
data imbalance between the new classes and the old classes (in the
exemplar-memory). While several methods have been proposed to correct such
score bias by some additional post-processing, e.g., score re-scaling or
balanced fine-tuning, no systematic analysis on the root cause of such bias has
been done. To that end, we analyze that computing the softmax probabilities by
combining the output scores for all old and new classes could be the main cause
of the bias. Then, we propose a new method, dubbed as Separated Softmax for
Incremental Learning (SS-IL), that consists of separated softmax (SS) output
layer combined with task-wise knowledge distillation (TKD) to resolve such
bias. Throughout our extensive experimental results on several large-scale CIL
benchmark datasets, we show our SS-IL achieves strong state-of-the-art accuracy
through attaining much more balanced prediction scores across old and new
classes, without any additional post-processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guided interactive image segmentation using machine learning and color based data set clustering. (arXiv:2005.07662v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.07662">
<div class="article-summary-box-inner">
<span><p>We present a novel approach that combines machine learning based interactive
image segmentation using supervoxels with a clustering method for the automated
identification of similarly colored images in large data sets which enables a
guided reuse of classifiers. Our approach solves the problem of significant
color variability prevalent and often unavoidable in biological and medical
images which typically leads to deteriorated segmentation and quantification
accuracy thereby greatly reducing the necessary training effort. This increase
in efficiency facilitates the quantification of much larger numbers of images
thereby enabling interactive image analysis for recent new technological
advances in high-throughput imaging. The presented methods are applicable for
almost any image type and represent a useful tool for image analysis tasks in
general.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Frequency and Image Space Learning for MRI Reconstruction and Analysis. (arXiv:2007.01441v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01441">
<div class="article-summary-box-inner">
<span><p>We propose neural network layers that explicitly combine frequency and image
feature representations and show that they can be used as a versatile building
block for reconstruction from frequency space data. Our work is motivated by
the challenges arising in MRI acquisition where the signal is a corrupted
Fourier transform of the desired image. The proposed joint learning schemes
enable both correction of artifacts native to the frequency space and
manipulation of image space representations to reconstruct coherent image
structures at every layer of the network. This is in contrast to most current
deep learning approaches for image reconstruction that treat frequency and
image space features separately and often operate exclusively in one of the two
spaces. We demonstrate the advantages of joint convolutional learning for a
variety of tasks, including motion correction, denoising, reconstruction from
undersampled acquisitions, and combined undersampling and motion correction on
simulated and real world multicoil MRI data. The joint models produce
consistently high quality output images across all tasks and datasets. When
integrated into a state of the art unrolled optimization network with
physics-inspired data consistency constraints for undersampled reconstruction,
the proposed architectures significantly improve the optimization landscape,
which yields an order of magnitude reduction of training time. This result
suggests that joint representations are particularly well suited for MRI
signals in deep learning networks. Our code and pretrained models are publicly
available at https://github.com/nalinimsingh/interlacer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating Example Difficulty Using Variance of Gradients. (arXiv:2008.11600v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11600">
<div class="article-summary-box-inner">
<span><p>In machine learning, a question of great interest is understanding what
examples are challenging for a model to classify. Identifying atypical examples
ensures the safe deployment of models, isolates samples that require further
human inspection and provides interpretability into model behavior. In this
work, we propose Variance of Gradients (VoG) as a valuable and efficient metric
to rank data by difficulty and to surface a tractable subset of the most
challenging examples for human-in-the-loop auditing. We show that data points
with high VoG scores are far more difficult for the model to learn and
over-index on corrupted or memorized examples. Further, restricting the
evaluation to the test set instances with the lowest VoG improves the model's
generalization performance. Finally, we show that VoG is a valuable and
efficient ranking for out-of-distribution detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Action Recognition from Various Data Modalities: A Review. (arXiv:2012.11866v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11866">
<div class="article-summary-box-inner">
<span><p>Human Action Recognition (HAR) aims to understand human behavior and assign a
label to each action. It has a wide range of applications, and therefore has
been attracting increasing attention in the field of computer vision. Human
actions can be represented using various data modalities, such as RGB,
skeleton, depth, infrared, point cloud, event stream, audio, acceleration,
radar, and WiFi signal, which encode different sources of useful yet distinct
information and have various advantages depending on the application scenarios.
Consequently, lots of existing works have attempted to investigate different
types of approaches for HAR using various modalities. In this paper, we present
a comprehensive survey of recent progress in deep learning methods for HAR
based on the type of input data modality. Specifically, we review the current
mainstream deep learning methods for single data modalities and multiple data
modalities, including the fusion-based and the co-learning-based frameworks. We
also present comparative results on several benchmark datasets for HAR,
together with insightful observations and inspiring future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Warping of Radar Data into Camera Image for Cross-Modal Supervision in Automotive Applications. (arXiv:2012.12809v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12809">
<div class="article-summary-box-inner">
<span><p>We present an approach to automatically generate semantic labels for real
recordings of automotive range-Doppler (RD) radar spectra. Such labels are
required when training a neural network for object recognition from radar data.
The automatic labeling approach rests on the simultaneous recording of camera
and lidar data in addition to the radar spectrum. By warping radar spectra into
the camera image, state-of-the-art object recognition algorithms can be applied
to label relevant objects, such as cars, in the camera image. The warping
operation is designed to be fully differentiable, which allows backpropagating
the gradient computed on the camera image through the warping operation to the
neural network operating on the radar data. As the warping operation relies on
accurate scene flow estimation, we further propose a novel scene flow
estimation algorithm which exploits information from camera, lidar and radar
sensors. The proposed scene flow estimation approach is compared against a
state-of-the-art scene flow algorithm, and it outperforms it by approximately
30% w.r.t. mean average error. The feasibility of the overall framework for
automatic label generation for RD spectra is verified by evaluating the
performance of neural networks trained with the proposed framework for
Direction-of-Arrival estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyperspectral Image Denoising via Multi-modal and Double-weighted Tensor Nuclear Norm. (arXiv:2101.07681v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07681">
<div class="article-summary-box-inner">
<span><p>Hyperspectral images (HSIs) usually suffer from different types of pollution.
This severely reduces the quality of HSIs and limits the accuracy of subsequent
processing tasks. HSI denoising can be modeled as a low-rank tensor denoising
problem. Tensor nuclear norm (TNN) induced by tensor singular value
decomposition plays an important role in this problem. In this letter, we first
reconsider three inconspicuous but crucial phenomenons in TNN. In the Fourier
transform domain of HSIs, different frequency slices (FS) contain different
information; different singular values (SVs) of each FS also represent
different information. The two physical phenomenons lie not only in the
spectral mode but also in the spatial modes. Then based on them, we propose a
multi-modal and double-weighted TNN. It can adaptively shrink the FS and SVs
according to their physical meanings in all modes of HSIs. In the framework of
the alternating direction method of multipliers, we design an effective
alternating iterative strategy to optimize our proposed model. Denoised
experiments on both synthetic and real HSI datasets demonstrate their
superiority against related methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Continual, Online, Self-Supervised Depth. (arXiv:2103.00369v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00369">
<div class="article-summary-box-inner">
<span><p>Although depth extraction with passive sensors has seen remarkable
improvement with deep learning, these approaches may fail to obtain correct
depth if they are exposed to environments not observed during training. Online
adaptation, where the neural network trains while deployed, with
self-supervised learning provides a convenient solution as the network can
learn from the scene where it is deployed without external supervision.
However, online adaptation causes a neural network to forget the past. Thus,
past training is wasted and the network is not able to provide good results if
it observes past scenes. This work deals with practical online-adaptation where
the input is online and temporally-correlated, and training is completely
self-supervised. Regularization and replay-based methods without task
boundaries are proposed to avoid catastrophic forgetting while adapting to
online data. Effort has been made to make the proposed approach suitable for
practical use. We apply our method to both structure-from-motion and stereo
depth estimation. We evaluate our method on diverse public datasets that
include outdoor, indoor and synthetic scenes. Qualitative and quantitative
results with both structure-from-motion and stereo show superior forgetting as
well as adaptation performance compared to recent methods. Furthermore, the
proposed method incurs negligible overhead compared to fine-tuning for online
adaptation, proving to be an adequate choice in terms of plasticity, stability
and applicability. The proposed approach is more inline with the artificial
general intelligence paradigm as the neural network learns continually with no
supervision. Source code is available at https://github.com/umarKarim/cou_sfm
and https://github.com/umarKarim/cou_stereo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GANav: Efficient Terrain Segmentation for Robot Navigation in Unstructured Outdoor Environments. (arXiv:2103.04233v5 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04233">
<div class="article-summary-box-inner">
<span><p>We propose GANav, a novel group-wise attention mechanism to identify safe and
navigable regions in off-road terrains and unstructured environments from RGB
images. Our approach classifies terrains based on their navigability levels
using coarse-grained semantic segmentation. Our novel group-wise attention loss
enables any backbone network to explicitly focus on the different groups'
features with low spatial resolution. Our design leads to efficient inference
while maintaining a high level of accuracy compared to existing SOTA methods.
Our extensive evaluations on the RUGD and RELLIS-3D datasets shows that GANav
achieves an improvement over the SOTA mIoU by 2.25-39.05% on RUGD and
5.17-19.06% on RELLIS-3D. We interface GANav with a deep reinforcement
learning-based navigation algorithm and highlight its benefits in terms of
navigation in real-world unstructured terrains. We integrate our GANav-based
navigation algorithm with ClearPath Jackal and Husky robots, and observe an
increase of 10% in terms of success rate, 2-47% in terms of selecting the
surface with the best navigability and a decrease of 4.6-13.9% in trajectory
roughness. Further, GANav reduces the false positive rate of forbidden regions
by 37.79%. Code, videos, and a full technical report are available at
https://gamma.umd.edu/offroad/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Highly Efficient Representation and Active Learning Framework and Its Application to Imbalanced Medical Image Classification. (arXiv:2103.05109v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05109">
<div class="article-summary-box-inner">
<span><p>We propose a highly data-efficient active learning framework for image
classification. Our novel framework combines: (1) unsupervised representation
learning of a Convolutional Neural Network and (2) the Gaussian Process (GP)
method, in sequence to achieve highly data and label efficient classifications.
Moreover, both elements are less sensitive to the prevalent and challenging
class imbalance issue, thanks to the (1) feature learned without labels and (2)
the Bayesian nature of GP. The GP-provided uncertainty estimates enable active
learning by ranking samples based on the uncertainty and selectively labeling
samples showing higher uncertainty. We apply this novel combination to the
severely imbalanced case of COVID-19 chest X-ray classification and the Nerthus
colonoscopy classification. We demonstrate that only . 10% of the labeled data
is needed to reach the accuracy from training all available labels. We also
applied our model architecture and proposed framework to a broader class of
datasets with expected success.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Person Extreme Motion Prediction. (arXiv:2105.08825v7 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08825">
<div class="article-summary-box-inner">
<span><p>Human motion prediction aims to forecast future poses given a sequence of
past 3D skeletons. While this problem has recently received increasing
attention, it has mostly been tackled for single humans in isolation. In this
paper, we explore this problem when dealing with humans performing
collaborative tasks, we seek to predict the future motion of two interacted
persons given two sequences of their past skeletons. We propose a novel cross
interaction attention mechanism that exploits historical information of both
persons, and learns to predict cross dependencies between the two pose
sequences. Since no dataset to train such interactive situations is available,
we collected ExPI (Extreme Pose Interaction), a new lab-based person
interaction dataset of professional dancers performing Lindy-hop dancing
actions, which contains 115 sequences with 30K frames annotated with 3D body
poses and shapes. We thoroughly evaluate our cross interaction network on ExPI
and show that both in short- and long-term predictions, it consistently
outperforms state-of-the-art methods for single-person motion prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Vision Transformers. (arXiv:2106.04560v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04560">
<div class="article-summary-box-inner">
<span><p>Attention-based neural networks such as the Vision Transformer (ViT) have
recently attained state-of-the-art results on many computer vision benchmarks.
Scale is a primary ingredient in attaining excellent results, therefore,
understanding a model's scaling properties is a key to designing future
generations effectively. While the laws for scaling Transformer language models
have been studied, it is unknown how Vision Transformers scale. To address
this, we scale ViT models and data, both up and down, and characterize the
relationships between error rate, data, and compute. Along the way, we refine
the architecture and training of ViT, reducing memory consumption and
increasing accuracy of the resulting models. As a result, we successfully train
a ViT model with two billion parameters, which attains a new state-of-the-art
on ImageNet of 90.45% top-1 accuracy. The model also performs well for few-shot
transfer, for example, reaching 84.86% top-1 accuracy on ImageNet with only 10
examples per class.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge distillation: A good teacher is patient and consistent. (arXiv:2106.05237v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05237">
<div class="article-summary-box-inner">
<span><p>There is a growing discrepancy in computer vision between large-scale models
that achieve state-of-the-art performance and models that are affordable in
practical applications. In this paper we address this issue and significantly
bridge the gap between these two types of models. Throughout our empirical
investigation we do not aim to necessarily propose a new method, but strive to
identify a robust and effective recipe for making state-of-the-art large scale
models affordable in practice. We demonstrate that, when performed correctly,
knowledge distillation can be a powerful tool for reducing the size of large
models without compromising their performance. In particular, we uncover that
there are certain implicit design choices, which may drastically affect the
effectiveness of distillation. Our key contribution is the explicit
identification of these design choices, which were not previously articulated
in the literature. We back up our findings by a comprehensive empirical study,
demonstrate compelling results on a wide range of vision datasets and, in
particular, obtain a state-of-the-art ResNet-50 model for ImageNet, which
achieves 82.8% top-1 accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Physion: Evaluating Physical Prediction from Vision in Humans and Machines. (arXiv:2106.08261v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08261">
<div class="article-summary-box-inner">
<span><p>While current vision algorithms excel at many challenging tasks, it is
unclear how well they understand the physical dynamics of real-world
environments. Here we introduce Physion, a dataset and benchmark for rigorously
evaluating the ability to predict how physical scenarios will evolve over time.
Our dataset features realistic simulations of a wide range of physical
phenomena, including rigid and soft-body collisions, stable multi-object
configurations, rolling, sliding, and projectile motion, thus providing a more
comprehensive challenge than previous benchmarks. We used Physion to benchmark
a suite of models varying in their architecture, learning objective,
input-output structure, and training data. In parallel, we obtained precise
measurements of human prediction behavior on the same set of scenarios,
allowing us to directly evaluate how well any model could approximate human
behavior. We found that vision algorithms that learn object-centric
representations generally outperform those that do not, yet still fall far
short of human performance. On the other hand, graph neural networks with
direct access to physical state information both perform substantially better
and make predictions that are more similar to those made by humans. These
results suggest that extracting physical representations of scenes is the main
bottleneck to achieving human-level and human-like physical understanding in
vision algorithms. We have publicly released all data and code to facilitate
the use of Physion to benchmark additional models in a fully reproducible
manner, enabling systematic evaluation of progress towards vision algorithms
that understand physical environments as robustly as people do.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Region-Aware Network: Model Human's Top-Down Visual Perception Mechanism for Crowd Counting. (arXiv:2106.12163v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12163">
<div class="article-summary-box-inner">
<span><p>Background noise and scale variation are common problems that have been long
recognized in crowd counting. Humans glance at a crowd image and instantly know
the approximate number of human and where they are through attention the crowd
regions and the congestion degree of crowd regions with a global receptive
field. Hence, in this paper, we propose a novel feedback network with
Region-Aware block called RANet by modeling humans Top-Down visual perception
mechanism. Firstly, we introduce a feedback architecture to generate priority
maps that provide prior about candidate crowd regions in input images. The
prior enables the RANet pay more attention to crowd regions. Then we design
Region-Aware block that could adaptively encode the contextual information into
input images through global receptive field. More specifically, we scan the
whole input images and its priority maps in the form of column vector to obtain
a relevance matrix estimating their similarity. The relevance matrix obtained
would be utilized to build global relationships between pixels. Our method
outperforms state-of-the-art crowd counting methods on several public datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal and frequency-weighted tensor nuclear norm for hyperspectral image denoising. (arXiv:2106.12489v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12489">
<div class="article-summary-box-inner">
<span><p>Low-rankness is important in the hyperspectral image (HSI) denoising tasks.
The tensor nuclear norm (TNN), defined based on the tensor singular value
decomposition, is a state-of-the-art method to describe the low-rankness of
HSI. However, TNN ignores some physical meanings of HSI in tackling denoising
tasks, leading to suboptimal denoising performance. In this paper, we propose
the multi-modal and frequency-weighted tensor nuclear norm (MFWTNN) and the
non-convex MFWTNN for HSI denoising tasks. Firstly, we investigate the physical
meaning of frequency slices and reconsider their weights to improve the
low-rank representation ability of TNN. Secondly, we consider the correlation
among two spatial dimensions and the spectral dimension of HSI and combine the
above improvements to TNN to propose MFWTNN. Thirdly, we use non-convex
functions to approximate the rank function of the frequency tensor and propose
the NonMFWTNN to relax the MFWTNN better. Besides, we adaptively choose bigger
weights for slices mainly containing noise information and smaller weights for
slices containing profile information. Finally, we develop the efficient
alternating direction method of multiplier (ADMM) based algorithm to solve the
proposed models, and the effectiveness of our models are substantiated in
simulated and real HSI datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OPA: Object Placement Assessment Dataset. (arXiv:2107.01889v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01889">
<div class="article-summary-box-inner">
<span><p>Image composition aims to generate realistic composite image by inserting an
object from one image into another background image, where the placement (e.g.,
location, size, occlusion) of inserted object may be unreasonable, which would
significantly degrade the quality of the composite image. Although some works
attempted to learn object placement to create realistic composite images, they
did not focus on assessing the plausibility of object placement. In this paper,
we focus on object placement assessment task, which verifies whether a
composite image is plausible in terms of the object placement. To accomplish
this task, we construct the first Object Placement Assessment (OPA) dataset
consisting of composite images and their rationality labels. We also propose a
simple yet effective baseline for this task. Dataset is available at
https://github.com/bcmi/Object-Placement-Assessment-Dataset-OPA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regularising Inverse Problems with Generative Machine Learning Models. (arXiv:2107.11191v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11191">
<div class="article-summary-box-inner">
<span><p>Deep neural network approaches to inverse imaging problems have produced
impressive results in the last few years. In this paper, we consider the use of
generative models in a variational regularisation approach to inverse problems.
The considered regularisers penalise images that are far from the range of a
generative model that has learned to produce images similar to a training
dataset. We name this family \textit{generative regularisers}. The success of
generative regularisers depends on the quality of the generative model and so
we propose a set of desired criteria to assess generative models and guide
future research. In our numerical experiments, we evaluate three common
generative models, autoencoders, variational autoencoders and generative
adversarial networks, against our desired criteria. We also test three
different generative regularisers on the inverse problems of deblurring,
deconvolution, and tomography. We show that restricting solutions of the
inverse problem to lie exactly in the range of a generative model can give good
results but that allowing small deviations from the range of the generator
produces more consistent results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Anomaly Discovery From Unlabeled Videos via Normality Advantage and Self-Paced Refinement. (arXiv:2108.01975v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01975">
<div class="article-summary-box-inner">
<span><p>While classic video anomaly detection (VAD) requires labeled normal videos
for training, emerging unsupervised VAD (UVAD) aims to discover anomalies
directly from fully unlabeled videos. However, existing UVAD methods still rely
on shallow models to perform detection or initialization, and they are
evidently inferior to classic VAD methods. This paper proposes a full deep
neural network (DNN) based solution that can realize highly effective UVAD.
First, we, for the first time, point out that deep reconstruction can be
surprisingly effective for UVAD, which inspires us to unveil a property named
"normality advantage", i.e., normal events will enjoy lower reconstruction loss
when DNN learns to reconstruct unlabeled videos. With this property, we propose
Localization based Reconstruction (LBR) as a strong UVAD baseline and a solid
foundation of our solution. Second, we propose a novel self-paced refinement
(SPR) scheme, which is synthesized into LBR to conduct UVAD. Unlike ordinary
self-paced learning that injects more samples in an easy-to-hard manner, the
proposed SPR scheme gradually drops samples so that suspicious anomalies can be
removed from the learning process. In this way, SPR consolidates normality
advantage and enables better UVAD in a more proactive way. Finally, we further
design a variant solution that explicitly takes the motion cues into account.
The solution evidently enhances the UVAD performance, and it sometimes even
surpasses the best classic VAD methods. Experiments show that our solution not
only significantly outperforms existing UVAD methods by a wide margin (5% to 9%
AUROC), but also enables UVAD to catch up with the mainstream performance of
classic VAD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Localized Shape Modelling with Global Coherence: An Inverse Spectral Approach. (arXiv:2108.02161v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02161">
<div class="article-summary-box-inner">
<span><p>Many natural shapes have most of their characterizing features concentrated
over a few regions in space. For example, humans and animals have distinctive
head shapes, while inorganic objects like chairs and airplanes are made of
well-localized functional parts with specific geometric features. Often, these
features are strongly correlated -- a modification of facial traits in a
quadruped should induce changes to the body structure. However, in shape
modelling applications, these types of edits are among the hardest ones; they
require high precision, but also a global awareness of the entire shape. Even
in the deep learning era, obtaining manipulable representations that satisfy
such requirements is an open problem posing significant constraints. In this
work, we address this problem by defining a data-driven model upon a family of
linear operators (variants of the mesh Laplacian), whose spectra capture global
and local geometric properties of the shape at hand. Modifications to these
spectra are translated to semantically valid deformations of the corresponding
surface. By explicitly decoupling the global from the local surface features,
our pipeline allows to perform local edits while simultaneously maintaining a
global stylistic coherence. We empirically demonstrate how our learning-based
model generalizes to shape representations not seen at training time, and we
systematically analyze different choices of local operators over diverse shape
categories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Acquisition and Preparation for Dual-reference Deep Learning of Image Super-Resolution. (arXiv:2108.02348v5 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02348">
<div class="article-summary-box-inner">
<span><p>The performance of deep learning based image super-resolution (SR) methods
depend on how accurately the paired low and high resolution images for training
characterize the sampling process of real cameras. Low and high resolution
(LR$\sim$HR) image pairs synthesized by degradation models (e.g., bicubic
downsampling) deviate from those in reality; thus the synthetically-trained
DCNN SR models work disappointingly when being applied to real-world images. To
address this issue, we propose a novel data acquisition process to shoot a
large set of LR$\sim$HR image pairs using real cameras. The images are
displayed on an ultra-high quality screen and captured at different
resolutions. The resulting LR$\sim$HR image pairs can be aligned at very high
sub-pixel precision by a novel spatial-frequency dual-domain registration
method, and hence they provide more appropriate training data for the learning
task of super-resolution. Moreover, the captured HR image and the original
digital image offer dual references to strengthen supervised learning.
Experimental results show that training a super-resolution DCNN by our
LR$\sim$HR dataset achieves higher image quality than training it by other
datasets in the literature. Moreover, the proposed screen-capturing data
collection process can be automated; it can be carried out for any target
camera with ease and low cost, offering a practical way of tailoring the
training of a DCNN SR model separately to each of the given cameras.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing MR Image Segmentation with Realistic Adversarial Data Augmentation. (arXiv:2108.03429v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03429">
<div class="article-summary-box-inner">
<span><p>The success of neural networks on medical image segmentation tasks typically
relies on large labeled datasets for model training. However, acquiring and
manually labeling a large medical image set is resource-intensive, expensive,
and sometimes impractical due to data sharing and privacy issues. To address
this challenge, we propose AdvChain, a generic adversarial data augmentation
framework, aiming at improving both the diversity and effectiveness of training
data for medical image segmentation tasks. AdvChain augments data with dynamic
data augmentation, generating randomly chained photo-metric and geometric
transformations to resemble realistic yet challenging imaging variations to
expand training data. By jointly optimizing the data augmentation model and a
segmentation network during training, challenging examples are generated to
enhance network generalizability for the downstream task. The proposed
adversarial data augmentation does not rely on generative networks and can be
used as a plug-in module in general segmentation networks. It is
computationally efficient and applicable for both low-shot supervised and
semi-supervised learning. We analyze and evaluate the method on two MR image
segmentation tasks: cardiac segmentation and prostate segmentation with limited
labeled data. Results show that the proposed approach can alleviate the need
for labeled data while improving model generalization ability, indicating its
practical value in medical imaging applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rapid Automated Analysis of Skull Base Tumor Specimens Using Intraoperative Optical Imaging and Artificial Intelligence. (arXiv:2108.03555v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03555">
<div class="article-summary-box-inner">
<span><p>Background: Accurate diagnosis of skull base tumors is essential for
providing personalized surgical treatment strategies. Intraoperative diagnosis
can be challenging due to tumor diversity and lack of intraoperative pathology
resources.
</p>
<p>Objective: To develop an independent and parallel intraoperative pathology
workflow that can provide rapid and accurate skull base tumor diagnoses using
label-free optical imaging and artificial intelligence.
</p>
<p>Method: We used a fiber laser-based, label-free, non-consumptive,
high-resolution microscopy method ($&lt;$ 60 sec per 1 $\times$ 1 mm$^\text{2}$),
called stimulated Raman histology (SRH), to image a consecutive, multicenter
cohort of skull base tumor patients. SRH images were then used to train a
convolutional neural network (CNN) model using three representation learning
strategies: cross-entropy, self-supervised contrastive learning, and supervised
contrastive learning. Our trained CNN models were tested on a held-out,
multicenter SRH dataset.
</p>
<p>Results: SRH was able to image the diagnostic features of both benign and
malignant skull base tumors. Of the three representation learning strategies,
supervised contrastive learning most effectively learned the distinctive and
diagnostic SRH image features for each of the skull base tumor types. In our
multicenter testing set, cross-entropy achieved an overall diagnostic accuracy
of 91.5%, self-supervised contrastive learning 83.9%, and supervised
contrastive learning 96.6%. Our trained model was able to identify tumor-normal
margins and detect regions of microscopic tumor infiltration in whole-slide SRH
images.
</p>
<p>Conclusion: SRH with trained artificial intelligence models can provide rapid
and accurate intraoperative analysis of skull base tumor specimens to inform
surgical decision-making.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ensemble CNN and Uncertainty Modeling to Improve Automatic Identification/Segmentation of Multiple Sclerosis Lesions in Magnetic Resonance Imaging. (arXiv:2108.11791v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11791">
<div class="article-summary-box-inner">
<span><p>To date, several automated strategies for identification/segmentation of
Multiple Sclerosis (MS) lesions with the use of Magnetic Resonance Imaging
(MRI) have been presented, but they are outperformed by human experts, from
whom they act very differently. This is mainly due to: the ambiguity originated
by MRI instabilities; peculiar variability of MS; non specificity of MRI
regarding MS. Physicians partially manage the uncertainty generated by
ambiguity relying on radiological/clinical/anatomical background and
experience. To emulate human diagnosis, we present an automated framework for
identification/segmentation of MS lesions from MRI based on three pivotal
concepts: 1. the modelling of uncertainty; 2. the proposal of two, separately
trained, CNN, one optimized for lesions and the other for lesions with respect
to the environment surrounding them, respectively repeated for axial, coronal
and sagittal directions; 3. the definition of an ensemble classifier to merge
the information collected by different CNN. The proposed framework is trained,
validated and tested on the 2016 MSSEG benchmark public data set from a single
imaging modality, the FLuid-Attenuated Inversion Recovery (FLAIR). The
comparison with the ground-truth and with each of 7 human raters, proves that
there is no significant difference between the automated and the human raters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with Vehicle-to-Vehicle Communication. (arXiv:2109.07644v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07644">
<div class="article-summary-box-inner">
<span><p>Employing Vehicle-to-Vehicle communication to enhance perception performance
in self-driving technology has attracted considerable attention recently;
however, the absence of a suitable open dataset for benchmarking algorithms has
made it difficult to develop and assess cooperative perception technologies. To
this end, we present the first large-scale open simulated dataset for
Vehicle-to-Vehicle perception. It contains over 70 interesting scenes, 11,464
frames, and 232,913 annotated 3D vehicle bounding boxes, collected from 8 towns
in CARLA and a digital town of Culver City, Los Angeles. We then construct a
comprehensive benchmark with a total of 16 implemented models to evaluate
several information fusion strategies~(i.e. early, late, and intermediate
fusion) with state-of-the-art LiDAR detection algorithms. Moreover, we propose
a new Attentive Intermediate Fusion pipeline to aggregate information from
multiple connected vehicles. Our experiments show that the proposed pipeline
can be easily integrated with existing 3D LiDAR detectors and achieve
outstanding performance even with large compression rates. To encourage more
researchers to investigate Vehicle-to-Vehicle perception, we will release the
dataset, benchmark methods, and all related codes in
https://mobility-lab.seas.ucla.edu/opv2v/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Hilti SLAM Challenge Dataset. (arXiv:2109.11316v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11316">
<div class="article-summary-box-inner">
<span><p>Research in Simultaneous Localization and Mapping (SLAM) has made outstanding
progress over the past years. SLAM systems are nowadays transitioning from
academic to real world applications. However, this transition has posed new
demanding challenges in terms of accuracy and robustness. To develop new SLAM
systems that can address these challenges, new datasets containing cutting-edge
hardware and realistic scenarios are required. We propose the Hilti SLAM
Challenge Dataset. Our dataset contains indoor sequences of offices, labs, and
construction environments and outdoor sequences of construction sites and
parking areas. All these sequences are characterized by featureless areas and
varying illumination conditions that are typical in real-world scenarios and
pose great challenges to SLAM algorithms that have been developed in confined
lab environments. Accurate sparse ground truth, at millimeter level, is
provided for each sequence. The sensor platform used to record the data
includes a number of visual, lidar, and inertial sensors, which are spatially
and temporally calibrated. The purpose of this dataset is to foster the
research in sensor fusion to develop SLAM algorithms that can be deployed in
tasks where high accuracy and robustness are required, e.g., in construction
environments. Many academic and industrial groups tested their SLAM systems on
the proposed dataset in the Hilti SLAM Challenge. The results of the challenge,
which are summarized in this paper, show that the proposed dataset is an
important asset in the development of new SLAM algorithms that are ready to be
deployed in the real-world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MD Loss: Efficient Training of 3D Seismic Fault Segmentation Network under Sparse Labels by Weakening Anomaly Annotation. (arXiv:2110.05319v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05319">
<div class="article-summary-box-inner">
<span><p>Data-driven fault detection has been regarded as a 3D image segmentation
task. The models trained from synthetic data are difficult to generalize in
some surveys. Recently, training 3D fault segmentation using sparse manual 2D
slices is thought to yield promising results, but manual labeling has many
false negative labels (abnormal annotations), which is detrimental to training
and consequently to detection performance. Motivated to train 3D fault
segmentation networks under sparse 2D labels while suppressing false negative
labels, we analyze the training process gradient and propose the Mask Dice (MD)
loss. Moreover, the fault is an edge feature, and current encoder-decoder
architectures widely used for fault detection (e.g., U-shape network) are not
conducive to edge representation. Consequently, Fault-Net is proposed, which is
designed for the characteristics of faults, employs high-resolution propagation
features, and embeds MultiScale Compression Fusion block to fuse multi-scale
information, which allows the edge information to be fully preserved during
propagation and fusion, thus enabling advanced performance via few
computational resources. Experimental demonstrates that MD loss supports the
inclusion of human experience in training and suppresses false negative labels
therein, enabling baseline models to improve performance and generalize to more
surveys. Fault-Net is capable to provide a more stable and reliable
interpretation of faults, it uses extremely low computational resources and
inference is significantly faster than other models. Our method indicates
optimal performance in comparison with several mainstream methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MixFace: Improving Face Verification Focusing on Fine-grained Conditions. (arXiv:2111.01717v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01717">
<div class="article-summary-box-inner">
<span><p>The performance of face recognition has become saturated for public benchmark
datasets such as LFW, CFP-FP, and AgeDB, owing to the rapid advances in CNNs.
However, the effects of faces with various fine-grained conditions on FR models
have not been investigated because of the absence of such datasets. This paper
analyzes their effects in terms of different conditions and loss functions
using K-FACE, a recently introduced FR dataset with fine-grained conditions. We
propose a novel loss function, MixFace, that combines classification and metric
losses. The superiority of MixFace in terms of effectiveness and robustness is
demonstrated experimentally on various benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TorchGeo: Deep Learning With Geospatial Data. (arXiv:2111.08872v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08872">
<div class="article-summary-box-inner">
<span><p>Remotely sensed geospatial data are critical for applications including
precision agriculture, urban planning, disaster monitoring and response, and
climate change research, among others. Deep learning methods are particularly
promising for modeling many remote sensing tasks given the success of deep
neural networks in similar computer vision tasks and the sheer volume of
remotely sensed imagery available. However, the variance in data collection
methods and handling of geospatial metadata make the application of deep
learning methodology to remotely sensed data nontrivial. For example, satellite
imagery often includes additional spectral bands beyond red, green, and blue
and must be joined to other geospatial data sources that can have differing
coordinate systems, bounds, and resolutions. To help realize the potential of
deep learning for remote sensing applications, we introduce TorchGeo, a Python
library for integrating geospatial data into the PyTorch deep learning
ecosystem. TorchGeo provides data loaders for a variety of benchmark datasets,
composable datasets for generic geospatial data sources, samplers for
geospatial data, and transforms that work with multispectral imagery. TorchGeo
is also the first library to provide pre-trained models for multispectral
satellite imagery (e.g., models that use all bands from the Sentinel-2
satellites), allowing for advances in transfer learning on downstream remote
sensing tasks with limited labeled data. We use TorchGeo to create reproducible
benchmark results on existing datasets and benchmark our proposed method for
preprocessing geospatial imagery on the fly. TorchGeo is open source and
available on GitHub: https://github.com/microsoft/torchgeo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Self and Semi-Supervised Methods for Remote Sensing Segmentation Tasks. (arXiv:2111.10079v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.10079">
<div class="article-summary-box-inner">
<span><p>Self- and semi-supervised machine learning techniques leverage unlabeled data
for improving downstream task performance. These methods are especially
valuable for remote sensing tasks where producing labeled ground truth datasets
can be prohibitively expensive but there is easy access to a wealth of
unlabeled imagery. We perform a rigorous evaluation of SimCLR, a
self-supervised method, and FixMatch, a semi-supervised method, on three remote
sensing tasks: riverbed segmentation, land cover mapping, and flood mapping. We
quantify performance improvements on these remote sensing segmentation tasks
when additional imagery outside of the original supervised dataset is made
available for training. We also design experiments to test the effectiveness of
these techniques when the test set is domain shifted to sample different
geographic areas compared to the training and validation sets. We find that
such techniques significantly improve generalization performance when labeled
data is limited and there are geographic domain shifts between the training
data and the validation/test data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Segment-level Semantics for Online Phase Recognition from Surgical Videos. (arXiv:2111.11044v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11044">
<div class="article-summary-box-inner">
<span><p>Automatic surgical phase recognition plays a vital role in robot-assisted
surgeries. Existing methods ignored a pivotal problem that surgical phases
should be classified by learning segment-level semantics instead of solely
relying on frame-wise information. This paper presents a segment-attentive
hierarchical consistency network (SAHC) for surgical phase recognition from
videos. The key idea is to extract hierarchical high-level semantic-consistent
segments and use them to refine the erroneous predictions caused by ambiguous
frames. To achieve it, we design a temporal hierarchical network to generate
hierarchical high-level segments. Then, we introduce a hierarchical
segment-frame attention module to capture relations between the low-level
frames and high-level segments. By regularizing the predictions of frames and
their corresponding segments via a consistency loss, the network can generate
semantic-consistent segments and then rectify the misclassified predictions
caused by ambiguous low-level frames. We validate SAHC on two public surgical
video datasets, i.e., the M2CAI16 challenge dataset and the Cholec80 dataset.
Experimental results show that our method outperforms previous
state-of-the-arts and ablation studies prove the effectiveness of our proposed
modules. Our code has been released at: https://github.com/xmed-lab/SAHC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Distilled Self-Supervised Representation Learning. (arXiv:2111.12958v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12958">
<div class="article-summary-box-inner">
<span><p>State-of-the-art frameworks in self-supervised learning have recently shown
that fully utilizing transformer-based models can lead to performance boost
compared to conventional CNN models. Striving to maximize the mutual
information of two views of an image, existing works apply a contrastive loss
to the final representations. Motivated by self-distillation in the supervised
regime, we further exploit this by allowing the intermediate representations to
learn from the final layer via the contrastive loss. Through self-distillation,
the intermediate layers are better suited for instance discrimination, making
the performance of an early-exited sub-network not much degraded from that of
the full network. This renders the pretext task easier also for the final
layer, lead to better representations. Our method, Self-Distilled
Self-Supervised Learning (SDSSL), outperforms competitive baselines (SimCLR,
BYOL and MoCo v3) using ViT on various tasks and datasets. In the linear
evaluation and k-NN protocol, SDSSL not only leads to superior performance in
the final layers, but also in most of the lower layers. Furthermore, positive
and negative alignments are used to explain how representations are formed more
effectively. Code will be available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SwinBERT: End-to-End Transformers with Sparse Attention for Video Captioning. (arXiv:2111.13196v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13196">
<div class="article-summary-box-inner">
<span><p>The canonical approach to video captioning dictates a caption generation
model to learn from offline-extracted dense video features. These feature
extractors usually operate on video frames sampled at a fixed frame rate and
are often trained on image/video understanding tasks, without adaption to video
captioning data. In this work, we present SwinBERT, an end-to-end
transformer-based model for video captioning, which takes video frame patches
directly as inputs, and outputs a natural language description. Instead of
leveraging multiple 2D/3D feature extractors, our method adopts a video
transformer to encode spatial-temporal representations that can adapt to
variable lengths of video input without dedicated design for different frame
rates. Based on this model architecture, we show that video captioning can
benefit significantly from more densely sampled video frames as opposed to
previous successes with sparsely sampled video frames for video-and-language
understanding tasks (e.g., video question answering). Moreover, to avoid the
inherent redundancy in consecutive video frames, we propose adaptively learning
a sparse attention mask and optimizing it for task-specific performance
improvement through better long-range video sequence modeling. Through
extensive experiments on 5 video captioning datasets, we show that SwinBERT
achieves across-the-board performance improvements over previous methods, often
by a large margin. The learned sparse attention masks in addition push the
limit to new state of the arts, and can be transferred between different video
lengths and between different datasets. Code is available at
https://github.com/microsoft/SwinBERT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HEAT: Holistic Edge Attention Transformer for Structured Reconstruction. (arXiv:2111.15143v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.15143">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel attention-based neural network for structured
reconstruction, which takes a 2D raster image as an input and reconstructs a
planar graph depicting an underlying geometric structure. The approach detects
corners and classifies edge candidates between corners in an end-to-end manner.
Our contribution is a holistic edge classification architecture, which 1)
initializes the feature of an edge candidate by a trigonometric positional
encoding of its end-points; 2) fuses image feature to each edge candidate by
deformable attention; 3) employs two weight-sharing Transformer decoders to
learn holistic structural patterns over the graph edge candidates; and 4) is
trained with a masked learning strategy. The corner detector is a variant of
the edge classification architecture, adapted to operate on pixels as corner
candidates. We conduct experiments on two structured reconstruction tasks:
outdoor building architecture and indoor floorplan planar graph reconstruction.
Extensive qualitative and quantitative evaluations demonstrate the superiority
of our approach over the state of the art. Code and pre-trained models are
available at https://heat-structured-reconstruction.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seeking Salient Facial Regions for Cross-Database Micro-Expression Recognition. (arXiv:2111.15361v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.15361">
<div class="article-summary-box-inner">
<span><p>Cross-Database Micro-Expression Recognition (CDMER) aims to develop the
Micro-Expression Recognition (MER) methods that satisfy different conditions
(equipment, subjects, and scenes) in practical application, i.e., the MER
method of strong domain adaption ability. CDMER faces two obstacles: 1) the
severe feature distribution gap between the training and test databases and 2)
the feature representation bottleneck for micro-expression (ME) such local and
subtle facial expressions. To solve these obstacles, this paper proposes a
novel Transfer Group Sparse Regression method, namely TGSR, which seeks and
selects those salient facial regions to 1) promote a more precise measurement
of the difference between source and target databases by the operation in the
feature level to alleviate their difference better, and to 2) improve the
extracted hand-crafted feature to be more effective and explicable for better
MER. We use two public micro-expression databases, i.e., CASME II and SMIC, to
evaluate the proposed TGSR. Experimental results show that TGSR learns the
discriminative feature and outperforms most state-of-the-art
subspace-learning-based domain adaption methods for CDMER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Margin Calibration for Long-Tailed Visual Recognition. (arXiv:2112.07225v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07225">
<div class="article-summary-box-inner">
<span><p>The long-tailed class distribution in visual recognition tasks poses great
challenges for neural networks on how to handle the biased predictions between
head and tail classes, i.e., the model tends to classify tail classes as head
classes. While existing research focused on data resampling and loss function
engineering, in this paper, we take a different perspective: the classification
margins. We study the relationship between the margins and logits
(classification scores) and empirically observe the biased margins and the
biased logits are positively correlated. We propose MARC, a simple yet
effective MARgin Calibration function to dynamically calibrate the biased
margins for unbiased logits. We validate MARC through extensive experiments on
common long-tailed benchmarks including CIFAR-LT, ImageNet-LT, Places-LT, and
iNaturalist-LT. Experimental results demonstrate that our MARC achieves
favorable results on these benchmarks. In addition, MARC is extremely easy to
implement with just three lines of code. We hope this simple method will
motivate people to rethink the biased margins and biased logits in long-tailed
visual recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pure Noise to the Rescue of Insufficient Data: Improving Imbalanced Classification by Training on Random Noise Images. (arXiv:2112.08810v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08810">
<div class="article-summary-box-inner">
<span><p>Despite remarkable progress on visual recognition tasks, deep neural-nets
still struggle to generalize well when training data is scarce or highly
imbalanced, rendering them extremely vulnerable to real-world examples. In this
paper, we present a surprisingly simple yet highly effective method to mitigate
this limitation: using pure noise images as additional training data. Unlike
the common use of additive noise or adversarial noise for data augmentation, we
propose an entirely different perspective by directly training on pure random
noise images. We present a new Distribution-Aware Routing Batch Normalization
layer (DAR-BN), which enables training on pure noise images in addition to
natural images within the same network. This encourages generalization and
suppresses overfitting. Our proposed method significantly improves imbalanced
classification performance, obtaining state-of-the-art results on a large
variety of long-tailed image classification datasets (CIFAR-10-LT,
CIFAR-100-LT, ImageNet-LT, Places-LT, and CelebA-5). Furthermore, our method is
extremely simple and easy to use as a general new augmentation tool (on top of
existing augmentations), and can be incorporated in any training scheme. It
does not require any specialized data generation or training procedures, thus
keeping training fast and efficient.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constrained Gradient Descent: A Powerful and Principled Evasion Attack Against Neural Networks. (arXiv:2112.14232v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.14232">
<div class="article-summary-box-inner">
<span><p>We propose new, more efficient targeted white-box attacks against deep neural
networks. Our attacks better align with the attacker's goal: (1) tricking a
model to assign higher probability to the target class than to any other class,
while (2) staying within an $\epsilon$-distance of the attacked input. First,
we demonstrate a loss function that explicitly encodes (1) and show that
Auto-PGD finds more attacks with it. Second, we propose a new attack method,
Constrained Gradient Descent (CGD), using a refinement of our loss function
that captures both (1) and (2). CGD seeks to satisfy both attacker objectives
-- misclassification and bounded $\ell_{p}$-norm -- in a principled manner, as
part of the optimization, instead of via ad hoc post-processing techniques
(e.g., projection or clipping). We show that CGD is more successful on CIFAR10
(0.9--4.2%) and ImageNet (8.6--13.6%) than state-of-the-art attacks while
consuming less time (11.4--18.8%). Statistical tests confirm that our attack
outperforms others against leading defenses on different datasets and values of
$\epsilon$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Category Discovery. (arXiv:2201.02609v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02609">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider a highly general image recognition setting
wherein, given a labelled and unlabelled set of images, the task is to
categorize all images in the unlabelled set. Here, the unlabelled images may
come from labelled classes or from novel ones. Existing recognition methods are
not able to deal with this setting, because they make several restrictive
assumptions, such as the unlabelled instances only coming from known - or
unknown - classes, and the number of unknown classes being known a-priori. We
address the more unconstrained setting, naming it 'Generalized Category
Discovery', and challenge all these assumptions. We first establish strong
baselines by taking state-of-the-art algorithms from novel category discovery
and adapting them for this task. Next, we propose the use of vision
transformers with contrastive representation learning for this open-world
setting. We then introduce a simple yet effective semi-supervised $k$-means
method to cluster the unlabelled data into seen and unseen classes
automatically, substantially outperforming the baselines. Finally, we also
propose a new approach to estimate the number of classes in the unlabelled
data. We thoroughly evaluate our approach on public datasets for generic object
classification and on fine-grained datasets, leveraging the recent Semantic
Shift Benchmark suite. Project page at
https://www.robots.ox.ac.uk/~vgg/research/gcd
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DynaMixer: A Vision MLP Architecture with Dynamic Mixing. (arXiv:2201.12083v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12083">
<div class="article-summary-box-inner">
<span><p>Recently, MLP-like vision models have achieved promising performances on
mainstream visual recognition tasks. In contrast with vision transformers and
CNNs, the success of MLP-like models shows that simple information fusion
operations among tokens and channels can yield a good representation power for
deep recognition models. However, existing MLP-like models fuse tokens through
static fusion operations, lacking adaptability to the contents of the tokens to
be mixed. Thus, customary information fusion procedures are not effective
enough. To this end, this paper presents an efficient MLP-like network
architecture, dubbed DynaMixer, resorting to dynamic information fusion.
Critically, we propose a procedure, on which the DynaMixer model relies, to
dynamically generate mixing matrices by leveraging the contents of all the
tokens to be mixed. To reduce the time complexity and improve the robustness, a
dimensionality reduction technique and a multi-segment fusion mechanism are
adopted. Our proposed DynaMixer model (97M parameters) achieves 84.3\% top-1
accuracy on the ImageNet-1K dataset without extra training data, performing
favorably against the state-of-the-art vision MLP models. When the number of
parameters is reduced to 26M, it still achieves 82.7\% top-1 accuracy,
surpassing the existing MLP-like models with a similar capacity. The code is
available at \url{https://github.com/ziyuwwang/DynaMixer}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Proximal Denoiser for Convergent Plug-and-Play Optimization with Nonconvex Regularization. (arXiv:2201.13256v4 [math.OC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.13256">
<div class="article-summary-box-inner">
<span><p>Plug-and-Play (PnP) methods solve ill-posed inverse problems through
iterative proximal algorithms by replacing a proximal operator by a denoising
operation. When applied with deep neural network denoisers, these methods have
shown state-of-the-art visual performance for image restoration problems.
However, their theoretical convergence analysis is still incomplete. Most of
the existing convergence results consider nonexpansive denoisers, which is
non-realistic, or limit their analysis to strongly convex data-fidelity terms
in the inverse problem to solve. Recently, it was proposed to train the
denoiser as a gradient descent step on a functional parameterized by a deep
neural network. Using such a denoiser guarantees the convergence of the PnP
version of the Half-Quadratic-Splitting (PnP-HQS) iterative algorithm. In this
paper, we show that this gradient denoiser can actually correspond to the
proximal operator of another scalar function. Given this new result, we exploit
the convergence theory of proximal algorithms in the nonconvex setting to
obtain convergence results for PnP-PGD (Proximal Gradient Descent) and PnP-ADMM
(Alternating Direction Method of Multipliers). When built on top of a smooth
gradient denoiser, we show that PnP-PGD and PnP-ADMM are convergent and target
stationary points of an explicit functional. These convergence results are
confirmed with numerical experiments on deblurring, super-resolution and
inpainting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fishing for User Data in Large-Batch Federated Learning via Gradient Magnification. (arXiv:2202.00580v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00580">
<div class="article-summary-box-inner">
<span><p>Federated learning (FL) has rapidly risen in popularity due to its promise of
privacy and efficiency. Previous works have exposed privacy vulnerabilities in
the FL pipeline by recovering user data from gradient updates. However,
existing attacks fail to address realistic settings because they either 1)
require toy settings with very small batch sizes, or 2) require unrealistic and
conspicuous architecture modifications. We introduce a new strategy that
dramatically elevates existing attacks to operate on batches of arbitrarily
large size, and without architectural modifications. Our model-agnostic
strategy only requires modifications to the model parameters sent to the user,
which is a realistic threat model in many scenarios. We demonstrate the
strategy in challenging large-scale settings, obtaining high-fidelity data
extraction in both cross-device and cross-silo federated learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Make Some Noise: Reliable and Efficient Single-Step Adversarial Training. (arXiv:2202.01181v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01181">
<div class="article-summary-box-inner">
<span><p>Recently, Wong et al. showed that adversarial training with single-step FGSM
leads to a characteristic failure mode named catastrophic overfitting (CO), in
which a model becomes suddenly vulnerable to multi-step attacks. They showed
that adding a random perturbation prior to FGSM (RS-FGSM) seemed to be
sufficient to prevent CO. However, Andriushchenko and Flammarion observed that
RS-FGSM still leads to CO for larger perturbations, and proposed an expensive
regularizer (GradAlign) to avoid CO. In this work, we methodically revisit the
role of noise and clipping in single-step adversarial training. Contrary to
previous intuitions, we find that using a stronger noise around the clean
sample combined with not clipping is highly effective in avoiding CO for large
perturbation radii. Based on these observations, we then propose Noise-FGSM
(N-FGSM) that, while providing the benefits of single-step adversarial
training, does not suffer from CO. Empirical analyses on a large suite of
experiments show that N-FGSM is able to match or surpass the performance of
previous single-step methods while achieving a 3$\times$ speed-up. Code can be
found in https://github.com/pdejorge/N-FGSM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Images: Label Noise Transition Matrix Estimation for Tasks with Lower-Quality Features. (arXiv:2202.01273v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01273">
<div class="article-summary-box-inner">
<span><p>The label noise transition matrix, denoting the transition probabilities from
clean labels to noisy labels, is crucial for designing statistically robust
solutions. Existing estimators for noise transition matrices, e.g., using
either anchor points or clusterability, focus on computer vision tasks that are
relatively easier to obtain high-quality representations. We observe that tasks
with lower-quality features fail to meet the anchor-point or clusterability
condition, due to the coexistence of both uninformative and informative
representations. To handle this issue, we propose a generic and practical
information-theoretic approach to down-weight the less informative parts of the
lower-quality features. This improvement is crucial to identifying and
estimating the label noise transition matrix. The salient technical challenge
is to compute the relevant information-theoretical metrics using only noisy
labels instead of clean ones. We prove that the celebrated $f$-mutual
information measure can often preserve the order when calculated using noisy
labels. We then build our transition matrix estimator using this distilled
version of features. The necessity and effectiveness of the proposed method are
also demonstrated by evaluating the estimation error on a varied set of tabular
data and text classification tasks with lower-quality features. Code is
available at github.com/UCSC-REAL/BeyondImages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic defect segmentation by unsupervised anomaly learning. (arXiv:2202.02998v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02998">
<div class="article-summary-box-inner">
<span><p>This paper addresses the problem of defect segmentation in semiconductor
manufacturing. The input of our segmentation is a scanning-electron-microscopy
(SEM) image of the candidate defect region. We train a U-net shape network to
segment defects using a dataset of clean background images. The samples of the
training phase are produced automatically such that no manual labeling is
required. To enrich the dataset of clean background samples, we apply defect
implant augmentation. To that end, we apply a copy-and-paste of a random image
patch in the clean specimen. To improve the robustness of the unlabeled data
scenario, we train the features of the network with unsupervised learning
methods and loss functions. Our experiments show that we succeed to segment
real defects with high quality, even though our dataset contains no defect
examples. Our approach performs accurately also on the problem of supervised
and labeled defect segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistency-Regularized Region-Growing Network for Semantic Segmentation of Urban Scenes with Point-Level Annotations. (arXiv:2202.03740v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03740">
<div class="article-summary-box-inner">
<span><p>Deep learning algorithms have obtained great success in semantic segmentation
of very high-resolution (VHR) images. Nevertheless, training these models
generally requires a large amount of accurate pixel-wise annotations, which is
very laborious and time-consuming to collect. To reduce the annotation burden,
this paper proposes a consistency-regularized region-growing network (CRGNet)
to achieve semantic segmentation of VHR images with point-level annotations.
The key idea of CRGNet is to iteratively select unlabeled pixels with high
confidence to expand the annotated area from the original sparse points.
However, since there may exist some errors and noises in the expanded
annotations, directly learning from them may mislead the training of the
network. To this end, we further propose the consistency regularization
strategy, where a base classifier and an expanded classifier are employed.
Specifically, the base classifier is supervised by the original sparse
annotations, while the expanded classifier aims to learn from the expanded
annotations generated by the base classifier with the region-growing mechanism.
The consistency regularization is thereby achieved by minimizing the
discrepancy between the predictions from both the base and the expanded
classifiers. We find such a simple regularization strategy is yet very useful
to control the quality of the region-growing mechanism. Extensive experiments
on two benchmark datasets demonstrate that the proposed CRGNet significantly
outperforms the existing state-of-the-art methods. Codes and pre-trained models
are available online (https://github.com/YonghaoXu/CRGNet).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NIMBLE: A Non-rigid Hand Model with Bones and Muscles. (arXiv:2202.04533v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04533">
<div class="article-summary-box-inner">
<span><p>Emerging Metaverse applications demand reliable, accurate, and photorealistic
reproductions of human hands to perform sophisticated operations as if in the
physical world. While real human hand represents one of the most intricate
coordination between bones, muscle, tendon, and skin, state-of-the-art
techniques unanimously focus on modeling only the skeleton of the hand. In this
paper, we present NIMBLE, a novel parametric hand model that includes the
missing key components, bringing 3D hand model to a new level of realism. We
first annotate muscles, bones and skins on the recent Magnetic Resonance
Imaging hand (MRI-Hand) dataset and then register a volumetric template hand
onto individual poses and subjects within the dataset. NIMBLE consists of 20
bones as triangular meshes, 7 muscle groups as tetrahedral meshes, and a skin
mesh. Via iterative shape registration and parameter learning, it further
produces shape blend shapes, pose blend shapes, and a joint regressor. We
demonstrate applying NIMBLE to modeling, rendering, and visual inference tasks.
By enforcing the inner bones and muscles to match anatomic and kinematic rules,
NIMBLE can animate 3D hands to new poses at unprecedented realism. To model the
appearance of skin, we further construct a photometric HandStage to acquire
high-quality textures and normal maps to model wrinkles and palm print.
Finally, NIMBLE also benefits learning-based hand pose and shape estimation by
either synthesizing rich data or acting directly as a differentiable layer in
the inference network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VLP: A Survey on Vision-Language Pre-training. (arXiv:2202.09061v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09061">
<div class="article-summary-box-inner">
<span><p>In the past few years, the emergence of pre-training models has brought
uni-modal fields such as computer vision (CV) and natural language processing
(NLP) to a new era. Substantial works have shown they are beneficial for
downstream uni-modal tasks and avoid training a new model from scratch. So can
such pre-trained models be applied to multi-modal tasks? Researchers have
explored this problem and made significant progress. This paper surveys recent
advances and new frontiers in vision-language pre-training (VLP), including
image-text and video-text pre-training. To give readers a better overall grasp
of VLP, we first review its recent advances from five aspects: feature
extraction, model architecture, pre-training objectives, pre-training datasets,
and downstream tasks. Then, we summarize the specific VLP models in detail.
Finally, we discuss the new frontiers in VLP. To the best of our knowledge,
this is the first survey on VLP. We hope that this survey can shed light on
future research in the VLP field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PointMatch: A Consistency Training Framework for Weakly Supervised Semantic Segmentation of 3D Point Clouds. (arXiv:2202.10705v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10705">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation of point cloud usually relies on dense annotation that
is exhausting and costly, so it attracts wide attention to investigate
solutions for the weakly supervised scheme with only sparse points annotated.
Existing works start from the given labels and propagate them to highly-related
but unlabeled points, with the guidance of data, e.g. intra-point relation.
However, it suffers from (i) the inefficient exploitation of data information,
and (ii) the strong reliance on labels thus is easily suppressed when given
much fewer annotations. Therefore, we propose a novel framework, PointMatch,
that stands on both data and label, by applying consistency regularization to
sufficiently probe information from data itself and leveraging weak labels as
assistance at the same time. By doing so, meaningful information can be learned
from both data and label for better representation learning, which also enables
the model more robust to the extent of label sparsity. Simple yet effective,
the proposed PointMatch achieves the state-of-the-art performance under various
weakly-supervised schemes on both ScanNet-v2 and S3DIS datasets, especially on
the settings with extremely sparse labels, e.g. surpassing SQN by 21.2% and
17.2% on the 0.01% and 0.1% setting of ScanNet-v2, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Confidence Calibration for Object Detection and Segmentation. (arXiv:2202.12785v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.12785">
<div class="article-summary-box-inner">
<span><p>Calibrated confidence estimates obtained from neural networks are crucial,
particularly for safety-critical applications such as autonomous driving or
medical image diagnosis. However, although the task of confidence calibration
has been investigated on classification problems, thorough investigations on
object detection and segmentation problems are still missing. Therefore, we
focus on the investigation of confidence calibration for object detection and
segmentation models in this chapter. We introduce the concept of multivariate
confidence calibration that is an extension of well-known calibration methods
to the task of object detection and segmentation. This allows for an extended
confidence calibration that is also aware of additional features such as
bounding box/pixel position, shape information, etc. Furthermore, we extend the
expected calibration error (ECE) to measure miscalibration of object detection
and segmentation models. We examine several network architectures on MS COCO as
well as on Cityscapes and show that especially object detection as well as
instance segmentation models are intrinsically miscalibrated given the
introduced definition of calibration. Using our proposed calibration methods,
we have been able to improve calibration so that it also has a positive impact
on the quality of segmentation masks as well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Scene Flow Estimation with 4-D Automotive Radar. (arXiv:2203.01137v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01137">
<div class="article-summary-box-inner">
<span><p>Scene flow allows autonomous vehicles to reason about the arbitrary motion of
multiple independent objects which is the key to long-term mobile autonomy.
While estimating the scene flow from LiDAR has progressed recently, it remains
largely unknown how to estimate the scene flow from a 4-D radar - an
increasingly popular automotive sensor for its robustness against adverse
weather and lighting conditions. Compared with the LiDAR point clouds, radar
data are drastically sparser, noisier and in much lower resolution. Annotated
datasets for radar scene flow are also in absence and costly to acquire in the
real world. These factors jointly pose the radar scene flow estimation as a
challenging problem. This work aims to address the above challenges and
estimate scene flow from 4-D radar point clouds by leveraging self-supervised
learning. A robust scene flow estimation architecture and three novel losses
are bespoken designed to cope with intractable radar data. Real-world
experimental results validate that our method is able to robustly estimate the
radar scene flow in the wild and effectively supports the downstream task of
motion segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuroFluid: Fluid Dynamics Grounding with Particle-Driven Neural Radiance Fields. (arXiv:2203.01762v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01762">
<div class="article-summary-box-inner">
<span><p>Deep learning has shown great potential for modeling the physical dynamics of
complex particle systems such as fluids. Existing approaches, however, require
the supervision of consecutive particle properties, including positions and
velocities. In this paper, we consider a partially observable scenario known as
fluid dynamics grounding, that is, inferring the state transitions and
interactions within the fluid particle systems from sequential visual
observations of the fluid surface. We propose a differentiable two-stage
network named NeuroFluid. Our approach consists of (i) a particle-driven neural
renderer, which involves fluid physical properties into the volume rendering
function, and (ii) a particle transition model optimized to reduce the
differences between the rendered and the observed images. NeuroFluid provides
the first solution to unsupervised learning of particle-based fluid dynamics by
training these two models jointly. It is shown to reasonably estimate the
underlying physics of fluids with different initial shapes, viscosity, and
densities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object-centric and memory-guided normality reconstruction for video anomaly detection. (arXiv:2203.03677v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03677">
<div class="article-summary-box-inner">
<span><p>This paper addresses video anomaly detection problem for videosurveillance.
Due to the inherent rarity and heterogeneity of abnormal events, the problem is
viewed as a normality modeling strategy, in which our model learns
object-centric normal patterns without seeing anomalous samples during
training. The main contributions consist in coupling pretrained object-level
action features prototypes with a cosine distance-based anomaly estimation
function, therefore extending previous methods by introducing additional
constraints to the mainstream reconstruction-based strategy. Our framework
leverages both appearance and motion information to learn object-level behavior
and captures prototypical patterns within a memory module. Experiments on
several well-known datasets demonstrate the effectiveness of our method as it
outperforms current state-of-the-art on most relevant spatio-temporal
evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Audio-Visual MLP for Scoring Sport. (arXiv:2203.03990v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03990">
<div class="article-summary-box-inner">
<span><p>Figure skating scoring is a challenging task because it requires judging
players' technical moves as well as coordination with the background music.
Prior learning-based work cannot solve it well for two reasons: 1) each move in
figure skating changes quickly, hence simply applying traditional frame
sampling will lose a lot of valuable information, especially in a 3-5 minutes
lasting video, so an extremely long-range representation learning is necessary;
2) prior methods rarely considered the critical audio-visual relationship in
their models. Thus, we introduce a multimodal MLP architecture, named
Skating-Mixer. It extends the MLP-Mixer-based framework into a multimodal
fashion and effectively learns long-term representations through our designed
memory recurrent unit (MRU). Aside from the model, we also collected a
high-quality audio-visual FS1000 dataset, which contains over 1000 videos on 8
types of programs with 7 different rating metrics, overtaking other datasets in
both quantity and diversity. Experiments show the proposed method outperforms
SOTAs over all major metrics on the public Fis-V and our FS1000 dataset. In
addition, we include an analysis applying our method to recent competitions
that occurred in Beijing 2022 Winter Olympic Games, proving our method has
strong robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NaviAirway: a Bronchiole-sensitive Deep Learning-based Airway Segmentation Pipeline. (arXiv:2203.04294v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.04294">
<div class="article-summary-box-inner">
<span><p>Airway segmentation is essential for chest CT image analysis. However, it
remains a challenging task because of the intrinsic complex tree-like structure
and imbalanced sizes of airway branches. Current deep learning-based methods
focus on model structure design while the potential of training strategy and
loss function have not been fully explored. Therefore, we present a simple yet
effective airway segmentation pipeline, denoted NaviAirway, which finds finer
bronchioles with a bronchiole-sensitive loss function and a
human-vision-inspired iterative training strategy. Experimental results show
that NaviAirway outperforms existing methods, particularly in identification of
higher generation bronchioles and robustness to new CT scans. Besides,
NaviAirway is general. It can be combined with different backbone models and
significantly improve their performance. Moreover, we propose two new metrics
(Branch Detected and Tree-length Detected) for a more comprehensive and fairer
evaluation of deep learning-based airway segmentation approaches. NaviAirway
can generate airway roadmap for Navigation Bronchoscopy and can also be applied
to other scenarios when segmenting fine and long tubular structures in
biomedical images. The code is publicly available on
https://github.com/AntonotnaWang/NaviAirway.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another in Neural Networks. (arXiv:2203.04466v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.04466">
<div class="article-summary-box-inner">
<span><p>Neural networks tend to achieve better accuracy with training if they are
larger -- even if the resulting models are overparameterized. Nevertheless,
carefully removing such excess parameters before, during, or after training may
also produce models with similar or even improved accuracy. In many cases, that
can be curiously achieved by heuristics as simple as removing a percentage of
the weights with the smallest absolute value -- even though magnitude is not a
perfect proxy for weight relevance. With the premise that obtaining
significantly better performance from pruning depends on accounting for the
combined effect of removing multiple weights, we revisit one of the classic
approaches for impact-based pruning: the Optimal Brain Surgeon(OBS). We propose
a tractable heuristic for solving the combinatorial extension of OBS, in which
we select weights for simultaneous removal, as well as a systematic update of
the remaining weights. Our selection method outperforms other methods under
high sparsity, and the weight update is advantageous even when combined with
the other methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Instance Domain Adaptation. (arXiv:2203.05028v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.05028">
<div class="article-summary-box-inner">
<span><p>Most existing studies on unsupervised domain adaptation (UDA) assume that
each domain's training samples come with domain labels (e.g., painting, photo).
Samples from each domain are assumed to follow the same distribution and the
domain labels are exploited to learn domain-invariant features via feature
alignment. However, such an assumption often does not hold true -- there often
exist numerous finer-grained domains (e.g., dozens of modern painting styles
have been developed, each differing dramatically from those of the classic
styles). Therefore, forcing feature distribution alignment across each
artificially-defined and coarse-grained domain can be ineffective. In this
paper, we address both single-source and multi-source UDA from a completely
different perspective, which is to view each instance as a fine domain. Feature
alignment across domains is thus redundant. Instead, we propose to perform
dynamic instance domain adaptation (DIDA). Concretely, a dynamic neural network
with adaptive convolutional kernels is developed to generate instance-adaptive
residuals to adapt domain-agnostic deep features to each individual instance.
This enables a shared classifier to be applied to both source and target domain
data without relying on any domain annotation. Further, instead of imposing
intricate feature alignment losses, we adopt a simple semi-supervised learning
paradigm using only a cross-entropy loss for both labeled source and pseudo
labeled target data. Our model, dubbed DIDA-Net, achieves state-of-the-art
performance on several commonly used single-source and multi-source UDA
datasets including Digits, Office-Home, DomainNet, Digit-Five, and PACS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supervised segmentation of NO2 plumes from individual ships using TROPOMI satellite data. (arXiv:2203.06993v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.06993">
<div class="article-summary-box-inner">
<span><p>Starting from 2021, the International Maritime Organization significantly
tightened the $\text{NO}_\text{x}$ emission requirements for ships entering the
Baltic and the North Sea waters. Since all methods currently used for the
ships' compliance monitoring are costly and require proximity to the ship, the
performance of global and continuous monitoring of the emission standards'
fulfillment has been impossible up to now. A promising approach is the use of
remote sensing with the recently launched TROPOMI/S5P satellite. Due to its
unprecedentedly high spatial resolution, it allows for the visual distinction
of $\text{NO}_\text{2}$ plumes of individual ships. To successfully deploy a
compliance monitoring system that is based on TROPOMI data, an automated
procedure for the attribution of $\text{NO}_\text{2}$ to individual ships has
to be developed. However, due to the extremely low signal-to-noise ratio,
interference with the signal from other - often stronger - sources, and the
absence of ground truth, the task is very challenging.
</p>
<p>This is the first study proposing an application of supervised learning for
the segmentation of emission plumes produced by individual ships. As such, it
is the first step towards an automated procedure for global ship compliance
monitoring using remote sensing data. To this end, we developed a feature
construction method allowing the application of multivariate models on spatial
data. We applied several supervised-learning models and benchmark them towards
existing unsupervised solutions of ship-plume segmentation with TROPOMI
satellite data. We showed that the proposed approach leads to significant plume
segmentation improvement and a high correlation with the theoretically derived
measure of the ship's emission potential.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-similarity based Hyperrelation Network for few-shot segmentation. (arXiv:2203.09550v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09550">
<div class="article-summary-box-inner">
<span><p>Few-shot semantic segmentation aims at recognizing the object regions of
unseen categories with only a few annotated examples as supervision. The key to
few-shot segmentation is to establish a robust semantic relationship between
the support and query images and to prevent overfitting. In this paper, we
propose an effective Multi-similarity Hyperrelation Network (MSHNet) to tackle
the few-shot semantic segmentation problem. In MSHNet, we propose a new
Generative Prototype Similarity (GPS), which together with cosine similarity
can establish a strong semantic relation between the support and query images.
The locally generated prototype similarity based on global feature is logically
complementary to the global cosine similarity based on local feature, and the
relationship between the query image and the supported image can be expressed
more comprehensively by using the two similarities simultaneously. In addition,
we propose a Symmetric Merging Block (SMB) in MSHNet to efficiently merge
multi-layer, multi-shot and multi-similarity hyperrelational features. MSHNet
is built on the basis of similarity rather than specific category features,
which can achieve more general unity and effectively reduce overfitting. On two
benchmark semantic segmentation datasets Pascal-5i and COCO-20i, MSHNet
achieves new state-of-the-art performances on 1-shot and 5-shot semantic
segmentation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SepTr: Separable Transformer for Audio Spectrogram Processing. (arXiv:2203.09581v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09581">
<div class="article-summary-box-inner">
<span><p>Following the successful application of vision transformers in multiple
computer vision tasks, these models have drawn the attention of the signal
processing community. This is because signals are often represented as
spectrograms (e.g. through Discrete Fourier Transform) which can be directly
provided as input to vision transformers. However, naively applying
transformers to spectrograms is suboptimal. Since the axes represent distinct
dimensions, i.e. frequency and time, we argue that a better approach is to
separate the attention dedicated to each axis. To this end, we propose the
Separable Transformer (SepTr), an architecture that employs two transformer
blocks in a sequential manner, the first attending to tokens within the same
time interval, and the second attending to tokens within the same frequency
bin. We conduct experiments on three benchmark data sets, showing that our
separable architecture outperforms conventional vision transformers and other
state-of-the-art methods. Unlike standard transformers, SepTr linearly scales
the number of trainable parameters with the input size, thus having a lower
memory footprint. Our code is available as open source at
https://github.com/ristea/septr.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GriTS: Grid table similarity metric for table structure recognition. (arXiv:2203.12555v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12555">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a new class of metric for table structure
recognition (TSR) evaluation, called grid table similarity (GriTS). Unlike
prior metrics, GriTS evaluates the correctness of a predicted table directly in
its natural form as a matrix. To create a similarity measure between matrices,
we generalize the two-dimensional largest common substructure (2D-LCS) problem,
which is NP-hard, to the 2D most similar substructures (2D-MSS) problem and
propose a polynomial-time heuristic for solving it. This algorithm produces
both an upper and a lower bound on the true similarity between matrices. We
show using evaluation on a large real-world dataset that in practice there is
almost no difference between these bounds. We compare GriTS to other metrics
and empirically validate that matrix similarity exhibits more desirable
behavior than alternatives for TSR performance evaluation. Finally, GriTS
unifies all three subtasks of cell topology recognition, cell location
recognition, and cell content recognition within the same framework, which
simplifies the evaluation and enables more meaningful comparisons across
different types of TSR approaches. Code will be released at
https://github.com/microsoft/table-transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Style-Guided Domain Adaptation for Face Presentation Attack Detection. (arXiv:2203.14565v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.14565">
<div class="article-summary-box-inner">
<span><p>Domain adaptation (DA) or domain generalization (DG) for face presentation
attack detection (PAD) has attracted attention recently with its robustness
against unseen attack scenarios. Existing DA/DG-based PAD methods, however,
have not yet fully explored the domain-specific style information that can
provide knowledge regarding attack styles (e.g., materials, background,
illumination and resolution). In this paper, we introduce a novel Style-Guided
Domain Adaptation (SGDA) framework for inference-time adaptive PAD.
Specifically, Style-Selective Normalization (SSN) is proposed to explore the
domain-specific style information within the high-order feature statistics. The
proposed SSN enables the adaptation of the model to the target domain by
reducing the style difference between the target and the source domains.
Moreover, we carefully design Style-Aware Meta-Learning (SAML) to boost the
adaptation ability, which simulates the inference-time adaptation with style
selection process on virtual test domain. In contrast to previous domain
adaptation approaches, our method does not require either additional auxiliary
models (e.g., domain adaptors) or the unlabeled target domain during training,
which makes our method more practical to PAD task. To verify our experiments,
we utilize the public datasets: MSU-MFSD, CASIA-FASD, OULU-NPU and Idiap
REPLAYATTACK. In most assessments, the result demonstrates a notable gap of
performance compared to the conventional DA/DG-based PAD methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BARC: Learning to Regress 3D Dog Shape from Images by Exploiting Breed Information. (arXiv:2203.15536v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.15536">
<div class="article-summary-box-inner">
<span><p>Our goal is to recover the 3D shape and pose of dogs from a single image.
This is a challenging task because dogs exhibit a wide range of shapes and
appearances, and are highly articulated. Recent work has proposed to directly
regress the SMAL animal model, with additional limb scale parameters, from
images. Our method, called BARC (Breed-Augmented Regression using
Classification), goes beyond prior work in several important ways. First, we
modify the SMAL shape space to be more appropriate for representing dog shape.
But, even with a better shape model, the problem of regressing dog shape from
an image is still challenging because we lack paired images with 3D ground
truth. To compensate for the lack of paired data, we formulate novel losses
that exploit information about dog breeds. In particular, we exploit the fact
that dogs of the same breed have similar body shapes. We formulate a novel
breed similarity loss consisting of two parts: One term encourages the shape of
dogs from the same breed to be more similar than dogs of different breeds. The
second one, a breed classification loss, helps to produce recognizable
breed-specific shapes. Through ablation studies, we find that our breed losses
significantly improve shape accuracy over a baseline without them. We also
compare BARC qualitatively to WLDO with a perceptual study and find that our
approach produces dogs that are significantly more realistic. This work shows
that a-priori information about genetic similarity can help to compensate for
the lack of 3D training data. This concept may be applicable to other animal
species or groups of species. Our code is publicly available for research
purposes at https://barc.is.tue.mpg.de/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Generalization of BasicVSR++ to Video Deblurring and Denoising. (arXiv:2204.05308v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05308">
<div class="article-summary-box-inner">
<span><p>The exploitation of long-term information has been a long-standing problem in
video restoration. The recent BasicVSR and BasicVSR++ have shown remarkable
performance in video super-resolution through long-term propagation and
effective alignment. Their success has led to a question of whether they can be
transferred to different video restoration tasks. In this work, we extend
BasicVSR++ to a generic framework for video restoration tasks. In tasks where
inputs and outputs possess identical spatial size, the input resolution is
reduced by strided convolutions to maintain efficiency. With only minimal
changes from BasicVSR++, the proposed framework achieves compelling performance
with great efficiency in various video restoration tasks including video
deblurring and denoising. Notably, BasicVSR++ achieves comparable performance
to Transformer-based approaches with up to 79% of parameter reduction and 44x
speedup. The promising results demonstrate the importance of propagation and
alignment in video restoration tasks beyond just video super-resolution. Code
and models are available at https://github.com/ckkelvinchan/BasicVSR_PlusPlus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models. (arXiv:2204.08790v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08790">
<div class="article-summary-box-inner">
<span><p>Learning visual representations from natural language supervision has
recently shown great promise in a number of pioneering works. In general, these
language-augmented visual models demonstrate strong transferability to a
variety of datasets and tasks. However, it remains challenging to evaluate the
transferablity of these models due to the lack of easy-to-use evaluation
toolkits and public benchmarks. To tackle this, we build ELEVATER (Evaluation
of Language-augmented Visual Task-level Transfer), the first benchmark and
toolkit for evaluating(pre-trained) language-augmented visual models. ELEVATER
is composed of three components. (i) Datasets. As downstream evaluation suites,
it consists of 20 image classification datasets and 35 object detection
datasets, each of which is augmented with external knowledge. (ii) Toolkit. An
automatic hyper-parameter tuning toolkit is developed to facilitate model
evaluation on downstream tasks. (iii) Metrics. A variety of evaluation metrics
are used to measure sample-efficiency (zero-shot and few-shot) and
parameter-efficiency (linear probing and full model fine-tuning). We publicly
release ELEVATER at https://computer-vision-in-the-wild.github.io/ELEVATER/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Moment Retrieval from Text Queries via Single Frame Annotation. (arXiv:2204.09409v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.09409">
<div class="article-summary-box-inner">
<span><p>Video moment retrieval aims at finding the start and end timestamps of a
moment (part of a video) described by a given natural language query. Fully
supervised methods need complete temporal boundary annotations to achieve
promising results, which is costly since the annotator needs to watch the whole
moment. Weakly supervised methods only rely on the paired video and query, but
the performance is relatively poor. In this paper, we look closer into the
annotation process and propose a new paradigm called "glance annotation". This
paradigm requires the timestamp of only one single random frame, which we refer
to as a "glance", within the temporal boundary of the fully supervised
counterpart. We argue this is beneficial because comparing to weak supervision,
trivial cost is added yet more potential in performance is provided. Under the
glance annotation setting, we propose a method named as Video moment retrieval
via Glance Annotation (ViGA) based on contrastive learning. ViGA cuts the input
video into clips and contrasts between clips and queries, in which glance
guided Gaussian distributed weights are assigned to all clips. Our extensive
experiments indicate that ViGA achieves better results than the
state-of-the-art weakly supervised methods by a large margin, even comparable
to fully supervised methods in some cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimMC: Simple Masked Contrastive Learning of Skeleton Representations for Unsupervised Person Re-Identification. (arXiv:2204.09826v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.09826">
<div class="article-summary-box-inner">
<span><p>Recent advances in skeleton-based person re-identification (re-ID) obtain
impressive performance via either hand-crafted skeleton descriptors or skeleton
representation learning with deep learning paradigms. However, they typically
require skeletal pre-modeling and label information for training, which leads
to limited applicability of these methods. In this paper, we focus on
unsupervised skeleton-based person re-ID, and present a generic Simple Masked
Contrastive learning (SimMC) framework to learn effective representations from
unlabeled 3D skeletons for person re-ID. Specifically, to fully exploit
skeleton features within each skeleton sequence, we first devise a masked
prototype contrastive learning (MPC) scheme to cluster the most typical
skeleton features (skeleton prototypes) from different subsequences randomly
masked from raw sequences, and contrast the inherent similarity between
skeleton features and different prototypes to learn discriminative skeleton
representations without using any label. Then, considering that different
subsequences within the same sequence usually enjoy strong correlations due to
the nature of motion continuity, we propose the masked intra-sequence
contrastive learning (MIC) to capture intra-sequence pattern consistency
between subsequences, so as to encourage learning more effective skeleton
representations for person re-ID. Extensive experiments validate that the
proposed SimMC outperforms most state-of-the-art skeleton-based methods. We
further show its scalability and efficiency in enhancing the performance of
existing models. Our codes are available at https://github.com/Kali-Hac/SimMC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning of Object Parts for Semantic Segmentation. (arXiv:2204.13101v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.13101">
<div class="article-summary-box-inner">
<span><p>Progress in self-supervised learning has brought strong general image
representation learning methods. Yet so far, it has mostly focused on
image-level learning. In turn, tasks such as unsupervised image segmentation
have not benefited from this trend as they require spatially-diverse
representations. However, learning dense representations is challenging, as in
the unsupervised context it is not clear how to guide the model to learn
representations that correspond to various potential object categories. In this
paper, we argue that self-supervised learning of object parts is a solution to
this issue. Object parts are generalizable: they are a priori independent of an
object definition, but can be grouped to form objects a posteriori. To this
end, we leverage the recently proposed Vision Transformer's capability of
attending to objects and combine it with a spatially dense clustering task for
fine-tuning the spatial tokens. Our method surpasses the state-of-the-art on
three semantic segmentation benchmarks by 17%-3%, showing that our
representations are versatile under various object definitions. Finally, we
extend this to fully unsupervised segmentation - which refrains completely from
using label information even at test-time - and demonstrate that a simple
method for automatically merging discovered object parts based on community
detection yields substantial gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domino Saliency Metrics: Improving Existing Channel Saliency Metrics with Structural Information. (arXiv:2205.02131v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02131">
<div class="article-summary-box-inner">
<span><p>Channel pruning is used to reduce the number of weights in a Convolutional
Neural Network (CNN). Channel pruning removes slices of the weight tensor so
that the convolution layer remains dense. The removal of these weight slices
from a single layer causes mismatching number of feature maps between layers of
the network. A simple solution is to force the number of feature map between
layers to match through the removal of weight slices from subsequent layers.
This additional constraint becomes more apparent in DNNs with branches where
multiple channels need to be pruned together to keep the network dense. Popular
pruning saliency metrics do not factor in the structural dependencies that
arise in DNNs with branches. We propose Domino metrics (built on existing
channel saliency metrics) to reflect these structural constraints. We test
Domino saliency metrics against the baseline channel saliency metrics on
multiple networks with branches. Domino saliency metrics improved pruning rates
in most tested networks and up to 25% in AlexNet on CIFAR-10.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReFine: Re-randomization before Fine-tuning for Cross-domain Few-shot Learning. (arXiv:2205.05282v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05282">
<div class="article-summary-box-inner">
<span><p>Cross-domain few-shot learning (CD-FSL), where there are few target samples
under extreme differences between source and target domains, has recently
attracted huge attention. For CD-FSL, recent studies generally have developed
transfer learning based approaches that pre-train a neural network on popular
labeled source domain datasets and then transfer it to target domain data.
Although the labeled datasets may provide suitable initial parameters for the
target data, the domain difference between the source and target might hinder
the fine-tuning on the target domain. This paper proposes a simple yet powerful
method that re-randomizes the parameters fitted on the source domain before
adapting to the target data. The re-randomization resets source-specific
parameters of the source pre-trained model and thus facilitates fine-tuning on
the target domain, improving few-shot performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GR-GAN: Gradual Refinement Text-to-image Generation. (arXiv:2205.11273v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11273">
<div class="article-summary-box-inner">
<span><p>A good Text-to-Image model should not only generate high quality images, but
also ensure the consistency between the text and the generated image. Previous
models failed to simultaneously fix both sides well. This paper proposes a
Gradual Refinement Generative Adversarial Network (GR-GAN) to alleviates the
problem efficiently. A GRG module is designed to generate images from low
resolution to high resolution with the corresponding text constraints from
coarse granularity (sentence) to fine granularity (word) stage by stage, a ITM
module is designed to provide image-text matching losses at both sentence-image
level and word-region level for corresponding stages. We also introduce a new
metric Cross-Model Distance (CMD) for simultaneously evaluating image quality
and image-text consistency. Experimental results show GR-GAN significant
outperform previous models, and achieve new state-of-the-art on both FID and
CMD. A detailed analysis demonstrates the efficiency of different generation
stages in GR-GAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Assemble Geometric Shapes. (arXiv:2205.11809v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11809">
<div class="article-summary-box-inner">
<span><p>Assembling parts into an object is a combinatorial problem that arises in a
variety of contexts in the real world and involves numerous applications in
science and engineering. Previous related work tackles limited cases with
identical unit parts or jigsaw-style parts of textured shapes, which greatly
mitigate combinatorial challenges of the problem. In this work, we introduce
the more challenging problem of shape assembly, which involves textureless
fragments of arbitrary shapes with indistinctive junctions, and then propose a
learning-based approach to solving it. We demonstrate the effectiveness on
shape assembly tasks with various scenarios, including the ones with abnormal
fragments (e.g., missing and distorted), the different number of fragments, and
different rotation discretization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Self-supervised Vision Pretraining with Local Masked Reconstruction. (arXiv:2206.00790v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.00790">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning for computer vision has achieved tremendous progress
and improved many downstream vision tasks such as image classification,
semantic segmentation, and object detection. Among these, generative
self-supervised vision learning approaches such as MAE and BEiT show promising
performance. However, their global masked reconstruction mechanism is
computationally demanding. To address this issue, we propose local masked
reconstruction (LoMaR), a simple yet effective approach that performs masked
reconstruction within a small window of 7$\times$7 patches on a simple
Transformer encoder, improving the trade-off between efficiency and accuracy
compared to global masked reconstruction over the entire image. Extensive
experiments show that LoMaR reaches 84.1% top-1 accuracy on ImageNet-1K
classification, outperforming MAE by 0.5%. After finetuning the pretrained
LoMaR on 384$\times$384 images, it can reach 85.4% top-1 accuracy, surpassing
MAE by 0.6%. On MS COCO, LoMaR outperforms MAE by 0.5 $\text{AP}^\text{box}$ on
object detection and 0.5 $\text{AP}^\text{mask}$ on instance segmentation.
LoMaR is especially more computation-efficient on pretraining high-resolution
images, e.g., it is 3.1$\times$ faster than MAE with 0.2% higher classification
accuracy on pretraining 448$\times$448 images. This local masked reconstruction
learning mechanism can be easily integrated into any other generative
self-supervised learning approach. Our code is publicly available in
https://github.com/junchen14/LoMaR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MaxStyle: Adversarial Style Composition for Robust Medical Image Segmentation. (arXiv:2206.01737v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01737">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) have achieved remarkable segmentation
accuracy on benchmark datasets where training and test sets are from the same
domain, yet their performance can degrade significantly on unseen domains,
which hinders the deployment of CNNs in many clinical scenarios. Most existing
works improve model out-of-domain (OOD) robustness by collecting multi-domain
datasets for training, which is expensive and may not always be feasible due to
privacy and logistical issues. In this work, we focus on improving model
robustness using a single-domain dataset only. We propose a novel data
augmentation framework called MaxStyle, which maximizes the effectiveness of
style augmentation for model OOD performance. It attaches an auxiliary
style-augmented image decoder to a segmentation network for robust feature
learning and data augmentation. Importantly, MaxStyle augments data with
improved image style diversity and hardness, by expanding the style space with
noise and searching for the worst-case style composition of latent features via
adversarial training. With extensive experiments on multiple public cardiac and
prostate MR datasets, we demonstrate that MaxStyle leads to significantly
improved out-of-distribution robustness against unseen corruptions as well as
common distribution shifts across multiple, different, unseen sites and unknown
image sequences under both low- and high-training data settings. The code can
be found at https://github.com/cherise215/MaxStyle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NORPPA: NOvel Ringed seal re-identification by Pelage Pattern Aggregation. (arXiv:2206.02498v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02498">
<div class="article-summary-box-inner">
<span><p>We propose a method for Saimaa ringed seal (Pusa hispida saimensis)
re-identification. Access to large image volumes through camera trapping and
crowdsourcing provides novel possibilities for animal monitoring and
conservation and calls for automatic methods for analysis, in particular, when
re-identifying individual animals from the images. The proposed method NOvel
Ringed seal re-identification by Pelage Pattern Aggregation (NORPPA) utilizes
the permanent and unique pelage pattern of Saimaa ringed seals and
content-based image retrieval techniques. First, the query image is
preprocessed, and each seal instance is segmented. Next, the seal's pelage
pattern is extracted using a U-net encoder-decoder based method. Then,
CNN-based affine invariant features are embedded and aggregated into Fisher
Vectors. Finally, the cosine distance between the Fisher Vectors is used to
find the best match from a database of known individuals. We perform extensive
experiments of various modifications of the method on a new challenging Saimaa
ringed seals re-identification dataset. The proposed method is shown to produce
the best re-identification accuracy on our dataset in comparisons with
alternative approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SUPER-IVIM-DC: Intra-voxel incoherent motion based Fetal lung maturity assessment from limited DWI data using supervised learning coupled with data-consistency. (arXiv:2206.03820v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03820">
<div class="article-summary-box-inner">
<span><p>Intra-voxel incoherent motion (IVIM) analysis of fetal lungs
Diffusion-Weighted MRI (DWI) data shows potential in providing quantitative
imaging bio-markers that reflect, indirectly, diffusion and pseudo-diffusion
for non-invasive fetal lung maturation assessment. However, long acquisition
times, due to the large number of different "b-value" images required for IVIM
analysis, precluded clinical feasibility. We introduce SUPER-IVIM-DC a
deep-neural-networks (DNN) approach which couples supervised loss with a
data-consistency term to enable IVIM analysis of DWI data acquired with a
limited number of b-values. We demonstrated the added-value of SUPER-IVIM-DC
over both classical and recent DNN approaches for IVIM analysis through
numerical simulations, healthy volunteer study, and IVIM analysis of fetal lung
maturation from fetal DWI data. Our numerical simulations and healthy volunteer
study show that SUPER-IVIM-DC estimates of the IVIM model parameters from
limited DWI data had lower normalized root mean-squared error compared to
previous DNN-based approaches. Further, SUPER-IVIM-DC estimates of the
pseudo-diffusion fraction parameter from limited DWI data of fetal lungs
correlate better with gestational age compared to both to classical and
DNN-based approaches (0.242 vs. -0.079 and 0.239). SUPER-IVIM-DC has the
potential to reduce the long acquisition times associated with IVIM analysis of
DWI data and to provide clinically feasible bio-markers for non-invasive fetal
lung maturity assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Patch-based Object-centric Transformers for Efficient Video Generation. (arXiv:2206.04003v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04003">
<div class="article-summary-box-inner">
<span><p>In this work, we present Patch-based Object-centric Video Transformer (POVT),
a novel region-based video generation architecture that leverages
object-centric information to efficiently model temporal dynamics in videos. We
build upon prior work in video prediction via an autoregressive transformer
over the discrete latent space of compressed videos, with an added modification
to model object-centric information via bounding boxes. Due to better
compressibility of object-centric representations, we can improve training
efficiency by allowing the model to only access object information for longer
horizon temporal information. When evaluated on various difficult
object-centric datasets, our method achieves better or equal performance to
other video generation models, while remaining computationally more efficient
and scalable. In addition, we show that our method is able to perform
object-centric controllability through bounding box manipulation, which may aid
downstream tasks such as video editing, or visual planning. Samples are
available at https://sites.google.com/view/povt-public
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Two-stage Method for Non-extreme Value Salt-and-Pepper Noise Removal. (arXiv:2206.05520v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05520">
<div class="article-summary-box-inner">
<span><p>There are several previous methods based on neural network can have great
performance in denoising salt and pepper noise. However, those methods are
based on a hypothesis that the value of salt and pepper noise is exactly 0 and
255. It is not true in the real world. The result of those methods deviate
sharply when the value is different from 0 and 255. To overcome this weakness,
our method aims at designing a convolutional neural network to detect the noise
pixels in a wider range of value and then a filter is used to modify pixel
value to 0, which is beneficial for further filtering. Additionally, another
convolutional neural network is used to conduct the denoising and restoration
work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TileGen: Tileable, Controllable Material Generation and Capture. (arXiv:2206.05649v2 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05649">
<div class="article-summary-box-inner">
<span><p>Recent methods (e.g. MaterialGAN) have used unconditional GANs to generate
per-pixel material maps, or as a prior to reconstruct materials from input
photographs. These models can generate varied random material appearance, but
do not have any mechanism to constrain the generated material to a specific
category or to control the coarse structure of the generated material, such as
the exact brick layout on a brick wall. Furthermore, materials reconstructed
from a single input photo commonly have artifacts and are generally not
tileable, which limits their use in practical content creation pipelines. We
propose TileGen, a generative model for SVBRDFs that is specific to a material
category, always tileable, and optionally conditional on a provided input
structure pattern. TileGen is a variant of StyleGAN whose architecture is
modified to always produce tileable (periodic) material maps. In addition to
the standard "style" latent code, TileGen can optionally take a condition
image, giving a user direct control over the dominant spatial (and optionally
color) features of the material. For example, in brick materials, the user can
specify a brick layout and the brick color, or in leather materials, the
locations of wrinkles and folds. Our inverse rendering approach can find a
material perceptually matching a single target photograph by optimization. This
reconstruction can also be conditional on a user-provided pattern. The
resulting materials are tileable, can be larger than the target image, and are
editable by varying the condition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DRNet: Decomposition and Reconstruction Network for Remote Physiological Measurement. (arXiv:2206.05687v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05687">
<div class="article-summary-box-inner">
<span><p>Remote photoplethysmography (rPPG) based physiological measurement has great
application values in affective computing, non-contact health monitoring,
telehealth monitoring, etc, which has become increasingly important especially
during the COVID-19 pandemic. Existing methods are generally divided into two
groups. The first focuses on mining the subtle blood volume pulse (BVP) signals
from face videos, but seldom explicitly models the noises that dominate face
video content. They are susceptible to the noises and may suffer from poor
generalization ability in unseen scenarios. The second focuses on modeling
noisy data directly, resulting in suboptimal performance due to the lack of
regularity of these severe random noises. In this paper, we propose a
Decomposition and Reconstruction Network (DRNet) focusing on the modeling of
physiological features rather than noisy data. A novel cycle loss is proposed
to constrain the periodicity of physiological information. Besides, a
plug-and-play Spatial Attention Block (SAB) is proposed to enhance features
along with the spatial location information. Furthermore, an efficient Patch
Cropping (PC) augmentation strategy is proposed to synthesize augmented samples
with different noise and features. Extensive experiments on different public
datasets as well as the cross-database testing demonstrate the effectiveness of
our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Featurized Query R-CNN. (arXiv:2206.06258v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.06258">
<div class="article-summary-box-inner">
<span><p>The query mechanism introduced in the DETR method is changing the paradigm of
object detection and recently there are many query-based methods have obtained
strong object detection performance. However, the current query-based detection
pipelines suffer from the following two issues. Firstly, multi-stage decoders
are required to optimize the randomly initialized object queries, incurring a
large computation burden. Secondly, the queries are fixed after training,
leading to unsatisfying generalization capability. To remedy the above issues,
we present featurized object queries predicted by a query generation network in
the well-established Faster R-CNN framework and develop a Featurized Query
R-CNN. Extensive experiments on the COCO dataset show that our Featurized Query
R-CNN obtains the best speed-accuracy trade-off among all R-CNN detectors,
including the recent state-of-the-art Sparse R-CNN detector. The code is
available at {https://github.com/hustvl/Featurized-QueryRCNN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Easy Example Mining for Weakly-supervised Gland Segmentation from Histology Images. (arXiv:2206.06665v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.06665">
<div class="article-summary-box-inner">
<span><p>Developing an AI-assisted gland segmentation method from histology images is
critical for automatic cancer diagnosis and prognosis; however, the high cost
of pixel-level annotations hinders its applications to broader diseases.
Existing weakly-supervised semantic segmentation methods in computer vision
achieve degenerative results for gland segmentation, since the characteristics
and problems of glandular datasets are different from general object datasets.
We observe that, unlike natural images, the key problem with histology images
is the confusion of classes owning to morphological homogeneity and low color
contrast among different tissues. To this end, we propose a novel method Online
Easy Example Mining (OEEM) that encourages the network to focus on credible
supervision signals rather than noisy signals, therefore mitigating the
influence of inevitable false predictions in pseudo-masks. According to the
characteristics of glandular datasets, we design a strong framework for gland
segmentation. Our results exceed many fully-supervised methods and
weakly-supervised methods for gland segmentation over 4.4% and 6.04% at mIoU,
respectively. Code is available at https://github.com/xmed-lab/OEEM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CNN-based Classification Framework for Lung Tissues with Auxiliary Information. (arXiv:2206.06701v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.06701">
<div class="article-summary-box-inner">
<span><p>Interstitial lung diseases are a large group of heterogeneous diseases
characterized by different degrees of alveolitis and pulmonary fibrosis.
Accurately diagnosing these diseases has significant guiding value for
formulating treatment plans. Although previous work has produced impressive
results in classifying interstitial lung diseases, there is still room for
improving the accuracy of these techniques, mainly to enhance automated
decision-making. In order to improve the classification precision, our study
proposes a convolutional neural networks-based framework with auxiliary
information. Firstly, ILD images are added with their medical information by
re-scaling the original image in Hounsfield Units. Secondly, a modified CNN
model is used to produce a vector of classification probability for each
tissue. Thirdly, location information of the input image, consisting of the
occurrence frequencies of different diseases in the CT scans on certain
locations, is used to calculate a location weight vector. Finally, the Hadamard
product between two vectors is used to produce a decision vector for the
prediction. Compared to the state-of-the-art methods, the results using a
publicly available ILD database show the potential of predicting these using
different auxiliary information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Asymmetric Dual-Decoder U-Net for Joint Rain and Haze Removal. (arXiv:2206.06803v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.06803">
<div class="article-summary-box-inner">
<span><p>This work studies the joint rain and haze removal problem. In real-life
scenarios, rain and haze, two often co-occurring common weather phenomena, can
greatly degrade the clarity and quality of the scene images, leading to a
performance drop in the visual applications, such as autonomous driving.
However, jointly removing the rain and haze in scene images is ill-posed and
challenging, where the existence of haze and rain and the change of atmosphere
light, can both degrade the scene information. Current methods focus on the
contamination removal part, thus ignoring the restoration of the scene
information affected by the change of atmospheric light. We propose a novel
deep neural network, named Asymmetric Dual-decoder U-Net (ADU-Net), to address
the aforementioned challenge. The ADU-Net produces both the contamination
residual and the scene residual to efficiently remove the rain and haze while
preserving the fidelity of the scene information. Extensive experiments show
our work outperforms the existing state-of-the-art methods by a considerable
margin in both synthetic data and real-world data benchmarks, including
RainCityscapes, BID Rain, and SPA-Data. For instance, we improve the
state-of-the-art PSNR value by 2.26/4.57 on the RainCityscapes/SPA-Data,
respectively.
</p>
<p>Codes will be made available freely to the research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos. (arXiv:2206.07038v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.07038">
<div class="article-summary-box-inner">
<span><p>This paper studies the problem of real-world video super-resolution (VSR) for
animation videos, and reveals three key improvements for practical animation
VSR. First, recent real-world super-resolution approaches typically rely on
degradation simulation using basic operators without any learning capability,
such as blur, noise, and compression. In this work, we propose to learn such
basic operators from real low-quality animation videos, and incorporate the
learned ones into the degradation generation pipeline. Such
neural-network-based basic operators could help to better capture the
distribution of real degradations. Second, a large-scale high-quality animation
video dataset, AVC, is built to facilitate comprehensive training and
evaluations for animation VSR. Third, we further investigate an efficient
multi-scale network structure. It takes advantage of the efficiency of
unidirectional recurrent networks and the effectiveness of sliding-window-based
methods. Thanks to the above delicate designs, our method, AnimeSR, is capable
of restoring real-world low-quality animation videos effectively and
efficiently, achieving superior performance to previous state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Technical Report for Argoverse2 Challenge 2022 -- Motion Forecasting Task. (arXiv:2206.07934v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.07934">
<div class="article-summary-box-inner">
<span><p>We propose a motion forecasting model called BANet, which means
Boundary-Aware Network, and it is a variant of LaneGCN. We believe that it is
not enough to use only the lane centerline as input to obtain the embedding
features of the vector map nodes. The lane centerline can only provide the
topology of the lanes, and other elements of the vector map also contain rich
information. For example, the lane boundary can provide traffic rule constraint
information such as whether it is possible to change lanes which is very
important. Therefore, we achieved better performance by encoding more vector
map elements in the motion forecasting model.We report our results on the 2022
Argoverse2 Motion Forecasting challenge and rank 1st on the test leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Channel Importance Matters in Few-Shot Image Classification. (arXiv:2206.08126v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08126">
<div class="article-summary-box-inner">
<span><p>Few-Shot Learning (FSL) requires vision models to quickly adapt to brand-new
classification tasks with a shift in task distribution. Understanding the
difficulties posed by this task distribution shift is central to FSL. In this
paper, we show that a simple channel-wise feature transformation may be the key
to unraveling this secret from a channel perspective. When facing novel
few-shot tasks in the test-time datasets, this transformation can greatly
improve the generalization ability of learned image representations, while
being agnostic to the choice of training algorithms and datasets. Through an
in-depth analysis of this transformation, we find that the difficulty of
representation transfer in FSL stems from the severe channel bias problem of
image representations: channels may have different importance in different
tasks, while convolutional neural networks are likely to be insensitive, or
respond incorrectly to such a shift. This points out a core problem of the
generalization ability of modern vision systems and needs further attention in
the future. Our code is available at
https://github.com/Frankluox/Channel_Importance_FSL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FWD: Real-time Novel View Synthesis with Forward Warping and Depth. (arXiv:2206.08355v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08355">
<div class="article-summary-box-inner">
<span><p>Novel view synthesis (NVS) is a challenging task requiring systems to
generate photorealistic images of scenes from new viewpoints, where both
quality and speed are important for applications. Previous image-based
rendering (IBR) methods are fast, but have poor quality when input views are
sparse. Recent Neural Radiance Fields (NeRF) and generalizable variants give
impressive results but are not real-time. In our paper, we propose a
generalizable NVS method with sparse inputs, called FWD, which gives
high-quality synthesis in real-time. With explicit depth and differentiable
rendering, it achieves competitive results to the SOTA methods with 130-1000x
speedup and better perceptual quality. If available, we can seamlessly
integrate sensor depth during either training or inference to improve image
quality while retaining real-time speed. With the growing prevalence of depths
sensors, we hope that methods making use of depth will become increasingly
useful.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Fourier-based Kernel and Nonlinearity Design for Equivariant Networks on Homogeneous Spaces. (arXiv:2206.08362v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08362">
<div class="article-summary-box-inner">
<span><p>We introduce a unified framework for group equivariant networks on
homogeneous spaces derived from a Fourier perspective. We consider
tensor-valued feature fields, before and after a convolutional layer. We
present a unified derivation of kernels via the Fourier domain by leveraging
the sparsity of Fourier coefficients of the lifted feature fields. The sparsity
emerges when the stabilizer subgroup of the homogeneous space is a compact Lie
group. We further introduce a nonlinear activation, via an elementwise
nonlinearity on the regular representation after lifting and projecting back to
the field through an equivariant convolution. We show that other methods
treating features as the Fourier coefficients in the stabilizer subgroup are
special cases of our activation. Experiments on $SO(3)$ and $SE(3)$ show
state-of-the-art performance in spherical vector field regression, point cloud
classification, and molecular completion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recursive Neural Programs: Variational Learning of Image Grammars and Part-Whole Hierarchies. (arXiv:2206.08462v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08462">
<div class="article-summary-box-inner">
<span><p>Human vision involves parsing and representing objects and scenes using
structured representations based on part-whole hierarchies. Computer vision and
machine learning researchers have recently sought to emulate this capability
using capsule networks, reference frames and active predictive coding, but a
generative model formulation has been lacking. We introduce Recursive Neural
Programs (RNPs), which, to our knowledge, is the first neural generative model
to address the part-whole hierarchy learning problem. RNPs model images as
hierarchical trees of probabilistic sensory-motor programs that recursively
reuse learned sensory-motor primitives to model an image within different
reference frames, forming recursive image grammars. We express RNPs as
structured variational autoencoders (sVAEs) for inference and sampling, and
demonstrate parts-based parsing, sampling and one-shot transfer learning for
MNIST, Omniglot and Fashion-MNIST datasets, demonstrating the model's
expressive power. Our results show that RNPs provide an intuitive and
explainable way of composing objects and scenes, allowing rich compositionality
and intuitive interpretations of objects in terms of part-whole hierarchies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TAVA: Template-free Animatable Volumetric Actors. (arXiv:2206.08929v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08929">
<div class="article-summary-box-inner">
<span><p>Coordinate-based volumetric representations have the potential to generate
photo-realistic virtual avatars from images. However, virtual avatars also need
to be controllable even to a novel pose that may not have been observed.
Traditional techniques, such as LBS, provide such a function; yet it usually
requires a hand-designed body template, 3D scan data, and limited appearance
models. On the other hand, neural representation has been shown to be powerful
in representing visual details, but are under explored on deforming dynamic
articulated actors. In this paper, we propose TAVA, a method to create T
emplate-free Animatable Volumetric Actors, based on neural representations. We
rely solely on multi-view data and a tracked skeleton to create a volumetric
model of an actor, which can be animated at the test time given novel pose.
Since TAVA does not require a body template, it is applicable to humans as well
as other creatures such as animals. Furthermore, TAVA is designed such that it
can recover accurate dense correspondences, making it amenable to
content-creation and editing tasks. Through extensive experiments, we
demonstrate that the proposed method generalizes well to novel poses as well as
unseen views and showcase basic editing capabilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A machine-generated catalogue of Charon's craters and implications for the Kuiper belt. (arXiv:2206.08277v1 [astro-ph.EP] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08277">
<div class="article-summary-box-inner">
<span><p>In this paper we investigate Charon's craters size distribution using a deep
learning model. This is motivated by the recent results of Singer et al. (2019)
who, using manual cataloging, found a change in the size distribution slope of
craters smaller than 12 km in diameter, translating into a paucity of small
Kuiper Belt objects. These results were corroborated by Robbins and Singer
(2021), but opposed by Morbidelli et al. (2021), necessitating an independent
review. Our MaskRCNN-based ensemble of models was trained on Lunar, Mercurian,
and Martian crater catalogues and both optical and digital elevation images. We
use a robust image augmentation scheme to force the model to generalize and
transfer-learn into icy objects. With no prior bias or exposure to Charon, our
model find best fit slopes of q =-1.47+-0.33 for craters smaller than 10 km,
and q =-2.91+-0.51 for craters larger than 15 km. These values indicate a clear
change in slope around 15 km as suggested by Singer et al. (2019) and thus
independently confirm their conclusions. Our slopes however are both slightly
flatter than those found more recently by Robbins and Singer (2021). Our
trained models and relevant codes are available online on
github.com/malidib/ACID .
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-06-22 23:07:54.787281706 UTC">2022-06-22 23:07:54 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>