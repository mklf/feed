<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-05-19T01:30:00Z">05-19</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Deploying self-supervised learning in the wild for hybrid automatic speech recognition. (arXiv:2205.08598v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08598">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) methods have proven to be very successful in
automatic speech recognition (ASR). These great improvements have been reported
mostly based on highly curated datasets such as LibriSpeech for non-streaming
End-to-End ASR models. However, the pivotal characteristics of SSL is to be
utilized for any untranscribed audio data. In this paper, we provide a full
exploration on how to utilize uncurated audio data in SSL from data
pre-processing to deploying an streaming hybrid ASR model. More specifically,
we present (1) the effect of Audio Event Detection (AED) model in data
pre-processing pipeline (2) analysis on choosing optimizer and learning rate
scheduling (3) comparison of recently developed contrastive losses, (4)
comparison of various pre-training strategies such as utilization of in-domain
versus out-domain pre-training data, monolingual versus multilingual
pre-training data, multi-head multilingual SSL versus single-head multilingual
SSL and supervised pre-training versus SSL. The experimental results show that
SSL pre-training with in-domain uncurated data can achieve better performance
in comparison to all the alternative out-domain pre-training strategies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OneAligner: Zero-shot Cross-lingual Transfer with One Rich-Resource Language Pair for Low-Resource Sentence Retrieval. (arXiv:2205.08605v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08605">
<div class="article-summary-box-inner">
<span><p>Aligning parallel sentences in multilingual corpora is essential to curating
data for downstream applications such as Machine Translation. In this work, we
present OneAligner, an alignment model specially designed for sentence
retrieval tasks. This model is able to train on only one language pair and
transfers, in a cross-lingual fashion, to low-resource language pairs with
negligible degradation in performance. When trained with all language pairs of
a large-scale parallel multilingual corpus (OPUS-100), this model achieves the
state-of-the-art result on the Tateoba dataset, outperforming an equally-sized
previous model by 8.0 points in accuracy while using less than 0.6% of their
parallel data. When finetuned on a single rich-resource language pair, be it
English-centered or not, our model is able to match the performance of the ones
finetuned on all language pairs under the same data budget with less than 2.0
points decrease in accuracy. Furthermore, with the same setup, scaling up the
number of rich-resource language pairs monotonically improves the performance,
reaching a minimum of 0.4 points discrepancy in accuracy, making it less
mandatory to collect any low-resource parallel data. Finally, we conclude
through empirical results and analyses that the performance of the sentence
alignment task depends mostly on the monolingual and parallel data size, up to
a certain size threshold, rather than on what language pairs are used for
training or evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geographical Distance Is The New Hyperparameter: A Case Study Of Finding The Optimal Pre-trained Language For English-isiZulu Machine Translation. (arXiv:2205.08621v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08621">
<div class="article-summary-box-inner">
<span><p>Stemming from the limited availability of datasets and textual resources for
low-resource languages such as isiZulu, there is a significant need to be able
to harness knowledge from pre-trained models to improve low resource machine
translation. Moreover, a lack of techniques to handle the complexities of
morphologically rich languages has compounded the unequal development of
translation models, with many widely spoken African languages being left
behind. This study explores the potential benefits of transfer learning in an
English-isiZulu translation framework. The results indicate the value of
transfer learning from closely related languages to enhance the performance of
low-resource translation models, thus providing a key strategy for low-resource
translation going forward. We gathered results from 8 different language
corpora, including one multi-lingual corpus, and saw that isiXhosa-isiZulu
outperformed all languages, with a BLEU score of 8.56 on the test set which was
better from the multi-lingual corpora pre-trained model by 2.73. We also
derived a new coefficient, Nasir's Geographical Distance Coefficient (NGDC)
which provides an easy selection of languages for the pre-trained models. NGDC
also indicated that isiXhosa should be selected as the language for the
pre-trained model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generic and Trend-aware Curriculum Learning for Relation Extraction in Graph Neural Networks. (arXiv:2205.08625v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08625">
<div class="article-summary-box-inner">
<span><p>We present a generic and trend-aware curriculum learning approach for graph
neural networks. It extends existing approaches by incorporating sample-level
loss trends to better discriminate easier from harder samples and schedule them
for training. The model effectively integrates textual and structural
information for relation extraction in text graphs. Experimental results show
that the model provides robust estimations of sample difficulty and shows
sizable improvement over the state-of-the-art approaches across several
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Addressing Resource and Privacy Constraints in Semantic Parsing Through Data Augmentation. (arXiv:2205.08675v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08675">
<div class="article-summary-box-inner">
<span><p>We introduce a novel setup for low-resource task-oriented semantic parsing
which incorporates several constraints that may arise in real-world scenarios:
(1) lack of similar datasets/models from a related domain, (2) inability to
sample useful logical forms directly from a grammar, and (3) privacy
requirements for unlabeled natural utterances. Our goal is to improve a
low-resource semantic parser using utterances collected through user
interactions. In this highly challenging but realistic setting, we investigate
data augmentation approaches involving generating a set of structured canonical
utterances corresponding to logical forms, before simulating corresponding
natural language and filtering the resulting pairs. We find that such
approaches are effective despite our restrictive setup: in a low-resource
setting on the complex SMCalFlow calendaring dataset (Andreas et al., 2020), we
observe 33% relative improvement over a non-data-augmented baseline in top-1
match.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Solvability of Interpretability Evaluation Metrics. (arXiv:2205.08696v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08696">
<div class="article-summary-box-inner">
<span><p>Feature attribution methods are popular for explaining neural network
predictions, and they are often evaluated on metrics such as comprehensiveness
and sufficiency, which are motivated by the principle that more important
features -- as judged by the explanation -- should have larger impacts on model
prediction. In this paper, we highlight an intriguing property of these
metrics: their solvability. Concretely, we can define the problem of optimizing
an explanation for a metric and solve it using beam search. This brings up the
obvious question: given such solvability, why do we still develop other
explainers and then evaluate them on the metric? We present a series of
investigations showing that this beam search explainer is generally comparable
or favorable to current choices such as LIME and SHAP, suggest rethinking the
goals of model interpretability, and identify several directions towards better
evaluations of new method proposals.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation to Address Out-of-Vocabulary Problem in Low-Resource Sinhala-English Neural Machine Translation. (arXiv:2205.08722v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08722">
<div class="article-summary-box-inner">
<span><p>Out-of-Vocabulary (OOV) is a problem for Neural Machine Translation (NMT).
OOV refers to words with a low occurrence in the training data, or to those
that are absent from the training data. To alleviate this, word or phrase-based
Data Augmentation (DA) techniques have been used. However, existing DA
techniques have addressed only one of these OOV types and limit to considering
either syntactic constraints or semantic constraints. We present a word and
phrase replacement-based DA technique that consider both types of OOV, by
augmenting (1) rare words in the existing parallel corpus, and (2) new words
from a bilingual dictionary. During augmentation, we consider both syntactic
and semantic properties of the words to guarantee fluency in the synthetic
sentences. This technique was experimented with low resource Sinhala-English
language pair. We observe with only semantic constraints in the DA, the results
are comparable with the scores obtained considering syntactic constraints, and
is favourable for low-resourced languages that lacks linguistic tool support.
Additionally, results can be further improved by considering both syntactic and
semantic constraints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A reproducible experimental survey on biomedical sentence similarity: a string-based method sets the state of the art. (arXiv:2205.08740v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08740">
<div class="article-summary-box-inner">
<span><p>This registered report introduces the largest, and for the first time,
reproducible experimental survey on biomedical sentence similarity with the
following aims: (1) to elucidate the state of the art of the problem; (2) to
solve some reproducibility problems preventing the evaluation of most of
current methods; (3) to evaluate several unexplored sentence similarity
methods; (4) to evaluate an unexplored benchmark, called
Corpus-Transcriptional-Regulation; (5) to carry out a study on the impact of
the pre-processing stages and Named Entity Recognition (NER) tools on the
performance of the sentence similarity methods; and finally, (6) to bridge the
lack of reproducibility resources for methods and experiments in this line of
research. Our experimental survey is based on a single software platform that
is provided with a detailed reproducibility protocol and dataset as
supplementary material to allow the exact replication of all our experiments.
In addition, we introduce a new aggregated string-based sentence similarity
method, called LiBlock, together with eight variants of current ontology-based
methods and a new pre-trained word embedding model trained on the full-text
articles in the PMC-BioC corpus. Our experiments show that our novel
string-based measure sets the new state of the art on the sentence similarity
task in the biomedical domain and significantly outperforms all the methods
evaluated herein, except one ontology-based method. Likewise, our experiments
confirm that the pre-processing stages, and the choice of the NER tool, have a
significant impact on the performance of the sentence similarity methods. We
also detail some drawbacks and limitations of current methods, and warn on the
need of refining the current benchmarks. Finally, a noticeable finding is that
our new string-based method significantly outperforms all state-of-the-art
Machine Learning models evaluated herein.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Persian Natural Language Inference: A Meta-learning approach. (arXiv:2205.08755v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08755">
<div class="article-summary-box-inner">
<span><p>Incorporating information from other languages can improve the results of
tasks in low-resource languages. A powerful method of building functional
natural language processing systems for low-resource languages is to combine
multilingual pre-trained representations with cross-lingual transfer learning.
In general, however, shared representations are learned separately, either
across tasks or across languages. This paper proposes a meta-learning approach
for inferring natural language in Persian. Alternately, meta-learning uses
different task information (such as QA in Persian) or other language
information (such as natural language inference in English). Also, we
investigate the role of task augmentation strategy for forming additional
high-quality tasks. We evaluate the proposed method using four languages and an
auxiliary task. Compared to the baseline approach, the proposed model
consistently outperforms it, improving accuracy by roughly six percent. We also
examine the effect of finding appropriate initial parameters using zero-shot
evaluation and CCA similarity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation Extraction with Weighted Contrastive Pre-training on Distant Supervision. (arXiv:2205.08770v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08770">
<div class="article-summary-box-inner">
<span><p>Contrastive pre-training on distant supervision has shown remarkable
effectiveness for improving supervised relation extraction tasks. However, the
existing methods ignore the intrinsic noise of distant supervision during the
pre-training stage. In this paper, we propose a weighted contrastive learning
method by leveraging the supervised data to estimate the reliability of
pre-training instances and explicitly reduce the effect of noise. Experimental
results on three supervised datasets demonstrate the advantages of our proposed
weighted contrastive learning approach, compared to two state-of-the-art
non-weighted baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Adaptive Semantic Transfer for Cross-domain Sentiment Classification. (arXiv:2205.08772v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08772">
<div class="article-summary-box-inner">
<span><p>Cross-domain sentiment classification (CDSC) aims to use the transferable
semantics learned from the source domain to predict the sentiment of reviews in
the unlabeled target domain. Existing studies in this task attach more
attention to the sequence modeling of sentences while largely ignoring the rich
domain-invariant semantics embedded in graph structures (i.e., the
part-of-speech tags and dependency relations). As an important aspect of
exploring characteristics of language comprehension, adaptive graph
representations have played an essential role in recent years. To this end, in
the paper, we aim to explore the possibility of learning invariant semantic
features from graph-like structures in CDSC. Specifically, we present Graph
Adaptive Semantic Transfer (GAST) model, an adaptive syntactic graph embedding
method that is able to learn domain-invariant semantics from both word
sequences and syntactic graphs. More specifically, we first raise a
POS-Transformer module to extract sequential semantic features from the word
sequences as well as the part-of-speech tags. Then, we design a Hybrid Graph
Attention (HGAT) module to generate syntax-based semantic features by
considering the transferable dependency relations. Finally, we devise an
Integrated aDaptive Strategy (IDS) to guide the joint learning process of both
modules. Extensive experiments on four public datasets indicate that GAST
achieves comparable effectiveness to a range of state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LogiGAN: Learning Logical Reasoning via Adversarial Pre-training. (arXiv:2205.08794v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08794">
<div class="article-summary-box-inner">
<span><p>We present LogiGAN, an unsupervised adversarial pre-training framework for
improving logical reasoning abilities of language models. Upon automatic
identifying logical reasoning phenomena in massive text corpus via detection
heuristics, we train language models to predict the masked-out logical
statements. Inspired by the facilitation effect of reflective thinking in human
learning, we analogically simulate the learning-thinking process with an
adversarial Generator-Verifier architecture to assist logic learning. LogiGAN
implements a novel sequential GAN approach that (a) circumvents the
non-differentiable challenge of the sequential GAN by leveraging the Generator
as a sentence-level generative likelihood scorer with a learning objective of
reaching scoring consensus with the Verifier; (b) is computationally feasible
for large-scale pre-training with arbitrary target length. Both base and large
size language models pre-trained with LogiGAN demonstrate obvious performance
improvement on 12 datasets requiring general reasoning abilities, revealing the
fundamental role of logic in broad reasoning, as well as the effectiveness of
LogiGAN. Ablation studies on LogiGAN components reveal the relative
orthogonality between linguistic and logic abilities and suggest that
reflective thinking's facilitation effect might also generalize to machine
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entity Alignment with Reliable Path Reasoning and Relation-Aware Heterogeneous Graph Transformer. (arXiv:2205.08806v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08806">
<div class="article-summary-box-inner">
<span><p>Entity Alignment (EA) has attracted widespread attention in both academia and
industry, which aims to seek entities with same meanings from different
Knowledge Graphs (KGs). There are substantial multi-step relation paths between
entities in KGs, indicating the semantic relations of entities. However,
existing methods rarely consider path information because not all natural paths
facilitate for EA judgment. In this paper, we propose a more effective entity
alignment framework, RPR-RHGT, which integrates relation and path structure
information, as well as the heterogeneous information in KGs. Impressively, an
initial reliable path reasoning algorithm is developed to generate the paths
favorable for EA task from the relation structures of KGs, which is the first
algorithm in the literature to successfully use unrestricted path information.
In addition, to efficiently capture heterogeneous features in entity
neighborhoods, a relation-aware heterogeneous graph transformer is designed to
model the relation and path structures of KGs. Extensive experiments on three
well-known datasets show RPR-RHGT significantly outperforms 11 state-of-the-art
methods, exceeding the best performing baseline up to 8.62% on Hits@1. We also
show its better performance than the baselines on different ratios of training
set, and harder datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of Transfer Learning for Polish with a Text-to-Text Model. (arXiv:2205.08808v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08808">
<div class="article-summary-box-inner">
<span><p>We introduce a new benchmark for assessing the quality of text-to-text models
for Polish. The benchmark consists of diverse tasks and datasets: KLEJ
benchmark adapted for text-to-text, en-pl translation, summarization, and
question answering. In particular, since summarization and question answering
lack benchmark datasets for the Polish language, we describe their construction
and make them publicly available. Additionally, we present plT5 - a
general-purpose text-to-text model for Polish that can be fine-tuned on various
Natural Language Processing (NLP) tasks with a single training objective.
Unsupervised denoising pre-training is performed efficiently by initializing
the model weights with a multi-lingual T5 (mT5) counterpart. We evaluate the
performance of plT5, mT5, Polish BART (plBART), and Polish GPT-2 (papuGaPT2).
The plT5 scores top on all of these tasks except summarization, where plBART is
best. In general (except for summarization), the larger the model, the better
the results. The encoder-decoder architectures prove to be better than the
decoder-only equivalent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regex in a Time of Deep Learning: The Role of an Old Technology in Age Discrimination Detection in Job Advertisements. (arXiv:2205.08813v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08813">
<div class="article-summary-box-inner">
<span><p>Deep learning holds great promise for detecting discriminatory language in
the public sphere. However, for the detection of illegal age discrimination in
job advertisements, regex approaches are still strong performers. In this
paper, we investigate job advertisements in the Netherlands. We present a
qualitative analysis of the benefits of the 'old' approach based on regexes and
investigate how neural embeddings could address its limitations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Social Media Content for Self-Supervised Style Transfer. (arXiv:2205.08814v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08814">
<div class="article-summary-box-inner">
<span><p>Recent research on style transfer takes inspiration from unsupervised neural
machine translation (UNMT), learning from large amounts of non-parallel data by
exploiting cycle consistency loss, back-translation, and denoising
autoencoders. By contrast, the use of self-supervised NMT (SSNMT), which
leverages (near) parallel instances hidden in non-parallel data more
efficiently than UNMT, has not yet been explored for style transfer. In this
paper we present a novel Self-Supervised Style Transfer (3ST) model, which
augments SSNMT with UNMT methods in order to identify and efficiently exploit
supervisory signals in non-parallel social media posts. We compare 3ST with
state-of-the-art (SOTA) style transfer models across civil rephrasing,
formality and polarity tasks. We show that 3ST is able to balance the three
major objectives (fluency, content preservation, attribute transfer accuracy)
the best, outperforming SOTA models on averaged performance across their tested
tasks in automatic and human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPoeT-2: A GPT-2 Based Poem Generator. (arXiv:2205.08847v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08847">
<div class="article-summary-box-inner">
<span><p>This project aims to produce the next volume of machine-generated poetry, a
complex art form that can be structured and unstructured, and carries depth in
the meaning between the lines. GPoeT-2 is based on fine-tuning a state of the
art natural language model (i.e. GPT-2) to generate limericks, typically
humorous structured poems consisting of five lines with a AABBA rhyming scheme.
With a two-stage generation system utilizing both forward and reverse language
modeling, GPoeT-2 is capable of freely generating limericks in diverse topics
while following the rhyming structure without any seed phrase or a posteriori
constraints.Based on the automated generation process, we explore a wide
variety of evaluation metrics to quantify "good poetry," including syntactical
correctness, lexical diversity, and subject continuity. Finally, we present a
collection of 94 categorized limericks that rank highly on the explored "good
poetry" metrics to provoke human creativity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BFCAI at SemEval-2022 Task 6: Multi-Layer Perceptron for Sarcasm Detection in Arabic Texts. (arXiv:2205.08868v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08868">
<div class="article-summary-box-inner">
<span><p>This paper describes the systems submitted to iSarcasm shared task. The aim
of iSarcasm is to identify the sarcastic contents in Arabic and English text.
Our team participated in iSarcasm for the Arabic language. A multi-Layer
machine learning based model has been submitted for Arabic sarcasm detection.
In this model, a vector space TF-IDF has been used as for feature
representation. The submitted system is simple and does not need any external
resources. The test results show encouraging results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Scalable Workflow to Build Machine Learning Classifiers with Clinician-in-the-Loop to Identify Patients in Specific Diseases. (arXiv:2205.08891v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08891">
<div class="article-summary-box-inner">
<span><p>Clinicians may rely on medical coding systems such as International
Classification of Diseases (ICD) to identify patients with diseases from
Electronic Health Records (EHRs). However, due to the lack of detail and
specificity as well as a probability of miscoding, recent studies suggest the
ICD codes often cannot characterise patients accurately for specific diseases
in real clinical practice, and as a result, using them to find patients for
studies or trials can result in high failure rates and missing out on uncoded
patients. Manual inspection of all patients at scale is not feasible as it is
highly costly and slow.
</p>
<p>This paper proposes a scalable workflow which leverages both structured data
and unstructured textual notes from EHRs with techniques including NLP, AutoML
and Clinician-in-the-Loop mechanism to build machine learning classifiers to
identify patients at scale with given diseases, especially those who might
currently be miscoded or missed by ICD codes.
</p>
<p>Case studies in the MIMIC-III dataset were conducted where the proposed
workflow demonstrates a higher classification performance in terms of F1 scores
compared to simply using ICD codes on gold testing subset to identify patients
with Ovarian Cancer (0.901 vs 0.814), Lung Cancer (0.859 vs 0.828), Cancer
Cachexia (0.862 vs 0.650), and Lupus Nephritis (0.959 vs 0.855). Also, the
proposed workflow that leverages unstructured notes consistently outperforms
the baseline that uses structured data only with an increase of F1 (Ovarian
Cancer 0.901 vs 0.719, Lung Cancer 0.859 vs 0.787, Cancer Cachexia 0.862 vs
0.838 and Lupus Nephritis 0.959 vs 0.785). Experiments on the large testing set
also demonstrate the proposed workflow can find more patients who are miscoded
or missed by ICD codes. Moreover, interpretability studies are also conducted
to clinically validate the top impact features of the classifiers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Features of Perceived Metaphoricity on the Discourse Level: Abstractness and Emotionality. (arXiv:2205.08939v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08939">
<div class="article-summary-box-inner">
<span><p>Research on metaphorical language has shown ties between abstractness and
emotionality with regard to metaphoricity; prior work is however limited to the
word and sentence levels, and up to date there is no empirical study
establishing the extent to which this is also true on the discourse level. This
paper explores which textual and perceptual features human annotators perceive
as important for the metaphoricity of discourses and expressions, and addresses
two research questions more specifically. First, is a metaphorically-perceived
discourse more abstract and more emotional in comparison to a
literally-perceived discourse? Second, is a metaphorical expression preceded by
a more metaphorical/abstract/emotional context than a synonymous literal
alternative? We used a dataset of 1,000 corpus-extracted discourses for which
crowdsourced annotators (1) provided judgements on whether they perceived the
discourses as more metaphorical or more literal, and (2) systematically listed
lexical terms which triggered their decisions in (1). Our results indicate that
metaphorical discourses are more emotional and to a certain extent more
abstract than literal discourses. However, neither the metaphoricity nor the
abstractness and emotionality of the preceding discourse seem to play a role in
triggering the choice between synonymous metaphorical vs. literal expressions.
Our dataset is available at
https://www.ims.uni-stuttgart.de/data/discourse-met-lit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CREATER: CTR-driven Advertising Text Generation with Controlled Pre-Training and Contrastive Fine-Tuning. (arXiv:2205.08943v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08943">
<div class="article-summary-box-inner">
<span><p>This paper focuses on automatically generating the text of an ad, and the
goal is that the generated text can capture user interest for achieving higher
click-through rate (CTR). We propose CREATER, a CTR-driven advertising text
generation approach, to generate ad texts based on high-quality user reviews.
To incorporate CTR objective, our model learns from online A/B test data with
contrastive learning, which encourages the model to generate ad texts that
obtain higher CTR. To alleviate the low-resource issue, we design a customized
self-supervised objective reducing the gap between pre-training and
fine-tuning. Experiments on industrial datasets show that CREATER significantly
outperforms current approaches. It has been deployed online in a leading
advertising platform and brings uplift on core online metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Pseudo-labeled Data to Improve Direct Speech-to-Speech Translation. (arXiv:2205.08993v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08993">
<div class="article-summary-box-inner">
<span><p>Direct Speech-to-speech translation (S2ST) has drawn more and more attention
recently. The task is very challenging due to data scarcity and complex
speech-to-speech mapping. In this paper, we report our recent achievements in
S2ST. Firstly, we build a S2ST Transformer baseline which outperforms the
original Translatotron. Secondly, we utilize the external data by
pseudo-labeling and obtain a new state-of-the-art result on the Fisher
English-to-Spanish test set. Indeed, we exploit the pseudo data with a
combination of popular techniques which are not trivial when applied to S2ST.
Moreover, we evaluate our approach on both syntactically similar
(Spanish-English) and distant (English-Chinese) language pairs. Our
implementation is available at
https://github.com/fengpeng-yue/speech-to-speech-translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Minimising Biasing Word Errors for Contextual ASR with the Tree-Constrained Pointer Generator. (arXiv:2205.09058v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09058">
<div class="article-summary-box-inner">
<span><p>Contextual knowledge is essential for reducing speech recognition errors on
high-valued long-tail words. This paper proposes a novel tree-constrained
pointer generator (TCPGen) component that enables end-to-end ASR models to bias
towards a list of long-tail words obtained using external contextual
information. With only a small overhead in memory use and computation cost,
TCPGen can structure thousands of biasing words efficiently into a symbolic
prefix-tree and creates a neural shortcut between the tree and the final ASR
output to facilitate the recognition of the biasing words. To enhance TCPGen,
we further propose a novel minimum biasing word error (MBWE) loss that directly
optimises biasing word errors during training, along with a biasing-word-driven
language model discounting (BLMD) method during the test. All contextual ASR
systems were evaluated on the public Librispeech audiobook corpus and the data
from the dialogue state tracking challenges (DSTC) with the biasing lists
extracted from the dialogue-system ontology. Consistent word error rate (WER)
reductions were achieved with TCPGen, which were particularly significant on
the biasing words with around 40\% relative reductions in the recognition error
rates. MBWE and BLMD further improved the effectiveness of TCPGen and achieved
more significant WER reductions on the biasing words. TCPGen also achieved
zero-shot learning of words not in the audio training set with large WER
reductions on the out-of-vocabulary words in the biasing list.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Rule Induction for Efficient Semi-Supervised Learning. (arXiv:2205.09067v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09067">
<div class="article-summary-box-inner">
<span><p>Semi-supervised learning has shown promise in allowing NLP models to
generalize from small amounts of labeled data. Meanwhile, pretrained
transformer models act as black-box correlation engines that are difficult to
explain and sometimes behave unreliably. In this paper, we propose tackling
both of these challenges via Automatic Rule Induction (ARI), a simple and
general-purpose framework for the automatic discovery and integration of
symbolic rules into pretrained transformer models. First, we extract weak
symbolic rules from low-capacity machine learning models trained on small
amounts of labeled data. Next, we use an attention mechanism to integrate these
rules into high-capacity pretrained transformer models. Last, the
rule-augmented system becomes part of a self-training framework to boost
supervision signal on unlabeled data. These steps can be layered beneath a
variety of existing weak supervision and semi-supervised NLP algorithms in
order to improve performance and interpretability. Experiments across nine
sequence classification and relation extraction tasks suggest that ARI can
improve state-of-the-art methods with no manual effort and minimal
computational overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dialog Inpainting: Turning Documents into Dialogs. (arXiv:2205.09073v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09073">
<div class="article-summary-box-inner">
<span><p>Many important questions (e.g. "How to eat healthier?") require conversation
to establish context and explore in depth. However, conversational question
answering (ConvQA) systems have long been stymied by scarce training data that
is expensive to collect. To address this problem, we propose a new technique
for synthetically generating diverse and high-quality dialog data: dialog
inpainting. Our approach takes the text of any document and transforms it into
a two-person dialog between the writer and an imagined reader: we treat
sentences from the article as utterances spoken by the writer, and then use a
dialog inpainter to predict what the imagined reader asked or said in between
each of the writer's utterances. By applying this approach to passages from
Wikipedia and the web, we produce WikiDialog and WebDialog, two datasets
totalling 19 million diverse information-seeking dialogs -- 1,000x larger than
the largest existing ConvQA dataset. Furthermore, human raters judge the answer
adequacy and conversationality of WikiDialog to be as good or better than
existing manually-collected datasets. Using our inpainted data to pre-train
ConvQA retrieval systems, we significantly advance state-of-the-art across
three benchmarks (QReCC, OR-QuAC, TREC CAsT) yielding up to 40% relative gains
on standard evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing the Transformer Decoder with Transition-based Syntax. (arXiv:2101.12640v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12640">
<div class="article-summary-box-inner">
<span><p>Notwithstanding recent advances, syntactic generalization remains a challenge
for text decoders. While some studies showed gains from incorporating
source-side symbolic syntactic and semantic structure into text generation
Transformers, very little work addressed the decoding of such structure. We
propose a general approach for tree decoding using a transition-based approach.
Examining the challenging test case of incorporating Universal Dependencies
syntax into machine translation, we present substantial improvements on test
sets that focus on syntactic generalization, while presenting improved or
comparable performance on standard MT benchmarks. Further qualitative analysis
addresses cases where syntactic generalization in the vanilla Transformer
decoder is inadequate and demonstrates the advantages afforded by integrating
syntactic information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation. (arXiv:2103.06874v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06874">
<div class="article-summary-box-inner">
<span><p>Pipelined NLP systems have largely been superseded by end-to-end neural
modeling, yet nearly all commonly-used models still require an explicit
tokenization step. While recent tokenization approaches based on data-derived
subword lexicons are less brittle than manually engineered tokenizers, these
techniques are not equally suited to all languages, and the use of any fixed
vocabulary may limit a model's ability to adapt. In this paper, we present
CANINE, a neural encoder that operates directly on character sequences, without
explicit tokenization or vocabulary, and a pre-training strategy that operates
either directly on characters or optionally uses subwords as a soft inductive
bias. To use its finer-grained input effectively and efficiently, CANINE
combines downsampling, which reduces the input sequence length, with a deep
transformer stack, which encodes context. CANINE outperforms a comparable mBERT
model by 2.8 F1 on TyDi QA, a challenging multilingual benchmark, despite
having 28% fewer model parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-autoregressive Transformer-based End-to-end ASR using BERT. (arXiv:2104.04805v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04805">
<div class="article-summary-box-inner">
<span><p>Transformer-based models have led to significant innovation in classical and
practical subjects as varied as speech processing, natural language processing,
and computer vision. On top of the Transformer, attention-based end-to-end
automatic speech recognition (ASR) models have recently become popular.
Specifically, non-autoregressive modeling, which boasts fast inference and
performance comparable to conventional autoregressive methods, is an emerging
research topic. In the context of natural language processing, the
bidirectional encoder representations from Transformers (BERT) model has
received widespread attention, partially due to its ability to infer
contextualized word representations and to enable superior performance for
downstream tasks while needing only simple fine-tuning. Motivated by the
success, we intend to view speech recognition as a downstream task of BERT,
thus an ASR system is expected to be deduced by performing fine-tuning.
Consequently, to not only inherit the advantages of non-autoregressive ASR
models but also enjoy the benefits of a pre-trained language model (e.g.,
BERT), we propose a non-autoregressive Transformer-based end-to-end ASR model
based on BERT. We conduct a series of experiments on the AISHELL-1 dataset that
demonstrate competitive or superior results for the model when compared to
state-of-the-art ASR systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimCSE: Simple Contrastive Learning of Sentence Embeddings. (arXiv:2104.08821v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08821">
<div class="article-summary-box-inner">
<span><p>This paper presents SimCSE, a simple contrastive learning framework that
greatly advances state-of-the-art sentence embeddings. We first describe an
unsupervised approach, which takes an input sentence and predicts itself in a
contrastive objective, with only standard dropout used as noise. This simple
method works surprisingly well, performing on par with previous supervised
counterparts. We find that dropout acts as minimal data augmentation, and
removing it leads to a representation collapse. Then, we propose a supervised
approach, which incorporates annotated pairs from natural language inference
datasets into our contrastive learning framework by using "entailment" pairs as
positives and "contradiction" pairs as hard negatives. We evaluate SimCSE on
standard semantic textual similarity (STS) tasks, and our unsupervised and
supervised models using BERT base achieve an average of 76.3% and 81.6%
Spearman's correlation respectively, a 4.2% and 2.2% improvement compared to
the previous best results. We also show -- both theoretically and empirically
-- that the contrastive learning objective regularizes pre-trained embeddings'
anisotropic space to be more uniform, and it better aligns positive pairs when
supervised signals are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Word Segmentation from Discrete Speech Units in Low-Resource Settings. (arXiv:2106.04298v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04298">
<div class="article-summary-box-inner">
<span><p>Documenting languages helps to prevent the extinction of endangered dialects,
many of which are otherwise expected to disappear by the end of the century.
When documenting oral languages, unsupervised word segmentation (UWS) from
speech is a useful, yet challenging, task. It consists in producing time-stamps
for slicing utterances into smaller segments corresponding to words, being
performed from phonetic transcriptions, or in the absence of these, from the
output of unsupervised speech discretization models. These discretization
models are trained using raw speech only, producing discrete speech units that
can be applied for downstream (text-based) tasks. In this paper we compare five
of these models: three Bayesian and two neural approaches, with regards to the
exploitability of the produced units for UWS. For the UWS task, we experiment
with two models, using as our target language the Mboshi (Bantu C25), an
unwritten language from Congo-Brazzaville. Additionally, we report results for
Finnish, Hungarian, Romanian and Russian in equally low-resource settings,
using only 4 hours of speech. Our results suggest that neural models for speech
discretization are difficult to exploit in our setting, and that it might be
necessary to adapt them to limit sequence length. We obtain our best UWS
results by using Bayesian models that produce high quality, yet compressed,
discrete representations of the input speech signal.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translatotron 2: High-quality direct speech-to-speech translation with voice preservation. (arXiv:2107.08661v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08661">
<div class="article-summary-box-inner">
<span><p>We present Translatotron 2, a neural direct speech-to-speech translation
model that can be trained end-to-end. Translatotron 2 consists of a speech
encoder, a linguistic decoder, an acoustic synthesizer, and a single attention
module that connects them together. Experimental results on three datasets
consistently show that Translatotron 2 outperforms the original Translatotron
by a large margin on both translation quality (up to +15.5 BLEU) and speech
generation quality, and approaches the same of cascade systems. In addition, we
propose a simple method for preserving speakers' voices from the source speech
to the translation speech in a different language. Unlike existing approaches,
the proposed method is able to preserve each speaker's voice on speaker turns
without requiring for speaker segmentation. Furthermore, compared to existing
approaches, it better preserves speaker's privacy and mitigates potential
misuse of voice cloning for creating spoofing audio artifacts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making Document-Level Information Extraction Right for the Right Reasons. (arXiv:2110.07686v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07686">
<div class="article-summary-box-inner">
<span><p>Document-level models for information extraction tasks like slot-filling are
flexible: they can be applied to settings where information is not necessarily
localized in a single sentence. For example, key features of a diagnosis in a
radiology report may not be explicitly stated in one place, but nevertheless
can be inferred from parts of the report's text. However, these models can
easily learn spurious correlations between labels and irrelevant information.
This work studies how to ensure that these models make correct inferences from
complex text and make those inferences in an auditable way: beyond just being
right, are these models "right for the right reasons?" We experiment with
post-hoc evidence extraction in a predict-select-verify framework using feature
attribution techniques. We show that regularization with small amounts of
evidence supervision during training can substantially improve the quality of
extracted evidence. We evaluate on two domains: a small-scale labeled dataset
of brain MRI reports and a large-scale modified version of DocRED (Yao et al.,
2019) and show that models' plausibility can be improved with no loss in
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object-aware Video-language Pre-training for Retrieval. (arXiv:2112.00656v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00656">
<div class="article-summary-box-inner">
<span><p>Recently, by introducing large-scale dataset and strong transformer network,
video-language pre-training has shown great success especially for retrieval.
Yet, existing video-language transformer models do not explicitly fine-grained
semantic align. In this work, we present Object-aware Transformers, an
object-centric approach that extends video-language transformer to incorporate
object representations. The key idea is to leverage the bounding boxes and
object tags to guide the training process. We evaluate our model on three
standard sub-tasks of video-text matching on four widely used benchmarks. We
also provide deep analysis and detailed ablation about the proposed method. We
show clear improvement in performance across all tasks and datasets considered,
demonstrating the value of a model that incorporates object representations
into a video-language architecture. The code will be released at
\url{https://github.com/FingerRec/OA-Transformer}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Testing the Robustness of a BiLSTM-based Structural Story Classifier. (arXiv:2201.02733v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02733">
<div class="article-summary-box-inner">
<span><p>The growing prevalence of counterfeit stories on the internet has fostered
significant interest towards fast and scalable detection of fake news in the
machine learning community. While several machine learning techniques for this
purpose have emerged, we observe that there is a need to evaluate the impact of
noise on these techniques' performance, where noise constitutes news articles
being mistakenly labeled as fake (or real). This work takes a step in that
direction, where we examine the impact of noise on a state-of-the-art,
structural model based on BiLSTM (Bidirectional Long-Short Term Model) for fake
news detection, Hierarchical Discourse-level Structure for Fake News Detection
by Karimi and Tang (Reference no. 9).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Describing Differences between Text Distributions with Natural Language. (arXiv:2201.12323v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12323">
<div class="article-summary-box-inner">
<span><p>How do two distributions of texts differ? Humans are slow at answering this,
since discovering patterns might require tediously reading through hundreds of
samples. We propose to automatically summarize the differences by "learning a
natural language hypothesis": given two distributions $D_{0}$ and $D_{1}$, we
search for a description that is more often true for $D_{1}$, e.g., "is
military-related." To tackle this problem, we fine-tune GPT-3 to propose
descriptions with the prompt: "[samples of $D_{0}$] + [samples of $D_{1}$] +
the difference between them is_____." We then re-rank the descriptions by
checking how often they hold on a larger set of samples with a learned
verifier. On a benchmark of 54 real-world binary classification tasks, while
GPT-3 Curie (13B) only generates a description similar to human annotation 7%
of the time, the performance reaches 61% with fine-tuning and re-ranking, and
our best system using GPT-3 Davinci (175B) reaches 76%. We apply our system to
describe distribution shifts, debug dataset shortcuts, summarize unknown tasks,
and label text clusters, and present analyses based on automatically generated
descriptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing Pretrained Models of Source Code. (arXiv:2202.08975v2 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08975">
<div class="article-summary-box-inner">
<span><p>Deep learning models are widely used for solving challenging code processing
tasks, such as code generation or code summarization. Traditionally, a specific
model architecture was carefully built to solve a particular code processing
task. However, recently general pretrained models such as CodeBERT or CodeT5
have been shown to outperform task-specific models in many applications. While
pretrained models are known to learn complex patterns from data, they may fail
to understand some properties of source code. To test diverse aspects of code
understanding, we introduce a set of diagnosting probing tasks. We show that
pretrained models of code indeed contain information about code syntactic
structure and correctness, the notions of identifiers, data flow and
namespaces, and natural language naming. We also investigate how probing
results are affected by using code-specific pretraining objectives, varying the
model size, or finetuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trigger-GNN: A Trigger-Based Graph Neural Network for Nested Named Entity Recognition. (arXiv:2204.05518v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05518">
<div class="article-summary-box-inner">
<span><p>Nested named entity recognition (NER) aims to identify the entity boundaries
and recognize categories of the named entities in a complex hierarchical
sentence. Some works have been done using character-level, word-level, or
lexicon-level based models. However, such researches ignore the role of the
complementary annotations. In this paper, we propose a trigger-based graph
neural network (Trigger-GNN) to leverage the nested NER. It obtains the
complementary annotation embeddings through entity trigger encoding and
semantic matching, and tackle nested entity utilizing an efficient graph
message passing architecture, aggregation-update mode. We posit that using
entity triggers as external annotations can add in complementary supervision
signals on the whole sentences. It helps the model to learn and generalize more
efficiently and cost-effectively. Experiments show that the Trigger-GNN
consistently outperforms the baselines on four public NER datasets, and it can
effectively alleviate the nested NER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Back to the Future: Bidirectional Information Decoupling Network for Multi-turn Dialogue Modeling. (arXiv:2204.08152v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08152">
<div class="article-summary-box-inner">
<span><p>Multi-turn dialogue modeling as a challenging branch of natural language
understanding (NLU), aims to build representations for machines to understand
human dialogues, which provides a solid foundation for multiple downstream
tasks. Recent studies of dialogue modeling commonly employ pre-trained language
models (PrLMs) to encode the dialogue history as successive tokens, which is
insufficient in capturing the temporal characteristics of dialogues. Therefore,
we propose Bidirectional Information Decoupling Network (BiDeN) as a universal
dialogue encoder, which explicitly incorporates both the past and future
contexts and can be generalized to a wide range of dialogue-related tasks.
Experimental results on datasets of different downstream tasks demonstrate the
universality and effectiveness of our BiDeN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Parallelize in a Shared-Memory Environment with Transformers. (arXiv:2204.12835v2 [cs.DC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12835">
<div class="article-summary-box-inner">
<span><p>In past years, the world has switched to many-core and multi-core shared
memory architectures. As a result, there is a growing need to utilize these
architectures by introducing shared memory parallelization schemes to software
applications. OpenMP is the most comprehensive API that implements such
schemes, characterized by a readable interface. Nevertheless, introducing
OpenMP into code is challenging due to pervasive pitfalls in management of
parallel shared memory. To facilitate the performance of this task, many
source-to-source (S2S) compilers have been created over the years, tasked with
inserting OpenMP directives into code automatically. In addition to having
limited robustness to their input format, these compilers still do not achieve
satisfactory coverage and precision in locating parallelizable code and
generating appropriate directives. In this work, we propose leveraging recent
advances in ML techniques, specifically in natural language processing (NLP),
to replace S2S compilers altogether. We create a database (corpus), Open-OMP,
specifically for this goal. Open-OMP contains over 28,000 code snippets, half
of which contain OpenMP directives while the other half do not need
parallelization at all with high probability. We use the corpus to train
systems to automatically classify code segments in need of parallelization, as
well as suggest individual OpenMP clauses. We train several transformer models,
named PragFormer, for these tasks, and show that they outperform
statistically-trained baselines and automatic S2S parallelization compilers in
both classifying the overall need for an OpenMP directive and the introduction
of private and reduction clauses.
</p>
<p>Our source code and database are available at:
https://github.com/Scientific-Computing-Lab-NRCN/PragFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supplementary Material: Implementation and Experiments for GAU-based Model. (arXiv:2205.05842v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05842">
<div class="article-summary-box-inner">
<span><p>In February this year Google proposed a new Transformer variant called FLASH,
which has a faster speed, lower VRAM footprint and better performance. This is
achieved by designing a performant layer named GAU (Gated Attention Unit),
which combines the Attention layer and FFN. In this paper, some implementation
details are re-analyzed both theoretically and practically. We then propose a
novel GAU-based model and pre-train it on a Chinese corpus. Results of the CLUE
benchmark show that our model achieves a dev average score of 75.02, 1% higher
than RoFormerV1 and being 45% faster, which is also competitive with
RoFormerV2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing Hate Speech Data along Racial, Gender and Intersectional Axes. (arXiv:2205.06621v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06621">
<div class="article-summary-box-inner">
<span><p>To tackle the rising phenomenon of hate speech, efforts have been made
towards data curation and analysis. When it comes to analysis of bias, previous
work has focused predominantly on race. In our work, we further investigate
bias in hate speech datasets along racial, gender and intersectional axes. We
identify strong bias against African American English (AAE), masculine and
AAE+Masculine tweets, which are annotated as disproportionately more hateful
and offensive than from other demographics. We provide evidence that BERT-based
models propagate this bias and show that balancing the training data for these
protected attributes can lead to fairer models with regards to gender, but not
race.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"What makes a question inquisitive?" A Study on Type-Controlled Inquisitive Question Generation. (arXiv:2205.08056v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08056">
<div class="article-summary-box-inner">
<span><p>We propose a type-controlled framework for inquisitive question generation.
We annotate an inquisitive question dataset with question types, train question
type classifiers, and finetune models for type-controlled question generation.
Empirical results demonstrate that we can generate a variety of questions that
adhere to specific types while drawing from the source texts. We also
investigate strategies for selecting a single question from a generated set,
considering both an informative vs.~inquisitive question classifier and a
pairwise ranker trained from a small set of expert annotations. Question
selection using the pairwise ranker yields strong results in automatic and
manual evaluation. Our human evaluation assesses multiple aspects of the
generated questions, finding that the ranker chooses questions with the best
syntax (4.59), semantics (4.37), and inquisitiveness (3.92) on a scale of 1-5,
even rivaling the performance of human-written questions.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Detection & Recognition in the Wild for Robot Localization. (arXiv:2205.08565v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08565">
<div class="article-summary-box-inner">
<span><p>Signage is everywhere and a robot should be able to take advantage of signs
to help it localize (including Visual Place Recognition (VPR)) and map. Robust
text detection &amp; recognition in the wild is challenging due to such factors as
pose, irregular text, illumination, and occlusion. We propose an end-to-end
scene text spotting model that simultaneously outputs the text string and
bounding boxes. This model is more suitable for VPR. Our central contribution
is introducing utilizing an end-to-end scene text spotting framework to
adequately capture the irregular and occluded text regions in different
challenging places. To evaluate our proposed architecture's performance for
VPR, we conducted several experiments on the challenging Self-Collected Text
Place (SCTP) benchmark dataset. The initial experimental results show that the
proposed method outperforms the SOTA methods in terms of precision and recall
when tested on this benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label-Efficient Self-Supervised Federated Learning for Tackling Data Heterogeneity in Medical Imaging. (arXiv:2205.08576v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08576">
<div class="article-summary-box-inner">
<span><p>The curation of large-scale medical datasets from multiple institutions
necessary for training deep learning models is challenged by the difficulty in
sharing patient data with privacy-preserving. Federated learning (FL), a
paradigm that enables privacy-protected collaborative learning among different
institutions, is a promising solution to this challenge. However, FL generally
suffers from performance deterioration due to heterogeneous data distributions
across institutions and the lack of quality labeled data. In this paper, we
present a robust and label-efficient self-supervised FL framework for medical
image analysis. Specifically, we introduce a novel distributed self-supervised
pre-training paradigm into the existing FL pipeline (i.e., pre-training the
models directly on the decentralized target task datasets). Built upon the
recent success of Vision Transformers, we employ masked image encoding tasks
for self-supervised pre-training, to facilitate more effective knowledge
transfer to downstream federated models. Extensive empirical results on
simulated and real-world medical imaging federated datasets show that
self-supervised pre-training largely benefits the robustness of federated
models against various degrees of data heterogeneity. Notably, under severe
data heterogeneity, our method, without relying on any additional pre-training
data, achieves an improvement of 5.06%, 1.53% and 4.58% in test accuracy on
retinal, dermatology and chest X-ray classification compared with the
supervised baseline with ImageNet pre-training. Moreover, we show that our
self-supervised FL algorithm generalizes well to out-of-distribution data and
learns federated models more effectively in limited label scenarios, surpassing
the supervised baseline by 10.36% and the semi-supervised FL method by 8.3% in
test accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CV4Code: Sourcecode Understanding via Visual Code Representations. (arXiv:2205.08585v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08585">
<div class="article-summary-box-inner">
<span><p>We present CV4Code, a compact and effective computer vision method for
sourcecode understanding. Our method leverages the contextual and the
structural information available from the code snippet by treating each snippet
as a two-dimensional image, which naturally encodes the context and retains the
underlying structural information through an explicit spatial representation.
To codify snippets as images, we propose an ASCII codepoint-based image
representation that facilitates fast generation of sourcecode images and
eliminates redundancy in the encoding that would arise from an RGB pixel
representation. Furthermore, as sourcecode is treated as images, neither
lexical analysis (tokenisation) nor syntax tree parsing is required, which
makes the proposed method agnostic to any particular programming language and
lightweight from the application pipeline point of view. CV4Code can even
featurise syntactically incorrect code which is not possible from methods that
depend on the Abstract Syntax Tree (AST). We demonstrate the effectiveness of
CV4Code by learning Convolutional and Transformer networks to predict the
functional task, i.e. the problem it solves, of the source code directly from
its two-dimensional representation, and using an embedding from its latent
space to derive a similarity score of two code snippets in a retrieval setup.
Experimental results show that our approach achieves state-of-the-art
performance in comparison to other methods with the same task and data
configurations. For the first time we show the benefits of treating sourcecode
understanding as a form of image processing task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RARITYNet: Rarity Guided Affective Emotion Learning Framework. (arXiv:2205.08595v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08595">
<div class="article-summary-box-inner">
<span><p>Inspired from the assets of handcrafted and deep learning approaches, we
proposed a RARITYNet: RARITY guided affective emotion learning framework to
learn the appearance features and identify the emotion class of facial
expressions. The RARITYNet framework is designed by combining the shallow
(RARITY) and deep (AffEmoNet) features to recognize the facial expressions from
challenging images as spontaneous expressions, pose variations, ethnicity
changes, and illumination conditions. The RARITY is proposed to encode the
inter-radial transitional patterns in the local neighbourhood. The AffEmoNet:
affective emotion learning network is proposed by incorporating three feature
streams: high boost edge filtering (HBSEF) stream, to extract the edge
information of highly affected facial expressive regions, multi-scale
sophisticated edge cumulative (MSSEC) stream is to learns the sophisticated
edge information from multi-receptive fields and RARITY uplift complementary
context feature (RUCCF) stream refines the RARITY-encoded features and aid the
MSSEC stream features to enrich the learning ability of RARITYNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robust Low Light Image Enhancement. (arXiv:2205.08615v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08615">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the problem of making brighter images from dark
images found in the wild. The images are dark because they are taken in dim
environments. They suffer from color shifts caused by quantization and from
sensor noise. We don't know the true camera reponse function for such images
and they are not RAW. We use a supervised learning method, relying on a
straightforward simulation of an imaging pipeline to generate usable dataset
for training and testing. On a number of standard datasets, our approach
outperforms the state of the art quantitatively. Qualitative comparisons
suggest strong improvements in reconstruction accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantically Accurate Super-Resolution Generative Adversarial Networks. (arXiv:2205.08659v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08659">
<div class="article-summary-box-inner">
<span><p>This work addresses the problems of semantic segmentation and image
super-resolution by jointly considering the performance of both in training a
Generative Adversarial Network (GAN). We propose a novel architecture and
domain-specific feature loss, allowing super-resolution to operate as a
pre-processing step to increase the performance of downstream computer vision
tasks, specifically semantic segmentation. We demonstrate this approach using
Nearmap's aerial imagery dataset which covers hundreds of urban areas at 5-7 cm
per pixel resolution. We show the proposed approach improves perceived image
quality as well as quantitative segmentation accuracy across all prediction
classes, yielding an average accuracy improvement of 11.8% and 108% at 4x and
32x super-resolution, compared with state-of-the art single-network methods.
This work demonstrates that jointly considering image-based and task-specific
losses can improve the performance of both, and advances the state-of-the-art
in semantic-aware super-resolution of aerial imagery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Monocular Depth Estimation via Selective Distillation of Stereo Knowledge. (arXiv:2205.08668v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08668">
<div class="article-summary-box-inner">
<span><p>Monocular depth estimation has been extensively explored based on deep
learning, yet its accuracy and generalization ability still lag far behind the
stereo-based methods. To tackle this, a few recent studies have proposed to
supervise the monocular depth estimation network by distilling disparity maps
as proxy ground-truths. However, these studies naively distill the stereo
knowledge without considering the comparative advantages of stereo-based and
monocular depth estimation methods. In this paper, we propose to selectively
distill the disparity maps for more reliable proxy supervision. Specifically,
we first design a decoder (MaskDecoder) that learns two binary masks which are
trained to choose optimally between the proxy disparity maps and the estimated
depth maps for each pixel. The learned masks are then fed to another decoder
(DepthDecoder) to enforce the estimated depths to learn from only the masked
area in the proxy disparity maps. Additionally, a Teacher-Student module is
designed to transfer the geometric knowledge of the StereoNet to the MonoNet.
Extensive experiments validate our methods achieve state-of-the-art performance
for self- and proxy-supervised monocular depth estimation on the KITTI dataset,
even surpassing some of the semi-supervised methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">K-textures, a self supervised hard clustering deep learning algorithm for satellite images segmentation. (arXiv:2205.08671v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08671">
<div class="article-summary-box-inner">
<span><p>Deep learning self supervised algorithms that can segment an image in a fixed
number of hard labels such as the k-means algorithm and only relying only on
deep learning techniques are still lacking. Here, we introduce the k-textures
algorithm which provides self supervised segmentation of a 4-band image
(RGB-NIR) for a $k$ number of classes. An example of its application on high
resolution Planet satellite imagery is given. Our algorithm shows that discrete
search is feasible using convolutional neural networks (CNN) and gradient
descent. The model detects $k$ hard clustering classes represented in the model
as $k$ discrete binary masks and their associated $k$ independently generated
textures, that combined are a simulation of the original image. The similarity
loss is the mean squared error between the features of the original and the
simulated image, both extracted from the penultimate convolutional block of
Keras 'imagenet' pretrained VGG-16 model and a custom feature extractor made
with Planet data. The main advances of the k-textures model are: first, the $k$
discrete binary masks are obtained inside the model using gradient descent. The
model allows for the generation of discrete binary masks using a novel method
using a hard sigmoid activation function. Second, it provides hard clustering
classes -- each pixels has only one class. Finally, in comparison to k-means,
where each pixel is considered independently, here, contextual information is
also considered and each class is not associated only to a similar values in
the color channels but to a texture. Our approach is designed to ease the
production of training samples for satellite image segmentation. The model
codes and weights are available at https://doi.org/10.5281/zenodo.6359859
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep learning on rail profiles matching. (arXiv:2205.08687v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08687">
<div class="article-summary-box-inner">
<span><p>Matching the rail cross-section profiles measured on site with the designed
profile is a must to evaluate the wear of the rail, which is very important for
track maintenance and rail safety. So far, the measured rail profiles to be
matched usually have four features, that is, large amount of data, diverse
section shapes, hardware made errors, and human experience needs to be
introduced to solve the complex situation on site during matching process.
However, traditional matching methods based on feature points or feature lines
could no longer meet the requirements. To this end, we first establish the rail
profiles matching dataset composed of 46386 pairs of professional manual
matched data, then propose a general high-precision method for rail profiles
matching using pre-trained convolutional neural network (CNN). This new method
based on deep learning is promising to be the dominant approach for this issue.
Source code is at
https://github.com/Kunqi1994/Deep-learning-on-rail-profile-matching.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyperparameter Optimization with Neural Network Pruning. (arXiv:2205.08695v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08695">
<div class="article-summary-box-inner">
<span><p>Since the deep learning model is highly dependent on hyperparameters,
hyperparameter optimization is essential in developing deep learning
model-based applications, even if it takes a long time. As service development
using deep learning models has gradually become competitive, many developers
highly demand rapid hyperparameter optimization algorithms. In order to keep
pace with the needs of faster hyperparameter optimization algorithms,
researchers are focusing on improving the speed of hyperparameter optimization
algorithm. However, the huge time consumption of hyperparameter optimization
due to the high computational cost of the deep learning model itself has not
been dealt with in-depth. Like using surrogate model in Bayesian optimization,
to solve this problem, it is necessary to consider proxy model for a neural
network (N_B) to be used for hyperparameter optimization. Inspired by the main
goal of neural network pruning, i.e., high computational cost reduction and
performance preservation, we presumed that the neural network (N_P) obtained
through neural network pruning would be a good proxy model of N_B. In order to
verify our idea, we performed extensive experiments by using CIFAR10, CFIAR100,
and TinyImageNet datasets and three generally-used neural networks and three
representative hyperparameter optmization methods. Through these experiments,
we verified that N_P can be a good proxy model of N_B for rapid hyperparameter
optimization. The proposed hyperparameter optimization framework can reduce the
amount of time up to 37%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemiCurv: Semi-Supervised Curvilinear Structure Segmentation. (arXiv:2205.08706v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08706">
<div class="article-summary-box-inner">
<span><p>Recent work on curvilinear structure segmentation has mostly focused on
backbone network design and loss engineering. The challenge of collecting
labelled data, an expensive and labor intensive process, has been overlooked.
While labelled data is expensive to obtain, unlabelled data is often readily
available. In this work, we propose SemiCurv, a semi-supervised learning (SSL)
framework for curvilinear structure segmentation that is able to utilize such
unlabelled data to reduce the labelling burden. Our framework addresses two key
challenges in formulating curvilinear segmentation in a semi-supervised manner.
First, to fully exploit the power of consistency based SSL, we introduce a
geometric transformation as strong data augmentation and then align
segmentation predictions via a differentiable inverse transformation to enable
the computation of pixel-wise consistency. Second, the traditional mean square
error (MSE) on unlabelled data is prone to collapsed predictions and this issue
exacerbates with severe class imbalance (significantly more background pixels).
We propose a N-pair consistency loss to avoid trivial predictions on unlabelled
data. We evaluate SemiCurv on six curvilinear segmentation datasets, and find
that with no more than 5% of the labelled data, it achieves close to 95% of the
performance relative to its fully supervised counterpart.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">It Isn't Sh!tposting, It's My CAT Posting. (arXiv:2205.08710v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08710">
<div class="article-summary-box-inner">
<span><p>In this paper, we describe a novel architecture which can generate hilarious
captions for a given input image. The architecture is split into two halves,
i.e. image captioning and hilarious text conversion. The architecture starts
with a pre-trained CNN model, VGG16 in this implementation, and applies
attention LSTM on it to generate normal caption. These normal captions then are
fed forward to our hilarious text conversion transformer which converts this
text into something hilarious while maintaining the context of the input image.
The architecture can also be split into two halves and only the seq2seq
transformer can be used to generate hilarious caption by inputting a
sentence.This paper aims to help everyday user to be more lazy and hilarious at
the same time by generating captions using CATNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse MDOD: Training End-to-End Multi-Object Detector without Bipartite Matching. (arXiv:2205.08714v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08714">
<div class="article-summary-box-inner">
<span><p>Recent end-to-end multi-object detectors simplify the inference pipeline by
removing the hand-crafted process such as the duplicate bounding box removal
using non-maximum suppression (NMS). However, in the training, they require
bipartite matching to calculate the loss from the output of the detector.
Contrary to the directivity of the end-to-end method, the bipartite matching
makes the training of the end-to-end detector complex, heuristic, and reliant.
In this paper, we aim to propose a method to train the end-to-end multi-object
detector without bipartite matching. To this end, we approach end-to-end
multi-object detection as a density estimation using a mixture model. Our
proposed detector, called Sparse Mixture Density Object Detector (Sparse MDOD)
estimates the distribution of bounding boxes using a mixture model. Sparse MDOD
is trained by minimizing the negative log-likelihood and our proposed
regularization term, maximum component maximization (MCM) loss that prevents
duplicated predictions. During training, no additional procedure such as
bipartite matching is needed, and the loss is directly computed from the
network outputs. Moreover, our Sparse MDOD outperforms the existing detectors
on MS-COCO, a renowned multi-object detection benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RandomMix: A mixed sample data augmentation method with multiple mixed modes. (arXiv:2205.08728v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08728">
<div class="article-summary-box-inner">
<span><p>Data augmentation is a very practical technique that can be used to improve
the generalization ability of neural networks and prevent overfitting.
Recently, mixed sample data augmentation has received a lot of attention and
achieved great success. In order to enhance the performance of mixed sample
data augmentation, a series of recent works are devoted to obtaining and
analyzing the salient regions of the image, and using the saliency area to
guide the image mixing. However, obtaining the salient information of an image
requires a lot of extra calculations. Different from improving performance
through saliency analysis, our proposed method RandomMix mainly increases the
diversity of the mixed sample to enhance the generalization ability and
performance of neural networks. Moreover, RandomMix can improve the robustness
of the model, does not require too much additional calculation, and is easy to
insert into the training pipeline. Finally, experiments on the CIFAR-10/100,
Tiny-ImageNet, ImageNet, and Google Speech Commands datasets demonstrate that
RandomMix achieves better performance than other state-of-the-art mixed sample
data augmentation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TTAPS: Test-Time Adaption by Aligning Prototypes using Self-Supervision. (arXiv:2205.08731v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08731">
<div class="article-summary-box-inner">
<span><p>Nowadays, deep neural networks outperform humans in many tasks. However, if
the input distribution drifts away from the one used in training, their
performance drops significantly. Recently published research has shown that
adapting the model parameters to the test sample can mitigate this performance
degradation. In this paper, we therefore propose a novel modification of the
self-supervised training algorithm SwAV that adds the ability to adapt to
single test samples. Using the provided prototypes of SwAV and our derived
test-time loss, we align the representation of unseen test samples with the
self-supervised learned prototypes. We show the success of our method on the
common benchmark dataset CIFAR10-C.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep-learned orthogonal basis patterns for fast, noise-robust single-pixel imaging. (arXiv:2205.08736v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08736">
<div class="article-summary-box-inner">
<span><p>Single-pixel imaging (SPI) is a novel, unconventional method that goes beyond
the notion of traditional cameras but can be computationally expensive and slow
for real-time applications. Deep learning has been proposed as an alternative
approach for solving the SPI reconstruction problem, but a detailed analysis of
its performance and generated basis patterns when used for SPI is limited. We
present a modified deep convolutional autoencoder network (DCAN) for SPI on
64x64 pixel images with up to 6.25% compression ratio and apply binary and
orthogonality regularizers during training. Training a DCAN with these
regularizers allows it to learn multiple measurement bases that have
combinations of binary or non-binary, and orthogonal or non-orthogonal
patterns. We compare the reconstruction quality, orthogonality of the patterns,
and robustness to noise of the resulting DCAN models to traditional SPI
reconstruction algorithms (such as Total Variation minimization and Fourier
Transform). Our DCAN models can be trained to be robust to noise while still
having fast enough reconstruction times (~3 ms per frame) to be viable for
real-time imaging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Passive Defense Against 3D Adversarial Point Clouds Through the Lens of 3D Steganalysis. (arXiv:2205.08738v1 [cs.MM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08738">
<div class="article-summary-box-inner">
<span><p>Nowadays, 3D data plays an indelible role in the computer vision field.
However, extensive studies have proved that deep neural networks (DNNs) fed
with 3D data, such as point clouds, are susceptible to adversarial examples,
which aim to misguide DNNs and might bring immeasurable losses. Currently, 3D
adversarial point clouds are chiefly generated in three fashions, i.e., point
shifting, point adding, and point dropping. These point manipulations would
modify geometrical properties and local correlations of benign point clouds
more or less. Motivated by this basic fact, we propose to defend such
adversarial examples with the aid of 3D steganalysis techniques. Specifically,
we first introduce an adversarial attack and defense model adapted from the
celebrated Prisoners' Problem in steganography to help us comprehend 3D
adversarial attack and defense more generally. Then we rethink two significant
but vague concepts in the field of adversarial example, namely, active defense
and passive defense, from the perspective of steganalysis. Most importantly, we
design a 3D adversarial point cloud detector through the lens of 3D
steganalysis. Our detector is double-blind, that is to say, it does not rely on
the exact knowledge of the adversarial attack means and victim models. To
enable the detector to effectively detect malicious point clouds, we craft a
64-D discriminant feature set, including features related to first-order and
second-order local descriptions of point clouds. To our knowledge, this work is
the first to apply 3D steganalysis to 3D adversarial example defense. Extensive
experimental results demonstrate that the proposed 3D adversarial point cloud
detector can achieve good detection performance on multiple types of 3D
adversarial point clouds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Validation of a photogrammetric approach for the study of ancient bowed instruments. (arXiv:2205.08745v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08745">
<div class="article-summary-box-inner">
<span><p>Some ancient violins have been reduced throughout their history. We propose
an objective photogrammetric approach to differentiate between a reduced and an
unreduced instrument, where a three-dimensional mesh is studied geometrically
by examining 2D slices. First, we validate the accuracy of the photogrammetric
mesh by the way of a comparison with reference images obtained with medical
imaging. Then, we show how contour lines and channels of minima can be
automatically extracted from the photogrammetric meshes, allowing to
successfully highlight differences between instruments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Attention-based Self-supervised Absolute Depth Estimation using Geometric Priors in Autonomous Driving. (arXiv:2205.08780v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08780">
<div class="article-summary-box-inner">
<span><p>Although existing monocular depth estimation methods have made great
progress, predicting an accurate absolute depth map from a single image is
still challenging due to the limited modeling capacity of networks and the
scale ambiguity issue. In this paper, we introduce a fully Visual
Attention-based Depth (VADepth) network, where spatial attention and channel
attention are applied to all stages. By continuously extracting the
dependencies of features along the spatial and channel dimensions over a long
distance, VADepth network can effectively preserve important details and
suppress interfering features to better perceive the scene structure for more
accurate depth estimates. In addition, we utilize geometric priors to form
scale constraints for scale-aware model training. Specifically, we construct a
novel scale-aware loss using the distance between the camera and a plane fitted
by the ground points corresponding to the pixels of the rectangular area in the
bottom middle of the image. Experimental results on the KITTI dataset show that
this architecture achieves the state-of-the-art performance and our method can
directly output absolute depth without post-processing. Moreover, our
experiments on the SeasonDepth dataset also demonstrate the robustness of our
model to multiple unseen environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-subject Action Unit Detection with Meta Learning and Transformer-based Relation Modeling. (arXiv:2205.08787v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08787">
<div class="article-summary-box-inner">
<span><p>Facial Action Unit (AU) detection is a crucial task for emotion analysis from
facial movements. The apparent differences of different subjects sometimes
mislead changes brought by AUs, resulting in inaccurate results. However, most
of the existing AU detection methods based on deep learning didn't consider the
identity information of different subjects. The paper proposes a
meta-learning-based cross-subject AU detection model to eliminate the
identity-caused differences. Besides, a transformer-based relation learning
module is introduced to learn the latent relations of multiple AUs. To be
specific, our proposed work is composed of two sub-tasks. The first sub-task is
meta-learning-based AU local region representation learning, called MARL, which
learns discriminative representation of local AU regions that incorporates the
shared information of multiple subjects and eliminates identity-caused
differences. The second sub-task uses the local region representation of AU of
the first sub-task as input, then adds relationship learning based on the
transformer encoder architecture to capture AU relationships. The entire
training process is cascaded. Ablation study and visualization show that our
MARL can eliminate identity-caused differences, thus obtaining a robust and
generalized AU discriminative embedding representation. Our results prove that
on the two public datasets BP4D and DISFA, our method is superior to the
state-of-the-art technology, and the F1 score is improved by 1.3% and 1.4%,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PhoCaL: A Multi-Modal Dataset for Category-Level Object Pose Estimation with Photometrically Challenging Objects. (arXiv:2205.08811v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08811">
<div class="article-summary-box-inner">
<span><p>Object pose estimation is crucial for robotic applications and augmented
reality. Beyond instance level 6D object pose estimation methods, estimating
category-level pose and shape has become a promising trend. As such, a new
research field needs to be supported by well-designed datasets. To provide a
benchmark with high-quality ground truth annotations to the community, we
introduce a multimodal dataset for category-level object pose estimation with
photometrically challenging objects termed PhoCaL. PhoCaL comprises 60 high
quality 3D models of household objects over 8 categories including highly
reflective, transparent and symmetric objects. We developed a novel
robot-supported multi-modal (RGB, depth, polarisation) data acquisition and
annotation process. It ensures sub-millimeter accuracy of the pose for opaque
textured, shiny and transparent objects, no motion blur and perfect camera
synchronisation. To set a benchmark for our dataset, state-of-the-art RGB-D and
monocular RGB methods are evaluated on the challenging scenes of PhoCaL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anomaly detection using prediction error with Spatio-Temporal Convolutional LSTM. (arXiv:2205.08812v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08812">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel method for video anomaly detection
motivated by an existing architecture for sequence-to-sequence prediction and
reconstruction using a spatio-temporal convolutional Long Short-Term Memory
(convLSTM). As in previous work on anomaly detection, anomalies arise as
spatially localised failures in reconstruction or prediction. In experiments
with five benchmark datasets, we show that using prediction gives superior
performance to using reconstruction. We also compare performance with different
length input/output sequences. Overall, our results using prediction are
comparable with the state of the art on the benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speckle Image Restoration without Clean Data. (arXiv:2205.08833v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08833">
<div class="article-summary-box-inner">
<span><p>Speckle noise is an inherent disturbance in coherent imaging systems such as
digital holography, synthetic aperture radar, optical coherence tomography, or
ultrasound systems. These systems usually produce only single observation per
view angle of the same interest object, imposing the difficulty to leverage the
statistic among observations. We propose a novel image restoration algorithm
that can perform speckle noise removal without clean data and does not require
multiple noisy observations in the same view angle. Our proposed method can
also be applied to the situation without knowing the noise distribution as
prior. We demonstrate our method is especially well-suited for spectral images
by first validating on the synthetic dataset, and also applied on real-world
digital holography samples. The results are superior in both quantitative
measurement and visual inspection compared to several widely applied baselines.
Our method even shows promising results across different speckle noise
strengths, without the clean data needed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Neural Networks Learning from Scratch with Very Few Data and without Regularization. (arXiv:2205.08836v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08836">
<div class="article-summary-box-inner">
<span><p>Recent findings have shown that Neural Networks generalize also in
over-parametrized regimes with zero training error. This is surprising, since
it is completely against traditional machine learning wisdom. In our empirical
study we fortify these findings in the domain of fine-grained image
classification. We show that very large Convolutional Neural Networks with
millions of weights do learn with only a handful of training samples and
without image augmentation, explicit regularization or pretraining. We train
the architectures ResNet018, ResNet101 and VGG19 on subsets of the difficult
benchmark datasets Caltech101, CUB_200_2011, FGVCAircraft, Flowers102 and
StanfordCars with 100 classes and more, perform a comprehensive comparative
study and draw implications for the practical application of CNNs. Finally, we
show that VGG19 with 140 million weights learns to distinguish airplanes and
motorbikes up to 95% accuracy with only 20 samples per class.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Positional Information is All You Need: A Novel Pipeline for Self-Supervised SVDE from Videos. (arXiv:2205.08851v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08851">
<div class="article-summary-box-inner">
<span><p>Recently, much attention has been drawn to learning the underlying 3D
structures of a scene from monocular videos in a fully self-supervised fashion.
One of the most challenging aspects of this task is handling the independently
moving objects as they break the rigid-scene assumption. For the first time, we
show that pixel positional information can be exploited to learn SVDE (Single
View Depth Estimation) from videos. Our proposed moving object (MO) masks,
which are induced by shifted positional information (SPI) and referred to as
`SPIMO' masks, are very robust and consistently remove the independently moving
objects in the scenes, allowing for better learning of SVDE from videos.
Additionally, we introduce a new adaptive quantization scheme that assigns the
best per-pixel quantization curve for our depth discretization. Finally, we
employ existing boosting techniques in a new way to further self-supervise the
depth of the moving objects. With these features, our pipeline is robust
against moving objects and generalizes well to high-resolution images, even
when trained with small patches, yielding state-of-the-art (SOTA) results with
almost 8.5x fewer parameters than the previous works that learn from videos. We
present extensive experiments on KITTI and CityScapes that show the
effectiveness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer based multiple instance learning for weakly supervised histopathology image segmentation. (arXiv:2205.08878v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08878">
<div class="article-summary-box-inner">
<span><p>Hispathological image segmentation algorithms play a critical role in
computer aided diagnosis technology. The development of weakly supervised
segmentation algorithm alleviates the problem of medical image annotation that
it is time-consuming and labor-intensive. As a subset of weakly supervised
learning, Multiple Instance Learning (MIL) has been proven to be effective in
segmentation. However, there is a lack of related information between instances
in MIL, which limits the further improvement of segmentation performance. In
this paper, we propose a novel weakly supervised method for pixel-level
segmentation in histopathology images, which introduces Transformer into the
MIL framework to capture global or long-range dependencies. The multi-head
self-attention in the Transformer establishes the relationship between
instances, which solves the shortcoming that instances are independent of each
other in MIL. In addition, deep supervision is introduced to overcome the
limitation of annotations in weakly supervised methods and make the better
utilization of hierarchical information. The state-of-the-art results on the
colon cancer dataset demonstrate the superiority of the proposed method
compared with other weakly supervised methods. It is worth believing that there
is a potential of our approach for various applications in medical images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Segmentation Guided Style-based Generative Adversarial Networks for PET Synthesis. (arXiv:2205.08887v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08887">
<div class="article-summary-box-inner">
<span><p>Potential radioactive hazards in full-dose positron emission tomography (PET)
imaging remain a concern, whereas the quality of low-dose images is never
desirable for clinical use. So it is of great interest to translate low-dose
PET images into full-dose. Previous studies based on deep learning methods
usually directly extract hierarchical features for reconstruction. We notice
that the importance of each feature is different and they should be weighted
dissimilarly so that tiny information can be captured by the neural network.
Furthermore, the synthesis on some regions of interest is important in some
applications. Here we propose a novel segmentation guided style-based
generative adversarial network (SGSGAN) for PET synthesis. (1) We put forward a
style-based generator employing style modulation, which specifically controls
the hierarchical features in the translation process, to generate images with
more realistic textures. (2) We adopt a task-driven strategy that couples a
segmentation task with a generative adversarial network (GAN) framework to
improve the translation performance. Extensive experiments show the superiority
of our overall framework in PET synthesis, especially on those regions of
interest.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Remote Sensing Novel View Synthesis with Implicit Multiplane Representations. (arXiv:2205.08908v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08908">
<div class="article-summary-box-inner">
<span><p>Novel view synthesis of remote sensing scenes is of great significance for
scene visualization, human-computer interaction, and various downstream
applications. Despite the recent advances in computer graphics and
photogrammetry technology, generating novel views is still challenging
particularly for remote sensing images due to its high complexity, view
sparsity and limited view-perspective variations. In this paper, we propose a
novel remote sensing view synthesis method by leveraging the recent advances in
implicit neural representations. Considering the overhead and far depth imaging
of remote sensing images, we represent the 3D space by combining implicit
multiplane images (MPI) representation and deep neural networks. The 3D scene
is reconstructed under a self-supervised optimization paradigm through a
differentiable multiplane renderer with multi-view input constraints. Images
from any novel views thus can be freely rendered on the basis of the
reconstructed model. As a by-product, the depth maps corresponding to the given
viewpoint can be generated along with the rendering output. We refer to our
method as Implicit Multiplane Images (ImMPI). To further improve the view
synthesis under sparse-view inputs, we explore the learning-based
initialization of remote sensing 3D scenes and proposed a neural network based
Prior extractor to accelerate the optimization process. In addition, we propose
a new dataset for remote sensing novel view synthesis with multi-view
real-world google earth images. Extensive experiments demonstrate the
superiority of the ImMPI over previous state-of-the-art methods in terms of
reconstruction accuracy, visual fidelity, and time efficiency. Ablation
experiments also suggest the effectiveness of our methodology design. Our
dataset and code can be found at https://github.com/wyc-Chang/ImMPI
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Financial Time Series Data Augmentation with Generative Adversarial Networks and extended Intertemporal Return Plots. (arXiv:2205.08924v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08924">
<div class="article-summary-box-inner">
<span><p>Data augmentation is a key regularization method to support the forecast and
classification performance of highly parameterized models in computer vision.
In the time series domain however, regularization in terms of augmentation is
not equally common even though these methods have proven to mitigate effects
from small sample size or non-stationarity. In this paper we apply state-of-the
art image-based generative models for the task of data augmentation and
introduce the extended intertemporal return plot (XIRP), a new image
representation for time series. Multiple tests are conducted to assess the
quality of the augmentation technique regarding its ability to synthesize time
series effectively and improve forecast results on a subset of the M4
competition. We further investigate the relationship between data set
characteristics and sampling results via Shapley values for feature attribution
on the performance metrics and the optimal ratio of augmented data. Over all
data sets, our approach proves to be effective in reducing the return forecast
error by 7% on 79% of the financial data sets with varying statistical
properties and frequencies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-Net UV: An End-to-End Spatio-Temporal Deep Neural Network Architecture for Automated Diagnosis of COVID-19 Infection from Ultrasound Videos. (arXiv:2205.08932v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08932">
<div class="article-summary-box-inner">
<span><p>Besides vaccination, as an effective way to mitigate the further spread of
COVID-19, fast and accurate screening of individuals to test for the disease is
yet necessary to ensure public health safety. We propose COVID-Net UV, an
end-to-end hybrid spatio-temporal deep neural network architecture, to detect
COVID-19 infection from lung point-of-care ultrasound videos captured by convex
transducers. COVID-Net UV comprises a convolutional neural network that
extracts spatial features and a recurrent neural network that learns temporal
dependence. After careful hyperparameter tuning, the network achieves an
average accuracy of 94.44% with no false-negative cases for COVID-19 cases. The
goal with COVID-Net UV is to assist front-line clinicians in the fight against
COVID-19 via accelerating the screening of lung point-of-care ultrasound videos
and automatic detection of COVID-19 positive cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Features for CBIR with Scarce Data using Hebbian Learning. (arXiv:2205.08935v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08935">
<div class="article-summary-box-inner">
<span><p>Features extracted from Deep Neural Networks (DNNs) have proven to be very
effective in the context of Content Based Image Retrieval (CBIR). In recent
work, biologically inspired \textit{Hebbian} learning algorithms have shown
promises for DNN training. In this contribution, we study the performance of
such algorithms in the development of feature extractors for CBIR tasks.
Specifically, we consider a semi-supervised learning strategy in two steps:
first, an unsupervised pre-training stage is performed using Hebbian learning
on the image dataset; second, the network is fine-tuned using supervised
Stochastic Gradient Descent (SGD) training. For the unsupervised pre-training
stage, we explore the nonlinear Hebbian Principal Component Analysis (HPCA)
learning rule. For the supervised fine-tuning stage, we assume sample
efficiency scenarios, in which the amount of labeled samples is just a small
fraction of the whole dataset. Our experimental analysis, conducted on the
CIFAR10 and CIFAR100 datasets shows that, when few labeled samples are
available, our Hebbian approach provides relevant improvements compared to
various alternative methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A lightweight multi-scale context network for salient object detection in optical remote sensing images. (arXiv:2205.08959v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08959">
<div class="article-summary-box-inner">
<span><p>Due to the more dramatic multi-scale variations and more complicated
foregrounds and backgrounds in optical remote sensing images (RSIs), the
salient object detection (SOD) for optical RSIs becomes a huge challenge.
However, different from natural scene images (NSIs), the discussion on the
optical RSI SOD task still remains scarce. In this paper, we propose a
multi-scale context network, namely MSCNet, for SOD in optical RSIs.
Specifically, a multi-scale context extraction module is adopted to address the
scale variation of salient objects by effectively learning multi-scale
contextual information. Meanwhile, in order to accurately detect complete
salient objects in complex backgrounds, we design an attention-based pyramid
feature aggregation mechanism for gradually aggregating and refining the
salient regions from the multi-scale context extraction module. Extensive
experiments on two benchmarks demonstrate that MSCNet achieves competitive
performance with only 3.26M parameters. The code will be available at
https://github.com/NuaaYH/MSCNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DL4DS -- Deep Learning for empirical DownScaling. (arXiv:2205.08967v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08967">
<div class="article-summary-box-inner">
<span><p>A common task in Earth Sciences is to infer climate information at local and
regional scales from global climate models. Dynamical downscaling requires
running expensive numerical models at high resolution which can be prohibitive
due to long model runtimes. On the other hand, statistical downscaling
techniques present an alternative approach for learning links between the
large- and local-scale climate in a more efficient way. A large number of deep
neural network-based approaches for statistical downscaling have been proposed
in recent years, mostly based on convolutional architectures developed for
computer vision and super-resolution tasks. This paper presents DL4DS, Deep
Learning for empirical DownScaling, a python library that implements a wide
variety of state-of-the-art and novel algorithms for downscaling gridded Earth
Science data with deep neural networks. DL4DS has been designed with the goal
of providing a general framework for training convolutional neural networks
with configurable architectures and learning strategies to facilitate the
conduction of comparative and ablation studies in a robust way. We showcase the
capabilities of DL4DS on air quality CAMS data over the western Mediterranean
area. The DL4DS library can be found in this repository:
https://github.com/carlos-gg/dl4ds
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trading Positional Complexity vs. Deepness in Coordinate Networks. (arXiv:2205.08987v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08987">
<div class="article-summary-box-inner">
<span><p>It is well noted that coordinate-based MLPs benefit -- in terms of preserving
high-frequency information -- through the encoding of coordinate positions as
an array of Fourier features. Hitherto, the rationale for the effectiveness of
these positional encodings has been mainly studied through a Fourier lens. In
this paper, we strive to broaden this understanding by showing that alternative
non-Fourier embedding functions can indeed be used for positional encoding.
Moreover, we show that their performance is entirely determined by a trade-off
between the stable rank of the embedded matrix and the distance preservation
between embedded coordinates. We further establish that the now ubiquitous
Fourier feature mapping of position is a special case that fulfills these
conditions. Consequently, we present a more general theory to analyze
positional encoding in terms of shifted basis functions. In addition, we argue
that employing a more complex positional encoding -- that scales exponentially
with the number of modes -- requires only a linear (rather than deep)
coordinate function to achieve comparable performance. Counter-intuitively, we
demonstrate that trading positional embedding complexity for network deepness
is orders of magnitude faster than current state-of-the-art; despite the
additional embedding complexity. To this end, we develop the necessary
theoretical formulae and empirically verify that our theoretical claims hold in
practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constraining the Attack Space of Machine Learning Models with Distribution Clamping Preprocessing. (arXiv:2205.08989v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08989">
<div class="article-summary-box-inner">
<span><p>Preprocessing and outlier detection techniques have both been applied to
neural networks to increase robustness with varying degrees of success. In this
paper, we formalize the ideal preprocessor function as one that would take any
input and set it to the nearest in-distribution input. In other words, we
detect any anomalous pixels and set them such that the new input is
in-distribution. We then illustrate a relaxed solution to this problem in the
context of patch attacks. Specifically, we demonstrate that we can model
constraints on the patch attack that specify regions as out of distribution.
With these constraints, we are able to preprocess inputs successfully,
increasing robustness on CARLA object detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empirical Advocacy of Bio-inspired Models for Robust Image Recognition. (arXiv:2205.09037v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09037">
<div class="article-summary-box-inner">
<span><p>Deep convolutional neural networks (DCNNs) have revolutionized computer
vision and are often advocated as good models of the human visual system.
However, there are currently many shortcomings of DCNNs, which preclude them as
a model of human vision. There are continuous attempts to use features of the
human visual system to improve the robustness of neural networks to data
perturbations. We provide a detailed analysis of such bio-inspired models and
their properties. To this end, we benchmark the robustness of several
bio-inspired models against their most comparable baseline DCNN models. We find
that bio-inspired models tend to be adversarially robust without requiring any
special data augmentation. Additionally, we find that bio-inspired models beat
adversarially trained models in the presence of more real-world common
corruptions. Interestingly, we also find that bio-inspired models tend to use
both low and mid-frequency information, in contrast to other DCNN models. We
find that this mix of frequency information makes them robust to both
adversarial perturbations and common corruptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global Contrast Masked Autoencoders Are Powerful Pathological Representation Learners. (arXiv:2205.09048v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09048">
<div class="article-summary-box-inner">
<span><p>Based on digital whole slide scanning technique, artificial intelligence
algorithms represented by deep learning have achieved remarkable results in the
field of computational pathology. Compared with other medical images such as
Computed Tomography (CT) or Magnetic Resonance Imaging (MRI), pathological
images are more difficult to annotate, thus there is an extreme lack of data
sets that can be used for supervised learning. In this study, a self-supervised
learning (SSL) model, Global Contrast Masked Autoencoders (GCMAE), is proposed,
which has the ability to represent both global and local domain-specific
features of whole slide image (WSI), as well as excellent cross-data transfer
ability. The Camelyon16 and NCTCRC datasets are used to evaluate the
performance of our model. When dealing with transfer learning tasks with
different data sets, the experimental results show that GCMAE has better linear
classification accuracy than MAE, which can reach 81.10% and 89.22%
respectively. Our method outperforms the previous state-of-the-art algorithm
and even surpass supervised learning (improved by 3.86% on NCTCRC data sets).
The source code of this paper is publicly available at
https://github.com/StarUniversus/gcmae
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VRAG: Region Attention Graphs for Content-Based Video Retrieval. (arXiv:2205.09068v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09068">
<div class="article-summary-box-inner">
<span><p>Content-based Video Retrieval (CBVR) is used on media-sharing platforms for
applications such as video recommendation and filtering. To manage databases
that scale to billions of videos, video-level approaches that use fixed-size
embeddings are preferred due to their efficiency. In this paper, we introduce
Video Region Attention Graph Networks (VRAG) that improves the state-of-the-art
of video-level methods. We represent videos at a finer granularity via
region-level features and encode video spatio-temporal dynamics through
region-level relations. Our VRAG captures the relationships between regions
based on their semantic content via self-attention and the permutation
invariant aggregation of Graph Convolution. In addition, we show that the
performance gap between video-level and frame-level methods can be reduced by
segmenting videos into shots and using shot embeddings for video retrieval. We
evaluate our VRAG over several video retrieval tasks and achieve a new
state-of-the-art for video-level retrieval. Furthermore, our shot-level VRAG
shows higher retrieval precision than other existing video-level methods, and
closer performance to frame-level methods at faster evaluation speeds. Finally,
our code will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pluralistic Image Completion with Probabilistic Mixture-of-Experts. (arXiv:2205.09086v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09086">
<div class="article-summary-box-inner">
<span><p>Pluralistic image completion focuses on generating both visually realistic
and diverse results for image completion. Prior methods enjoy the empirical
successes of this task. However, their used constraints for pluralistic image
completion are argued to be not well interpretable and unsatisfactory from two
aspects. First, the constraints for visual reality can be weakly correlated to
the objective of image completion or even redundant. Second, the constraints
for diversity are designed to be task-agnostic, which causes the constraints to
not work well. In this paper, to address the issues, we propose an end-to-end
probabilistic method. Specifically, we introduce a unified probabilistic graph
model that represents the complex interactions in image completion. The entire
procedure of image completion is then mathematically divided into several
sub-procedures, which helps efficient enforcement of constraints. The
sub-procedure directly related to pluralistic results is identified, where the
interaction is established by a Gaussian mixture model (GMM). The inherent
parameters of GMM are task-related, which are optimized adaptively during
training, while the number of its primitives can control the diversity of
results conveniently. We formally establish the effectiveness of our method and
demonstrate it with comprehensive experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BodyMap: Learning Full-Body Dense Correspondence Map. (arXiv:2205.09111v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09111">
<div class="article-summary-box-inner">
<span><p>Dense correspondence between humans carries powerful semantic information
that can be utilized to solve fundamental problems for full-body understanding
such as in-the-wild surface matching, tracking and reconstruction. In this
paper we present BodyMap, a new framework for obtaining high-definition
full-body and continuous dense correspondence between in-the-wild images of
clothed humans and the surface of a 3D template model. The correspondences
cover fine details such as hands and hair, while capturing regions far from the
body surface, such as loose clothing. Prior methods for estimating such dense
surface correspondence i) cut a 3D body into parts which are unwrapped to a 2D
UV space, producing discontinuities along part seams, or ii) use a single
surface for representing the whole body, but none handled body details. Here,
we introduce a novel network architecture with Vision Transformers that learn
fine-level features on a continuous body surface. BodyMap outperforms prior
work on various metrics and datasets, including DensePose-COCO by a large
margin. Furthermore, we show various applications ranging from multi-layer
dense cloth correspondence, neural rendering with novel-view synthesis and
appearance swapping.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masked Autoencoders As Spatiotemporal Learners. (arXiv:2205.09113v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09113">
<div class="article-summary-box-inner">
<span><p>This paper studies a conceptually simple extension of Masked Autoencoders
(MAE) to spatiotemporal representation learning from videos. We randomly mask
out spacetime patches in videos and learn an autoencoder to reconstruct them in
pixels. Interestingly, we show that our MAE method can learn strong
representations with almost no inductive bias on spacetime (only except for
patch and positional embeddings), and spacetime-agnostic random masking
performs the best. We observe that the optimal masking ratio is as high as 90%
(vs. 75% on images), supporting the hypothesis that this ratio is related to
information redundancy of the data. A high masking ratio leads to a large
speedup, e.g., &gt; 4x in wall-clock time or even more. We report competitive
results on several challenging video datasets using vanilla Vision
Transformers. We observe that MAE can outperform supervised pre-training by
large margins. We further report encouraging results of training on real-world,
uncurated Instagram data. Our study suggests that the general framework of
masked autoencoding (BERT, MAE, etc.) can be a unified methodology for
representation learning with minimal domain knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Selective Sensor Fusion for States Estimation. (arXiv:1912.13077v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.13077">
<div class="article-summary-box-inner">
<span><p>Autonomous vehicles and mobile robotic systems are typically equipped with
multiple sensors to provide redundancy. By integrating the observations from
different sensors, these mobile agents are able to perceive the environment and
estimate system states, e.g. locations and orientations. Although deep learning
approaches for multimodal odometry estimation and localization have gained
traction, they rarely focus on the issue of robust sensor fusion - a necessary
consideration to deal with noisy or incomplete sensor observations in the real
world. Moreover, current deep odometry models suffer from a lack of
interpretability. To this extent, we propose SelectFusion, an end-to-end
selective sensor fusion module which can be applied to useful pairs of sensor
modalities such as monocular images and inertial measurements, depth images and
LIDAR point clouds. Our model is a uniform framework that is not restricted to
specific modality or task. During prediction, the network is able to assess the
reliability of the latent features from different sensor modalities and
estimate trajectory both at scale and global pose. In particular, we propose
two fusion modules - a deterministic soft fusion and a stochastic hard fusion,
and offer a comprehensive study of the new strategies compared to trivial
direct fusion. We extensively evaluate all fusion strategies in both public
datasets and on progressively degraded datasets that present synthetic
occlusions, noisy and missing data and time misalignment between sensors, and
we investigate the effectiveness of the different fusion strategies in
attending the most reliable features, which in itself, provides insights into
the operation of the various models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Increasing-Margin Adversarial (IMA) Training to Improve Adversarial Robustness of Neural Networks. (arXiv:2005.09147v8 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.09147">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) are vulnerable to adversarial noises. By adding
adversarial noises to training samples, adversarial training can improve the
model's robustness against adversarial noises. However, adversarial training
samples with excessive noises can harm standard accuracy, which may be
unacceptable for many medical image analysis applications. This issue has been
termed the trade-off between standard accuracy and adversarial robustness. In
this paper, we hypothesize that this issue may be alleviated if the adversarial
samples for training are placed right on the decision boundaries. Based on this
hypothesis, we design an adaptive adversarial training method, named IMA. For
each individual training sample, IMA makes a sample-wise estimation of the
upper bound of the adversarial perturbation. In the training process, each of
the sample-wise adversarial perturbations is gradually increased to match the
margin. Once an equilibrium state is reached, the adversarial perturbations
will stop increasing. IMA is evaluated on publicly available datasets under two
popular adversarial attacks, PGD and IFGSM. The results show that: (1) IMA
significantly improves adversarial robustness of DNN classifiers, which
achieves the state-of-the-art performance; (2) IMA has a minimal reduction in
clean accuracy among all competing defense methods; (3) IMA can be applied to
pretrained models to reduce time cost; (4) IMA can be applied to the
state-of-the-art medical image segmentation networks, with outstanding
performance. We hope our work may help to lift the trade-off between
adversarial robustness and clean accuracy and facilitate the development of
robust applications in the medical field. The source code will be released when
this paper is published.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Moderately Supervised Learning: Definition, Framework and Generality. (arXiv:2008.11945v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11945">
<div class="article-summary-box-inner">
<span><p>Learning with supervision has achieved remarkable success in numerous
artificial intelligence (AI) applications. In the current literature, by
referring to the properties of the labels prepared for the training data set,
learning with supervision is categorized as supervised learning (SL) and weakly
supervised learning (WSL). SL concerns the situation where the training data
set is assigned with ideal labels, while WSL concerns the situation where the
training data set is assigned with non-ideal labels. However, without
considering the properties of the transformation from the given labels to
learnable targets, the definition of SL is relatively abstract, which conceals
some details that can be critical to building the appropriate solutions for
specific SL tasks. Thus, it is desirable to reveal these details more
concretely. This article attempts to achieve this goal by expanding the
categorization of SL and investigating the sub-type that plays the central role
in SL. More specifically, taking into consideration the properties of the
transformation from the given labels to learnable targets, we firstly
categorize SL into three narrower sub-types. Then we focus on the moderately
supervised learning (MSL) sub-type that concerns the situation where the given
labels are ideal, but due to the simplicity in annotation, careful designs are
required to transform the given labels into learnable targets. From the
perspectives of the definition, framework and generality, we comprehensively
illustrate MSL and reveal what details are concealed by the abstractness of the
definition of SL. At the meantime, the whole presentation of this paper as well
establishes a tutorial for AI application engineers to refer to viewing a
problem to be solved from the mathematicians' vision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medical Deep Learning -- A systematic Meta-Review. (arXiv:2010.14881v5 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14881">
<div class="article-summary-box-inner">
<span><p>Deep learning (DL) has remarkably impacted several different scientific
disciplines over the last few years. E.g., in image processing and analysis, DL
algorithms were able to outperform other cutting-edge methods. Additionally, DL
has delivered state-of-the-art results in tasks like autonomous driving,
outclassing previous attempts. There are even instances where DL outperformed
humans, for example with object recognition and gaming. DL is also showing vast
potential in the medical domain. With the collection of large quantities of
patient records and data, and a trend towards personalized treatments, there is
a great need for automated and reliable processing and analysis of health
information. Patient data is not only collected in clinical centers, like
hospitals and private practices, but also by mobile healthcare apps or online
websites. The abundance of collected patient data and the recent growth in the
DL field has resulted in a large increase in research efforts. In Q2/2020, the
search engine PubMed returned already over 11,000 results for the search term
'deep learning', and around 90% of these publications are from the last three
years. However, even though PubMed represents the largest search engine in the
medical field, it does not cover all medical-related publications. Hence, a
complete overview of the field of 'medical deep learning' is almost impossible
to obtain and acquiring a full overview of medical sub-fields is becoming
increasingly more difficult. Nevertheless, several review and survey articles
about medical DL have been published within the last few years. They focus, in
general, on specific medical scenarios, like the analysis of medical images
containing specific pathologies. With these surveys as a foundation, the aim of
this article is to provide the first high-level, systematic meta-review of
medical DL surveys.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PocketNet: A Smaller Neural Network for Medical Image Analysis. (arXiv:2104.10745v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10745">
<div class="article-summary-box-inner">
<span><p>Medical imaging deep learning models are often large and complex, requiring
specialized hardware to train and evaluate these models. To address such
issues, we propose the PocketNet paradigm to reduce the size of deep learning
models by throttling the growth of the number of channels in convolutional
neural networks. We demonstrate that, for a range of segmentation and
classification tasks, PocketNet architectures produce results comparable to
that of conventional neural networks while reducing the number of parameters by
multiple orders of magnitude, using up to 90% less GPU memory, and speeding up
training times by up to 40%, thereby allowing such models to be trained and
deployed in resource-constrained settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimizing Operating Points for High Performance Lesion Detection and Segmentation Using Lesion Size Reweighting. (arXiv:2107.12978v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12978">
<div class="article-summary-box-inner">
<span><p>There are many clinical contexts which require accurate detection and
segmentation of all focal pathologies (e.g. lesions, tumours) in patient
images. In cases where there are a mix of small and large lesions, standard
binary cross entropy loss will result in better segmentation of large lesions
at the expense of missing small ones. Adjusting the operating point to
accurately detect all lesions generally leads to oversegmentation of large
lesions. In this work, we propose a novel reweighing strategy to eliminate this
performance gap, increasing small pathology detection performance while
maintaining segmentation accuracy. We show that our reweighing strategy vastly
outperforms competing strategies based on experiments on a large scale,
multi-scanner, multi-center dataset of Multiple Sclerosis patient images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Physics-informed Guided Disentanglement in Generative Networks. (arXiv:2107.14229v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14229">
<div class="article-summary-box-inner">
<span><p>Image-to-image translation (i2i) networks suffer from entanglement effects in
presence of physics-related phenomena in target domain (such as occlusions,
fog, etc), lowering altogether the translation quality, controllability and
variability. In this paper, we build upon collection of simple physics models
and present a comprehensive method for disentangling visual traits in target
images, guiding the process with a physical model that renders some of the
target traits, and learning the remaining ones. Because it allows explicit and
interpretable outputs, our physical models (optimally regressed on target)
allows generating unseen scenarios in a controllable manner. We also extend our
framework, showing versatility to neural-guided disentanglement. The results
show our disentanglement strategies dramatically increase performances
qualitatively and quantitatively in several challenging scenarios for image
translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cohort Bias Adaptation in Aggregated Datasets for Lesion Segmentation. (arXiv:2108.00713v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00713">
<div class="article-summary-box-inner">
<span><p>Many automatic machine learning models developed for focal pathology (e.g.
lesions, tumours) detection and segmentation perform well, but do not
generalize as well to new patient cohorts, impeding their widespread adoption
into real clinical contexts. One strategy to create a more diverse,
generalizable training set is to naively pool datasets from different cohorts.
Surprisingly, training on this \it{big data} does not necessarily increase, and
may even reduce, overall performance and model generalizability, due to the
existence of cohort biases that affect label distributions. In this paper, we
propose a generalized affine conditioning framework to learn and account for
cohort biases across multi-source datasets, which we call Source-Conditioned
Instance Normalization (SCIN). Through extensive experimentation on three
different, large scale, multi-scanner, multi-centre Multiple Sclerosis (MS)
clinical trial MRI datasets, we show that our cohort bias adaptation method (1)
improves performance of the network on pooled datasets relative to naively
pooling datasets and (2) can quickly adapt to a new cohort by fine-tuning the
instance normalization parameters, thus learning the new cohort bias with only
10 labelled samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GRI: General Reinforced Imitation and its Application to Vision-Based Autonomous Driving. (arXiv:2111.08575v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08575">
<div class="article-summary-box-inner">
<span><p>Deep reinforcement learning (DRL) has been demonstrated to be effective for
several complex decision-making applications such as autonomous driving and
robotics. However, DRL is notoriously limited by its high sample complexity and
its lack of stability. Prior knowledge, e.g. as expert demonstrations, is often
available but challenging to leverage to mitigate these issues. In this paper,
we propose General Reinforced Imitation (GRI), a novel method which combines
benefits from exploration and expert data and is straightforward to implement
over any off-policy RL algorithm. We make one simplifying hypothesis: expert
demonstrations can be seen as perfect data whose underlying policy gets a
constant high reward. Based on this assumption, GRI introduces the notion of
offline demonstration agents. This agent sends expert data which are processed
both concurrently and indistinguishably with the experiences coming from the
online RL exploration agent. We show that our approach enables major
improvements on vision-based autonomous driving in urban environments. We
further validate the GRI method on Mujoco continuous control tasks with
different off-policy RL algorithms. Our method ranked first on the CARLA
Leaderboard and outperforms World on Rails, the previous state-of-the-art, by
17%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DIVeR: Real-time and Accurate Neural Radiance Fields with Deterministic Integration for Volume Rendering. (arXiv:2111.10427v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.10427">
<div class="article-summary-box-inner">
<span><p>DIVeR builds on the key ideas of NeRF and its variants -- density models and
volume rendering -- to learn 3D object models that can be rendered
realistically from small numbers of images. In contrast to all previous NeRF
methods, DIVeR uses deterministic rather than stochastic estimates of the
volume rendering integral. DIVeR's representation is a voxel based field of
features. To compute the volume rendering integral, a ray is broken into
intervals, one per voxel; components of the volume rendering integral are
estimated from the features for each interval using an MLP, and the components
are aggregated. As a result, DIVeR can render thin translucent structures that
are missed by other integrators. Furthermore, DIVeR's representation has
semantics that is relatively exposed compared to other such methods -- moving
feature vectors around in the voxel space results in natural edits. Extensive
qualitative and quantitative comparisons to current state-of-the-art methods
show that DIVeR produces models that (1) render at or above state-of-the-art
quality, (2) are very small without being baked, (3) render very fast without
being baked, and (4) can be edited in natural ways.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MegLoc: A Robust and Accurate Visual Localization Pipeline. (arXiv:2111.13063v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13063">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a visual localization pipeline, namely MegLoc, for
robust and accurate 6-DoF pose estimation under varying scenarios, including
indoor and outdoor scenes, different time across a day, different seasons
across a year, and even across years. MegLoc achieves state-of-the-art results
on a range of challenging datasets, including winning the Outdoor and Indoor
Visual Localization Challenge of ICCV 2021 Workshop on Long-term Visual
Localization under Changing Conditions, as well as the Re-localization
Challenge for Autonomous Driving of ICCV 2021 Workshop on Map-based
Localization for Autonomous Driving.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer. (arXiv:2111.13824v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13824">
<div class="article-summary-box-inner">
<span><p>Network quantization significantly reduces model inference complexity and has
been widely used in real-world deployments. However, most existing quantization
methods have been developed mainly on Convolutional Neural Networks (CNNs), and
suffer severe degradation when applied to fully quantized vision transformers.
In this work, we demonstrate that many of these difficulties arise because of
serious inter-channel variation in LayerNorm inputs, and present, Power-of-Two
Factor (PTF), a systematic method to reduce the performance degradation and
inference complexity of fully quantized vision transformers. In addition,
observing an extreme non-uniform distribution in attention maps, we propose
Log-Int-Softmax (LIS) to sustain that and simplify inference by using 4-bit
quantization and the BitShift operator. Comprehensive experiments on various
transformer-based architectures and benchmarks show that our Fully Quantized
Vision Transformer (FQ-ViT) outperforms previous works while even using lower
bit-width on attention maps. For instance, we reach 84.89% top-1 accuracy with
ViT-L on ImageNet and 50.8 mAP with Cascade Mask R-CNN (Swin-S) on COCO. To our
knowledge, we are the first to achieve lossless accuracy degradation (~1%) on
fully quantized vision transformers. The code is available at
https://github.com/megvii-research/FQ-ViT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated Objects via Few-shot Interactions. (arXiv:2112.00246v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00246">
<div class="article-summary-box-inner">
<span><p>Perceiving and interacting with 3D articulated objects, such as cabinets,
doors, and faucets, pose particular challenges for future home-assistant robots
performing daily tasks in human environments. Besides parsing the articulated
parts and joint parameters, researchers recently advocate learning manipulation
affordance over the input shape geometry which is more task-aware and
geometrically fine-grained. However, taking only passive observations as
inputs, these methods ignore many hidden but important kinematic constraints
(e.g., joint location and limits) and dynamic factors (e.g., joint friction and
restitution), therefore losing significant accuracy for test cases with such
uncertainties. In this paper, we propose a novel framework, named AdaAfford,
that learns to perform very few test-time interactions for quickly adapting the
affordance priors to more accurate instance-specific posteriors. We conduct
large-scale experiments using the PartNet-Mobility dataset and prove that our
system performs better than baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object-aware Video-language Pre-training for Retrieval. (arXiv:2112.00656v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00656">
<div class="article-summary-box-inner">
<span><p>Recently, by introducing large-scale dataset and strong transformer network,
video-language pre-training has shown great success especially for retrieval.
Yet, existing video-language transformer models do not explicitly fine-grained
semantic align. In this work, we present Object-aware Transformers, an
object-centric approach that extends video-language transformer to incorporate
object representations. The key idea is to leverage the bounding boxes and
object tags to guide the training process. We evaluate our model on three
standard sub-tasks of video-text matching on four widely used benchmarks. We
also provide deep analysis and detailed ablation about the proposed method. We
show clear improvement in performance across all tasks and datasets considered,
demonstrating the value of a model that incorporates object representations
into a video-language architecture. The code will be released at
\url{https://github.com/FingerRec/OA-Transformer}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Holistic Interpretation of Public Scenes Using Computer Vision and Temporal Graphs to Identify Social Distancing Violations. (arXiv:2112.06428v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06428">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has caused an unprecedented global public health
crisis. Given its inherent nature, social distancing measures are proposed as
the primary strategies to curb the spread of this pandemic. Therefore,
identifying situations where these protocols are violated, has implications for
curtailing the spread of the disease and promoting a sustainable lifestyle.
This paper proposes a novel computer vision-based system to analyze CCTV
footage to provide a threat level assessment of COVID-19 spread. The system
strives to holistically capture and interpret the information content of CCTV
footage spanning multiple frames to recognize instances of various violations
of social distancing protocols, across time and space, as well as
identification of group behaviors. This functionality is achieved primarily by
utilizing a temporal graph-based structure to represent the information of the
CCTV footage and a strategy to holistically interpret the graph and quantify
the threat level of the given scene. The individual components are tested and
validated on a range of scenarios and the complete system is tested against
human expert opinion. The results reflect the dependence of the threat level on
people, their physical proximity, interactions, protective clothing, and group
dynamics. The system performance has an accuracy of 76%, thus enabling a
deployable threat monitoring system in cities, to permit normalcy and
sustainability in the society.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust photon-efficient imaging using a pixel-wise residual shrinkage network. (arXiv:2201.01453v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01453">
<div class="article-summary-box-inner">
<span><p>Single-photon light detection and ranging (LiDAR) has been widely applied to
3D imaging in challenging scenarios. However, limited signal photon counts and
high noises in the collected data have posed great challenges for predicting
the depth image precisely. In this paper, we propose a pixel-wise residual
shrinkage network for photon-efficient imaging from high-noise data, which
adaptively generates the optimal thresholds for each pixel and denoises the
intermediate features by soft thresholding. Besides, redefining the
optimization target as pixel-wise classification provides a sharp advantage in
producing confident and accurate depth estimation when compared with existing
research. Comprehensive experiments conducted on both simulated and real-world
datasets demonstrate that the proposed model outperforms the state-of-the-arts
and maintains robust imaging performance under different signal-to-noise ratios
including the extreme case of 1:100.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">You Only Cut Once: Boosting Data Augmentation with a Single Cut. (arXiv:2201.12078v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12078">
<div class="article-summary-box-inner">
<span><p>We present You Only Cut Once (YOCO) for performing data augmentations. YOCO
cuts one image into two pieces and performs data augmentations individually
within each piece. Applying YOCO improves the diversity of the augmentation per
sample and encourages neural networks to recognize objects from partial
information. YOCO enjoys the properties of parameter-free, easy usage, and
boosting almost all augmentations for free. Thorough experiments are conducted
to evaluate its effectiveness. We first demonstrate that YOCO can be seamlessly
applied to varying data augmentations, neural network architectures, and brings
performance gains on CIFAR and ImageNet classification tasks, sometimes
surpassing conventional image-level augmentation by large margins. Moreover, we
show YOCO benefits contrastive pre-training toward a more powerful
representation that can be better transferred to multiple downstream tasks.
Finally, we study a number of variants of YOCO and empirically analyze the
performance for respective settings. Code is available at GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UQGAN: A Unified Model for Uncertainty Quantification of Deep Classifiers trained via Conditional GANs. (arXiv:2201.13279v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.13279">
<div class="article-summary-box-inner">
<span><p>We present an approach to quantifying both aleatoric and epistemic
uncertainty for deep neural networks in image classification, based on
generative adversarial networks (GANs). While most works in the literature that
use GANs to generate out-of-distribution (OoD) examples only focus on the
evaluation of OoD detection, we present a GAN based approach to learn a
classifier that produces proper uncertainties for OoD examples as well as for
false positives (FPs). Instead of shielding the entire in-distribution data
with GAN generated OoD examples which is state-of-the-art, we shield each class
separately with out-of-class examples generated by a conditional GAN and
complement this with a one-vs-all image classifier. In our experiments, in
particular on CIFAR10 and CIFAR100, we improve over the OoD detection and FP
detection performance of state-of-the-art GAN-training based classifiers.
Furthermore, we also find that the generated GAN examples do not significantly
affect the calibration error of our classifier and result in a significant gain
in model accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computing Multiple Image Reconstructions with a Single Hypernetwork. (arXiv:2202.11009v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11009">
<div class="article-summary-box-inner">
<span><p>Deep learning based techniques achieve state-of-the-art results in a wide
range of image reconstruction tasks like compressed sensing. These methods
almost always have hyperparameters, such as the weight coefficients that
balance the different terms in the optimized loss function. The typical
approach is to train the model for a hyperparameter setting determined with
some empirical or theoretical justification. Thus, at inference time, the model
can only compute reconstructions corresponding to the pre-determined
hyperparameter values. In this work, we present a hypernetwork-based approach,
called HyperRecon, to train reconstruction models that are agnostic to
hyperparameter settings. At inference time, HyperRecon can efficiently produce
diverse reconstructions, which would each correspond to different
hyperparameter values. In this framework, the user is empowered to select the
most useful output(s) based on their own judgement. We demonstrate our method
in compressed sensing, super-resolution and denoising tasks, using two
large-scale and publicly-available MRI datasets. Our code is available at
https://github.com/alanqrwang/hyperrecon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mobile authentication of copy detection patterns. (arXiv:2203.02397v2 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.02397">
<div class="article-summary-box-inner">
<span><p>In the recent years, the copy detection patterns (CDP) attracted a lot of
attention as a link between the physical and digital worlds, which is of great
interest for the internet of things and brand protection applications. However,
the security of CDP in terms of their reproducibility by unauthorized parties
or clonability remains largely unexplored. In this respect this paper addresses
a problem of anti-counterfeiting of physical objects and aims at investigating
the authentication aspects and the resistances to illegal copying of the modern
CDP from machine learning perspectives. A special attention is paid to a
reliable authentication under the real life verification conditions when the
codes are printed on an industrial printer and enrolled via modern mobile
phones under regular light conditions. The theoretical and empirical
investigation of authentication aspects of CDP is performed with respect to
four types of copy fakes from the point of view of (i) multi-class supervised
classification as a baseline approach and (ii) one-class classification as a
real-life application case. The obtained results show that the modern
machine-learning approaches and the technical capacities of modern mobile
phones allow to reliably authenticate CDP on end-user mobile phones under the
considered classes of fakes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Transformer-based Multiple Instance Learning for Weakly Supervised Polyp Frame Detection. (arXiv:2203.12121v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12121">
<div class="article-summary-box-inner">
<span><p>Current polyp detection methods from colonoscopy videos use exclusively
normal (i.e., healthy) training images, which i) ignore the importance of
temporal information in consecutive video frames, and ii) lack knowledge about
the polyps. Consequently, they often have high detection errors, especially on
challenging polyp cases (e.g., small, flat, or partially visible polyps). In
this work, we formulate polyp detection as a weakly-supervised anomaly
detection task that uses video-level labelled training data to detect
frame-level polyps. In particular, we propose a novel convolutional
transformer-based multiple instance learning method designed to identify
abnormal frames (i.e., frames with polyps) from anomalous videos (i.e., videos
containing at least one frame with polyp). In our method, local and global
temporal dependencies are seamlessly captured while we simultaneously optimise
video and snippet-level anomaly scores. A contrastive snippet mining method is
also proposed to enable an effective modelling of the challenging polyp cases.
The resulting method achieves a detection accuracy that is substantially better
than current state-of-the-art approaches on a new large-scale colonoscopy video
dataset introduced in this work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MonoTrack: Shuttle trajectory reconstruction from monocular badminton video. (arXiv:2204.01899v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.01899">
<div class="article-summary-box-inner">
<span><p>Trajectory estimation is a fundamental component of racket sport analytics,
as the trajectory contains information not only about the winning and losing of
each point, but also how it was won or lost. In sports such as badminton,
players benefit from knowing the full 3D trajectory, as the height of
shuttlecock or ball provides valuable tactical information. Unfortunately, 3D
reconstruction is a notoriously hard problem, and standard trajectory
estimators can only track 2D pixel coordinates. In this work, we present the
first complete end-to-end system for the extraction and segmentation of 3D
shuttle trajectories from monocular badminton videos. Our system integrates
badminton domain knowledge such as court dimension, shot placement, physical
laws of motion, along with vision-based features such as player poses and
shuttle tracking. We find that significant engineering efforts and model
improvements are needed to make the overall system robust, and as a by-product
of our work, improve state-of-the-art results on court recognition, 2D
trajectory estimation, and hit recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dite-HRNet: Dynamic Lightweight High-Resolution Network for Human Pose Estimation. (arXiv:2204.10762v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10762">
<div class="article-summary-box-inner">
<span><p>A high-resolution network exhibits remarkable capability in extracting
multi-scale features for human pose estimation, but fails to capture long-range
interactions between joints and has high computational complexity. To address
these problems, we present a Dynamic lightweight High-Resolution Network
(Dite-HRNet), which can efficiently extract multi-scale contextual information
and model long-range spatial dependency for human pose estimation.
Specifically, we propose two methods, dynamic split convolution and adaptive
context modeling, and embed them into two novel lightweight blocks, which are
named dynamic multi-scale context block and dynamic global context block. These
two blocks, as the basic component units of our Dite-HRNet, are specially
designed for the high-resolution networks to make full use of the parallel
multi-resolution architecture. Experimental results show that the proposed
network achieves superior performance on both COCO and MPII human pose
estimation datasets, surpassing the state-of-the-art lightweight networks. Code
is available at: \url{https://github.com/ZiyiZhang27/Dite-HRNet}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02152">
<div class="article-summary-box-inner">
<span><p>Recent studies indicate that detecting radiographic patterns on CT scans can
yield high sensitivity and specificity for Covid-19 localization. In this
paper, we investigate the appropriateness of deep learning models
transferability, for semantic segmentation of pneumonia-infected areas in CT
images. Transfer learning allows for the fast initialization/reutilization of
detection models, given that large volumes of training data are not available.
Our work explores the efficacy of using pre-trained U-Net architectures, on a
specific CT data set, for identifying Covid-19 side-effects over images from
different datasets. Experimental results indicate improvement in the
segmentation accuracy of identifying Covid-19 infected regions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural 3D Scene Reconstruction with the Manhattan-world Assumption. (arXiv:2205.02836v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02836">
<div class="article-summary-box-inner">
<span><p>This paper addresses the challenge of reconstructing 3D indoor scenes from
multi-view images. Many previous works have shown impressive reconstruction
results on textured objects, but they still have difficulty in handling
low-textured planar regions, which are common in indoor scenes. An approach to
solving this issue is to incorporate planer constraints into the depth map
estimation in multi-view stereo-based methods, but the per-view plane
estimation and depth optimization lack both efficiency and multi-view
consistency. In this work, we show that the planar constraints can be
conveniently integrated into the recent implicit neural representation-based
reconstruction methods. Specifically, we use an MLP network to represent the
signed distance function as the scene geometry. Based on the Manhattan-world
assumption, planar constraints are employed to regularize the geometry in floor
and wall regions predicted by a 2D semantic segmentation network. To resolve
the inaccurate segmentation, we encode the semantics of 3D points with another
MLP and design a novel loss that jointly optimizes the scene geometry and
semantics in 3D space. Experiments on ScanNet and 7-Scenes datasets show that
the proposed method outperforms previous methods by a large margin on 3D
reconstruction quality. The code is available at
https://zju3dv.github.io/manhattan_sdf.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LatentKeypointGAN: Controlling Images via Latent Keypoints -- Extended Abstract. (arXiv:2205.03448v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03448">
<div class="article-summary-box-inner">
<span><p>Generative adversarial networks (GANs) can now generate photo-realistic
images. However, how to best control the image content remains an open
challenge. We introduce LatentKeypointGAN, a two-stage GAN internally
conditioned on a set of keypoints and associated appearance embeddings
providing control of the position and style of the generated objects and their
respective parts. A major difficulty that we address is disentangling the image
into spatial and appearance factors with little domain knowledge and
supervision signals. We demonstrate in a user study and quantitative
experiments that LatentKeypointGAN provides an interpretable latent space that
can be used to re-arrange the generated images by re-positioning and exchanging
keypoint embeddings, such as generating portraits by combining the eyes, and
mouth from different images. Notably, our method does not require labels as it
is self-supervised and thereby applies to diverse application domains, such as
editing portraits, indoor rooms, and full-body human poses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identical Image Retrieval using Deep Learning. (arXiv:2205.04883v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.04883">
<div class="article-summary-box-inner">
<span><p>In recent years, we know that the interaction with images has increased.
Image similarity involves fetching similar-looking images abiding by a given
reference image. The target is to find out whether the image searched as a
query can result in similar pictures. We are using the BigTransfer Model, which
is a state-of-art model itself. BigTransfer(BiT) is essentially a ResNet but
pre-trained on a larger dataset like ImageNet and ImageNet-21k with additional
modifications. Using the fine-tuned pre-trained Convolution Neural Network
Model, we extract the key features and train on the K-Nearest Neighbor model to
obtain the nearest neighbor. The application of our model is to find similar
images, which are hard to achieve through text queries within a low inference
time. We analyse the benchmark of our model based on this application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gender and Racial Bias in Visual Question Answering Datasets. (arXiv:2205.08148v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08148">
<div class="article-summary-box-inner">
<span><p>Vision-and-language tasks have increasingly drawn more attention as a means
to evaluate human-like reasoning in machine learning models. A popular task in
the field is visual question answering (VQA), which aims to answer questions
about images. However, VQA models have been shown to exploit language bias by
learning the statistical correlations between questions and answers without
looking into the image content: e.g., questions about the color of a banana are
answered with yellow, even if the banana in the image is green. If societal
bias (e.g., sexism, racism, ableism, etc.) is present in the training data,
this problem may be causing VQA models to learn harmful stereotypes. For this
reason, we investigate gender and racial bias in five VQA datasets. In our
analysis, we find that the distribution of answers is highly different between
questions about women and men, as well as the existence of detrimental
gender-stereotypical samples. Likewise, we identify that specific race-related
attributes are underrepresented, whereas potentially discriminatory samples
appear in the analyzed datasets. Our findings suggest that there are dangers
associated to using VQA datasets without considering and dealing with the
potentially harmful stereotypes. We conclude the paper by proposing solutions
to alleviate the problem before, during, and after the dataset collection
process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Transformer Adapter for Dense Predictions. (arXiv:2205.08534v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08534">
<div class="article-summary-box-inner">
<span><p>This work investigates a simple yet powerful adapter for Vision Transformer
(ViT). Unlike recent visual transformers that introduce vision-specific
inductive biases into their architectures, ViT achieves inferior performance on
dense prediction tasks due to lacking prior information of images. To solve
this issue, we propose a Vision Transformer Adapter (ViT-Adapter), which can
remedy the defects of ViT and achieve comparable performance to vision-specific
models by introducing inductive biases via an additional architecture.
Specifically, the backbone in our framework is a vanilla transformer that can
be pre-trained with multi-modal data. When fine-tuning on downstream tasks, a
modality-specific adapter is used to introduce the data and tasks' prior
information into the model, making it suitable for these tasks. We verify the
effectiveness of our ViT-Adapter on multiple downstream tasks, including object
detection, instance segmentation, and semantic segmentation. Notably, when
using HTC++, our ViT-Adapter-L yields 60.1 box AP and 52.1 mask AP on COCO
test-dev, surpassing Swin-L by 1.4 box AP and 1.0 mask AP. For semantic
segmentation, our ViT-Adapter-L establishes a new state-of-the-art of 60.5 mIoU
on ADE20K val, 0.6 points higher than SwinV2-G. We hope that the proposed
ViT-Adapter could serve as an alternative for vision-specific transformers and
facilitate future research. The code and models will be released at
https://github.com/czczup/ViT-Adapter.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-time semantic segmentation on FPGAs for autonomous vehicles with hls4ml. (arXiv:2205.07690v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07690">
<div class="article-summary-box-inner">
<span><p>In this paper, we investigate how field programmable gate arrays can serve as
hardware accelerators for real-time semantic segmentation tasks relevant for
autonomous driving. Considering compressed versions of the ENet convolutional
neural network architecture, we demonstrate a fully-on-chip deployment with a
latency of 4.9 ms per image, using less than 30% of the available resources on
a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when
increasing the batch size to ten, corresponding to the use case where the
autonomous vehicle receives inputs from multiple cameras simultaneously. We
show, through aggressive filter reduction and heterogeneous quantization-aware
training, and an optimized implementation of convolutional layers, that the
power consumption and resource utilization can be significantly reduced while
maintaining accuracy on the Cityscapes dataset.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-05-19 23:08:51.189685875 UTC">2022-05-19 23:08:51 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>