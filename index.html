<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-02-02T01:30:00Z">02-02</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Fair Representations via Rate-Distortion Maximization. (arXiv:2202.00035v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00035">
<div class="article-summary-box-inner">
<span><p>Text representations learned by machine learning models often encode
undesirable demographic information of the user. Predictive models based on
these representations can rely on such information resulting in biased
decisions. We present a novel debiasing technique Fairness-aware Rate
Maximization (FaRM), that removes demographic information by making
representations of instances belonging to the same protected attribute class
uncorrelated using the rate-distortion function. FaRM is able to debias
representations with or without a target task at hand. FaRM can also be adapted
to simultaneously remove information about multiple protected attributes.
Empirical evaluations show that FaRM achieves state-of-the-art performance on
several datasets, and learned representations leak significantly less protected
attribute information against an attack by a non-linear probing network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning affective meanings that derives the social behavior using Bidirectional Encoder Representations from Transformers. (arXiv:2202.00065v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00065">
<div class="article-summary-box-inner">
<span><p>Predicting the outcome of a process requires modeling the system dynamic and
observing the states. In the context of social behaviors, sentiments
characterize the states of the system. Affect Control Theory (ACT) uses
sentiments to manifest potential interaction. ACT is a generative theory of
culture and behavior based on a three-dimensional sentiment lexicon.
Traditionally, the sentiments are quantified using survey data which is fed
into a regression model to explain social behavior. The lexicons used in the
survey are limited due to prohibitive cost. This paper uses a fine-tuned
Bidirectional Encoder Representations from Transformers (BERT) model to develop
a replacement for these surveys. This model achieves state-of-the-art accuracy
in estimating affective meanings, expanding the affective lexicon, and allowing
more behaviors to be explained.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia and Wikidata Translated by Native Speakers. (arXiv:2202.00120v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00120">
<div class="article-summary-box-inner">
<span><p>The ability to have the same experience for different user groups (i.e.,
accessibility) is one of the most important characteristics of Web-based
systems. The same is true for Knowledge Graph Question Answering (KGQA) systems
that provide the access to Semantic Web data via natural language interface.
While following our research agenda on the multilingual aspect of accessibility
of KGQA systems, we identified several ongoing challenges. One of them is the
lack of multilingual KGQA benchmarks. In this work, we extend one of the most
popular KGQA benchmarks - QALD-9 by introducing high-quality questions'
translations to 8 languages provided by native speakers, and transferring the
SPARQL queries of QALD-9 from DBpedia to Wikidata, s.t., the usability and
relevance of the dataset is strongly increased. Five of the languages -
Armenian, Ukrainian, Lithuanian, Bashkir and Belarusian - to our best knowledge
were never considered in KGQA research community before. The latter two of the
languages are considered as "endangered" by UNESCO. We call the extended
dataset QALD-9-plus and made it available online
https://github.com/Perevalov/qald_9_plus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Annotation and Querying Framework based on Semi-structured Ayurvedic Text. (arXiv:2202.00216v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00216">
<div class="article-summary-box-inner">
<span><p>Knowledge bases (KB) are an important resource in a number of natural
language processing (NLP) and information retrieval (IR) tasks, such as
semantic search, automated question-answering etc. They are also useful for
researchers trying to gain information from a text. Unfortunately, however, the
state-of-the-art in Sanskrit NLP does not yet allow automated construction of
knowledge bases due to unavailability or lack of sufficient accuracy of tools
and methods. Thus, in this work, we describe our efforts on manual annotation
of Sanskrit text for the purpose of knowledge graph (KG) creation. We choose
the chapter Dhanyavarga from Bhavaprakashanighantu of the Ayurvedic text
Bhavaprakasha for annotation. The constructed knowledge graph contains 410
entities and 764 relationships. Since Bhavaprakashanighantu is a technical
glossary text that describes various properties of different substances, we
develop an elaborate ontology to capture the semantics of the entity and
relationship types present in the text. To query the knowledge graph, we design
31 query templates that cover most of the common question patterns. For both
manual annotation and querying, we customize the Sangrahaka framework
previously developed by us. The entire system including the dataset is
available from https://sanskrit.iitk.ac.in/ayurveda/ . We hope that the
knowledge graph that we have created through manual annotation and subsequent
curation will help in development and testing of NLP tools in future as well as
studying of the Bhavaprakasanighantu text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebFormer: The Web-page Transformer for Structure Information Extraction. (arXiv:2202.00217v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00217">
<div class="article-summary-box-inner">
<span><p>Structure information extraction refers to the task of extracting structured
text fields from web pages, such as extracting a product offer from a shopping
page including product title, description, brand and price. It is an important
research topic which has been widely studied in document understanding and web
search. Recent natural language models with sequence modeling have demonstrated
state-of-the-art performance on web information extraction. However,
effectively serializing tokens from unstructured web pages is challenging in
practice due to a variety of web layout patterns. Limited work has focused on
modeling the web layout for extracting the text fields. In this paper, we
introduce WebFormer, a Web-page transFormer model for structure information
extraction from web documents. First, we design HTML tokens for each DOM node
in the HTML by embedding representations from their neighboring tokens through
graph attention. Second, we construct rich attention patterns between HTML
tokens and text tokens, which leverages the web layout for effective attention
weight computation. We conduct an extensive set of experiments on SWDE and
Common Crawl benchmarks. Experimental results demonstrate the superior
performance of the proposed approach over several state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Learning Over Multiple Domains in Natural Language Tasks. (arXiv:2202.00254v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00254">
<div class="article-summary-box-inner">
<span><p>Studies of active learning traditionally assume the target and source data
stem from a single domain. However, in realistic applications, practitioners
often require active learning with multiple sources of out-of-distribution
data, where it is unclear a priori which data sources will help or hurt the
target domain. We survey a wide variety of techniques in active learning (AL),
domain shift detection (DS), and multi-domain sampling to examine this
challenging setting for question answering and sentiment analysis. We ask (1)
what family of methods are effective for this task? And, (2) what properties of
selected examples and domains achieve strong results? Among 18 acquisition
functions from 4 families of methods, we find H- Divergence methods, and
particularly our proposed variant DAL-E, yield effective results, averaging
2-3% improvements over the random baseline. We also show the importance of a
diverse allocation of domains, as well as room-for-improvement of existing
methods on both domain and example selection. Our findings yield the first
comprehensive analysis of both existing and novel methods for practitioners
faced with multi-domain active learning for natural language tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XAlign: Cross-lingual Fact-to-Text Alignment and Generation for Low-Resource Languages. (arXiv:2202.00291v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00291">
<div class="article-summary-box-inner">
<span><p>Multiple critical scenarios (like Wikipedia text generation given English
Infoboxes) need automated generation of descriptive text in low resource (LR)
languages from English fact triples. Previous work has focused on English
fact-to-text (F2T) generation. To the best of our knowledge, there has been no
previous attempt on cross-lingual alignment or generation for LR languages.
Building an effective cross-lingual F2T (XF2T) system requires alignment
between English structured facts and LR sentences. We propose two unsupervised
methods for cross-lingual alignment. We contribute XALIGN, an XF2T dataset with
0.45M pairs across 8 languages, of which 5402 pairs have been manually
annotated. We also train strong baseline XF2T generation models on the XAlign
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Research on Question Classification Methods in the Medical Field. (arXiv:2202.00298v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00298">
<div class="article-summary-box-inner">
<span><p>Question classification is one of the important links in the research of
question and answering system. The existing question classification models are
more trained on public data sets. At present, there is a lack of question
classification data sets in specific fields, especially in the medical field.
To make up for this gap, this paper presents a data set for question
classification in the medical field. Moreover, this paper proposes a
multi-dimensional extraction of the characteristics of the question by
combining multiple neural network models, and proposes a question
classification model based on multi-dimensional feature extraction. The
experimental results show that the proposed method can effectively improve the
performance of question classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Language to Code Using Transformers. (arXiv:2202.00367v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00367">
<div class="article-summary-box-inner">
<span><p>We tackle the problem of generating code snippets from natural language
descriptions using the CoNaLa dataset. We use the self-attention based
transformer architecture and show that it performs better than recurrent
attention-based encoder decoder. Furthermore, we develop a modified form of
back translation and use cycle consistent losses to train the model in an
end-to-end fashion. We achieve a BLEU score of 16.99 beating the previously
reported baseline of the CoNaLa challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Politics and Virality in the Time of Twitter: A Large-Scale Cross-Party Sentiment Analysis in Greece, Spain and United Kingdom. (arXiv:2202.00396v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00396">
<div class="article-summary-box-inner">
<span><p>Social media has become extremely influential when it comes to policy making
in modern societies especially in the western world (e.g., 48% of Europeans use
social media every day or almost every day). Platforms such as Twitter allow
users to follow politicians, thus making citizens more involved in political
discussion. In the same vein, politicians use Twitter to express their
opinions, debate among others on current topics and promote their political
agenda aiming to influence voter behaviour. Previous studies have shown that
tweets conveying negative sentiment are likely to be retweeted more frequently.
In this paper, we attempt to analyse tweets from politicians from different
countries and explore if their tweets follow the same trend. Utilising
state-of-the-art pre-trained language models we performed sentiment analysis on
multilingual tweets collected from members of parliament of Greece, Spain and
United Kingdom, including devolved administrations. We achieved this by
systematically exploring and analysing the differences between influential and
less popular tweets. Our analysis indicates that politicians' negatively
charged tweets spread more widely, especially in more recent times, and
highlights interesting trends in the intersection of sentiment and popularity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Dependencies in Adversarial Attacks on Speech Recognition Systems. (arXiv:2202.00399v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00399">
<div class="article-summary-box-inner">
<span><p>Automatic speech recognition (ASR) systems are ubiquitously present in our
daily devices. They are vulnerable to adversarial attacks, where manipulated
input samples fool the ASR system's recognition. While adversarial examples for
various English ASR systems have already been analyzed, there exists no
inter-language comparative vulnerability analysis.
</p>
<p>We compare the attackability of a German and an English ASR system, taking
Deepspeech as an example. We investigate if one of the language models is more
susceptible to manipulations than the other. The results of our experiments
suggest statistically significant differences between English and German in
terms of computational effort necessary for the successful generation of
adversarial examples. This result encourages further research in
language-dependent characteristics in the robustness analysis of ASR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Inference Principles for Reasoning about Commonsense Causality. (arXiv:2202.00436v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00436">
<div class="article-summary-box-inner">
<span><p>Commonsense causality reasoning (CCR) aims at identifying plausible causes
and effects in natural language descriptions that are deemed reasonable by an
average person. Although being of great academic and practical interest, this
problem is still shadowed by the lack of a well-posed theoretical framework;
existing work usually relies on deep language models wholeheartedly, and is
potentially susceptible to confounding co-occurrences. Motivated by classical
causal principles, we articulate the central question of CCR and draw parallels
between human subjects in observational studies and natural languages to adopt
CCR to the potential-outcomes framework, which is the first such attempt for
commonsense tasks. We propose a novel framework, ROCK, to Reason O(A)bout
Commonsense K(C)ausality, which utilizes temporal signals as incidental
supervision, and balances confounding effects using temporal propensities that
are analogous to propensity scores. The ROCK implementation is modular and
zero-shot, and demonstrates good CCR capabilities on various datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Text Anonymization Benchmark (TAB): A Dedicated Corpus and Evaluation Framework for Text Anonymization. (arXiv:2202.00443v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00443">
<div class="article-summary-box-inner">
<span><p>We present a novel benchmark and associated evaluation metrics for assessing
the performance of text anonymization methods. Text anonymization, defined as
the task of editing a text document to prevent the disclosure of personal
information, currently suffers from a shortage of privacy-oriented annotated
text resources, making it difficult to properly evaluate the level of privacy
protection offered by various anonymization methods. This paper presents TAB
(Text Anonymization Benchmark), a new, open-source annotated corpus developed
to address this shortage. The corpus comprises 1,268 English-language court
cases from the European Court of Human Rights (ECHR) enriched with
comprehensive annotations about the personal information appearing in each
document, including their semantic category, identifier type, confidential
attributes, and co-reference relations. Compared to previous work, the TAB
corpus is designed to go beyond traditional de-identification (which is limited
to the detection of predefined semantic categories), and explicitly marks which
text spans ought to be masked in order to conceal the identity of the person to
be protected. Along with presenting the corpus and its annotation layers, we
also propose a set of evaluation metrics that are specifically tailored towards
measuring the performance of text anonymization, both in terms of privacy
protection and utility preservation. We illustrate the use of the benchmark and
the proposed metrics by assessing the empirical performance of several baseline
text anonymization models. The full corpus along with its privacy-oriented
annotation guidelines, evaluation scripts and baseline models are available on:
https://github.com/NorskRegnesentral/text-anonymisation-benchmark
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TableQuery: Querying tabular data with natural language. (arXiv:2202.00454v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00454">
<div class="article-summary-box-inner">
<span><p>This paper presents TableQuery, a novel tool for querying tabular data using
deep learning models pre-trained to answer questions on free text. Existing
deep learning methods for question answering on tabular data have various
limitations, such as having to feed the entire table as input into a neural
network model, making them unsuitable for most real-world applications. Since
real-world data might contain millions of rows, it may not entirely fit into
the memory. Moreover, data could be stored in live databases, which are updated
in real-time, and it is impractical to serialize an entire database to a neural
network-friendly format each time it is updated. In TableQuery, we use deep
learning models pre-trained for question answering on free text to convert
natural language queries to structured queries, which can be run against a
database or a spreadsheet. This method eliminates the need for fitting the
entire data into memory as well as serializing databases. Furthermore, deep
learning models pre-trained for question answering on free text are readily
available on platforms such as HuggingFace Model Hub (7). TableQuery does not
require re-training; when a newly trained model for question answering with
better performance is available, it can replace the existing model in
TableQuery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Invariable Semantical Representation from Language for Extensible Policy Generalization. (arXiv:2202.00466v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00466">
<div class="article-summary-box-inner">
<span><p>Recently, incorporating natural language instructions into reinforcement
learning (RL) to learn semantically meaningful representations and foster
generalization has caught many concerns. However, the semantical information in
language instructions is usually entangled with task-specific state
information, which hampers the learning of semantically invariant and reusable
representations. In this paper, we propose a method to learn such
representations called element randomization, which extracts task-relevant but
environment-agnostic semantics from instructions using a set of environments
with randomized elements, e.g., topological structures or textures, yet the
same language instruction. We theoretically prove the feasibility of learning
semantically invariant representations through randomization. In practice, we
accordingly develop a hierarchy of policies, where a high-level policy is
designed to modulate the behavior of a goal-conditioned low-level policy by
proposing subgoals as semantically invariant representations. Experiments on
challenging long-horizon tasks show that (1) our low-level policy reliably
generalizes to tasks against environment changes; (2) our hierarchical policy
exhibits extensible generalization in unseen new tasks that can be decomposed
into several solvable sub-tasks; and (3) by storing and replaying language
trajectories as succinct policy representations, the agent can complete tasks
in a one-shot fashion, i.e., once one successful trajectory has been attained.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Multimodal Punctuation Restoration Framework for Mixed-Modality Corpus. (arXiv:2202.00468v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00468">
<div class="article-summary-box-inner">
<span><p>The punctuation restoration task aims to correctly punctuate the output
transcriptions of automatic speech recognition systems. Previous punctuation
models, either using text only or demanding the corresponding audio, tend to be
constrained by real scenes, where unpunctuated sentences are a mixture of those
with and without audio. This paper proposes a unified multimodal punctuation
restoration framework, named UniPunc, to punctuate the mixed sentences with a
single model. UniPunc jointly represents audio and non-audio samples in a
shared latent space, based on which the model learns a hybrid representation
and punctuates both kinds of samples. We validate the effectiveness of the
UniPunc on real-world datasets, which outperforms various strong baselines
(e.g. BERT, MuSe) by at least 0.8 overall F1 scores, making a new
state-of-the-art. Extensive experiments show that UniPunc's design is a
pervasive solution: by grafting onto previous models, UniPunc enables them to
punctuate on the mixed corpus. Our code is available at
github.com/Yaoming95/UniPunc
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient-guided Unsupervised Text Style Transfer via Contrastive Learning. (arXiv:2202.00469v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00469">
<div class="article-summary-box-inner">
<span><p>Text style transfer is a challenging text generation problem, which aims at
altering the style of a given sentence to a target one while keeping its
content unchanged. Since there is a natural scarcity of parallel datasets,
recent works mainly focus on solving the problem in an unsupervised manner.
However, previous gradient-based works generally suffer from the deficiencies
as follows, namely: (1) Content migration. Previous approaches lack explicit
modeling of content invariance and are thus susceptible to content shift
between the original sentence and the transferred one. (2) Style
misclassification. A natural drawback of the gradient-guided approaches is that
the inference process is homogeneous with a line of adversarial attack, making
latent optimization easily becomes an attack to the classifier due to
misclassification. This leads to difficulties in achieving high transfer
accuracy. To address the problems, we propose a novel gradient-guided model
through a contrastive paradigm for text style transfer, to explicitly gather
similar semantic sentences, and to design a siamese-structure based style
classifier for alleviating such two issues, respectively. Experiments on two
datasets show the effectiveness of our proposed approach, as compared to the
state-of-the-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Assessment of the Impact of OCR Noise on Language Models. (arXiv:2202.00470v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00470">
<div class="article-summary-box-inner">
<span><p>Neural language models are the backbone of modern-day natural language
processing applications. Their use on textual heritage collections which have
undergone Optical Character Recognition (OCR) is therefore also increasing.
Nevertheless, our understanding of the impact OCR noise could have on language
models is still limited. We perform an assessment of the impact OCR noise has
on a variety of language models, using data in Dutch, English, French and
German. We find that OCR noise poses a significant obstacle to language
modelling, with language models increasingly diverging from their noiseless
targets as OCR quality lowers. In the presence of small corpora, simpler models
including PPMI and Word2Vec consistently outperform transformer-based models in
this respect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal effect of racial bias in data and machine learning algorithms on user persuasiveness & discriminatory decision making: An Empirical Study. (arXiv:2202.00471v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00471">
<div class="article-summary-box-inner">
<span><p>Language data and models demonstrate various types of bias, be it ethnic,
religious, gender, or socioeconomic. AI/NLP models, when trained on the
racially biased dataset, AI/NLP models instigate poor model explainability,
influence user experience during decision making and thus further magnifies
societal biases, raising profound ethical implications for society. The
motivation of the study is to investigate how AI systems imbibe bias from data
and produce unexplainable discriminatory outcomes and influence an individual's
articulateness of system outcome due to the presence of racial bias features in
datasets. The design of the experiment involves studying the counterfactual
impact of racial bias features present in language datasets and its associated
effect on the model outcome. A mixed research methodology is adopted to
investigate the cross implication of biased model outcome on user experience,
effect on decision-making through controlled lab experimentation. The findings
provide foundation support for correlating the implication of carry-over an
artificial intelligence model solving NLP task due to biased concept presented
in the dataset. Further, the research outcomes justify the negative influence
on users' persuasiveness that leads to alter the decision-making quotient of an
individual when trying to rely on the model outcome to act. The paper bridges
the gap across the harm caused in establishing poor customer trustworthiness
due to an inequitable system design and provides strong support for
researchers, policymakers, and data scientists to build responsible AI
frameworks within organizations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Examples to Rules: Neural Guided Rule Synthesis for Information Extraction. (arXiv:2202.00475v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00475">
<div class="article-summary-box-inner">
<span><p>While deep learning approaches to information extraction have had many
successes, they can be difficult to augment or maintain as needs shift.
Rule-based methods, on the other hand, can be more easily modified. However,
crafting rules requires expertise in linguistics and the domain of interest,
making it infeasible for most users. Here we attempt to combine the advantages
of these two directions while mitigating their drawbacks. We adapt recent
advances from the adjacent field of program synthesis to information
extraction, synthesizing rules from provided examples. We use a
transformer-based architecture to guide an enumerative search, and show that
this reduces the number of steps that need to be explored before a rule is
found. Further, we show that without training the synthesis algorithm on the
specific domain, our synthesized rules achieve state-of-the-art performance on
the 1-shot scenario of a task that focuses on few-shot learning for relation
classification, and competitive performance in the 5-shot scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring COVID-19 Related Stressors Using Topic Modeling. (arXiv:2202.00476v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00476">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has affected lives of people from different countries
for almost two years. The changes on lifestyles due to the pandemic may cause
psychosocial stressors for individuals, and have a potential to lead to mental
health problems. To provide high quality mental health supports, healthcare
organization need to identify the COVID-19 specific stressors, and notice the
trends of prevalence of those stressors. This study aims to apply natural
language processing (NLP) on social media data to identify the psychosocial
stressors during COVID-19 pandemic, and to analyze the trend on prevalence of
stressors at different stages of the pandemic. We obtained dataset of 9266
Reddit posts from subreddit \rCOVID19_support, from 14th Feb ,2020 to 19th July
2021. We used Latent Dirichlet Allocation (LDA) topic model and lexicon methods
to identify the topics that were mentioned on the subreddit. Our result
presented a dashboard to visualize the trend of prevalence of topics about
covid-19 related stressors being discussed on social media platform. The result
could provide insights about the prevalence of pandemic related stressors
during different stages of COVID-19. The NLP techniques leveraged in this study
could also be applied to analyze event specific stressors in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detection of Increased Time Intervals of Anti-Vaccine Tweets for COVID-19 Vaccine with BERT Model. (arXiv:2202.00477v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00477">
<div class="article-summary-box-inner">
<span><p>The most effective of the solutions against Covid-19 is the various vaccines
developed. Distrust of vaccines can hinder the rapid and effective use of this
remedy. One of the means of expressing the thoughts of society is social media.
Determining the time intervals during which anti-vaccination increases in
social media can help institutions determine the strategy to be used in
combating anti-vaccination. Recording and tracking every tweet entered with
human labor would be inefficient, so various automation solutions are needed.
In this study, The Bidirectional Encoder Representations from Transformers
(BERT) model, which is a deep learning-based natural language processing (NLP)
model, was used. In a dataset of 1506 tweets divided into four different
categories as news, irrelevant, anti-vaccine, and vaccine supporters, the model
was trained with a learning rate of 5e-6 for 25 epochs. To determine the
intervals in which anti-vaccine tweets are concentrated, the categories to
which 652840 tweets belong were determined by using the trained model. The
change of the determined categories overtime was visualized and the events that
could cause the change were determined. As a result of model training, in the
test dataset, the f-score of 0.81 and AUC values for different classes were
obtained as 0.99,0.91, 0.92, 0.92, respectively. In this model, unlike the
studies in the literature, an auxiliary system is designed that provides data
that institutions can use when determining their strategy by measuring and
visualizing the frequency of anti-vaccine tweets in a time interval, different
from detecting and censoring such tweets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuraHealthNLP: An Automated Screening Pipeline to Detect Undiagnosed Cognitive Impairment in Electronic Health Records with Deep Learning and Natural Language Processing. (arXiv:2202.00478v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00478">
<div class="article-summary-box-inner">
<span><p>Dementia related cognitive impairment (CI) affects over 55 million people
worldwide and is growing rapidly at the rate of one new case every 3 seconds.
With a recurring failure of clinical trials, early diagnosis is crucial, but
75% of dementia cases go undiagnosed globally with up to 90% in
low-and-middle-income countries. Current diagnostic methods are notoriously
complex, involving manual review of medical notes, numerous cognitive tests,
expensive brain scans or spinal fluid tests. Information relevant to CI is
often found in the electronic health records (EHRs) and can provide vital clues
for early diagnosis, but a manual review by experts is tedious and error prone.
This project develops a novel state-of-the-art automated screening pipeline for
scalable and high-speed discovery of undetected CI in EHRs. To understand the
linguistic context from complex language structures in EHR, a database of 8,656
sequences was constructed to train attention-based deep learning natural
language processing model to classify sequences. A patient level prediction
model based on logistic regression was developed using the sequence level
classifier. The deep learning system achieved 93% accuracy and AUC = 0.98 to
identify patients who had no earlier diagnosis, dementia-related diagnosis
code, or dementia-related medications in their EHR. These patients would have
otherwise gone undetected or detected too late. The EHR screening pipeline was
deployed in NeuraHealthNLP, a web application for automated and real-time CI
screening by simply uploading EHRs in a browser. NeuraHealthNLP is cheaper,
faster, more accessible, and outperforms current clinical methods including
text-based analytics and machine learning approaches. It makes early diagnosis
viable in regions with scarce health care services but accessible internet or
cellular services.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intent Matching based Customer Services Chatbot with Natural Language Understanding. (arXiv:2202.00480v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00480">
<div class="article-summary-box-inner">
<span><p>Customer service is the lifeblood of any business. Excellent customer service
not only generates return business but also creates new customers. Looking at
the demanding market to provide a 24/7 service to customers, many organisations
are increasingly engaged in popular social media and text messaging platforms
such as WhatsApp and Facebook Messenger in providing a 24/7 service to
customers in the current demanding market. In this paper, we present an intent
matching based customer services chatbot (IMCSC), which is capable of replacing
the customer service work of sales personnel, whilst interacting in a more
natural and human-like manner through the employment of Natural Language
Understanding (NLU). The bot is able to answer the most common frequently asked
questions and we have also integrated features for the processing and exporting
of customer orders to a Google Sheet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RabindraNet, Creating Literary Works in the Style of Rabindranath Tagore. (arXiv:2202.00481v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00481">
<div class="article-summary-box-inner">
<span><p>Bengali literature has a rich history of hundreds of years with luminary
figures such as Rabindranath Tagore and Kazi Nazrul Islam. However, analytical
works involving the most recent advancements in NLP have barely scratched the
surface utilizing the enormous volume of the collected works from the writers
of the language. In order to bring attention to the analytical study involving
the works of Bengali writers and spearhead the text generation endeavours in
the style of existing literature, we are introducing RabindraNet, a character
level RNN model with stacked-LSTM layers trained on the works of Rabindranath
Tagore to produce literary works in his style for multiple genres. We created
an extensive dataset as well by compiling the digitized works of Rabindranath
Tagore from authentic online sources and published as open source dataset on
data science platform Kaggle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auto-ABSA: Automatic Detection of Aspects in Aspect-Based Sentiment Analysis. (arXiv:2202.00484v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00484">
<div class="article-summary-box-inner">
<span><p>After transformer is proposed, lots of pre-trained language models have been
come up with and sentiment analysis (SA) task has been improved. In this paper,
we proposed a method that uses an auxiliary sentence about aspects that the
sentence contains to help sentiment prediction. The first is aspect detection,
which uses a multi-aspects detection model to predict all aspects that the
sentence has. Combining the predicted aspects and the original sentence as
Sentiment Analysis (SA) model's input. The second is to do out-of-domain
aspect-based sentiment analysis(ABSA), train sentiment classification model
with one kind of dataset and validate it with another kind of dataset. Finally,
we created two baselines, they use no aspect and all aspects as sentiment
classification model's input, respectively. Compare two baselines performance
to our method, found that our method really makes sense.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Theoretical Understanding of Word and Relation Representation. (arXiv:2202.00486v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00486">
<div class="article-summary-box-inner">
<span><p>Representing words by vectors, or embeddings, enables computational reasoning
and is foundational to automating natural language tasks. For example, if word
embeddings of similar words contain similar values, word similarity can be
readily assessed, whereas judging that from their spelling is often impossible
(e.g. cat /feline) and to predetermine and store similarities between all words
is prohibitively time-consuming, memory intensive and subjective. We focus on
word embeddings learned from text corpora and knowledge graphs. Several
well-known algorithms learn word embeddings from text on an unsupervised basis
by learning to predict those words that occur around each word, e.g. word2vec
and GloVe. Parameters of such word embeddings are known to reflect word
co-occurrence statistics, but how they capture semantic meaning has been
unclear. Knowledge graph representation models learn representations both of
entities (words, people, places, etc.) and relations between them, typically by
training a model to predict known facts in a supervised manner. Despite steady
improvements in fact prediction accuracy, little is understood of the latent
structure that enables this.
</p>
<p>The limited understanding of how latent semantic structure is encoded in the
geometry of word embeddings and knowledge graph representations makes a
principled means of improving their performance, reliability or
interpretability unclear. To address this:
</p>
<p>1. we theoretically justify the empirical observation that particular
geometric relationships between word embeddings learned by algorithms such as
word2vec and GloVe correspond to semantic relations between words; and
</p>
<p>2. we extend this correspondence between semantics and geometry to the
entities and relations of knowledge graphs, providing a model for the latent
structure of knowledge graph representation linked to that of word embeddings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Examining Scaling and Transfer of Language Model Architectures for Machine Translation. (arXiv:2202.00528v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00528">
<div class="article-summary-box-inner">
<span><p>Natural language understanding and generation models follow one of the two
dominant architectural paradigms: language models (LMs) that process
concatenated sequences in a single stack of layers, and encoder-decoder models
(EncDec) that utilize separate layer stacks for input and output processing. In
machine translation, EncDec has long been the favoured approach, but with few
studies investigating the performance of LMs. In this work, we thoroughly
examine the role of several architectural design choices on the performance of
LMs on bilingual, (massively) multilingual and zero-shot translation tasks,
under systematic variations of data conditions and model sizes. Our results
show that: (i) Different LMs have different scaling properties, where
architectural differences often have a significant impact on model performance
at small scales, but the performance gap narrows as the number of parameters
increases, (ii) Several design choices, including causal masking and
language-modeling objectives for the source sequence, have detrimental effects
on translation quality, and (iii) When paired with full-visible masking for
source sequences, LMs could perform on par with EncDec on supervised bilingual
and multilingual translation tasks, and improve greatly on zero-shot directions
by facilitating the reduction of off-target translations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Novelty Controlled Paraphrase Generation with Retrieval Augmented Conditional Prompt Tuning. (arXiv:2202.00535v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00535">
<div class="article-summary-box-inner">
<span><p>Paraphrase generation is a fundamental and long-standing task in natural
language processing. In this paper, we concentrate on two contributions to the
task: (1) we propose Retrieval Augmented Prompt Tuning (RAPT) as a
parameter-efficient method to adapt large pre-trained language models for
paraphrase generation; (2) we propose Novelty Conditioned RAPT (NC-RAPT) as a
simple model-agnostic method of using specialized prompt tokens for controlled
paraphrase generation with varying levels of lexical novelty. By conducting
extensive experiments on four datasets, we demonstrate the effectiveness of the
proposed approaches for retaining the semantic content of the original text
while inducing lexical novelty in the generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Maximum Batch Frobenius Norm for Multi-Domain Text Classification. (arXiv:2202.00537v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00537">
<div class="article-summary-box-inner">
<span><p>Multi-domain text classification (MDTC) has obtained remarkable achievements
due to the advent of deep learning. Recently, many endeavors are devoted to
applying adversarial learning to extract domain-invariant features to yield
state-of-the-art results. However, these methods still face one challenge:
transforming original features to be domain-invariant distorts the
distributions of the original features, degrading the discriminability of the
learned features. To address this issue, we first investigate the structure of
the batch classification output matrix and theoretically justify that the
discriminability of the learned features has a positive correlation with the
Frobenius norm of the batch output matrix. Based on this finding, we propose a
maximum batch Frobenius norm (MBF) method to boost the feature discriminability
for MDTC. Experiments on two MDTC benchmarks show that our MBF approach can
effectively advance the performance of the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dominant Set-based Active Learning for Text Classification and its Application to Online Social Media. (arXiv:2202.00540v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00540">
<div class="article-summary-box-inner">
<span><p>Recent advances in natural language processing (NLP) in online social media
are evidently owed to large-scale datasets. However, labeling, storing, and
processing a large number of textual data points, e.g., tweets, has remained
challenging. On top of that, in applications such as hate speech detection,
labeling a sufficiently large dataset containing offensive content can be
mentally and emotionally taxing for human annotators. Thus, NLP methods that
can make the best use of significantly less labeled data points are of great
interest. In this paper, we present a novel pool-based active learning method
that can be used for the training of large unlabeled corpus with minimum
annotation cost. For that, we propose to find the dominant sets of local
clusters in the feature space. These sets represent maximally cohesive
structures in the data. Then, the samples that do not belong to any of the
dominant sets are selected to be used to train the model, as they represent the
boundaries of the local clusters and are more challenging to classify. Our
proposed method does not have any parameters to be tuned, making it
dataset-independent, and it can approximately achieve the same classification
accuracy as full training data, with significantly fewer data points.
Additionally, our method achieves a higher performance in comparison to the
state-of-the-art active learning strategies. Furthermore, our proposed
algorithm is able to incorporate conventional active learning scores, such as
uncertainty-based scores, into its selection criteria. We show the
effectiveness of our method on different datasets and using different neural
network architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finding the optimal human strategy for Wordle using maximum correct letter probabilities and reinforcement learning. (arXiv:2202.00557v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00557">
<div class="article-summary-box-inner">
<span><p>Wordle is an online word puzzle game that gained viral popularity in January
2022. The goal is to guess a hidden five letter word. After each guess, the
player gains information about whether the letters they guessed are present in
the word, and whether they are in the correct position. Numerous blogs have
suggested guessing strategies and starting word lists that improve the chance
of winning. Optimized algorithms can win 100% of games within five of the six
allowed trials. However, it is infeasible for human players to use these
algorithms due to an inability to perfectly recall all known 5-letter words and
perform complex calculations that optimize information gain. Here, we present
two different methods for choosing starting words along with a framework for
discovering the optimal human strategy based on reinforcement learning. Human
Wordle players can use the rules we discover to optimize their chance of
winning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BEA-Base: A Benchmark for ASR of Spontaneous Hungarian. (arXiv:2202.00601v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00601">
<div class="article-summary-box-inner">
<span><p>Hungarian is spoken by 15 million people, still, easily accessible Automatic
Speech Recognition (ASR) benchmark datasets - especially for spontaneous speech
- have been practically unavailable. In this paper, we introduce BEA-Base, a
subset of the BEA spoken Hungarian database comprising mostly spontaneous
speech of 140 speakers. It is built specifically to assess ASR, primarily for
conversational AI applications. After defining the speech recognition subsets
and task, several baselines - including classic HMM-DNN hybrid and end-to-end
approaches augmented by cross-language transfer learning - are developed using
open-source toolkits. The best results obtained are based on multilingual
self-supervised pretraining, achieving a 45% recognition error rate reduction
as compared to the classical approach - without the application of an external
language model or additional supervised data. The results show the feasibility
of using BEA-Base for training and evaluation of Hungarian speech recognition
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic of Cloud Computing services for Time Series workflows. (arXiv:2202.00609v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00609">
<div class="article-summary-box-inner">
<span><p>Time series (TS) are present in many fields of knowledge, research, and
engineering. The processing and analysis of TS are essential in order to
extract knowledge from the data and to tackle forecasting or predictive
maintenance tasks among others The modeling of TS is a challenging task,
requiring high statistical expertise as well as outstanding knowledge about the
application of Data Mining(DM) and Machine Learning (ML) methods. The overall
work with TS is not limited to the linear application of several techniques,
but is composed of an open workflow of methods and tests. These workflow,
developed mainly on programming languages, are complicated to execute and run
effectively on different systems, including Cloud Computing (CC) environments.
The adoption of CC can facilitate the integration and portability of services
allowing to adopt solutions towards services Internet Technologies (IT)
industrialization. The definition and description of workflow services for TS
open up a new set of possibilities regarding the reduction of complexity in the
deployment of this type of issues in CC environments. In this sense, we have
designed an effective proposal based on semantic modeling (or vocabulary) that
provides the full description of workflow for Time Series modeling as a CC
service. Our proposal includes a broad spectrum of the most extended
operations, accommodating any workflow applied to classification, regression,
or clustering problems for Time Series, as well as including evaluation
measures, information, tests, or machine learning algorithms among others.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FiNCAT: Financial Numeral Claim Analysis Tool. (arXiv:2202.00631v1 [q-fin.GN])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00631">
<div class="article-summary-box-inner">
<span><p>While making investment decisions by reading financial documents, investors
need to differentiate between in-claim and outof-claim numerals. In this paper,
we present a tool which does it automatically. It extracts context embeddings
of the numerals using one of the transformer based pre-trained language model
called BERT. After this, it uses a Logistic Regression based model to detect
whether the numerals is in-claim or out-of-claim. We use FinNum-3 (English)
dataset to train our model. After conducting rigorous experiments we achieve a
Macro F1 score of 0.8223 on the validation set. We have open-sourced this tool
and it can be accessed from
https://github.com/sohomghosh/FiNCAT_Financial_Numeral_Claim_Analysis_Tool
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Typical Decoding for Natural Language Generation. (arXiv:2202.00666v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00666">
<div class="article-summary-box-inner">
<span><p>Despite achieving incredibly low perplexities on myriad natural language
corpora, today's language models still often underperform when used to generate
text. This dichotomy has puzzled the language generation community for the last
few years. In this work, we posit that the abstraction of natural language as a
communication channel (\`a la Shannon, 1948) can provide new insights into the
behaviors of probabilistic language generators, e.g., why high-probability
texts can be dull or repetitive. Humans use language as a means of
communicating information, and do so in an efficient yet error-minimizing
manner, choosing each word in a string with this (perhaps subconscious) goal in
mind. We propose that generation from probabilistic models should mimic this
behavior. Rather than always choosing words from the high-probability region of
the distribution--which have a low Shannon information content--we sample from
the set of words with an information content close to its expected value, i.e.,
close to the conditional entropy of our model. This decision criterion can be
realized through a simple and efficient implementation, which we call typical
sampling. Automatic and human evaluations show that, in comparison to nucleus
and top-k sampling, typical sampling offers competitive performance in terms of
quality while consistently reducing the number of degenerate repetitions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FlexParser -- the adaptive log file parser for continuous results in a changing world. (arXiv:2106.03170v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03170">
<div class="article-summary-box-inner">
<span><p>Any modern system writes events into files, called log files. Those contain
crucial information which are subject to various analyses. Examples range from
cybersecurity, intrusion detection over usage analyses to trouble shooting.
Before data analysis is possible, desired information needs to be extracted
first out of the semi-structured log messages. State-of-the-art event parsing
often assumes static log events. However, any modern system is updated
consistently and with updates also log file structures can change. We call
those changes "mutation" and study parsing performance for different mutation
cases. Latest research discovers mutations using anomaly detection post mortem,
however, does not cover actual continuous parsing. Thus, we propose a novel and
flexible parser, called FlexParser, which can extract desired values despite
gradual changes in the log messages. It implies basic text preprocessing
followed by a supervised Deep Learning method. We train a stateful LSTM on
parsing one event per data set. Statefulness enforces the model to learn log
message structures across several examples. Our model was tested on seven
different, publicly available log file data sets and various kinds of
mutations. Exhibiting an average F1-Score of 0.98, it outperforms other Deep
Learning methods as well as state-of-the-art unsupervised parsers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Task-Oriented Dialog Modeling with Semi-Structured Knowledge Management. (arXiv:2106.11796v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11796">
<div class="article-summary-box-inner">
<span><p>Current task-oriented dialog (TOD) systems mostly manage structured knowledge
(e.g. databases and tables) to guide the goal-oriented conversations. However,
they fall short of handling dialogs which also involve unstructured knowledge
(e.g. reviews and documents). In this paper, we formulate a task of modeling
TOD grounded on a fusion of structured and unstructured knowledge. To address
this task, we propose a TOD system with semi-structured knowledge management,
SeKnow, which extends the belief state to manage knowledge with both structured
and unstructured contents. Furthermore, we introduce two implementations of
SeKnow based on a non-pretrained sequence-to-sequence model and a pretrained
language model, respectively. Both implementations use the end-to-end manner to
jointly optimize dialog modeling grounded on structured and unstructured
knowledge. We conduct experiments on a modified version of MultiWOZ 2.1
dataset, Mod-MultiWOZ 2.1, where dialogs are processed to involve
semi-structured knowledge. Experimental results show that SeKnow has strong
performances in both end-to-end dialog and intermediate knowledge management,
compared to existing TOD systems and their extensions with pipeline knowledge
management schemes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Audiomer: A Convolutional Transformer For Keyword Spotting. (arXiv:2109.10252v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10252">
<div class="article-summary-box-inner">
<span><p>Transformers have seen an unprecedented rise in Natural Language Processing
and Computer Vision tasks. However, in audio tasks, they are either infeasible
to train due to extremely large sequence length of audio waveforms or incur a
performance penalty when trained on Fourier-based features. In this work, we
introduce an architecture, Audiomer, where we combine 1D Residual Networks with
Performer Attention to achieve state-of-the-art performance in keyword spotting
with raw audio waveforms, outperforming all previous methods while being
computationally cheaper and parameter-efficient. Additionally, our model has
practical advantages for speech processing, such as inference on arbitrarily
long audio clips owing to the absence of positional encoding. The code is
available at https://github.com/The-Learning-Machines/Audiomer-PyTorch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capturing Structural Locality in Non-parametric Language Models. (arXiv:2110.02870v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02870">
<div class="article-summary-box-inner">
<span><p>Structural locality is a ubiquitous feature of real-world datasets, wherein
data points are organized into local hierarchies. Some examples include topical
clusters in text or project hierarchies in source code repositories. In this
paper, we explore utilizing this structural locality within non-parametric
language models, which generate sequences that reference retrieved examples
from an external source. We propose a simple yet effective approach for adding
locality information into such models by adding learned parameters that improve
the likelihood of retrieving examples from local neighborhoods. Experiments on
two different domains, Java source code and Wikipedia text, demonstrate that
locality features improve model efficacy over models without access to these
features, with interesting differences. We also perform an analysis of how and
where locality features contribute to improved performance and why the
traditionally used contextual similarity metrics alone are not enough to grasp
the locality structure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CsFEVER and CTKFacts: Czech Datasets for Fact Verification. (arXiv:2201.11115v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11115">
<div class="article-summary-box-inner">
<span><p>In this paper, we present two Czech datasets for automated fact-checking,
which is a task commonly modeled as a classification of textual claim veracity
w.r.t. a corpus of trusted ground truths. We consider 3 classes: SUPPORTS,
REFUTES complemented with evidence documents or NEI (Not Enough Info) alone.
Our first dataset, CsFEVER, has 127,328 claims. It is an automatically
generated Czech version of the large-scale FEVER dataset built on top of
Wikipedia corpus. We take a hybrid approach of machine translation and document
alignment; the approach, and the tools we provide, can be easily applied to
other languages. The second dataset, CTKFacts of 3,097 claims, is annotated
using the corpus of 2.2M articles of Czech News Agency. We present its extended
annotation methodology based on the FEVER approach. We analyze both datasets
for spurious cues - annotation patterns leading to model overfitting. CTKFacts
is further examined for inter-annotator agreement, thoroughly cleaned, and a
typology of common annotator errors is extracted. Finally, we provide baseline
models for all stages of the fact-checking pipeline.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">BREAK: Bronchi Reconstruction by gEodesic transformation And sKeleton embedding. (arXiv:2202.00002v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00002">
<div class="article-summary-box-inner">
<span><p>Airway segmentation is critical for virtual bronchoscopy and computer-aided
pulmonary disease analysis. In recent years, convolutional neural networks
(CNNs) have been widely used to delineate the bronchial tree. However, the
segmentation results of the CNN-based methods usually include many
discontinuous branches, which need manual repair in clinical use. A major
reason for the breakages is that the appearance of the airway wall can be
affected by the lung disease as well as the adjacency of the vessels, while the
network tends to overfit to these special patterns in the training set. To
learn robust features for these areas, we design a multi-branch framework that
adopts the geodesic distance transform to capture the intensity changes between
airway lumen and wall. Another reason for the breakages is the intra-class
imbalance. Since the volume of the peripheral bronchi may be much smaller than
the large branches in an input patch, the common segmentation loss is not
sensitive to the breakages among the distal branches. Therefore, in this paper,
a breakage-sensitive regularization term is designed and can be easily combined
with other loss functions. Extensive experiments are conducted on publicly
available datasets. Compared with state-of-the-art methods, our framework can
detect more branches while maintaining competitive segmentation performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Bitstream Metadata for Fast and Accurate Video Compression Correction. (arXiv:2202.00011v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00011">
<div class="article-summary-box-inner">
<span><p>Video compression is a central feature of the modern internet powering
technologies from social media to video conferencing. While video compression
continues to mature, for many, and particularly for extreme, compression
settings, quality loss is still noticeable. These extreme settings nevertheless
have important applications to the efficient transmission of videos over
bandwidth constrained or otherwise unstable connections. In this work, we
develop a deep learning architecture capable of restoring detail to compressed
videos which leverages the underlying structure and motion information embedded
in the video bitstream. We show that this improves restoration accuracy
compared to prior compression correction methods and is competitive when
compared with recent deep-learning-based video compression methods on
rate-distortion while achieving higher throughput.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finding Directions in GAN's Latent Space for Neural Face Reenactment. (arXiv:2202.00046v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00046">
<div class="article-summary-box-inner">
<span><p>This paper is on face/head reenactment where the goal is to transfer the
facial pose (3D head orientation and expression) of a target face to a source
face. Previous methods focus on learning embedding networks for identity and
pose disentanglement which proves to be a rather hard task, degrading the
quality of the generated images. We take a different approach, bypassing the
training of such networks, by using (fine-tuned) pre-trained GANs which have
been shown capable of producing high-quality facial images. Because GANs are
characterized by weak controllability, the core of our approach is a method to
discover which directions in latent GAN space are responsible for controlling
facial pose and expression variations. We present a simple pipeline to learn
such directions with the aid of a 3D shape model which, by construction,
already captures disentangled directions for facial pose, identity and
expression. Moreover, we show that by embedding real images in the GAN latent
space, our method can be successfully used for the reenactment of real-world
faces. Our method features several favorable properties including using a
single source image (one-shot) and enabling cross-person reenactment. Our
qualitative and quantitative results show that our approach often produces
reenacted faces of significantly higher quality than those produced by
state-of-the-art methods for the standard benchmarks of VoxCeleb1 &amp; 2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep-Disaster: Unsupervised Disaster Detection and Localization Using Visual Data. (arXiv:2202.00050v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00050">
<div class="article-summary-box-inner">
<span><p>Social media plays a significant role in sharing essential information, which
helps humanitarian organizations in rescue operations during and after disaster
incidents. However, developing an efficient method that can provide rapid
analysis of social media images in the early hours of disasters is still
largely an open problem, mainly due to the lack of suitable datasets and the
sheer complexity of this task. In addition, supervised methods can not
generalize well to novel disaster incidents. In this paper, inspired by the
success of Knowledge Distillation (KD) methods, we propose an unsupervised deep
neural network to detect and localize damages in social media images. Our
proposed KD architecture is a feature-based distillation approach that
comprises a pre-trained teacher and a smaller student network, with both
networks having similar GAN architecture containing a generator and a
discriminator. The student network is trained to emulate the behavior of the
teacher on training input samples, which, in turn, contain images that do not
include any damaged regions. Therefore, the student network only learns the
distribution of no damage data and would have different behavior from the
teacher network-facing damages. To detect damage, we utilize the difference
between features generated by two networks using a defined score function that
demonstrates the probability of damages occurring. Our experimental results on
the benchmark dataset confirm that our approach outperforms state-of-the-art
methods in detecting and localizing the damaged areas, especially for novel
disaster types.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoGeoLabel: Automated Label Generation for Geospatial Machine Learning. (arXiv:2202.00067v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00067">
<div class="article-summary-box-inner">
<span><p>A key challenge of supervised learning is the availability of human-labeled
data. We evaluate a big data processing pipeline to auto-generate labels for
remote sensing data. It is based on rasterized statistical features extracted
from surveys such as e.g. LiDAR measurements. Using simple combinations of the
rasterized statistical layers, it is demonstrated that multiple classes can be
generated at accuracies of ~0.9. As proof of concept, we utilize the big
geo-data platform IBM PAIRS to dynamically generate such labels in dense urban
areas with multiple land cover classes. The general method proposed here is
platform independent, and it can be adapted to generate labels for other
satellite modalities in order to enable machine learning on overhead imagery
for land use classification and object detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Holistic Fine-grained GGS Characterization: From Detection to Unbalanced Classification. (arXiv:2202.00087v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00087">
<div class="article-summary-box-inner">
<span><p>Recent studies have demonstrated the diagnostic and prognostic values of
global glomerulosclerosis (GGS) in IgA nephropathy, aging, and end-stage renal
disease. However, the fine-grained quantitative analysis of multiple GGS
subtypes (e.g., obsolescent, solidified, and disappearing glomerulosclerosis)
is typically a resource extensive manual process. Very few automatic methods,
if any, have been developed to bridge this gap for such analytics. In this
paper, we present a holistic pipeline to quantify GGS (with both detection and
classification) from a whole slide image in a fully automatic manner. In
addition, we conduct the fine-grained classification for the sub-types of GGS.
Our study releases the open-source quantitative analytical tool for
fine-grained GGS characterization while tackling the technical challenges in
unbalanced classification and integrating detection and classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Query Efficient Decision Based Sparse Attacks Against Black-Box Deep Learning Models. (arXiv:2202.00091v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00091">
<div class="article-summary-box-inner">
<span><p>Despite our best efforts, deep learning models remain highly vulnerable to
even tiny adversarial perturbations applied to the inputs. The ability to
extract information from solely the output of a machine learning model to craft
adversarial perturbations to black-box models is a practical threat against
real-world systems, such as autonomous cars or machine learning models exposed
as a service (MLaaS). Of particular interest are sparse attacks. The
realization of sparse attacks in black-box models demonstrates that machine
learning models are more vulnerable than we believe. Because these attacks aim
to minimize the number of perturbed pixels measured by l_0 norm-required to
mislead a model by solely observing the decision (the predicted label) returned
to a model query; the so-called decision-based attack setting. But, such an
attack leads to an NP-hard optimization problem. We develop an evolution-based
algorithm-SparseEvo-for the problem and evaluate against both convolutional
deep neural networks and vision transformers. Notably, vision transformers are
yet to be investigated under a decision-based attack setting. SparseEvo
requires significantly fewer model queries than the state-of-the-art sparse
attack Pointwise for both untargeted and targeted attacks. The attack
algorithm, although conceptually simple, is also competitive with only a
limited query budget against the state-of-the-art gradient-based whitebox
attacks in standard computer vision tasks such as ImageNet. Importantly, the
query efficient SparseEvo, along with decision-based attacks, in general, raise
new questions regarding the safety of deployed systems and poses new directions
to study and understand the robustness of machine learning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-supervised Identification and Mapping of Surface Water Extent using Street-level Monitoring Videos. (arXiv:2202.00096v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00096">
<div class="article-summary-box-inner">
<span><p>Urban flooding is becoming a common and devastating hazard to cause life loss
and economic damage. Monitoring and understanding urban flooding in the local
scale is a challenging task due to the complicated urban landscape, intricate
hydraulic process, and the lack of high-quality and resolution data. The
emerging smart city technology such as monitoring cameras provides an
unprecedented opportunity to address the data issue. However, estimating the
water accumulation on the land surface based on the monitoring footage is
unreliable using the traditional segmentation technique because the boundary of
the water accumulation, under the influence of varying weather, background, and
illumination, is usually too fuzzy to identify, and the oblique angle and image
distortion in the video monitoring data prevents georeferencing and
object-based measurements. This paper presents a novel semi-supervised
segmentation scheme for surface water extent recognition from the footage of an
oblique monitoring camera. The semi-supervised segmentation algorithm was found
suitable to determine the water boundary and the monoplotting method was
successfully applied to georeference the pixels of the monitoring video for the
virtual quantification of the local drainage process. The correlation and
mechanism-based analysis demonstrates the value of the proposed method in
advancing the understanding of local drainage hydraulics. The workflow and
created methods in this study has a great potential to study other street-level
and earth surface processes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-Time Facial Expression Recognition using Facial Landmarks and Neural Networks. (arXiv:2202.00102v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00102">
<div class="article-summary-box-inner">
<span><p>This paper presents a lightweight algorithm for feature extraction,
classification of seven different emotions, and facial expression recognition
in a real-time manner based on static images of the human face. In this regard,
a Multi-Layer Perceptron (MLP) neural network is trained based on the foregoing
algorithm. In order to classify human faces, first, some pre-processing is
applied to the input image, which can localize and cut out faces from it. In
the next step, a facial landmark detection library is used, which can detect
the landmarks of each face. Then, the human face is split into upper and lower
faces, which enables the extraction of the desired features from each part. In
the proposed model, both geometric and texture-based feature types are taken
into account. After the feature extraction phase, a normalized vector of
features is created. A 3-layer MLP is trained using these feature vectors,
leading to 96% accuracy on the test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Visualization and Spatial Data Mining for Analysis of LULC Images. (arXiv:2202.00123v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00123">
<div class="article-summary-box-inner">
<span><p>The present study is an attempt made to create a new tool for the analysis of
Land Use Land Cover (LUCL) images in 3D visualization. This study mainly uses
spatial data mining techniques on high resolution LULC satellite imagery.
Visualization of feature space allows exploration of patterns in the image data
and insight into the classification process and related uncertainty. Visual
Data Mining provides added value to image classifications as the user can be
involved in the classification process providing increased confidence in and
understanding of the results. In this study, we present a prototype of image
segmentation, K-Means clustering and 3D visualization tool for visual data
mining (VDM) of LUCL satellite imagery into volume visualization. This volume
based representation divides feature space into spheres or voxels. The
visualization tool is showcased in a classification study of high-resolution
LULC imagery of Latur district (Maharashtra state, India) is used as sample
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning-Based Framework for Camera Calibration with Distortion Correction and High Precision Feature Detection. (arXiv:2202.00158v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00158">
<div class="article-summary-box-inner">
<span><p>Camera calibration is a crucial technique which significantly influences the
performance of many robotic systems. Robustness and high precision have always
been the pursuit of diverse calibration methods. State-of-the-art calibration
techniques based on classical Zhang's method, however, still suffer from
environmental noise, radial lens distortion and sub-optimal parameter
estimation. Therefore, in this paper, we propose a hybrid camera calibration
framework which combines learning-based approaches with traditional methods to
handle these bottlenecks. In particular, this framework leverages
learning-based approaches to perform efficient distortion correction and robust
chessboard corner coordinate encoding. For sub-pixel accuracy of corner
detection, a specially-designed coordinate decoding algorithm with embed
outlier rejection mechanism is proposed. To avoid sub-optimal estimation
results, we improve the traditional parameter estimation by RANSAC algorithm
and achieve stable results. Compared with two widely-used camera calibration
toolboxes, experiment results on both real and synthetic datasets manifest the
better robustness and higher precision of the proposed framework. The massive
synthetic dataset is the basis of our framework's decent performance and will
be publicly available along with the code at
https://github.com/Easonyesheng/CCS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dilated Continuous Random Field for Semantic Segmentation. (arXiv:2202.00162v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00162">
<div class="article-summary-box-inner">
<span><p>Mean field approximation methodology has laid the foundation of modern
Continuous Random Field (CRF) based solutions for the refinement of semantic
segmentation. In this paper, we propose to relax the hard constraint of mean
field approximation - minimizing the energy term of each node from
probabilistic graphical model, by a global optimization with the proposed
dilated sparse convolution module (DSConv). In addition, adaptive global
average-pooling and adaptive global max-pooling are implemented as replacements
of fully connected layers. In order to integrate DSConv, we design an
end-to-end, time-efficient DilatedCRF pipeline. The unary energy term is
derived either from pre-softmax and post-softmax features, or the predicted
affordance map using a conventional classifier, making it easier to implement
DilatedCRF for varieties of classifiers. We also present superior experimental
results of proposed approach on the suction dataset comparing to other
CRF-based approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DexVIP: Learning Dexterous Grasping with Human Hand Pose Priors from Video. (arXiv:2202.00164v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00164">
<div class="article-summary-box-inner">
<span><p>Dexterous multi-fingered robotic hands have a formidable action space, yet
their morphological similarity to the human hand holds immense potential to
accelerate robot learning. We propose DexVIP, an approach to learn dexterous
robotic grasping from human-object interactions present in in-the-wild YouTube
videos. We do this by curating grasp images from human-object interaction
videos and imposing a prior over the agent's hand pose when learning to grasp
with deep reinforcement learning. A key advantage of our method is that the
learned policy is able to leverage free-form in-the-wild visual data. As a
result, it can easily scale to new objects, and it sidesteps the standard
practice of collecting human demonstrations in a lab -- a much more expensive
and indirect way to capture human expertise. Through experiments on 27 objects
with a 30-DoF simulated robot hand, we demonstrate that DexVIP compares
favorably to existing approaches that lack a hand pose prior or rely on
specialized tele-operation equipment to obtain human demonstrations, while also
being faster to train. Project page:
https://vision.cs.utexas.edu/projects/dexvip-dexterous-grasp-pose-prior
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fractional Motion Estimation for Point Cloud Compression. (arXiv:2202.00172v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00172">
<div class="article-summary-box-inner">
<span><p>Motivated by the success of fractional pixel motion in video coding, we
explore the design of motion estimation with fractional-voxel resolution for
compression of color attributes of dynamic 3D point clouds. Our proposed
block-based fractional-voxel motion estimation scheme takes into account the
fundamental differences between point clouds and videos, i.e., the irregularity
of the distribution of voxels within a frame and across frames. We show that
motion compensation can benefit from the higher resolution reference and more
accurate displacements provided by fractional precision. Our proposed scheme
significantly outperforms comparable methods that only use integer motion. The
proposed scheme can be combined with and add sizeable gains to state-of-the-art
systems that use transforms such as Region Adaptive Graph Fourier Transform and
Region Adaptive Haar Transform.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Blind Image Deconvolution Using Variational Deep Image Prior. (arXiv:2202.00179v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00179">
<div class="article-summary-box-inner">
<span><p>Conventional deconvolution methods utilize hand-crafted image priors to
constrain the optimization. While deep-learning-based methods have simplified
the optimization by end-to-end training, they fail to generalize well to blurs
unseen in the training dataset. Thus, training image-specific models is
important for higher generalization. Deep image prior (DIP) provides an
approach to optimize the weights of a randomly initialized network with a
single degraded image by maximum a posteriori (MAP), which shows that the
architecture of a network can serve as the hand-crafted image prior. Different
from the conventional hand-crafted image priors that are statistically
obtained, it is hard to find a proper network architecture because the
relationship between images and their corresponding network architectures is
unclear. As a result, the network architecture cannot provide enough constraint
for the latent sharp image. This paper proposes a new variational deep image
prior (VDIP) for blind image deconvolution, which exploits additive
hand-crafted image priors on latent sharp images and approximates a
distribution for each pixel to avoid suboptimal solutions. Our mathematical
analysis shows that the proposed method can better constrain the optimization.
The experimental results further demonstrate that the generated images have
better quality than that of the original DIP on benchmark datasets. The source
code of our VDIP is available at
https://github.com/Dong-Huo/VDIP-Deconvolution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLA-NeRF: Category-Level Articulated Neural Radiance Field. (arXiv:2202.00181v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00181">
<div class="article-summary-box-inner">
<span><p>We propose CLA-NeRF -- a Category-Level Articulated Neural Radiance Field
that can perform view synthesis, part segmentation, and articulated pose
estimation. CLA-NeRF is trained at the object category level using no CAD
models and no depth, but a set of RGB images with ground truth camera poses and
part segments. During inference, it only takes a few RGB views (i.e., few-shot)
of an unseen 3D object instance within the known category to infer the object
part segmentation and the neural radiance field. Given an articulated pose as
input, CLA-NeRF can perform articulation-aware volume rendering to generate the
corresponding RGB image at any camera pose. Moreover, the articulated pose of
an object can be estimated via inverse rendering. In our experiments, we
evaluate the framework across five categories on both synthetic and real-world
data. In all cases, our method shows realistic deformation results and accurate
articulated pose estimation. We believe that both few-shot articulated object
rendering and articulated pose estimation open doors for robots to perceive and
interact with unseen articulated objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-supervised 3D Object Detection via Temporal Graph Neural Networks. (arXiv:2202.00182v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00182">
<div class="article-summary-box-inner">
<span><p>3D object detection plays an important role in autonomous driving and other
robotics applications. However, these detectors usually require training on
large amounts of annotated data that is expensive and time-consuming to
collect. Instead, we propose leveraging large amounts of unlabeled point cloud
videos by semi-supervised learning of 3D object detectors via temporal graph
neural networks. Our insight is that temporal smoothing can create more
accurate detection results on unlabeled data, and these smoothed detections can
then be used to retrain the detector. We learn to perform this temporal
reasoning with a graph neural network, where edges represent the relationship
between candidate detections in different time frames. After semi-supervised
learning, our method achieves state-of-the-art detection performance on the
challenging nuScenes and H3D benchmarks, compared to baselines trained on the
same amount of labeled data. Project and code are released at
https://www.jianrenw.com/SOD-TGNN/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ATEK: Augmenting Transformers with Expert Knowledge for Indoor Layout Synthesis. (arXiv:2202.00185v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00185">
<div class="article-summary-box-inner">
<span><p>We address the problem of indoor layout synthesis, which is a topic of
continuing research interest in computer graphics. The newest works made
significant progress using data-driven generative methods; however, these
approaches rely on suitable datasets. In practice, desirable layout properties
may not exist in a dataset, for instance, specific expert knowledge can be
missing in the data. We propose a method that combines expert knowledge, for
example, knowledge about ergonomics, with a data-driven generator based on the
popular Transformer architecture. The knowledge is given as differentiable
scalar functions, which can be used both as weights or as additional terms in
the loss function. Using this knowledge, the synthesized layouts can be biased
to exhibit desirable properties, even if these properties are not present in
the dataset. Our approach can also alleviate problems of lack of data and
imperfections in the data. Our work aims to improve generative machine learning
for modeling and provide novel tools for designers and amateurs for the problem
of interior layout creation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognition-Aware Learned Image Compression. (arXiv:2202.00198v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00198">
<div class="article-summary-box-inner">
<span><p>Learned image compression methods generally optimize a rate-distortion loss,
trading off improvements in visual distortion for added bitrate. Increasingly,
however, compressed imagery is used as an input to deep learning networks for
various tasks such as classification, object detection, and superresolution. We
propose a recognition-aware learned compression method, which optimizes a
rate-distortion loss alongside a task-specific loss, jointly learning
compression and recognition networks. We augment a hierarchical
autoencoder-based compression network with an EfficientNet recognition model
and use two hyperparameters to trade off between distortion, bitrate, and
recognition performance. We characterize the classification accuracy of our
proposed method as a function of bitrate and find that for low bitrates our
method achieves as much as 26% higher recognition accuracy at equivalent
bitrates compared to traditional methods such as Better Portable Graphics
(BPG).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling multiple scattering with deep learning: application to strain mapping from electron diffraction patterns. (arXiv:2202.00204v1 [cond-mat.mtrl-sci])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00204">
<div class="article-summary-box-inner">
<span><p>Implementation of a fast, robust, and fully-automated pipeline for crystal
structure determination and underlying strain mapping for crystalline materials
is important for many technological applications. Scanning electron
nanodiffraction offers a procedure for identifying and collecting strain maps
with good accuracy and high spatial resolutions. However, the application of
this technique is limited, particularly in thick samples where the electron
beam can undergo multiple scattering, which introduces signal nonlinearities.
Deep learning methods have the potential to invert these complex signals, but
previous implementations are often trained only on specific crystal systems or
a small subset of the crystal structure and microscope parameter phase space.
In this study, we implement a Fourier space, complex-valued deep neural network
called FCU-Net, to invert highly nonlinear electron diffraction patterns into
the corresponding quantitative structure factor images. We trained the FCU-Net
using over 200,000 unique simulated dynamical diffraction patterns which
include many different combinations of crystal structures, orientations,
thicknesses, microscope parameters, and common experimental artifacts. We
evaluated the trained FCU-Net model against simulated and experimental 4D-STEM
diffraction datasets, where it substantially out-performs conventional analysis
methods. Our simulated diffraction pattern library, implementation of FCU-Net,
and trained model weights are freely available in open source repositories, and
can be adapted to many different diffraction measurement problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ISNet: Costless and Implicit Image Segmentation for Deep Classifiers, with Application in COVID-19 Detection. (arXiv:2202.00232v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00232">
<div class="article-summary-box-inner">
<span><p>In this work we propose a novel deep neural network (DNN) architecture,
ISNet, to solve the task of image segmentation followed by classification,
substituting the common pipeline of two networks by a single model. We designed
the ISNet for high flexibility and performance: it allows virtually any
classification neural network architecture to analyze a common image as if it
had been previously segmented. Furthermore, in relation to the original
classifier, the ISNet does not cause any increment in computational cost or
architectural changes at run-time. To accomplish this, we introduce the concept
of optimizing DNNs for relevance segmentation in heatmaps created by Layer-wise
Relevance Propagation (LRP), which proves to be equivalent to the
classification of previously segmented images. We apply an ISNet based on a
DenseNet121 classifier to solve the task of COVID-19 detection in chest X-rays.
We compare the model to a U-net (performing lung segmentation) followed by a
DenseNet121, and to a standalone DenseNet121. Due to the implicit segmentation,
the ISNet precisely ignored the X-ray regions outside of the lungs; it achieved
94.5 +/-4.1% mean accuracy with an external database, showing strong
generalization capability and surpassing the other models' performances by 6 to
7.9%. ISNet presents a fast and light methodology to perform classification
preceded by segmentation, while also being more accurate than standard
pipelines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Imitation Learning from Video using a State Observer. (arXiv:2202.00243v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00243">
<div class="article-summary-box-inner">
<span><p>The imitation learning research community has recently made significant
progress towards the goal of enabling artificial agents to imitate behaviors
from video demonstrations alone. However, current state-of-the-art approaches
developed for this problem exhibit high sample complexity due, in part, to the
high-dimensional nature of video observations. Towards addressing this issue,
we introduce here a new algorithm called Visual Generative Adversarial
Imitation from Observation using a State Observer VGAIfO-SO. At its core,
VGAIfO-SO seeks to address sample inefficiency using a novel, self-supervised
state observer, which provides estimates of lower-dimensional proprioceptive
state representations from high-dimensional images. We show experimentally in
several continuous control environments that VGAIfO-SO is more sample efficient
than other IfO algorithms at learning from video-only demonstrations and can
sometimes even achieve performance close to the Generative Adversarial
Imitation from Observation (GAIfO) algorithm that has privileged access to the
demonstrator's proprioceptive state information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Human-Object Interactions with Object-Guided Cross-Modal Calibrated Semantics. (arXiv:2202.00259v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00259">
<div class="article-summary-box-inner">
<span><p>Human-Object Interaction (HOI) detection is an essential task to understand
human-centric images from a fine-grained perspective. Although end-to-end HOI
detection models thrive, their paradigm of parallel human/object detection and
verb class prediction loses two-stage methods' merit: object-guided hierarchy.
The object in one HOI triplet gives direct clues to the verb to be predicted.
In this paper, we aim to boost end-to-end models with object-guided statistical
priors. Specifically, We propose to utilize a Verb Semantic Model (VSM) and use
semantic aggregation to profit from this object-guided hierarchy. Similarity KL
(SKL) loss is proposed to optimize VSM to align with the HOI dataset's priors.
To overcome the static semantic embedding problem, we propose to generate
cross-modality-aware visual and semantic features by Cross-Modal Calibration
(CMC). The above modules combined composes Object-guided Cross-modal
Calibration Network (OCN). Experiments conducted on two popular HOI detection
benchmarks demonstrate the significance of incorporating the statistical prior
knowledge and produce state-of-the-art performances. More detailed analysis
indicates proposed modules serve as a stronger verb predictor and a more
superior method of utilizing prior knowledge. The codes are available at
\url{https://github.com/JacobYuan7/OCN-HOI-Benchmark}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Online Meta-Learning Without Task Boundaries. (arXiv:2202.00263v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00263">
<div class="article-summary-box-inner">
<span><p>While deep networks can learn complex functions such as classifiers,
detectors, and trackers, many applications require models that continually
adapt to changing input distributions, changing tasks, and changing
environmental conditions. Indeed, this ability to continuously accrue knowledge
and use past experience to learn new tasks quickly in continual settings is one
of the key properties of an intelligent system. For complex and
high-dimensional problems, simply updating the model continually with standard
learning algorithms such as gradient descent may result in slow adaptation.
Meta-learning can provide a powerful tool to accelerate adaptation yet is
conventionally studied in batch settings. In this paper, we study how
meta-learning can be applied to tackle online problems of this nature,
simultaneously adapting to changing tasks and input distributions and
meta-training the model in order to adapt more quickly in the future. Extending
meta-learning into the online setting presents its own challenges, and although
several prior methods have studied related problems, they generally require a
discrete notion of tasks, with known ground-truth task boundaries. Such methods
typically adapt to each task in sequence, resetting the model between tasks,
rather than adapting continuously across tasks. In many real-world settings,
such discrete boundaries are unavailable, and may not even exist. To address
these settings, we propose a Fully Online Meta-Learning (FOML) algorithm, which
does not require any ground truth knowledge about the task boundaries and stays
fully online without resetting back to pre-trained weights. Our experiments
show that FOML was able to learn new tasks faster than the state-of-the-art
online learning methods on Rainbow-MNIST, CIFAR100 and CELEBA datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Access Control of Object Detection Models Using Encrypted Feature Maps. (arXiv:2202.00265v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00265">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose an access control method for object detection
models. The use of encrypted images or encrypted feature maps has been
demonstrated to be effective in access control of models from unauthorized
access. However, the effectiveness of the approach has been confirmed in only
image classification models and semantic segmentation models, but not in object
detection models. In this paper, the use of encrypted feature maps is shown to
be effective in access control of object detection models for the first time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets. (arXiv:2202.00273v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00273">
<div class="article-summary-box-inner">
<span><p>Computer graphics has experienced a recent surge of data-centric approaches
for photorealistic and controllable content creation. StyleGAN in particular
sets new standards for generative modeling regarding image quality and
controllability. However, StyleGAN's performance severely degrades on large
unstructured datasets such as ImageNet. StyleGAN was designed for
controllability; hence, prior works suspect its restrictive design to be
unsuitable for diverse datasets. In contrast, we find the main limiting factor
to be the current training strategy. Following the recently introduced
Projected GAN paradigm, we leverage powerful neural network priors and a
progressive growing strategy to successfully train the latest StyleGAN3
generator on ImageNet. Our final model, StyleGAN-XL, sets a new
state-of-the-art on large-scale image synthesis and is the first to generate
images at a resolution of $1024^2$ at such a dataset scale. We demonstrate that
this model can invert and edit images beyond the narrow domain of portraits or
specific object classes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Laplacian2Mesh: Laplacian-Based Mesh Understanding. (arXiv:2202.00307v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00307">
<div class="article-summary-box-inner">
<span><p>Geometric deep learning has sparked a rising interest in computer graphics to
perform shape understanding tasks, such as shape classification and semantic
segmentation on three-dimensional (3D) geometric surfaces. Previous works
explored the significant direction by defining the operations of convolution
and pooling on triangle meshes, but most methods explicitly utilized the graph
connection structure of the mesh. Motivated by the geometric spectral surface
reconstruction theory, we introduce a novel and flexible convolutional neural
network (CNN) model, called Laplacian2Mesh, for 3D triangle mesh, which maps
the features of mesh in the Euclidean space to the multi-dimensional
Laplacian-Beltrami space, which is similar to the multi-resolution input in 2D
CNN. Mesh pooling is applied to expand the receptive field of the network by
the multi-space transformation of Laplacian which retains the surface topology,
and channel self-attention convolutions are applied in the new space. Since
implicitly using the intrinsic geodesic connections of the mesh through the
adjacency matrix, we do not consider the number of the neighbors of the
vertices, thereby mesh data with different numbers of vertices can be input.
Experiments on various learning tasks applied to 3D meshes demonstrate the
effectiveness and efficiency of Laplacian2Mesh.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Explanations to Segmentation: Using Explainable AI for Image Segmentation. (arXiv:2202.00315v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00315">
<div class="article-summary-box-inner">
<span><p>The new era of image segmentation leveraging the power of Deep Neural Nets
(DNNs) comes with a price tag: to train a neural network for pixel-wise
segmentation, a large amount of training samples has to be manually labeled on
pixel-precision. In this work, we address this by following an indirect
solution. We build upon the advances of the Explainable AI (XAI) community and
extract a pixel-wise binary segmentation from the output of the Layer-wise
Relevance Propagation (LRP) explaining the decision of a classification
network. We show that we achieve similar results compared to an established
U-Net segmentation architecture, while the generation of the training data is
significantly simplified. The proposed method can be trained in a weakly
supervised fashion, as the training samples must be only labeled on
image-level, at the same time enabling the output of a segmentation mask. This
makes it especially applicable to a wider range of real applications where
tedious pixel-level labelling is often not possible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space. (arXiv:2202.00368v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00368">
<div class="article-summary-box-inner">
<span><p>Learning causal relationships in high-dimensional data (images, videos) is a
hard task, as they are often defined on low dimensional manifolds and must be
extracted from complex signals dominated by appearance, lighting, textures and
also spurious correlations in the data. We present a method for learning
counterfactual reasoning of physical processes in pixel space, which requires
the prediction of the impact of interventions on initial conditions. Going
beyond the identification of structural relationships, we deal with the
challenging problem of forecasting raw video over long horizons. Our method
does not require the knowledge or supervision of any ground truth positions or
other object or scene properties. Our model learns and acts on a suitable
hybrid latent representation based on a combination of dense features, sets of
2D keypoints and an additional latent vector per keypoint. We show that this
better captures the dynamics of physical processes than purely dense or sparse
representations. We introduce a new challenging and carefully designed
counterfactual benchmark for predictions in pixel space and outperform strong
baselines in physics-inspired ML and video prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Study of Calibration Methods for Imbalanced Class Incremental Learning. (arXiv:2202.00386v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00386">
<div class="article-summary-box-inner">
<span><p>Deep learning approaches are successful in a wide range of AI problems and in
particular for visual recognition tasks. However, there are still open problems
among which is the capacity to handle streams of visual information and the
management of class imbalance in datasets. Existing research approaches these
two problems separately while they co-occur in real world applications. Here,
we study the problem of learning incrementally from imbalanced datasets. We
focus on algorithms which have a constant deep model complexity and use a
bounded memory to store exemplars of old classes across incremental states.
Since memory is bounded, old classes are learned with fewer images than new
classes and an imbalance due to incremental learning is added to the initial
dataset imbalance. A score prediction bias in favor of new classes appears and
we evaluate a comprehensive set of score calibration methods to reduce it.
Evaluation is carried with three datasets, using two dataset imbalance
configurations and three bounded memory sizes. Results show that most
calibration methods have beneficial effect and that they are most useful for
lower bounded memory sizes, which are most interesting in practice. As a
secondary contribution, we remove the usual distillation component from the
loss function of incremental learning algorithms. We show that simpler vanilla
fine tuning is a stronger backbone for imbalanced incremental learning
algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Minority Class Oriented Active Learning for Imbalanced Datasets. (arXiv:2202.00390v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00390">
<div class="article-summary-box-inner">
<span><p>Active learning aims to optimize the dataset annotation process when
resources are constrained. Most existing methods are designed for balanced
datasets. Their practical applicability is limited by the fact that a majority
of real-life datasets are actually imbalanced. Here, we introduce a new active
learning method which is designed for imbalanced datasets. It favors samples
likely to be in minority classes so as to reduce the imbalance of the labeled
subset and create a better representation for these classes. We also compare
two training schemes for active learning: (1) the one commonly deployed in deep
active learning using model fine tuning for each iteration and (2) a scheme
which is inspired by transfer learning and exploits generic pre-trained models
and train shallow classifiers for each iteration. Evaluation is run with three
imbalanced datasets. Results show that the proposed active learning method
outperforms competitive baselines. Equally interesting, they also indicate that
the transfer learning training scheme outperforms model fine tuning if features
are transferable from the generic dataset to the unlabeled one. This last
result is surprising and should encourage the community to explore the design
of deep active learning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CAESR: Conditional Autoencoder and Super-Resolution for Learned Spatial Scalability. (arXiv:2202.00416v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00416">
<div class="article-summary-box-inner">
<span><p>In this paper, we present CAESR, an hybrid learning-based coding approach for
spatial scalability based on the versatile video coding (VVC) standard. Our
framework considers a low-resolution signal encoded with VVC intra-mode as a
base-layer (BL), and a deep conditional autoencoder with hyperprior (AE-HP) as
an enhancement-layer (EL) model. The EL encoder takes as inputs both the
upscaled BL reconstruction and the original image. Our approach relies on
conditional coding that learns the optimal mixture of the source and the
upscaled BL image, enabling better performance than residual coding. On the
decoder side, a super-resolution (SR) module is used to recover high-resolution
details and invert the conditional coding process. Experimental results have
shown that our solution is competitive with the VVC full-resolution intra
coding while being scalable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Review of Serial and Parallel Min-Cut/Max-Flow Algorithms for Computer Vision. (arXiv:2202.00418v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00418">
<div class="article-summary-box-inner">
<span><p>Minimum cut / maximum flow (min-cut/max-flow) algorithms are used to solve a
variety of problems in computer vision and thus significant effort has been put
into developing fast min-cut/max-flow algorithms. This makes it difficult to
choose an optimal algorithm for a given problem - especially for parallel
algorithms, which have not been thoroughly compared. In this paper, we review
the state-of-the-art min-cut/max-flow algorithms for unstructured graphs in
computer vision. We evaluate run time performance and memory use of various
implementations of both serial and parallel algorithms on a set of graph cut
problems. Our results show that the Hochbaum pseudoflow algorithm is the
fastest serial algorithm closely followed by the Excesses Incremental Breadth
First Search algorithm, while the Boykov-Kolmogorov algorithm is the most
memory efficient. The best parallel algorithm is the adaptive bottom-up merging
approach by Liu and Sun. Additionally, we show significant variations in
performance between different implementations the same algorithms highlighting
the importance of low-level implementation details. Finally, we note that
existing parallel min-cut/max-flow algorithms can significantly outperform
serial algorithms on large problems but suffers from added overhead on small to
medium problems. Implementations of all algorithms are available at
https://github.com/patmjen/maxflow_algorithms
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sinogram Enhancement with Generative Adversarial Networks using Shape Priors. (arXiv:2202.00419v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00419">
<div class="article-summary-box-inner">
<span><p>Compensating scarce measurements by inferring them from computational models
is a way to address ill-posed inverse problems. We tackle Limited Angle
Tomography by completing the set of acquisitions using a generative model and
prior-knowledge about the scanned object. Using a Generative Adversarial
Network as model and Computer-Assisted Design data as shape prior, we
demonstrate a quantitative and qualitative advantage of our technique over
other state-of-the-art methods. Inferring a substantial number of consecutive
missing measurements, we offer an alternative to other image inpainting
techniques that fall short of providing a satisfying answer to our research
question: can X-Ray exposition be reduced by using generative models to infer
lacking measurements?
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual Attentive Fusion for Incremental Learning in Semantic Segmentation. (arXiv:2202.00432v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00432">
<div class="article-summary-box-inner">
<span><p>Over the past years, semantic segmentation, as many other tasks in computer
vision, benefited from the progress in deep neural networks, resulting in
significantly improved performance. However, deep architectures trained with
gradient-based techniques suffer from catastrophic forgetting, which is the
tendency to forget previously learned knowledge while learning new tasks.
Aiming at devising strategies to counteract this effect, incremental learning
approaches have gained popularity over the past years. However, the first
incremental learning methods for semantic segmentation appeared only recently.
While effective, these approaches do not account for a crucial aspect in
pixel-level dense prediction problems, i.e. the role of attention mechanisms.
To fill this gap, in this paper we introduce a novel attentive feature
distillation approach to mitigate catastrophic forgetting while accounting for
semantic spatial- and channel-level dependencies. Furthermore, we propose a
{continual attentive fusion} structure, which takes advantage of the attention
learned from the new and the old tasks while learning features for the new
task. Finally, we also introduce a novel strategy to account for the background
class in the distillation loss, thus preventing biased predictions. We
demonstrate the effectiveness of our approach with an extensive evaluation on
Pascal-VOC 2012 and ADE20K, setting a new state of the art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Order Networks for Action Unit Detection. (arXiv:2202.00446v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00446">
<div class="article-summary-box-inner">
<span><p>Deep multi-task methods, where several tasks are learned within a single
network, have recently attracted increasing attention. Burning point of this
attention is their capacity to capture inter-task relationships. Current
approaches either only rely on weight sharing, or add explicit dependency
modelling by decomposing the task joint distribution using Bayes chain rule. If
the latter strategy yields comprehensive inter-task relationships modelling, it
requires imposing an arbitrary order into an unordered task set. Most
importantly, this sequence ordering choice has been identified as a critical
source of performance variations. In this paper, we present Multi-Order Network
(MONET), a multi-task learning method with joint task order optimization. MONET
uses a differentiable order selection based on soft order modelling inside
Birkhoff's polytope to jointly learn task-wise recurrent modules with their
optimal chaining order. Furthermore, we introduce warm up and order dropout to
enhance order selection by encouraging order exploration. Experimentally, we
first validate MONET capacity to retrieve the optimal order in a toy
environment. Second, we use an attribute detection scenario to show that MONET
outperforms existing multi-task baselines on a wide range of dependency
settings. Finally, we demonstrate that MONET significantly extends
state-of-the-art performance in Facial Action Unit detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sim2Real Object-Centric Keypoint Detection and Description. (arXiv:2202.00448v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00448">
<div class="article-summary-box-inner">
<span><p>Keypoint detection and description play a central role in computer vision.
Most existing methods are in the form of scene-level prediction, without
returning the object classes of different keypoints. In this paper, we propose
the object-centric formulation, which, beyond the conventional setting,
requires further identifying which object each interest point belongs to. With
such fine-grained information, our framework enables more downstream
potentials, such as object-level matching and pose estimation in a clustered
environment. To get around the difficulty of label collection in the real
world, we develop a sim2real contrastive learning mechanism that can generalize
the model trained in simulation to real-world applications. The novelties of
our training method are three-fold: (i) we integrate the uncertainty into the
learning framework to improve feature description of hard cases, e.g.,
less-textured or symmetric patches; (ii) we decouple the object descriptor into
two output branches -- intra-object salience and inter-object distinctness,
resulting in a better pixel-wise description; (iii) we enforce cross-view
semantic consistency for enhanced robustness in representation learning.
Comprehensive experiments on image matching and 6D pose estimation verify the
encouraging generalization ability of our method from simulation to reality.
Particularly for 6D pose estimation, our method significantly outperforms
typical unsupervised/sim2real methods, achieving a closer gap with the fully
supervised counterpart.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Feature Attribution: An Information-Theoretic Perspective. (arXiv:2202.00449v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00449">
<div class="article-summary-box-inner">
<span><p>With a variety of local feature attribution methods being proposed in recent
years, follow-up work suggested several evaluation strategies. To assess the
attribution quality across different attribution techniques, the most popular
among these evaluation strategies in the image domain use pixel perturbations.
However, recent advances discovered that different evaluation strategies
produce conflicting rankings of attribution methods and can be prohibitively
expensive to compute. In this work, we present an information-theoretic
analysis of evaluation strategies based on pixel perturbations. Our findings
reveal that the results output by different evaluation strategies are strongly
affected by information leakage through the shape of the removed pixels as
opposed to their actual values. Using our theoretical insights, we propose a
novel evaluation framework termed Remove and Debias (ROAD) which offers two
contributions: First, it mitigates the impact of the confounders, which entails
higher consistency among evaluation strategies. Second, ROAD does not require
the computationally expensive retraining step and saves up to 99% in
computational costs compared to the state-of-the-art. Our source code is
available at https://github.com/tleemann/road_evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HCSC: Hierarchical Contrastive Selective Coding. (arXiv:2202.00455v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00455">
<div class="article-summary-box-inner">
<span><p>Hierarchical semantic structures naturally exist in an image dataset, in
which several semantically relevant image clusters can be further integrated
into a larger cluster with coarser-grained semantics. Capturing such structures
with image representations can greatly benefit the semantic understanding on
various downstream tasks. Existing contrastive representation learning methods
lack such an important model capability. In addition, the negative pairs used
in these methods are not guaranteed to be semantically distinct, which could
further hamper the structural correctness of learned image representations. To
tackle these limitations, we propose a novel contrastive learning framework
called Hierarchical Contrastive Selective Coding (HCSC). In this framework, a
set of hierarchical prototypes are constructed and also dynamically updated to
represent the hierarchical semantic structures underlying the data in the
latent space. To make image representations better fit such semantic
structures, we employ and further improve conventional instance-wise and
prototypical contrastive learning via an elaborate pair selection scheme. This
scheme seeks to select more diverse positive pairs with similar semantics and
more precise negative pairs with truly distinct semantics. On extensive
downstream tasks, we verify the superior performance of HCSC over
state-of-the-art contrastive methods, and the effectiveness of major model
components is proved by plentiful analytical studies. Our source code and model
weights are available at https://github.com/gyfastas/HCSC
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A generalizable approach based on U-Net model for automatic Intra retinal cyst segmentation in SD-OCT images. (arXiv:2202.00465v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00465">
<div class="article-summary-box-inner">
<span><p>Intra retinal fluids or Cysts are one of the important symptoms of macular
pathologies that are efficiently visualized in OCT images. Automatic
segmentation of these abnormalities has been widely investigated in medical
image processing studies. In this paper, we propose a new U-Net-based approach
for Intra retinal cyst segmentation across different vendors that improves some
of the challenges faced by previous deep-based techniques. The proposed method
has two main steps: 1- prior information embedding and input data adjustment,
and 2- IRC segmentation model. In the first step, we inject the information
into the network in a way that overcomes some of the network limitations in
receiving data and learning important contextual knowledge. And in the next
step, we introduced a connection module between encoder and decoder parts of
the standard U-Net architecture that transfers information more effectively
from the encoder to the decoder part. Two public datasets namely OPTIMA and
KERMANY were employed to evaluate the proposed method. Results showed that the
proposed method is an efficient vendor-independent approach for IRC
segmentation with mean Dice values of 0.78 and 0.81 on the OPTIMA and KERMANY
datasets, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The impact of removing head movements on audio-visual speech enhancement. (arXiv:2202.00538v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00538">
<div class="article-summary-box-inner">
<span><p>This paper investigates the impact of head movements on audio-visual speech
enhancement (AVSE). Although being a common conversational feature, head
movements have been ignored by past and recent studies: they challenge today's
learning-based methods as they often degrade the performance of models that are
trained on clean, frontal, and steady face images. To alleviate this problem,
we propose to use robust face frontalization (RFF) in combination with an AVSE
method based on a variational auto-encoder (VAE) model. We briefly describe the
basic ingredients of the proposed pipeline and we perform experiments with a
recently released audio-visual dataset. In the light of these experiments, and
based on three standard metrics, namely STOI, PESQ and SI-SDR, we conclude that
RFF improves the performance of AVSE by a considerable margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Development of a neural network to recognize standards and features from 3D CAD models. (arXiv:2202.00573v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00573">
<div class="article-summary-box-inner">
<span><p>Focus of this work is to recognize standards and further features directly
from 3D CAD models. For this reason, a neural network was trained to recognize
nine classes of machine elements. After the system identified a part as a
standard, like a hexagon head screw after the DIN EN ISO 8676, it accesses the
geometrical information of the CAD system via the Application Programming
Interface (API). In the API, the system searches for necessary information to
describe the part appropriately. Based on this information standardized parts
can be recognized in detail and supplemented with further information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fishing for User Data in Large-Batch Federated Learning via Gradient Magnification. (arXiv:2202.00580v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00580">
<div class="article-summary-box-inner">
<span><p>Federated learning (FL) has rapidly risen in popularity due to its promise of
privacy and efficiency. Previous works have exposed privacy vulnerabilities in
the FL pipeline by recovering user data from gradient updates. However,
existing attacks fail to address realistic settings because they either 1)
require a `toy' settings with very small batch sizes, or 2) require unrealistic
and conspicuous architecture modifications. We introduce a new strategy that
dramatically elevates existing attacks to operate on batches of arbitrarily
large size, and without architectural modifications. Our model-agnostic
strategy only requires modifications to the model parameters sent to the user,
which is a realistic threat model in many scenarios. We demonstrate the
strategy in challenging large-scale settings, obtaining high-fidelity data
extraction in both cross-device and cross-silo federated learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Datamodels: Predicting Predictions from Training Data. (arXiv:2202.00622v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00622">
<div class="article-summary-box-inner">
<span><p>We present a conceptual framework, datamodeling, for analyzing the behavior
of a model class in terms of the training data. For any fixed "target" example
$x$, training set $S$, and learning algorithm, a datamodel is a parameterized
function $2^S \to \mathbb{R}$ that for any subset of $S' \subset S$ -- using
only information about which examples of $S$ are contained in $S'$ -- predicts
the outcome of training a model on $S'$ and evaluating on $x$. Despite the
potential complexity of the underlying process being approximated (e.g.,
end-to-end training and evaluation of deep neural networks), we show that even
simple linear datamodels can successfully predict model outputs. We then
demonstrate that datamodels give rise to a variety of applications, such as:
accurately predicting the effect of dataset counterfactuals; identifying
brittle predictions; finding semantically similar examples; quantifying
train-test leakage; and embedding data into a well-behaved and feature-rich
representation space. Data for this paper (including pre-computed datamodels as
well as raw predictions from four million trained deep neural networks) is
available at https://github.com/MadryLab/datamodels-data .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing the Amount of Real World Data for Object Detector Training with Synthetic Data. (arXiv:2202.00632v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00632">
<div class="article-summary-box-inner">
<span><p>A number of studies have investigated the training of neural networks with
synthetic data for applications in the real world. The aim of this study is to
quantify how much real world data can be saved when using a mixed dataset of
synthetic and real world data. By modeling the relationship between the number
of training examples and detection performance by a simple power law, we find
that the need for real world data can be reduced by up to 70% without
sacrificing detection performance. The training of object detection networks is
especially enhanced by enriching the mixed dataset with classes
underrepresented in the real world dataset. The results indicate that mixed
datasets with real world data ratios between 5% and 20% reduce the need for
real world data the most without reducing the detection performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-based Medical e-Diagnosis for Fast and Automatic Ventricular Volume Measurement in the Patients with Normal Pressure Hydrocephalus. (arXiv:2202.00650v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00650">
<div class="article-summary-box-inner">
<span><p>Based on CT and MRI images acquired from normal pressure hydrocephalus (NPH)
patients, using machine learning methods, we aim to establish a multi-modal and
high-performance automatic ventricle segmentation method to achieve efficient
and accurate automatic measurement of the ventricular volume. First, we extract
the brain CT and MRI images of 143 definite NPH patients. Second, we manually
label the ventricular volume (VV) and intracranial volume (ICV). Then, we use
machine learning method to extract features and establish automatic ventricle
segmentation model. Finally, we verify the reliability of the model and
achieved automatic measurement of VV and ICV. In CT images, the Dice similarity
coefficient (DSC), Intraclass Correlation Coefficient (ICC), Pearson
correlation, and Bland-Altman analysis of the automatic and manual segmentation
result of the VV were 0.95, 0.99, 0.99, and 4.2$\pm$2.6 respectively. The
results of ICV were 0.96, 0.99, 0.99, and 6.0$\pm$3.8 respectively. The whole
process takes 3.4$\pm$0.3 seconds. In MRI images, the DSC, ICC, Pearson
correlation, and Bland-Altman analysis of the automatic and manual segmentation
result of the VV were 0.94, 0.99, 0.99, and 2.0$\pm$0.6 respectively. The
results of ICV were 0.93, 0.99, 0.99, and 7.9$\pm$3.8 respectively. The whole
process took 1.9$\pm$0.1 seconds. We have established a multi-modal and
high-performance automatic ventricle segmentation method to achieve efficient
and accurate automatic measurement of the ventricular volume of NPH patients.
This can help clinicians quickly and accurately understand the situation of NPH
patient's ventricles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stay Positive: Non-Negative Image Synthesis for Augmented Reality. (arXiv:2202.00659v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00659">
<div class="article-summary-box-inner">
<span><p>In applications such as optical see-through and projector augmented reality,
producing images amounts to solving non-negative image generation, where one
can only add light to an existing image. Most image generation methods,
however, are ill-suited to this problem setting, as they make the assumption
that one can assign arbitrary color to each pixel. In fact, naive application
of existing methods fails even in simple domains such as MNIST digits, since
one cannot create darker pixels by adding light. We know, however, that the
human visual system can be fooled by optical illusions involving certain
spatial configurations of brightness and contrast. Our key insight is that one
can leverage this behavior to produce high quality images with negligible
artifacts. For example, we can create the illusion of darker patches by
brightening surrounding pixels. We propose a novel optimization procedure to
produce images that satisfy both semantic and non-negativity constraints. Our
approach can incorporate existing state-of-the-art methods, and exhibits strong
performance in a variety of tasks including image-to-image translation and
style transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactron: Embodied Adaptive Object Detection. (arXiv:2202.00660v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00660">
<div class="article-summary-box-inner">
<span><p>Over the years various methods have been proposed for the problem of object
detection. Recently, we have witnessed great strides in this domain owing to
the emergence of powerful deep neural networks. However, there are typically
two main assumptions common among these approaches. First, the model is trained
on a fixed training set and is evaluated on a pre-recorded test set. Second,
the model is kept frozen after the training phase, so no further updates are
performed after the training is finished. These two assumptions limit the
applicability of these methods to real-world settings. In this paper, we
propose Interactron, a method for adaptive object detection in an interactive
setting, where the goal is to perform object detection in images observed by an
embodied agent navigating in different environments. Our idea is to continue
training during inference and adapt the model at test time without any explicit
supervision via interacting with the environment. Our adaptive object detection
model provides a 11.8 point improvement in AP (and 19.1 points in AP50) over
DETR, a recent, high-performance object detector. Moreover, we show that our
object detection model adapts to environments with completely different
appearance characteristics, and its performance is on par with a model trained
with full supervision for those environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Kernelized Dense Geometric Matching. (arXiv:2202.00667v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00667">
<div class="article-summary-box-inner">
<span><p>Dense geometric matching is a challenging computer vision task, requiring
accurate correspondences under extreme variations in viewpoint and
illumination, even for low-texture regions. In this task, finding accurate
global correspondences is essential for later refinement stages. The current
learning based paradigm is to perform global fixed-size correlation, followed
by flattening and convolution to predict correspondences. In this work, we
consider the problem from a different perspective and propose to formulate
global correspondence estimation as a continuous probabilistic regression task
using deep kernels, yielding a novel approach to learning dense
correspondences. Our full approach, \textbf{D}eep \textbf{K}ernelized
\textbf{M}atching, achieves significant improvements compared to the
state-of-the-art on the competitive HPatches and YFCC100m benchmarks, and we
dissect the gains of our contributions in a thorough ablation study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extract an essential skeleton of a character as a graph from a character image. (arXiv:1506.05068v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1506.05068">
<div class="article-summary-box-inner">
<span><p>This paper aims to make a graph representing an essential skeleton of a
character from an image that includes a machine printed or a handwritten
character using growing neural gas (GNG) method and relative network graph
(RNG) algorithm. The visual system in our brain can recognize printed
characters and handwritten characters easily, robustly, and precisely. How does
our brain robustly recognize characters? The visual processing in our brain
uses the essential features of an object, such as crosses and corners. These
features will be helpful for character recognition by a computer. However,
extraction of the features is difficult. If the skeleton of a character is
represented as a graph, we can more easily extract the features. To extract the
skeleton of a character as a graph from an image, this paper proposes the new
approach using GNG and RNG algorithm. I achieved to extract skeleton graphs
from images including distorted, noisy, and handwritten characters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iterative Augmentation of Visual Evidence for Weakly-Supervised Lesion Localization in Deep Interpretability Frameworks: Application to Color Fundus Images. (arXiv:1910.07373v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.07373">
<div class="article-summary-box-inner">
<span><p>Interpretability of deep learning (DL) systems is gaining attention in
medical imaging to increase experts' trust in the obtained predictions and
facilitate their integration in clinical settings. We propose a deep
visualization method to generate interpretability of DL classification tasks in
medical imaging by means of visual evidence augmentation. The proposed method
iteratively unveils abnormalities based on the prediction of a classifier
trained only with image-level labels. For each image, initial visual evidence
of the prediction is extracted with a given visual attribution technique. This
provides localization of abnormalities that are then removed through selective
inpainting. We iteratively apply this procedure until the system considers the
image as normal. This yields augmented visual evidence, including less
discriminative lesions which were not detected at first but should be
considered for final diagnosis. We apply the method to grading of two retinal
diseases in color fundus images: diabetic retinopathy (DR) and age-related
macular degeneration (AMD). We evaluate the generated visual evidence and the
performance of weakly-supervised localization of different types of DR and AMD
abnormalities, both qualitatively and quantitatively. We show that the
augmented visual evidence of the predictions highlights the biomarkers
considered by experts for diagnosis and improves the final localization
performance. It results in a relative increase of 11.2+/-2.0% per image
regarding sensitivity averaged at 10 false positives/image on average, when
applied to different classification tasks, visual attribution techniques and
network architectures. This makes the proposed method a useful tool for
exhaustive visual support of DL classifiers in medical imaging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Free-Hand Sketch: A Survey. (arXiv:2001.02600v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.02600">
<div class="article-summary-box-inner">
<span><p>Free-hand sketches are highly illustrative, and have been widely used by
humans to depict objects or stories from ancient times to the present. The
recent prevalence of touchscreen devices has made sketch creation a much easier
task than ever and consequently made sketch-oriented applications increasingly
popular. The progress of deep learning has immensely benefited free-hand sketch
research and applications. This paper presents a comprehensive survey of the
deep learning techniques oriented at free-hand sketch data, and the
applications that they enable. The main contents of this survey include: (i) A
discussion of the intrinsic traits and unique challenges of free-hand sketch,
to highlight the essential differences between sketch data and other data
modalities, e.g., natural photos. (ii) A review of the developments of
free-hand sketch research in the deep learning era, by surveying existing
datasets, research topics, and the state-of-the-art methods through a detailed
taxonomy and experimental evaluation. (iii) Promotion of future work via a
discussion of bottlenecks, open problems, and potential research directions for
the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ulixes: Facial Recognition Privacy with Adversarial Machine Learning. (arXiv:2010.10242v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10242">
<div class="article-summary-box-inner">
<span><p>Facial recognition tools are becoming exceptionally accurate in identifying
people from images. However, this comes at the cost of privacy for users of
online services with photo management (e.g. social media platforms).
Particularly troubling is the ability to leverage unsupervised learning to
recognize faces even when the user has not labeled their images. In this paper
we propose Ulixes, a strategy to generate visually non-invasive facial noise
masks that yield adversarial examples, preventing the formation of identifiable
user clusters in the embedding space of facial encoders. This is applicable
even when a user is unmasked and labeled images are available online. We
demonstrate the effectiveness of Ulixes by showing that various classification
and clustering methods cannot reliably label the adversarial examples we
generate. We also study the effects of Ulixes in various black-box settings and
compare it to the current state of the art in adversarial machine learning.
Finally, we challenge the effectiveness of Ulixes against adversarially trained
models and show that it is robust to countermeasures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DOC2PPT: Automatic Presentation Slides Generation from Scientific Documents. (arXiv:2101.11796v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11796">
<div class="article-summary-box-inner">
<span><p>Creating presentation materials requires complex multimodal reasoning skills
to summarize key concepts and arrange them in a logical and visually pleasing
manner. Can machines learn to emulate this laborious process? We present a
novel task and approach for document-to-slide generation. Solving this involves
document summarization, image and text retrieval, slide structure and layout
prediction to arrange key elements in a form suitable for presentation. We
propose a hierarchical sequence-to-sequence approach to tackle our task in an
end-to-end manner. Our approach exploits the inherent structures within
documents and slides and incorporates paraphrasing and layout prediction
modules to generate slides. To help accelerate research in this domain, we
release a dataset about 6K paired documents and slide decks used in our
experiments. We show that our approach outperforms strong baselines and
produces slides with rich content and aligned imagery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Exact Hypergraph Matching Algorithm for Nuclear Identification in Embryonic Caenorhabditis elegans. (arXiv:2104.10003v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10003">
<div class="article-summary-box-inner">
<span><p>Finding an optimal correspondence between point sets is a common task in
computer vision. Existing techniques assume relatively simple relationships
among points and do not guarantee an optimal match. We introduce an algorithm
capable of exactly solving point set matching by modeling the task as
hypergraph matching. The algorithm extends the classical branch and bound
paradigm to select and aggregate vertices under a proposed decomposition of the
multilinear objective function. The methodology is motivated by Caenorhabditis
elegans, a model organism used frequently in developmental biology and
neurobiology. The embryonic C. elegans contains seam cells that can act as
fiducial markers allowing the identification of other nuclei during embryo
development. The proposed algorithm identifies seam cells more accurately than
established point-set matching methods, while providing a framework to approach
other similarly complex point set matching tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Transformer for Accurate and Reliable Salient Object Detection. (arXiv:2104.10127v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10127">
<div class="article-summary-box-inner">
<span><p>In this paper, we conduct extensive research on exploring the contribution of
transformers to salient object detection, achieving both accurate and reliable
saliency predictions. We first investigate transformers for accurate salient
object detection with deterministic neural networks, and explain that the
effective structure modeling and global context modeling abilities lead to its
superior performance compared with the CNN based frameworks. Then, we design
stochastic networks to evaluate the transformers' ability in reliable salient
object detection. We observe that both CNN and transformer based frameworks
suffer greatly from the over-confidence issue, where the models tend to
generate wrong predictions with high confidence, leading to over-confident
predictions or a poorly-calibrated model. To estimate the calibration degree of
both CNN- and transformer-based frameworks for reliable saliency prediction, we
introduce generative adversarial network (GAN) based models to identify the
over-confident regions by sampling from the latent space. Specifically, we
present the inferential generative adversarial network (iGAN). Different from
the conventional GAN based framework, which defines the distribution of the
latent variable as fixed standard normal distribution N(0,1), the proposed
"iGAN" infers the latent variable by gradient-based Markov Chain Monte Carlo
(MCMC), namely Langevin dynamics. We apply the proposed inferential generative
adversarial network (iGAN) to both fully and weakly supervised salient object
detection, and explain that iGAN within the transformer framework leads to both
accurate and reliable salient object detection. The source code and
experimental results are publicly available via our project page:
https://github.com/fupiao1998/TrasformerSOD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust 3D Cell Segmentation: Extending the View of Cellpose. (arXiv:2105.00794v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00794">
<div class="article-summary-box-inner">
<span><p>Increasing data set sizes of 3D microscopy imaging experiments demand for an
automation of segmentation processes to be able to extract meaningful
biomedical information. Due to the shortage of annotated 3D image data that can
be used for machine learning-based approaches, 3D segmentation approaches are
required to be robust and to generalize well to unseen data. The Cellpose
approach proposed by Stringer et al. proved to be such a generalist approach
for cell instance segmentation tasks. In this paper, we extend the Cellpose
approach to improve segmentation accuracy on 3D image data and we further show
how the formulation of the gradient maps can be simplified while still being
robust and reaching similar segmentation accuracy. The code is publicly
available and was integrated into two established open-source applications that
allow using the 3D extension of Cellpose without any programming knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual 3D Convolutional Neural Networks for Real-time Processing of Videos. (arXiv:2106.00050v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00050">
<div class="article-summary-box-inner">
<span><p>This paper introduces Continual 3D Convolutional Neural Networks (Co3D CNNs),
a new computational formulation of spatio-temporal 3D CNNs, in which videos are
processed frame-by-frame rather than by clip. In online processing tasks
demanding frame-wise predictions, Co3D CNNs dispense with the computational
redundancies of regular 3D CNNs, namely the repeated convolutions over frames,
which appear in overlapping clips. We show that Continual 3D CNNs can reuse
preexisting 3D-CNN weights to reduce the per-prediction floating point
operations (FLOPs) in proportion to the temporal receptive field while
retaining similar memory requirements and accuracy. This is validated with
multiple models on the Kinetics-400 and Charades datasets with remarkable
results: Continual X3D models attain state-of-the-art complexity/accuracy
trade-offs on Kinetics-400 with 12.1-15.3x reductions of FLOPs and 2.3-3.8%
improvements in accuracy compared to regular X3D models while reducing peak
memory consumption by up to 48%. Moreover, we investigate the transient
response of Co3D CNNs at start-up and perform an extensive benchmark of
on-hardware processing speed and accuracy for publicly available 3D CNNs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topology-Preserved Human Reconstruction with Details. (arXiv:2106.06313v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06313">
<div class="article-summary-box-inner">
<span><p>It is challenging to directly estimate the human geometry from a single image
due to the high diversity and complexity of body shapes with the various
clothing styles. Most of model-based approaches are limited to predict the
shape and pose of a minimally clothed body with over-smoothing surface. While
capturing the fine detailed geometries, the model-free methods are lack of the
fixed mesh topology. To address these issues, we propose a novel
topology-preserved human reconstruction approach by bridging the gap between
model-based and model-free human reconstruction. We present an end-to-end
neural network that simultaneously predicts the pixel-aligned implicit surface
and an explicit mesh model built by graph convolutional neural network.
Experiments on DeepHuman and our collected dataset showed that our approach is
effective. The code will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Robustness via Fisher-Rao Regularization. (arXiv:2106.06685v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06685">
<div class="article-summary-box-inner">
<span><p>Adversarial robustness has become a topic of growing interest in machine
learning since it was observed that neural networks tend to be brittle. We
propose an information-geometric formulation of adversarial defense and
introduce FIRE, a new Fisher-Rao regularization for the categorical
cross-entropy loss, which is based on the geodesic distance between the softmax
outputs corresponding to natural and perturbed input features. Based on the
information-geometric properties of the class of softmax distributions, we
derive an explicit characterization of the Fisher-Rao Distance (FRD) for the
binary and multiclass cases, and draw some interesting properties as well as
connections with standard regularization metrics. Furthermore, for a simple
linear and Gaussian model, we show that all Pareto-optimal points in the
accuracy-robustness region can be reached by FIRE while other state-of-the-art
methods fail. Empirically, we evaluate the performance of various classifiers
trained with the proposed loss on standard datasets, showing up to a
simultaneous 1\% of improvement in terms of clean and robust performances while
reducing the training time by 20\% over the best-performing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-Clustering Point Clouds of Crop Fields Using Scalable Methods. (arXiv:2107.10950v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10950">
<div class="article-summary-box-inner">
<span><p>In order to apply the recent successes of machine learning and automated
plant phenotyping on a large scale using agricultural robotics, efficient and
general algorithms must be designed to intelligently split crop fields into
small, yet actionable, portions that can then be processed by more complex
algorithms. In this paper, we notice a similarity between the current
state-of-the-art for separating corn plants and a commonly used density-based
clustering algorithm, Quickshift. Exploiting this similarity we propose a
number of novel, application-specific algorithms with the goal of producing a
general and scalable field segmentation algorithm. The novel algorithms
proposed in this work are shown to produce quantitatively better results than
the current state-of-the-art while being less sensitive to input parameters and
maintaining the same algorithmic time complexity. When incorporated into
field-scale phenotyping systems, the proposed algorithms should work as a
drop-in replacement that can greatly improve the accuracy of results while
ensuring that performance and scalability remain undiminished.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning the shape of female breasts: an open-access 3D statistical shape model of the female breast built from 110 breast scans. (arXiv:2107.13463v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13463">
<div class="article-summary-box-inner">
<span><p>We present the Regensburg Breast Shape Model (RBSM) -- a 3D statistical shape
model of the female breast built from 110 breast scans acquired in a standing
position, and the first publicly available. Together with the model, a fully
automated, pairwise surface registration pipeline used to establish dense
correspondence among 3D breast scans is introduced. Our method is
computationally efficient and requires only four landmarks to guide the
registration process. A major challenge when modeling female breasts from
surface-only 3D breast scans is the non-separability of breast and thorax. In
order to weaken the strong coupling between breast and surrounding areas, we
propose to minimize the variance outside the breast region as much as possible.
To achieve this goal, a novel concept called breast probability masks (BPMs) is
introduced. A BPM assigns probabilities to each point of a 3D breast scan,
telling how likely it is that a particular point belongs to the breast area.
During registration, we use BPMs to align the template to the target as
accurately as possible inside the breast region and only roughly outside. This
simple yet effective strategy significantly reduces the unwanted variance
outside the breast region, leading to better statistical shape models in which
breast shapes are quite well decoupled from the thorax. The RBSM is thus able
to produce a variety of different breast shapes as independently as possible
from the shape of the thorax. Our systematic experimental evaluation reveals a
generalization ability of 0.17 mm and a specificity of 2.8 mm. To underline the
expressiveness of the proposed model, we finally demonstrate in two showcase
applications how the RBSM can be used for surgical outcome simulation and the
prediction of a missing breast from the remaining one. Our model is available
at https://www.rbsm.re-mic.de/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RealisticHands: A Hybrid Model for 3D Hand Reconstruction. (arXiv:2108.13995v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13995">
<div class="article-summary-box-inner">
<span><p>Estimating 3D hand meshes from RGB images robustly is a highly desirable
task, made challenging due to the numerous degrees of freedom, and issues such
as self similarity and occlusions. Previous methods generally either use
parametric 3D hand models or follow a model-free approach. While the former can
be considered more robust, e.g. to occlusions, they are less expressive. We
propose a hybrid approach, utilizing a deep neural network and differential
rendering based optimization to demonstrably achieve the best of both worlds.
In addition, we explore Virtual Reality (VR) as an application. Most VR
headsets are nowadays equipped with multiple cameras, which we can leverage by
extending our method to the egocentric stereo domain. This extension proves to
be more resilient to the above mentioned issues. Finally, as a use-case, we
show that the improved image-model alignment can be used to acquire the user's
hand texture, which leads to a more realistic virtual hand representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reiterative Domain Aware Multi-Target Adaptation. (arXiv:2109.00919v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00919">
<div class="article-summary-box-inner">
<span><p>Most domain adaptation methods focus on single-source-single-target
adaptation settings. Multi-target domain adaptation is a powerful extension in
which a single classifier is learned for multiple unlabeled target domains. To
build a multi-target classifier, it is important to have: a feature extractor
that generalizes well across domains; and effective aggregation of features
from the labeled source and different unlabeled target domains. Towards the
first, we use the recently popular Transformer as a feature extraction
backbone. Towards the second, we use a co-teaching-based approach using a
dual-classifier head, one of which is based on the graph neural network. The
proposed approach uses a sequential adaptation strategy that adapts one domain
at a time starting from the target domains that are more similar to the source,
assuming that the network finds it easier to adapt to such target domains.
After adapting on each target, samples with a softmax-based confidence score
greater than a threshold are added to the pseudo-source, thus aggregating
knowledge from different domains. However, softmax is not entirely trustworthy
as a confidence score and may generate a high score for unreliable samples if
trained for many iterations. To mitigate this effect, we adopt a reiterative
approach, where we reduce target adaptation iterations, however, reiterate
multiple times over the target domains. The experimental evaluation on the
Office-Home, Office-31 and DomainNet datasets shows significant improvement
over the existing methods. We have achieved 10.7$\%$ average improvement in
Office-Home dataset over the state-of-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuation of Famous Art with AI: A Conditional Adversarial Network Inpainting Approach. (arXiv:2110.09170v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09170">
<div class="article-summary-box-inner">
<span><p>Much of the state-of-the-art in image synthesis inspired by real artwork are
either entirely generative by filtered random noise or inspired by the transfer
of style. This work explores the application of image inpainting to continue
famous artworks and produce generative art with a Conditional GAN. During the
training stage of the process, the borders of images are cropped, leaving only
the centre. An inpainting GAN is then tasked with learning to reconstruct the
original image from the centre crop by way of minimising both adversarial and
absolute difference losses, which are analysed by both their Fr\'echet
Inception Distances and manual observations which are presented. Once the
network is trained, images are then resized rather than cropped and presented
as input to the generator. Following the learning process, the generator then
creates new images by continuing from the edges of the original piece. Three
experiments are performed with datasets of 4766 landscape paintings
(impressionism and romanticism), 1167 Ukiyo-e works from the Japanese Edo
period, and 4968 abstract artworks. Results show that geometry and texture
(including canvas and paint) as well as scenery such as sky, clouds, water,
land (including hills and mountains), grass, and flowers are implemented by the
generator when extending real artworks. In the Ukiyo-e experiments, it was
observed that features such as written text were generated even in cases where
the original image did not have any, due to the presence of an unpainted border
within the input image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Wide Neural Networks Forget Less Catastrophically. (arXiv:2110.11526v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11526">
<div class="article-summary-box-inner">
<span><p>A primary focus area in continual learning research is alleviating the
"catastrophic forgetting" problem in neural networks by designing new
algorithms that are more robust to the distribution shifts. While the recent
progress in continual learning literature is encouraging, our understanding of
what properties of neural networks contribute to catastrophic forgetting is
still limited. To address this, instead of focusing on continual learning
algorithms, in this work, we focus on the model itself and study the impact of
"width" of the neural network architecture on catastrophic forgetting, and show
that width has a surprisingly significant effect on forgetting. To explain this
effect, we study the learning dynamics of the network from various perspectives
such as gradient orthogonality, sparsity, and lazy training regime. We provide
potential explanations that are consistent with the empirical results across
different architectures and continual learning benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Mutual Adaptation of Deep Depth Prediction and Visual SLAM. (arXiv:2111.04096v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.04096">
<div class="article-summary-box-inner">
<span><p>The ability of accurate depth prediction by a convolutional neural network
(CNN) is a major challenge for its wide use in practical visual simultaneous
localization and mapping (SLAM) applications, such as enhanced camera tracking
and dense mapping. This paper is set out to answer the following question: Can
we tune a depth prediction CNN with the help of a visual SLAM algorithm even if
the CNN is not trained for the current operating environment in order to
benefit the SLAM performance? To this end, we propose a novel online adaptation
framework consisting of two complementary processes: a SLAM algorithm that is
used to generate keyframes to fine-tune the depth prediction and another
algorithm that uses the online adapted depth to improve map quality. Once the
potential noisy map points are removed, we perform global photometric bundle
adjustment (BA) to improve the overall SLAM performance. Experimental results
on both benchmark datasets and a real robot in our own experimental
environments show that our proposed method improves the overall SLAM accuracy.
While regularization has been shown to be effective in multi-task
classification problems, we present experimental results and an ablation study
to show the effectiveness of regularization in preventing catastrophic
forgetting in the online adaptation of depth prediction, a single-task
regression problem. In addition, we compare our online adaptation framework
against the state-of-the-art pre-trained depth prediction CNNs to show that our
online adapted depth prediction CNN outperforms the depth prediction CNNs that
have been trained on a large collection of datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLAWS: Contrastive Learning with hard Attention and Weak Supervision. (arXiv:2112.00847v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00847">
<div class="article-summary-box-inner">
<span><p>Learning effective visual representations without human supervision is a
long-standing problem in computer vision. Recent advances in self-supervised
learning algorithms have utilized contrastive learning, with methods such as
SimCLR, which applies a composition of augmentations to an image, and minimizes
a contrastive loss between the two augmented images. In this paper, we present
CLAWS, an annotation-efficient learning framework, addressing the problem of
manually labeling large-scale agricultural datasets along with potential
applications such as anomaly detection and plant growth analytics. CLAWS uses a
network backbone inspired by SimCLR and weak supervision to investigate the
effect of contrastive learning within class clusters. In addition, we inject a
hard attention mask to the cropped input image before maximizing agreement
between the image pairs using a contrastive loss function. This mask forces the
network to focus on pertinent object features and ignore background features.
We compare results between a supervised SimCLR and CLAWS using an agricultural
dataset with 227,060 samples consisting of 11 different crop classes. Our
experiments and extensive evaluations show that CLAWS achieves a competitive
NMI score of 0.7325. Furthermore, CLAWS engenders the creation of low
dimensional representations of very large datasets with minimal parameter
tuning and forming well-defined clusters, which lends themselves to using
efficient, transparent, and highly interpretable clustering methods such as
Gaussian Mixture Models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FastSurferVINN: Building Resolution-Independence into Deep Learning Segmentation Methods -- A Solution for HighRes Brain MRI. (arXiv:2112.09654v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.09654">
<div class="article-summary-box-inner">
<span><p>Leading neuroimaging studies have pushed 3T MRI acquisition resolutions below
1.0 mm for improved structure definition and morphometry. Yet, only few,
time-intensive automated image analysis pipelines have been validated for
high-resolution (HiRes) settings. Efficient deep learning approaches, on the
other hand, rarely support more than one fixed resolution (usually 1.0 mm).
Furthermore, the lack of a standard submillimeter resolution as well as limited
availability of diverse HiRes data with sufficient coverage of scanner, age,
diseases, or genetic variance poses additional, unsolved challenges for
training HiRes networks. Incorporating resolution-independence into deep
learning-based segmentation, i.e., the ability to segment images at their
native resolution across a range of different voxel sizes, promises to overcome
these challenges, yet no such approach currently exists. We now fill this gap
by introducing a Voxelsize Independent Neural Network (VINN) for
resolution-independent segmentation tasks and present FastSurferVINN, which (i)
establishes and implements resolution-independence for deep learning as the
first method simultaneously supporting 0.7-1.0 mm whole brain segmentation,
(ii) significantly outperforms state-of-the-art methods across resolutions, and
(iii) mitigates the data imbalance problem present in HiRes datasets. Overall,
internal resolution-independence mutually benefits both HiRes and 1.0 mm MRI
segmentation. With our rigorously validated FastSurferVINN we distribute a
rapid tool for morphometric neuroimage analysis. The VINN architecture,
furthermore, represents an efficient resolution-independent segmentation method
for wider application
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">iSegFormer: Interactive Image Segmentation with Transformers. (arXiv:2112.11325v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11325">
<div class="article-summary-box-inner">
<span><p>We propose iSegFormer, a novel transformer-based approach for interactive
image segmentation. iSegFormer is built upon existing segmentation transformers
with user clicks as an additional input, allowing users to interactively and
iteratively refine the segmentation mask.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When less is more: Simplifying inputs aids neural network understanding. (arXiv:2201.05610v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05610">
<div class="article-summary-box-inner">
<span><p>How do neural network image classifiers respond to simpler and simpler
inputs? And what do such responses reveal about the learning process? To answer
these questions, we need a clear measure of input simplicity (or inversely,
complexity), an optimization objective that correlates with simplification, and
a framework to incorporate such objective into training and inference. Lastly
we need a variety of testbeds to experiment and evaluate the impact of such
simplification on learning. In this work, we measure simplicity with the
encoding bit size given by a pretrained generative model, and minimize the bit
size to simplify inputs in training and inference. We investigate the effect of
such simplification in several scenarios: conventional training, dataset
condensation and post-hoc explanations. In all settings, inputs are simplified
along with the original classification task, and we investigate the trade-off
between input simplicity and task performance. For images with injected
distractors, such simplification naturally removes superfluous information. For
dataset condensation, we find that inputs can be simplified with almost no
accuracy degradation. When used in post-hoc explanation, our learning-based
simplification approach offers a valuable new tool to explore the basis of
network decisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The KFIoU Loss for Rotated Object Detection. (arXiv:2201.12558v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12558">
<div class="article-summary-box-inner">
<span><p>Differing from the well-developed horizontal object detection area whereby
the computing-friendly IoU based loss is readily adopted and well fits with the
detection metrics. In contrast, rotation detectors often involve a more
complicated loss based on SkewIoU which is unfriendly to gradient-based
training. In this paper, we argue that one effective alternative is to devise
an approximate loss who can achieve trend-level alignment with SkewIoU loss
instead of the strict value-level identity. Specifically, we model the objects
as Gaussian distribution and adopt Kalman filter to inherently mimic the
mechanism of SkewIoU by its definition, and show its alignment with the SkewIoU
at trend-level. This is in contrast to recent Gaussian modeling based rotation
detectors e.g. GWD, KLD that involves a human-specified distribution distance
metric which requires additional hyperparameter tuning. The resulting new loss
called KFIoU is easier to implement and works better compared with exact
SkewIoU, thanks to its full differentiability and ability to handle the
non-overlapping cases. We further extend our technique to the 3-D case which
also suffers from the same issues as 2-D detection. Extensive results on
various public datasets (2-D/3-D, aerial/text/face images) with different base
detectors show the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self Semi Supervised Neural Architecture Search for Semantic Segmentation. (arXiv:2201.12646v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12646">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a Neural Architecture Search strategy based on self
supervision and semi-supervised learning for the task of semantic segmentation.
Our approach builds an optimized neural network (NN) model for this task by
jointly solving a jigsaw pretext task discovered with self-supervised learning
over unlabeled training data, and, exploiting the structure of the unlabeled
data with semi-supervised learning. The search of the architecture of the NN
model is performed by dynamic routing using a gradient descent algorithm.
Experiments on the Cityscapes and PASCAL VOC 2012 datasets demonstrate that the
discovered neural network is more efficient than a state-of-the-art
hand-crafted NN model with four times less floating operations.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-02-02 23:06:30.211698881 UTC">2022-02-02 23:06:30 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>