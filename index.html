<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-01-24T01:30:00Z">01-24</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Regional Negative Bias in Word Embeddings Predicts Racial Animus--but only via Name Frequency. (arXiv:2201.08451v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08451">
<div class="article-summary-box-inner">
<span><p>The word embedding association test (WEAT) is an important method for
measuring linguistic biases against social groups such as ethnic minorities in
large text corpora. It does so by comparing the semantic relatedness of words
prototypical of the groups (e.g., names unique to those groups) and attribute
words (e.g., 'pleasant' and 'unpleasant' words). We show that anti-black WEAT
estimates from geo-tagged social media data at the level of metropolitan
statistical areas strongly correlate with several measures of racial
animus--even when controlling for sociodemographic covariates. However, we also
show that every one of these correlations is explained by a third variable: the
frequency of Black names in the underlying corpora relative to White names.
This occurs because word embeddings tend to group positive (negative) words and
frequent (rare) words together in the estimated semantic space. As the
frequency of Black names on social media is strongly correlated with Black
Americans' prevalence in the population, this results in spurious anti-Black
WEAT estimates wherever few Black Americans live. This suggests that research
using the WEAT to measure bias should consider term frequency, and also
demonstrates the potential consequences of using black-box models like word
embeddings to study human cognition and behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SciBERTSUM: Extractive Summarization for Scientific Documents. (arXiv:2201.08495v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08495">
<div class="article-summary-box-inner">
<span><p>The summarization literature focuses on the summarization of news articles.
The news articles in the CNN-DailyMail are relatively short documents with
about 30 sentences per document on average. We introduce SciBERTSUM, our
summarization framework designed for the summarization of long documents like
scientific papers with more than 500 sentences. SciBERTSUM extends BERTSUM to
long documents by 1) adding a section embedding layer to include section
information in the sentence vector and 2) applying a sparse attention mechanism
where each sentences will attend locally to nearby sentences and only a small
number of sentences attend globally to all other sentences. We used slides
generated by the authors of scientific papers as reference summaries since they
contain the technical details from the paper. The results show the superiority
of our model in terms of ROUGE scores.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement Learning. (arXiv:2201.08520v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08520">
<div class="article-summary-box-inner">
<span><p>We present a two-step hybrid reinforcement learning (RL) policy that is
designed to generate interpretable and robust hierarchical policies on the RL
problem with graph-based input. Unlike prior deep reinforcement learning
policies parameterized by an end-to-end black-box graph neural network, our
approach disentangles the decision-making process into two steps. The first
step is a simplified classification problem that maps the graph input to an
action group where all actions share a similar semantic meaning. The second
step implements a sophisticated rule-miner that conducts explicit one-hop
reasoning over the graph and identifies decisive edges in the graph input
without the necessity of heavy domain knowledge. This two-step hybrid policy
presents human-friendly interpretations and achieves better performance in
terms of generalization and robustness. Extensive experimental studies on four
levels of complex text-based games have demonstrated the superiority of the
proposed method compared to the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Black-box Prompt Learning for Pre-trained Language Models. (arXiv:2201.08531v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08531">
<div class="article-summary-box-inner">
<span><p>Domain-specific fine-tuning strategies for large pre-trained models received
vast attention in recent years. In previously studied settings, the model
architectures and parameters are tunable or at least visible, which we refer to
as white-box settings. This work considers a new scenario, where we do not have
access to a pre-trained model, except for its outputs given inputs, and we call
this problem black-box fine-tuning. To illustrate our approach, we first
introduce the black-box setting formally on text classification, where the
pre-trained model is not only frozen but also invisible. We then propose our
solution black-box prompt, a new technique in the prompt-learning family, which
can leverage the knowledge learned by pre-trained models from the pre-training
corpus. Our experiments demonstrate that the proposed method achieved the
state-of-the-art performance on eight datasets. Further analyses on different
human-designed objectives, prompt lengths, and intuitive explanations
demonstrate the robustness and flexibility of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Model Compression Improve NLP Fairness. (arXiv:2201.08542v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08542">
<div class="article-summary-box-inner">
<span><p>Model compression techniques are receiving increasing attention; however, the
effect of compression on model fairness is still under explored. This is the
first paper to examine the effect of distillation and pruning on the toxicity
and bias of generative language models. We test Knowledge Distillation and
Pruning methods on the GPT2 model and found a consistent pattern of toxicity
and bias reduction after model distillation; this result can be potentially
interpreted by existing line of research which describes model compression as a
regularization technique; our work not only serves as a reference for safe
deployment of compressed models, but also extends the discussion of
"compression as regularization" into the setting of neural LMs, and hints at
the possibility of using compression to develop fairer models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying Adversarial Attacks on Text Classifiers. (arXiv:2201.08555v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08555">
<div class="article-summary-box-inner">
<span><p>The landscape of adversarial attacks against text classifiers continues to
grow, with new attacks developed every year and many of them available in
standard toolkits, such as TextAttack and OpenAttack. In response, there is a
growing body of work on robust learning, which reduces vulnerability to these
attacks, though sometimes at a high cost in compute time or accuracy. In this
paper, we take an alternate approach -- we attempt to understand the attacker
by analyzing adversarial text to determine which methods were used to create
it. Our first contribution is an extensive dataset for attack detection and
labeling: 1.5~million attack instances, generated by twelve adversarial attacks
targeting three classifiers trained on six source datasets for sentiment
analysis and abuse detection in English. As our second contribution, we use
this dataset to develop and benchmark a number of classifiers for attack
identification -- determining if a given text has been adversarially
manipulated and by which attack. As a third contribution, we demonstrate the
effectiveness of three classes of features for these tasks: text properties,
capturing content and presentation of text; language model properties,
determining which tokens are more or less probable throughout the input; and
target model properties, representing how the text classifier is influenced by
the attack, including internal node activations. Overall, this represents a
first step towards forensics for adversarial attacks against text classifiers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Taxonomy Enrichment with Text and Graph Vector Representations. (arXiv:2201.08598v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08598">
<div class="article-summary-box-inner">
<span><p>Knowledge graphs such as DBpedia, Freebase or Wikidata always contain a
taxonomic backbone that allows the arrangement and structuring of various
concepts in accordance with the hypo-hypernym ("class-subclass") relationship.
With the rapid growth of lexical resources for specific domains, the problem of
automatic extension of the existing knowledge bases with new words is becoming
more and more widespread. In this paper, we address the problem of taxonomy
enrichment which aims at adding new words to the existing taxonomy.
</p>
<p>We present a new method that allows achieving high results on this task with
little effort. It uses the resources which exist for the majority of languages,
making the method universal. We extend our method by incorporating deep
representations of graph structures like node2vec, Poincar\'e embeddings, GCN
etc. that have recently demonstrated promising results on various NLP tasks.
Furthermore, combining these representations with word embeddings allows us to
beat the state of the art.
</p>
<p>We conduct a comprehensive study of the existing approaches to taxonomy
enrichment based on word and graph vector representations and their fusion
approaches. We also explore the ways of using deep learning architectures to
extend the taxonomic backbones of knowledge graphs. We create a number of
datasets for taxonomy extension for English and Russian. We achieve
state-of-the-art results across different datasets and provide an in-depth
error analysis of mistakes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Style Transfer for Bias Mitigation using Masked Language Modeling. (arXiv:2201.08643v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08643">
<div class="article-summary-box-inner">
<span><p>It is well known that textual data on the internet and other digital
platforms contain significant levels of bias and stereotypes. Although many
such texts contain stereotypes and biases that inherently exist in natural
language for reasons that are not necessarily malicious, there are crucial
reasons to mitigate these biases. For one, these texts are being used as
training corpus to train language models for salient applications like
cv-screening, search engines, and chatbots; such applications are turning out
to produce discriminatory results. Also, several research findings have
concluded that biased texts have significant effects on the target demographic
groups. For instance, masculine-worded job advertisements tend to be less
appealing to female applicants.
</p>
<p>In this paper, we present a text style transfer model that can be used to
automatically debias textual data. Our style transfer model improves on the
limitations of many existing style transfer techniques such as loss of content
information. Our model solves such issues by combining latent content encoding
with explicit keyword replacement. We will show that this technique produces
better content preservation whilst maintaining good style transfer accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context-Tuning: Learning Contextualized Prompts for Natural Language Generation. (arXiv:2201.08670v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08670">
<div class="article-summary-box-inner">
<span><p>Recently, pretrained language models (PLMs) have made exceptional success in
language generation. To leverage the rich knowledge encoded by PLMs, a simple
yet powerful mechanism is to use prompts, in the form of either discrete tokens
or continuous embeddings. In existing studies, manual prompts are
time-consuming and require domain expertise, while continuous prompts are
typically independent of the inputs. To address this issue, we propose a novel
continuous prompting approach, called Context-Tuning, to fine-tuning PLMs for
natural language generation. Firstly, the prompts are derived based on the
input text, so that they can elicit useful knowledge from PLMs for generation.
We refer to such prompts as contextualized prompts. Secondly, to further
enhance the relevance of the generated text to the inputs, we utilize
continuous inverse prompting to refine the process of natural language
generation by modeling an inverse generation process from output to input.
Moreover, we propose a lightweight contexttuning, fine-tuning only 0.4% of
parameters while retaining well performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gender Bias in Text: Labeled Datasets and Lexicons. (arXiv:2201.08675v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08675">
<div class="article-summary-box-inner">
<span><p>Language has a profound impact on our thoughts, perceptions, and conceptions
of gender roles. Gender-inclusive language is, therefore, a key tool to promote
social inclusion and contribute to achieving gender equality. Consequently,
detecting and mitigating gender bias in texts is instrumental in halting its
propagation and societal implications. However, there is a lack of gender bias
datasets and lexicons for automating the detection of gender bias using
supervised and unsupervised machine learning (ML) and natural language
processing (NLP) techniques. Therefore, the main contribution of this work is
to publicly provide labeled datasets and exhaustive lexicons by collecting,
annotating, and augmenting relevant sentences to facilitate the detection of
gender bias in English text. Towards this end, we present an updated version of
our previously proposed taxonomy by re-formalizing its structure, adding a new
bias type, and mapping each bias subtype to an appropriate detection
methodology. The released datasets and lexicons span multiple bias subtypes
including: Generic He, Generic She, Explicit Marking of Sex, and Gendered
Neologisms. We leveraged the use of word embedding models to further augment
the collected lexicons. The underlying motivation of our work is to enable the
technical community to combat gender bias in text and halt its propagation
using ML and NLP techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Study on Language Models for Task-Oriented Dialogue Systems. (arXiv:2201.08687v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08687">
<div class="article-summary-box-inner">
<span><p>The recent development of language models has shown promising results by
achieving state-of-the-art performance on various natural language tasks by
fine-tuning pretrained models. In task-oriented dialogue (ToD) systems,
language models can be used for end-to-end training without relying on dialogue
state tracking to track the dialogue history but allowing the language models
to generate responses according to the context given as input. This paper
conducts a comparative study to show the effectiveness and strength of using
recent pretrained models for fine-tuning, such as BART and T5, on endto-end ToD
systems. The experimental results show substantial performance improvements
after language model fine-tuning. The models produce more fluent responses
after adding knowledge to the context that guides the model to avoid
hallucination and generate accurate entities in the generated responses.
Furthermore, we found that BART and T5 outperform GPT-based models in BLEU and
F1 scores and achieve state-of-the-art performance in a ToD system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Contrastive Learning: Text Classification via Label-Aware Data Augmentation. (arXiv:2201.08702v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08702">
<div class="article-summary-box-inner">
<span><p>Contrastive learning has achieved remarkable success in representation
learning via self-supervision in unsupervised settings. However, effectively
adapting contrastive learning to supervised learning tasks remains as a
challenge in practice. In this work, we introduce a dual contrastive learning
(DualCL) framework that simultaneously learns the features of input samples and
the parameters of classifiers in the same space. Specifically, DualCL regards
the parameters of the classifiers as augmented samples associating to different
labels and then exploits the contrastive learning between the input samples and
the augmented samples. Empirical studies on five benchmark text classification
datasets and their low-resource version demonstrate the improvement in
classification accuracy and confirm the capability of learning discriminative
representations of DualCL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personality Type Based on Myers-Briggs Type Indicator with Text Posting Style by using Traditional and Deep Learning. (arXiv:2201.08717v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08717">
<div class="article-summary-box-inner">
<span><p>The term personality may be expressed in terms of the individual differences
in characteristics pattern of thinking, feeling, and behavior. This work
presents several machine learning techniques including Naive Bayes, Support
Vector Machines, and Recurrent Neural Networks to predict people personality
from text based on Myers-Briggs Type Indicator (MBTI). Furthermore, this
project applies CRISP-DM, which stands for Cross-Industry Standard Process for
Data Mining, to guide the learning process. Since, CRISP-DM is kind of
iterative development, we have adopted it with agile methodology, which is a
rapid iterative software development method, in order to reduce the development
cycle to be minimal.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Building Economic Models of Conversational Search. (arXiv:2201.08742v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08742">
<div class="article-summary-box-inner">
<span><p>Various conceptual and descriptive models of conversational search have been
proposed in the literature -- while useful, they do not provide insights into
how interaction between the agent and user would change in response to the
costs and benefits of the different interactions. In this paper, we develop two
economic models of conversational search based on patterns previously observed
during conversational search sessions, which we refer to as: Feedback First
where the agent asks clarifying questions then presents results, and Feedback
After where the agent presents results, and then asks follow up questions. Our
models show that the amount of feedback given/requested depends on its
efficiency at improving the initial or subsequent query and the relative cost
of providing said feedback. This theoretical framework for conversational
search provides a number of insights that can be used to guide and inform the
development of conversational search agents. However, empirical work is needed
to estimate the parameters in order to make predictions specific to a given
conversational search setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conversational Information Seeking. (arXiv:2201.08808v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08808">
<div class="article-summary-box-inner">
<span><p>Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAP-Gen: Guided Automatic Python Code Generation. (arXiv:2201.08810v1 [cs.PL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08810">
<div class="article-summary-box-inner">
<span><p>Automatic code generation from natural language descriptions can be highly
beneficial during the process of software development. In this work, we propose
GAP-Gen, an automatic code generation method guided by Python syntactic
constraints and semantic constraints. We first introduce Python syntactic
constraints in the form of Syntax-Flow, which is a simplified version of
Abstract Syntax Tree (AST) reducing the size and high complexity of Abstract
Syntax Tree but maintaining the crucial syn-tactic information of Python code.
In addition to Syntax-Flow, we introduce Variable-Flow which abstracts variable
and function names consistently throughout the code. In our work, rather than
pre-training, we focus on modifying the fine-tuning process which reduces
computational requirements but retains high generation performance on automatic
Python code generation task. GAP-Gen fine-tunes the transformer-based language
models T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet,
CodeSearchNet AdvTest, and Code-Docstring-Corpus from EdinburghNLP. Our
experiments show that GAP-Gen achieves better results on automatic Python code
generation task than previous works
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Biochemical Space Language in Relation to Multiset Rewriting Systems. (arXiv:2201.08817v1 [cs.LO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08817">
<div class="article-summary-box-inner">
<span><p>This technical report relates Biochemical Space Language (BCSL) to Multiset
rewriting systems (MRS). For a BCSL model, the semantics are defined in terms
of transition systems, while for an MRS, they are defined in terms of a set of
runs. In this report, we relate BCSL to MRS by first showing how the transition
system is related to a set of runs and consequently showing how for every BCSL
model, an MRS can be constructed such that both represent the same set of runs.
The motivation of this step is to establish BCSL in the context of a more
general rewriting system and benefit from properties shown for them. Finally,
we show that regulations defined for MRS can be consequently used in the BCSL
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pairwise Representation Learning for Event Coreference. (arXiv:2010.12808v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12808">
<div class="article-summary-box-inner">
<span><p>Natural Language Processing tasks such as resolving the coreference of events
require understanding the relations between two text snippets. These tasks are
typically formulated as (binary) classification problems over independently
induced representations of the text snippets. In this work, we develop a
Pairwise Representation Learning (PairwiseRL) scheme for the event mention
pairs, in which we jointly encode a pair of text snippets so that the
representation of each mention in the pair is induced in the context of the
other one. Furthermore, our representation supports a finer, structured
representation of the text snippet to facilitate encoding events and their
arguments. We show that PairwiseRL, despite its simplicity, outperforms the
prior state-of-the-art event coreference systems on both cross-document and
within-document event coreference benchmarks. We also conduct in-depth analysis
in terms of the improvement and the limitation of pairwise representation so as
to provide insights for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graph Reasoning with Relational Digraph. (arXiv:2108.06040v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06040">
<div class="article-summary-box-inner">
<span><p>Reasoning on the knowledge graph (KG) aims to infer new facts from existing
ones. Methods based on the relational path have shown strong, interpretable,
and transferable reasoning ability. However, paths are naturally limited in
capturing local evidence in graphs. In this paper, we introduce a novel
relational structure, i.e., relational directed graph (r-digraph), which is
composed of overlapped relational paths, to capture the KG's local evidence.
Since the r- digraphs are more complex than paths, how to efficiently construct
and effectively learn from them are challenging. Directly encoding the
r-digraphs cannot scale well and capturing query-dependent information is hard
in r-digraphs. We propose a variant of graph neural network, i.e., RED-GNN, to
address the above challenges. Specifically, RED-GNN makes use of dynamic
programming to recursively encodes multiple r-digraphs with shared edges, and
utilizes a query-dependent attention mechanism to select the strongly
correlated edges. We demonstrate that RED-GNN is not only efficient but also
can achieve significant performance gains in both inductive and transductive
reasoning tasks over existing methods. Besides, the learned attention weights
in RED-GNN can exhibit interpretable evidence for KG reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Czech News Dataset for Semantic Textual Similarity. (arXiv:2108.08708v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08708">
<div class="article-summary-box-inner">
<span><p>This paper describes a novel dataset consisting of sentences with semantic
similarity annotations. The data originate from the journalistic domain in the
Czech language. We describe the process of collecting and annotating the data
in detail. The dataset contains 138,556 human annotations divided into train
and test sets. In total, 485 journalism students participated in the creation
process. To increase the reliability of the test set, we compute the annotation
as an average of 9 individual annotations. We evaluate the quality of the
dataset by measuring inter and intra annotation annotators' agreements. Beside
agreement numbers, we provide detailed statistics of the collected dataset. We
conclude our paper with a baseline experiment of building a system for
predicting the semantic similarity of sentences. Due to the massive number of
training annotations (116 956), the model can perform significantly better than
an average annotator (0,92 versus 0,86 of Person's correlation coefficients).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capturing Structural Locality in Non-parametric Language Models. (arXiv:2110.02870v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02870">
<div class="article-summary-box-inner">
<span><p>Structural locality is a ubiquitous feature of real-world datasets, wherein
data points are organized into local hierarchies. Some examples include topical
clusters in text or project hierarchies in source code repositories. In this
paper, we explore utilizing this structural locality within non-parametric
language models, which generate sequences that reference retrieved examples
from an external source. We propose a simple yet effective approach for adding
locality information into such models by adding learned parameters that improve
the likelihood of retrieving examples from local neighborhoods. Experiments on
two different domains, Java source code and Wikipedia text, demonstrate that
locality features improve model efficacy over models without access to these
features, with interesting differences. We also perform an analysis of how and
where locality features contribute to improved performance and why the
traditionally used contextual similarity metrics alone are not enough to grasp
the locality structure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GNN-LM: Language Modeling based on Global Contexts via GNN. (arXiv:2110.08743v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08743">
<div class="article-summary-box-inner">
<span><p>Inspired by the notion that {\it to copy is easier than to memorize}, in this
work, we introduce GNN-LM, which extends the vanilla neural language model (LM)
by allowing to reference similar contexts in the entire training corpus. We
build a directed heterogeneous graph between an input context and its
semantically related neighbors selected from the training corpus, where nodes
are tokens in the input context and retrieved neighbor contexts, and edges
represent connections between nodes. Graph neural networks (GNNs) are
constructed upon the graph to aggregate information from similar contexts to
decode the token. This learning paradigm provides direct access to the
reference contexts and helps improve a model's generalization ability. We
conduct comprehensive experiments to validate the effectiveness of the GNN-LM:
GNN-LM achieves a new state-of-the-art perplexity of 14.8 on WikiText-103 (a
4.5 point improvement over its counterpart of the vanilla LM model) and shows
substantial improvement on One Billion Word and Enwiki8 datasets against strong
baselines. In-depth ablation studies are performed to understand the mechanics
of GNN-LM. The code can be found at \url{https://github.com/ShannonAI/GNN-LM}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">English-to-Chinese Transliteration with Phonetic Back-transliteration. (arXiv:2112.10321v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10321">
<div class="article-summary-box-inner">
<span><p>Transliteration is a task of translating named entities from a language to
another, based on phonetic similarity. The task has embraced deep learning
approaches in recent years, yet, most ignore the phonetic features of the
involved languages. In this work, we incorporate phonetic information into
neural networks in two ways: we synthesize extra data using forward and
back-translation but in a phonetic manner; and we pre-train models on a
phonetic task before learning transliteration. Our experiments include three
language pairs and six directions, namely English to and from Chinese, Hebrew
and Thai. Results indicate that our proposed approach brings benefits to the
model and achieves better or similar performance when compared to state of the
art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Language Models: Methods, Analysis & Insights from Training Gopher. (arXiv:2112.11446v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11446">
<div class="article-summary-box-inner">
<span><p>Language modelling provides a step towards intelligent communication systems
by harnessing large repositories of written human knowledge to better predict
and understand the world. In this paper, we present an analysis of
Transformer-based language model performance across a wide range of model
scales -- from models with tens of millions of parameters up to a 280 billion
parameter model called Gopher. These models are evaluated on 152 diverse tasks,
achieving state-of-the-art performance across the majority. Gains from scale
are largest in areas such as reading comprehension, fact-checking, and the
identification of toxic language, but logical and mathematical reasoning see
less benefit. We provide a holistic analysis of the training dataset and
model's behaviour, covering the intersection of model scale with bias and
toxicity. Finally we discuss the application of language models to AI safety
and the mitigation of downstream harms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning grammar with a divide-and-concur neural network. (arXiv:2201.07341v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.07341">
<div class="article-summary-box-inner">
<span><p>We implement a divide-and-concur iterative projection approach to
context-free grammar inference. Unlike most state-of-the-art models of natural
language processing, our method requires a relatively small number of discrete
parameters, making the inferred grammar directly interpretable -- one can read
off from a solution how to construct grammatically valid sentences. Another
advantage of our approach is the ability to infer meaningful grammatical rules
from just a few sentences, compared to the hundreds of gigabytes of training
data many other models employ. We demonstrate several ways of applying our
approach: classifying words and inferring a grammar from scratch, taking an
existing grammar and refining its categories and rules, and taking an existing
grammar and expanding its lexicon as it encounters new words in new data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VISA: An Ambiguous Subtitles Dataset for Visual Scene-Aware Machine Translation. (arXiv:2201.08054v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08054">
<div class="article-summary-box-inner">
<span><p>Existing multimodal machine translation (MMT) datasets consist of images and
video captions or general subtitles, which rarely contain linguistic ambiguity,
making visual information not so effective to generate appropriate
translations. We introduce VISA, a new dataset that consists of 40k
Japanese-English parallel sentence pairs and corresponding video clips with the
following key features: (1) the parallel sentences are subtitles from movies
and TV episodes; (2) the source subtitles are ambiguous, which means they have
multiple possible translations with different meanings; (3) we divide the
dataset into Polysemy and Omission according to the cause of ambiguity. We show
that VISA is challenging for the latest MMT system, and we hope that the
dataset can facilitate MMT research.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Specificity in Mammography Using Cross-correlation between Wavelet and Fourier Transform. (arXiv:2201.08385v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08385">
<div class="article-summary-box-inner">
<span><p>Breast cancer is in the most common malignant tumor in women. It accounted
for 30% of new malignant tumor cases. Although the incidence of breast cancer
remains high around the world, the mortality rate has been continuously
reduced. This is mainly due to recent developments in molecular biology
technology and improved level of comprehensive diagnosis and standard
treatment. Early detection by mammography is an integral part of that. The most
common breast abnormalities that may indicate breast cancer are masses and
calcifications. Previous detection approaches usually obtain relatively high
sensitivity but unsatisfactory specificity. We will investigate an approach
that applies the discrete wavelet transform and Fourier transform to parse the
images and extracts statistical features that characterize an image's content,
such as the mean intensity and the skewness of the intensity. A naive Bayesian
classifier uses these features to classify the images. We expect to achieve an
optimal high specificity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Steerable Pyramid Transform Enables Robust Left Ventricle Quantification. (arXiv:2201.08388v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08388">
<div class="article-summary-box-inner">
<span><p>Although multifarious variants of convolutional neural networks (CNNs) have
proved successful in cardiac index quantification, they seem vulnerable to mild
input perturbations, e.g., spatial transformations, image distortions, and
adversarial attacks. Such brittleness erodes our trust in CNN-based automated
diagnosis of various cardiovascular diseases. In this work, we describe a
simple and effective method to learn robust CNNs for left ventricle (LV)
quantification, including cavity and myocardium areas, directional dimensions,
and regional wall thicknesses. The key to the success of our approach is the
use of the biologically-inspired steerable pyramid transform (SPT) as fixed
front-end processing, which brings three computational advantages to LV
quantification. First, the basis functions of SPT match the anatomical
structure of the LV as well as the geometric characteristics of the estimated
indices. Second, SPT enables sharing a CNN across different orientations as a
form of parameter regularization, and explicitly captures the scale variations
of the LV in a natural way. Third, the residual highpass subband can be
conveniently discarded to further encourage robust feature learning. A concise
and effective metric, named Robustness Ratio, is proposed to evaluate the
robustness under various input perturbations. Extensive experiments on 145
cardiac sequences show that our SPT-augmented method performs favorably against
state-of-the-art algorithms in terms of prediction accuracy, but is
significantly more robust under input perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SoftDropConnect (SDC) -- Effective and Efficient Quantification of the Network Uncertainty in Deep MR Image Analysis. (arXiv:2201.08418v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08418">
<div class="article-summary-box-inner">
<span><p>Recently, deep learning has achieved remarkable successes in medical image
analysis. Although deep neural networks generate clinically important
predictions, they have inherent uncertainty. Such uncertainty is a major
barrier to report these predictions with confidence. In this paper, we propose
a novel yet simple Bayesian inference approach called SoftDropConnect (SDC) to
quantify the network uncertainty in medical imaging tasks with gliomas
segmentation and metastases classification as initial examples. Our key idea is
that during training and testing SDC modulates network parameters continuously
so as to allow affected information processing channels still in operation,
instead of disabling them as Dropout or DropConnet does. When compared with
three popular Bayesian inference methods including Bayes By Backprop, Dropout,
and DropConnect, our SDC method (SDC-W after optimization) outperforms the
three competing methods with a substantial margin. Quantitatively, our proposed
method generates results withsubstantially improved prediction accuracy (by
10.0%, 5.4% and 3.7% respectively for segmentation in terms of dice score; by
11.7%, 3.9%, 8.7% on classification in terms of test accuracy) and greatly
reduced uncertainty in terms of mutual information (by 64%, 33% and 70% on
segmentation; 98%, 88%, and 88% on classification). Our approach promises to
deliver better diagnostic performance and make medical AI imaging more
explainable and trustworthy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FaceOcc: A Diverse, High-quality Face Occlusion Dataset for Human Face Extraction. (arXiv:2201.08425v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08425">
<div class="article-summary-box-inner">
<span><p>Occlusions often occur in face images in the wild, troubling face-related
tasks such as landmark detection, 3D reconstruction, and face recognition. It
is beneficial to extract face regions from unconstrained face images
accurately. However, current face segmentation datasets suffer from small data
volumes, few occlusion types, low resolution, and imprecise annotation,
limiting the performance of data-driven-based algorithms. This paper proposes a
novel face occlusion dataset with manually labeled face occlusions from the
CelebA-HQ and the internet. The occlusion types cover sunglasses, spectacles,
hands, masks, scarfs, microphones, etc. To the best of our knowledge, it is by
far the largest and most comprehensive face occlusion dataset. Combining it
with the attribute mask in CelebAMask-HQ, we trained a straightforward face
segmentation model but obtained SOTA performance, convincingly demonstrating
the effectiveness of the proposed dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Visual Analytics Approach to Building Logistic Regression Models and its Application to Health Records. (arXiv:2201.08429v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08429">
<div class="article-summary-box-inner">
<span><p>Multidimensional data analysis has become increasingly important in many
fields, mainly due to current vast data availability and the increasing demand
to extract knowledge from it. In most applications, the role of the final user
is crucial to build proper machine learning models and to explain the patterns
found in data. In this paper, we present an open unified approach for
generating, evaluating, and applying regression models in high-dimensional data
sets within a user-guided process. The approach is based on exposing a broad
correlation panorama for attributes, by which the user can select relevant
attributes to build and evaluate prediction models for one or more contexts. We
name the approach UCReg (User-Centered Regression). We demonstrate
effectiveness and efficiency of UCReg through the application of our framework
to the analysis of Covid-19 and other synthetic and real health records data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Investigation of Model-to-Model Distribution Shifts in Trained Convolutional Filters. (arXiv:2201.08465v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08465">
<div class="article-summary-box-inner">
<span><p>We present first empirical results from our ongoing investigation of
distribution shifts in image data used for various computer vision tasks.
Instead of analyzing the original training and test data, we propose to study
shifts in the learned weights of trained models. In this work, we focus on the
properties of the distributions of dominantly used 3x3 convolution filter
kernels. We collected and publicly provide a data set with over half a billion
filters from hundreds of trained CNNs, using a wide range of data sets,
architectures, and vision tasks. Our analysis shows interesting distribution
shifts (or the lack thereof) between trained filters along different axes of
meta-parameters, like data type, task, architecture, or layer depth. We argue,
that the observed properties are a valuable source for further investigation
into a better understanding of the impact of shifts in the input data to the
generalization abilities of CNN models and novel methods for more robust
transfer-learning in this domain. Data available at:
https://github.com/paulgavrikov/CNN-Filter-DB/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vertical Federated Edge Learning with Distributed Integrated Sensing and Communication. (arXiv:2201.08512v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08512">
<div class="article-summary-box-inner">
<span><p>This letter studies a vertical federated edge learning (FEEL) system for
collaborative objects/human motion recognition by exploiting the distributed
integrated sensing and communication (ISAC). In this system, distributed edge
devices first send wireless signals to sense targeted objects/human, and then
exchange intermediate computed vectors (instead of raw sensing data) for
collaborative recognition while preserving data privacy. To boost the spectrum
and hardware utilization efficiency for FEEL, we exploit ISAC for both target
sensing and data exchange, by employing dedicated frequency-modulated
continuous-wave (FMCW) signals at each edge device. Under this setup, we
propose a vertical FEEL framework for realizing the recognition based on the
collected multi-view wireless sensing data. In this framework, each edge device
owns an individual local L-model to transform its sensing data into an
intermediate vector with relatively low dimensions, which is then transmitted
to a coordinating edge device for final output via a common downstream S-model.
By considering a human motion recognition task, experimental results show that
our vertical FEEL based approach achieves recognition accuracy up to 98\% with
an improvement up to 8\% compared to the benchmarks, including on-device
training and horizontal FEEL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Can Machine Vision Do for Lymphatic Histopathology Image Analysis: A Comprehensive Review. (arXiv:2201.08550v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08550">
<div class="article-summary-box-inner">
<span><p>In the past ten years, the computing power of machine vision (MV) has been
continuously improved, and image analysis algorithms have developed rapidly. At
the same time, histopathological slices can be stored as digital images.
Therefore, MV algorithms can provide doctors with diagnostic references. In
particular, the continuous improvement of deep learning algorithms has further
improved the accuracy of MV in disease detection and diagnosis. This paper
reviews the applications of image processing technology based on MV in lymphoma
histopathological images in recent years, including segmentation,
classification and detection. Finally, the current methods are analyzed, some
more potential methods are proposed, and further prospects are made.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classroom Slide Narration System. (arXiv:2201.08574v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08574">
<div class="article-summary-box-inner">
<span><p>Slide presentations are an effective and efficient tool used by the teaching
community for classroom communication. However, this teaching model can be
challenging for blind and visually impaired (VI) students. The VI student
required personal human assistance for understand the presented slide. This
shortcoming motivates us to design a Classroom Slide Narration System (CSNS)
that generates audio descriptions corresponding to the slide content. This
problem poses as an image-to-markup language generation task. The initial step
is to extract logical regions such as title, text, equation, figure, and table
from the slide image. In the classroom slide images, the logical regions are
distributed based on the location of the image. To utilize the location of the
logical regions for slide image segmentation, we propose the architecture,
Classroom Slide Segmentation Network (CSSN). The unique attributes of this
architecture differs from most other semantic segmentation networks. Publicly
available benchmark datasets such as WiSe and SPaSe are used to validate the
performance of our segmentation architecture. We obtained 9.54 segmentation
accuracy improvement in WiSe dataset. We extract content (information) from the
slide using four well-established modules such as optical character recognition
(OCR), figure classification, equation description, and table structure
recognizer. With this information, we build a Classroom Slide Narration System
(CSNS) to help VI students understand the slide content. The users have given
better feedback on the quality output of the proposed CSNS in comparison to
existing systems like Facebooks Automatic Alt-Text (AAT) and Tesseract.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SegTransVAE: Hybrid CNN -- Transformer with Regularization for medical image segmentation. (arXiv:2201.08582v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08582">
<div class="article-summary-box-inner">
<span><p>Current research on deep learning for medical image segmentation exposes
their limitations in learning either global semantic information or local
contextual information. To tackle these issues, a novel network named
SegTransVAE is proposed in this paper. SegTransVAE is built upon
encoder-decoder architecture, exploiting transformer with the variational
autoencoder (VAE) branch to the network to reconstruct the input images jointly
with segmentation. To the best of our knowledge, this is the first method
combining the success of CNN, transformer, and VAE. Evaluation on various
recently introduced datasets shows that SegTransVAE outperforms previous
methods in Dice Score and $95\%$-Haudorff Distance while having comparable
inference time to a simple CNN-based architecture network. The source code is
available at: https://github.com/itruonghai/SegTransVAE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pseudo-Labeled Auto-Curriculum Learning for Semi-Supervised Keypoint Localization. (arXiv:2201.08613v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08613">
<div class="article-summary-box-inner">
<span><p>Localizing keypoints of an object is a basic visual problem. However,
supervised learning of a keypoint localization network often requires a large
amount of data, which is expensive and time-consuming to obtain. To remedy
this, there is an ever-growing interest in semi-supervised learning (SSL),
which leverages a small set of labeled data along with a large set of unlabeled
data. Among these SSL approaches, pseudo-labeling (PL) is one of the most
popular. PL approaches apply pseudo-labels to unlabeled data, and then train
the model with a combination of the labeled and pseudo-labeled data
iteratively. The key to the success of PL is the selection of high-quality
pseudo-labeled samples. Previous works mostly select training samples by
manually setting a single confidence threshold. We propose to automatically
select reliable pseudo-labeled samples with a series of dynamic thresholds,
which constitutes a learning curriculum. Extensive experiments on six keypoint
localization benchmark datasets demonstrate that the proposed approach
significantly outperforms the previous state-of-the-art SSL approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object Detectors in the Physical World. (arXiv:2201.08619v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08619">
<div class="article-summary-box-inner">
<span><p>Deep learning models have been shown to be vulnerable to recent backdoor
attacks. A backdoored model behaves normally for inputs containing no
attacker-secretly-chosen trigger and maliciously for inputs with the trigger.
To date, backdoor attacks and countermeasures mainly focus on image
classification tasks. And most of them are implemented in the digital world
with digital triggers. Besides the classification tasks, object detection
systems are also considered as one of the basic foundations of computer vision
tasks. However, there is no investigation and understanding of the backdoor
vulnerability of the object detector, even in the digital world with digital
triggers. For the first time, this work demonstrates that existing object
detectors are inherently susceptible to physical backdoor attacks. We use a
natural T-shirt bought from a market as a trigger to enable the cloaking
effect--the person bounding-box disappears in front of the object detector. We
show that such a backdoor can be implanted from two exploitable attack
scenarios into the object detector, which is outsourced or fine-tuned through a
pretrained model. We have extensively evaluated three popular object detection
algorithms: anchor-based Yolo-V3, Yolo-V4, and anchor-free CenterNet. Building
upon 19 videos shot in real-world scenes, we confirm that the backdoor attack
is robust against various factors: movement, distance, angle, non-rigid
deformation, and lighting. Specifically, the attack success rate (ASR) in most
videos is 100% or close to it, while the clean data accuracy of the backdoored
model is the same as its clean counterpart. The latter implies that it is
infeasible to detect the backdoor behavior merely through a validation set. The
averaged ASR still remains sufficiently high to be 78% in the transfer learning
attack scenarios evaluated on CenterNet. See the demo video on
https://youtu.be/Q3HOF4OobbY.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VIPriors 2: Visual Inductive Priors for Data-Efficient Deep Learning Challenges. (arXiv:2201.08625v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08625">
<div class="article-summary-box-inner">
<span><p>The second edition of the "VIPriors: Visual Inductive Priors for
Data-Efficient Deep Learning" challenges featured five data-impaired
challenges, where models are trained from scratch on a reduced number of
training samples for various key computer vision tasks. To encourage new and
creative ideas on incorporating relevant inductive biases to improve the data
efficiency of deep learning models, we prohibited the use of pre-trained
checkpoints and other transfer learning techniques. The provided baselines are
outperformed by a large margin in all five challenges, mainly thanks to
extensive data augmentation policies, model ensembling, and data efficient
network architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-view Monocular Depth and Uncertainty Prediction with Deep SfM in Dynamic Environments. (arXiv:2201.08633v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08633">
<div class="article-summary-box-inner">
<span><p>3D reconstruction of depth and motion from monocular video in dynamic
environments is a highly ill-posed problem due to scale ambiguities when
projecting to the 2D image domain. In this work, we investigate the performance
of the current State-of-the-Art (SotA) deep multi-view systems in such
environments. We find that current supervised methods work surprisingly well
despite not modelling individual object motions, but make systematic errors due
to a lack of dense ground truth data. To detect such errors during usage, we
extend the cost volume based Deep Video to Depth (DeepV2D) framework
\cite{teed2018deepv2d} with a learned uncertainty. Our Deep Video to certain
Depth (DeepV2cD) model allows i) to perform en par or better with current SotA
and ii) achieve a better uncertainty measure than the naive Shannon entropy.
Our experiments show that a simple filter strategy based on the uncertainty can
significantly reduce systematic errors. This results in cleaner reconstructions
both on static and dynamic parts of the scene.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conceptor Learning for Class Activation Mapping. (arXiv:2201.08636v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08636">
<div class="article-summary-box-inner">
<span><p>Class Activation Mapping (CAM) has been widely adopted to generate saliency
maps which provides visual explanations for deep neural networks (DNNs). The
saliency maps are conventionally generated by fusing the channels of the target
feature map using a weighted average scheme. It is a weak model for the
inter-channel relation, in the sense that it only models the relation among
channels in a contrastive way (i.e., channels that play key roles in the
prediction are given higher weights for them to stand out in the fusion). The
collaborative relation, which makes the channels work together to provide cross
reference, has been ignored. Furthermore, the model has neglected the
intra-channel relation thoroughly.In this paper, we address this problem by
introducing Conceptor learning into CAM generation. Conceptor leaning has been
originally proposed to model the patterns of state changes in recurrent neural
networks (RNNs). By relaxing the dependency of Conceptor learning to RNNs, we
make Conceptor-CAM not only generalizable to more DNN architectures but also
able to learn both the inter- and intra-channel relations for better saliency
map generation. Moreover, we have enabled the use of Boolean operations to
combine the positive and pseudo-negative evidences, which has made the CAM
inference more robust and comprehensive. The effectiveness of Conceptor-CAM has
been validated with both formal verifications and experiments on the dataset of
the largest scale in literature. The experimental results show that
Conceptor-CAM is compatible with and can bring significant improvement to all
well recognized CAM-based methods, and has outperformed the state-of-the-art
methods by 43.14%~72.79% (88.39%~168.15%) on ILSVRC2012 in Average Increase
(Drop), 15.42%~42.55% (47.09%~372.09%) on VOC, and 17.43%~31.32%
(47.54%~206.45%) on COCO, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Pseudo Label Quality for Semi-SupervisedDomain-Generalized Medical Image Segmentation. (arXiv:2201.08657v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08657">
<div class="article-summary-box-inner">
<span><p>Generalizing the medical image segmentation algorithms tounseen domains is an
important research topic for computer-aided diagnosis and surgery. Most
existing methods requirea fully labeled dataset in each source domain. Although
(Liuet al. 2021b) developed a semi-supervised domain general-ized method, it
still requires the domain labels. This paperpresents a novel confidence-aware
cross pseudo supervisionalgorithm for semi-supervised domain generalized
medicalimage segmentation. The main goal is to enhance the pseudolabel quality
for unlabeled images from unknown distribu-tions. To achieve it, we perform the
Fourier transformationto learn low-level statistic information across domains
andaugment the images to incorporate cross-domain information.With these
augmentations as perturbations, we feed the inputto a confidence-aware cross
pseudo supervision network tomeasure the variance of pseudo labels and
regularize the net-work to learn with more confident pseudo labels. Our
methodsets new records on public datasets,i.e., M&amp;Ms and SCGM.Notably, without
using domain labels, our method surpassesthe prior art that even uses domain
labels by 11.67% on Diceon M&amp;Ms dataset with 2% labeled data. Code will be
avail-able after the conference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Differentiable Matrix Square Root. (arXiv:2201.08663v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08663">
<div class="article-summary-box-inner">
<span><p>Computing the matrix square root or its inverse in a differentiable manner is
important in a variety of computer vision tasks. Previous methods either adopt
the Singular Value Decomposition (SVD) to explicitly factorize the matrix or
use the Newton-Schulz iteration (NS iteration) to derive the approximate
solution. However, both methods are not computationally efficient enough in
either the forward pass or in the backward pass. In this paper, we propose two
more efficient variants to compute the differentiable matrix square root. For
the forward propagation, one method is to use Matrix Taylor Polynomial (MTP),
and the other method is to use Matrix Pad\'e Approximants (MPA). The backward
gradient is computed by iteratively solving the continuous-time Lyapunov
equation using the matrix sign function. Both methods yield considerable
speed-up compared with the SVD or the Newton-Schulz iteration. Experimental
results on the de-correlated batch normalization and second-order vision
transformer demonstrate that our methods can also achieve competitive and even
slightly better performances. The code is available at
\href{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Deep Convolutional Candlestick Learner. (arXiv:2201.08669v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08669">
<div class="article-summary-box-inner">
<span><p>Candlestick pattern is one of the most fundamental and valuable graphical
tools in financial trading that supports traders observing the current market
conditions to make the proper decision. This task has a long history and, most
of the time, human experts. Recently, efforts have been made to automatically
classify these patterns with the deep learning models. The GAF-CNN model is a
well-suited way to imitate how human traders capture the candlestick pattern by
integrating spatial features visually. However, with the great potential of the
GAF encoding, this classification task can be extended to a more complicated
object detection level. This work presents an innovative integration of modern
object detection techniques and GAF time-series encoding on candlestick pattern
tasks. We make crucial modifications to the representative yet straightforward
YOLO version 1 model based on our time-series encoding method and the property
of such data type. Powered by the deep neural networks and the unique
architectural design, the proposed model performs pretty well in candlestick
classification and location recognition. The results show tremendous potential
in applying modern object detection techniques on time-series tasks in a
real-time manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Fusion Strategies for Accurate RGBT Visual Object Tracking. (arXiv:2201.08673v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08673">
<div class="article-summary-box-inner">
<span><p>We address the problem of multi-modal object tracking in video and explore
various options of fusing the complementary information conveyed by the visible
(RGB) and thermal infrared (TIR) modalities including pixel-level,
feature-level and decision-level fusion. Specifically, different from the
existing methods, paradigm of image fusion task is heeded for fusion at pixel
level. Feature-level fusion is fulfilled by attention mechanism with channels
excited optionally. Besides, at decision level, a novel fusion strategy is put
forward since an effortless averaging configuration has shown the superiority.
The effectiveness of the proposed decision-level fusion strategy owes to a
number of innovative contributions, including a dynamic weighting of the RGB
and TIR contributions and a linear template update operation. A variant of
which produced the winning tracker at the Visual Object Tracking Challenge 2020
(VOT-RGBT2020). The concurrent exploration of innovative pixel- and
feature-level fusion strategies highlights the advantages of the proposed
decision-level fusion method. Extensive experimental results on three
challenging datasets, \textit{i.e.}, GTOT, VOT-RGBT2019, and VOT-RGBT2020,
demonstrate the effectiveness and robustness of the proposed method, compared
to the state-of-the-art approaches. Code will be shared at
\textcolor{blue}{\emph{https://github.com/Zhangyong-Tang/DFAT}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distance-Ratio-Based Formulation for Metric Learning. (arXiv:2201.08676v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08676">
<div class="article-summary-box-inner">
<span><p>In metric learning, the goal is to learn an embedding so that data points
with the same class are close to each other and data points with different
classes are far apart. We propose a distance-ratio-based (DR) formulation for
metric learning. Like softmax-based formulation for metric learning, it models
$p(y=c|x')$, which is a probability that a query point $x'$ belongs to a class
$c$. The DR formulation has two useful properties. First, the corresponding
loss is not affected by scale changes of an embedding. Second, it outputs the
optimal (maximum or minimum) classification confidence scores on representing
points for classes. To demonstrate the effectiveness of our formulation, we
conduct few-shot classification experiments using softmax-based and DR
formulations on CUB and mini-ImageNet datasets. The results show that DR
formulation generally enables faster and more stable metric learning than the
softmax-based formulation. As a result, using DR formulation achieves improved
or comparable generalization performances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Study of Vision Transformers on Dense Prediction Tasks. (arXiv:2201.08683v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08683">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks (CNNs), architectures consisting of
convolutional layers, have been the standard choice in vision tasks. Recent
studies have shown that Vision Transformers (VTs), architectures based on
self-attention modules, achieve comparable performance in challenging tasks
such as object detection and semantic segmentation. However, the image
processing mechanism of VTs is different from that of conventional CNNs. This
poses several questions about their generalizability, robustness, reliability,
and texture bias when used to extract features for complex tasks. To address
these questions, we study and compare VT and CNN architectures as feature
extractors in object detection and semantic segmentation. Our extensive
empirical results show that the features generated by VTs are more robust to
distribution shifts, natural corruptions, and adversarial attacks in both
tasks, whereas CNNs perform better at higher image resolutions in object
detection. Furthermore, our results demonstrate that VTs in dense prediction
tasks produce more reliable and less texture-biased predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SparseAlign: A Super-Resolution Algorithm for Automatic Marker Localization and Deformation Estimation in Cryo-Electron Tomography. (arXiv:2201.08706v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08706">
<div class="article-summary-box-inner">
<span><p>Tilt-series alignment is crucial to obtaining high-resolution reconstructions
in cryo-electron tomography. Beam-induced local deformation of the sample is
hard to estimate from the low-contrast sample alone, and often requires
fiducial gold bead markers. The state-of-the-art approach for deformation
estimation uses (semi-)manually labelled marker locations in projection data to
fit the parameters of a polynomial deformation model. Manually-labelled marker
locations are difficult to obtain when data are noisy or markers overlap in
projection data. We propose an alternative mathematical approach for
simultaneous marker localization and deformation estimation by extending a
grid-free super-resolution algorithm first proposed in the context of
single-molecule localization microscopy. Our approach does not require labelled
marker locations; instead, we use an image-based loss where we compare the
forward projection of markers with the observed data. We equip this marker
localization scheme with an additional deformation estimation component and
solve for a reduced number of deformation parameters. Using extensive numerical
studies on marker-only samples, we show that our approach automatically finds
markers and reliably estimates sample deformation without labelled marker data.
We further demonstrate the applicability of our approach for a broad range of
model mismatch scenarios, including experimental electron tomography data of
gold markers on ice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Across-Dataset Brain Tissue Segmentation Using Transformer. (arXiv:2201.08741v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08741">
<div class="article-summary-box-inner">
<span><p>Brain tissue segmentation has demonstrated great utility in quantifying MRI
data through Voxel-Based Morphometry and highlighting subtle structural changes
associated with various conditions within the brain. However, manual
segmentation is highly labor-intensive, and automated approaches have struggled
due to properties inherent to MRI acquisition, leaving a great need for an
effective segmentation tool. Despite the recent success of deep convolutional
neural networks (CNNs) for brain tissue segmentation, many such solutions do
not generalize well to new datasets, which is critical for a reliable solution.
Transformers have demonstrated success in natural image segmentation and have
recently been applied to 3D medical image segmentation tasks due to their
ability to capture long-distance relationships in the input where the local
receptive fields of CNNs struggle. This study introduces a novel
CNN-Transformer hybrid architecture designed for brain tissue segmentation. We
validate our model's performance across four multi-site T1w MRI datasets,
covering different vendors, field strengths, scan parameters, time points, and
neuropsychiatric conditions. In all situations, our model achieved the greatest
generality and reliability. Out method is inherently robust and can serve as a
valuable tool for brain-related T1w MRI studies. The code for the TABS network
is available at: https://github.com/raovish6/TABS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ERS: a novel comprehensive endoscopy image dataset for machine learning, compliant with the MST 3.0 specification. (arXiv:2201.08746v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08746">
<div class="article-summary-box-inner">
<span><p>The article presents a new multi-label comprehensive image dataset from
flexible endoscopy, colonoscopy and capsule endoscopy, named ERS. The
collection has been labeled according to the full medical specification of
'Minimum Standard Terminology 3.0' (MST 3.0), describing all possible findings
in the gastrointestinal tract (104 possible labels), extended with an
additional 19 labels useful in common machine learning applications.
</p>
<p>The dataset contains around 6000 precisely and 115,000 approximately labeled
frames from endoscopy videos, 3600 precise and 22,600 approximate segmentation
masks, and 1.23 million unlabeled frames from flexible and capsule endoscopy
videos. The labeled data cover almost entirely the MST 3.0 standard. The data
came from 1520 videos of 1135 patients.
</p>
<p>Additionally, this paper proposes and describes four exemplary experiments in
gastrointestinal image classification task performed using the created dataset.
The obtained results indicate the high usefulness and flexibility of the
dataset in training and testing machine learning algorithms in the field of
endoscopic data analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object Detection in Aerial Images: What Improves the Accuracy?. (arXiv:2201.08763v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08763">
<div class="article-summary-box-inner">
<span><p>Object detection is a challenging and popular computer vision problem. The
problem is even more challenging in aerial images due to significant variation
in scale and viewpoint in a diverse set of object categories. Recently, deep
learning-based object detection approaches have been actively explored for the
problem of object detection in aerial images. In this work, we investigate the
impact of Faster R-CNN for aerial object detection and explore numerous
strategies to improve its performance for aerial images. We conduct extensive
experiments on the challenging iSAID dataset. The resulting adapted Faster
R-CNN obtains a significant mAP gain of 4.96% over its vanilla baseline
counterpart on the iSAID validation set, demonstrating the impact of different
strategies investigated in this work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive and Selective Hidden Embeddings for Medical Image Segmentation. (arXiv:2201.08779v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08779">
<div class="article-summary-box-inner">
<span><p>Medical image segmentation has been widely recognized as a pivot procedure
for clinical diagnosis, analysis, and treatment planning. However, the
laborious and expensive annotation process lags down the speed of further
advances. Contrastive learning-based weight pre-training provides an
alternative by leveraging unlabeled data to learn a good representation. In
this paper, we investigate how contrastive learning benefits the general
supervised medical segmentation tasks. To this end, patch-dragsaw contrastive
regularization (PDCR) is proposed to perform patch-level tugging and repulsing
with the extent controlled by a continuous affinity score. And a new structure
dubbed uncertainty-aware feature selection block (UAFS) is designed to perform
the feature selection process, which can handle the learning target shift
caused by minority features with high uncertainty. By plugging the proposed 2
modules into the existing segmentation architecture, we achieve
state-of-the-art results across 8 public datasets from 6 domains. Newly
designed modules further decrease the amount of training data to a quarter
while achieving comparable, if not better, performances. From this perspective,
we take the opposite direction of the original self/un-supervised contrastive
learning by further excavating information contained within the label.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AiTLAS: Artificial Intelligence Toolbox for Earth Observation. (arXiv:2201.08789v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08789">
<div class="article-summary-box-inner">
<span><p>The AiTLAS toolbox (Artificial Intelligence Toolbox for Earth Observation)
includes state-of-the-art machine learning methods for exploratory and
predictive analysis of satellite imagery as well as repository of AI-ready
Earth Observation (EO) datasets. It can be easily applied for a variety of
Earth Observation tasks, such as land use and cover classification, crop type
prediction, localization of specific objects (semantic segmentation), etc. The
main goal of AiTLAS is to facilitate better usability and adoption of novel AI
methods (and models) by EO experts, while offering easy access and standardized
format of EO datasets to AI experts which further allows benchmarking of
various existing and novel AI methods tailored for EO data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Realtime 3D Object Detection for Headsets. (arXiv:2201.08812v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08812">
<div class="article-summary-box-inner">
<span><p>Mobile headsets should be capable of understanding 3D physical environments
to offer a truly immersive experience for augmented/mixed reality (AR/MR).
However, their small form-factor and limited computation resources make it
extremely challenging to execute in real-time 3D vision algorithms, which are
known to be more compute-intensive than their 2D counterparts. In this paper,
we propose DeepMix, a mobility-aware, lightweight, and hybrid3D object
detection framework for improving the user experience of AR/MR on mobile
headsets. Motivated by our analysis and evaluation of state-of-the-art 3D
object detection models, DeepMix intelligently combines edge-assisted 2D object
detection and novel, on-device 3D bounding box estimations that leverage depth
data captured by headsets. This leads to low end-to-end latency and
significantly boosts detection accuracy in mobile scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Predictive Coding Networks: A Neural Solution to the Problem of Learning Reference Frames and Part-Whole Hierarchies. (arXiv:2201.08813v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08813">
<div class="article-summary-box-inner">
<span><p>We introduce Active Predictive Coding Networks (APCNs), a new class of neural
networks that solve a major problem posed by Hinton and others in the fields of
artificial intelligence and brain modeling: how can neural networks learn
intrinsic reference frames for objects and parse visual scenes into part-whole
hierarchies by dynamically allocating nodes in a parse tree? APCNs address this
problem by using a novel combination of ideas: (1) hypernetworks are used for
dynamically generating recurrent neural networks that predict parts and their
locations within intrinsic reference frames conditioned on higher object-level
embedding vectors, and (2) reinforcement learning is used in conjunction with
backpropagation for end-to-end learning of model parameters. The APCN
architecture lends itself naturally to multi-level hierarchical learning and is
closely related to predictive coding models of cortical function. Using the
MNIST, Fashion-MNIST and Omniglot datasets, we demonstrate that APCNs can (a)
learn to parse images into part-whole hierarchies, (b) learn compositional
representations, and (c) transfer their knowledge to unseen classes of objects.
With their ability to dynamically generate parse trees with part locations for
objects, APCNs offer a new framework for explainable AI that leverages advances
in deep learning while retaining interpretability and compositionality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from One and Only One Shot. (arXiv:2201.08815v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08815">
<div class="article-summary-box-inner">
<span><p>Humans can generalize from only a few examples and from little pre-training
on similar tasks. Yet, machine learning (ML) typically requires large data to
learn or pre-learn to transfer. Inspired by nativism, we directly model basic
human-innate priors in abstract visual tasks e.g., character/doodle
recognition. This yields a white-box model that learns general-appearance
similarity -- how any two images look in general -- by mimicking how humans
naturally "distort" an object at first sight. Using simply the nearest-neighbor
classifier on this similarity space, we achieve human-level character
recognition using only 1--10 examples per class and nothing else (no
pre-training). This differs from few-shot learning (FSL) using significant
pre-training. On standard benchmarks MNIST/EMNIST and the Omniglot challenge,
we outperform both neural-network-based and classical ML in the "tiny-data"
regime, including FSL pre-trained on large data. Our model enables unsupervised
learning too: by learning the non-Euclidean, general-appearance similarity
space in a k-means style, we can generate human-intuitive archetypes as cluster
``centroids''.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skyline variations allow estimating distance to trees on landscape photos using semantic segmentation. (arXiv:2201.08816v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08816">
<div class="article-summary-box-inner">
<span><p>Approximate distance estimation can be used to determine fundamental
landscape properties including complexity and openness. We show that variations
in the skyline of landscape photos can be used to estimate distances to trees
on the horizon. A methodology based on the variations of the skyline has been
developed and used to investigate potential relationships with the distance to
skyline objects. The skyline signal, defined by the skyline height expressed in
pixels, was extracted for several Land Use/Cover Area frame Survey (LUCAS)
landscape photos. Photos were semantically segmented with DeepLabV3+ trained
with the Common Objects in Context (COCO) dataset. This provided pixel-level
classification of the objects forming the skyline. A Conditional Random Fields
(CRF) algorithm was also applied to increase the details of the skyline signal.
Three metrics, able to capture the skyline signal variations, were then
considered for the analysis. These metrics shows a functional relationship with
distance for the class of trees, whose contours have a fractal nature. In
particular, regression analysis was performed against 475 ortho-photo based
distance measurements, and, in the best case, a R2 score equal to 0.47 was
achieved. This is an encouraging result which shows the potential of skyline
variation metrics for inferring distance related information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reliable Detection of Doppelg\"angers based on Deep Face Representations. (arXiv:2201.08831v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08831">
<div class="article-summary-box-inner">
<span><p>Doppelg\"angers (or lookalikes) usually yield an increased probability of
false matches in a facial recognition system, as opposed to random face image
pairs selected for non-mated comparison trials. In this work, we assess the
impact of doppelg\"angers on the HDA Doppelg\"anger and Disguised Faces in The
Wild databases using a state-of-the-art face recognition system. It is found
that doppelg\"anger image pairs yield very high similarity scores resulting in
a significant increase of false match rates. Further, we propose a
doppelg\"anger detection method which distinguishes doppelg\"angers from mated
comparison trials by analysing differences in deep representations obtained
from face image pairs. The proposed detection system employs a machine
learning-based classifier, which is trained with generated doppelg\"anger image
pairs utilising face morphing techniques. Experimental evaluations conducted on
the HDA Doppelg\"anger and Look-Alike Face databases reveal a detection equal
error rate of approximately 2.7% for the task of separating mated
authentication attempts from doppelg\"angers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point-NeRF: Point-based Neural Radiance Fields. (arXiv:2201.08845v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08845">
<div class="article-summary-box-inner">
<span><p>Volumetric neural rendering methods like NeRF generate high-quality view
synthesis results but are optimized per-scene leading to prohibitive
reconstruction time. On the other hand, deep multi-view stereo methods can
quickly reconstruct scene geometry via direct network inference. Point-NeRF
combines the advantages of these two approaches by using neural 3D point
clouds, with associated neural features, to model a radiance field. Point-NeRF
can be rendered efficiently by aggregating neural point features near scene
surfaces, in a ray marching-based rendering pipeline. Moreover, Point-NeRF can
be initialized via direct inference of a pre-trained deep network to produce a
neural point cloud; this point cloud can be finetuned to surpass the visual
quality of NeRF with 30X faster training time. Point-NeRF can be combined with
other 3D reconstruction methods and handles the errors and outliers in such
methods via a novel pruning and growing mechanism.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Globally Optimal 2D-to-3D Deformable Shape Matching. (arXiv:1601.06070v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1601.06070">
<div class="article-summary-box-inner">
<span><p>We propose the first algorithm for non-rigid 2D-to-3D shape matching, where
the input is a 2D shape represented as a planar curve and a 3D shape
represented as a surface; the output is a continuous curve on the surface. We
cast the problem as finding the shortest circular path on the product
3-manifold of the surface and the curve. We prove that the optimal matching can
be computed in polynomial time with a (worst-case) complexity of
$O(mn^2\log(n))$, where $m$ and $n$ denote the number of vertices on the
template curve and the 3D shape respectively. We also demonstrate that in
practice the runtime is essentially linear in $m\!\cdot\! n$ making it an
efficient method for shape analysis and shape retrieval. Quantitative
evaluation confirms that the method provides excellent results for sketch-based
deformable 3D shape retrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysis and algorithms for $\ell_p$-based semi-supervised learning on graphs. (arXiv:1901.05031v3 [math.NA] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.05031">
<div class="article-summary-box-inner">
<span><p>This paper addresses theory and applications of $\ell_p$-based Laplacian
regularization in semi-supervised learning. The graph $p$-Laplacian for $p&gt;2$
has been proposed recently as a replacement for the standard ($p=2$) graph
Laplacian in semi-supervised learning problems with very few labels, where
Laplacian learning is degenerate.
</p>
<p>In the first part of the paper we prove new discrete to continuum convergence
results for $p$-Laplace problems on $k$-nearest neighbor ($k$-NN) graphs, which
are more commonly used in practice than random geometric graphs. Our analysis
shows that, on $k$-NN graphs, the $p$-Laplacian retains information about the
data distribution as $p\to \infty$ and Lipschitz learning ($p=\infty$) is
sensitive to the data distribution. This situation can be contrasted with
random geometric graphs, where the $p$-Laplacian forgets the data distribution
as $p\to \infty$. We also present a general framework for proving discrete to
continuum convergence results in graph-based learning that only requires
pointwise consistency and monotonicity.
</p>
<p>In the second part of the paper, we develop fast algorithms for solving the
variational and game-theoretic $p$-Laplace equations on weighted graphs for
$p&gt;2$. We present several efficient and scalable algorithms for both
formulations, and present numerical results on synthetic data indicating their
convergence properties. Finally, we conduct extensive numerical experiments on
the MNIST, FashionMNIST and EMNIST datasets that illustrate the effectiveness
of the $p$-Laplacian formulation for semi-supervised learning with few labels.
In particular, we find that Lipschitz learning ($p=\infty$) performs well with
very few labels on $k$-NN graphs, which experimentally validates our
theoretical findings that Lipschitz learning retains information about the data
distribution (the unlabeled data) on $k$-NN graphs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Pixel to Patch: Synthesize Context-aware Features for Zero-shot Semantic Segmentation. (arXiv:2009.12232v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12232">
<div class="article-summary-box-inner">
<span><p>Zero-shot learning has been actively studied for image classification task to
relieve the burden of annotating image labels. Interestingly, semantic
segmentation task requires more labor-intensive pixel-wise annotation, but
zero-shot semantic segmentation has only attracted limited research interest.
Thus, we focus on zero-shot semantic segmentation, which aims to segment unseen
objects with only category-level semantic representations provided for unseen
categories. In this paper, we propose a novel Context-aware feature Generation
Network (CaGNet), which can synthesize context-aware pixel-wise visual features
for unseen categories based on category-level semantic representations and
pixel-wise contextual information. The synthesized features are used to
finetune the classifier to enable segmenting unseen objects. Furthermore, we
extend pixel-wise feature generation and finetuning to patch-wise feature
generation and finetuning, which additionally considers inter-pixel
relationship. Experimental results on Pascal-VOC, Pascal-Context, and
COCO-stuff show that our method significantly outperforms the existing
zero-shot semantic segmentation methods. Code is available at
https://github.com/bcmi/CaGNetv2-Zero-Shot-Semantic-Segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Learning with Stronger Augmentations. (arXiv:2104.07713v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07713">
<div class="article-summary-box-inner">
<span><p>Representation learning has significantly been developed with the advance of
contrastive learning methods. Most of those methods have benefited from various
data augmentations that are carefully designated to maintain their identities
so that the images transformed from the same instance can still be retrieved.
However, those carefully designed transformations limited us to further explore
the novel patterns exposed by other transformations. Meanwhile, as found in our
experiments, the strong augmentations distorted the images' structures,
resulting in difficult retrieval. Thus, we propose a general framework called
Contrastive Learning with Stronger Augmentations~(CLSA) to complement current
contrastive learning approaches. Here, the distribution divergence between the
weakly and strongly augmented images over the representation bank is adopted to
supervise the retrieval of strongly augmented queries from a pool of instances.
Experiments on the ImageNet dataset and downstream datasets showed the
information from the strongly augmented images can significantly boost the
performance. For example, CLSA achieves top-1 accuracy of 76.2% on ImageNet
with a standard ResNet-50 architecture with a single-layer classifier
fine-tuned, which is almost the same level as 76.5% of supervised results. The
code and pre-trained models are available in
https://github.com/maple-research-lab/CLSA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Aliased Resizing and Surprising Subtleties in GAN Evaluation. (arXiv:2104.11222v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11222">
<div class="article-summary-box-inner">
<span><p>Metrics for evaluating generative models aim to measure the discrepancy
between real and generated images. The often-used Frechet Inception Distance
(FID) metric, for example, extracts "high-level" features using a deep network
from the two sets. However, we find that the differences in "low-level"
preprocessing, specifically image resizing and compression, can induce large
variations and have unforeseen consequences. For instance, when resizing an
image, e.g., with a bilinear or bicubic kernel, signal processing principles
mandate adjusting prefilter width depending on the downsampling factor, to
antialias to the appropriate bandwidth. However, commonly-used implementations
use a fixed-width prefilter, resulting in aliasing artifacts. Such aliasing
leads to corruptions in the feature extraction downstream. Next, lossy
compression, such as JPEG, is commonly used to reduce the file size of an
image. Although designed to minimally degrade the perceptual quality of an
image, the operation also produces variations downstream. Furthermore, we show
that if compression is used on real training images, FID can actually improve
if the generated images are also subsequently compressed. This paper shows that
choices in low-level image processing have been an underappreciated aspect of
generative modeling. We identify and characterize variations in generative
modeling development pipelines, provide recommendations based on signal
processing principles, and release a reference implementation to facilitate
future comparisons.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CapillaryNet: An Automated System to Quantify Skin Capillary Density and Red Blood Cell Velocity from Handheld Vital Microscopy. (arXiv:2104.11574v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11574">
<div class="article-summary-box-inner">
<span><p>Capillaries are the smallest vessels in the body responsible for delivering
oxygen and nutrients to surrounding cells. Various life-threatening diseases
are known to alter the density of healthy capillaries and the flow velocity of
erythrocytes within the capillaries. In previous studies, capillary density and
flow velocity were manually assessed by trained specialists. However, manual
analysis of a standard 20-second microvascular video requires 20 minutes on
average and necessitates extensive training. Thus, manual analysis has been
reported to hinder the application of microvascular microscopy in a clinical
environment. To address this problem, this paper presents a fully automated
state-of-the-art system to quantify skin nutritive capillary density and red
blood cell velocity captured by handheld-based microscopy videos. The proposed
method combines the speed of traditional computer vision algorithms with the
accuracy of convolutional neural networks to enable clinical capillary
analysis. The results show that the proposed system fully automates capillary
detection with an accuracy exceeding that of trained analysts and measures
several novel microvascular parameters that had eluded quantification thus far,
namely, capillary hematocrit and intracapillary flow velocity heterogeneity.
The proposed end-to-end system, named CapillaryNet, can detect capillaries at
$\sim$0.9 seconds per frame with $\sim$93\% accuracy. The system is currently
being used as a clinical research product in a larger e-health application to
analyse capillary data captured from patients suffering from COVID-19,
pancreatitis, and acute heart diseases. CapillaryNet narrows the gap between
the analysis of microcirculation images in a clinical environment and
state-of-the-art systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Jet Classification of Boosted Top Quarks with the CMS Open Data. (arXiv:2104.14659v3 [physics.data-an] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14659">
<div class="article-summary-box-inner">
<span><p>We describe a novel application of the end-to-end deep learning technique to
the task of discriminating top quark-initiated jets from those originating from
the hadronization of a light quark or a gluon. The end-to-end deep learning
technique combines deep learning algorithms and low-level detector
representation of the high-energy collision event. In this study, we use
low-level detector information from the simulated CMS Open Data samples to
construct the top jet classifiers. To optimize classifier performance we
progressively add low-level information from the CMS tracking detector,
including pixel detector reconstructed hits and impact parameters, and
demonstrate the value of additional tracking information even when no new
spatial structures are added. Relying only on calorimeter energy deposits and
reconstructed pixel detector hits, the end-to-end classifier achieves an AUC
score of 0.975$\pm$0.002 for the task of classifying boosted top quark jets.
After adding derived track quantities, the classifier AUC score increases to
0.9824$\pm$0.0013, serving as the first performance benchmark for these CMS
Open Data samples. We additionally provide a timing performance comparison of
different processor unit architectures for training the network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">You Never Cluster Alone. (arXiv:2106.01908v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01908">
<div class="article-summary-box-inner">
<span><p>Recent advances in self-supervised learning with instance-level contrastive
objectives facilitate unsupervised clustering. However, a standalone datum is
not perceiving the context of the holistic cluster, and may undergo sub-optimal
assignment. In this paper, we extend the mainstream contrastive learning
paradigm to a cluster-level scheme, where all the data subjected to the same
cluster contribute to a unified representation that encodes the context of each
data group. Contrastive learning with this representation then rewards the
assignment of each datum. To implement this vision, we propose twin-contrast
clustering (TCC). We define a set of categorical variables as clustering
assignment confidence, which links the instance-level learning track with the
cluster-level one. On one hand, with the corresponding assignment variables
being the weight, a weighted aggregation along the data points implements the
set representation of a cluster. We further propose heuristic cluster
augmentation equivalents to enable cluster-level contrastive learning. On the
other hand, we derive the evidence lower-bound of the instance-level
contrastive objective with the assignments. By reparametrizing the assignment
variables, TCC is trained end-to-end, requiring no alternating steps. Extensive
experiments show that TCC outperforms the state-of-the-art on challenging
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01981">
<div class="article-summary-box-inner">
<span><p>Our work focuses on the development of a learnable neural representation of
human pose for advanced AI assisted animation tooling. Specifically, we tackle
the problem of constructing a full static human pose based on sparse and
variable user inputs (e.g. locations and/or orientations of a subset of body
joints). To solve this problem, we propose a novel neural architecture that
combines residual connections with prototype encoding of a partially specified
pose to create a new complete pose from the learned latent space. We show that
our architecture outperforms a baseline based on Transformer, both in terms of
accuracy and computational efficiency. Additionally, we develop a user
interface to integrate our neural model in Unity, a real-time 3D development
platform. Furthermore, we introduce two new datasets representing the static
human pose modeling problem, based on high-quality human motion capture data,
which will be released publicly along with model code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual learning under domain transfer with sparse synaptic bursting. (arXiv:2108.12056v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12056">
<div class="article-summary-box-inner">
<span><p>Existing machines are functionally specific tools that were made for easy
prediction and control. Tomorrow's machines may be closer to biological systems
in their mutability, resilience, and autonomy. But first they must be capable
of learning, and retaining, new information without repeated exposure to it.
Past efforts to engineer such systems have sought to build or regulate
artificial neural networks using task-specific modules with constrained
circumstances of application. This has not yet enabled continual learning over
long sequences of previously unseen data without corrupting existing knowledge:
a problem known as catastrophic forgetting. In this paper, we introduce a
system that can learn sequentially over previously unseen datasets (ImageNet,
CIFAR-100) with little forgetting over time. This is accomplished by regulating
the activity of weights in a convolutional neural network on the basis of
inputs using top-down modulation generated by a second feed-forward neural
network. We find that our method learns continually under domain transfer with
sparse bursts of activity in weights that are recycled across tasks, rather
than by maintaining task-specific modules. Sparse synaptic bursting is found to
balance enhanced and diminished activity in a way that facilitates adaptation
to new inputs without corrupting previously acquired functions. This behavior
emerges during a prior meta-learning phase in which regulated synapses are
selectively disinhibited, or grown, from an initial state of uniform
suppression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Review of Computer Vision Technologies for Fish Tracking. (arXiv:2110.02551v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02551">
<div class="article-summary-box-inner">
<span><p>Fish tracking based on computer vision is a complex and challenging task in
fishery production and ecological studies. Most of the applications of fish
tracking use classic filtering algorithms, which lack in accuracy and
efficiency. To solve this issue, deep learning methods utilized deep neural
networks to extract the features, which achieve a good performance in the fish
tracking. Some one-stage detection algorithms have gradually been adopted in
this area for the real-time applications. The transfer learning to fish target
is the current development direction. At present, fish tracking technology is
not enough to cover actual application requirements. According to the
literature data collected by us, there has not been any extensive review about
vision-based fish tracking in the community. In this paper, we introduced the
development and application prospects of fish tracking technology in last ten
years. Firstly, we introduced the open source datasets of fish, and summarized
the preprocessing technologies of underwater images. Secondly, we analyzed the
detection and tracking algorithms for fish, and sorted out some transferable
frontier tracking model. Thirdly, we listed the actual applications, metrics
and bottlenecks of the fish tracking such as occlusion and multi-scale.
Finally, we give the discussion for fish tracking datasets, solutions of the
bottlenecks, and improvements. We expect that our work can help the fish
tracking models to achieve higher accuracy and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling. (arXiv:2110.06607v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06607">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose THOMAS, a joint multi-agent trajectory prediction
framework allowing for an efficient and consistent prediction of multi-agent
multi-modal trajectories. We present a unified model architecture for
simultaneous agent future heatmap estimation, in which we leverage hierarchical
and sparse image generation for fast and memory-efficient inference. We propose
a learnable trajectory recombination model that takes as input a set of
predicted trajectories for each agent and outputs its consistent reordered
recombination. This recombination module is able to realign the initially
independent modalities so that they do no collide and are coherent with each
other. We report our results on the Interaction multi-agent prediction
challenge and rank $1^{st}$ on the online test leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining. (arXiv:2110.08009v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08009">
<div class="article-summary-box-inner">
<span><p>Deep Generative Networks (DGNs) are extensively employed in Generative
Adversarial Networks (GANs), Variational Autoencoders (VAEs), and their
variants to approximate the data manifold and distribution. However, training
samples are often distributed in a non-uniform fashion on the manifold, due to
costs or convenience of collection. For example, the CelebA dataset contains a
large fraction of smiling faces. These inconsistencies will be reproduced when
sampling from the trained DGN, which is not always preferred, e.g., for
fairness or data augmentation. In response, we develop MaGNET, a novel and
theoretically motivated latent space sampler for any pre-trained DGN, that
produces samples uniformly distributed on the learned manifold. We perform a
range of experiments on various datasets and DGNs, e.g., for the
state-of-the-art StyleGAN2 trained on FFHQ dataset, uniform sampling via MaGNET
increases distribution precision and recall by 4.1\% \&amp; 3.0\% and decreases
gender bias by 41.2\%, without requiring labels or retraining. As uniform
distribution does not imply uniform semantic distribution, we also explore
separately how semantic attributes of generated samples vary under MaGNET
sampling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PP-ShiTu: A Practical Lightweight Image Recognition System. (arXiv:2111.00775v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00775">
<div class="article-summary-box-inner">
<span><p>In recent years, image recognition applications have developed rapidly. A
large number of studies and techniques have emerged in different fields, such
as face recognition, pedestrian and vehicle re-identification, landmark
retrieval, and product recognition. In this paper, we propose a practical
lightweight image recognition system, named PP-ShiTu, consisting of the
following 3 modules, mainbody detection, feature extraction and vector search.
We introduce popular strategies including metric learning, deep hash, knowledge
distillation and model quantization to improve accuracy and inference speed.
With strategies above, PP-ShiTu works well in different scenarios with a set of
models trained on a mixed dataset. Experiments on different datasets and
benchmarks show that the system is widely effective in different domains of
image recognition. All the above mentioned models are open-sourced and the code
is available in the GitHub repository PaddleClas on PaddlePaddle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BEVT: BERT Pretraining of Video Transformers. (arXiv:2112.01529v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01529">
<div class="article-summary-box-inner">
<span><p>This paper studies the BERT pretraining of video transformers. It is a
straightforward but worth-studying extension given the recent success from BERT
pretraining of image transformers. We introduce BEVT which decouples video
representation learning into spatial representation learning and temporal
dynamics learning. In particular, BEVT first performs masked image modeling on
image data, and then conducts masked image modeling jointly with masked video
modeling on video data. This design is motivated by two observations: 1)
transformers learned on image datasets provide decent spatial priors that can
ease the learning of video transformers, which are often times
computationally-intensive if trained from scratch; 2) discriminative clues,
i.e., spatial and temporal information, needed to make correct predictions vary
among different videos due to large intra-class and inter-class variations. We
conduct extensive experiments on three challenging video benchmarks where BEVT
achieves very promising results. On Kinetics 400, for which recognition mostly
relies on discriminative spatial representations, BEVT achieves comparable
results to strong supervised baselines. On Something-Something-V2 and Diving
48, which contain videos relying on temporal dynamics, BEVT outperforms by
clear margins all alternative baselines and achieves state-of-the-art
performance with a 71.4% and 87.2% Top-1 accuracy respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Body-Aware 3D Shape Generative Models. (arXiv:2112.07022v3 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07022">
<div class="article-summary-box-inner">
<span><p>The shape of many objects in the built environment is dictated by their
relationships to the human body: how will a person interact with this object?
Existing data-driven generative models of 3D shapes produce plausible objects
but do not reason about the relationship of those objects to the human body. In
this paper, we learn body-aware generative models of 3D shapes. Specifically,
we train generative models of chairs, an ubiquitous shape category, which can
be conditioned on a given body shape or sitting pose. The
body-shape-conditioned models produce chairs which will be comfortable for a
person with the given body shape; the pose-conditioned models produce chairs
which accommodate the given sitting pose. To train these models, we define a
"sitting pose matching" metric and a novel "sitting comfort" metric.
Calculating these metrics requires an expensive optimization to sit the body
into the chair, which is too slow to be used as a loss function for training a
generative model. Thus, we train neural networks to efficiently approximate
these metrics. We use our approach to train three body-aware generative shape
models: a structured part-based generator, a point cloud generator, and an
implicit surface generator. In all cases, our approach produces models which
adapt their output chair shapes to input human body specifications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Approach to Addressing Zero-Shot Learning Problem. (arXiv:2201.01391v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01391">
<div class="article-summary-box-inner">
<span><p>In recent years, self-supervised learning has had significant success in
applications involving computer vision and natural language processing. The
type of pretext task is important to this boost in performance. One common
pretext task is the measure of similarity and dissimilarity between pairs of
images. In this scenario, the two images that make up the negative pair are
visibly different to humans. However, in entomology, species are nearly
indistinguishable and thus hard to differentiate. In this study, we explored
the performance of a Siamese neural network using contrastive loss by learning
to push apart embeddings of bumblebee species pair that are dissimilar, and
pull together similar embeddings. Our experimental results show a 61% F1-score
on zero-shot instances, a performance showing 11% improvement on samples of
classes that share intersections with the training set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning with Less Labels in Digital Pathology via Scribble Supervision from Natural Images. (arXiv:2201.02627v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02627">
<div class="article-summary-box-inner">
<span><p>A critical challenge of training deep learning models in the Digital
Pathology (DP) domain is the high annotation cost by medical experts. One way
to tackle this issue is via transfer learning from the natural image domain
(NI), where the annotation cost is considerably cheaper. Cross-domain transfer
learning from NI to DP is shown to be successful via class labels. One
potential weakness of relying on class labels is the lack of spatial
information, which can be obtained from spatial labels such as full pixel-wise
segmentation labels and scribble labels. We demonstrate that scribble labels
from NI domain can boost the performance of DP models on two cancer
classification datasets (Patch Camelyon Breast Cancer and Colorectal Cancer
dataset). Furthermore, we show that models trained with scribble labels yield
the same performance boost as full pixel-wise segmentation labels despite being
significantly easier and faster to collect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In Defense of the Unitary Scalarization for Deep Multi-Task Learning. (arXiv:2201.04122v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04122">
<div class="article-summary-box-inner">
<span><p>Recent multi-task learning research argues against unitary scalarization,
where training simply minimizes the sum of the task losses. Several ad-hoc
multi-task optimization algorithms have instead been proposed, inspired by
various hypotheses about what makes multi-task settings difficult. The majority
of these optimizers require per-task gradients, and introduce significant
memory, runtime, and implementation overhead. We present a theoretical analysis
suggesting that many specialized multi-task optimizers can be interpreted as
forms of regularization. Moreover, we show that, when coupled with standard
regularization and stabilization techniques from single-task learning, unitary
scalarization matches or improves upon the performance of complex multi-task
optimizers in both supervised and reinforcement learning settings. We believe
our results call for a critical reevaluation of recent research in the area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers in Action: Weakly Supervised Action Segmentation. (arXiv:2201.05675v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05675">
<div class="article-summary-box-inner">
<span><p>The video action segmentation task is regularly explored under weaker forms
of supervision, such as transcript supervision, where a list of actions is
easier to obtain than dense frame-wise labels. In this formulation, the task
presents various challenges for sequence modeling approaches due to the
emphasis on action transition points, long sequence lengths, and frame
contextualization, making the task well-posed for transformers. Given
developments enabling transformers to scale linearly, we demonstrate through
our architecture how they can be applied to improve action alignment accuracy
over the equivalent RNN-based models with the attention mechanism focusing
around salient action transition regions. Additionally, given the recent focus
on inference-time transcript selection, we propose a supplemental transcript
embedding approach to select transcripts more quickly at inference-time.
Furthermore, we subsequently demonstrate how this approach can also improve the
overall segmentation performance. Finally, we evaluate our proposed methods
across the benchmark datasets to better understand the applicability of
transformers and the importance of transcript selection on this video-driven
weakly-supervised task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weighting and Pruning based Ensemble Deep Random Vector Functional Link Network for Tabular Data Classification. (arXiv:2201.05809v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05809">
<div class="article-summary-box-inner">
<span><p>In this paper, we first introduce batch normalization to the edRVFL network.
This re-normalization method can help the network avoid divergence of the
hidden features. Then we propose novel variants of Ensemble Deep Random Vector
Functional Link (edRVFL). Weighted edRVFL (WedRVFL) uses weighting methods to
give training samples different weights in different layers according to how
the samples were classified confidently in the previous layer thereby
increasing the ensemble's diversity and accuracy. Furthermore, a pruning-based
edRVFL (PedRVFL) has also been proposed. We prune some inferior neurons based
on their importance for classification before generating the next hidden layer.
Through this method, we ensure that the randomly generated inferior features
will not propagate to deeper layers. Subsequently, the combination of weighting
and pruning, called Weighting and Pruning based Ensemble Deep Random Vector
Functional Link Network (WPedRVFL), is proposed. We compare their performances
with other state-of-the-art deep feedforward neural networks (FNNs) on 24
tabular UCI classification datasets. The experimental results illustrate the
superior performance of our proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-Stage is Enough: A Concise Deep Unfolding Reconstruction Network for Flexible Video Compressive Sensing. (arXiv:2201.05810v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05810">
<div class="article-summary-box-inner">
<span><p>We consider the reconstruction problem of video compressive sensing (VCS)
under the deep unfolding/rolling structure. Yet, we aim to build a flexible and
concise model using minimum stages. Different from existing deep unfolding
networks used for inverse problems, where more stages are used for higher
performance but without flexibility to different masks and scales, hereby we
show that a 2-stage deep unfolding network can lead to the state-of-the-art
(SOTA) results (with a 1.7dB gain in PSNR over the single stage model, RevSCI)
in VCS. The proposed method possesses the properties of adaptation to new masks
and ready to scale to large data without any additional training thanks to the
advantages of deep unfolding. Furthermore, we extend the proposed model for
color VCS to perform joint reconstruction and demosaicing. Experimental results
demonstrate that our 2-stage model has also achieved SOTA on color VCS
reconstruction, leading to a &gt;2.3dB gain in PSNR over the previous SOTA
algorithm based on plug-and-play framework, meanwhile speeds up the
reconstruction by &gt;17 times. In addition, we have found that our network is
also flexible to the mask modulation and scale size for color VCS
reconstruction so that a single trained network can be applied to different
hardware systems. The code and models will be released to the public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YOLO -- You only look 10647 times. (arXiv:2201.06159v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.06159">
<div class="article-summary-box-inner">
<span><p>With this work we are explaining the "You Only Look Once" (YOLO) single-stage
object detection approach as a parallel classification of 10647 fixed region
proposals. We support this view by showing that each of YOLOs output pixel is
attentive to a specific sub-region of previous layers, comparable to a local
region proposal. This understanding reduces the conceptual gap between
YOLO-like single-stage object detection models, RCNN-like two-stage region
proposal based models, and ResNet-like image classification models. In
addition, we created interactive exploration tools for a better visual
understanding of the YOLO information processing streams:
https://limchr.github.io/yolo_visualization
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Video Representation Learning with Cascade Positive Retrieval. (arXiv:2201.07989v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.07989">
<div class="article-summary-box-inner">
<span><p>Self-supervised video representation learning has been shown to effectively
improve downstream tasks such as video retrieval and action recognition. In
this paper, we present the Cascade Positive Retrieval (CPR) that successively
mines positive examples w.r.t. the query for contrastive learning in a cascade
of stages. Specifically, CPR exploits multiple views of a query example in
different modalities, where an alternative view may help find another positive
example dissimilar in the query view. We explore the effects of possible CPR
configurations in ablations including the number of mining stages, the top
similar example selection ratio in each stage, and progressive training with an
incremental number of the final Top-k selection. The overall mining quality is
measured to reflect the recall across training set classes. CPR reaches a
median class mining recall of 83.3%, outperforming previous work by 5.5%.
Implementation-wise, CPR is complementary to pretext tasks and can be easily
applied to previous work. In the evaluation of pretraining on UCF101, CPR
consistently improves existing work and even achieves state-of-the-art R@1 of
56.7% and 24.4% in video retrieval as well as 83.8% and 54.8% in action
recognition on UCF101 and HMDB51. For transfer from large video dataset
Kinetics400 to UCF101 and HDMB, CPR benefits existing work, showing competitive
Top-1 accuracies of 85.1% and 57.4% despite pretraining at a lower resolution
and frame sampling rate. The code will be released soon for reproducing the
results. The code is available at https://github.com/necla-ml/CPR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TerViT: An Efficient Ternary Vision Transformer. (arXiv:2201.08050v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08050">
<div class="article-summary-box-inner">
<span><p>Vision transformers (ViTs) have demonstrated great potential in various
visual tasks, but suffer from expensive computational and memory cost problems
when deployed on resource-constrained devices. In this paper, we introduce a
ternary vision transformer (TerViT) to ternarize the weights in ViTs, which are
challenged by the large loss surface gap between real-valued and ternary
parameters. To address the issue, we introduce a progressive training scheme by
first training 8-bit transformers and then TerViT, and achieve a better
optimization than conventional methods. Furthermore, we introduce channel-wise
ternarization, by partitioning each matrix to different channels, each of which
is with an unique distribution and ternarization interval. We apply our methods
to popular DeiT and Swin backbones, and extensive results show that we can
achieve competitive performance. For example, TerViT can quantize Swin-S to
13.1MB model size while achieving above 79% Top-1 accuracy on ImageNet dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DIVA-DAF: A Deep Learning Framework for Historical Document Image Analysis. (arXiv:2201.08295v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08295">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a new deep learning framework called DIVA-DAF. We
have developed this framework to support our research on historical document
image analysis tasks and to develop techniques to reduce the need for
manually-labeled ground truth. We want to apply self-supervised learning
techniques and use different kinds of training data. Our new framework aids us
in performing rapid prototyping and reproducible experiments. We present a
first semantic segmentation experiment on DIVA-HisDB using our framework,
achieving state-of-the-art results. The DIVA-DAF framework is open-source, and
we encourage other research groups to use it for their experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stitch it in Time: GAN-Based Facial Editing of Real Videos. (arXiv:2201.08361v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08361">
<div class="article-summary-box-inner">
<span><p>The ability of Generative Adversarial Networks to encode rich semantics
within their latent space has been widely adopted for facial image editing.
However, replicating their success with videos has proven challenging. Sets of
high-quality facial videos are lacking, and working with videos introduces a
fundamental barrier to overcome - temporal coherency. We propose that this
barrier is largely artificial. The source video is already temporally coherent,
and deviations from this state arise in part due to careless treatment of
individual components in the editing pipeline. We leverage the natural
alignment of StyleGAN and the tendency of neural networks to learn low
frequency functions, and demonstrate that they provide a strongly consistent
prior. We draw on these insights and propose a framework for semantic editing
of faces in videos, demonstrating significant improvements over the current
state-of-the-art. Our method produces meaningful face manipulations, maintains
a higher degree of temporal consistency, and can be applied to challenging,
high quality, talking head videos which current methods struggle with.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-01-24 23:06:34.965136027 UTC">2022-01-24 23:06:34 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>