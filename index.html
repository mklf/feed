<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-05T01:30:00Z">10-05</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentiment and structure in word co-occurrence networks on Twitter. (arXiv:2110.00587v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00587">
<div class="article-summary-box-inner">
<span><p>We explore the relationship between context and happiness scores in political
tweets using word co-occurrence networks, where nodes in the network are the
words, and the weight of an edge is the number of tweets in the corpus for
which the two connected words co-occur. In particular, we consider tweets with
hashtags #imwithher and #crookedhillary, both relating to Hillary Clinton's
presidential bid in 2016. We then analyze the network properties in conjunction
with the word scores by comparing with null models to separate the effects of
the network structure and the score distribution. Neutral words are found to be
dominant and most words, regardless of polarity, tend to co-occur with neutral
words. We do not observe any score homophily among positive and negative words.
However, when we perform network backboning, community detection results in
word groupings with meaningful narratives, and the happiness scores of the
words in each group correspond to its respective theme. Thus, although we
observe no clear relationship between happiness scores and co-occurrence at the
node or edge level, a community-centric approach can isolate themes of
competing sentiments in a corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Expected Validation Performance and Estimation of a Random Variable's Maximum. (arXiv:2110.00613v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00613">
<div class="article-summary-box-inner">
<span><p>Research in NLP is often supported by experimental results, and improved
reporting of such results can lead to better understanding and more
reproducible science. In this paper we analyze three statistical estimators for
expected validation performance, a tool used for reporting performance (e.g.,
accuracy) as a function of computational budget (e.g., number of hyperparameter
tuning experiments). Where previous work analyzing such estimators focused on
the bias, we also examine the variance and mean squared error (MSE). In both
synthetic and realistic scenarios, we evaluate three estimators and find the
unbiased estimator has the highest variance, and the estimator with the
smallest variance has the largest bias; the estimator with the smallest MSE
strikes a balance between bias and variance, displaying a classic bias-variance
tradeoff. We use expected validation performance to compare between different
models, and analyze how frequently each estimator leads to drawing incorrect
conclusions about which of two models performs best. We find that the two
biased estimators lead to the fewest incorrect conclusions, which hints at the
importance of minimizing variance and MSE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Attentive Constituency Parsing for UCCA-based Semantic Parsing. (arXiv:2110.00621v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00621">
<div class="article-summary-box-inner">
<span><p>Semantic parsing provides a way to extract the semantic structure of a text
that could be understood by machines. It is utilized in various NLP
applications that require text comprehension such as summarization and question
answering. Graph-based representation is one of the semantic representation
approaches to express the semantic structure of a text. Such representations
generate expressive and adequate graph-based target structures. In this paper,
we focus primarily on UCCA graph-based semantic representation. The paper not
only presents the existing approaches proposed for UCCA representation, but
also proposes a novel self-attentive neural parsing model for the UCCA
representation. We present the results for both single-lingual and
cross-lingual tasks using zero-shot and few-shot learning for low-resource
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ALBU: An approximate Loopy Belief message passing algorithm for LDA to improve performance on small data sets. (arXiv:2110.00635v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00635">
<div class="article-summary-box-inner">
<span><p>Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) has
become the most popular algorithm for aspect modeling. While sufficiently
successful in text topic extraction from large corpora, VB is less successful
in identifying aspects in the presence of limited data. We present a novel
variational message passing algorithm as applied to Latent Dirichlet Allocation
(LDA) and compare it with the gold standard VB and collapsed Gibbs sampling. In
situations where marginalisation leads to non-conjugate messages, we use ideas
from sampling to derive approximate update equations. In cases where conjugacy
holds, Loopy Belief update (LBU) (also known as Lauritzen-Spiegelhalter) is
used. Our algorithm, ALBU (approximate LBU), has strong similarities with
Variational Message Passing (VMP) (which is the message passing variant of VB).
To compare the performance of the algorithms in the presence of limited data,
we use data sets consisting of tweets and news groups. Additionally, to perform
more fine grained evaluations and comparisons, we use simulations that enable
comparisons with the ground truth via Kullback-Leibler divergence (KLD). Using
coherence measures for the text corpora and KLD with the simulations we show
that ALBU learns latent distributions more accurately than does VB, especially
for smaller data sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low Frequency Names Exhibit Bias and Overfitting in Contextualizing Language Models. (arXiv:2110.00672v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00672">
<div class="article-summary-box-inner">
<span><p>We use a dataset of U.S. first names with labels based on predominant gender
and racial group to examine the effect of training corpus frequency on
tokenization, contextualization, similarity to initial representation, and bias
in BERT, GPT-2, T5, and XLNet. We show that predominantly female and non-white
names are less frequent in the training corpora of these four language models.
We find that infrequent names are more self-similar across contexts, with
Spearman's r between frequency and self-similarity as low as -.763. Infrequent
names are also less similar to initial representation, with Spearman's r
between frequency and linear centered kernel alignment (CKA) similarity to
initial representation as high as .702. Moreover, we find Spearman's r between
racial bias and name frequency in BERT of .492, indicating that lower-frequency
minority group names are more associated with unpleasantness. Representations
of infrequent names undergo more processing, but are more self-similar,
indicating that models rely on less context-informed representations of
uncommon and minority names which are overfit to a lower number of observed
contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Technology for Everyone: Automatic Speech Recognition for Non-Native English with Transfer Learning. (arXiv:2110.00678v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00678">
<div class="article-summary-box-inner">
<span><p>To address the performance gap of English ASR models on L2 English speakers,
we evaluate fine-tuning of pretrained wav2vec 2.0 models (Baevski et al., 2020;
Xu et al., 2021) on L2-ARCTIC, a non-native English speech corpus (Zhao et al.,
2018) under different training settings. We compare \textbf{(a)} models trained
with a combination of diverse accents to ones trained with only specific
accents and \textbf{(b)} results from different single-accent models. Our
experiments demonstrate the promise of developing ASR models for non-native
English speakers, even with small amounts of L2 training data and even without
a language model. Our models also excel in the zero-shot setting where we train
on multiple L2 datasets and test on a blind L2 test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Robustness of Dialog Models to Popular Figurative Language Constructs. (arXiv:2110.00687v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00687">
<div class="article-summary-box-inner">
<span><p>Humans often employ figurative language use in communication, including
during interactions with dialog systems. Thus, it is important for real-world
dialog systems to be able to handle popular figurative language constructs like
metaphor and simile. In this work, we analyze the performance of existing
dialog models in situations where the input dialog context exhibits use of
figurative language. We observe large gaps in handling of figurative language
when evaluating the models on two open domain dialog datasets. When faced with
dialog contexts consisting of figurative language, some models show very large
drops in performance compared to contexts without figurative language. We
encourage future research in dialog modeling to separately analyze and report
results on figurative language in order to better test model capabilities
relevant to real-world use. Finally, we propose lightweight solutions to help
existing models become more robust to figurative language by simply using an
external resource to translate figurative language to literal (non-figurative)
forms while preserving the meaning to the best extent possible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clustering and Network Analysis for the Embedding Spaces of Sentences and Sub-Sentences. (arXiv:2110.00697v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00697">
<div class="article-summary-box-inner">
<span><p>Sentence embedding methods offer a powerful approach for working with short
textual constructs or sequences of words. By representing sentences as dense
numerical vectors, many natural language processing (NLP) applications have
improved their performance. However, relatively little is understood about the
latent structure of sentence embeddings. Specifically, research has not
addressed whether the length and structure of sentences impact the sentence
embedding space and topology. This paper reports research on a set of
comprehensive clustering and network analyses targeting sentence and
sub-sentence embedding spaces. Results show that one method generates the most
clusterable embeddings. In general, the embeddings of span sub-sentences have
better clustering properties than the original sentences. The results have
implications for future sentence embedding models and applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Zero-shot Multilingual Neural Machine Translation for Low-Resource Languages. (arXiv:2110.00712v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00712">
<div class="article-summary-box-inner">
<span><p>Although the multilingual Neural Machine Translation(NMT), which extends
Google's multilingual NMT, has ability to perform zero-shot translation and the
iterative self-learning algorithm can improve the quality of zero-shot
translation, it confronts with two problems: the multilingual NMT model is
prone to generate wrong target language when implementing zero-shot
translation; the self-learning algorithm, which uses beam search to generate
synthetic parallel data, demolishes the diversity of the generated source
language and amplifies the impact of the same noise during the iterative
learning process. In this paper, we propose the tagged-multilingual NMT model
and improve the self-learning algorithm to handle these two problems. Firstly,
we extend the Google's multilingual NMT model and add target tokens to the
target languages, which associates the start tag with the target language to
ensure that the source language can be translated to the required target
language. Secondly, we improve the self-learning algorithm by replacing beam
search with random sample to increases the diversity of the generated data and
makes it properly cover the true data distribution. Experimental results on
IWSLT show that the adjusted tagged-multilingual NMT separately obtains 9.41
and 7.85 BLEU scores over the multilingual NMT on 2010 and 2017
Romanian-Italian test sets. Similarly, it obtains 9.08 and 7.99 BLEU scores on
Italian-Romanian zero-shot translation. Furthermore, the improved self-learning
algorithm shows its superiorities over the conventional self-learning algorithm
on zero-shot translations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is There More Pattern in Knowledge Graph? Exploring Proximity Pattern for Knowledge Graph Embedding. (arXiv:2110.00720v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00720">
<div class="article-summary-box-inner">
<span><p>Modeling of relation pattern is the core focus of previous Knowledge Graph
Embedding works, which represents how one entity is related to another
semantically by some explicit relation. However, there is a more natural and
intuitive relevancy among entities being always ignored, which is that how one
entity is close to another semantically, without the consideration of any
explicit relation. We name such semantic phenomenon in knowledge graph as
proximity pattern. In this work, we explore the problem of how to define and
represent proximity pattern, and how it can be utilized to help knowledge graph
embedding. Firstly, we define the proximity of any two entities according to
their statistically shared queries, then we construct a derived graph structure
and represent the proximity pattern from global view. Moreover, with the
original knowledge graph, we design a Chained couPle-GNN (CP-GNN) architecture
to deeply merge the two patterns (graphs) together, which can encode a more
comprehensive knowledge embedding. Being evaluated on FB15k-237 and WN18RR
datasets, CP-GNN achieves state-of-the-art results for Knowledge Graph
Completion task, and can especially boost the modeling capacity for complex
queries that contain multiple answer entities, proving the effectiveness of
introduced proximity pattern.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simplify Your Law: Using Information Theory to Deduplicate Legal Documents. (arXiv:2110.00735v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00735">
<div class="article-summary-box-inner">
<span><p>Textual redundancy is one of the main challenges to ensuring that legal texts
remain comprehensible and maintainable. Drawing inspiration from the
refactoring literature in software engineering, which has developed methods to
expose and eliminate duplicated code, we introduce the duplicated phrase
detection problem for legal texts and propose the Dupex algorithm to solve it.
Leveraging the Minimum Description Length principle from information theory,
Dupex identifies a set of duplicated phrases, called patterns, that together
best compress a given input text. Through an extensive set of experiments on
the Titles of the United States Code, we confirm that our algorithm works well
in practice: Dupex will help you simplify your law.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TopiOCQA: Open-domain Conversational Question Answeringwith Topic Switching. (arXiv:2110.00768v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00768">
<div class="article-summary-box-inner">
<span><p>In a conversational question answering scenario, a questioner seeks to
extract information about a topic through a series of interdependent questions
and answers. As the conversation progresses, they may switch to related topics,
a phenomenon commonly observed in information-seeking search sessions. However,
current datasets for conversational question answering are limiting in two
ways: 1) they do not contain topic switches; and 2) they assume the reference
text for the conversation is given, i.e., the setting is not open-domain. We
introduce TopiOCQA (pronounced Tapioca), an open-domain conversational dataset
with topic switches on Wikipedia. TopiOCQA contains 3,920 conversations with
information-seeking questions and free-form answers. TopiOCQA poses a
challenging test-bed for models, where efficient retrieval is required on
multiple turns of the same conversation, in conjunction with constructing valid
responses using conversational history. We evaluate several baselines, by
combining state-of-the-art document retrieval methods with neural reader
models. Our best models achieves F1 of 51.9, and BLEU score of 42.1 which falls
short of human performance by 18.3 points and 17.6 points respectively,
indicating the difficulty of our dataset. Our dataset and code will be
available at https://mcgill-nlp.github.io/topiocqa
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Minimizing LR(1) State Machines is NP-Hard. (arXiv:2110.00776v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00776">
<div class="article-summary-box-inner">
<span><p>LR(1) parsing was a focus of extensive research in the past 50 years. Though
most fundamental mysteries have been resolved, a few remain hidden in the dark
corners. The one we bumped into is the minimization of the LR(1) state
machines, which we prove is NP-hard. It is the node-coloring problem that is
reduced to the minimization puzzle. The reduction makes use of two technique:
indirect reduction and incremental construction. Indirect reduction means the
graph to be colored is not reduced to an LR(1) state machine directly. Instead,
it is reduced to a context-free grammar from which an LR(1) state machine is
derived. Furthermore, by considering the nodes in the graph to be colored one
at a time, the context-free grammar is incrementally extended from a template
context-free grammar that is for a two-node graph. The extension is done by
adding new grammar symbols and rules. A minimized LR(1) machine can be used to
recover a minimum coloring of the original graph.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aspect Sentiment Quad Prediction as Paraphrase Generation. (arXiv:2110.00796v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00796">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis (ABSA) has been extensively studied in recent
years, which typically involves four fundamental sentiment elements, including
the aspect category, aspect term, opinion term, and sentiment polarity.
Existing studies usually consider the detection of partial sentiment elements,
instead of predicting the four elements in one shot. In this work, we introduce
the Aspect Sentiment Quad Prediction (ASQP) task, aiming to jointly detect all
sentiment elements in quads for a given opinionated sentence, which can reveal
a more comprehensive and complete aspect-level sentiment structure. We further
propose a novel \textsc{Paraphrase} modeling paradigm to cast the ASQP task to
a paraphrase generation process. On one hand, the generation formulation allows
solving ASQP in an end-to-end manner, alleviating the potential error
propagation in the pipeline solution. On the other hand, the semantics of the
sentiment elements can be fully exploited by learning to generate them in the
natural language form. Extensive experiments on benchmark datasets show the
superiority of our proposed method and the capacity of cross-task transfer with
the proposed unified \textsc{Paraphrase} modeling framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Swiss-Judgment-Prediction: A Multilingual Legal Judgment Prediction Benchmark. (arXiv:2110.00806v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00806">
<div class="article-summary-box-inner">
<span><p>In many jurisdictions, the excessive workload of courts leads to high delays.
Suitable predictive AI models can assist legal professionals in their work, and
thus enhance and speed up the process. So far, Legal Judgment Prediction (LJP)
datasets have been released in English, French, and Chinese. We publicly
release a multilingual (German, French, and Italian), diachronic (2000-2020)
corpus of 85K cases from the Federal Supreme Court of Switzerland (FSCS). We
evaluate state-of-the-art BERT-based methods including two variants of BERT
that overcome the BERT input (text) length limitation (up to 512 tokens).
Hierarchical BERT has the best performance (approx. 68-70% Macro-F1-Score in
German and French). Furthermore, we study how several factors (canton of
origin, year of publication, text length, legal area) affect performance. We
release both the benchmark dataset and our code to accelerate future research
and ensure reproducibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mapping Language to Programs using Multiple Reward Components with Inverse Reinforcement Learning. (arXiv:2110.00842v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00842">
<div class="article-summary-box-inner">
<span><p>Mapping natural language instructions to programs that computers can process
is a fundamental challenge. Existing approaches focus on likelihood-based
training or using reinforcement learning to fine-tune models based on a single
reward. In this paper, we pose program generation from language as Inverse
Reinforcement Learning. We introduce several interpretable reward components
and jointly learn (1) a reward function that linearly combines them, and (2) a
policy for program generation. Fine-tuning with our approach achieves
significantly better performance than competitive methods using Reinforcement
Learning (RL). On the VirtualHome framework, we get improvements of up to 9.0%
on the Longest Common Subsequence metric and 14.7% on recall-based metrics over
previous work on this framework (Puig et al., 2018). The approach is
data-efficient, showing larger gains in performance in the low-data regime.
Generated programs are also preferred by human evaluators over an RL-based
approach, and rated higher on relevance, completeness, and human-likeness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Study of Sentiment Analysis Using NLP and Different Machine Learning Techniques on US Airline Twitter Data. (arXiv:2110.00859v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00859">
<div class="article-summary-box-inner">
<span><p>Today's business ecosystem has become very competitive. Customer satisfaction
has become a major focus for business growth. Business organizations are
spending a lot of money and human resources on various strategies to understand
and fulfill their customer's needs. But, because of defective manual analysis
on multifarious needs of customers, many organizations are failing to achieve
customer satisfaction. As a result, they are losing customer's loyalty and
spending extra money on marketing. We can solve the problems by implementing
Sentiment Analysis. It is a combined technique of Natural Language Processing
(NLP) and Machine Learning (ML). Sentiment Analysis is broadly used to extract
insights from wider public opinion behind certain topics, products, and
services. We can do it from any online available data. In this paper, we have
introduced two NLP techniques (Bag-of-Words and TF-IDF) and various ML
classification algorithms (Support Vector Machine, Logistic Regression,
Multinomial Naive Bayes, Random Forest) to find an effective approach for
Sentiment Analysis on a large, imbalanced, and multi-classed dataset. Our best
approaches provide 77% accuracy using Support Vector Machine and Logistic
Regression with Bag-of-Words technique.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Case Study to Reveal if an Area of Interest has a Trend in Ongoing Tweets Using Word and Sentence Embeddings. (arXiv:2110.00866v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00866">
<div class="article-summary-box-inner">
<span><p>In the field of Natural Language Processing, information extraction from
texts has been the objective of many researchers for years. Many different
techniques have been applied in order to reveal the opinion that a tweet might
have, thus understanding the sentiment of the small writing up to 280
characters. Other than figuring out the sentiment of a tweet, a study can also
focus on finding the correlation of the tweets with a certain area of interest,
which constitutes the purpose of this study. In order to reveal if an area of
interest has a trend in ongoing tweets, we have proposed an easily applicable
automated methodology in which the Daily Mean Similarity Scores that show the
similarity between the daily tweet corpus and the target words representing our
area of interest is calculated by using a na\"ive correlation-based technique
without training any Machine Learning Model. The Daily Mean Similarity Scores
have mainly based on cosine similarity and word/sentence embeddings computed by
Multilanguage Universal Sentence Encoder and showed main opinion stream of the
tweets with respect to a certain area of interest, which proves that an ongoing
trend of a specific subject on Twitter can easily be captured in almost real
time by using the proposed methodology in this study. We have also compared the
effectiveness of using word versus sentence embeddings while applying our
methodology and realized that both give almost the same results, whereas using
word embeddings requires less computational time than sentence embeddings, thus
being more effective. This paper will start with an introduction followed by
the background information about the basics, then continue with the explanation
of the proposed methodology and later on finish by interpreting the results and
concluding the findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Subtractive mountain clustering algorithm applied to a chatbot to assist elderly people in medication intake. (arXiv:2110.00933v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00933">
<div class="article-summary-box-inner">
<span><p>Errors in medication intake among elderly people are very common. One of the
main causes for this is their loss of ability to retain information. The high
amount of medicine intake required by the advanced age is another limiting
factor. Thence, the design of an interactive aid system, preferably using
natural language, to help the older population with medication is in demand. A
chatbot based on a subtractive cluster algorithm, included in unsupervised
learned models, is the chosen solution since the processing of natural
languages is a necessary step in view to construct a chatbot able to answer
questions that older people may pose upon themselves concerning a particular
drug. In this work, the subtractive mountain clustering algorithm has been
adapted to the problem of natural languages processing. This algorithm version
allows for the association of a set of words into clusters. After finding the
centre of every cluster -- the most relevant word, all the others are
aggregated according to a defined metric adapted to the language processing
realm. All the relevant stored information is processed, as well as the
questions, by the algorithm. The correct processing of the text enables the
chatbot to produce answers that relate to the posed queries. To validate the
method, we use the package insert of a drug as the available information and
formulate associated questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Likelihood Ratio Estimation for High- to Zero-frequency N-grams. (arXiv:2110.00946v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00946">
<div class="article-summary-box-inner">
<span><p>Likelihood ratios (LRs), which are commonly used for probabilistic data
processing, are often estimated based on the frequency counts of individual
elements obtained from samples. In natural language processing, an element can
be a continuous sequence of $N$ items, called an $N$-gram, in which each item
is a word, letter, etc. In this paper, we attempt to estimate LRs based on
$N$-gram frequency information. A naive estimation approach that uses only
$N$-gram frequencies is sensitive to low-frequency (rare) $N$-grams and not
applicable to zero-frequency (unobserved) $N$-grams; these are known as the
low- and zero-frequency problems, respectively. To address these problems, we
propose a method for decomposing $N$-grams into item units and then applying
their frequencies along with the original $N$-gram frequencies. Our method can
obtain the estimates of unobserved $N$-grams by using the unit frequencies.
Although using only unit frequencies ignores dependencies between items, our
method takes advantage of the fact that certain items often co-occur in
practice and therefore maintains their dependencies by using the relevant
$N$-gram frequencies. We also introduce a regularization to achieve robust
estimation for rare $N$-grams. Our experimental results demonstrate that our
method is effective at solving both problems and can effectively control
dependencies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LexGLUE: A Benchmark Dataset for Legal Language Understanding in English. (arXiv:2110.00976v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00976">
<div class="article-summary-box-inner">
<span><p>Law, interpretations of law, legal arguments, agreements, etc. are typically
expressed in writing, leading to the production of vast corpora of legal text.
Their analysis, which is at the center of legal practice, becomes increasingly
elaborate as these collections grow in size. Natural language understanding
(NLU) technologies can be a valuable tool to support legal practitioners in
these endeavors. Their usefulness, however, largely depends on whether current
state-of-the-art models can generalize across various tasks in the legal
domain. To answer this currently open question, we introduce the Legal General
Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets
for evaluating model performance across a diverse set of legal NLU tasks in a
standardized way. We also provide an evaluation and analysis of several generic
and legal-oriented models demonstrating that the latter consistently offer
performance improvements across multiple tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple Recurrent Neural Networks is all we need for clinical events predictions using EHR data. (arXiv:2110.00998v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00998">
<div class="article-summary-box-inner">
<span><p>Recently, there is great interest to investigate the application of deep
learning models for the prediction of clinical events using electronic health
records (EHR) data. In EHR data, a patient's history is often represented as a
sequence of visits, and each visit contains multiple events. As a result, deep
learning models developed for sequence modeling, like recurrent neural networks
(RNNs) are common architecture for EHR-based clinical events predictive models.
While a large variety of RNN models were proposed in the literature, it is
unclear if complex architecture innovations will offer superior predictive
performance. In order to move this field forward, a rigorous evaluation of
various methods is needed. In this study, we conducted a thorough benchmark of
RNN architectures in modeling EHR data. We used two prediction tasks: the risk
for developing heart failure and the risk of early readmission for inpatient
hospitalization. We found that simple gated RNN models, including GRUs and
LSTMs, often offer competitive results when properly tuned with Bayesian
Optimization, which is in line with similar to findings in the natural language
processing (NLP) domain. For reproducibility, Our codebase is shared at
https://github.com/ZhiGroup/pytorch_ehr.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Samples Synthesizing and Training for Robust Visual Question Answering. (arXiv:2110.01013v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01013">
<div class="article-summary-box-inner">
<span><p>Today's VQA models still tend to capture superficial linguistic correlations
in the training set and fail to generalize to the test set with different QA
distributions. To reduce these language biases, recent VQA works introduce an
auxiliary question-only model to regularize the training of targeted VQA model,
and achieve dominating performance on diagnostic benchmarks for
out-of-distribution testing. However, due to complex model design, these
ensemble-based methods are unable to equip themselves with two indispensable
characteristics of an ideal VQA model: 1) Visual-explainable: The model should
rely on the right visual regions when making decisions. 2) Question-sensitive:
The model should be sensitive to the linguistic variations in questions. To
this end, we propose a novel model-agnostic Counterfactual Samples Synthesizing
and Training (CSST) strategy. After training with CSST, VQA models are forced
to focus on all critical objects and words, which significantly improves both
visual-explainable and question-sensitive abilities. Specifically, CSST is
composed of two parts: Counterfactual Samples Synthesizing (CSS) and
Counterfactual Samples Training (CST). CSS generates counterfactual samples by
carefully masking critical objects in images or words in questions and
assigning pseudo ground-truth answers. CST not only trains the VQA models with
both complementary samples to predict respective ground-truth answers, but also
urges the VQA models to further distinguish the original samples and
superficially similar counterfactual ones. To facilitate the CST training, we
propose two variants of supervised contrastive loss for VQA, and design an
effective positive and negative sample selection mechanism based on CSS.
Extensive experiments have shown the effectiveness of CSST. Particularly, by
building on top of model LMH+SAR, we achieve record-breaking performance on all
OOD benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Project Debater APIs: Decomposing the AI Grand Challenge. (arXiv:2110.01029v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01029">
<div class="article-summary-box-inner">
<span><p>Project Debater was revealed in 2019 as the first AI system that can debate
human experts on complex topics. Engaging in a live debate requires a diverse
set of skills, and Project Debater has been developed accordingly as a
collection of components, each designed to perform a specific subtask. Project
Debater APIs provide access to many of these capabilities, as well as to more
recently developed ones. This diverse set of web services, publicly available
for academic use, includes core NLP services, argument mining and analysis
capabilities, and higher-level services for content summarization. We describe
these APIs and their performance, and demonstrate how they can be used for
building practical solutions. In particular, we will focus on Key Point
Analysis, a novel technology that identifies the main points and their
prevalence in a collection of texts such as survey responses and user reviews.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Document Keyphrase Extraction: A Literature Review and the First Dataset. (arXiv:2110.01073v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01073">
<div class="article-summary-box-inner">
<span><p>Keyphrase extraction has been comprehensively researched within the
single-document setting, with an abundance of methods and a wealth of datasets.
In contrast, multi-document keyphrase extraction has been infrequently studied,
despite its utility for describing sets of documents, and its use in
summarization. Moreover, no dataset existed for multi-document keyphrase
extraction, hindering the progress of the task. Recent advances in multi-text
processing make the task an even more appealing challenge to pursue. To
initiate this pursuit, we present here the first literature review and the
first dataset for the task, MK-DUC-01, which can serve as a new benchmark. We
test several keyphrase extraction baselines on our data and show their results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-task Voice-Activated Framework using Self-supervised Learning. (arXiv:2110.01077v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01077">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning methods such as wav2vec 2.0 have shown promising
results in learning speech representations from unlabelled and untranscribed
speech data that are useful for speech recognition. Since these representations
are learned without any task-specific supervision, they can also be useful for
other voice-activated tasks like speaker verification, keyword spotting,
emotion classification etc. In our work, we propose a general purpose framework
for adapting a pre-trained wav2vec 2.0 model for different voice-activated
tasks. We develop downstream network architectures that operate on the
contextualized speech representations of wav2vec 2.0 to adapt the
representations for solving a given task. Finally, we extend our framework to
perform multi-task learning by jointly optimizing the network parameters on
multiple voice activated tasks using a shared transformer backbone. Both of our
single and multi-task frameworks achieve state-of-the-art results in speaker
verification and keyword spotting benchmarks. Our best performing models
achieve 1.98% and 3.15% EER on VoxCeleb1 test set when trained on VoxCeleb2 and
VoxCeleb1 respectively, and 98.23% accuracy on Google Speech Commands v1.0
keyword spotting dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Understanding Persuasion in Computational Argumentation. (arXiv:2110.01078v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01078">
<div class="article-summary-box-inner">
<span><p>Opinion formation and persuasion in argumentation are affected by three major
factors: the argument itself, the source of the argument, and the properties of
the audience. Understanding the role of each and the interplay between them is
crucial for obtaining insights regarding argument interpretation and
generation. It is particularly important for building effective argument
generation systems that can take both the discourse and the audience
characteristics into account. Having such personalized argument generation
systems would be helpful to expose individuals to different viewpoints and help
them make a more fair and informed decision on an issue. Even though studies in
Social Sciences and Psychology have shown that source and audience effects are
essential components of the persuasion process, most research in computational
persuasion has focused solely on understanding the characteristics of
persuasive language. In this thesis, we make several contributions to
understand the relative effect of the source, audience, and language in
computational persuasion. We first introduce a large-scale dataset with
extensive user information to study these factors' effects simultaneously.
Then, we propose models to understand the role of the audience's prior beliefs
on their perception of arguments. We also investigate the role of social
interactions and engagement in understanding users' success in online debating
over time. We find that the users' prior beliefs and social interactions play
an essential role in predicting their success in persuasion. Finally, we
explore the importance of incorporating contextual information to predict
argument impact and show improvements compared to encoding only the text of the
arguments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Examples Generation for Reducing Implicit Gender Bias in Pre-trained Models. (arXiv:2110.01094v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01094">
<div class="article-summary-box-inner">
<span><p>Over the last few years, Contextualized Pre-trained Neural Language Models,
such as BERT, GPT, have shown significant gains in various NLP tasks. To
enhance the robustness of existing pre-trained models, one way is adversarial
examples generation and evaluation for conducting data augmentation or
adversarial learning. In the meanwhile, gender bias embedded in the models
seems to be a serious problem in practical applications. Many researches have
covered the gender bias produced by word-level information(e.g.
gender-stereotypical occupations), while few researchers have investigated the
sentence-level cases and implicit cases.
</p>
<p>In this paper, we proposed a method to automatically generate implicit gender
bias samples at sentence-level and a metric to measure gender bias. Samples
generated by our method will be evaluated in terms of accuracy. The metric will
be used to guide the generation of examples from Pre-trained models. Therefore,
those examples could be used to impose attacks on Pre-trained Models. Finally,
we discussed the evaluation efficacy of our generated examples on reducing
gender bias for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing Language Models for Understanding of Temporal Expressions. (arXiv:2110.01113v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01113">
<div class="article-summary-box-inner">
<span><p>We present three Natural Language Inference (NLI) challenge sets that can
evaluate NLI models on their understanding of temporal expressions. More
specifically, we probe these models for three temporal properties: (a) the
order between points in time, (b) the duration between two points in time, (c)
the relation between the magnitude of times specified in different units. We
find that although large language models fine-tuned on MNLI have some basic
perception of the order between points in time, at large, these models do not
have a thorough understanding of the relation between temporal expressions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured abbreviation expansion in context. (arXiv:2110.01140v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01140">
<div class="article-summary-box-inner">
<span><p>Ad hoc abbreviations are commonly found in informal communication channels
that favor shorter messages. We consider the task of reversing these
abbreviations in context to recover normalized, expanded versions of
abbreviated messages. The problem is related to, but distinct from, spelling
correction, in that ad hoc abbreviations are intentional and may involve
substantial differences from the original words. Ad hoc abbreviations are
productively generated on-the-fly, so they cannot be resolved solely by
dictionary lookup. We generate a large, open-source data set of ad hoc
abbreviations. This data is used to study abbreviation strategies and to
develop two strong baselines for abbreviation expansion
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Interplay Between Sparsity, Naturalness, Intelligibility, and Prosody in Speech Synthesis. (arXiv:2110.01147v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01147">
<div class="article-summary-box-inner">
<span><p>Are end-to-end text-to-speech (TTS) models over-parametrized? To what extent
can these models be pruned, and what happens to their synthesis capabilities?
This work serves as a starting point to explore pruning both spectrogram
prediction networks and vocoders. We thoroughly investigate the tradeoffs
between sparstiy and its subsequent effects on synthetic speech. Additionally,
we explored several aspects of TTS pruning: amount of finetuning data versus
sparsity, TTS-Augmentation to utilize unspoken text, and combining knowledge
distillation and pruning. Our findings suggest that not only are end-to-end TTS
models highly prunable, but also, perhaps surprisingly, pruned TTS models can
produce synthetic speech with equal or higher naturalness and intelligibility,
with similar prosody. All of our experiments are conducted on publicly
available models, and findings in this work are backed by large-scale
subjective tests and objective measures. Code and 200 pruned models are made
available to facilitate future research on efficiency in TTS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TLDR9+: A Large Scale Resource for Extreme Summarization of Social Media Posts. (arXiv:2110.01159v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01159">
<div class="article-summary-box-inner">
<span><p>Recent models in developing summarization systems consist of millions of
parameters and the model performance is highly dependent on the abundance of
training data. While most existing summarization corpora contain data in the
order of thousands to one million, generation of large-scale summarization
datasets in order of couple of millions is yet to be explored. Practically,
more data is better at generalizing the training patterns to unseen data. In
this paper, we introduce TLDR9+ -- a large-scale summarization dataset --
containing over 9 million training instances extracted from Reddit discussion
forum (https://github.com/sajastu/reddit_collector). This dataset is
specifically gathered to perform extreme summarization (i.e., generating
one-sentence summary in high compression and abstraction) and is more than
twice larger than the previously proposed dataset. We go one step further and
with the help of human annotations, we distill a more fine-grained dataset by
sampling High-Quality instances from TLDR9+ and call it TLDRHQ dataset. We
further pinpoint different state-of-the-art summarization models on our
proposed datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Topics: Discovering Latent Healthcare Objectives from Event Sequences. (arXiv:2110.01160v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01160">
<div class="article-summary-box-inner">
<span><p>A meaningful understanding of clinical protocols and patient pathways helps
improve healthcare outcomes. Electronic health records (EHR) reflect real-world
treatment behaviours that are used to enhance healthcare management but present
challenges; protocols and pathways are often loosely defined and with elements
frequently not recorded in EHRs, complicating the enhancement. To solve this
challenge, healthcare objectives associated with healthcare management
activities can be indirectly observed in EHRs as latent topics. Topic models,
such as Latent Dirichlet Allocation (LDA), are used to identify latent patterns
in EHR data. However, they do not examine the ordered nature of EHR sequences,
nor do they appraise individual events in isolation. Our novel approach, the
Categorical Sequence Encoder (CaSE) addresses these shortcomings. The
sequential nature of EHRs is captured by CaSE's event-level representations,
revealing latent healthcare objectives. In synthetic EHR sequences, CaSE
outperforms LDA by up to 37% at identifying healthcare objectives. In the
real-world MIMIC-III dataset, CaSE identifies meaningful representations that
could critically enhance protocol and pathway development.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Metric for Evaluating Semantics Preservation. (arXiv:2110.01176v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01176">
<div class="article-summary-box-inner">
<span><p>In this paper, we leverage pre-trained language models (PLMs) to precisely
evaluate the semantics preservation of edition process on sentences. Our
metric, Neighbor Distribution Divergence (NDD), evaluates the disturbance on
predicted distribution of neighboring words from mask language model (MLM). NDD
is capable of detecting precise changes in semantics which are easily ignored
by text similarity. By exploiting the property of NDD, we implement a
unsupervised and even training-free algorithm for extractive sentence
compression. We show that our NDD-based algorithm outperforms previous
perplexity-based unsupervised algorithm by a large margin. For further
exploration on interpretability, we evaluate NDD by pruning on syntactic
dependency treebanks and apply NDD for predicate detection as well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The state-of-the-art in text-based automatic personality prediction. (arXiv:2110.01186v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01186">
<div class="article-summary-box-inner">
<span><p>Personality detection is an old topic in psychology and Automatic Personality
Prediction (or Perception) (APP) is the automated (computationally) forecasting
of the personality on different types of human generated/exchanged contents
(such as text, speech, image, video). The principal objective of this study is
to offer a shallow (overall) review of natural language processing approaches
on APP since 2010. With the advent of deep learning and following it
transfer-learning and pre-trained model in NLP, APP research area has been a
hot topic, so in this review, methods are categorized into three; pre-trained
independent, pre-trained model based, multimodal approaches. Also, to achieve a
comprehensive comparison, reported results are informed by datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LawSum: A weakly supervised approach for Indian Legal Document Summarization. (arXiv:2110.01188v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01188">
<div class="article-summary-box-inner">
<span><p>Unlike the courts in western countries, public records of Indian judiciary
are completely unstructured and noisy. No large scale publicly available
annotated datasets of Indian legal documents exist till date. This limits the
scope for legal analytics research. In this work, we propose a new dataset
consisting of over 10,000 judgements delivered by the supreme court of India
and their corresponding hand written summaries. The proposed dataset is
pre-processed by normalising common legal abbreviations, handling spelling
variations in named entities, handling bad punctuations and accurate sentence
tokenization. Each sentence is tagged with their rhetorical roles. We also
annotate each judgement with several attributes like date, names of the
plaintiffs, defendants and the people representing them, judges who delivered
the judgement, acts/statutes that are cited and the most common citations used
to refer the judgement. Further, we propose an automatic labelling technique
for identifying sentences which have summary worthy information. We demonstrate
that this auto labeled data can be used effectively to train a weakly
supervised sentence extractor with high accuracy. Some possible applications of
this dataset besides legal document summarization can be in retrieval, citation
analysis and prediction of decisions by a particular judge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeBERTa: Decoding-enhanced BERT with Disentangled Attention. (arXiv:2006.03654v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03654">
<div class="article-summary-box-inner">
<span><p>Recent progress in pre-trained neural language models has significantly
improved the performance of many natural language processing (NLP) tasks. In
this paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT
with disentangled attention) that improves the BERT and RoBERTa models using
two novel techniques. The first is the disentangled attention mechanism, where
each word is represented using two vectors that encode its content and
position, respectively, and the attention weights among words are computed
using disentangled matrices on their contents and relative positions,
respectively. Second, an enhanced mask decoder is used to incorporate absolute
positions in the decoding layer to predict the masked tokens in model
pre-training. In addition, a new virtual adversarial training method is used
for fine-tuning to improve models' generalization. We show that these
techniques significantly improve the efficiency of model pre-training and the
performance of both natural language understanding (NLU) and natural langauge
generation (NLG) downstream tasks. Compared to RoBERTa-Large, a DeBERTa model
trained on half of the training data performs consistently better on a wide
range of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%),
on SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%).
Notably, we scale up DeBERTa by training a larger version that consists of 48
Transform layers with 1.5 billion parameters. The significant performance boost
makes the single DeBERTa model surpass the human performance on the SuperGLUE
benchmark (Wang et al., 2019a) for the first time in terms of macro-average
score (89.9 versus 89.8), and the ensemble DeBERTa model sits atop the
SuperGLUE leaderboard as of January 6, 2021, out performing the human baseline
by a decent margin (90.3 versus 89.8).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Named Entity Recognition for Kazakh. (arXiv:2007.13626v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.13626">
<div class="article-summary-box-inner">
<span><p>We present several neural networks to address the task of named entity
recognition for morphologically complex languages (MCL). Kazakh is a
morphologically complex language in which each root/stem can produce hundreds
or thousands of variant word forms. This nature of the language could lead to a
serious data sparsity problem, which may prevent the deep learning models from
being well trained for under-resourced MCLs. In order to model the MCLs' words
effectively, we introduce root and entity tag embedding plus tensor layer to
the neural networks. The effects of those are significant for improving NER
model performance of MCLs. The proposed models outperform state-of-the-art
including character-based approaches, and can be potentially applied to other
morphologically complex languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Text Generation with Pattern-Exploiting Training. (arXiv:2012.11926v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11926">
<div class="article-summary-box-inner">
<span><p>Providing pretrained language models with simple task descriptions in natural
language enables them to solve some tasks in a fully unsupervised fashion.
Moreover, when combined with regular learning from examples, this idea yields
impressive few-shot results for a wide range of text classification tasks. It
is also a promising direction to improve data efficiency in generative
settings, but there are several challenges to using a combination of task
descriptions and example-based learning for text generation. In particular, it
is crucial to find task descriptions that are easy to understand for the
pretrained model and to ensure that it actually makes good use of them;
furthermore, effective measures against overfitting have to be implemented. In
this paper, we show how these challenges can be tackled: We introduce GenPET, a
method for text generation that is based on pattern-exploiting training, a
recent approach for combining textual instructions with supervised learning
that only works for classification tasks. On several summarization and headline
generation datasets, GenPET gives consistent improvements over strong baselines
in few-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast WordPiece Tokenization. (arXiv:2012.15524v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15524">
<div class="article-summary-box-inner">
<span><p>Tokenization is a fundamental preprocessing step for almost all NLP tasks. In
this paper, we propose efficient algorithms for the WordPiece tokenization used
in BERT, from single-word tokenization to general text (e.g., sentence)
tokenization. When tokenizing a single word, WordPiece uses a
longest-match-first strategy, known as maximum matching. The best known
algorithms so far are O(n^2) (where n is the input length) or O(nm) (where m is
the maximum vocabulary token length). We propose a novel algorithm whose
tokenization complexity is strictly O(n). Our method is inspired by the
Aho-Corasick algorithm. We introduce additional linkages on top of the trie
built from the vocabulary, allowing smart transitions when the trie matching
cannot continue. For general text, we further propose an algorithm that
combines pre-tokenization (splitting the text into words) and our linear-time
WordPiece method into a single pass. Experimental results show that our method
is 8.2x faster than HuggingFace Tokenizers and 5.1x faster than TensorFlow Text
on average for general text tokenization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vy\=akarana: A Colorless Green Benchmark for Syntactic Evaluation in Indic Languages. (arXiv:2103.00854v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00854">
<div class="article-summary-box-inner">
<span><p>While there has been significant progress towards developing NLU resources
for Indic languages, syntactic evaluation has been relatively less explored.
Unlike English, Indic languages have rich morphosyntax, grammatical genders,
free linear word-order, and highly inflectional morphology. In this paper, we
introduce Vy\=akarana: a benchmark of Colorless Green sentences in Indic
languages for syntactic evaluation of multilingual language models. The
benchmark comprises four syntax-related tasks: PoS Tagging, Syntax Tree-depth
Prediction, Grammatical Case Marking, and Subject-Verb Agreement. We use the
datasets from the evaluation tasks to probe five multilingual language models
of varying architectures for syntax in Indic languages. Due to its prevalence,
we also include a code-switching setting in our experiments. Our results show
that the token-level and sentence-level representations from the Indic language
models (IndicBERT and MuRIL) do not capture the syntax in Indic languages as
efficiently as the other highly multilingual language models. Further, our
layer-wise probing experiments reveal that while mBERT, DistilmBERT, and XLM-R
localize the syntax in middle layers, the Indic language models do not show
such syntactic localization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-autoregressive Mandarin-English Code-switching Speech Recognition. (arXiv:2104.02258v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02258">
<div class="article-summary-box-inner">
<span><p>Mandarin-English code-switching (CS) is frequently used among East and
Southeast Asian people. However, the intra-sentence language switching of the
two very different languages makes recognizing CS speech challenging.
Meanwhile, the recent successful non-autoregressive (NAR) ASR models remove the
need for left-to-right beam decoding in autoregressive (AR) models and achieved
outstanding performance and fast inference speed, but it has not been applied
to Mandarin-English CS speech recognition. This paper takes advantage of the
Mask-CTC NAR ASR framework to tackle the CS speech recognition issue. We
further propose to change the Mandarin output target of the encoder to Pinyin
for faster encoder training and introduce the Pinyin-to-Mandarin decoder to
learn contextualized information. Moreover, we use word embedding label
smoothing to regularize the decoder with contextualized information and
projection matrix regularization to bridge that gap between the encoder and
decoder. We evaluate these methods on the SEAME corpus and achieved exciting
results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Datasets with Pretrained Language Models. (arXiv:2104.07540v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07540">
<div class="article-summary-box-inner">
<span><p>To obtain high-quality sentence embeddings from pretrained language models
(PLMs), they must either be augmented with additional pretraining objectives or
finetuned on a large set of labeled text pairs. While the latter approach
typically outperforms the former, it requires great human effort to generate
suitable datasets of sufficient size. In this paper, we show how PLMs can be
leveraged to obtain high-quality sentence embeddings without the need for
labeled data, finetuning or modifications to the pretraining objective: We
utilize the generative abilities of large and high-performing PLMs to generate
entire datasets of labeled text pairs from scratch, which we then use for
finetuning much smaller and more efficient models. Our fully unsupervised
approach outperforms strong baselines on several semantic textual similarity
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IndoNLG: Benchmark and Resources for Evaluating Indonesian Natural Language Generation. (arXiv:2104.08200v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08200">
<div class="article-summary-box-inner">
<span><p>A benchmark provides an ecosystem to measure the advancement of models with
standard datasets and automatic and human evaluation metrics. We introduce
IndoNLG, the first such benchmark for the Indonesian language for natural
language generation (NLG). It covers six tasks: summarization, question
answering, open chitchat, as well as three different language-pairs of machine
translation tasks. We provide a vast and clean pre-training corpus of
Indonesian, Sundanese, and Javanese datasets called Indo4B-Plus, which is used
to train our pre-trained NLG model, IndoBART. We evaluate the effectiveness and
efficiency of IndoBART by conducting extensive evaluation on all IndoNLG tasks.
Our findings show that IndoBART achieves competitive performance on Indonesian
tasks with five times fewer parameters compared to the largest multilingual
model in our benchmark, mBART-LARGE (Liu et al., 2020), and an almost 4x and
2.5x faster inference time on the CPU and GPU respectively. We additionally
demonstrate the ability of IndoBART to learn Javanese and Sundanese, and it
achieves decent performance on machine translation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human-Imitating Metrics for Training and Evaluating Privacy Preserving Emotion Recognition Models Using Sociolinguistic Knowledge. (arXiv:2104.08792v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08792">
<div class="article-summary-box-inner">
<span><p>Privacy preservation is a crucial component of any real-world application.
But, in applications relying on machine learning backends, privacy is
challenging because models often capture more than what the model was initially
trained for, resulting in the potential leakage of sensitive information. In
this paper, we propose an automatic and quantifiable metric that allows us to
evaluate humans' perception of a model's ability to preserve privacy with
respect to sensitive variables. In this paper, we focus on saliency-based
explanations, explanations that highlight regions of the input text, to infer
internal workings of a black box model. We use the degree with which
differences in interpretation of general vs privacy preserving models correlate
with sociolinguistic biases to inform metric design. We show how certain
commonly-used methods that seek to preserve privacy do not align with human
perception of privacy preservation leading to distrust about model's claims. We
demonstrate the versatility of our proposed metric by validating its utility
for measuring cross corpus generalization for both privacy and emotion.
Finally, we conduct crowdsourcing experiments to evaluate the inclination of
the evaluators to choose a particular model for a given purpose when model
explanations are provided, and show a positive relationship with the proposed
metric. To the best of our knowledge, we take the first step in proposing
automatic and quantifiable metrics that best align with human perception of
model's ability for privacy preservation, allowing for cost-effective model
development.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks. (arXiv:2104.08815v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08815">
<div class="article-summary-box-inner">
<span><p>Increasing concerns and regulations about data privacy and sparsity
necessitate the study of privacy-preserving, decentralized learning methods for
natural language processing (NLP) tasks. Federated learning (FL) provides
promising approaches for a large number of clients (e.g., personal devices or
organizations) to collaboratively learn a shared global model to benefit all
clients while allowing users to keep their data locally. Despite interest in
studying FL methods for NLP tasks, a systematic comparison and analysis is
lacking in the literature. Herein, we present the FedNLP, a benchmarking
framework for evaluating federated learning methods on four different task
formulations: text classification, sequence tagging, question answering, and
seq2seq. We propose a universal interface between Transformer-based language
models (e.g., BERT, BART) and FL methods (e.g., FedAvg, FedOPT, etc.) under
various non-IID partitioning strategies. Our extensive experiments with FedNLP
provide empirical comparisons between FL methods and helps us better understand
the inherent challenges of this direction. The comprehensive analysis points to
intriguing and exciting future research aimed at developing FL methods for NLP
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Gender by First Name Using Character-level Machine Learning. (arXiv:2106.10156v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10156">
<div class="article-summary-box-inner">
<span><p>Predicting gender by the first name is not a simple task. In many
applications, especially in the natural language processing (NLP) field, this
task may be necessary, mainly when considering foreign names. In this paper, we
examined and implemented several machine learning algorithms, such as extra
trees, KNN, Naive Bayes, SVM, random forest, gradient boosting, light GBM,
logistic regression, ridge classifier, and deep neural network models, such as
MLP, RNN, GRU, CNN, and BiLSTM, to classify gender through the first name. A
dataset of Brazilian names is used to train and evaluate the models. We
analyzed the accuracy, recall, precision, f1 score, and confusion matrix to
measure the models' performances. The results indicate that the gender
prediction can be performed from the feature extraction strategy looking at the
names as a set of strings. Some models accurately predict gender in more than
95% of the cases. The recurrent models overcome the feedforward models in this
binary classification problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Preserved Accuracy: Evaluating Loyalty and Robustness of BERT Compression. (arXiv:2109.03228v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03228">
<div class="article-summary-box-inner">
<span><p>Recent studies on compression of pretrained language models (e.g., BERT)
usually use preserved accuracy as the metric for evaluation. In this paper, we
propose two new metrics, label loyalty and probability loyalty that measure how
closely a compressed model (i.e., student) mimics the original model (i.e.,
teacher). We also explore the effect of compression with regard to robustness
under adversarial attacks. We benchmark quantization, pruning, knowledge
distillation and progressive module replacing with loyalty and robustness. By
combining multiple compression techniques, we provide a practical strategy to
achieve better accuracy, loyalty and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't Search for a Search Method -- Simple Heuristics Suffice for Adversarial Text Attacks. (arXiv:2109.07926v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07926">
<div class="article-summary-box-inner">
<span><p>Recently more attention has been given to adversarial attacks on neural
networks for natural language processing (NLP). A central research topic has
been the investigation of search algorithms and search constraints, accompanied
by benchmark algorithms and tasks. We implement an algorithm inspired by zeroth
order optimization-based attacks and compare with the benchmark results in the
TextAttack framework. Surprisingly, we find that optimization-based methods do
not yield any improvement in a constrained setup and slightly benefit from
approximate gradient information only in unconstrained setups where search
spaces are larger. In contrast, simple heuristics exploiting nearest neighbors
without querying the target function yield substantial success rates in
constrained setups, and nearly full success rate in unconstrained setups, at an
order of magnitude fewer queries. We conclude from these results that current
TextAttack benchmark tasks are too easy and constraints are too strict,
preventing meaningful research on black-box adversarial text attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Variational Graph Autoencoders for Unsupervised Cross-domain Prerequisite Chains. (arXiv:2109.08722v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08722">
<div class="article-summary-box-inner">
<span><p>Prerequisite chain learning helps people acquire new knowledge efficiently.
While people may quickly determine learning paths over concepts in a domain,
finding such paths in other domains can be challenging. We introduce
Domain-Adversarial Variational Graph Autoencoders (DAVGAE) to solve this
cross-domain prerequisite chain learning task efficiently. Our novel model
consists of a variational graph autoencoder (VGAE) and a domain discriminator.
The VGAE is trained to predict concept relations through link prediction, while
the domain discriminator takes both source and target domain data as input and
is trained to predict domain labels. Most importantly, this method only needs
simple homogeneous graphs as input, compared with the current state-of-the-art
model. We evaluate our model on the LectureBankCD dataset, and results show
that our model outperforms recent graph-based benchmarks while using only 1/10
of graph scale and 1/3 computation time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From None to Severe: Predicting Severity in Movie Scripts. (arXiv:2109.09276v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09276">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce the task of predicting severity of age-restricted
aspects of movie content based solely on the dialogue script. We first
investigate categorizing the ordinal severity of movies on 5 aspects: Sex,
Violence, Profanity, Substance consumption, and Frightening scenes. The problem
is handled using a siamese network-based multitask framework which concurrently
improves the interpretability of the predictions. The experimental results show
that our method outperforms the previous state-of-the-art model and provides
useful information to interpret model predictions. The proposed dataset and
source code are publicly available at our GitHub repository.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAIL-KD: RAndom Intermediate Layer Mapping for Knowledge Distillation. (arXiv:2109.10164v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10164">
<div class="article-summary-box-inner">
<span><p>Intermediate layer knowledge distillation (KD) can improve the standard KD
technique (which only targets the output of teacher and student models)
especially over large pre-trained language models. However, intermediate layer
distillation suffers from excessive computational burdens and engineering
efforts required for setting up a proper layer mapping. To address these
problems, we propose a RAndom Intermediate Layer Knowledge Distillation
(RAIL-KD) approach in which, intermediate layers from the teacher model are
selected randomly to be distilled into the intermediate layers of the student
model. This randomized selection enforce that: all teacher layers are taken
into account in the training process, while reducing the computational cost of
intermediate layer distillation. Also, we show that it act as a regularizer for
improving the generalizability of the student model. We perform extensive
experiments on GLUE tasks as well as on out-of-domain test sets. We show that
our proposed RAIL-KD approach outperforms other state-of-the-art intermediate
layer KD methods considerably in both performance and training-time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Putting Words in BERT's Mouth: Navigating Contextualized Vector Spaces with Pseudowords. (arXiv:2109.11491v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11491">
<div class="article-summary-box-inner">
<span><p>We present a method for exploring regions around individual points in a
contextualized vector space (particularly, BERT space), as a way to investigate
how these regions correspond to word senses. By inducing a contextualized
"pseudoword" as a stand-in for a static embedding in the input layer, and then
performing masked prediction of a word in the sentence, we are able to
investigate the geometry of the BERT-space in a controlled manner around
individual instances. Using our method on a set of carefully constructed
sentences targeting ambiguous English words, we find substantial regularity in
the contextualized space, with regions that correspond to distinct word senses;
but between these regions there are occasionally "sense voids" -- regions that
do not correspond to any intelligible sense.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERT got a Date: Introducing Transformers to Temporal Tagging. (arXiv:2109.14927v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14927">
<div class="article-summary-box-inner">
<span><p>Temporal expressions in text play a significant role in language
understanding and correctly identifying them is fundamental to various
retrieval and natural language processing systems. Previous works have slowly
shifted from rule-based to neural architectures, capable of tagging expressions
with higher accuracy. However, neural models can not yet distinguish between
different expression types at the same level as their rule-based counterparts.
In this work, we aim to identify the most suitable transformer architecture for
joint temporal tagging and type classification, as well as, investigating the
effect of semi-supervised training on the performance of these systems. Based
on our study of token classification variants and encoder-decoder
architectures, we present a transformer encoder-decoder model using the RoBERTa
language model as our best performing system. By supplementing training
resources with weakly labeled data from rule-based systems, our model surpasses
previous works in temporal tagging and type classification, especially on rare
classes. Our code and pre-trained experiments are available at:
https://github.com/satya77/Transformer_Temporal_Tagger
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Reconstructing group wavelet transform from feature maps with a reproducing kernel iteration. (arXiv:2110.00600v1 [math.NA])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00600">
<div class="article-summary-box-inner">
<span><p>In this paper we consider the problem of reconstructing an image that is
downsampled in the space of its $SE(2)$ wavelet transform, which is motivated
by classical models of simple cells receptive fields and feature preference
maps in primary visual cortex. We prove that, whenever the problem is solvable,
the reconstruction can be obtained by an elementary project and replace
iterative scheme based on the reproducing kernel arising from the group
structure, and show numerical results on real images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Algorithm Fairness in AI for Medicine and Healthcare. (arXiv:2110.00603v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00603">
<div class="article-summary-box-inner">
<span><p>In the current development and deployment of many artificial intelligence
(AI) systems in healthcare, algorithm fairness is a challenging problem in
delivering equitable care. Recent evaluation of AI models stratified across
race sub-populations have revealed enormous inequalities in how patients are
diagnosed, given treatments, and billed for healthcare costs. In this
perspective article, we summarize the intersectional field of fairness in
machine learning through the context of current issues in healthcare, outline
how algorithmic biases (e.g. - image acquisition, genetic variation,
intra-observer labeling variability) arise in current clinical workflows and
their resulting healthcare disparities. Lastly, we also review emerging
strategies for mitigating bias via decentralized learning, disentanglement, and
model explainability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPEC: Seeing People in the Wild with an Estimated Camera. (arXiv:2110.00620v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00620">
<div class="article-summary-box-inner">
<span><p>Due to the lack of camera parameter information for in-the-wild images,
existing 3D human pose and shape (HPS) estimation methods make several
simplifying assumptions: weak-perspective projection, large constant focal
length, and zero camera rotation. These assumptions often do not hold and we
show, quantitatively and qualitatively, that they cause errors in the
reconstructed 3D shape and pose. To address this, we introduce SPEC, the first
in-the-wild 3D HPS method that estimates the perspective camera from a single
image and employs this to reconstruct 3D human bodies more accurately. %regress
3D human bodies. First, we train a neural network to estimate the field of
view, camera pitch, and roll given an input image. We employ novel losses that
improve the calibration accuracy over previous work. We then train a novel
network that concatenates the camera calibration to the image features and uses
these together to regress 3D body shape and pose. SPEC is more accurate than
the prior art on the standard benchmark (3DPW) as well as two new datasets with
more challenging camera views and varying focal lengths. Specifically, we
create a new photorealistic synthetic dataset (SPEC-SYN) with ground truth 3D
bodies and a novel in-the-wild dataset (SPEC-MTP) with calibration and
high-quality reference bodies. Both qualitative and quantitative analysis
confirm that knowing camera parameters during inference regresses better human
bodies. Code and datasets are available for research purposes at
https://spec.is.tue.mpg.de.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RoomStructNet: Learning to Rank Non-Cuboidal Room Layouts From Single View. (arXiv:2110.00644v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00644">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a new approach to estimate the layout of a room
from its single image. While recent approaches for this task use robust
features learnt from data, they resort to optimization for detecting the final
layout. In addition to using learnt robust features, our approach learns an
additional ranking function to estimate the final layout instead of using
optimization. To learn this ranking function, we propose a framework to train a
CNN using max-margin structure cost. Also, while most approaches aim at
detecting cuboidal layouts, our approach detects non-cuboidal layouts for which
we explicitly estimates layout complexity parameters. We use these parameters
to propose layout candidates in a novel way. Our approach shows
state-of-the-art results on standard datasets with mostly cuboidal layouts and
also performs well on a dataset containing rooms with non-cuboidal layouts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-view SA-LA Net: A framework for simultaneous segmentation of RV on multi-view cardiac MR Images. (arXiv:2110.00682v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00682">
<div class="article-summary-box-inner">
<span><p>We proposed a multi-view SA-LA model for simultaneous segmentation of RV on
the short-axis (SA) and long-axis (LA) cardiac MR images. The multi-view SA-LA
model is a multi-encoder, multi-decoder U-Net architecture based on the U-Net
model. One encoder-decoder pair segments the RV on SA images and the other pair
on LA images. Multi-view SA-LA model assembles an extremely rich set of
synergistic features, at the root of the encoder branch, by combining feature
maps learned from matched SA and LA cardiac MR images. Segmentation performance
is further enhanced by: (1) incorporating spatial context of LV as a prior and
(2) performing deep supervision in the last three layers of the decoder branch.
Multi-view SA-LA model was extensively evaluated on the MICCAI 2021 Multi-
Disease, Multi-View, and Multi- Centre RV Segmentation Challenge dataset
(M&amp;Ms-2021). M&amp;Ms-2021 dataset consists of multi-phase, multi-view cardiac MR
images of 360 subjects acquired at four clinical centers with three different
vendors. On the challenge cohort (160 subjects), the proposed multi-view SA-LA
model achieved a Dice Score of 91% and Hausdorff distance of 11.2 mm on
short-axis images and a Dice Score of 89.6% and Hausdorff distance of 8.1 mm on
long-axis images. Moreover, multi-view SA-LA model exhibited strong
generalization to unseen RV related pathologies including Dilated Right
Ventricle (DSC: SA 91.41%, LA 89.63%) and Tricuspidal Regurgitation (DSC: SA
91.40%, LA 90.40%) with low variance (std_DSC: SA &lt;5%, LA&lt;6%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Light Field Saliency Detection with Dual Local Graph Learning andReciprocative Guidance. (arXiv:2110.00698v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00698">
<div class="article-summary-box-inner">
<span><p>The application of light field data in salient object de-tection is becoming
increasingly popular recently. The diffi-culty lies in how to effectively fuse
the features within the fo-cal stack and how to cooperate them with the feature
of theall-focus image. Previous methods usually fuse focal stackfeatures via
convolution or ConvLSTM, which are both lesseffective and ill-posed. In this
paper, we model the infor-mation fusion within focal stack via graph networks.
Theyintroduce powerful context propagation from neighbouringnodes and also
avoid ill-posed implementations. On the onehand, we construct local graph
connections thus avoidingprohibitive computational costs of traditional graph
net-works. On the other hand, instead of processing the twokinds of data
separately, we build a novel dual graph modelto guide the focal stack fusion
process using all-focus pat-terns. To handle the second difficulty, previous
methods usu-ally implement one-shot fusion for focal stack and
all-focusfeatures, hence lacking a thorough exploration of their sup-plements.
We introduce a reciprocative guidance schemeand enable mutual guidance between
these two kinds of in-formation at multiple steps. As such, both kinds of
featurescan be enhanced iteratively, finally benefiting the saliencyprediction.
Extensive experimental results show that theproposed models are all beneficial
and we achieve signif-icantly better results than state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal Adversarial Spoofing Attacks against Face Recognition. (arXiv:2110.00708v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00708">
<div class="article-summary-box-inner">
<span><p>We assess the vulnerabilities of deep face recognition systems for images
that falsify/spoof multiple identities simultaneously. We demonstrate that, by
manipulating the deep feature representation extracted from a face image via
imperceptibly small perturbations added at the pixel level using our proposed
Universal Adversarial Spoofing Examples (UAXs), one can fool a face
verification system into recognizing that the face image belongs to multiple
different identities with a high success rate. One characteristic of the UAXs
crafted with our method is that they are universal (identity-agnostic); they
are successful even against identities not known in advance. For a certain deep
neural network, we show that we are able to spoof almost all tested identities
(99\%), including those not known beforehand (not included in training). Our
results indicate that a multiple-identity attack is a real threat and should be
taken into account when deploying face recognition systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Asking questions on handwritten document collections. (arXiv:2110.00711v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00711">
<div class="article-summary-box-inner">
<span><p>This work addresses the problem of Question Answering (QA) on handwritten
document collections. Unlike typical QA and Visual Question Answering (VQA)
formulations where the answer is a short text, we aim to locate a document
snippet where the answer lies. The proposed approach works without recognizing
the text in the documents. We argue that the recognition-free approach is
suitable for handwritten documents and historical collections where robust text
recognition is often difficult. At the same time, for human users, document
image snippets containing answers act as a valid alternative to textual
answers. The proposed approach uses an off-the-shelf deep embedding network
which can project both textual words and word images into a common sub-space.
This embedding bridges the textual and visual domains and helps us retrieve
document snippets that potentially answer a question. We evaluate results of
the proposed approach on two new datasets: (i) HW-SQuAD: a synthetic,
handwritten document image counterpart of SQuAD1.0 dataset and (ii) BenthamQA:
a smaller set of QA pairs defined on documents from the popular Bentham
manuscripts collection. We also present a thorough analysis of the proposed
recognition-free approach compared to a recognition-based approach which uses
text recognized from the images using an OCR. Datasets presented in this work
are available to download at docvqa.org
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Optimization-Based Meta-Learning Model for MRI Reconstruction with Diverse Dataset. (arXiv:2110.00715v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00715">
<div class="article-summary-box-inner">
<span><p>Purpose: This work aims at developing a generalizable MRI reconstruction
model in the meta-learning framework. The standard benchmarks in meta-learning
are challenged by learning on diverse task distributions. The proposed network
learns the regularization function in a variational model and reconstructs MR
images with various under-sampling ratios or patterns that may or may not be
seen in the training data by leveraging a heterogeneous dataset. Methods: We
propose an unrolling network induced by learnable optimization algorithms (LOA)
for solving our nonconvex nonsmooth variational model for MRI reconstruction.
In this model, the learnable regularization function contains a task-invariant
common feature encoder and task-specific learner represented by a shallow
network. To train the network we split the training data into two parts:
training and validation, and introduce a bilevel optimization algorithm. The
lower-level optimization trains task-invariant parameters for the feature
encoder with fixed parameters of the task-specific learner on the training
dataset, and the upper-level optimizes the parameters of the task-specific
learner on the validation dataset. Results: The average PSNR increases
significantly compared to the network trained through conventional supervised
learning on the seen CS ratios. We test the result of quick adaption on the
unseen tasks after meta-training and in the meanwhile saving half of the
training time; Conclusion: We proposed a meta-learning framework consisting of
the base network architecture, design of regularization, and bi-level
optimization-based training. The network inherits the convergence property of
the LOA and interpretation of the variational model. The generalization ability
is improved by the designated regularization and bilevel optimization-based
training algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-Specific Bias Filtering for Single Labeled Domain Generalization. (arXiv:2110.00726v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00726">
<div class="article-summary-box-inner">
<span><p>Domain generalization (DG) utilizes multiple labeled source datasets to train
a generalizable model for unseen target domains. However, due to expensive
annotation costs, the requirements of labeling all the source data are hard to
be met in real-world applications. In this paper, we investigate a Single
Labeled Domain Generalization (SLDG) task with only one source domain being
labeled, which is more practical and challenging than the Conventional Domain
Generalization (CDG). A major obstacle in the SLDG task is the
discriminability-generalization bias: discriminative information in the labeled
source dataset may contain domain-specific bias, constraining the
generalization of the trained model. To tackle this challenging task, we
propose a novel method called Domain-Specific Bias Filtering (DSBF), which
initializes a discriminative model with the labeled source data and filters out
its domain-specific bias with the unlabeled source data for generalization
improvement. We divide the filtering process into: (1) Feature extractor
debiasing using k-means clustering-based semantic feature re-extraction; and
(2) Classifier calibrating using attention-guided semantic feature projection.
DSBF unifies the exploration of the labeled and the unlabeled source data to
enhance the discriminability and generalization of the trained model, resulting
in a highly generalizable model. We further provide theoretical analysis to
verify the proposed domain-specific bias filtering process. Extensive
experiments on multiple datasets show the superior performance of DSBF in
tackling both the challenging SLDG task and the CDG task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FICGAN: Facial Identity Controllable GAN for De-identification. (arXiv:2110.00740v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00740">
<div class="article-summary-box-inner">
<span><p>In this work, we present Facial Identity Controllable GAN (FICGAN) for not
only generating high-quality de-identified face images with ensured privacy
protection, but also detailed controllability on attribute preservation for
enhanced data utility. We tackle the less-explored yet desired functionality in
face de-identification based on the two factors. First, we focus on the
challenging issue to obtain a high level of privacy protection in the
de-identification task while uncompromising the image quality. Second, we
analyze the facial attributes related to identity and non-identity and explore
the trade-off between the degree of face de-identification and preservation of
the source attributes for enhanced data utility. Based on the analysis, we
develop Facial Identity Controllable GAN (FICGAN), an autoencoder-based
conditional generative model that learns to disentangle the identity attributes
from non-identity attributes on a face image. By applying the manifold k-same
algorithm to satisfy k-anonymity for strengthened security, our method achieves
enhanced privacy protection in de-identified face images. Numerous experiments
demonstrate that our model outperforms others in various scenarios of face
de-identification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable Event Recognition. (arXiv:2110.00755v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00755">
<div class="article-summary-box-inner">
<span><p>The literature shows outstanding capabilities for CNNs in event recognition
in images. However, fewer attempts are made to analyze the potential causes
behind the decisions of the models and exploring whether the predictions are
based on event-salient objects or regions? To explore this important aspect of
event recognition, in this work, we propose an explainable event recognition
framework relying on Grad-CAM and an Xception architecture-based CNN model.
Experiments are conducted on three large-scale datasets covering a diversified
set of natural disasters, social, and sports events. Overall, the model showed
outstanding generalization capabilities obtaining overall F1-scores of 0.91,
0.94, and 0.97 on natural disasters, social, and sports events, respectively.
Moreover, for subjective analysis of activation maps generated through Grad-CAM
for the predicted samples of the model, a crowdsourcing study is conducted to
analyze whether the model's predictions are based on event-related
objects/regions or not? The results of the study indicate that 78%, 84%, and
78% of the model decisions on natural disasters, sports, and social events
datasets, respectively, are based onevent-related objects or regions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Seed Quality Testing System using GAN & Active Learning. (arXiv:2110.00777v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00777">
<div class="article-summary-box-inner">
<span><p>Quality assessment of agricultural produce is a crucial step in minimizing
food stock wastage. However, this is currently done manually and often requires
expert supervision, especially in smaller seeds like corn. We propose a novel
computer vision-based system for automating this process. We build a novel seed
image acquisition setup, which captures both the top and bottom views. Dataset
collection for this problem has challenges of data annotation costs/time and
class imbalance. We address these challenges by i.) using a Conditional
Generative Adversarial Network (CGAN) to generate real-looking images for the
classes with lesser images and ii.) annotate a large dataset with minimal
expert human intervention by using a Batch Active Learning (BAL) based
annotation tool. We benchmark different image classification models on the
dataset obtained. We are able to get accuracies of up to 91.6% for testing the
physical purity of seed samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seeking Visual Discomfort: Curiosity-driven Representations for Reinforcement Learning. (arXiv:2110.00784v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00784">
<div class="article-summary-box-inner">
<span><p>Vision-based reinforcement learning (RL) is a promising approach to solve
control tasks involving images as the main observation. State-of-the-art RL
algorithms still struggle in terms of sample efficiency, especially when using
image observations. This has led to increased attention on integrating state
representation learning (SRL) techniques into the RL pipeline. Work in this
field demonstrates a substantial improvement in sample efficiency among other
benefits. However, to take full advantage of this paradigm, the quality of
samples used for training plays a crucial role. More importantly, the diversity
of these samples could affect the sample efficiency of vision-based RL, but
also its generalization capability. In this work, we present an approach to
improve sample diversity for state representation learning. Our method enhances
the exploration capability of RL algorithms, by taking advantage of the SRL
setup. Our experiments show that our proposed approach boosts the visitation of
problematic states, improves the learned state representation, and outperforms
the baselines for all tested environments. These results are most apparent for
environments where the baseline methods struggle. Even in simple environments,
our method stabilizes the training, reduces the reward variance, and promotes
sample efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inference-InfoGAN: Inference Independence via Embedding Orthogonal Basis Expansion. (arXiv:2110.00788v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00788">
<div class="article-summary-box-inner">
<span><p>Disentanglement learning aims to construct independent and interpretable
latent variables in which generative models are a popular strategy. InfoGAN is
a classic method via maximizing Mutual Information (MI) to obtain interpretable
latent variables mapped to the target space. However, it did not emphasize
independent characteristic. To explicitly infer latent variables with
inter-independence, we propose a novel GAN-based disentanglement framework via
embedding Orthogonal Basis Expansion (OBE) into InfoGAN network
(Inference-InfoGAN) in an unsupervised way. Under the OBE module, one set of
orthogonal basis can be adaptively found to expand arbitrary data with
independence property. To ensure the target-wise interpretable representation,
we add a consistence constraint between the expansion coefficients and latent
variables on the base of MI maximization. Additionally, we design an
alternating optimization step on the consistence constraint and orthogonal
requirement updating, so that the training of Inference-InfoGAN can be more
convenient. Finally, experiments validate that our proposed OBE module obtains
adaptive orthogonal basis, which can express better independent characteristics
than fixed basis expression of Discrete Cosine Transform (DCT). To depict the
performance in downstream tasks, we compared with the state-of-the-art
GAN-based and even VAE-based approaches on different datasets. Our
Inference-InfoGAN achieves higher disentanglement score in terms of FactorVAE,
Separated Attribute Predictability (SAP), Mutual Information Gap (MIG) and
Variation Predictability (VP) metrics without model fine-tuning. All the
experimental results illustrate that our method has inter-independence
inference ability because of the OBE module, and provides a good trade-off
between it and target-wise interpretability of latent variables via jointing
the alternating optimization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimizing Neural Network for Computer Vision task in Edge Device. (arXiv:2110.00791v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00791">
<div class="article-summary-box-inner">
<span><p>The field of computer vision has grown very rapidly in the past few years due
to networks like convolution neural networks and their variants. The memory
required to store the model and computational expense are very high for such a
network limiting it to deploy on the edge device. Many times, applications rely
on the cloud but that makes it hard for working in real-time due to round-trip
delays. We overcome these problems by deploying the neural network on the edge
device itself. The computational expense for edge devices is reduced by
reducing the floating-point precision of the parameters in the model. After
this the memory required for the model decreases and the speed of the
computation increases where the performance of the model is least affected.
This makes an edge device to predict from the neural network all by itself.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Welsch Based Multiview Disparity Estimation. (arXiv:2110.00803v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00803">
<div class="article-summary-box-inner">
<span><p>In this work, we explore disparity estimation from a high number of views. We
experimentally identify occlusions as a key challenge for disparity estimation
for applications with high numbers of views. In particular, occlusions can
actually result in a degradation in accuracy as more views are added to a
dataset. We propose the use of a Welsch loss function for the data term in a
global variational framework for disparity estimation. We also propose a
disciplined warping strategy and a progressive inclusion of views strategy that
can reduce the need for coarse to fine strategies that discard high spatial
frequency components from the early iterations. Experimental results
demonstrate that the proposed approach produces superior and/or more robust
estimates than other conventional variational approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProTo: Program-Guided Transformer for Program-Guided Tasks. (arXiv:2110.00804v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00804">
<div class="article-summary-box-inner">
<span><p>Programs, consisting of semantic and structural information, play an
important role in the communication between humans and agents. Towards learning
general program executors to unify perception, reasoning, and decision making,
we formulate program-guided tasks which require learning to execute a given
program on the observed task specification. Furthermore, we propose the
Program-guided Transformer (ProTo), which integrates both semantic and
structural guidance of a program by leveraging cross-attention and masked
self-attention to pass messages between the specification and routines in the
program. ProTo executes a program in a learned latent space and enjoys stronger
representation ability than previous neural-symbolic approaches. We demonstrate
that ProTo significantly outperforms the previous state-of-the-art methods on
GQA visual reasoning and 2D Minecraft policy learning datasets. Additionally,
ProTo demonstrates better generalization to unseen, complex, and human-written
programs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Implicit and Explicit Attention for Zero-Shot Learning. (arXiv:2110.00860v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00860">
<div class="article-summary-box-inner">
<span><p>Most of the existing Zero-Shot Learning (ZSL) methods focus on learning a
compatibility function between the image representation and class attributes.
Few others concentrate on learning image representation combining local and
global features. However, the existing approaches still fail to address the
bias issue towards the seen classes. In this paper, we propose implicit and
explicit attention mechanisms to address the existing bias problem in ZSL
models. We formulate the implicit attention mechanism with a self-supervised
image angle rotation task, which focuses on specific image features aiding to
solve the task. The explicit attention mechanism is composed with the
consideration of a multi-headed self-attention mechanism via Vision Transformer
model, which learns to map image features to semantic space during the training
stage. We conduct comprehensive experiments on three popular benchmarks: AWA2,
CUB and SUN. The performance of our proposed attention mechanisms has proved
its effectiveness, and has achieved the state-of-the-art harmonic mean on all
the three datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BdSL36: A Dataset for Bangladeshi Sign Letters Recognition. (arXiv:2110.00869v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00869">
<div class="article-summary-box-inner">
<span><p>Bangladeshi Sign Language (BdSL) is a commonly used medium of communication
for the hearing-impaired people in Bangladesh. A real-time BdSL interpreter
with no controlled lab environment has a broad social impact and an interesting
avenue of research as well. Also, it is a challenging task due to the variation
in different subjects (age, gender, color, etc.), complex features, and
similarities of signs and clustered backgrounds. However, the existing dataset
for BdSL classification task is mainly built in a lab friendly setup which
limits the application of powerful deep learning technology. In this paper, we
introduce a dataset named BdSL36 which incorporates background augmentation to
make the dataset versatile and contains over four million images belonging to
36 categories. Besides, we annotate about 40,000 images with bounding boxes to
utilize the potentiality of object detection algorithms. Furthermore, several
intensive experiments are performed to establish the baseline performance of
our BdSL36. Moreover, we employ beta testing of our classifiers at the user
level to justify the possibilities of real-world application with this dataset.
We believe our BdSL36 will expedite future research on practical sign letter
classification. We make the datasets and all the pre-trained models available
for further researcher.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Attention-based Models Using Activation Maps for Citrus Mite and Insect Pest Classification. (arXiv:2110.00881v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00881">
<div class="article-summary-box-inner">
<span><p>Citrus juices and fruits are commodities with great economic potential in the
international market, but productivity losses caused by mites and other pests
are still far from being a good mark. Despite the integrated pest mechanical
aspect, only a few works on automatic classification have handled images with
orange mite characteristics, which means tiny and noisy regions of interest. On
the computational side, attention-based models have gained prominence in deep
learning research, and, along with weakly supervised learning algorithms, they
have improved tasks performed with some label restrictions. In agronomic
research of pests and diseases, these techniques can improve classification
performance while pointing out the location of mites and insects without
specific labels, reducing deep learning development costs related to generating
bounding boxes. In this context, this work proposes an attention-based
activation map approach developed to improve the classification of tiny regions
called Two-Weighted Activation Mapping, which also produces locations using
feature map scores learned from class labels. We apply our method in a
two-stage network process called Attention-based Multiple Instance Learning
Guided by Saliency Maps. We analyze the proposed approach in two challenging
datasets, the Citrus Pest Benchmark, which was captured directly in the field
using magnifying glasses, and the Insect Pest, a large pest image benchmark. In
addition, we evaluate and compare our models with weakly supervised methods,
such as Attention-based Deep MIL and WILDCAT. The results show that our
classifier is superior to literature methods that use tiny regions in their
classification tasks, surpassing them in all scenarios by at least 16
percentage points. Moreover, our approach infers bounding box locations for
salient insects, even training without any location labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disarranged Zone Learning (DZL): An unsupervised and dynamic automatic stenosis recognition methodology based on coronary angiography. (arXiv:2110.00896v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00896">
<div class="article-summary-box-inner">
<span><p>We proposed a novel unsupervised methodology named Disarranged Zone Learning
(DZL) to automatically recognize stenosis in coronary angiography. The
methodology firstly disarranges the frames in a video, secondly it generates an
effective zone and lastly trains an encoder-decoder GRU model to learn the
capability to recover disarranged frames. The breakthrough of our study is to
discover and validate the Sequence Intensity (Recover Difficulty) is a measure
of Coronary Artery Stenosis Status. Hence, the prediction accuracy of DZL is
used as an approximator of coronary stenosis indicator. DZL is an unsupervised
methodology and no label engineering effort is needed, the sub GRU model in DZL
works as a self-supervised approach. So DZL could theoretically utilize
infinitely huge amounts of coronary angiographies to learn and improve
performance without laborious data labeling. There is no data preprocessing
precondition to run DZL as it dynamically utilizes the whole video, hence it is
easy to be implemented and generalized to overcome the data heterogeneity of
coronary angiography. The overall average precision score achieves 0.93, AUC
achieves 0.8 for this pure methodology. The highest segmented average precision
score is 0.98 and the highest segmented AUC is 0.87 for coronary occlusion
indicator. Finally, we developed a software demo to implement DZL methodology.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anti-aliasing Deep Image Classifiers using Novel Depth Adaptive Blurring and Activation Function. (arXiv:2110.00899v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00899">
<div class="article-summary-box-inner">
<span><p>Deep convolutional networks are vulnerable to image translation or shift,
partly due to common down-sampling layers, e.g., max-pooling and strided
convolution. These operations violate the Nyquist sampling rate and cause
aliasing. The textbook solution is low-pass filtering (blurring) before
down-sampling, which can benefit deep networks as well. Even so, non-linearity
units, such as ReLU, often re-introduce the problem, suggesting that blurring
alone may not suffice. In this work, first, we analyse deep features with
Fourier transform and show that Depth Adaptive Blurring is more effective, as
opposed to monotonic blurring. To this end, we outline how this can replace
existing down-sampling methods. Second, we introduce a novel activation
function -- with a built-in low pass filter, to keep the problem from
reappearing. From experiments, we observe generalisation on other forms of
transformations and corruptions as well, e.g., rotation, scale, and noise. We
evaluate our method under three challenging settings: (1) a variety of image
translations; (2) adversarial attacks -- both $\ell_{p}$ bounded and unbounded;
and (3) data corruptions and perturbations. In each setting, our method
achieves state-of-the-art results and improves clean accuracy on various
benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GROWN: GRow Only When Necessary for Continual Learning. (arXiv:2110.00908v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00908">
<div class="article-summary-box-inner">
<span><p>Catastrophic forgetting is a notorious issue in deep learning, referring to
the fact that Deep Neural Networks (DNN) could forget the knowledge about
earlier tasks when learning new tasks. To address this issue, continual
learning has been developed to learn new tasks sequentially and perform
knowledge transfer from the old tasks to the new ones without forgetting. While
recent structure-based learning methods show the capability of alleviating the
forgetting problem, these methods start from a redundant full-size network and
require a complex learning process to gradually grow-and-prune or search the
network structure for each task, which is inefficient. To address this problem
and enable efficient network expansion for new tasks, we first develop a
learnable sparse growth method eliminating the additional pruning/searching
step in previous structure-based methods. Building on this learnable sparse
growth method, we then propose GROWN, a novel end-to-end continual learning
framework to dynamically grow the model only when necessary. Different from all
previous structure-based methods, GROWN starts from a small seed network,
instead of a full-sized one. We validate GROWN on multiple datasets against
state-of-the-art methods, which shows superior performance in both accuracy and
model size. For example, we achieve 1.0\% accuracy gain on average compared to
the current SOTA results on CIFAR-100 Superclass 20 tasks setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does deep learning model calibration improve performance in class-imbalanced medical image classification?. (arXiv:2110.00918v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00918">
<div class="article-summary-box-inner">
<span><p>In medical image classification tasks, it is common to find that the number
of normal samples far exceeds the number of abnormal samples. In such
class-imbalanced situations, reliable training of deep neural networks
continues to be a major challenge. Under these circumstances, the predicted
class confidence may be biased toward the majority class. Calibration has been
suggested to alleviate some of these effects. However, there is insufficient
analysis explaining when and whether calibrating a model would be beneficial in
improving performance. In this study, we perform a systematic analysis of the
effect of model calibration on its performance on two medical image modalities,
namely, chest X-rays (CXRs) and fundus images, using various deep learning
classifier backbones. For this, we study the following variations: (i) the
degree of imbalances in the dataset used for training; (ii) calibration
methods; and, (iii) two classification thresholds, namely, default decision
threshold of 0.5, and optimal threshold from precision-recall (PR) curves. Our
results indicate that at the default operating threshold of 0.5, the
performance achieved through calibration is significantly superior (p &lt; 0.05)
to an uncalibrated model. However, at the PR-guided threshold, these gains were
not significantly different (p &gt; 0.05). This finding holds for both image
modalities and at varying degrees of imbalance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention module improves both performance and interpretability of 4D fMRI decoding neural network. (arXiv:2110.00920v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00920">
<div class="article-summary-box-inner">
<span><p>Decoding brain cognitive states from neuroimaging signals is an important
topic in neuroscience. In recent years, deep neural networks (DNNs) have been
recruited for multiple brain state decoding and achieved good performance.
However, the open question of how to interpret the DNN black box remains
unanswered. Capitalizing on advances in machine learning, we integrated
attention modules into brain decoders to facilitate an in-depth interpretation
of DNN channels. A 4D convolution operation was also included to extract
temporo-spatial interaction within the fMRI signal. The experiments showed that
the proposed model obtains a very high accuracy (97.4%) and outperforms
previous researches on the 7 different task benchmarks from the Human
Connectome Project (HCP) dataset. The visualization analysis further
illustrated the hierarchical emergence of task-specific masks with depth.
Finally, the model was retrained to regress individual traits within the HCP
and to classify viewing images from the BOLD5000 dataset, respectively.
Transfer learning also achieves good performance. A further visualization
analysis shows that, after transfer learning, low-level attention masks
remained similar to the source domain, whereas high-level attention masks
changed adaptively. In conclusion, the proposed 4D model with attention module
performed well and facilitated interpretation of DNNs, which is helpful for
subsequent research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bounding Box Tightness Prior for Weakly Supervised Image Segmentation. (arXiv:2110.00934v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00934">
<div class="article-summary-box-inner">
<span><p>This paper presents a weakly supervised image segmentation method that adopts
tight bounding box annotations. It proposes generalized multiple instance
learning (MIL) and smooth maximum approximation to integrate the bounding box
tightness prior into the deep neural network in an end-to-end manner. In
generalized MIL, positive bags are defined by parallel crossing lines with a
set of different angles, and negative bags are defined as individual pixels
outside of any bounding boxes. Two variants of smooth maximum approximation,
i.e., $\alpha$-softmax function and $\alpha$-quasimax function, are exploited
to conquer the numeral instability introduced by maximum function of bag
prediction. The proposed approach was evaluated on two pubic medical datasets
using Dice coefficient. The results demonstrate that it outperforms the
state-of-the-art methods. The codes are available at
\url{https://github.com/wangjuan313/wsis-boundingbox}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anatomical Landmarks Localization for 3D Foot Point Clouds. (arXiv:2110.00937v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00937">
<div class="article-summary-box-inner">
<span><p>3D anatomical landmarks play an important role in health research. Their
automated prediction/localization thus becomes a vital task. In this paper, we
introduce a deformation method for 3D anatomical landmarks prediction. It
utilizes a source model with anatomical landmarks which are annotated by
clinicians, and deforms this model non-rigidly to match the target model. Two
constraints are introduced in the optimization, which are responsible for
alignment and smoothness, respectively. Experiments are performed on our
dataset and the results demonstrate the robustness of our method, and show that
it yields better performance than the state-of-the-art techniques in most
cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Artificial Intelligence For Breast Cancer Detection: Trends & Directions. (arXiv:2110.00942v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00942">
<div class="article-summary-box-inner">
<span><p>In the last decade, researchers working in the domain of computer vision and
Artificial Intelligence (AI) have beefed up their efforts to come up with the
automated framework that not only detects but also identifies stage of breast
cancer. The reason for this surge in research activities in this direction are
mainly due to advent of robust AI algorithms (deep learning), availability of
hardware that can train those robust and complex AI algorithms and
accessibility of large enough dataset required for training AI algorithms.
Different imaging modalities that have been exploited by researchers to
automate the task of breast cancer detection are mammograms, ultrasound,
magnetic resonance imaging, histopathological images or any combination of
them. This article analyzes these imaging modalities and presents their
strengths, limitations and enlists resources from where their datasets can be
accessed for research purpose. This article then summarizes AI and computer
vision based state-of-the-art methods proposed in the last decade, to detect
breast cancer using various imaging modalities. Generally, in this article we
have focused on to review frameworks that have reported results using
mammograms as it is most widely used breast imaging modality that serves as
first test that medical practitioners usually prescribe for the detection of
breast cancer. Second reason of focusing on mammogram imaging modalities is the
availability of its labeled datasets. Datasets availability is one of the most
important aspect for the development of AI based frameworks as such algorithms
are data hungry and generally quality of dataset affects performance of AI
based algorithms. In a nutshell, this research article will act as a primary
resource for the research community working in the field of automated breast
imaging analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate Cup-to-Disc Ratio Measurement with Tight Bounding Box Supervision in Fundus Photography. (arXiv:2110.00943v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00943">
<div class="article-summary-box-inner">
<span><p>The cup-to-disc ratio (CDR) is one of the most significant indicator for
glaucoma diagnosis. Different from the use of costly fully supervised learning
formulation with pixel-wise annotations in the literature, this study
investigates the feasibility of accurate CDR measurement in fundus images using
only tight bounding box supervision. For this purpose, we develop a two-task
network for accurate CDR measurement, one for weakly supervised image
segmentation, and the other for bounding-box regression. The weakly supervised
image segmentation task is implemented based on generalized multiple instance
learning formulation and smooth maximum approximation, and the bounding-box
regression task outputs class-specific bounding box prediction in a single
scale at the original image resolution. To get accurate bounding box
prediction, a class-specific bounding-box normalizer and an expected
intersection-over-union are proposed. In the experiments, the proposed approach
was evaluated by a testing set with 1200 images using CDR error and F1 score
for CDR measurement and dice coefficient for image segmentation. A grader study
was conducted to compare the performance of the proposed approach with those of
individual graders. The results demonstrate that the proposed approach
outperforms the state-of-the-art performance obtained from the fully supervised
image segmentation (FSIS) approach using pixel-wise annotation for CDR
measurement, which is also better than those of individual graders. It also
gets performance close to the state-of-the-art obtained from FSIS for optic cup
and disc segmentation, similar to those of individual graders. The codes are
available at \url{https://github.com/wangjuan313/CDRNet}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Segmentation for COVID-19 Infection Quantification on Longitudinal CT scans. (arXiv:2110.00948v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00948">
<div class="article-summary-box-inner">
<span><p>Consistent segmentation of COVID-19 patient's CT scans across multiple time
points is essential to assess disease progression and response to therapy
accurately. Existing automatic and interactive segmentation models for medical
images only use data from a single time point (static). However, valuable
segmentation information from previous time points is often not used to aid the
segmentation of a patient's follow-up scans. Also, fully automatic segmentation
techniques frequently produce results that would need further editing for
clinical use. In this work, we propose a new single network model for
interactive segmentation that fully utilizes all available past information to
refine the segmentation of follow-up scans. In the first segmentation round,
our model takes 3D volumes of medical images from two-time points (target and
reference) as concatenated slices with the additional reference time point
segmentation as a guide to segment the target scan. In subsequent segmentation
refinement rounds, user feedback in the form of scribbles that correct the
segmentation and the target's previous segmentation results are additionally
fed into the model. This ensures that the segmentation information from
previous refinement rounds is retained. Experimental results on our in-house
multiclass longitudinal COVID-19 dataset show that the proposed model
outperforms its static version and can assist in localizing COVID-19 infections
in patient's follow-up scans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Unsupervised Video Game Playstyle Metric via State Discretization. (arXiv:2110.00950v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00950">
<div class="article-summary-box-inner">
<span><p>On playing video games, different players usually have their own playstyles.
Recently, there have been great improvements for the video game AIs on the
playing strength. However, past researches for analyzing the behaviors of
players still used heuristic rules or the behavior features with the
game-environment support, thus being exhausted for the developers to define the
features of discriminating various playstyles. In this paper, we propose the
first metric for video game playstyles directly from the game observations and
actions, without any prior specification on the playstyle in the target game.
Our proposed method is built upon a novel scheme of learning discrete
representations that can map game observations into latent discrete states,
such that playstyles can be exhibited from these discrete states. Namely, we
measure the playstyle distance based on game observations aligned to the same
states. We demonstrate high playstyle accuracy of our metric in experiments on
some video game platforms, including TORCS, RGSK, and seven Atari games, and
for different agents including rule-based AI bots, learning-based AI bots, and
human players.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Representation Learning for Spatial Image Steganalysis. (arXiv:2110.00957v1 [cs.MM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00957">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a graph representation learning architecture for
spatial image steganalysis, which is motivated by the assumption that
steganographic modifications unavoidably distort the statistical
characteristics of the hidden graph features derived from cover images. In the
detailed architecture, we translate each image to a graph, where nodes
represent the patches of the image and edges indicate the local associations
between the patches. Each node is associated with a feature vector determined
from the corresponding patch by a shallow convolutional neural network (CNN)
structure. By feeding the graph to an attention network, the discriminative
features can be learned for efficient steganalysis. Experiments indicate that
the reported architecture achieves a competitive performance compared to the
benchmark CNN model, which has shown the potential of graph learning for
steganalysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fingerprint Matching using the Onion Peeling Approach and Turning Function. (arXiv:2110.00958v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00958">
<div class="article-summary-box-inner">
<span><p>Fingerprint, as one of the most popular and robust biometric traits, can be
used in automatic identification and verification systems to identify
individuals. Fingerprint matching is a vital and challenging issue in
fingerprint recognition systems. Most fingerprint matching algorithms are
minutiae-based. The minutiae in fingerprints can be determined by their
discontinuity. Ridge ending and ridge bifurcation are two frequently used
minutiae in most fingerprint-based matching algorithms.
</p>
<p>This paper presents a new minutiae-based fingerprint matching using the onion
peeling approach. In the proposed method, fingerprints are aligned to find the
matched minutiae points. Then, the nested convex polygons of matched minutiae
points are constructed and the comparison between peer-to-peer polygons is
performed by the turning function distance. Simplicity, accuracy, and low time
complexity of the Onion peeling approach are three important factors that make
it a standard method for fingerprint matching purposes. The performance of the
proposed algorithm is evaluated on the database $FVC2002$. The results show
that fingerprints of the same fingers have higher scores than different
fingers. Since the fingerprints that the difference between the number of their
layers is more than $2$ and the minutiae matching score lower than 0.15 are
ignored, the better results are obtained.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translating Images into Maps. (arXiv:2110.00966v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00966">
<div class="article-summary-box-inner">
<span><p>We approach instantaneous mapping, converting images to a top-down view of
the world, as a translation problem. We show how a novel form of transformer
network can be used to map from images and video directly to an overhead map or
bird's-eye-view (BEV) of the world, in a single end-to-end network. We assume a
1-1 correspondence between a vertical scanline in the image, and rays passing
through the camera location in an overhead map. This lets us formulate map
generation from an image as a set of sequence-to-sequence translations. Posing
the problem as translation allows the network to use the context of the image
when interpreting the role of each pixel. This constrained formulation, based
upon a strong physical grounding of the problem, leads to a restricted
transformer network that is convolutional in the horizontal direction only. The
structure allows us to make efficient use of data when training, and obtains
state-of-the-art results for instantaneous mapping of three large-scale
datasets, including a 15% and 30% relative gain against existing best
performing methods on the nuScenes and Argoverse datasets, respectively. We
make our code available on
https://github.com/avishkarsaha/translating-images-into-maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic-Guided Zero-Shot Learning for Low-Light Image/Video Enhancement. (arXiv:2110.00970v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00970">
<div class="article-summary-box-inner">
<span><p>Low-light images challenge both human perceptions and computer vision
algorithms. It is crucial to make algorithms robust to enlighten low-light
images for computational photography and computer vision applications such as
real-time detection and segmentation tasks. This paper proposes a
semantic-guided zero-shot low-light enhancement network which is trained in the
absence of paired images, unpaired datasets, and segmentation annotation.
Firstly, we design an efficient enhancement factor extraction network using
depthwise separable convolution. Secondly, we propose a recurrent image
enhancement network for progressively enhancing the low-light image. Finally,
we introduce an unsupervised semantic segmentation network for preserving the
semantic information. Extensive experiments on various benchmark datasets and a
low-light video demonstrate that our model outperforms the previous
state-of-the-art qualitatively and quantitatively. We further discuss the
benefits of the proposed method for low-light detection and segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Robust Scheme for 3D Point Cloud Copy Detection. (arXiv:2110.00972v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00972">
<div class="article-summary-box-inner">
<span><p>Most existing 3D geometry copy detection research focused on 3D watermarking,
which first embeds ``watermarks'' and then detects the added watermarks.
However, this kind of methods is non-straightforward and may be less robust to
attacks such as cropping and noise. In this paper, we focus on a fundamental
and practical research problem: judging whether a point cloud is plagiarized or
copied to another point cloud in the presence of several manipulations (e.g.,
similarity transformation, smoothing). We propose a novel method to address
this critical problem. Our key idea is first to align the two point clouds and
then calculate their similarity distance. We design three different measures to
compute the similarity. We also introduce two strategies to speed up our
method. Comprehensive experiments and comparisons demonstrate the effectiveness
and robustness of our method in estimating the similarity of two given 3D point
clouds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Unfolding Total Variation Network for Low-Light Image Enhancement. (arXiv:2110.00984v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00984">
<div class="article-summary-box-inner">
<span><p>Real-world low-light images suffer from two main degradations, namely,
inevitable noise and poor visibility. Since the noise exhibits different
levels, its estimation has been implemented in recent works when enhancing
low-light images from raw Bayer space. When it comes to sRGB color space, the
noise estimation becomes more complicated due to the effect of the image
processing pipeline. Nevertheless, most existing enhancing algorithms in sRGB
space only focus on the low visibility problem or suppress the noise under a
hypothetical noise level, leading them impractical due to the lack of
robustness. To address this issue,we propose an adaptive unfolding total
variation network (UTVNet), which approximates the noise level from the real
sRGB low-light image by learning the balancing parameter in the model-based
denoising method with total variation regularization. Meanwhile, we learn the
noise level map by unrolling the corresponding minimization process for
providing the inferences of smoothness and fidelity constraints. Guided by the
noise level map, our UTVNet can recover finer details and is more capable to
suppress noise in real captured low-light scenes. Extensive experiments on
real-world low-light images clearly demonstrate the superior performance of
UTVNet over state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Keypoint Communities. (arXiv:2110.00988v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00988">
<div class="article-summary-box-inner">
<span><p>We present a fast bottom-up method that jointly detects over 100 keypoints on
humans or objects, also referred to as human/object pose estimation. We model
all keypoints belonging to a human or an object -- the pose -- as a graph and
leverage insights from community detection to quantify the independence of
keypoints. We use a graph centrality measure to assign training weights to
different parts of a pose. Our proposed measure quantifies how tightly a
keypoint is connected to its neighborhood. Our experiments show that our method
outperforms all previous methods for human pose estimation with fine-grained
keypoint annotations on the face, the hands and the feet with a total of 133
keypoints. We also show that our method generalizes to car poses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Kinematic Probability Distributions for 3D Human Shape and Pose Estimation from Images in the Wild. (arXiv:2110.00990v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00990">
<div class="article-summary-box-inner">
<span><p>This paper addresses the problem of 3D human body shape and pose estimation
from an RGB image. This is often an ill-posed problem, since multiple plausible
3D bodies may match the visual evidence present in the input - particularly
when the subject is occluded. Thus, it is desirable to estimate a distribution
over 3D body shape and pose conditioned on the input image instead of a single
3D reconstruction. We train a deep neural network to estimate a hierarchical
matrix-Fisher distribution over relative 3D joint rotation matrices (i.e. body
pose), which exploits the human body's kinematic tree structure, as well as a
Gaussian distribution over SMPL body shape parameters. To further ensure that
the predicted shape and pose distributions match the visual evidence in the
input image, we implement a differentiable rejection sampler to impose a
reprojection loss between ground-truth 2D joint coordinates and samples from
the predicted distributions, projected onto the image plane. We show that our
method is competitive with the state-of-the-art in terms of 3D shape and pose
metrics on the SSP-3D and 3DPW datasets, while also yielding a structured
probability distribution over 3D body shape and pose, with which we can
meaningfully quantify prediction uncertainty and sample multiple plausible 3D
reconstructions to explain a given input image. Code is available at
https://github.com/akashsengupta1997/HierarchicalProbabilistic3DHuman .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Precise Object Placement with Pose Distance Estimations for Different Objects and Grippers. (arXiv:2110.00992v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00992">
<div class="article-summary-box-inner">
<span><p>This paper introduces a novel approach for the grasping and precise placement
of various known rigid objects using multiple grippers within highly cluttered
scenes. Using a single depth image of the scene, our method estimates multiple
6D object poses together with an object class, a pose distance for object pose
estimation, and a pose distance from a target pose for object placement for
each automatically obtained grasp pose with a single forward pass of a neural
network. By incorporating model knowledge into the system, our approach has
higher success rates for grasping than state-of-the-art model-free approaches.
Furthermore, our method chooses grasps that result in significantly more
precise object placements than prior model-based work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Samples Synthesizing and Training for Robust Visual Question Answering. (arXiv:2110.01013v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01013">
<div class="article-summary-box-inner">
<span><p>Today's VQA models still tend to capture superficial linguistic correlations
in the training set and fail to generalize to the test set with different QA
distributions. To reduce these language biases, recent VQA works introduce an
auxiliary question-only model to regularize the training of targeted VQA model,
and achieve dominating performance on diagnostic benchmarks for
out-of-distribution testing. However, due to complex model design, these
ensemble-based methods are unable to equip themselves with two indispensable
characteristics of an ideal VQA model: 1) Visual-explainable: The model should
rely on the right visual regions when making decisions. 2) Question-sensitive:
The model should be sensitive to the linguistic variations in questions. To
this end, we propose a novel model-agnostic Counterfactual Samples Synthesizing
and Training (CSST) strategy. After training with CSST, VQA models are forced
to focus on all critical objects and words, which significantly improves both
visual-explainable and question-sensitive abilities. Specifically, CSST is
composed of two parts: Counterfactual Samples Synthesizing (CSS) and
Counterfactual Samples Training (CST). CSS generates counterfactual samples by
carefully masking critical objects in images or words in questions and
assigning pseudo ground-truth answers. CST not only trains the VQA models with
both complementary samples to predict respective ground-truth answers, but also
urges the VQA models to further distinguish the original samples and
superficially similar counterfactual ones. To facilitate the CST training, we
propose two variants of supervised contrastive loss for VQA, and design an
effective positive and negative sample selection mechanism based on CSS.
Extensive experiments have shown the effectiveness of CSST. Particularly, by
building on top of model LMH+SAR, we achieve record-breaking performance on all
OOD benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EAR-U-Net: EfficientNet and attention-based residual U-Net for automatic liver segmentation in CT. (arXiv:2110.01014v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01014">
<div class="article-summary-box-inner">
<span><p>Purpose: This paper proposes a new network framework called EAR-U-Net, which
leverages EfficientNetB4, attention gate, and residual learning techniques to
achieve automatic and accurate liver segmentation. Methods: The proposed method
is based on the U-Net framework. First, we use EfficientNetB4 as the encoder to
extract more feature information during the encoding stage. Then, an attention
gate is introduced in the skip connection to eliminate irrelevant regions and
highlight features of a specific segmentation task. Finally, to alleviate the
problem of gradient vanishment, we replace the traditional convolution of the
decoder with a residual block to improve the segmentation accuracy. Results: We
verified the proposed method on the LiTS17 and SLiver07 datasets and compared
it with classical networks such as FCN, U-Net, Attention U-Net, and Attention
Res-U-Net. In the Sliver07 evaluation, the proposed method achieved the best
segmentation performance on all five standard metrics. Meanwhile, in the LiTS17
assessment, the best performance is obtained except for a slight inferior on
RVD. Moreover, we also participated in the MICCIA-LiTS17 challenge, and the
Dice per case score was 0.952. Conclusion: The proposed method's qualitative
and quantitative results demonstrated its applicability in liver segmentation
and proved its good prospect in computer-assisted liver segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatio-Temporal Video Representation Learning for AI Based Video Playback Style Prediction. (arXiv:2110.01015v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01015">
<div class="article-summary-box-inner">
<span><p>Ever-increasing smartphone-generated video content demands intelligent
techniques to edit and enhance videos on power-constrained devices. Most of the
best performing algorithms for video understanding tasks like action
recognition, localization, etc., rely heavily on rich spatio-temporal
representations to make accurate predictions. For effective learning of the
spatio-temporal representation, it is crucial to understand the underlying
object motion patterns present in the video. In this paper, we propose a novel
approach for understanding object motions via motion type classification. The
proposed motion type classifier predicts a motion type for the video based on
the trajectories of the objects present. Our classifier assigns a motion type
for the given video from the following five primitive motion classes: linear,
projectile, oscillatory, local and random. We demonstrate that the
representations learned from the motion type classification generalizes well
for the challenging downstream task of video retrieval. Further, we proposed a
recommendation system for video playback style based on the motion type
classifier predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of Viral Pneumonia X-ray Images with the Aucmedi Framework. (arXiv:2110.01017v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01017">
<div class="article-summary-box-inner">
<span><p>In this work we use the AUCMEDI-Framework to train a deep neural network to
classify chest X-ray images as either normal or viral pneumonia. Stratified
k-fold cross-validation with k=3 is used to generate the validation-set and 15%
of the data are set aside for the evaluation of the models of the different
folds and ensembles each. A random-forest ensemble as well as a
Soft-Majority-Vote ensemble are built from the predictions of the different
folds. Evaluation metrics (Classification-Report, macro f1-scores,
Confusion-Matrices, ROC-Curves) of the individual folds and the ensembles show
that the classifier works well. Finally Grad-CAM and LIME explainable
artificial intelligence (XAI) algorithms are applied to visualize the image
features that are most important for the prediction. For Grad-CAM the heatmaps
of the three folds are furthermore averaged for all images in order to
calculate a mean XAI-heatmap. As the heatmaps of the different folds for most
images differ only slightly this averaging procedure works well. However, only
medical professionals can evaluate the quality of the features marked by the
XAI. A comparison of the evaluation metrics with metrics of standard procedures
such as PCR would also be important. Further limitations are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DARDet: A Dense Anchor-free Rotated Object Detector in Aerial Images. (arXiv:2110.01025v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01025">
<div class="article-summary-box-inner">
<span><p>Rotated object detection in aerial images has received increasing attention
for a wide range of applications. However, it is also a challenging task due to
the huge variations of scale, rotation, aspect ratio, and densely arranged
targets. Most existing methods heavily rely on a large number of pre-defined
anchors with different scales, angles, and aspect ratios, and are optimized
with a distance loss. Therefore, these methods are sensitive to anchor
hyper-parameters and easily suffer from performance degradation caused by
boundary discontinuity. To handle this problem, in this paper, we propose a
dense anchor-free rotated object detector (DARDet) for rotated object detection
in aerial images. Our DARDet directly predicts five parameters of rotated boxes
at each foreground pixel of feature maps. We design a new alignment convolution
module to extracts aligned features and introduce a PIoU loss for precise and
stable regression. Our method achieves state-of-the-art performance on three
commonly used aerial objects datasets (i.e., DOTA, HRSC2016, and UCAS-AOD)
while keeping high efficiency. Code is available at
https://github.com/zf020114/DARDet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal Face Restoration With Memorized Modulation. (arXiv:2110.01033v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01033">
<div class="article-summary-box-inner">
<span><p>Blind face restoration (BFR) is a challenging problem because of the
uncertainty of the degradation patterns. This paper proposes a Restoration with
Memorized Modulation (RMM) framework for universal BFR in diverse degraded
scenes and heterogeneous domains. We apply random noise as well as unsupervised
wavelet memory to adaptively modulate the face-enhancement generator,
considering attentional denormalization in both layer and instance levels.
Specifically, in the training stage, the low-level spatial feature embedding,
the wavelet memory embedding obtained by wavelet transformation of the
high-resolution image, as well as the disentangled high-level noise embeddings
are integrated, with the guidance of attentional maps generated from layer
normalization, instance normalization, and the original feature map. These
three embeddings are respectively associated with the spatial content,
high-frequency texture details, and a learnable universal prior against other
blind image degradation patterns. We store the spatial feature of the
low-resolution image and the corresponding wavelet style code as key and value
in the memory unit, respectively. In the test stage, the wavelet memory value
whose corresponding spatial key is the most matching with that of the inferred
image is retrieved to modulate the generator. Moreover, the universal prior
learned from the random noise has been memorized by training the modulation
network. Experimental results show the superiority of the proposed method
compared with the state-of-the-art methods, and a good generalization in the
wild.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAP-Net: Region Attention Predictive Network for Precipitation Nowcasting. (arXiv:2110.01035v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01035">
<div class="article-summary-box-inner">
<span><p>Natural disasters caused by heavy rainfall often cost huge loss of life and
property. To avoid it, the task of precipitation nowcasting is imminent. To
solve the problem, increasingly deep learning methods are proposed to forecast
future radar echo images and then the predicted maps have converted the
distribution of rainfall. The prevailing spatiotemporal sequence prediction
methods apply ConvRNN structure which combines the Convolution and Recurrent
neural network. Although improvements based on ConvRNN achieve remarkable
success, these methods ignore capturing both local and global spatial features
simultaneously, which degrades the nowcasting in the region of heavy rainfall.
To address this issue, we proposed the Region Attention Block (RAB) and embed
it into ConvRNN to enhance the forecast in the area with strong rainfall.
Besides, the ConvRNN models are hard to memory longer history representations
with limited parameters. Considering it, we propose Recall Attention Mechanism
(RAM) to improve the prediction. By preserving longer temporal information, RAM
contributes to the forecasting, especially in the middle rainfall intensity.
The experiments show that the proposed model Region Attention Predictive
Network (RAP-Net) has outperformed the state-of-art method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Marginally calibrated response distributions for end-to-end learning in autonomous driving. (arXiv:2110.01050v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01050">
<div class="article-summary-box-inner">
<span><p>End-to-end learners for autonomous driving are deep neural networks that
predict the instantaneous steering angle directly from images of the
ahead-lying street. These learners must provide reliable uncertainty estimates
for their predictions in order to meet safety requirements and initiate a
switch to manual control in areas of high uncertainty. Yet end-to-end learners
typically only deliver point predictions, since distributional predictions are
associated with large increases in training time or additional computational
resources during prediction. To address this shortcoming we investigate
efficient and scalable approximate inference for the implicit copula neural
linear model of Klein, Nott and Smith (2021) in order to quantify uncertainty
for the predictions of end-to-end learners. The result are densities for the
steering angle that are marginally calibrated, i.e.~the average of the
estimated densities equals the empirical distribution of steering angles. To
ensure the scalability to large $n$ regimes, we develop efficient estimation
based on variational inference as a fast alternative to computationally
intensive, exact inference via Hamiltonian Monte Carlo. We demonstrate the
accuracy and speed of the variational approach in comparison to Hamiltonian
Monte Carlo on two end-to-end learners trained for highway driving using the
comma2k19 data set. The implicit copula neural linear model delivers accurate
calibration, high-quality prediction intervals and allows to identify
overconfident learners. Our approach also contributes to the explainability of
black-box end-to-end learners, since predictive densities can be used to
understand which steering actions the end-to-end learner sees as valid.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learn then Test: Calibrating Predictive Algorithms to Achieve Risk Control. (arXiv:2110.01052v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01052">
<div class="article-summary-box-inner">
<span><p>We introduce Learn then Test (LTT), a framework for calibrating machine
learning models so that their predictions satisfy explicit, finite-sample
statistical guarantees regardless of the underlying model and (unknown)
data-generating distribution. The framework addresses, among other examples,
false discovery rate control in multi-label classification,
intersection-over-union control in instance segmentation, and the simultaneous
control of the type-1 error of outlier detection and confidence set coverage in
classification or regression. To accomplish this, we solve a key technical
challenge: the control of arbitrary risks that are not necessarily monotonic.
Our main insight is to reframe the risk-control problem as multiple hypothesis
testing, enabling techniques and mathematical arguments different from those in
the previous literature. We use our framework to provide new calibration
methods for several core machine learning tasks with detailed worked examples
in computer vision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Approach for Image Authentication Framework for Media Forensics Purpose. (arXiv:2110.01065v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01065">
<div class="article-summary-box-inner">
<span><p>With the increasing widely spread digital media become using in most fields
such as medical care, Oceanography, Exploration processing, security purpose,
military fields and astronomy, evidence in criminals and more vital fields and
then digital Images become have different appreciation values according to what
is important of carried information by digital images. Due to the easy
manipulation property of digital images (by proper computer software) makes us
doubtful when are juries using digital images as forensic evidence in courts,
especially, if the digital images are main evidence to demonstrate the
relationship between suspects and the criminals. Obviously, here demonstrate
importance of data Originality Protection methods to detect unauthorized
process like modification or duplication and then enhancement protection of
evidence to guarantee rights of incriminatory. In this paper, we shall
introduce a novel digital forensic security framework for digital image
authentication and originality identification techniques and related
methodologies, algorithms and protocols that are applied on camera captured
images. The approach depends on implanting secret code into RGB images that
should indicate any unauthorized modification on the image under investigation.
The secret code generation depends mainly on two main parameter types, namely
the image characteristics and capturing device identifier. In this paper, the
architecture framework will be analyzed, explained and discussed together with
the associated protocols, algorithms and methodologies. Also, the secret code
deduction and insertion techniques will be analyzed and discussed, in addition
to the image benchmarking and quality testing techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhance Images as You Like with Unpaired Learning. (arXiv:2110.01161v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01161">
<div class="article-summary-box-inner">
<span><p>Low-light image enhancement exhibits an ill-posed nature, as a given image
may have many enhanced versions, yet recent studies focus on building a
deterministic mapping from input to an enhanced version. In contrast, we
propose a lightweight one-path conditional generative adversarial network
(cGAN) to learn a one-to-many relation from low-light to normal-light image
space, given only sets of low- and normal-light training images without any
correspondence. By formulating this ill-posed problem as a modulation code
learning task, our network learns to generate a collection of enhanced images
from a given input conditioned on various reference images. Therefore our
inference model easily adapts to various user preferences, provided with a few
favorable photos from each user. Our model achieves competitive visual and
quantitative results on par with fully supervised methods on both noisy and
clean datasets, while being 6 to 10 times lighter than state-of-the-art
generative adversarial networks (GANs) approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Kernel Representation for Image Reconstruction in PET. (arXiv:2110.01174v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01174">
<div class="article-summary-box-inner">
<span><p>Image reconstruction for positron emission tomography (PET) is challenging
because of the ill-conditioned tomographic problem and low counting statistics.
Kernel methods address this challenge by using kernel representation to
incorporate image prior information in the forward model of iterative PET image
reconstruction. Existing kernel methods construct the kernels commonly using an
empirical process, which may lead to suboptimal performance. In this paper, we
describe the equivalence between the kernel representation and a trainable
neural network model. A deep kernel method is proposed by exploiting deep
neural networks to enable an automated learning of an optimized kernel model.
The proposed method is directly applicable to single subjects. The training
process utilizes available image prior data to seek the best way to form a set
of robust kernels optimally rather than empirically. The results from computer
simulations and a real patient dataset demonstrate that the proposed deep
kernel method can outperform existing kernel method and neural network method
for dynamic PET image reconstruction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BPFNet: A Unified Framework for Bimodal Palmprint Alignment and Fusion. (arXiv:2110.01179v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01179">
<div class="article-summary-box-inner">
<span><p>Bimodal palmprint recognition leverages palmprint and palm vein images
simultaneously,which achieves high accuracy by multi-model information fusion
and has strong anti-falsification property. In the recognition pipeline, the
detection of palm and the alignment of region-of-interest (ROI) are two crucial
steps for accurate matching. Most existing methods localize palm ROI by
keypoint detection algorithms, however the intrinsic difficulties of keypoint
detection tasks make the results unsatisfactory. Besides, the ROI alignment and
fusion algorithms at image-level are not fully investigaged.To bridge the gap,
in this paper, we propose Bimodal Palmprint Fusion Network (BPFNet) which
focuses on ROI localization, alignment and bimodal image fusion.BPFNet is an
end-to-end framework containing two subnets: The detection network directly
regresses the palmprint ROIs based on bounding box prediction and conducts
alignment by translation estimation.In the downstream,the bimodal fusion
network implements bimodal ROI image fusion leveraging a novel proposed
cross-modal selection scheme. To show the effectiveness of BPFNet,we carry out
experiments on the large-scale touchless palmprint datasets CUHKSZ-v1 and
TongJi and the proposed method achieves state-of-the-art performances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adding Quaternion Representations to Attention Networks for Classification. (arXiv:2110.01185v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01185">
<div class="article-summary-box-inner">
<span><p>This paper introduces a novel modification to axial-attention networks to
improve their image classification accuracy. The modification involves
supplementing axial-attention modules with quaternion input representations to
improve image classification accuracy. We chose axial-attention networks
because they factor 2D attention operations into two consecutive 1D operations
(similar to separable convolution) and are thus less resource intensive than
non-axial attention networks. We chose a quaternion encoder because of they
share weights across four real-valued input channels and the weight-sharing has
been shown to produce a more interlinked/interwoven output representation. We
hypothesize that an attention module can be more effective using these
interlinked representations as input. Our experiments support this hypothesis
as reflected in the improved classification accuracy compared to standard
axial-attention networks. We think this happens because the attention modules
have better input representations to work with.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Structural Representations for Recipe Generation and Food Retrieval. (arXiv:2110.01209v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01209">
<div class="article-summary-box-inner">
<span><p>Food is significant to human daily life. In this paper, we are interested in
learning structural representations for lengthy recipes, that can benefit the
recipe generation and food retrieval tasks. We mainly investigate an open
research task of generating cooking instructions based on food images and
ingredients, which is similar to the image captioning task. However, compared
with image captioning datasets, the target recipes are lengthy paragraphs and
do not have annotations on structure information. To address the above
limitations, we propose a novel framework of Structure-aware Generation Network
(SGN) to tackle the food recipe generation task. Our approach brings together
several novel ideas in a systematic framework: (1) exploiting an unsupervised
learning approach to obtain the sentence-level tree structure labels before
training; (2) generating trees of target recipes from images with the
supervision of tree structure labels learned from (1); and (3) integrating the
inferred tree structures into the recipe generation procedure. Our proposed
model can produce high-quality and coherent recipes, and achieve the
state-of-the-art performance on the benchmark Recipe1M dataset. We also
validate the usefulness of our learned tree structures in the food cross-modal
retrieval task, where the proposed model with tree representations can
outperform state-of-the-art benchmark results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Max and Coincidence Neurons in Neural Networks. (arXiv:2110.01218v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01218">
<div class="article-summary-box-inner">
<span><p>Network design has been a central topic in machine learning. Large amounts of
effort have been devoted towards creating efficient architectures through
manual exploration as well as automated neural architecture search. However,
todays architectures have yet to consider the diversity of neurons and the
existence of neurons with specific processing functions. In this work, we
optimize networks containing models of the max and coincidence neurons using
neural architecture search, and analyze the structure, operations, and neurons
of optimized networks to develop a signal-processing ResNet. The developed
network achieves an average of 2% improvement in accuracy and a 25% improvement
in network size across a variety of datasets, demonstrating the importance of
neuronal functions in creating compact, efficient networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Distillation for Human Action Anticipation. (arXiv:1904.04868v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.04868">
<div class="article-summary-box-inner">
<span><p>We consider the task of training a neural network to anticipate human actions
in video. This task is challenging given the complexity of video data, the
stochastic nature of the future, and the limited amount of annotated training
data. In this paper, we propose a novel knowledge distillation framework that
uses an action recognition network to supervise the training of an action
anticipation network, guiding the latter to attend to the relevant information
needed for correctly anticipating the future actions. This framework is
possible thanks to a novel loss function to account for positional shifts of
semantic concepts in a dynamic video. The knowledge distillation framework is a
form of self-supervised learning, and it takes advantage of unlabeled data.
Experimental results on JHMDB and EPIC-KITCHENS dataset show the effectiveness
of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A new approach for measuring semantic similarity of ontology concepts using dynamic programming. (arXiv:1904.08501v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.08501">
<div class="article-summary-box-inner">
<span><p>Today, with the emergence of semantic web technologies and increasing of
information quantity, searching for information based on the semantic web has
become a fertile area of research. For this reason, a large number of studies
are performed based on the measure of semantic similarity. Therefore, in this
paper, we propose a new method of semantic similarity measuring which uses the
dynamic programming to compute the semantic distance between any two concepts
defined in the same hierarchy of ontology. Then, we base on this result to
compute the semantic similarity. Finally, we present an experimental comparison
between our method and other methods of similarity measuring. Where we will
show the limits of these methods and how we avoid them with our method. This
one bases on a function of weight allocation, which allows finding different
rate of semantic similarity between a given concept and two other sibling
concepts which is impossible using the other methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Merging-ISP: Multi-Exposure High Dynamic Range Image Signal Processing. (arXiv:1911.04762v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.04762">
<div class="article-summary-box-inner">
<span><p>High dynamic range (HDR) imaging combines multiple images with different
exposure times into a single high-quality image. The image signal processing
pipeline (ISP) is a core component in digital cameras to perform these
operations. It includes demosaicing of raw color filter array (CFA) data at
different exposure times, alignment of the exposures, conversion to HDR domain,
and exposure merging into an HDR image. Traditionally, such pipelines cascade
algorithms that address these individual subtasks. However, cascaded designs
suffer from error propagation, since simply combining multiple steps is not
necessarily optimal for the entire imaging task. This paper proposes a
multi-exposure HDR image signal processing pipeline (Merging-ISP) to jointly
solve all these subtasks. Our pipeline is modeled by a deep neural network
architecture. As such, it is end-to-end trainable, circumvents the use of
hand-crafted and potentially complex algorithms, and mitigates error
propagation. Merging-ISP enables direct reconstructions of HDR images of
dynamic scenes from multiple raw CFA images with different exposures. We
compare Merging-ISP against several state-of-the-art cascaded pipelines. The
proposed method provides HDR reconstructions of high perceptual quality and it
quantitatively outperforms competing ISPs by more than 1 dB in terms of PSNR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detection and Tracking Meet Drones Challenge. (arXiv:2001.06303v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.06303">
<div class="article-summary-box-inner">
<span><p>Drones, or general UAVs, equipped with cameras have been fast deployed with a
wide range of applications, including agriculture, aerial photography, and
surveillance. Consequently, automatic understanding of visual data collected
from drones becomes highly demanding, bringing computer vision and drones more
and more closely. To promote and track the developments of object detection and
tracking algorithms, we have organized three challenge workshops in conjunction
with ECCV 2018, ICCV 2019 and ECCV 2020, attracting more than 100 teams around
the world. We provide a large-scale drone captured dataset, VisDrone, which
includes four tracks, i.e., (1) image object detection, (2) video object
detection, (3) single object tracking, and (4) multi-object tracking. In this
paper, we first present a thorough review of object detection and tracking
datasets and benchmarks, and discuss the challenges of collecting large-scale
drone-based object detection and tracking datasets with fully manual
annotations. After that, we describe our VisDrone dataset, which is captured
over various urban/suburban areas of 14 different cities across China from
North to South. Being the largest such dataset ever published, VisDrone enables
extensive evaluation and investigation of visual analysis algorithms for the
drone platform. We provide a detailed analysis of the current state of the
field of large-scale object detection and tracking on drones, and conclude the
challenge as well as propose future directions. We expect the benchmark largely
boost the research and development in video analysis on drone platforms. All
the datasets and experimental results can be downloaded from
https://github.com/VisDrone/VisDrone-Dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VPR-Bench: An Open-Source Visual Place Recognition Evaluation Framework with Quantifiable Viewpoint and Appearance Change. (arXiv:2005.08135v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.08135">
<div class="article-summary-box-inner">
<span><p>Visual Place Recognition (VPR) is the process of recognising a previously
visited place using visual information, often under varying appearance
conditions and viewpoint changes and with computational constraints. VPR is
related to the concepts of localisation, loop closure, image retrieval and is a
critical component of many autonomous navigation systems ranging from
autonomous vehicles to drones and computer vision systems. While the concept of
place recognition has been around for many years, VPR research has grown
rapidly as a field over the past decade due to improving camera hardware and
its potential for deep learning-based techniques, and has become a widely
studied topic in both the computer vision and robotics communities. This growth
however has led to fragmentation and a lack of standardisation in the field,
especially concerning performance evaluation. Moreover, the notion of viewpoint
and illumination invariance of VPR techniques has largely been assessed
qualitatively and hence ambiguously in the past. In this paper, we address
these gaps through a new comprehensive open-source framework for assessing the
performance of VPR techniques, dubbed "VPR-Bench". VPR-Bench (Open-sourced at:
https://github.com/MubarizZaffar/VPR-Bench) introduces two much-needed
capabilities for VPR researchers: firstly, it contains a benchmark of 12
fully-integrated datasets and 10 VPR techniques, and secondly, it integrates a
comprehensive variation-quantified dataset for quantifying viewpoint and
illumination invariance. We apply and analyse popular evaluation metrics for
VPR from both the computer vision and robotics communities, and discuss how
these different metrics complement and/or replace each other, depending upon
the underlying applications and system requirements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-View Fine-grained Classification of Plant Species. (arXiv:2005.09110v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.09110">
<div class="article-summary-box-inner">
<span><p>Automatic plant classification is a challenging problem due to the wide
biodiversity of the existing plant species in a fine-grained scenario. Powerful
deep learning architectures have been used to improve the classification
performance in such a fine-grained problem, but usually building models that
are highly dependent on a large training dataset and which are not scalable. In
this paper, we propose a novel method based on a two-view leaf image
representation and a hierarchical classification strategy for fine-grained
recognition of plant species. It uses the botanical taxonomy as a basis for a
coarse-to-fine strategy applied to identify the plant genus and species. The
two-view representation provides complementary global and local features of
leaf images. A deep metric based on Siamese convolutional neural networks is
used to reduce the dependence on a large number of training samples and make
the method scalable to new plant species. The experimental results on two
challenging fine-grained datasets of leaf images (i.e. LifeCLEF 2015 and
LeafSnap) have shown the effectiveness of the proposed method, which achieved
recognition accuracy of 0.87 and 0.96 respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cloud Transformers: A Universal Approach To Point Cloud Processing Tasks. (arXiv:2007.11679v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.11679">
<div class="article-summary-box-inner">
<span><p>We present a new versatile building block for deep point cloud processing
architectures that is equally suited for diverse tasks. This building block
combines the ideas of spatial transformers and multi-view convolutional
networks with the efficiency of standard convolutional layers in two and
three-dimensional dense grids. The new block operates via multiple parallel
heads, whereas each head differentiably rasterizes feature representations of
individual points into a low-dimensional space, and then uses dense convolution
to propagate information across points. The results of the processing of
individual heads are then combined together resulting in the update of point
features. Using the new block, we build architectures for both discriminative
(point cloud segmentation, point cloud classification) and generative (point
cloud inpainting and image-based point cloud reconstruction) tasks. The
resulting architectures achieve state-of-the-art performance for these tasks,
demonstrating the versatility of the new block for point cloud processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Families In Wild Multimedia: A Multimodal Database for Recognizing Kinship. (arXiv:2007.14509v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14509">
<div class="article-summary-box-inner">
<span><p>Kinship, a soft biometric detectable in media, is fundamental for a myriad of
use-cases. Despite the difficulty of detecting kinship, annual data challenges
using still-images have consistently improved performances and attracted new
researchers. Now, systems reach performance levels unforeseeable a decade ago,
closing in on performances acceptable to deploy in practice. Like other
biometric tasks, we expect systems can receive help from other modalities. We
hypothesize that adding modalities to FIW, which has only still-images, will
improve performance. Thus, to narrow the gap between research and reality and
enhance the power of kinship recognition systems, we extend FIW with multimedia
(MM) data (i.e., video, audio, and text captions). Specifically, we introduce
the first publicly available multi-task MM kinship dataset. To build FIW MM, we
developed machinery to automatically collect, annotate, and prepare the data,
requiring minimal human input and no financial cost. The proposed MM corpus
allows the problem statements to be more realistic template-based protocols. We
show significant improvements in all benchmarks with the added modalities. The
results highlight edge cases to inspire future research with different areas of
improvement. FIW MM supplies the data needed to increase the potential of
automated systems to detect kinship in MM. It also allows experts from diverse
fields to collaborate in novel ways.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuous Color Transfer. (arXiv:2008.13626v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.13626">
<div class="article-summary-box-inner">
<span><p>Color transfer, which plays a key role in image editing, has attracted
noticeable attention recently. It has remained a challenge to date due to
various issues such as time-consuming manual adjustments and prior segmentation
issues. In this paper, we propose to model color transfer under a probability
framework and cast it as a parameter estimation problem. In particular, we
relate the transferred image with the example image under the Gaussian Mixture
Model (GMM) and regard the transferred image color as the GMM centroids. We
employ the Expectation-Maximization (EM) algorithm (E-step and M-step) for
optimization. To better preserve gradient information, we introduce a Laplacian
based regularization term to the objective function at the M-step which is
solved by deriving a gradient descent algorithm. Given the input of a source
image and an example image, our method is able to generate continuous color
transfer results with increasing EM iterations. Various experiments show that
our approach generally outperforms other competitive color transfer methods,
both visually and quantitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grow-Push-Prune: aligning deep discriminants for effective structural network compression. (arXiv:2009.13716v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13716">
<div class="article-summary-box-inner">
<span><p>Most of today's popular deep architectures are hand-engineered to be
generalists. However, this design procedure usually leads to massive redundant,
useless, or even harmful features for specific tasks. Unnecessarily high
complexities render deep nets impractical for many real-world applications,
especially those without powerful GPU support. In this paper, we attempt to
derive task-dependent compact models from a deep discriminant analysis
perspective. We propose an iterative and proactive approach for classification
tasks which alternates between (1) a pushing step, with an objective to
simultaneously maximize class separation, penalize co-variances, and push deep
discriminants into alignment with a compact set of neurons, and (2) a pruning
step, which discards less useful or even interfering neurons. Deconvolution is
adopted to reverse 'unimportant' filters' effects and recover useful
contributing sources. A simple network growing strategy based on the basic
Inception module is proposed for challenging tasks requiring larger capacity
than what the base net can offer. Experiments on the MNIST, CIFAR10, and
ImageNet datasets demonstrate our approach's efficacy. On ImageNet, by pushing
and pruning our grown Inception-88 model, we achieve more accurate models than
Inception nets generated during growing, residual nets, and popular compact
nets at similar sizes. We also show that our grown Inception nets (without
hard-coded dimension alignment) clearly outperform residual nets of similar
complexities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmark for Anonymous Video Analytics. (arXiv:2009.14684v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14684">
<div class="article-summary-box-inner">
<span><p>Out-of-home audience measurement aims to count and characterize the people
exposed to advertising content in the physical world. While audience
measurement solutions based on computer vision are of increasing interest, no
commonly accepted benchmark exists to evaluate and compare their performance.
In this paper, we propose the first benchmark for digital out-of-home audience
measurement that evaluates the vision-based tasks of audience localization and
counting, and audience demographics. The benchmark is composed of a novel,
dataset captured at multiple locations and a set of performance measures. Using
the benchmark, we present an in-depth comparison of eight open-source
algorithms on four hardware platforms with GPU and CPU-optimized inferences and
of two commercial off-the-shelf solutions for localization, count, age, and
gender estimation. This benchmark and related open-source codes are available
at <a href="http://ava.eecs.qmul.ac.uk.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exposure Trajectory Recovery from Motion Blur. (arXiv:2010.02484v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02484">
<div class="article-summary-box-inner">
<span><p>Motion blur in dynamic scenes is an important yet challenging research topic.
Recently, deep learning methods have achieved impressive performance for
dynamic scene deblurring. However, the motion information contained in a blurry
image has yet to be fully explored and accurately formulated because: (i) the
ground truth of dynamic motion is difficult to obtain; (ii) the temporal
ordering is destroyed during the exposure; and (iii) the motion estimation from
a blurry image is highly ill-posed. By revisiting the principle of camera
exposure, motion blur can be described by the relative motions of sharp content
with respect to each exposed position. In this paper, we define exposure
trajectories, which represent the motion information contained in a blurry
image and explain the causes of motion blur. A novel motion offset estimation
framework is proposed to model pixel-wise displacements of the latent sharp
image at multiple timepoints. Under mild constraints, our method can recover
dense, (non-)linear exposure trajectories, which significantly reduce temporal
disorder and ill-posed problems. Finally, experiments demonstrate that the
recovered exposure trajectories not only capture accurate and interpretable
motion information from a blurry image, but also benefit motion-aware image
deblurring and warping-based video extraction tasks. Codes are available on
https://github.com/yjzhang96/Motion-ETR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Action Understanding. (arXiv:2010.06647v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06647">
<div class="article-summary-box-inner">
<span><p>Many believe that the successes of deep learning on image understanding
problems can be replicated in the realm of video understanding. However, due to
the scale and temporal nature of video, the span of video understanding
problems and the set of proposed deep learning solutions is arguably wider and
more diverse than those of their 2D image siblings. Finding, identifying, and
predicting actions are a few of the most salient tasks in this emerging and
rapidly evolving field. With a pedagogical emphasis, this tutorial introduces
and systematizes fundamental topics, basic concepts, and notable examples in
supervised video action understanding. Specifically, we clarify a taxonomy of
action problems, catalog and highlight video datasets, describe common video
data preparation methods, present the building blocks of state-of-the art deep
learning model architectures, and formalize domain-specific metrics to baseline
proposed solutions. This tutorial is intended to be accessible to a general
computer science audience and assumes a conceptual understanding of supervised
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Psychophysical Oriented Saliency Map Prediction Model. (arXiv:2011.04076v11 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04076">
<div class="article-summary-box-inner">
<span><p>Visual attention is one of the most significant characteristics for selecting
and understanding the outside redundancy world. The human vision system cannot
process all information simultaneously, due to the visual information
bottleneck. In order to reduce the redundant input of visual information, the
human visual system mainly focuses on dominant parts of scenes. This is
commonly known as visual saliency map prediction. This paper proposed a new
psychophysical saliency prediction architecture, WECSF, inspired by
multi-channel model of visual cortex functioning in humans. The model consists
of opponent color channels, wavelet transform, wavelet energy map, and contrast
sensitivity function for extracting low-level image features and providing
maximum approximation to the human visual system. The proposed model is
evaluated using several datasets, including the MIT1003, MIT300, TORONTO,
SID4VAM, and UCF Sports datasets. We also quantitatively and qualitatively
compare the saliency prediction performance with that of other state-of-the-art
models. Our model achieved strongly stable and better performance with
different metrics on nature images, psychophysical synthetic images and dynamic
videos. Additionally, we found that Fourier and spectral-inspired saliency
prediction models outperformed other state-of-the-art non-neural network and
even deep neural network models on psychophysical synthetic images, it can be
explained and supported the Fourier Vision Hypothesis. Finally, the proposed
model could be used as a computational model of primate vision system and help
us understand mechanism of vision system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Representations of Positive Functions via First and Second-Order Pseudo-Mirror Descent. (arXiv:2011.07142v2 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07142">
<div class="article-summary-box-inner">
<span><p>We consider expected risk minimization when the range of the estimator is
required to be nonnegative, motivated by the settings of maximum likelihood
estimation (MLE) and trajectory optimization. To facilitate nonlinear
interpolation, we hypothesize that search is conducted over a Reproducing
Kernel Hilbert Space (RKHS). To solve it, we develop first and second-order
variants of stochastic mirror descent employing (i) pseudo-gradients and (ii)
complexity-reducing projections. Compressive projection in first-order scheme
is executed via kernel orthogonal matching pursuit (KOMP), and overcome the
fact that the vanilla RKHS parameterization grows unbounded with time.
Moreover, pseudo-gradients are needed when stochastic estimates of the gradient
of the expected cost are only computable up to some numerical errors, which
arise in, e.g., integral approximations. The second-order scheme develops a
Hessian inverse approximation via recursively averaged pseudo-gradient outer
products. For the first-order scheme, we establish tradeoffs between accuracy
of convergence in mean and the projection budget parameter under constant
step-size and compression budget are established, as well as non-asymptotic
bounds on the model complexity. Analogous convergence results are established
for the second-order scheme under an additional eigenvalue decay condition on
the Hessian of the optimal RKHS element. Experiments demonstrate favorable
performance on inhomogeneous Poisson Process intensity estimation in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CM-Net: Concentric Mask based Arbitrary-Shaped Text Detection. (arXiv:2011.14714v7 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14714">
<div class="article-summary-box-inner">
<span><p>Recently fast arbitrary-shaped text detection has become an attractive
research topic. However, most existing methods are non-real-time, which may
fall short in intelligent systems. Although a few real-time text methods are
proposed, the detection accuracy is far behind non-real-time methods. To
improve the detection accuracy and speed simultaneously, we propose a novel
fast and accurate text detection framework, namely CM-Net, which is constructed
based on a new text representation method and a multi-perspective feature (MPF)
module. The former can fit arbitrary-shaped text contours by concentric mask
(CM) in an efficient and robust way. The latter encourages the network to learn
more CM-related discriminative features from multiple perspectives and brings
no extra computational cost. Benefiting the advantages of CM and MPF, the
proposed CM-Net only needs to predict one CM of the text instance to rebuild
the text contour and achieves the best balance between detection accuracy and
speed compared with previous works. Moreover, to ensure that multi-perspective
features are effectively learned, the multi-factor constraints loss is
proposed. Extensive experiments demonstrate the proposed CM is efficient and
robust to fit arbitrary-shaped text instances, and also validate the
effectiveness of MPF and constraints loss for discriminative text features
recognition. Furthermore, experimental results show that the proposed CM-Net is
superior to existing state-of-the-art (SOTA) real-time text detection methods
in both detection speed and accuracy on MSRA-TD500, CTW1500, Total-Text, and
ICDAR2015 datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers in Vision: A Survey. (arXiv:2101.01169v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01169">
<div class="article-summary-box-inner">
<span><p>Astounding results from Transformer models on natural language tasks have
intrigued the vision community to study their application to computer vision
problems. Among their salient benefits, Transformers enable modeling long
dependencies between input sequence elements and support parallel processing of
sequence as compared to recurrent networks e.g., Long short-term memory (LSTM).
Different from convolutional networks, Transformers require minimal inductive
biases for their design and are naturally suited as set-functions. Furthermore,
the straightforward design of Transformers allows processing multiple
modalities (e.g., images, videos, text and speech) using similar processing
blocks and demonstrates excellent scalability to very large capacity networks
and huge datasets. These strengths have led to exciting progress on a number of
vision tasks using Transformer networks. This survey aims to provide a
comprehensive overview of the Transformer models in the computer vision
discipline. We start with an introduction to fundamental concepts behind the
success of Transformers i.e., self-attention, large-scale pre-training, and
bidirectional encoding. We then cover extensive applications of transformers in
vision including popular recognition tasks (e.g., image classification, object
detection, action recognition, and segmentation), generative modeling,
multi-modal tasks (e.g., visual-question answering, visual reasoning, and
visual grounding), video processing (e.g., activity recognition, video
forecasting), low-level vision (e.g., image super-resolution, image
enhancement, and colorization) and 3D analysis (e.g., point cloud
classification and segmentation). We compare the respective advantages and
limitations of popular techniques both in terms of architectural design and
their experimental value. Finally, we provide an analysis on open research
directions and possible future works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAN-Control: Explicitly Controllable GANs. (arXiv:2101.02477v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02477">
<div class="article-summary-box-inner">
<span><p>We present a framework for training GANs with explicit control over generated
images. We are able to control the generated image by settings exact attributes
such as age, pose, expression, etc. Most approaches for editing GAN-generated
images achieve partial control by leveraging the latent space disentanglement
properties, obtained implicitly after standard GAN training. Such methods are
able to change the relative intensity of certain attributes, but not explicitly
set their values. Recently proposed methods, designed for explicit control over
human faces, harness morphable 3D face models to allow fine-grained control
capabilities in GANs. Unlike these methods, our control is not constrained to
morphable 3D face model parameters and is extendable beyond the domain of human
faces. Using contrastive learning, we obtain GANs with an explicitly
disentangled latent space. This disentanglement is utilized to train
control-encoders mapping human-interpretable inputs to suitable latent vectors,
thus allowing explicit control. In the domain of human faces we demonstrate
control over identity, age, pose, expression, hair color and illumination. We
also demonstrate control capabilities of our framework in the domains of
painted portraits and dog image generation. We demonstrate that our approach
achieves state-of-the-art performance both qualitatively and quantitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised driven consistency training for annotation efficient histopathology image analysis. (arXiv:2102.03897v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03897">
<div class="article-summary-box-inner">
<span><p>Training a neural network with a large labeled dataset is still a dominant
paradigm in computational histopathology. However, obtaining such exhaustive
manual annotations is often expensive, laborious, and prone to inter and
Intra-observer variability. While recent self-supervised and semi-supervised
methods can alleviate this need by learn-ing unsupervised feature
representations, they still struggle to generalize well to downstream tasks
when the number of labeled instances is small. In this work, we overcome this
challenge by leveraging both task-agnostic and task-specific unlabeled data
based on two novel strategies: i) a self-supervised pretext task that harnesses
the underlying multi-resolution contextual cues in histology whole-slide images
to learn a powerful supervisory signal for unsupervised representation
learning; ii) a new teacher-student semi-supervised consistency paradigm that
learns to effectively transfer the pretrained representations to downstream
tasks based on prediction consistency with the task-specific un-labeled data.
We carry out extensive validation experiments on three histopathology benchmark
datasets across two classification and one regression-based tasks, i.e., tumor
metastasis detection, tissue type classification, and tumor cellularity
quantification. Under limited-label data, the proposed method yields tangible
improvements, which is close or even outperforming other state-of-the-art
self-supervised and supervised baselines. Furthermore, we empirically show that
the idea of bootstrapping the self-supervised pretrained features is an
effective way to improve the task-specific semi-supervised learning on standard
benchmarks. Code and pretrained models will be made available at:
https://github.com/srinidhiPY/SSL_CR_Histo
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unlocking Pixels for Reinforcement Learning via Implicit Attention. (arXiv:2102.04353v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04353">
<div class="article-summary-box-inner">
<span><p>There has recently been significant interest in training reinforcement
learning (RL) agents in vision-based environments. This poses many challenges,
such as high dimensionality and the potential for observational overfitting
through spurious correlations. A promising approach to solve both of these
problems is an attention bottleneck, which provides a simple and effective
framework for learning high performing policies, even in the presence of
distractions. However, due to poor scalability of attention architectures,
these methods cannot be applied beyond low resolution visual inputs, using
large patches (thus small attention matrices). In this paper we make use of new
efficient attention algorithms, recently shown to be highly effective for
Transformers, and demonstrate that these techniques can be successfully adopted
for the RL setting. This allows our attention-based controllers to scale to
larger visual inputs, and facilitate the use of smaller patches, even
individual pixels, improving generalization. We show this on a range of tasks
from the Distracting Control Suite to vision-based quadruped robots locomotion.
We provide rigorous theoretical analysis of the proposed algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">State-of-the-Art in Human Scanpath Prediction. (arXiv:2102.12239v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12239">
<div class="article-summary-box-inner">
<span><p>The last years have seen a surge in models predicting the scanpaths of
fixations made by humans when viewing images. However, the field is lacking a
principled comparison of those models with respect to their predictive power.
In the past, models have usually been evaluated based on comparing human
scanpaths to scanpaths generated from the model. Here, instead we evaluate
models based on how well they predict each fixation in a scanpath given the
previous scanpath history. This makes model evaluation closely aligned with the
biological processes thought to underly scanpath generation and allows to apply
established saliency metrics like AUC and NSS in an intuitive and interpretable
way. We evaluate many existing models of scanpath prediction on the datasets
MIT1003, MIT300, CAT2000 train and CAT200 test, for the first time giving a
detailed picture of the current state of the art of human scanpath prediction.
We also show that the discussed method of model benchmarking allows for more
detailed analyses leading to interesting insights about where and when models
fail to predict human behaviour. The MIT/Tuebingen Saliency Benchmark will
implement the evaluation of scanpath models as detailed here, allowing
researchers to score their models on the established benchmark datasets MIT300
and CAT2000.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness Evaluation of Stacked Generative Adversarial Networks using Metamorphic Testing. (arXiv:2103.02870v2 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02870">
<div class="article-summary-box-inner">
<span><p>Synthesising photo-realistic images from natural language is one of the
challenging problems in computer vision. Over the past decade, a number of
approaches have been proposed, of which the improved Stacked Generative
Adversarial Network (StackGAN-v2) has proven capable of generating high
resolution images that reflect the details specified in the input text
descriptions. In this paper, we aim to assess the robustness and
fault-tolerance capability of the StackGAN-v2 model by introducing variations
in the training data. However, due to the working principle of Generative
Adversarial Network (GAN), it is difficult to predict the output of the model
when the training data are modified. Hence, in this work, we adopt Metamorphic
Testing technique to evaluate the robustness of the model with a variety of
unexpected training dataset. As such, we first implement StackGAN-v2 algorithm
and test the pre-trained model provided by the original authors to establish a
ground truth for our experiments. We then identify a metamorphic relation, from
which test cases are generated. Further, metamorphic relations were derived
successively based on the observations of prior test results. Finally, we
synthesise the results from our experiment of all the metamorphic relations and
found that StackGAN-v2 algorithm is susceptible to input images with obtrusive
objects, even if it overlaps with the main object minimally, which was not
reported by the authors and users of StackGAN-v2 model. The proposed
metamorphic relations can be applied to other text-to-image synthesis models to
not only verify the robustness but also to help researchers understand and
interpret the results made by the machine learning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">R-PointHop: A Green, Accurate and Unsupervised Point Cloud Registration Method. (arXiv:2103.08129v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08129">
<div class="article-summary-box-inner">
<span><p>Inspired by the recent PointHop classification method, an unsupervised 3D
point cloud registration method, called R-PointHop, is proposed in this work.
R-PointHop first determines a local reference frame (LRF) for every point using
its nearest neighbors and finds its local attributes. Next, R-PointHop obtains
local-to-global hierarchical features by point downsampling, neighborhood
expansion, attribute construction and dimensionality reduction steps. Thus, we
can build the correspondence of points in the hierarchical feature space using
the nearest neighbor rule. Afterwards, a subset of salient points of good
correspondence is selected to estimate the 3D transformation. The use of LRF
allows for hierarchical features of points to be invariant with respect to
rotation and translation, thus making R-PointHop more robust in building point
correspondence even when rotation angles are large. Experiments are conducted
on the 3DMatch, ModelNet40 and the Stanford Bunny dataset, which demonstrate
the effectiveness of R-PointHop on the 3D point cloud registration task.
R-PointHop is a green and accurate solution since its model size and training
time are smaller than those of deep learning methods by an order of magnitude
while its registration errors are smaller. Our codes are available on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D-FFS: Faster 3D object detection with Focused Frustum Search in sensor fusion based networks. (arXiv:2103.08294v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08294">
<div class="article-summary-box-inner">
<span><p>In this work we propose 3D-FFS, a novel approach to make sensor fusion based
3D object detection networks significantly faster using a class of
computationally inexpensive heuristics. Existing sensor fusion based networks
generate 3D region proposals by leveraging inferences from 2D object detectors.
However, as images have no depth information, these networks rely on extracting
semantic features of points from the entire scene to locate the object. By
leveraging aggregated intrinsic properties (e.g. point density) of point cloud
data, 3D-FFS can substantially constrain the 3D search space and thereby
significantly reduce training time, inference time and memory consumption
without sacrificing accuracy. To demonstrate the efficacy of 3D-FFS, we have
integrated it with Frustum ConvNet (F-ConvNet), a prominent sensor fusion based
3D object detection model. We assess the performance of 3D-FFS on the KITTI
dataset. Compared to F-ConvNet, we achieve improvements in training and
inference times by up to 62.80% and 58.96%, respectively, while reducing the
memory usage by up to 58.53%. Additionally, we achieve 0.36%, 0.59% and 2.19%
improvements in accuracy for the Car, Pedestrian and Cyclist classes,
respectively. 3D-FFS shows a lot of promise in domains with limited computing
power, such as autonomous vehicles, drones and robotics where LiDAR-Camera
based sensor fusion perception systems are widely used.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pros and Cons of GAN Evaluation Measures: New Developments. (arXiv:2103.09396v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09396">
<div class="article-summary-box-inner">
<span><p>This work is an update of a previous paper on the same topic published a few
years ago. With the dramatic progress in generative modeling, a suite of new
quantitative and qualitative techniques to evaluate models has emerged.
Although some measures such as Inception Score, Frechet Inception Distance,
Precision-Recall, and Perceptual Path Length are relatively more popular, GAN
evaluation is not a settled issue and there is still room for improvement.
Here, I describe new dimensions that are becoming important in assessing models
(e.g. bias and fairness) and discuss the connection between GAN evaluation and
deepfakes. These are important areas of concern in the machine learning
community today and progress in GAN evaluation can help mitigate them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimization for Oriented Object Detection via Representation Invariance Loss. (arXiv:2103.11636v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11636">
<div class="article-summary-box-inner">
<span><p>Arbitrary-oriented objects exist widely in natural scenes, and thus the
oriented object detection has received extensive attention in recent years. The
mainstream rotation detectors use oriented bounding boxes (OBB) or
quadrilateral bounding boxes (QBB) to represent the rotating objects. However,
these methods suffer from the representation ambiguity for oriented object
definition, which leads to suboptimal regression optimization and the
inconsistency between the loss metric and the localization accuracy of the
predictions. In this paper, we propose a Representation Invariance Loss (RIL)
to optimize the bounding box regression for the rotating objects. Specifically,
RIL treats multiple representations of an oriented object as multiple
equivalent local minima, and hence transforms bounding box regression into an
adaptive matching process with these local minima. Then, the Hungarian matching
algorithm is adopted to obtain the optimal regression strategy. We also propose
a normalized rotation loss to alleviate the weak correlation between different
variables and their unbalanced loss contribution in OBB representation.
Extensive experiments on remote sensing datasets and scene text datasets show
that our method achieves consistent and substantial improvement. The source
code and trained models are available at https://github.com/ming71/RIDet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Facial expression and attributes recognition based on multi-task learning of lightweight neural networks. (arXiv:2103.17107v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17107">
<div class="article-summary-box-inner">
<span><p>In this paper, the multi-task learning of lightweight convolutional neural
networks is studied for face identification and classification of facial
attributes (age, gender, ethnicity) trained on cropped faces without margins.
The necessity to fine-tune these networks to predict facial expressions is
highlighted. Several models are presented based on MobileNet, EfficientNet and
RexNet architectures. It was experimentally demonstrated that they lead to near
state-of-the-art results in age, gender and race recognition on the UTKFace
dataset and emotion classification on the AffectNet dataset. Moreover, it is
shown that the usage of the trained models as feature extractors of facial
regions in video frames leads to 4.5% higher accuracy than the previously known
state-of-the-art single models for the AFEW and the VGAF datasets from the
EmotiW challenges. The models and source code are publicly available at
https://github.com/HSE-asavchenko/face-emotion-recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BiP-Net: Bidirectional Perspective Strategy based Arbitrary-Shaped Text Detection Network. (arXiv:2104.04903v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04903">
<div class="article-summary-box-inner">
<span><p>Detecting irregular-shaped text instances is the main challenge for text
detection. Existing approaches can be roughly divided into top-down and
bottom-up perspective methods. The former encodes text contours into unified
units, which always fails to fit highly curved text contours. The latter
represents text instances by a number of local units, where the complicated
network and post-processing lead to slow detection speed. In this paper, to
detect arbitrary-shaped text instances with high detection accuracy and speed
simultaneously, we propose a \textbf{Bi}directional \textbf{P}erspective
strategy based \textbf{Net}work (BiP-Net). Specifically, a new text
representation strategy is proposed to represent text contours from a top-down
perspective, which can fit highly curved text contours effectively. Moreover, a
contour connecting (CC) algorithm is proposed to avoid the information loss of
text contours by rebuilding interval contours from a bottom-up perspective. The
experimental results on MSRA-TD500, CTW1500, and ICDAR2015 datasets demonstrate
the superiority of BiP-Net against several state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discover the Unknown Biased Attribute of an Image Classifier. (arXiv:2104.14556v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14556">
<div class="article-summary-box-inner">
<span><p>Recent works find that AI algorithms learn biases from data. Therefore, it is
urgent and vital to identify biases in AI algorithms. However, the previous
bias identification pipeline overly relies on human experts to conjecture
potential biases (e.g., gender), which may neglect other underlying biases not
realized by humans. To help human experts better find the AI algorithms'
biases, we study a new problem in this work -- for a classifier that predicts a
target attribute of the input image, discover its unknown biased attribute.
</p>
<p>To solve this challenging problem, we use a hyperplane in the generative
model's latent space to represent an image attribute; thus, the original
problem is transformed to optimizing the hyperplane's normal vector and offset.
We propose a novel total-variation loss within this framework as the objective
function and a new orthogonalization penalty as a constraint. The latter
prevents trivial solutions in which the discovered biased attribute is
identical with the target or one of the known-biased attributes. Extensive
experiments on both disentanglement datasets and real-world datasets show that
our method can discover biased attributes and achieve better disentanglement
w.r.t. target attributes. Furthermore, the qualitative results show that our
method can discover unnoticeable biased attributes for various object and scene
classifiers, proving our method's generalizability for detecting biased
attributes in diverse domains of images. The code is available at
https://git.io/J3kMh.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to drive from a world on rails. (arXiv:2105.00636v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00636">
<div class="article-summary-box-inner">
<span><p>We learn an interactive vision-based driving policy from pre-recorded driving
logs via a model-based approach. A forward model of the world supervises a
driving policy that predicts the outcome of any potential driving trajectory.
To support learning from pre-recorded logs, we assume that the world is on
rails, meaning neither the agent nor its actions influence the environment.
This assumption greatly simplifies the learning problem, factorizing the
dynamics into a nonreactive world model and a low-dimensional and compact
forward model of the ego-vehicle. Our approach computes action-values for each
training trajectory using a tabular dynamic-programming evaluation of the
Bellman equations; these action-values in turn supervise the final vision-based
driving policy. Despite the world-on-rails assumption, the final driving policy
acts well in a dynamic and reactive world. At the time of writing, our method
ranks first on the CARLA leaderboard, attaining a 25% higher driving score
while using 40 times less data. Our method is also an order of magnitude more
sample-efficient than state-of-the-art model-free reinforcement learning
techniques on navigational tasks in the ProcGen benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating Parkinsonism Severity in Natural Gait Videos of Older Adults with Dementia. (arXiv:2105.03464v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03464">
<div class="article-summary-box-inner">
<span><p>Drug-induced parkinsonism affects many older adults with dementia, often
causing gait disturbances. New advances in vision-based human pose-estimation
have opened possibilities for frequent and unobtrusive analysis of gait in
residential settings. This work leverages novel spatial-temporal graph
convolutional network (ST-GCN) architectures and training procedures to predict
clinical scores of parkinsonism in gait from video of individuals with
dementia. We propose a two-stage training approach consisting of a
self-supervised pretraining stage that encourages the ST-GCN model to learn
about gait patterns before predicting clinical scores in the finetuning stage.
The proposed ST-GCN models are evaluated on joint trajectories extracted from
video and are compared against traditional (ordinal, linear, random forest)
regression models and temporal convolutional network baselines. Three 2D human
pose-estimation libraries (OpenPose, Detectron, AlphaPose) and the Microsoft
Kinect (2D and 3D) are used to extract joint trajectories of 4787 natural
walking bouts from 53 older adults with dementia. A subset of 399 walks from 14
participants is annotated with scores of parkinsonism severity on the gait
criteria of the Unified Parkinson's Disease Rating Scale (UPDRS) and the
Simpson-Angus Scale (SAS). Our results demonstrate that ST-GCN models operating
on 3D joint trajectories extracted from the Kinect consistently outperform all
other models and feature sets. Prediction of parkinsonism scores in natural
walking bouts of unseen participants remains a challenging task, with the best
models achieving macro-averaged F1-scores of 0.53 +/- 0.03 and 0.40 +/- 0.02
for UPDRS-gait and SAS-gait, respectively. Pre-trained model and demo code for
this work is available:
https://github.com/TaatiTeam/stgcn_parkinsonism_prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revitalizing Optimization for 3D Human Pose and Shape Estimation: A Sparse Constrained Formulation. (arXiv:2105.13965v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13965">
<div class="article-summary-box-inner">
<span><p>We propose a novel sparse constrained formulation and from it derive a
real-time optimization method for 3D human pose and shape estimation. Our
optimization method, SCOPE (Sparse Constrained Optimization for 3D human Pose
and shapE estimation), is orders of magnitude faster (avg. 4 ms convergence)
than existing optimization methods, while being mathematically equivalent to
their dense unconstrained formulation under mild assumptions. We achieve this
by exploiting the underlying sparsity and constraints of our formulation to
efficiently compute the Gauss-Newton direction. We show that this computation
scales linearly with the number of joints and measurements of a complex 3D
human model, in contrast to prior work where it scales cubically due to their
dense unconstrained formulation. Based on our optimization method, we present a
real-time motion capture framework that estimates 3D human poses and shapes
from a single image at over 30 FPS. In benchmarks against state-of-the-art
methods on multiple public datasets, our framework outperforms other
optimization methods and achieves competitive accuracy against regression
methods. Project page with code and videos:
https://sites.google.com/view/scope-human/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Seamless and High-Performance Out-of-Distribution Detection Approach Simply Replacing the SoftMax Loss. (arXiv:2105.14399v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14399">
<div class="article-summary-box-inner">
<span><p>Current out-of-distribution detection approaches usually present special
requirements (e.g., collecting outlier data and hyperparameter validation) and
produce side effects (classification accuracy drop and slow/inefficient
inferences). Recently, entropic out-of-distribution detection has been proposed
as a seamless approach (i.e., a solution that avoids all the previously
mentioned drawbacks). The entropic out-of-distribution detection solution
comprises the IsoMax loss for training and the entropic score for
out-of-distribution detection. The IsoMax loss works as a SoftMax loss drop-in
replacement because swapping the SoftMax loss with the IsoMax loss requires no
changes in the model's architecture or training procedures/hyperparameters. In
this paper, we propose to perform what we call an isometrization of the
distances used in the IsoMax loss. Additionally, we propose to replace the
entropic score with the minimum distance score. Our experiments showed that
these simple modifications increase out-of-distribution detection performance
while keeping the solution seamless. Besides being competitive with or
outperforming all major current approaches, our solution avoids all their
current limitations in addition to being much easier to use, as just a simple
loss replacement for training the neural network is required. Code available at
https://github.com/dlmacedo/entropic-out-of-distribution-detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">You Never Cluster Alone. (arXiv:2106.01908v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01908">
<div class="article-summary-box-inner">
<span><p>Recent advances in self-supervised learning with instance-level contrastive
objectives facilitate unsupervised clustering. However, a standalone datum is
not perceiving the context of the holistic cluster, and may undergo sub-optimal
assignment. In this paper, we extend the mainstream contrastive learning
paradigm to a cluster-level scheme, where all the data subjected to the same
cluster contribute to a unified representation that encodes the context of each
data group. Contrastive learning with this representation then rewards the
assignment of each datum. To implement this vision, we propose twin-contrast
clustering (TCC). We define a set of categorical variables as clustering
assignment confidence, which links the instance-level learning track with the
cluster-level one. On one hand, with the corresponding assignment variables
being the weight, a weighted aggregation along the data points implements the
set representation of a cluster. We further propose heuristic cluster
augmentation equivalents to enable cluster-level contrastive learning. On the
other hand, we derive the evidence lower-bound of the instance-level
contrastive objective with the assignments. By reparametrizing the assignment
variables, TCC is trained end-to-end, requiring no alternating steps. Extensive
experiments show that TCC outperforms the state-of-the-art on challenging
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Implicit 3D Shapes from Single Images with Spatial Patterns. (arXiv:2106.03087v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03087">
<div class="article-summary-box-inner">
<span><p>3D shape reconstruction from a single image has been a long-standing problem
in computer vision. Recent advances have led to 3D representation learning,
wherein pixel-aligned 3D reconstruction methods show impressive performance.
However, it is normally hard to exploit meaningful local image features to
describe 3D point samplings from the aligned pixels when large variations of
occlusions, views, and appearances exist. In this paper, we study a general
kernel to encode local image features with considering geometric relationships
of point samplings from the underlying surfaces. The kernel is derived from the
proposed spatial pattern, in a way the kernel points are obtained as the 2D
projections of a number of 3D pattern points around a sampling. Supported by
the spatial pattern, the 2D kernel encodes geometric information that is
essential for 3D reconstruction tasks, while traditional 2D kernels mainly
consider appearance information. Furthermore, to enable the network to discover
more adaptive spatial patterns for further capturing non-local contextual
information, the spatial pattern is devised to be deformable. Experimental
results on both synthetic datasets and real datasets demonstrate the
superiority of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Densely connected normalizing flows. (arXiv:2106.04627v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04627">
<div class="article-summary-box-inner">
<span><p>Normalizing flows are bijective mappings between inputs and latent
representations with a fully factorized distribution. They are very attractive
due to exact likelihood evaluation and efficient sampling. However, their
effective capacity is often insufficient since the bijectivity constraint
limits the model width. We address this issue by incrementally padding
intermediate representations with noise. We precondition the noise in
accordance with previous invertible units, which we describe as cross-unit
coupling. Our invertible glow-like modules express intra-unit affine coupling
as a fusion of a densely connected block and Nystr\"om self-attention. We refer
to our architecture as DenseFlow since both cross-unit and intra-unit couplings
rely on dense connectivity. Experiments show significant improvements due to
the proposed contributions, and reveal state-of-the-art density estimation
among all generative models under moderate computing budgets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-supervised Meta-learning with Disentanglement for Domain-generalised Medical Image Segmentation. (arXiv:2106.13292v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13292">
<div class="article-summary-box-inner">
<span><p>Generalising deep models to new data from new centres (termed here domains)
remains a challenge. This is largely attributed to shifts in data statistics
(domain shifts) between source and unseen domains. Recently, gradient-based
meta-learning approaches where the training data are split into meta-train and
meta-test sets to simulate and handle the domain shifts during training have
shown improved generalisation performance. However, the current fully
supervised meta-learning approaches are not scalable for medical image
segmentation, where large effort is required to create pixel-wise annotations.
Meanwhile, in a low data regime, the simulated domain shifts may not
approximate the true domain shifts well across source and unseen domains. To
address this problem, we propose a novel semi-supervised meta-learning
framework with disentanglement. We explicitly model the representations related
to domain shifts. Disentangling the representations and combining them to
reconstruct the input image allows unlabeled data to be used to better
approximate the true domain shifts for meta-learning. Hence, the model can
achieve better generalisation performance, especially when there is a limited
amount of labeled data. Experiments show that the proposed method is robust on
different segmentation tasks and achieves state-of-the-art generalisation
performance on two public benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Technical Document Classification. (arXiv:2106.14269v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14269">
<div class="article-summary-box-inner">
<span><p>In large technology companies, the requirements for managing and organizing
technical documents created by engineers and managers in supporting relevant
decision making have increased dramatically in recent years, which has led to a
higher demand for more scalable, accurate, and automated document
classification. Prior studies have only focused on processing text for
classification, whereas technical documents often contain multimodal
information. This paper presents a novel multimodal deep learning architecture,
TechDoc, for technical document classification, which utilizes three types of
information, including natural language texts and descriptive images within
documents and the associations among the documents. The architecture
synthesizes the convolutional neural network, recurrent neural network, and
graph neural network through an integrated multimodal training process. We
applied the architecture to a large multimodal technical document database and
trained the model for classifying documents based on the hierarchical
International Patent Classification system. Our results show that TechDoc
presents a greater classification accuracy than the unimodal methods and other
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A 3D CNN Network with BERT For Automatic COVID-19 Diagnosis From CT-Scan Images. (arXiv:2106.14403v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14403">
<div class="article-summary-box-inner">
<span><p>We present an automatic COVID1-19 diagnosis framework from lung CT-scan slice
images. In this framework, the slice images of a CT-scan volume are first
proprocessed using segmentation techniques to filter out images of closed lung,
and to remove the useless background. Then a resampling method is used to
select one or multiple sets of a fixed number of slice images for training and
validation. A 3D CNN network with BERT is used to classify this set of selected
slice images. In this network, an embedding feature is also extracted. In cases
where there are more than one set of slice images in a volume, the features of
all sets are extracted and pooled into a global feature vector for the whole
CT-scan volume. A simple multiple-layer perceptron (MLP) network is used to
further classify the aggregated feature vector. The models are trained and
evaluated on the provided training and validation datasets. On the validation
dataset, the accuracy is 0.9278 and the F1 score is 0.9261.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prior-Guided Multi-View 3D Head Reconstruction. (arXiv:2107.04277v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04277">
<div class="article-summary-box-inner">
<span><p>Recovery of a 3D head model including the complete face and hair regions is
still a challenging problem in computer vision and graphics. In this paper, we
consider this problem using only a few multi-view portrait images as input.
Previous multi-view stereo methods that have been based, either on optimization
strategies or deep learning techniques, suffer from low-frequency geometric
structures such as unclear head structures and inaccurate reconstruction in
hair regions. To tackle this problem, we propose a prior-guided implicit neural
rendering network. Specifically, we model the head geometry with a learnable
signed distance field (SDF) and optimize it via an implicit differentiable
renderer with the guidance of some human head priors, including the facial
prior knowledge, head semantic segmentation information and 2D hair orientation
maps. The utilization of these priors can improve the reconstruction accuracy
and robustness, leading to a high-quality integrated 3D head model. Extensive
ablation studies and comparisons with state-of-the-art methods demonstrate that
our method can generate high-fidelity 3D head geometries with the guidance of
these priors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Representation Learning Does Not Generalize Strongly Within the Same Domain. (arXiv:2107.08221v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08221">
<div class="article-summary-box-inner">
<span><p>An important component for generalization in machine learning is to uncover
underlying latent factors of variation as well as the mechanism through which
each factor acts in the world. In this paper, we test whether 17 unsupervised,
weakly supervised, and fully supervised representation learning approaches
correctly infer the generative factors of variation in simple datasets
(dSprites, Shapes3D, MPI3D) from controlled environments, and on our
contributed CelebGlow dataset. In contrast to prior robustness work that
introduces novel factors of variation during test time, such as blur or other
(un)structured noise, we here recompose, interpolate, or extrapolate only
existing factors of variation from the training data set (e.g., small and
medium-sized objects during training and large objects during testing). Models
that learn the correct mechanism should be able to generalize to this
benchmark. In total, we train and test 2000+ models and observe that all of
them struggle to learn the underlying mechanism regardless of supervision
signal and architectural bias. Moreover, the generalization capabilities of all
tested models drop significantly as we move from artificial datasets towards
more realistic real-world datasets. Despite their inability to identify the
correct mechanism, the models are quite modular as their ability to infer other
in-distribution factors remains fairly stable, providing only a single factor
is out-of-distribution. These results point to an important yet understudied
problem of learning mechanistic models of observations that can facilitate
generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">X-GGM: Graph Generative Modeling for Out-of-Distribution Generalization in Visual Question Answering. (arXiv:2107.11576v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11576">
<div class="article-summary-box-inner">
<span><p>Encouraging progress has been made towards Visual Question Answering (VQA) in
recent years, but it is still challenging to enable VQA models to adaptively
generalize to out-of-distribution (OOD) samples. Intuitively, recompositions of
existing visual concepts (\ie, attributes and objects) can generate unseen
compositions in the training set, which will promote VQA models to generalize
to OOD samples. In this paper, we formulate OOD generalization in VQA as a
compositional generalization problem and propose a graph generative
modeling-based training scheme (X-GGM) to implicitly model the problem. X-GGM
leverages graph generative modeling to iteratively generate a relation matrix
and node representations for the predefined graph that utilizes
attribute-object pairs as nodes. Furthermore, to alleviate the unstable
training issue in graph generative modeling, we propose a gradient distribution
consistency loss to constrain the data distribution with adversarial
perturbations and the generated distribution. The baseline VQA model (LXMERT)
trained with the X-GGM scheme achieves state-of-the-art OOD performance on two
standard VQA OOD benchmarks, \ie, VQA-CP v2 and GQA-OOD. Extensive ablation
studies demonstrate the effectiveness of X-GGM components. Code is available at
\url{https://github.com/jingjing12110/x-ggm}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Visual Domain Transfer Learning Approach for Heartbeat Sound Classification. (arXiv:2107.13237v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13237">
<div class="article-summary-box-inner">
<span><p>Heart disease is the most common reason for human mortality that causes
almost one-third of deaths throughout the world. Detecting the disease early
increases the chances of survival of the patient and there are several ways a
sign of heart disease can be detected early. This research proposes to convert
cleansed and normalized heart sound into visual mel scale spectrograms and then
using visual domain transfer learning approaches to automatically extract
features and categorize between heart sounds. Some of the previous studies
found that the spectrogram of various types of heart sounds is visually
distinguishable to human eyes, which motivated this study to experiment on
visual domain classification approaches for automated heart sound
classification. It will use convolution neural network-based architectures i.e.
ResNet, MobileNetV2, etc as the automated feature extractors from spectrograms.
These well-accepted models in the image domain showed to learn generalized
feature representations of cardiac sounds collected from different environments
with varying amplitude and noise levels. Model evaluation criteria used were
categorical accuracy, precision, recall, and AUROC as the chosen dataset is
unbalanced. The proposed approach has been implemented on datasets A and B of
the PASCAL heart sound collection and resulted in ~ 90% categorical accuracy
and AUROC of ~0.97 for both sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HiFT: Hierarchical Feature Transformer for Aerial Tracking. (arXiv:2108.00202v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00202">
<div class="article-summary-box-inner">
<span><p>Most existing Siamese-based tracking methods execute the classification and
regression of the target object based on the similarity maps. However, they
either employ a single map from the last convolutional layer which degrades the
localization accuracy in complex scenarios or separately use multiple maps for
decision making, introducing intractable computations for aerial mobile
platforms. Thus, in this work, we propose an efficient and effective
hierarchical feature transformer (HiFT) for aerial tracking. Hierarchical
similarity maps generated by multi-level convolutional layers are fed into the
feature transformer to achieve the interactive fusion of spatial (shallow
layers) and semantics cues (deep layers). Consequently, not only the global
contextual information can be raised, facilitating the target search, but also
our end-to-end architecture with the transformer can efficiently learn the
interdependencies among multi-level features, thereby discovering a
tracking-tailored feature space with strong discriminability. Comprehensive
evaluations on four aerial benchmarks have proven the effectiveness of HiFT.
Real-world tests on the aerial platform have strongly validated its
practicability with a real-time speed. Our code is available at
https://github.com/vision4robotics/HiFT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BIDCD -- Bosch Industrial Depth Completion Dataset. (arXiv:2108.04706v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04706">
<div class="article-summary-box-inner">
<span><p>We introduce BIDCD -- the Bosch Industrial Depth Completion Dataset. BIDCD is
a new RGBD dataset of metallic industrial objects, collected with a depth
camera mounted on a robotic manipulator. The main purpose of this dataset is to
facilitate the training of domain-specific depth completion models, to be used
in logistics and manufacturing tasks. We trained a State-of-the-Art depth
completion model on this dataset, and report the results, setting an initial
benchmark. Further, we propose to use this dataset for learning
synthetic-to-depth-camera domain adaptation. Modifying synthetic RGBD data to
mimic characteristics of real-world depth acquisition could potentially enhance
training on synthetic data. For this end, we trained a Generative Adversarial
Network (GAN) on a synthetic industrial dataset and our real-world data.
Finally, to address geometric distortions in the generated images, we introduce
an auxiliary loss that promotes preservation of the original shape. The BIDCD
data is publicly available at https://zenodo.org/communities/bidcd.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DRB-GAN: A Dynamic ResBlock Generative Adversarial Network for Artistic Style Transfer. (arXiv:2108.07379v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07379">
<div class="article-summary-box-inner">
<span><p>The paper proposes a Dynamic ResBlock Generative Adversarial Network
(DRB-GAN) for artistic style transfer. The style code is modeled as the shared
parameters for Dynamic ResBlocks connecting both the style encoding network and
the style transfer network. In the style encoding network, a style class-aware
attention mechanism is used to attend the style feature representation for
generating the style codes. In the style transfer network, multiple Dynamic
ResBlocks are designed to integrate the style code and the extracted CNN
semantic feature and then feed into the spatial window Layer-Instance
Normalization (SW-LIN) decoder, which enables high-quality synthetic images
with artistic style transfer. Moreover, the style collection conditional
discriminator is designed to equip our DRB-GAN model with abilities for both
arbitrary style transfer and collection style transfer during the training
stage. No matter for arbitrary style transfer or collection style transfer,
extensive experiments strongly demonstrate that our proposed DRB-GAN
outperforms state-of-the-art methods and exhibits its superior performance in
terms of visual quality and efficiency. Our source code is available at
\color{magenta}{\url{https://github.com/xuwenju123/DRB-GAN}}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Convolutional Neural Network (CNN) vs Visual Transformer (ViT) for Digital Holography. (arXiv:2108.09147v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09147">
<div class="article-summary-box-inner">
<span><p>In Digital Holography (DH), it is crucial to extract the object distance from
a hologram in order to reconstruct its amplitude and phase. This step is called
auto-focusing and it is conventionally solved by first reconstructing a stack
of images and then by sharpening each reconstructed image using a focus metric
such as entropy or variance. The distance corresponding to the sharpest image
is considered the focal position. This approach, while effective, is
computationally demanding and time-consuming. In this paper, the determination
of the distance is performed by Deep Learning (DL). Two deep learning (DL)
architectures are compared: Convolutional Neural Network (CNN)and Visual
transformer (ViT). ViT and CNN are used to cope with the problem of
auto-focusing as a classification problem. Compared to a first attempt [11] in
which the distance between two consecutive classes was 100$\mu$m, our proposal
allows us to drastically reduce this distance to 1$\mu$m. Moreover, ViT reaches
similar accuracy and is more robust than CNN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DKM: Differentiable K-Means Clustering Layer for Neural Network Compression. (arXiv:2108.12659v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12659">
<div class="article-summary-box-inner">
<span><p>Deep neural network (DNN) model compression for efficient on-device inference
is becoming increasingly important to reduce memory requirements and keep user
data on-device. To this end, we propose a novel differentiable k-means
clustering layer (DKM) and its application to train-time weight
clustering-based DNN model compression. DKM casts k-means clustering as an
attention problem and enables joint optimization of the DNN parameters and
clustering centroids. Unlike prior works that rely on additional regularizers
and parameters, DKM-based compression keeps the original loss function and
model architecture fixed. We evaluated DKM-based compression on various DNN
models for computer vision and natural language processing (NLP) tasks. Our
results demonstrate that DKM delivers superior compression and accuracy
trade-off on ImageNet1k and GLUE benchmarks. For example, DKM-based compression
can offer 74.5% top-1 ImageNet1k accuracy on ResNet50 DNN model with 3.3MB
model size (29.4x model compression factor). For MobileNet-v1, which is a
challenging DNN to compress, DKM delivers 62.8% top-1 ImageNet1k accuracy with
0.74 MB model size (22.4x model compression factor). This result is 6.8% higher
top-1accuracy and 33% relatively smaller model size than the current
state-of-the-art DNN compression algorithms. Additionally, DKM enables
compression of DistilBERT model by 11.8x with minimal (1.1%) accuracy loss on
GLUE NLP benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Common Assumptions to Mitigate Racial Bias in Face Recognition Datasets. (arXiv:2109.03229v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03229">
<div class="article-summary-box-inner">
<span><p>Many existing works have made great strides towards reducing racial bias in
face recognition. However, most of these methods attempt to rectify bias that
manifests in models during training instead of directly addressing a major
source of the bias, the dataset itself. Exceptions to this are
BUPT-Balancedface/RFW and Fairface, but these works assume that primarily
training on a single race or not racially balancing the dataset are inherently
disadvantageous. We demonstrate that these assumptions are not necessarily
valid. In our experiments, training on only African faces induced less bias
than training on a balanced distribution of faces and distributions skewed to
include more African faces produced more equitable models. We additionally
notice that adding more images of existing identities to a dataset in place of
adding new identities can lead to accuracy boosts across racial categories. Our
code is available at $\small
\href{https://github.com/j-alex-hanson/rethinking-race-face-datasets}{\text{this
https URL}}$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Person Re-Identification: A Systematic Survey of Challenges and Solutions. (arXiv:2109.06057v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06057">
<div class="article-summary-box-inner">
<span><p>Person re-identification (Re-ID) has been a significant research topic in the
past decade due to its real-world applications and research significance. While
supervised person Re-ID methods achieve superior performance over unsupervised
counterparts, they can not scale to large unlabelled datasets and new domains
due to the prohibitive labelling cost. Therefore, unsupervised person Re-ID has
drawn increasing attention for its potential to address the scalability issue
in person Re-ID. Unsupervised person Re-ID is challenging primarily due to
lacking identity labels to supervise person feature learning. The corresponding
solutions are diverse and complex, with various merits and limitations.
Therefore, comprehensive surveys on this topic are essential to summarise
challenges and solutions to foster future research. Existing person Re-ID
surveys have focused on supervised methods from classifications and
applications but lack detailed discussion on how the person Re-ID solutions
address the underlying challenges. This survey review recent works on
unsupervised person Re-ID from the perspective of challenges and solutions.
Specifically, we provide an in-depth analysis of highly influential methods
considering the four significant challenges in unsupervised person Re-ID: 1)
lacking ground-truth identity labels to supervise person feature learning; 2)
learning discriminative person features with pseudo-supervision; 3) learning
cross-camera invariant person feature, and 4) the domain shift between
datasets. We summarise and analyse evaluation results and provide insights on
the effectiveness of the solutions. Finally, we discuss open issues and suggest
some promising future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-Task Cross-Task Learning Architecture for Ad-hoc Uncertainty Estimation in 3D Cardiac MRI Image Segmentation. (arXiv:2109.07702v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07702">
<div class="article-summary-box-inner">
<span><p>Medical image segmentation has significantly benefitted thanks to deep
learning architectures. Furthermore, semi-supervised learning (SSL) has
recently been a growing trend for improving a model's overall performance by
leveraging abundant unlabeled data. Moreover, learning multiple tasks within
the same model further improves model generalizability. To generate smoother
and accurate segmentation masks from 3D cardiac MR images, we present a
Multi-task Cross-task learning consistency approach to enforce the correlation
between the pixel-level (segmentation) and the geometric-level (distance map)
tasks. Our extensive experimentation with varied quantities of labeled data in
the training sets justifies the effectiveness of our model for the segmentation
of the left atrial cavity from Gadolinium-enhanced magnetic resonance (GE-MR)
images. With the incorporation of uncertainty estimates to detect failures in
the segmentation masks generated by CNNs, our study further showcases the
potential of our model to flag low-quality segmentation from a given model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MHFC: Multi-Head Feature Collaboration for Few-Shot Learning. (arXiv:2109.07785v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07785">
<div class="article-summary-box-inner">
<span><p>Few-shot learning (FSL) aims to address the data-scarce problem. A standard
FSL framework is composed of two components: (1) Pre-train. Employ the base
data to generate a CNN-based feature extraction model (FEM). (2) Meta-test.
Apply the trained FEM to acquire the novel data's features and recognize them.
FSL relies heavily on the design of the FEM. However, various FEMs have
distinct emphases. For example, several may focus more attention on the contour
information, whereas others may lay particular emphasis on the texture
information. The single-head feature is only a one-sided representation of the
sample. Besides the negative influence of cross-domain (e.g., the trained FEM
can not adapt to the novel class flawlessly), the distribution of novel data
may have a certain degree of deviation compared with the ground truth
distribution, which is dubbed as distribution-shift-problem (DSP). To address
the DSP, we propose Multi-Head Feature Collaboration (MHFC) algorithm, which
attempts to project the multi-head features (e.g., multiple features extracted
from a variety of FEMs) to a unified space and fuse them to capture more
discriminative information. Typically, first, we introduce a subspace learning
method to transform the multi-head features to aligned low-dimensional
representations. It corrects the DSP via learning the feature with more
powerful discrimination and overcomes the problem of inconsistent measurement
scales from different head features. Then, we design an attention block to
update combination weights for each head feature automatically. It
comprehensively considers the contribution of various perspectives and further
improves the discrimination of features. We evaluate the proposed method on
five benchmark datasets (including cross-domain experiments) and achieve
significant improvements of 2.1%-7.8% compared with state-of-the-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Logo Generation Using Regional Features: A Faster R-CNN Approach to Generative Adversarial Networks. (arXiv:2109.12628v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12628">
<div class="article-summary-box-inner">
<span><p>In this paper we introduce Local Logo Generative Adversarial Network (LL-GAN)
that uses regional features extracted from Faster R-CNN for logo generation. We
demonstrate the strength of this approach by training the framework on a small
style-rich dataset of real heavy metal logos to generate new ones. LL-GAN
achieves Inception Score of 5.29 and Frechet Inception Distance of 223.94,
improving on state-of-the-art models StyleGAN2 and Self-Attention GAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cluster Analysis with Deep Embeddings and Contrastive Learning. (arXiv:2109.12714v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12714">
<div class="article-summary-box-inner">
<span><p>Unsupervised disentangled representation learning is a long-standing problem
in computer vision. This work proposes a novel framework for performing image
clustering from deep embeddings by combining instance-level contrastive
learning with a deep embedding based cluster center predictor. Our approach
jointly learns representations and predicts cluster centers in an end-to-end
manner. This is accomplished via a three-pronged approach that combines a
clustering loss, an instance-wise contrastive loss, and an anchor loss. Our
fundamental intuition is that using an ensemble loss that incorporates
instance-level features and a clustering procedure focusing on semantic
similarity reinforces learning better representations in the latent space. We
observe that our method performs exceptionally well on popular vision datasets
when evaluated using standard clustering metrics such as Normalized Mutual
Information (NMI), in addition to producing geometrically well-separated
cluster embeddings as defined by the Euclidean distance. Our framework performs
on par with widely accepted clustering methods and outperforms the
state-of-the-art contrastive learning method on the CIFAR-10 dataset with an
NMI score of 0.772, a 7-8% improvement on the strong baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FathomNet: A global underwater image training set for enabling artificial intelligence in the ocean. (arXiv:2109.14646v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14646">
<div class="article-summary-box-inner">
<span><p>Ocean-going platforms are integrating high-resolution camera feeds for
observation and navigation, producing a deluge of visual data. The volume and
rate of this data collection can rapidly outpace researchers' abilities to
process and analyze them. Recent advances in machine learning enable fast,
sophisticated analysis of visual data, but have had limited success in the
ocean due to lack of data set standardization, insufficient formatting, and
aggregation of existing, expertly curated imagery for use by data scientists.
To address this need, we have built FathomNet, a public platform that makes use
of existing, expertly curated data. Initial efforts have leveraged MBARI's
Video Annotation and Reference System and annotated deep sea video database,
which has more than 7M annotations, 1M frame grabs, and 5k terms in the
knowledgebase, with additional contributions by National Geographic Society
(NGS) and NOAA's Office of Ocean Exploration and Research. FathomNet has over
160k localizations of 1.4k midwater and benthic classes, and contains more than
70k iconic and non-iconic views of marine animals, underwater equipment,
debris, etc. We demonstrate how machine learning models trained on FathomNet
data can be applied across different institutional video data, and enable
automated acquisition and tracking of midwater animals using a remotely
operated vehicle. As FathomNet continues to develop and incorporate more image
data from other oceanographic community members, this effort will enable
scientists, explorers, policymakers, storytellers, and the public to understand
and care for our ocean.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Pose Transfer with Correspondence Learning and Mesh Refinement. (arXiv:2109.15025v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.15025">
<div class="article-summary-box-inner">
<span><p>3D pose transfer is one of the most challenging 3D generation tasks. It aims
to transfer the pose of a source mesh to a target mesh and keep the identity
(e.g., body shape) of the target mesh. Some previous works require key point
annotations to build reliable correspondence between the source and target
meshes, while other methods do not consider any shape correspondence between
sources and targets, which leads to limited generation quality. In this work,
we propose a correspondence-refinement network to help the 3D pose transfer for
both human and animal meshes. The correspondence between source and target
meshes is first established by solving an optimal transport problem. Then, we
warp the source mesh according to the dense correspondence and obtain a coarse
warped mesh. The warped mesh will be better refined with our proposed Elastic
Instance Normalization, which is a conditional normalization layer and can help
to generate high-quality meshes. Extensive experimental results show that the
proposed architecture can effectively transfer the poses from source to target
meshes and produce better results with satisfied visual performance than
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-05 23:02:30.241122538 UTC">2021-10-05 23:02:30 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>