<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-24T01:30:00Z">09-24</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-linguistically Consistent Semantic and Syntactic Annotation of Child-directed Speech. (arXiv:2109.10952v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10952">
<div class="article-summary-box-inner">
<span><p>While corpora of child speech and child-directed speech (CDS) have enabled
major contributions to the study of child language acquisition, semantic
annotation for such corpora is still scarce and lacks a uniform standard. We
compile two CDS corpora with sentential logical forms, one in English and the
other in Hebrew. In compiling the corpora we employ a methodology that enforces
a cross-linguistically consistent representation, building on recent advances
in dependency representation and semantic parsing. The corpora are based on a
sizable portion of Brown's Adam corpus from CHILDES (about 80% of its
child-directed utterances), and to all child-directed utterances from Berman's
Hebrew CHILDES corpus Hagar.
</p>
<p>We begin by annotating the corpora with the Universal Dependencies (UD)
scheme for syntactic annotation, motivated by its applicability to a wide
variety of domains and languages. We then proceed by applying an automatic
method for transducing sentential logical forms (LFs) from UD structures. The
two representations have complementary strengths: UD structures are
language-neutral and support direct annotation, whereas LFs are neutral as to
the interface between syntax and semantics, and transparently encode semantic
distinctions. We verify the quality of the annotated UD annotation using an
inter-annotator agreement study. We then demonstrate the utility of the
compiled corpora through a longitudinal corpus study of the prevalence of
different syntactic and semantic phenomena.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable Fact-checking with Human-in-the-Loop. (arXiv:2109.10992v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10992">
<div class="article-summary-box-inner">
<span><p>Researchers have been investigating automated solutions for fact-checking in
a variety of fronts. However, current approaches often overlook the fact that
the amount of information released every day is escalating, and a large amount
of them overlap. Intending to accelerate fact-checking, we bridge this gap by
grouping similar messages and summarizing them into aggregated claims.
Specifically, we first clean a set of social media posts (e.g., tweets) and
build a graph of all posts based on their semantics; Then, we perform two
clustering methods to group the messages for further claim summarization. We
evaluate the summaries both quantitatively with ROUGE scores and qualitatively
with human evaluation. We also generate a graph of summaries to verify that
there is no significant overlap among them. The results reduced 28,818 original
messages to 700 summary claims, showing the potential to speed up the
fact-checking process by organizing and selecting representative claims from
massive disorganized and redundant messages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Alzheimers Dementia Detection using Acoustic & Linguistic features and Pre-Trained BERT. (arXiv:2109.11010v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11010">
<div class="article-summary-box-inner">
<span><p>Alzheimers disease is a fatal progressive brain disorder that worsens with
time. It is high time we have inexpensive and quick clinical diagnostic
techniques for early detection and care. In previous studies, various Machine
Learning techniques and Pre-trained Deep Learning models have been used in
conjunction with the extraction of various acoustic and linguistic features.
Our study focuses on three models for the classification task in the ADReSS
(The Alzheimers Dementia Recognition through Spontaneous Speech) 2021
Challenge. We use the well-balanced dataset provided by the ADReSS Challenge
for training and validating our models. Model 1 uses various acoustic features
from the eGeMAPs feature-set, Model 2 uses various linguistic features that we
generated from auto-generated transcripts and Model 3 uses the auto-generated
transcripts directly to extract features using a Pre-trained BERT and TF-IDF.
These models are described in detail in the models section.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Decomposition for Table-based Fact Verification. (arXiv:2109.11020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11020">
<div class="article-summary-box-inner">
<span><p>Fact verification based on structured data is challenging as it requires
models to understand both natural language and symbolic operations performed
over tables. Although pre-trained language models have demonstrated a strong
capability in verifying simple statements, they struggle with complex
statements that involve multiple operations. In this paper, we improve fact
verification by decomposing complex statements into simpler subproblems.
Leveraging the programs synthesized by a weakly supervised semantic parser, we
propose a program-guided approach to constructing a pseudo dataset for
decomposition model training. The subproblems, together with their predicted
answers, serve as the intermediate evidence to enhance our fact verification
model. Experiments show that our proposed approach achieves the new
state-of-the-art performance, an 82.7\% accuracy, on the TabFact benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional Poisson Stochastic Beam Search. (arXiv:2109.11034v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11034">
<div class="article-summary-box-inner">
<span><p>Beam search is the default decoding strategy for many sequence generation
tasks in NLP. The set of approximate K-best items returned by the algorithm is
a useful summary of the distribution for many applications; however, the
candidates typically exhibit high overlap and may give a highly biased estimate
for expectations under our model. These problems can be addressed by instead
using stochastic decoding strategies. In this work, we propose a new method for
turning beam search into a stochastic process: Conditional Poisson stochastic
beam search. Rather than taking the maximizing set at each iteration, we sample
K candidates without replacement according to the conditional Poisson sampling
design. We view this as a more natural alternative to Kool et. al. 2019's
stochastic beam search (SBS). Furthermore, we show how samples generated under
the CPSBS design can be used to build consistent estimators and sample diverse
sets from sequence models. In our experiments, we observe CPSBS produces lower
variance and more efficient estimators than SBS, even showing improvements in
high entropy settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlled Evaluation of Grammatical Knowledge in Mandarin Chinese Language Models. (arXiv:2109.11058v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11058">
<div class="article-summary-box-inner">
<span><p>Prior work has shown that structural supervision helps English language
models learn generalizations about syntactic phenomena such as subject-verb
agreement. However, it remains unclear if such an inductive bias would also
improve language models' ability to learn grammatical dependencies in
typologically different languages. Here we investigate this question in
Mandarin Chinese, which has a logographic, largely syllable-based writing
system; different word order; and sparser morphology than English. We train
LSTMs, Recurrent Neural Network Grammars, Transformer language models, and
Transformer-parameterized generative parsing models on two Mandarin Chinese
datasets of different sizes. We evaluate the models' ability to learn different
aspects of Mandarin grammar that assess syntactic and semantic relationships.
We find suggestive evidence that structural supervision helps with representing
syntactic state across intervening content and improves performance in low-data
settings, suggesting that the benefits of hierarchical inductive biases in
acquiring dependency relationships may extend beyond English.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Sociolinguistic Variables to Reveal Changing Attitudes Towards Sexuality and Gender. (arXiv:2109.11061v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11061">
<div class="article-summary-box-inner">
<span><p>Individuals signal aspects of their identity and beliefs through linguistic
choices. Studying these choices in aggregate allows us to examine large-scale
attitude shifts within a population. Here, we develop computational methods to
study word choice within a sociolinguistic lexical variable -- alternate words
used to express the same concept -- in order to test for change in the United
States towards sexuality and gender. We examine two variables: i) referents to
significant others, such as the word "partner" and ii) referents to an
indefinite person, both of which could optionally be marked with gender. The
linguistic choices in each variable allow us to study increased rates of
acceptances of gay marriage and gender equality, respectively. In longitudinal
analyses across Twitter and Reddit over 87M messages, we demonstrate that
attitudes are changing but that these changes are driven by specific
demographics within the United States. Further, in a quasi-causal analysis, we
show that passages of Marriage Equality Acts in different states are drivers of
linguistic change.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Actionable Conversational Quality Indicators for Improving Task-Oriented Dialog Systems. (arXiv:2109.11064v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11064">
<div class="article-summary-box-inner">
<span><p>Automatic dialog systems have become a mainstream part of online customer
service. Many such systems are built, maintained, and improved by customer
service specialists, rather than dialog systems engineers and computer
programmers. As conversations between people and machines become commonplace,
it is critical to understand what is working, what is not, and what actions can
be taken to reduce the frequency of inappropriate system responses. These
analyses and recommendations need to be presented in terms that directly
reflect the user experience rather than the internal dialog processing.
</p>
<p>This paper introduces and explains the use of Actionable Conversational
Quality Indicators (ACQIs), which are used both to recognize parts of dialogs
that can be improved, and to recommend how to improve them. This combines
benefits of previous approaches, some of which have focused on producing dialog
quality scoring while others have sought to categorize the types of errors the
dialog system is making.
</p>
<p>We demonstrate the effectiveness of using ACQIs on LivePerson internal dialog
systems used in commercial customer service applications, and on the publicly
available CMU LEGOv2 conversational dataset (Raux et al. 2005). We report on
the annotation and analysis of conversational datasets showing which ACQIs are
important to fix in various situations.
</p>
<p>The annotated datasets are then used to build a predictive model which uses a
turn-based vector embedding of the message texts and achieves an 79% weighted
average f1-measure at the task of finding the correct ACQI for a given
conversation. We predict that if such a model worked perfectly, the range of
potential improvement actions a bot-builder must consider at each turn could be
reduced by an average of 81%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Universal Dense Retrieval for Open-domain Question Answering. (arXiv:2109.11085v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11085">
<div class="article-summary-box-inner">
<span><p>In open-domain question answering, a model receives a text question as input
and searches for the correct answer using a large evidence corpus. The
retrieval step is especially difficult as typical evidence corpora have
\textit{millions} of documents, each of which may or may not have the correct
answer to the question. Very recently, dense models have replaced sparse
methods as the de facto retrieval method. Rather than focusing on lexical
overlap to determine similarity, dense methods build an encoding function that
captures semantic similarity by learning from a small collection of
question-answer or question-context pairs. In this paper, we investigate dense
retrieval models in the context of open-domain question answering across
different input distributions. To do this, first we introduce an entity-rich
question answering dataset constructed from Wikidata facts and demonstrate
dense models are unable to generalize to unseen input question distributions.
Second, we perform analyses aimed at better understanding the source of the
problem and propose new training techniques to improve out-of-domain
performance on a wide variety of datasets. We encourage the field to further
investigate the creation of a single, universal dense retrieval model that
generalizes well across all input distributions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BiRdQA: A Bilingual Dataset for Question Answering on Tricky Riddles. (arXiv:2109.11087v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11087">
<div class="article-summary-box-inner">
<span><p>A riddle is a question or statement with double or veiled meanings, followed
by an unexpected answer. Solving riddle is a challenging task for both machine
and human, testing the capability of understanding figurative, creative natural
language and reasoning with commonsense knowledge. We introduce BiRdQA, a
bilingual multiple-choice question answering dataset with 6614 English riddles
and 8751 Chinese riddles. For each riddle-answer pair, we provide four
distractors with additional information from Wikipedia. The distractors are
automatically generated at scale with minimal bias. Existing monolingual and
multilingual QA models fail to perform well on our dataset, indicating that
there is a long way to go before machine can beat human on solving tricky
riddles. The dataset has been released to the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distiller: A Systematic Study of Model Distillation Methods in Natural Language Processing. (arXiv:2109.11105v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11105">
<div class="article-summary-box-inner">
<span><p>We aim to identify how different components in the KD pipeline affect the
resulting performance and how much the optimal KD pipeline varies across
different datasets/tasks, such as the data augmentation policy, the loss
function, and the intermediate representation for transferring the knowledge
between teacher and student. To tease apart their effects, we propose
Distiller, a meta KD framework that systematically combines a broad range of
techniques across different stages of the KD pipeline, which enables us to
quantify each component's contribution. Within Distiller, we unify commonly
used objectives for distillation of intermediate representations under a
universal mutual information (MI) objective and propose a class of MI-$\alpha$
objective functions with better bias/variance trade-off for estimating the MI
between the teacher and the student. On a diverse set of NLP datasets, the best
Distiller configurations are identified via large-scale hyperparameter
optimization. Our experiments reveal the following: 1) the approach used to
distill the intermediate representations is the most important factor in KD
performance, 2) among different objectives for intermediate distillation,
MI-$\alpha$ performs the best, and 3) data augmentation provides a large boost
for small training datasets or small student networks. Moreover, we find that
different datasets/tasks prefer different KD algorithms, and thus propose a
simple AutoDistiller algorithm that can recommend a good KD pipeline for a new
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Lingual Language Model Meta-Pretraining. (arXiv:2109.11129v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11129">
<div class="article-summary-box-inner">
<span><p>The success of pretrained cross-lingual language models relies on two
essential abilities, i.e., generalization ability for learning downstream tasks
in a source language, and cross-lingual transferability for transferring the
task knowledge to other languages. However, current methods jointly learn the
two abilities in a single-phase cross-lingual pretraining process, resulting in
a trade-off between generalization and cross-lingual transfer. In this paper,
we propose cross-lingual language model meta-pretraining, which learns the two
abilities in different training phases. Our method introduces an additional
meta-pretraining phase before cross-lingual pretraining, where the model learns
generalization ability on a large-scale monolingual corpus. Then, the model
focuses on learning cross-lingual transfer on a multilingual corpus.
Experimental results show that our method improves both generalization and
cross-lingual transfer, and produces better-aligned representations across
different languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-Parametric Online Learning from Human Feedback for Neural Machine Translation. (arXiv:2109.11136v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11136">
<div class="article-summary-box-inner">
<span><p>We study the problem of online learning with human feedback in the
human-in-the-loop machine translation, in which the human translators revise
the machine-generated translations and then the corrected translations are used
to improve the neural machine translation (NMT) system. However, previous
methods require online model updating or additional translation memory networks
to achieve high-quality performance, making them inflexible and inefficient in
practice. In this paper, we propose a novel non-parametric online learning
method without changing the model structure. This approach introduces two
k-nearest-neighbor (KNN) modules: one module memorizes the human feedback,
which is the correct sentences provided by human translators, while the other
balances the usage of the history human feedback and original NMT models
adaptively. Experiments conducted on EMEA and JRC-Acquis benchmarks demonstrate
that our proposed method obtains substantial improvements on translation
accuracy and achieves better adaptation performance with less repeating human
correction operations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint speaker diarisation and tracking in switching state-space model. (arXiv:2109.11140v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11140">
<div class="article-summary-box-inner">
<span><p>Speakers may move around while diarisation is being performed. When a
microphone array is used, the instantaneous locations of where the sounds
originated from can be estimated, and previous investigations have shown that
such information can be complementary to speaker embeddings in the diarisation
task. However, these approaches often assume that speakers are fairly
stationary throughout a meeting. This paper relaxes this assumption, by
proposing to explicitly track the movements of speakers while jointly
performing diarisation within a unified model. A state-space model is proposed,
where the hidden state expresses the identity of the current active speaker and
the predicted locations of all speakers. The model is implemented as a particle
filter. Experiments on a Microsoft rich meeting transcription task show that
the proposed joint location tracking and diarisation approach is able to
perform comparably with other methods that use location information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Information Extraction as a Unified Text-to-Triple Translation. (arXiv:2109.11171v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11171">
<div class="article-summary-box-inner">
<span><p>We cast a suite of information extraction tasks into a text-to-triple
translation framework. Instead of solving each task relying on task-specific
datasets and models, we formalize the task as a translation between
task-specific input text and output triples. By taking the task-specific input,
we enable a task-agnostic translation by leveraging the latent knowledge that a
pre-trained language model has about the task. We further demonstrate that a
simple pre-training task of predicting which relational information corresponds
to which input text is an effective way to produce task-specific outputs. This
enables the zero-shot transfer of our framework to downstream tasks. We study
the zero-shot performance of this framework on open information extraction
(OIE2016, NYT, WEB, PENN), relation classification (FewRel and TACRED), and
factual probe (Google-RE and T-REx). The model transfers non-trivially to most
tasks and is often competitive with a fully supervised method without the need
for any task-specific training. For instance, we significantly outperform the
F1 score of the supervised open information extraction without needing to use
its training set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Curriculum Learning in Unsupervised Neural Machine Translation. (arXiv:2109.11177v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11177">
<div class="article-summary-box-inner">
<span><p>Back-translation (BT) has become one of the de facto components in
unsupervised neural machine translation (UNMT), and it explicitly makes UNMT
have translation ability. However, all the pseudo bi-texts generated by BT are
treated equally as clean data during optimization without considering the
quality diversity, leading to slow convergence and limited translation
performance. To address this problem, we propose a curriculum learning method
to gradually utilize pseudo bi-texts based on their quality from multiple
granularities. Specifically, we first apply cross-lingual word embedding to
calculate the potential translation difficulty (quality) for the monolingual
sentences. Then, the sentences are fed into UNMT from easy to hard batch by
batch. Furthermore, considering the quality of sentences/tokens in a particular
batch are also diverse, we further adopt the model itself to calculate the
fine-grained quality scores, which are served as learning factors to balance
the contributions of different parts when computing loss and encourage the UNMT
model to focus on pseudo data with higher quality. Experimental results on WMT
14 En-Fr, WMT 16 En-De, WMT 16 En-Ro, and LDC En-Zh translation tasks
demonstrate that the proposed method achieves consistent improvements with
faster convergence speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incorporating Linguistic Knowledge for Abstractive Multi-document Summarization. (arXiv:2109.11199v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11199">
<div class="article-summary-box-inner">
<span><p>Within natural language processing tasks, linguistic knowledge can always
serve an important role in assisting the model to learn excel representations
and better guide the natural language generation. In this work, we develop a
neural network based abstractive multi-document summarization (MDS) model which
leverages dependency parsing to capture cross-positional dependencies and
grammatical structures. More concretely, we process the dependency information
into the linguistic-guided attention mechanism and further fuse it with the
multi-head attention for better feature representation. With the help of
linguistic signals, sentence-level relations can be correctly captured, thus
improving MDS performance. Our model has two versions based on Flat-Transformer
and Hierarchical Transformer respectively. Empirical studies on both versions
demonstrate that this simple but effective method outperforms existing works on
the benchmark dataset. Extensive analyses examine different settings and
configurations of the proposed model which provide a good reference to the
community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fuzzy Generalised Quantifiers for Natural Language in Categorical Compositional Distributional Semantics. (arXiv:2109.11227v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11227">
<div class="article-summary-box-inner">
<span><p>Recent work on compositional distributional models shows that bialgebras over
finite dimensional vector spaces can be applied to treat generalised
quantifiers for natural language. That technique requires one to construct the
vector space over powersets, and therefore is computationally costly. In this
paper, we overcome this problem by considering fuzzy versions of quantifiers
along the lines of Zadeh, within the category of many valued relations. We show
that this category is a concrete instantiation of the compositional
distributional model. We show that the semantics obtained in this model is
equivalent to the semantics of the fuzzy quantifiers of Zadeh. As a result, we
are now able to treat fuzzy quantification without requiring a powerset
construction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pregroup Grammars, their Syntax and Semantics. (arXiv:2109.11237v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11237">
<div class="article-summary-box-inner">
<span><p>Pregroup grammars were developed in 1999 and stayed Lambek's preferred
algebraic model of grammar. The set-theoretic semantics of pregroups, however,
faces an ambiguity problem. In his latest book, Lambek suggests that this
problem might be overcome using finite dimensional vector spaces rather than
sets. What is the right notion of composition in this setting, direct sum or
tensor product of spaces?
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Volctrans GLAT System: Non-autoregressive Translation Meets WMT21. (arXiv:2109.11247v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11247">
<div class="article-summary-box-inner">
<span><p>This paper describes the Volctrans' submission to the WMT21 news translation
shared task for German-&gt;English translation. We build a parallel (i.e.,
non-autoregressive) translation system using the Glancing Transformer, which
enables fast and accurate parallel decoding in contrast to the currently
prevailing autoregressive models. To the best of our knowledge, this is the
first parallel translation system that can be scaled to such a practical
scenario like WMT competition. More importantly, our parallel translation
system achieves the best BLEU score (35.0) on German-&gt;English translation task,
outperforming all strong autoregressive counterparts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Question Generation Debias Question Answering Models? A Case Study on Question-Context Lexical Overlap. (arXiv:2109.11256v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11256">
<div class="article-summary-box-inner">
<span><p>Question answering (QA) models for reading comprehension have been
demonstrated to exploit unintended dataset biases such as question-context
lexical overlap. This hinders QA models from generalizing to under-represented
samples such as questions with low lexical overlap. Question generation (QG), a
method for augmenting QA datasets, can be a solution for such performance
degradation if QG can properly debias QA datasets. However, we discover that
recent neural QG models are biased towards generating questions with high
lexical overlap, which can amplify the dataset bias. Moreover, our analysis
reveals that data augmentation with these QG models frequently impairs the
performance on questions with low lexical overlap, while improving that on
questions with high lexical overlap. To address this problem, we use a synonym
replacement-based approach to augment questions with low lexical overlap. We
demonstrate that the proposed data augmentation approach is simple yet
effective to mitigate the degradation problem with only 70k synthetic examples.
Our data is publicly available at
https://github.com/KazutoshiShinoda/Synonym-Replacement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't be Contradicted with Anything! CI-ToD: Towards Benchmarking Consistency for Task-oriented Dialogue System. (arXiv:2109.11292v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11292">
<div class="article-summary-box-inner">
<span><p>Consistency Identification has obtained remarkable success on open-domain
dialogue, which can be used for preventing inconsistent response generation.
However, in contrast to the rapid development in open-domain dialogue, few
efforts have been made to the task-oriented dialogue direction. In this paper,
we argue that consistency problem is more urgent in task-oriented domain. To
facilitate the research, we introduce CI-ToD, a novel dataset for Consistency
Identification in Task-oriented Dialog system. In addition, we not only
annotate the single label to enable the model to judge whether the system
response is contradictory, but also provide more fine-grained labels (i.e.,
Dialogue History Inconsistency, User Query Inconsistency and Knowledge Base
Inconsistency) to encourage model to know what inconsistent sources lead to it.
Empirical results show that state-of-the-art methods only achieve 51.3%, which
is far behind the human performance of 93.2%, indicating that there is ample
room for improving consistency identification ability. Finally, we conduct
exhaustive experiments and qualitative analysis to comprehend key challenges
and provide guidance for future directions. All datasets and models are
publicly available at \url{https://github.com/yizhen20133868/CI-ToD}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Knowledge Distillation for Pre-trained Language Models. (arXiv:2109.11295v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11295">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation~(KD) has been proved effective for compressing
large-scale pre-trained language models. However, existing methods conduct KD
statically, e.g., the student model aligns its output distribution to that of a
selected teacher model on the pre-defined training dataset. In this paper, we
explore whether a dynamic knowledge distillation that empowers the student to
adjust the learning procedure according to its competency, regarding the
student performance and learning efficiency. We explore the dynamical
adjustments on three aspects: teacher model adoption, data selection, and KD
objective adaptation. Experimental results show that (1) proper selection of
teacher model can boost the performance of student model; (2) conducting KD
with 10% informative instances achieves comparable performance while greatly
accelerates the training; (3) the student performance can be boosted by
adjusting the supervision contribution of different alignment objective. We
find dynamic knowledge distillation is promising and provide discussions on
potential future directions towards more efficient KD methods. Our code is
available at https://github.com/lancopku/DynamicKD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breaking BERT: Understanding its Vulnerabilities for Named Entity Recognition through Adversarial Attack. (arXiv:2109.11308v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11308">
<div class="article-summary-box-inner">
<span><p>Both generic and domain-specific BERT models are widely used for natural
language processing (NLP) tasks. In this paper we investigate the vulnerability
of BERT models to variation in input data for Named Entity Recognition (NER)
through adversarial attack. Experimental results show that the original as well
as the domain-specific BERT models are highly vulnerable to entity replacement:
They can be fooled in 89.2 to 99.4% of the cases to mislabel previously correct
entities. BERT models are also vulnerable to variation in the entity context
with 20.2 to 45.0% of entities predicted completely wrong and another 29.3 to
53.3% of entities predicted wrong partially. Often a single change is
sufficient to fool the model. BERT models seem most vulnerable to changes in
the local context of entities. Of the two domain-specific BERT models, the
vulnerability of BioBERT is comparable to the original BERT model whereas
SciBERT is even more vulnerable. Our results chart the vulnerabilities of BERT
models for NER and emphasize the importance of further research into uncovering
and reducing these weaknesses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ParaShoot: A Hebrew Question Answering Dataset. (arXiv:2109.11314v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11314">
<div class="article-summary-box-inner">
<span><p>NLP research in Hebrew has largely focused on morphology and syntax, where
rich annotated datasets in the spirit of Universal Dependencies are available.
Semantic datasets, however, are in short supply, hindering crucial advances in
the development of NLP technology in Hebrew. In this work, we present
ParaShoot, the first question answering dataset in modern Hebrew. The dataset
follows the format and crowdsourcing methodology of SQuAD, and contains
approximately 3000 annotated examples, similar to other question-answering
datasets in low-resource languages. We provide the first baseline results using
recently-released BERT-style models for Hebrew, showing that there is
significant room for improvement on this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Learning for Argument Strength Estimation. (arXiv:2109.11319v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11319">
<div class="article-summary-box-inner">
<span><p>High-quality arguments are an essential part of decision-making.
Automatically predicting the quality of an argument is a complex task that
recently got much attention in argument mining. However, the annotation effort
for this task is exceptionally high. Therefore, we test uncertainty-based
active learning (AL) methods on two popular argument-strength data sets to
estimate whether sample-efficient learning can be enabled. Our extensive
empirical evaluation shows that uncertainty-based acquisition functions can not
surpass the accuracy reached with the random acquisition on these data sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transferring Knowledge from Vision to Language: How to Achieve it and how to Measure it?. (arXiv:2109.11321v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11321">
<div class="article-summary-box-inner">
<span><p>Large language models are known to suffer from the hallucination problem in
that they are prone to output statements that are false or inconsistent,
indicating a lack of knowledge. A proposed solution to this is to provide the
model with additional data modalities that complements the knowledge obtained
through text. We investigate the use of visual data to complement the knowledge
of large language models by proposing a method for evaluating visual knowledge
transfer to text for uni- or multimodal language models. The method is based on
two steps, 1) a novel task querying for knowledge of memory colors, i.e.
typical colors of well-known objects, and 2) filtering of model training data
to clearly separate knowledge contributions. Additionally, we introduce a model
architecture that involves a visual imagination step and evaluate it with our
proposed method. We find that our method can successfully be used to measure
visual knowledge transfer capabilities in models and that our novel model
architecture shows promising results for leveraging multimodal knowledge in a
unimodal setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Current State of Finnish NLP. (arXiv:2109.11326v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11326">
<div class="article-summary-box-inner">
<span><p>There are a lot of tools and resources available for processing Finnish. In
this paper, we survey recent papers focusing on Finnish NLP related to many
different subcategories of NLP such as parsing, generation, semantics and
speech. NLP research is conducted in many different research groups in Finland,
and it is frequently the case that NLP tools and models resulting from academic
research are made available for others to use on platforms such as Github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating Pattern- and Fact-based Fake News Detection via Model Preference Learning. (arXiv:2109.11333v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11333">
<div class="article-summary-box-inner">
<span><p>To defend against fake news, researchers have developed various methods based
on texts. These methods can be grouped as 1) pattern-based methods, which focus
on shared patterns among fake news posts rather than the claim itself; and 2)
fact-based methods, which retrieve from external sources to verify the claim's
veracity without considering patterns. The two groups of methods, which have
different preferences of textual clues, actually play complementary roles in
detecting fake news. However, few works consider their integration. In this
paper, we study the problem of integrating pattern- and fact-based models into
one framework via modeling their preference differences, i.e., making the
pattern- and fact-based models focus on respective preferred parts in a post
and mitigate interference from non-preferred parts as possible. To this end, we
build a Preference-aware Fake News Detection Framework (Pref-FEND), which
learns the respective preferences of pattern- and fact-based models for joint
detection. We first design a heterogeneous dynamic graph convolutional network
to generate the respective preference maps, and then use these maps to guide
the joint learning of pattern- and fact-based models for final prediction.
Experiments on two real-world datasets show that Pref-FEND effectively captures
model preferences and improves the performance of models based on patterns,
facts, or both.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Second Pandemic? Analysis of Fake News About COVID-19 Vaccines in Qatar. (arXiv:2109.11372v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11372">
<div class="article-summary-box-inner">
<span><p>While COVID-19 vaccines are finally becoming widely available, a second
pandemic that revolves around the circulation of anti-vaxxer fake news may
hinder efforts to recover from the first one. With this in mind, we performed
an extensive analysis of Arabic and English tweets about COVID-19 vaccines,
with focus on messages originating from Qatar. We found that Arabic tweets
contain a lot of false information and rumors, while English tweets are mostly
factual. However, English tweets are much more propagandistic than Arabic ones.
In terms of propaganda techniques, about half of the Arabic tweets express
doubt, and 1/5 use loaded language, while English tweets are abundant in loaded
language, exaggeration, fear, name-calling, doubt, and flag-waving. Finally, in
terms of framing, Arabic tweets adopt a health and safety perspective, while in
English economic concerns dominate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WRENCH: A Comprehensive Benchmark for Weak Supervision. (arXiv:2109.11377v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11377">
<div class="article-summary-box-inner">
<span><p>Recent \emph{Weak Supervision (WS)} approaches have had widespread success in
easing the bottleneck of labeling training data for machine learning by
synthesizing labels from multiple potentially noisy supervision sources.
However, proper measurement and analysis of these approaches remain a
challenge. First, datasets used in existing works are often private and/or
custom, limiting standardization. Second, WS datasets with the same name and
base data often vary in terms of the labels and weak supervision sources used,
a significant "hidden" source of evaluation variance. Finally, WS studies often
diverge in terms of the evaluation protocol and ablations used. To address
these problems, we introduce a benchmark platform, \benchmark, for a thorough
and standardized evaluation of WS approaches. It consists of 22 varied
real-world datasets for classification and sequence tagging; a range of real,
synthetic, and procedurally-generated weak supervision sources; and a modular,
extensible framework for WS evaluation, including implementations for popular
WS methods. We use \benchmark to conduct extensive comparisons over more than
100 method variants to demonstrate its efficacy as a benchmark platform. The
code is available at \url{https://github.com/JieyuZ2/wrench}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cluster-based Mention Typing for Named Entity Disambiguation. (arXiv:2109.11389v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11389">
<div class="article-summary-box-inner">
<span><p>An entity mention in text such as "Washington" may correspond to many
different named entities such as the city "Washington D.C." or the newspaper
"Washington Post." The goal of named entity disambiguation is to identify the
mentioned named entity correctly among all possible candidates. If the type
(e.g. location or person) of a mentioned entity can be correctly predicted from
the context, it may increase the chance of selecting the right candidate by
assigning low probability to the unlikely ones. This paper proposes
cluster-based mention typing for named entity disambiguation. The aim of
mention typing is to predict the type of a given mention based on its context.
Generally, manually curated type taxonomies such as Wikipedia categories are
used. We introduce cluster-based mention typing, where named entities are
clustered based on their contextual similarities and the cluster ids are
assigned as types. The hyperlinked mentions and their context in Wikipedia are
used in order to obtain these cluster-based types. Then, mention typing models
are trained on these mentions, which have been labeled with their cluster-based
types through distant supervision. At the named entity disambiguation phase,
first the cluster-based types of a given mention are predicted and then, these
types are used as features in a ranking model to select the best entity among
the candidates. We represent entities at multiple contextual levels and obtain
different clusterings (and thus typing models) based on each level. As each
clustering breaks the entity space differently, mention typing based on each
clustering discriminates the mention differently. When predictions from all
typing models are used together, our system achieves better or comparable
results based on randomization tests with respect to the state-of-the-art
levels on four defacto test sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Named Entity Recognition and Classification on Historical Documents: A Survey. (arXiv:2109.11406v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11406">
<div class="article-summary-box-inner">
<span><p>After decades of massive digitisation, an unprecedented amount of historical
documents is available in digital format, along with their machine-readable
texts. While this represents a major step forward with respect to preservation
and accessibility, it also opens up new opportunities in terms of content
mining and the next fundamental challenge is to develop appropriate
technologies to efficiently search, retrieve and explore information from this
'big data of the past'. Among semantic indexing opportunities, the recognition
and classification of named entities are in great demand among humanities
scholars. Yet, named entity recognition (NER) systems are heavily challenged
with diverse, historical and noisy inputs. In this survey, we present the array
of challenges posed by historical documents to NER, inventory existing
resources, describe the main approaches deployed so far, and identify key
priorities for future developments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Algorithm for Generating Gap-Fill Multiple Choice Questions of an Expert System. (arXiv:2109.11421v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11421">
<div class="article-summary-box-inner">
<span><p>This research is aimed to propose an artificial intelligence algorithm
comprising an ontology-based design, text mining, and natural language
processing for automatically generating gap-fill multiple choice questions
(MCQs). The simulation of this research demonstrated an application of the
algorithm in generating gap-fill MCQs about software testing. The simulation
results revealed that by using 103 online documents as inputs, the algorithm
could automatically produce more than 16 thousand valid gap-fill MCQs covering
a variety of topics in the software testing domain. Finally, in the discussion
section of this paper we suggest how the proposed algorithm should be applied
to produce gap-fill MCQs being collected in a question pool used by a knowledge
expert system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Fact-Checking: A Survey. (arXiv:2109.11427v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11427">
<div class="article-summary-box-inner">
<span><p>As online false information continues to grow, automated fact-checking has
gained an increasing amount of attention in recent years. Researchers in the
field of Natural Language Processing (NLP) have contributed to the task by
building fact-checking datasets, devising automated fact-checking pipelines and
proposing NLP methods to further research in the development of different
components. This paper reviews relevant research on automated fact-checking
covering both the claim detection and claim validation components.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Corpus and Models for Lemmatisation and POS-tagging of Old French. (arXiv:2109.11442v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11442">
<div class="article-summary-box-inner">
<span><p>Old French is a typical example of an under-resourced historic languages,
that furtherly displays animportant amount of linguistic variation. In this
paper, we present the current results of a long going project (2015-...) and
describe how we broached the difficult question of providing lemmatisation
andPOS models for Old French with the help of neural taggers and the
progressive constitution of dedicated corpora.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Putting Words in BERT's Mouth: Navigating Contextualized Vector Spaces with Pseudowords. (arXiv:2109.11491v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11491">
<div class="article-summary-box-inner">
<span><p>We present a method for exploring regions around individual points in a
contextualized vector space (particularly, BERT space), as a way to investigate
how these regions correspond to word senses. By inducing a contextualized
"pseudoword" as a stand-in for a static embedding in the input layer, and then
performing masked prediction of a word in the sentence, we are able to
investigate the geometry of the BERT-space in a controlled manner around
individual instances. Using our method on a set of carefully constructed
sentences targeting ambiguous English words, we find substantial regularity in
the contextualized space, with regions that correspond to distinct word senses;
but between these regions there are occasionally "sense voids" -- regions that
do not correspond to any intelligible sense.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finding a Balanced Degree of Automation for Summary Evaluation. (arXiv:2109.11503v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11503">
<div class="article-summary-box-inner">
<span><p>Human evaluation for summarization tasks is reliable but brings in issues of
reproducibility and high costs. Automatic metrics are cheap and reproducible
but sometimes poorly correlated with human judgment. In this work, we propose
flexible semiautomatic to automatic summary evaluation metrics, following the
Pyramid human evaluation method. Semi-automatic Lite2Pyramid retains the
reusable human-labeled Summary Content Units (SCUs) for reference(s) but
replaces the manual work of judging SCUs' presence in system summaries with a
natural language inference (NLI) model. Fully automatic Lite3Pyramid further
substitutes SCUs with automatically extracted Semantic Triplet Units (STUs) via
a semantic role labeling (SRL) model. Finally, we propose in-between metrics,
Lite2.xPyramid, where we use a simple regressor to predict how well the STUs
can simulate SCUs and retain SCUs that are more difficult to simulate, which
provides a smooth transition and balance between automation and manual
evaluation. Comparing to 15 existing metrics, we evaluate human-metric
correlations on 3 existing meta-evaluation datasets and our newly-collected
PyrXSum (with 100/10 XSum examples/systems). It shows that Lite2Pyramid
consistently has the best summary-level correlations; Lite3Pyramid works better
than or comparable to other automatic metrics; Lite2.xPyramid trades off small
correlation drops for larger manual effort reduction, which can reduce costs
for future data collection. Our code and data are publicly available at:
https://github.com/ZhangShiyue/Lite2-3Pyramid
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MARMOT: A Deep Learning Framework for Constructing Multimodal Representations for Vision-and-Language Tasks. (arXiv:2109.11526v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11526">
<div class="article-summary-box-inner">
<span><p>Political activity on social media presents a data-rich window into political
behavior, but the vast amount of data means that almost all content analyses of
social media require a data labeling step. However, most automated machine
classification methods ignore the multimodality of posted content, focusing
either on text or images. State-of-the-art vision-and-language models are
unusable for most political science research: they require all observations to
have both image and text and require computationally expensive pretraining.
This paper proposes a novel vision-and-language framework called multimodal
representations using modality translation (MARMOT). MARMOT presents two
methodological contributions: it can construct representations for observations
missing image or text, and it replaces the computationally expensive
pretraining with modality translation. MARMOT outperforms an ensemble text-only
classifier in 19 of 20 categories in multilabel classifications of tweets
reporting election incidents during the 2016 U.S. general election. Moreover,
MARMOT shows significant improvements over the results of benchmark multimodal
models on the Hateful Memes dataset, improving the best result set by
VisualBERT in terms of accuracy from 0.6473 to 0.6760 and area under the
receiver operating characteristic curve (AUC) from 0.7141 to 0.7530.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Query-Variant Advertisement Text Generation with Association Knowledge. (arXiv:2004.06438v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.06438">
<div class="article-summary-box-inner">
<span><p>Online advertising is an important revenue source for many IT companies. In
the search advertising scenario, advertisement text that meets the need of the
search query would be more attractive to the user. However, the manual creation
of query-variant advertisement texts for massive items is expensive.
Traditional text generation methods tend to focus on the general searching
needs with high frequency while ignoring the diverse personalized searching
needs with low frequency. In this paper, we propose the query-variant
advertisement text generation task that aims to generate candidate
advertisement texts for different web search queries with various needs based
on queries and item keywords. To solve the problem of ignoring low-frequency
needs, we propose a dynamic association mechanism to expand the receptive field
based on external knowledge, which can obtain associated words to be added to
the input. These associated words can serve as bridges to transfer the ability
of the model from the familiar high-frequency words to the unfamiliar
low-frequency words. With association, the model can make use of various
personalized needs in queries and generate query-variant advertisement texts.
Both automatic and human evaluations show that our model can generate more
attractive advertisement text than baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summary-Source Proposition-level Alignment: Task, Datasets and Supervised Baseline. (arXiv:2009.00590v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00590">
<div class="article-summary-box-inner">
<span><p>Aligning sentences in a reference summary with their counterparts in source
documents was shown as a useful auxiliary summarization task, notably for
generating training data for salience detection. Despite its assessed utility,
the alignment step was mostly approached with heuristic unsupervised methods,
typically ROUGE-based, and was never independently optimized or evaluated. In
this paper, we propose establishing summary-source alignment as an explicit
task, while introducing two major novelties: (1) applying it at the more
accurate proposition span level, and (2) approaching it as a supervised
classification task. To that end, we created a novel training dataset for
proposition-level alignment, derived automatically from available summarization
evaluation data. In addition, we crowdsourced dev and test datasets, enabling
model development and proper evaluation. Utilizing these data, we present a
supervised proposition alignment baseline model, showing improved
alignment-quality over the unsupervised approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">N-LTP: An Open-source Neural Language Technology Platform for Chinese. (arXiv:2009.11616v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.11616">
<div class="article-summary-box-inner">
<span><p>We introduce \texttt{N-LTP}, an open-source neural language technology
platform supporting six fundamental Chinese NLP tasks: {lexical analysis}
(Chinese word segmentation, part-of-speech tagging, and named entity
recognition), {syntactic parsing} (dependency parsing), and {semantic parsing}
(semantic dependency parsing and semantic role labeling). Unlike the existing
state-of-the-art toolkits, such as \texttt{Stanza}, that adopt an independent
model for each task, \texttt{N-LTP} adopts the multi-task framework by using a
shared pre-trained model, which has the advantage of capturing the shared
knowledge across relevant Chinese tasks. In addition, a knowledge distillation
method \cite{DBLP:journals/corr/abs-1907-04829} where the single-task model
teaches the multi-task model is further introduced to encourage the multi-task
model to surpass its single-task teacher. Finally, we provide a collection of
easy-to-use APIs and a visualization tool to make users to use and view the
processing results more easily and directly. To the best of our knowledge, this
is the first toolkit to support six Chinese NLP fundamental tasks. Source code,
documentation, and pre-trained models are available at
\url{https://github.com/HIT-SCIR/ltp}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Simultaneous Translation by Incorporating Pseudo-References with Fewer Reorderings. (arXiv:2010.11247v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11247">
<div class="article-summary-box-inner">
<span><p>Simultaneous translation is vastly different from full-sentence translation,
in the sense that it starts translation before the source sentence ends, with
only a few words delay. However, due to the lack of large-scale, high-quality
simultaneous translation datasets, most such systems are still trained on
conventional full-sentence bitexts. This is far from ideal for the simultaneous
scenario due to the abundance of unnecessary long-distance reorderings in those
bitexts. We propose a novel method that rewrites the target side of existing
full-sentence corpora into simultaneous-style translation. Experiments on
Zh-&gt;En and Ja-&gt;En simultaneous translation show substantial improvements (up to
+2.7 BLEU) with the addition of these generated pseudo-references.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Validating Label Consistency in NER Data Annotation. (arXiv:2101.08698v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08698">
<div class="article-summary-box-inner">
<span><p>Data annotation plays a crucial role in ensuring your named entity
recognition (NER) projects are trained with the right information to learn
from. Producing the most accurate labels is a challenge due to the complexity
involved with annotation. Label inconsistency between multiple subsets of data
annotation (e.g., training set and test set, or multiple training subsets) is
an indicator of label mistakes. In this work, we present an empirical method to
explore the relationship between label (in-)consistency and NER model
performance. It can be used to validate the label consistency (or catches the
inconsistency) in multiple sets of NER data annotation. In experiments, our
method identified the label inconsistency of test data in SCIERC and CoNLL03
datasets (with 26.7% and 5.4% label mistakes). It validated the consistency in
the corrected version of both datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking. (arXiv:2104.04466v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04466">
<div class="article-summary-box-inner">
<span><p>Dialogue State Tracking is central to multi-domain task-oriented dialogue
systems, responsible for extracting information from user utterances. We
present a novel hybrid architecture that augments GPT-2 with representations
derived from Graph Attention Networks in such a way to allow causal, sequential
prediction of slot values. The model architecture captures inter-slot
relationships and dependencies across domains that otherwise can be lost in
sequential prediction. We report improvements in state tracking performance in
MultiWOZ 2.0 against a strong GPT-2 baseline and investigate a simplified
sparse training scenario in which DST models are trained only on session-level
annotations but evaluated at the turn level. We further report detailed
analyses to demonstrate the effectiveness of graph models in DST by showing
that the proposed graph modules capture inter-slot dependencies and improve the
predictions of values that are common to multiple domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effect of Visual Extensions on Natural Language Understanding in Vision-and-Language Models. (arXiv:2104.08066v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08066">
<div class="article-summary-box-inner">
<span><p>A method for creating a vision-and-language (V&amp;L) model is to extend a
language model through structural modifications and V&amp;L pre-training. Such an
extension aims to make a V&amp;L model inherit the capability of natural language
understanding (NLU) from the original language model. To see how well this is
achieved, we propose to evaluate V&amp;L models using an NLU benchmark (GLUE). We
compare five V&amp;L models, including single-stream and dual-stream models,
trained with the same pre-training. Dual-stream models, with their higher
modality independence achieved by approximately doubling the number of
parameters, are expected to preserve the NLU capability better. Our main
finding is that the dual-stream scores are not much different than the
single-stream scores, contrary to expectation. Further analysis shows that
pre-training causes the performance drop in NLU tasks with few exceptions.
These results suggest that adopting a single-stream structure and devising the
pre-training could be an effective method for improving the maintenance of
language knowledge in V&amp;L extensions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers: "The End of History" for NLP?. (arXiv:2105.00813v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00813">
<div class="article-summary-box-inner">
<span><p>Recent advances in neural architectures, such as the Transformer, coupled
with the emergence of large-scale pre-trained models such as BERT, have
revolutionized the field of Natural Language Processing (NLP), pushing the
state of the art for a number of NLP tasks. A rich family of variations of
these models has been proposed, such as RoBERTa, ALBERT, and XLNet, but
fundamentally, they all remain limited in their ability to model certain kinds
of information, and they cannot cope with certain information sources, which
was easy for pre-existing models. Thus, here we aim to shed light on some
important theoretical limitations of pre-trained BERT-style models that are
inherent in the general Transformer architecture. First, we demonstrate in
practice on two general types of tasks -- segmentation and segment labeling --
and on four datasets that these limitations are indeed harmful and that
addressing them, even in some very simple and naive ways, can yield sizable
improvements over vanilla RoBERTa and XLNet models. Then, we offer a more
general discussion on desiderata for future additions to the Transformer
architecture that would increase its expressiveness, which we hope could help
in the design of the next generation of deep NLP architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Neural Diarization for Unlimited Numbers of Speakers Using Global and Local Attractors. (arXiv:2107.01545v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01545">
<div class="article-summary-box-inner">
<span><p>Attractor-based end-to-end diarization is achieving comparable accuracy to
the carefully tuned conventional clustering-based methods on challenging
datasets. However, the main drawback is that it cannot deal with the case where
the number of speakers is larger than the one observed during training. This is
because its speaker counting relies on supervised learning. In this work, we
introduce an unsupervised clustering process embedded in the attractor-based
end-to-end diarization. We first split a sequence of frame-wise embeddings into
short subsequences and then perform attractor-based diarization for each
subsequence. Given subsequence-wise diarization results, inter-subsequence
speaker correspondence is obtained by unsupervised clustering of the vectors
computed from the attractors from all the subsequences. This makes it possible
to produce diarization results of a large number of speakers for the whole
recording even if the number of output speakers for each subsequence is
limited. Experimental results showed that our method could produce accurate
diarization results of an unseen number of speakers. Our method achieved 11.84
%, 28.33 %, and 19.49 % on the CALLHOME, DIHARD II, and DIHARD III datasets,
respectively, each of which is better than the conventional end-to-end
diarization methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Token-Level Supervised Contrastive Learning for Punctuation Restoration. (arXiv:2107.09099v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09099">
<div class="article-summary-box-inner">
<span><p>Punctuation is critical in understanding natural language text. Currently,
most automatic speech recognition (ASR) systems do not generate punctuation,
which affects the performance of downstream tasks, such as intent detection and
slot filling. This gives rise to the need for punctuation restoration. Recent
work in punctuation restoration heavily utilizes pre-trained language models
without considering data imbalance when predicting punctuation classes. In this
work, we address this problem by proposing a token-level supervised contrastive
learning method that aims at maximizing the distance of representation of
different punctuation marks in the embedding space. The result shows that
training with token-level supervised contrastive learning obtains up to 3.2%
absolute F1 improvement on the test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finetuning Pretrained Transformers into Variational Autoencoders. (arXiv:2108.02446v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02446">
<div class="article-summary-box-inner">
<span><p>Text variational autoencoders (VAEs) are notorious for posterior collapse, a
phenomenon where the model's decoder learns to ignore signals from the encoder.
Because posterior collapse is known to be exacerbated by expressive decoders,
Transformers have seen limited adoption as components of text VAEs. Existing
studies that incorporate Transformers into text VAEs (Li et al., 2020; Fang et
al., 2021) mitigate posterior collapse using massive pretraining, a technique
unavailable to most of the research community without extensive computing
resources. We present a simple two-phase training scheme to convert a
sequence-to-sequence Transformer into a VAE with just finetuning. The resulting
language model is competitive with massively pretrained Transformer-based VAEs
in some internal metrics while falling short on others. To facilitate training
we comprehensively explore the impact of common posterior collapse alleviation
techniques in the literature. We release our code for reproducability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapted End-to-End Coreference Resolution System for Anaphoric Identities in Dialogues. (arXiv:2109.00185v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00185">
<div class="article-summary-box-inner">
<span><p>We present an effective system adapted from the end-to-end neural coreference
resolution model, targeting on the task of anaphora resolution in dialogues.
Three aspects are specifically addressed in our approach, including the support
of singletons, encoding speakers and turns throughout dialogue interactions,
and knowledge transfer utilizing existing resources. Despite the simplicity of
our adaptation strategies, they are shown to bring significant impact to the
final performance, with up to 27 F1 improvement over the baseline. Our final
system ranks the 1st place on the leaderboard of the anaphora resolution track
in the CRAC 2021 shared task, and achieves the best evaluation results on all
four datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Cross-Lingual Transfer via Self-Learning with Uncertainty Estimation. (arXiv:2109.00194v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00194">
<div class="article-summary-box-inner">
<span><p>Recent multilingual pre-trained language models have achieved remarkable
zero-shot performance, where the model is only finetuned on one source language
and directly evaluated on target languages. In this work, we propose a
self-learning framework that further utilizes unlabeled data of target
languages, combined with uncertainty estimation in the process to select
high-quality silver labels. Three different uncertainties are adapted and
analyzed specifically for the cross lingual transfer: Language
Heteroscedastic/Homoscedastic Uncertainty (LEU/LOU), Evidential Uncertainty
(EVI). We evaluate our framework with uncertainties on two cross-lingual tasks
including Named Entity Recognition (NER) and Natural Language Inference (NLI)
covering 40 languages in total, which outperforms the baselines significantly
by 10 F1 on average for NER and 2.5 accuracy score for NLI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model Bias in NLP -- Application to Hate Speech Classification. (arXiv:2109.09725v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09725">
<div class="article-summary-box-inner">
<span><p>This document sums up our results forthe NLP lecture at ETH in the spring
semester 2021. In this work, a BERT based neural network model (Devlin et
al.,2018) is applied to the JIGSAW dataset (Jigsaw/Conversation AI, 2019) in
order to create a model identifying hateful and toxic comments (strictly
seperated from offensive language) in online social platforms (English
language), inthis case Twitter. Three other neural network architectures and a
GPT-2 (Radfordet al., 2019) model are also applied on the provided data set in
order to compare these different models. The trained BERT model is then applied
on two different data sets to evaluate its generalisation power, namely on
another Twitter data set (Tom Davidson, 2017) (Davidsonet al., 2017) and the
data set HASOC 2019 (Thomas Mandl, 2019) (Mandl et al.,2019) which includes
Twitter and also Facebook comments; we focus on the English HASOC 2019 data. In
addition, it can be shown that by fine-tuning the trained BERT model on these
two datasets by applying different transfer learning scenarios via retraining
partial or all layers the predictive scores improve compared to simply applying
the model pre-trained on the JIGSAW data set. Withour results, we get
precisions from 64% to around 90% while still achieving acceptable recall
values of at least lower 60s%, proving that BERT is suitable for real usecases
in social platforms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FCM: A Fine-grained Comparison Model for Multi-turn Dialogue Reasoning. (arXiv:2109.10510v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10510">
<div class="article-summary-box-inner">
<span><p>Despite the success of neural dialogue systems in achieving high performance
on the leader-board, they cannot meet users' requirements in practice, due to
their poor reasoning skills. The underlying reason is that most neural dialogue
models only capture the syntactic and semantic information, but fail to model
the logical consistency between the dialogue history and the generated
response. Recently, a new multi-turn dialogue reasoning task has been proposed,
to facilitate dialogue reasoning research. However, this task is challenging,
because there are only slight differences between the illogical response and
the dialogue history. How to effectively solve this challenge is still worth
exploring. This paper proposes a Fine-grained Comparison Model (FCM) to tackle
this problem. Inspired by human's behavior in reading comprehension, a
comparison mechanism is proposed to focus on the fine-grained differences in
the representation of each response candidate. Specifically, each candidate
representation is compared with the whole history to obtain a history
consistency representation. Furthermore, the consistency signals between each
candidate and the speaker's own history are considered to drive a model to
prefer a candidate that is logically consistent with the speaker's history
logic. Finally, the above consistency representations are employed to output a
ranking list of the candidate responses for multi-turn dialogue reasoning.
Experimental results on two public dialogue datasets show that our method
obtains higher ranking scores than the baseline models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Small-Bench NLP: Benchmark for small single GPU trained models in Natural Language Processing. (arXiv:2109.10847v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10847">
<div class="article-summary-box-inner">
<span><p>Recent progress in the Natural Language Processing domain has given us
several State-of-the-Art (SOTA) pretrained models which can be finetuned for
specific tasks. These large models with billions of parameters trained on
numerous GPUs/TPUs over weeks are leading in the benchmark leaderboards. In
this paper, we discuss the need for a benchmark for cost and time effective
smaller models trained on a single GPU. This will enable researchers with
resource constraints experiment with novel and innovative ideas on
tokenization, pretraining tasks, architecture, fine tuning methods etc. We set
up Small-Bench NLP, a benchmark for small efficient neural language models
trained on a single GPU. Small-Bench NLP benchmark comprises of eight NLP tasks
on the publicly available GLUE datasets and a leaderboard to track the progress
of the community. Our ELECTRA-DeBERTa (15M parameters) small model architecture
achieves an average score of 81.53 which is comparable to that of BERT-Base's
82.20 (110M parameters). Our models, code and leaderboard are available at
https://github.com/smallbenchnlp
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixed-supervised segmentation: Confidence maximization helps knowledge distillation. (arXiv:2109.10902v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10902">
<div class="article-summary-box-inner">
<span><p>Despite achieving promising results in a breadth of medical image
segmentation tasks, deep neural networks require large training datasets with
pixel-wise annotations. Obtaining these curated datasets is a cumbersome
process which limits the application in scenarios where annotated images are
scarce. Mixed supervision is an appealing alternative for mitigating this
obstacle, where only a small fraction of the data contains complete pixel-wise
annotations and other images have a weaker form of supervision. In this work,
we propose a dual-branch architecture, where the upper branch (teacher)
receives strong annotations, while the bottom one (student) is driven by
limited supervision and guided by the upper branch. Combined with a standard
cross-entropy loss over the labeled pixels, our novel formulation integrates
two important terms: (i) a Shannon entropy loss defined over the
less-supervised images, which encourages confident student predictions in the
bottom branch; and (ii) a Kullback-Leibler (KL) divergence term, which
transfers the knowledge of the strongly supervised branch to the
less-supervised branch and guides the entropy (student-confidence) term to
avoid trivial solutions. We show that the synergy between the entropy and KL
divergence yields substantial improvements in performance. We also discuss an
interesting link between Shannon-entropy minimization and standard pseudo-mask
generation, and argue that the former should be preferred over the latter for
leveraging information from unlabeled pixels. Quantitative and qualitative
results on two publicly available datasets demonstrate that our method
significantly outperforms other strategies for semantic segmentation within a
mixed-supervision framework, as well as recent semi-supervised approaches.
Moreover, we show that the branch trained with reduced supervision and guided
by the top branch largely outperforms the latter.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The CAMELS Multifield Dataset: Learning the Universe's Fundamental Parameters with Artificial Intelligence. (arXiv:2109.10915v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10915">
<div class="article-summary-box-inner">
<span><p>We present the Cosmology and Astrophysics with MachinE Learning Simulations
(CAMELS) Multifield Dataset, CMD, a collection of hundreds of thousands of 2D
maps and 3D grids containing many different properties of cosmic gas, dark
matter, and stars from 2,000 distinct simulated universes at several cosmic
times. The 2D maps and 3D grids represent cosmic regions that span $\sim$100
million light years and have been generated from thousands of state-of-the-art
hydrodynamic and gravity-only N-body simulations from the CAMELS project.
Designed to train machine learning models, CMD is the largest dataset of its
kind containing more than 70 Terabytes of data. In this paper we describe CMD
in detail and outline a few of its applications. We focus our attention on one
such task, parameter inference, formulating the problems we face as a challenge
to the community. We release all data and provide further technical details at
https://camels-multifield-dataset.readthedocs.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">T6D-Direct: Transformers for Multi-Object 6D Pose Direct Regression. (arXiv:2109.10948v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10948">
<div class="article-summary-box-inner">
<span><p>6D pose estimation is the task of predicting the translation and orientation
of objects in a given input image, which is a crucial prerequisite for many
robotics and augmented reality applications. Lately, the Transformer Network
architecture, equipped with a multi-head self-attention mechanism, is emerging
to achieve state-of-the-art results in many computer vision tasks. DETR, a
Transformer-based model, formulated object detection as a set prediction
problem and achieved impressive results without standard components like region
of interest pooling, non-maximal suppression, and bounding box proposals. In
this work, we propose T6D-Direct, a real-time single-stage direct method with a
transformer-based architecture built on DETR to perform 6D multi-object pose
direct estimation. We evaluate the performance of our method on the YCB-Video
dataset. Our method achieves the fastest inference time, and the pose
estimation accuracy is comparable to state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Contrastive Representation for Semantic Correspondence. (arXiv:2109.10967v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10967">
<div class="article-summary-box-inner">
<span><p>Dense correspondence across semantically related images has been extensively
studied, but still faces two challenges: 1) large variations in appearance,
scale and pose exist even for objects from the same category, and 2) labeling
pixel-level dense correspondences is labor intensive and infeasible to scale.
Most existing approaches focus on designing various matching approaches with
fully-supervised ImageNet pretrained networks. On the other hand, while a
variety of self-supervised approaches are proposed to explicitly measure
image-level similarities, correspondence matching the pixel level remains
under-explored. In this work, we propose a multi-level contrastive learning
approach for semantic matching, which does not rely on any ImageNet pretrained
model. We show that image-level contrastive learning is a key component to
encourage the convolutional features to find correspondence between similar
objects, while the performance can be further enhanced by regularizing
cross-instance cycle-consistency at intermediate feature levels. Experimental
results on the PF-PASCAL, PF-WILLOW, and SPair-71k benchmark datasets
demonstrate that our method performs favorably against the state-of-the-art
approaches. The source code and trained models will be made available to the
public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Efficient and Scalable Collection of Fly-inspired Voting Units for Visual Place Recognition in Changing Environments. (arXiv:2109.10986v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10986">
<div class="article-summary-box-inner">
<span><p>State-of-the-art visual place recognition performance is currently being
achieved utilizing deep learning based approaches. Despite the recent efforts
in designing lightweight convolutional neural network based models, these can
still be too expensive for the most hardware restricted robot applications.
Low-overhead VPR techniques would not only enable platforms equipped with
low-end, cheap hardware but also reduce computation on more powerful systems,
allowing these resources to be allocated for other navigation tasks. In this
work, our goal is to provide an algorithm of extreme compactness and efficiency
while achieving state-of-the-art robustness to appearance changes and small
point-of-view variations. Our first contribution is DrosoNet, an exceptionally
compact model inspired by the odor processing abilities of the fruit fly,
Drosophyla melanogaster. Our second and main contribution is a voting mechanism
that leverages multiple small and efficient classifiers to achieve more robust
and consistent VPR compared to a single one. We use DrosoNet as the baseline
classifier for the voting mechanism and evaluate our models on five benchmark
datasets, assessing moderate to extreme appearance changes and small to
moderate viewpoint variations. We then compare the proposed algorithms to
state-of-the-art methods, both in terms of precision-recall AUC results and
computational efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Benchmark Comparison of Visual Place Recognition Techniques for Resource-Constrained Embedded Platforms. (arXiv:2109.11002v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11002">
<div class="article-summary-box-inner">
<span><p>Visual Place Recognition (VPR) has been a subject of significant research
over the last 15 to 20 years. VPR is a fundamental task for autonomous
navigation as it enables self-localization within an environment. Although
robots are often equipped with resource-constrained hardware, the computational
requirements of and effects on VPR techniques have received little attention.
In this work, we present a hardware-focused benchmark evaluation of a number of
state-of-the-art VPR techniques on public datasets. We consider popular single
board computers, including ODroid, UP and Raspberry Pi 3, in addition to a
commodity desktop and laptop for reference. We present our analysis based on
several key metrics, including place-matching accuracy, image encoding time,
descriptor matching time and memory needs. Key questions addressed include: (1)
How does the performance accuracy of a VPR technique change with processor
architecture? (2) How does power consumption vary for different VPR techniques
and embedded platforms? (3) How much does descriptor size matter in comparison
to today's embedded platforms' storage? (4) How does the performance of a
high-end platform relate to an on-board low-end embedded platform for VPR? The
extensive analysis and results in this work serve not only as a benchmark for
the VPR community, but also provide useful insights for real-world adoption of
VPR applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Modal Coherence for Text-to-Image Retrieval. (arXiv:2109.11047v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11047">
<div class="article-summary-box-inner">
<span><p>Common image-text joint understanding techniques presume that images and the
associated text can universally be characterized by a single implicit model.
However, co-occurring images and text can be related in qualitatively different
ways, and explicitly modeling it could improve the performance of current joint
understanding models. In this paper, we train a Cross-Modal Coherence Modelfor
text-to-image retrieval task. Our analysis shows that models trained with
image--text coherence relations can retrieve images originally paired with
target text more often than coherence-agnostic models. We also show via human
evaluation that images retrieved by the proposed coherence-aware model are
preferred over a coherence-agnostic baseline by a huge margin. Our findings
provide insights into the ways that different modalities communicate and the
role of coherence relations in capturing commonsense inferences in text and
imagery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards practical object detection for weed spraying in precision agriculture. (arXiv:2109.11048v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11048">
<div class="article-summary-box-inner">
<span><p>The evolution of smaller, faster processors and cheaper digital storage
mechanisms across the last 4-5 decades has vastly increased the opportunity to
integrate intelligent technologies in a wide range of practical environments to
address a broad spectrum of tasks. One exciting application domain for such
technologies is precision agriculture, where the ability to integrate on-board
machine vision with data-driven actuation means that farmers can make decisions
about crop care and harvesting at the level of the individual plant rather than
the whole field. This makes sense both economically and environmentally.
However, the key driver for this capability is fast and robust machine vision
-- typically driven by machine learning (ML) solutions and dependent on
accurate modelling. One critical challenge is that the bulk of ML-based vision
research considers only metrics that evaluate the accuracy of object detection
and do not assess practical factors. This paper introduces three metrics that
highlight different aspects relevant for real-world deployment of precision
weeding and demonstrates their utility through experimental results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A two-step machine learning approach for crop disease detection: an application of GAN and UAV technology. (arXiv:2109.11066v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11066">
<div class="article-summary-box-inner">
<span><p>Automated plant diagnosis is a technology that promises large increases in
cost-efficiency for agriculture. However, multiple problems reduce the
effectiveness of drones, including the inverse relationship between resolution
and speed and the lack of adequate labeled training data. This paper presents a
two-step machine learning approach that analyzes low-fidelity and high-fidelity
images in sequence, preserving efficiency as well as accuracy. Two
data-generators are also used to minimize class imbalance in the high-fidelity
dataset and to produce low-fidelity data that is representative of UAV images.
The analysis of applications and methods is conducted on a database of
high-fidelity apple tree images which are corrupted with class imbalance. The
application begins by generating high-fidelity data using generative networks
and then uses this novel data alongside the original high-fidelity data to
produce low-fidelity images. A machine-learning identifier identifies plants
and labels them as potentially diseased or not. A machine learning classifier
is then given the potentially diseased plant images and returns actual
diagnoses for these plants. The results show an accuracy of 96.3% for the
high-fidelity system and a 75.5% confidence level for our low-fidelity system.
Our drone technology shows promising results in accuracy when compared to
labor-based methods of diagnosis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Downsample for Segmentation of Ultra-High Resolution Images. (arXiv:2109.11071v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11071">
<div class="article-summary-box-inner">
<span><p>Segmentation of ultra-high resolution images with deep learning is
challenging because of their enormous size, often millions or even billions of
pixels. Typical solutions drastically downsample the image uniformly to meet
memory constraints, implicitly assuming all pixels equally important by
sampling at the same density at all spatial locations. However this assumption
is not true and compromises the performance of deep learning techniques that
have proved powerful on standard-sized images. For example with uniform
downsampling, see green boxed region in Fig.1, the rider and bike do not have
enough corresponding samples while the trees and buildings are oversampled, and
lead to a negative effect on the segmentation prediction from the
low-resolution downsampled image. In this work we show that learning the
spatially varying downsampling strategy jointly with segmentation offers
advantages in segmenting large images with limited computational budget. Fig.1
shows that our method adapts the sampling density over different locations so
that more samples are collected from the small important regions and less from
the others, which in turn leads to better segmentation accuracy. We show on two
public and one local high-resolution datasets that our method consistently
learns sampling locations preserving more information and boosting segmentation
accuracy over baseline methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Factor Graph-Based Optimization Technique for Stereo Correspondence Estimation. (arXiv:2109.11077v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11077">
<div class="article-summary-box-inner">
<span><p>Dense disparities among multiple views is essential for estimating the 3D
architecture of a scene based on the geometrical relationship among the scene
and the views or cameras. Scenes with larger extents of heterogeneous textures,
differing scene illumination among the multiple views and with occluding
objects affect the accuracy of the estimated disparities. Markov random fields
(MRF) based methods for disparity estimation address these limitations using
spatial dependencies among the observations and among the disparity estimates.
These methods, however, are limited by spatially fixed and smaller neighborhood
systems or cliques. In this work, we present a new factor graph-based
probabilistic graphical model for disparity estimation that allows a larger and
a spatially variable neighborhood structure determined based on the local scene
characteristics. We evaluated our method using the Middlebury benchmark stereo
datasets and the Middlebury evaluation dataset version 3.0 and compared its
performance with recent state-of-the-art disparity estimation algorithms. The
new factor graph-based method provided disparity estimates with higher accuracy
when compared to the recent non-learning- and learning-based disparity
estimation algorithms. In addition to disparity estimation, our factor graph
formulation can be useful for obtaining maximum a posteriori solution to
optimization problems with complex and variable dependency structures as well
as for other dense estimation problems such as optical flow estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unseen Object Amodal Instance Segmentation via Hierarchical Occlusion Modeling. (arXiv:2109.11103v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11103">
<div class="article-summary-box-inner">
<span><p>Instance-aware segmentation of unseen objects is essential for a robotic
system in an unstructured environment. Although previous works achieved
encouraging results, they were limited to segmenting the only visible regions
of unseen objects. For robotic manipulation in a cluttered scene, amodal
perception is required to handle the occluded objects behind others. This paper
addresses Unseen Object Amodal Instance Segmentation (UOAIS) to detect 1)
visible masks, 2) amodal masks, and 3) occlusions on unseen object instances.
For this, we propose a Hierarchical Occlusion Modeling (HOM) scheme designed to
reason about the occlusion by assigning a hierarchy to a feature fusion and
prediction order. We evaluated our method on three benchmarks (tabletop,
indoors, and bin environments) and achieved state-of-the-art (SOTA)
performance. Robot demos for picking up occluded objects, codes, and datasets
are available at https://sites.google.com/view/uoais
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rational Polynomial Camera Model Warping for Deep Learning Based Satellite Multi-View Stereo Matching. (arXiv:2109.11121v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11121">
<div class="article-summary-box-inner">
<span><p>Satellite multi-view stereo (MVS) imagery is particularly suited for
large-scale Earth surface reconstruction. Differing from the perspective camera
model (pin-hole model) that is commonly used for close-range and aerial
cameras, the cubic rational polynomial camera (RPC) model is the mainstream
model for push-broom linear-array satellite cameras. However, the homography
warping used in the prevailing learning based MVS methods is only applicable to
pin-hole cameras. In order to apply the SOTA learning based MVS technology to
the satellite MVS task for large-scale Earth surface reconstruction, RPC
warping should be considered. In this work, we propose, for the first time, a
rigorous RPC warping module. The rational polynomial coefficients are recorded
as a tensor, and the RPC warping is formulated as a series of tensor
transformations. Based on the RPC warping, we propose the deep learning based
satellite MVS (SatMVS) framework for large-scale and wide depth range Earth
surface reconstruction. We also introduce a large-scale satellite image dataset
consisting of 519 5120${\times}$5120 images, which we call the TLC SatMVS
dataset. The satellite images were acquired from a three-line camera (TLC) that
catches triple-view images simultaneously, forming a valuable supplement to the
existing open-source WorldView-3 datasets with single-scanline images.
Experiments show that the proposed RPC warping module and the SatMVS framework
can achieve a superior reconstruction accuracy compared to the pin-hole fitting
method and conventional MVS methods. Code and data are available at
https://github.com/WHU-GPCV/SatMVS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Transfer Attacks With Unknown Data and Class Overlap. (arXiv:2109.11125v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11125">
<div class="article-summary-box-inner">
<span><p>The ability to transfer adversarial attacks from one model (the surrogate) to
another model (the victim) has been an issue of concern within the machine
learning (ML) community. The ability to successfully evade unseen models
represents an uncomfortable level of ease toward implementing attacks. In this
work we note that as studied, current transfer attack research has an
unrealistic advantage for the attacker: the attacker has the exact same
training data as the victim. We present the first study of transferring
adversarial attacks focusing on the data available to attacker and victim under
imperfect settings without querying the victim, where there is some variable
level of overlap in the exact data used or in the classes learned by each
model. This threat model is relevant to applications in medicine, malware, and
others. Under this new threat model attack success rate is not correlated with
data or class overlap in the way one would expect, and varies with dataset.
This makes it difficult for attacker and defender to reason about each other
and contributes to the broader study of model robustness and security. We
remedy this by developing a masked version of Projected Gradient Descent that
simulates class disparity, which enables the attacker to reliably estimate a
lower-bound on their attack's success.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OH-Former: Omni-Relational High-Order Transformer for Person Re-Identification. (arXiv:2109.11159v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11159">
<div class="article-summary-box-inner">
<span><p>Transformers have shown preferable performance on many vision tasks. However,
for the task of person re-identification (ReID), vanilla transformers leave the
rich contexts on high-order feature relations under-exploited and deteriorate
local feature details, which are insufficient due to the dramatic variations of
pedestrians. In this work, we propose an Omni-Relational High-Order Transformer
(OH-Former) to model omni-relational features for ReID. First, to strengthen
the capacity of visual representation, instead of obtaining the attention
matrix based on pairs of queries and isolated keys at each spatial location, we
take a step further to model high-order statistics information for the
non-local mechanism. We share the attention weights in the corresponding layer
of each order with a prior mixing mechanism to reduce the computation cost.
Then, a convolution-based local relation perception module is proposed to
extract the local relations and 2D position information. The experimental
results of our model are superior promising, which show state-of-the-art
performance on Market-1501, DukeMTMC, MSMT17 and Occluded-Duke datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clustering performance analysis using new correlation based cluster validity indices. (arXiv:2109.11172v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11172">
<div class="article-summary-box-inner">
<span><p>There are various cluster validity measures used for evaluating clustering
results. One of the main objective of using these measures is to seek the
optimal unknown number of clusters. Some measures work well for clusters with
different densities, sizes and shapes. Yet, one of the weakness that those
validity measures share is that they sometimes provide only one clear optimal
number of clusters. That number is actually unknown and there might be more
than one potential sub-optimal options that a user may wish to choose based on
different applications. We develop two new cluster validity indices based on a
correlation between an actual distance between a pair of data points and a
centroid distance of clusters that the two points locate in. Our proposed
indices constantly yield several peaks at different numbers of clusters which
overcome the weakness previously stated. Furthermore, the introduced
correlation can also be used for evaluating the quality of a selected
clustering result. Several experiments in different scenarios including the
well-known iris data set and a real-world marketing application have been
conducted in order to compare the proposed validity indices with several
well-known ones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting the Timing of Camera Movements From the Kinematics of Instruments in Robotic-Assisted Surgery Using Artificial Neural Networks. (arXiv:2109.11192v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11192">
<div class="article-summary-box-inner">
<span><p>Robotic-assisted surgeries benefit both surgeons and patients, however,
surgeons frequently need to adjust the endoscopic camera to achieve good
viewpoints. Simultaneously controlling the camera and the surgical instruments
is impossible, and consequentially, these camera adjustments repeatedly
interrupt the surgery. Autonomous camera control could help overcome this
challenge, but most existing systems are reactive, e.g., by having the camera
follow the surgical instruments. We propose a predictive approach for
anticipating when camera movements will occur using artificial neural networks.
We used the kinematic data of the surgical instruments, which were recorded
during robotic-assisted surgical training on porcine models. We split the data
into segments, and labeled each either as a segment that immediately precedes a
camera movement, or one that does not. Due to the large class imbalance, we
trained an ensemble of networks, each on a balanced sub-set of the training
data. We found that the instruments' kinematic data can be used to predict when
camera movements will occur, and evaluated the performance on different segment
durations and ensemble sizes. We also studied how much in advance an upcoming
camera movement can be predicted, and found that predicting a camera movement
0.25, 0.5, and 1 second before they occurred achieved 98%, 94%, and 84%
accuracy relative to the prediction of an imminent camera movement. This
indicates that camera movement events can be predicted early enough to leave
time for computing and executing an autonomous camera movement and suggests
that an autonomous camera controller for RAMIS may one day be feasible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Fine-grained 3D Face Dense Registration: An Optimal Dividing and Diffusing Method. (arXiv:2109.11204v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11204">
<div class="article-summary-box-inner">
<span><p>Dense vertex-to-vertex correspondence between 3D faces is a fundamental and
challenging issue for 3D&amp;2D face analysis. While the sparse landmarks have
anatomically ground-truth correspondence, the dense vertex correspondences on
most facial regions are unknown. In this view, the current literatures commonly
result in reasonable but diverse solutions, which deviate from the optimum to
the 3D face dense registration problem. In this paper, we revisit dense
registration by a dimension-degraded problem, i.e. proportional segmentation of
a line, and employ an iterative dividing and diffusing method to reach the
final solution uniquely. This method is then extended to 3D surface by
formulating a local registration problem for dividing and a linear least-square
problem for diffusing, with constraints on fixed features. On this basis, we
further propose a multi-resolution algorithm to accelerate the computational
process. The proposed method is linked to a novel local scaling metric, where
we illustrate the physical meaning as smooth rearrangement for local cells of
3D facial shapes. Extensive experiments on public datasets demonstrate the
effectiveness of the proposed method in various aspects. Generally, the
proposed method leads to coherent local registrations and elegant mesh grid
routines for fine-grained 3D face dense registrations, which benefits many
downstream applications significantly. It can also be applied to dense
correspondence for other format of data which are not limited to face. The core
code will be publicly available at
https://github.com/NaughtyZZ/3D_face_dense_registration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pairwise Emotional Relationship Recognition in Drama Videos: Dataset and Benchmark. (arXiv:2109.11243v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11243">
<div class="article-summary-box-inner">
<span><p>Recognizing the emotional state of people is a basic but challenging task in
video understanding. In this paper, we propose a new task in this field, named
Pairwise Emotional Relationship Recognition (PERR). This task aims to recognize
the emotional relationship between the two interactive characters in a given
video clip. It is different from the traditional emotion and social relation
recognition task. Varieties of information, consisting of character appearance,
behaviors, facial emotions, dialogues, background music as well as subtitles
contribute differently to the final results, which makes the task more
challenging but meaningful in developing more advanced multi-modal models. To
facilitate the task, we develop a new dataset called Emotional RelAtionship of
inTeractiOn (ERATO) based on dramas and movies. ERATO is a large-scale
multi-modal dataset for PERR task, which has 31,182 video clips, lasting about
203 video hours. Different from the existing datasets, ERATO contains
interaction-centric videos with multi-shots, varied video length, and multiple
modalities including visual, audio and text. As a minor contribution, we
propose a baseline model composed of Synchronous Modal-Temporal Attention
(SMTA) unit to fuse the multi-modal information for the PERR task. In contrast
to other prevailing attention mechanisms, our proposed SMTA can steadily
improve the performance by about 1\%. We expect the ERATO as well as our
proposed SMTA to open up a new way for PERR task in video understanding and
further improve the research of multi-modal fusion methodology.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Dense Video Grounding via Parallel Regression. (arXiv:2109.11265v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11265">
<div class="article-summary-box-inner">
<span><p>Video grounding aims to localize the corresponding video moment in an
untrimmed video given a language query. Existing methods often address this
task in an indirect way, by casting it as a proposal-and-match or
fusion-and-detection problem. Solving these surrogate problems often requires
sophisticated label assignment during training and hand-crafted removal of
near-duplicate results. Meanwhile, existing works typically focus on sparse
video grounding with a single sentence as input, which could result in
ambiguous localization due to its unclear description. In this paper, we tackle
a new problem of dense video grounding, by simultaneously localizing multiple
moments with a paragraph as input. From a perspective on video grounding as
language conditioned regression, we present an end-to-end parallel decoding
paradigm by re-purposing a Transformer-alike architecture (PRVG). The key
design in our PRVG is to use languages as queries, and directly regress the
moment boundaries based on language-modulated visual representations. Thanks to
its simplicity in design, our PRVG framework can be applied in different
testing schemes (sparse or dense grounding) and allows for efficient inference
without any post-processing technique. In addition, we devise a robust
proposal-level attention loss to guide the training of PRVG, which is invariant
to moment duration and contributes to model convergence. We perform experiments
on two video grounding benchmarks of ActivityNet Captions and TACoS,
demonstrating that our PRVG can significantly outperform previous methods. We
also perform in-depth studies to investigate the effectiveness of parallel
regression paradigm on video grounding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Strategies for Industrial Surface Defect Detection Systems. (arXiv:2109.11304v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11304">
<div class="article-summary-box-inner">
<span><p>Deep learning methods have proven to outperform traditional computer vision
methods in various areas of image processing. However, the application of deep
learning in industrial surface defect detection systems is challenging due to
the insufficient amount of training data, the expensive data generation
process, the small size, and the rare occurrence of surface defects. From
literature and a polymer products manufacturing use case, we identify design
requirements which reflect the aforementioned challenges. Addressing these, we
conceptualize design principles and features informed by deep learning
research. Finally, we instantiate and evaluate the gained design knowledge in
the form of actionable guidelines and strategies based on an industrial surface
defect detection use case. This article, therefore, contributes to academia as
well as practice by (1) systematically identifying challenges for the
industrial application of deep learning-based surface defect detection, (2)
strategies to overcome these, and (3) an experimental case study assessing the
strategies' applicability and usefulness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-resolution deep learning pipeline for dense large scale point clouds. (arXiv:2109.11311v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11311">
<div class="article-summary-box-inner">
<span><p>Recent development of 3D sensors allows the acquisition of extremely dense 3D
point clouds of large-scale scenes. The main challenge of processing such large
point clouds remains in the size of the data, which induce expensive
computational and memory cost. In this context, the full resolution cloud is
particularly hard to process, and details it brings are rarely exploited.
Although fine-grained details are important for detection of small objects,
they can alter the local geometry of large structural parts and mislead deep
learning networks. In this paper, we introduce a new generic deep learning
pipeline to exploit the full precision of large scale point clouds, but only
for objects that require details. The core idea of our approach is to split up
the process into multiple sub-networks which operate on different resolutions
and with each their specific classes to retrieve. Thus, the pipeline allows
each class to benefit either from noise and memory cost reduction of a
sub-sampling or from fine-grained details.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Hilti SLAM Challenge Dataset. (arXiv:2109.11316v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11316">
<div class="article-summary-box-inner">
<span><p>Accurate and robust pose estimation is a fundamental capability for
autonomous systems to navigate, map and perform tasks. Particularly,
construction environments pose challenging problem to Simultaneous Localization
and Mapping (SLAM) algorithms due to sparsity, varying illumination conditions,
and dynamic objects. Current academic research in SLAM is focused on developing
more accurate and robust algorithms for example by fusing different sensor
modalities. To help this research, we propose a new dataset, the Hilti SLAM
Challenge Dataset. The sensor platform used to collect this dataset contains a
number of visual, lidar and inertial sensors which have all been rigorously
calibrated. All data is temporally aligned to support precise multi-sensor
fusion. Each dataset includes accurate ground truth to allow direct testing of
SLAM results. Raw data as well as intrinsic and extrinsic sensor calibration
data from twelve datasets in various environments is provided. Each environment
represents common scenarios found in building construction sites in various
stages of completion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Generalized and Incremental Few-Shot Object Detection. (arXiv:2109.11336v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11336">
<div class="article-summary-box-inner">
<span><p>Real-world object detection is highly desired to be equipped with the
learning expandability that can enlarge its detection classes incrementally.
Moreover, such learning from only few annotated training samples further adds
the flexibility for the object detector, which is highly expected in many
applications such as autonomous driving, robotics, etc. However, such
sequential learning scenario with few-shot training samples generally causes
catastrophic forgetting and dramatic overfitting. In this paper, to address the
above incremental few-shot learning issues, a novel Incremental Few-Shot Object
Detection (iFSOD) method is proposed to enable the effective continual learning
from few-shot samples. Specifically, a Double-Branch Framework (DBF) is
proposed to decouple the feature representation of base and novel (few-shot)
class, which facilitates both the old-knowledge retention and new-class
adaption simultaneously. Furthermore, a progressive model updating rule is
carried out to preserve the long-term memory on old classes effectively when
adapt to sequential new classes. Moreover, an inter-task class separation loss
is proposed to extend the decision region of new-coming classes for better
feature discrimination. We conduct experiments on both Pascal VOC and MS-COCO,
which demonstrate that our method can effectively solve the problem of
incremental few-shot detection and significantly improve the detection accuracy
on both base and novel classes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PRANet: Point Cloud Registration with an Artificial Agent. (arXiv:2109.11349v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11349">
<div class="article-summary-box-inner">
<span><p>Point cloud registration plays a critical role in a multitude of computer
vision tasks, such as pose estimation and 3D localization. Recently, a plethora
of deep learning methods were formulated that aim to tackle this problem. Most
of these approaches find point or feature correspondences, from which the
transformations are computed. We give a different perspective and frame the
registration problem as a Markov Decision Process. Instead of directly
searching for the transformation, the problem becomes one of finding a sequence
of translation and rotation actions that is equivalent to this transformation.
To this end, we propose an artificial agent trained end-to-end using deep
supervised learning. In contrast to conventional reinforcement learning
techniques, the observations are sampled i.i.d. and thus no experience replay
buffer is required, resulting in a more streamlined training process.
Experiments on ModelNet40 show results comparable or superior to the state of
the art in the case of clean, noisy and partially visible datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recent Advances of Continual Learning in Computer Vision: An Overview. (arXiv:2109.11369v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11369">
<div class="article-summary-box-inner">
<span><p>In contrast to batch learning where all training data is available at once,
continual learning represents a family of methods that accumulate knowledge and
learn continuously with data available in sequential order. Similar to the
human learning process with the ability of learning, fusing, and accumulating
new knowledge coming at different time steps, continual learning is considered
to have high practical significance. Hence, continual learning has been studied
in various artificial intelligence tasks. In this paper, we present a
comprehensive review of the recent progress of continual learning in computer
vision. In particular, the works are grouped by their representative
techniques, including regularization, knowledge distillation, memory,
generative replay, parameter isolation, and a combination of the above
techniques. For each category of these techniques, both its characteristics and
applications in computer vision are presented. At the end of this overview,
several subareas, where continuous knowledge accumulation is potentially
helpful while continual learning has not been well studied, are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross Attention-guided Dense Network for Images Fusion. (arXiv:2109.11393v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11393">
<div class="article-summary-box-inner">
<span><p>In recent years, various applications in computer vision have achieved
substantial progress based on deep learning, which has been widely used for
image fusion and shown to achieve adequate performance. However, suffering from
limited ability in modelling the spatial correspondence of different source
images, it still remains a great challenge for existing unsupervised image
fusion models to extract appropriate feature and achieves adaptive and balanced
fusion. In this paper, we propose a novel cross attention-guided image fusion
network, which is a unified and unsupervised framework for multi-modal image
fusion, multi-exposure image fusion, and multi-focus image fusion. Different
from the existing self-attention module, our cross attention module focus on
modelling the cross-correlation between different source images. Using the
proposed cross attention module as core block, a densely connected cross
attention-guided network is built to dynamically learn the spatial
correspondence to derive better alignment of important details from different
input images. Meanwhile, an auxiliary branch is also designed to model the
long-range information, and a merging network is attached to finally
reconstruct the fusion image. Extensive experiments have been carried out on
publicly available datasets, and the results demonstrate that the proposed
model outperforms the state-of-the-art quantitatively and qualitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scene Graph Generation for Better Image Captioning?. (arXiv:2109.11398v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11398">
<div class="article-summary-box-inner">
<span><p>We investigate the incorporation of visual relationships into the task of
supervised image caption generation by proposing a model that leverages
detected objects and auto-generated visual relationships to describe images in
natural language. To do so, we first generate a scene graph from raw image
pixels by identifying individual objects and visual relationships between them.
This scene graph then serves as input to our graph-to-text model, which
generates the final caption. In contrast to previous approaches, our model thus
explicitly models the detection of objects and visual relationships in the
image. For our experiments we construct a new dataset from the intersection of
Visual Genome and MS COCO, consisting of images with both a corresponding gold
scene graph and human-authored caption. Our results show that our methods
outperform existing state-of-the-art end-to-end models that generate image
descriptions directly from raw input pixels when compared in terms of the BLEU
and METEOR evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Skeleton-Driven Neural Occupancy Representation for Articulated Hands. (arXiv:2109.11399v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11399">
<div class="article-summary-box-inner">
<span><p>We present Hand ArticuLated Occupancy (HALO), a novel representation of
articulated hands that bridges the advantages of 3D keypoints and neural
implicit surfaces and can be used in end-to-end trainable architectures. Unlike
existing statistical parametric hand models (e.g.~MANO), HALO directly
leverages 3D joint skeleton as input and produces a neural occupancy volume
representing the posed hand surface. The key benefits of HALO are (1) it is
driven by 3D key points, which have benefits in terms of accuracy and are
easier to learn for neural networks than the latent hand-model parameters; (2)
it provides a differentiable volumetric occupancy representation of the posed
hand; (3) it can be trained end-to-end, allowing the formulation of losses on
the hand surface that benefit the learning of 3D keypoints. We demonstrate the
applicability of HALO to the task of conditional generation of hands that grasp
3D objects. The differentiable nature of HALO is shown to improve the quality
of the synthesized hands both in terms of physical plausibility and user
preference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Memory Matching Network for Video Object Segmentation. (arXiv:2109.11404v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11404">
<div class="article-summary-box-inner">
<span><p>We present Hierarchical Memory Matching Network (HMMN) for semi-supervised
video object segmentation. Based on a recent memory-based method [33], we
propose two advanced memory read modules that enable us to perform memory
reading in multiple scales while exploiting temporal smoothness. We first
propose a kernel guided memory matching module that replaces the non-local
dense memory read, commonly adopted in previous memory-based methods. The
module imposes the temporal smoothness constraint in the memory read, leading
to accurate memory retrieval. More importantly, we introduce a hierarchical
memory matching scheme and propose a top-k guided memory matching module in
which memory read on a fine-scale is guided by that on a coarse-scale. With the
module, we perform memory read in multiple scales efficiently and leverage both
high-level semantic and low-level fine-grained memory features to predict
detailed object masks. Our network achieves state-of-the-art performance on the
validation sets of DAVIS 2016/2017 (90.8% and 84.7%) and YouTube-VOS 2018/2019
(82.6% and 82.5%), and test-dev set of DAVIS 2017 (78.6%). The source code and
model are available online: https://github.com/Hongje/HMMN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layered Neural Atlases for Consistent Video Editing. (arXiv:2109.11418v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11418">
<div class="article-summary-box-inner">
<span><p>We present a method that decomposes, or "unwraps", an input video into a set
of layered 2D atlases, each providing a unified representation of the
appearance of an object (or background) over the video. For each pixel in the
video, our method estimates its corresponding 2D coordinate in each of the
atlases, giving us a consistent parameterization of the video, along with an
associated alpha (opacity) value. Importantly, we design our atlases to be
interpretable and semantic, which facilitates easy and intuitive editing in the
atlas domain, with minimal manual work required. Edits applied to a single 2D
atlas (or input video frame) are automatically and consistently mapped back to
the original video frames, while preserving occlusions, deformation, and other
complex scene effects such as shadows and reflections. Our method employs a
coordinate-based Multilayer Perceptron (MLP) representation for mappings,
atlases, and alphas, which are jointly optimized on a per-video basis, using a
combination of video reconstruction and regularization losses. By operating
purely in 2D, our method does not require any prior 3D knowledge about scene
geometry or camera poses, and can handle complex dynamic real world videos. We
demonstrate various video editing applications, including texture mapping,
video style transfer, image-to-video texture transfer, and
segmentation/labeling propagation, all automatically produced by editing a
single 2D atlas image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepRare: Generic Unsupervised Visual Attention Models. (arXiv:2109.11439v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11439">
<div class="article-summary-box-inner">
<span><p>Human visual system is modeled in engineering field providing
feature-engineered methods which detect contrasted/surprising/unusual data into
images. This data is "interesting" for humans and leads to numerous
applications. Deep learning (DNNs) drastically improved the algorithms
efficiency on the main benchmark datasets. However, DNN-based models are
counter-intuitive: surprising or unusual data is by definition difficult to
learn because of its low occurrence probability. In reality, DNN-based models
mainly learn top-down features such as faces, text, people, or animals which
usually attract human attention, but they have low efficiency in extracting
surprising or unusual data in the images. In this paper, we propose a new
visual attention model called DeepRare2021 (DR21) which uses the power of DNNs
feature extraction and the genericity of feature-engineered algorithms. This
algorithm is an evolution of a previous version called DeepRare2019 (DR19)
based on a common framework. DR21 1) does not need any training and uses the
default ImageNet training, 2) is fast even on CPU, 3) is tested on four very
different eye-tracking datasets showing that the DR21 is generic and is always
in the within the top models on all datasets and metrics while no other model
exhibits such a regularity and genericity. Finally DR21 4) is tested with
several network architectures such as VGG16 (V16), VGG19 (V19) and MobileNetV2
(MN2) and 5) it provides explanation and transparency on which parts of the
image are the most surprising at different levels despite the use of a
DNN-based feature extractor. DeepRare2021 code can be found at
https://github.com/numediart/VisualAttention-RareFamil}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisit Geophysical Imaging in A New View of Physics-informed Generative Adversarial Learning. (arXiv:2109.11452v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11452">
<div class="article-summary-box-inner">
<span><p>Seismic full waveform inversion (FWI) is a powerful geophysical imaging
technique that produces high-resolution subsurface models by iteratively
minimizing the misfit between the simulated and observed seismograms.
Unfortunately, conventional FWI with least-squares function suffers from many
drawbacks such as the local-minima problem and computation of explicit
gradient. It is particularly challenging with the contaminated measurements or
poor starting models. Recent works relying on partial differential equations
and neural networks show promising performance for two-dimensional FWI.
Inspired by the competitive learning of generative adversarial networks, we
proposed an unsupervised learning paradigm that integrates wave equation with a
discriminate network to accurately estimate the physically consistent models in
a distribution sense. Our framework needs no labelled training data nor
pretraining of the network, is flexible to achieve multi-parameters inversion
with minimal user interaction. The proposed method faithfully recovers the
well-known synthetic models that outperforms the classical algorithms.
Furthermore, our work paves the way to sidestep the local-minima issue via
reducing the sensitivity to initial models and noise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Segmentation-assisted Scene Completion for LiDAR Point Clouds. (arXiv:2109.11453v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11453">
<div class="article-summary-box-inner">
<span><p>Outdoor scene completion is a challenging issue in 3D scene understanding,
which plays an important role in intelligent robotics and autonomous driving.
Due to the sparsity of LiDAR acquisition, it is far more complex for 3D scene
completion and semantic segmentation. Since semantic features can provide
constraints and semantic priors for completion tasks, the relationship between
them is worth exploring. Therefore, we propose an end-to-end semantic
segmentation-assisted scene completion network, including a 2D completion
branch and a 3D semantic segmentation branch. Specifically, the network takes a
raw point cloud as input, and merges the features from the segmentation branch
into the completion branch hierarchically to provide semantic information. By
adopting BEV representation and 3D sparse convolution, we can benefit from the
lower operand while maintaining effective expression. Besides, the decoder of
the segmentation branch is used as an auxiliary, which can be discarded in the
inference stage to save computational consumption. Extensive experiments
demonstrate that our method achieves competitive performance on SemanticKITTI
dataset with low latency. Code and models will be released at
https://github.com/jokester-zzz/SSA-SC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Learning for Semi-supervised Temporal Language Grounding. (arXiv:2109.11475v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11475">
<div class="article-summary-box-inner">
<span><p>Given a text description, Temporal Language Grounding (TLG) aims to localize
temporal boundaries of the segments that contain the specified semantics in an
untrimmed video. TLG is inherently a challenging task, as it requires to have
comprehensive understanding of both video contents and text sentences. Previous
works either tackle this task in a fully-supervised setting that requires a
large amount of manual annotations or in a weakly supervised setting that
cannot achieve satisfactory performance. To achieve good performance with
limited annotations, we tackle this task in a semi-supervised way and propose a
unified Semi-supervised Temporal Language Grounding (STLG) framework. STLG
consists of two parts: (1) A pseudo label generation module that produces
adaptive instant pseudo labels for unlabeled data based on predictions from a
teacher model; (2) A self-supervised feature learning module with two
sequential perturbations, i.e., time lagging and time scaling, for improving
the video representation by inter-modal and intra-modal contrastive learning.
We conduct experiments on the ActivityNet-CD-OOD and Charades-CD-OOD datasets
and the results demonstrate that our proposed STLG framework achieve
competitive performance compared to fully-supervised state-of-the-art methods
with only a small portion of temporal annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Tuberculosis (TB) Prediction using Synthetically Generated Computed Tomography (CT) Images. (arXiv:2109.11480v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11480">
<div class="article-summary-box-inner">
<span><p>The evaluation of infectious disease processes on radiologic images is an
important and challenging task in medical image analysis. Pulmonary infections
can often be best imaged and evaluated through computed tomography (CT) scans,
which are often not available in low-resource environments and difficult to
obtain for critically ill patients. On the other hand, X-ray, a different type
of imaging procedure, is inexpensive, often available at the bedside and more
widely available, but offers a simpler, two dimensional image. We show that by
relying on a model that learns to generate CT images from X-rays synthetically,
we can improve the automatic disease classification accuracy and provide
clinicians with a different look at the pulmonary disease process.
Specifically, we investigate Tuberculosis (TB), a deadly bacterial infectious
disease that predominantly affects the lungs, but also other organ systems. We
show that relying on synthetically generated CT improves TB identification by
7.50% and distinguishes TB properties up to 12.16% better than the X-ray
baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LGD: Label-guided Self-distillation for Object Detection. (arXiv:2109.11496v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11496">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose the first self-distillation framework for general
object detection, termed LGD (Label-Guided self-Distillation). Previous studies
rely on a strong pretrained teacher to provide instructive knowledge for
distillation. However, this could be unavailable in real-world scenarios.
Instead, we generate an instructive knowledge by inter-and-intra relation
modeling among objects, requiring only student representations and regular
labels. In detail, our framework involves sparse label-appearance encoding,
inter-object relation adaptation and intra-object knowledge mapping to obtain
the instructive knowledge. Modules in LGD are trained end-to-end with student
detector and are discarded in inference. Empirically, LGD obtains decent
results on various detectors, datasets, and extensive task like instance
segmentation. For example in MS-COCO dataset, LGD improves RetinaNet with
ResNet-50 under 2x single-scale training from 36.2% to 39.0% mAP (+ 2.8%). For
much stronger detectors like FCOS with ResNeXt-101 DCN v2 under 2x multi-scale
training (46.1%), LGD achieves 47.9% (+ 1.8%). For pedestrian detection in
CrowdHuman dataset, LGD boosts mMR by 2.3% for Faster R-CNN with ResNet-50.
Compared with a classical teacher-based method FGFI, LGD not only performs
better without requiring pretrained teacher but also with 51% lower training
cost beyond inherent student learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging distributed contact force measurements for slip detection: a physics-based approach enabled by a data-driven tactile sensor. (arXiv:2109.11504v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11504">
<div class="article-summary-box-inner">
<span><p>Grasping objects whose physical properties are unknown is still a great
challenge in robotics. Most solutions rely entirely on visual data to plan the
best grasping strategy. However, to match human abilities and be able to
reliably pick and hold unknown objects, the integration of an artificial sense
of touch in robotic systems is pivotal. This paper describes a novel
model-based slip detection pipeline that can predict possibly failing grasps in
real-time and signal a necessary increase in grip force. As such, the slip
detector does not rely on manually collected data, but exploits physics to
generalize across different tasks. To evaluate the approach, a state-of-the-art
vision-based tactile sensor that accurately estimates distributed forces was
integrated into a grasping setup composed of a six degrees-of-freedom cobot and
a two-finger gripper. Results show that the system can reliably predict slip
while manipulating objects of different shapes, materials, and weights. The
sensor can detect both translational and rotational slip in various scenarios,
making it suitable to improve the stability of a grasp.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How much "human-like" visual experience do current self-supervised learning algorithms need to achieve human-level object recognition?. (arXiv:2109.11523v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11523">
<div class="article-summary-box-inner">
<span><p>This paper addresses a fundamental question: how good are our current
self-supervised visual representation learning algorithms relative to humans?
More concretely, how much "human-like", natural visual experience would these
algorithms need in order to reach human-level performance in a complex,
realistic visual object recognition task such as ImageNet? Using a scaling
experiment, here we estimate that the answer is on the order of a million years
of natural visual experience, in other words several orders of magnitude longer
than a human lifetime. However, this estimate is quite sensitive to some
underlying assumptions, underscoring the need to run carefully controlled human
experiments. We discuss the main caveats surrounding our estimate and the
implications of this rather surprising result.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End AI-based MRI Reconstruction and Lesion Detection Pipeline for Evaluation of Deep Learning Image Reconstruction. (arXiv:2109.11524v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11524">
<div class="article-summary-box-inner">
<span><p>Deep learning techniques have emerged as a promising approach to highly
accelerated MRI. However, recent reconstruction challenges have shown several
drawbacks in current deep learning approaches, including the loss of fine image
details even using models that perform well in terms of global quality metrics.
In this study, we propose an end-to-end deep learning framework for image
reconstruction and pathology detection, which enables a clinically aware
evaluation of deep learning reconstruction quality. The solution is
demonstrated for a use case in detecting meniscal tears on knee MRI studies,
ultimately finding a loss of fine image details with common reconstruction
methods expressed as a reduced ability to detect important pathology like
meniscal tears. Despite the common practice of quantitative reconstruction
methodology evaluation with metrics such as SSIM, impaired pathology detection
as an automated pathology-based reconstruction evaluation approach suggests
existing quantitative methods do not capture clinically important
reconstruction outcomes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MARMOT: A Deep Learning Framework for Constructing Multimodal Representations for Vision-and-Language Tasks. (arXiv:2109.11526v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11526">
<div class="article-summary-box-inner">
<span><p>Political activity on social media presents a data-rich window into political
behavior, but the vast amount of data means that almost all content analyses of
social media require a data labeling step. However, most automated machine
classification methods ignore the multimodality of posted content, focusing
either on text or images. State-of-the-art vision-and-language models are
unusable for most political science research: they require all observations to
have both image and text and require computationally expensive pretraining.
This paper proposes a novel vision-and-language framework called multimodal
representations using modality translation (MARMOT). MARMOT presents two
methodological contributions: it can construct representations for observations
missing image or text, and it replaces the computationally expensive
pretraining with modality translation. MARMOT outperforms an ensemble text-only
classifier in 19 of 20 categories in multilabel classifications of tweets
reporting election incidents during the 2016 U.S. general election. Moreover,
MARMOT shows significant improvements over the results of benchmark multimodal
models on the Hateful Memes dataset, improving the best result set by
VisualBERT in terms of accuracy from 0.6473 to 0.6760 and area under the
receiver operating characteristic curve (AUC) from 0.7141 to 0.7530.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Big to Small: Multi-Scale Local Planar Guidance for Monocular Depth Estimation. (arXiv:1907.10326v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.10326">
<div class="article-summary-box-inner">
<span><p>Estimating accurate depth from a single image is challenging because it is an
ill-posed problem as infinitely many 3D scenes can be projected to the same 2D
scene. However, recent works based on deep convolutional neural networks show
great progress with plausible results. The convolutional neural networks are
generally composed of two parts: an encoder for dense feature extraction and a
decoder for predicting the desired depth. In the encoder-decoder schemes,
repeated strided convolution and spatial pooling layers lower the spatial
resolution of transitional outputs, and several techniques such as skip
connections or multi-layer deconvolutional networks are adopted to recover the
original resolution for effective dense prediction. In this paper, for more
effective guidance of densely encoded features to the desired depth prediction,
we propose a network architecture that utilizes novel local planar guidance
layers located at multiple stages in the decoding phase. We show that the
proposed method outperforms the state-of-the-art works with significant margin
evaluating on challenging benchmarks. We also provide results from an ablation
study to validate the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Pruning for Model Compression. (arXiv:1911.09817v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.09817">
<div class="article-summary-box-inner">
<span><p>Previous AutoML pruning works utilized individual layer features to
automatically prune filters. We analyze the correlation for two layers from the
different blocks which have a short-cut structure. It shows that, in one block,
the deeper layer has many redundant filters which can be represented by filters
in the former layer. So, it is necessary to take information from other layers
into consideration in pruning. In this paper, a novel pruning method, named
GraphPruning, is proposed. Any series of the network is viewed as a graph. To
automatically aggregate neighboring features for each node, a graph aggregator
based on graph convolution networks(GCN) is designed. In the training stage, a
PruningNet that is given aggregated node features generates reasonable weights
for any size of the sub-network. Subsequently, the best configuration of the
Pruned Network is searched by reinforcement learning. Different from previous
work, we take the node features from a well-trained graph aggregator instead of
the hand-craft features, as the states in reinforcement learning. Compared with
other AutoML pruning works, our method has achieved the state-of-the-art under
the same conditions on ImageNet-2012.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Angular Triplet Loss-based Camera Network for ReID. (arXiv:2005.05740v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.05740">
<div class="article-summary-box-inner">
<span><p>Person re-identification (ReID) is a challenging crosscamera retrieval task
to identify pedestrians. Many complex network structures are proposed recently
and many of them concentrate on multi-branch features to achieve high
performance. However, they are too heavy-weight to deploy in realworld
applications. Additionally, pedestrian images are often captured by different
surveillance cameras, so the varied lights, perspectives and resolutions result
in inevitable multi-camera domain gaps for ReID. To address these issues, this
paper proposes ATCN, a simple but effective angular triplet loss-based camera
network, which is able to achieve compelling performance with only global
features. In ATCN, a novel angular distance is introduced to learn a more
discriminative feature representation in the embedding space. Meanwhile, a
lightweight camera network is designed to transfer global features to more
discriminative features. ATCN is designed to be simple and flexible so it can
be easily deployed in practice. The experiment results on various benchmark
datasets show that ATCN outperforms many SOTA approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Convolutional Neural Network for emotion recognition to assist psychiatrists and psychologists during the COVID-19 pandemic: experts opinion. (arXiv:2005.07649v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.07649">
<div class="article-summary-box-inner">
<span><p>A web application with real-time emotion recognition for psychologists and
psychiatrists is presented. Mental health effects during COVID-19 quarantine
need to be handled because society is being emotionally impacted. The human
micro-expressions can describe genuine emotions that can be captured by
Convolutional Neural Networks (CNN) models. But the challenge is to implement
it under the poor performance of a part of society computers and the low speed
of internet connection, i.e., improve the computational efficiency and reduce
the data transfer. To validate the computational efficiency premise, we compare
CNN architectures results, collecting the floating-point operations per second
(FLOPS), the Number of Parameters (NP) and accuracy from the MobileNet,
PeleeNet, Extended Deep Neural Network (EDNN), Inception- Based Deep Neural
Network (IDNN) and our proposed Residual mobile-based Network model (ResmoNet).
Also, we compare the trained models results in terms of Main Memory Utilization
(MMU) and Response Time to complete the Emotion (RTE) recognition. Besides, we
design a data transfer that includes the raw data of emotions and the basic
patient information. The web application was evaluated with the System
Usability Scale (SUS) and a utility questionnaire by psychologists and
psychiatrists. ResmoNet model generated the most reduced NP, FLOPS, and MMU
results, only EDNN overcomes ResmoNet in 0.01sec in RTE. The optimizations to
our model impacted the accuracy, therefore IDNN and EDNN are 0.02 and 0.05 more
accurate than our model respectively. Finally, according to psychologists and
psychiatrists, the web application has good usability (73.8 of 100) and utility
(3.94 of 5).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Co-Training with Task Decomposition for Semi-Supervised Domain Adaptation. (arXiv:2007.12684v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12684">
<div class="article-summary-box-inner">
<span><p>Semi-supervised domain adaptation (SSDA) aims to adapt models trained from a
labeled source domain to a different but related target domain, from which
unlabeled data and a small set of labeled data are provided. Current methods
that treat source and target supervision without distinction overlook their
inherent discrepancy, resulting in a source-dominated model that has not
effectively used the target supervision. In this paper, we argue that the
labeled target data needs to be distinguished for effective SSDA, and propose
to explicitly decompose the SSDA task into two sub-tasks: a semi-supervised
learning (SSL) task in the target domain and an unsupervised domain adaptation
(UDA) task across domains. By doing so, the two sub-tasks can better leverage
the corresponding supervision and thus yield very different classifiers. To
integrate the strengths of the two classifiers, we apply the well-established
co-training framework, in which the two classifiers exchange their high
confident predictions to iteratively "teach each other" so that both
classifiers can excel in the target domain. We call our approach Deep
Co-training with Task decomposition (DeCoTa). DeCoTa requires no adversarial
training and is easy to implement. Moreover, DeCoTa is well-founded on the
theoretical condition of when co-training would succeed. As a result, DeCoTa
achieves state-of-the-art results on several SSDA datasets, outperforming the
prior art by a notable 4% margin on DomainNet. Code is available at
https://github.com/LoyoYang/DeCoTa
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Gradient Flow Framework For Analyzing Network Pruning. (arXiv:2009.11839v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.11839">
<div class="article-summary-box-inner">
<span><p>Recent network pruning methods focus on pruning models early-on in training.
To estimate the impact of removing a parameter, these methods use importance
measures that were originally designed to prune trained models. Despite lacking
justification for their use early-on in training, such measures result in
surprisingly low accuracy loss. To better explain this behavior, we develop a
general framework that uses gradient flow to unify state-of-the-art importance
measures through the norm of model parameters. We use this framework to
determine the relationship between pruning measures and evolution of model
parameters, establishing several results related to pruning models early-on in
training: (i) magnitude-based pruning removes parameters that contribute least
to reduction in loss, resulting in models that converge faster than
magnitude-agnostic methods; (ii) loss-preservation based pruning preserves
first-order model evolution dynamics and is therefore appropriate for pruning
minimally trained models; and (iii) gradient-norm based pruning affects
second-order model evolution dynamics, such that increasing gradient norm via
pruning can produce poorly performing models. We validate our claims on several
VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100. Code
available at https://github.com/EkdeepSLubana/flowandprune.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Annotation-efficient deep learning for automatic medical image segmentation. (arXiv:2012.04885v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04885">
<div class="article-summary-box-inner">
<span><p>Automatic medical image segmentation plays a critical role in scientific
research and medical care. Existing high-performance deep learning methods
typically rely on large training datasets with high-quality manual annotations,
which are difficult to obtain in many clinical applications. Here, we introduce
Annotation-effIcient Deep lEarning (AIDE), an open-source framework to handle
imperfect training datasets. Methodological analyses and empirical evaluations
are conducted, and we demonstrate that AIDE surpasses conventional
fully-supervised models by presenting better performance on open datasets
possessing scarce or noisy annotations. We further test AIDE in a real-life
case study for breast tumor segmentation. Three datasets containing 11,852
breast images from three medical centers are employed, and AIDE, utilizing 10%
training annotations, consistently produces segmentation maps comparable to
those generated by fully-supervised counterparts or provided by independent
radiologists. The 10-fold enhanced efficiency in utilizing expert labels has
the potential to promote a wide range of biomedical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Affective Computer Vision Models by Crowdsourcing Soft-Target Labels. (arXiv:2101.03477v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03477">
<div class="article-summary-box-inner">
<span><p>Emotion classifiers traditionally predict discrete emotions. However, emotion
expressions are often subjective, thus requiring a method to handle subjective
labels. We explore the use of crowdsourcing to acquire reliable soft-target
labels and evaluate an emotion detection classifier trained with these labels.
We center our study on the Child Affective Facial Expression (CAFE) dataset, a
gold standard collection of images depicting pediatric facial expressions along
with 100 human labels per image. To test the feasibility of crowdsourcing to
generate these labels, we used Microworkers to acquire labels for 207 CAFE
images. We evaluate both unfiltered workers as well as workers selected through
a short crowd filtration process. We then train two versions of a classifiers
on soft-target CAFE labels using the original 100 annotations provided with the
dataset: (1) a classifier trained with traditional one-hot encoded labels, and
(2) a classifier trained with vector labels representing the distribution of
CAFE annotator responses. We compare the resulting softmax output distributions
of the two classifiers with a 2-sample independent t-test of L1 distances
between the classifier's output probability distribution and the distribution
of human labels. While agreement with CAFE is weak for unfiltered crowd
workers, the filtered crowd agree with the CAFE labels 100% of the time for
many emotions. While the F1-score for a one-hot encoded classifier is much
higher (94.33% vs. 78.68%) with respect to the ground truth CAFE labels, the
output probability vector of the crowd-trained classifier more closely
resembles the distribution of human labels (t=3.2827, p=0.0014). Reporting an
emotion probability distribution that accounts for the subjectivity of human
interpretation. Crowdsourcing, including a sufficient filtering mechanism, is a
feasible solution for acquiring soft-target labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Puzzle-CAM: Improved localization via matching partial and full features. (arXiv:2101.11253v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11253">
<div class="article-summary-box-inner">
<span><p>Weakly-supervised semantic segmentation (WSSS) is introduced to narrow the
gap for semantic segmentation performance from pixel-level supervision to
image-level supervision. Most advanced approaches are based on class activation
maps (CAMs) to generate pseudo-labels to train the segmentation network. The
main limitation of WSSS is that the process of generating pseudo-labels from
CAMs that use an image classifier is mainly focused on the most discriminative
parts of the objects. To address this issue, we propose Puzzle-CAM, a process
that minimizes differences between the features from separate patches and the
whole image. Our method consists of a puzzle module and two regularization
terms to discover the most integrated region in an object. Puzzle-CAM can
activate the overall region of an object using image-level supervision without
requiring extra parameters. % In experiments, Puzzle-CAM outperformed previous
state-of-the-art methods using the same labels for supervision on the PASCAL
VOC 2012 test dataset. In experiments, Puzzle-CAM outperformed previous
state-of-the-art methods using the same labels for supervision on the PASCAL
VOC 2012 dataset. Code associated with our experiments is available at
https://github.com/OFRIN/PuzzleCAM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Representation Learning via Maximization of Local Mutual Information. (arXiv:2103.04537v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04537">
<div class="article-summary-box-inner">
<span><p>We propose and demonstrate a representation learning approach by maximizing
the mutual information between local features of images and text. The goal of
this approach is to learn useful image representations by taking advantage of
the rich information contained in the free text that describes the findings in
the image. Our method trains image and text encoders by encouraging the
resulting representations to exhibit high local mutual information. We make use
of recent advances in mutual information estimation with neural network
discriminators. We argue that the sum of local mutual information is typically
a lower bound on the global mutual information. Our experimental results in the
downstream image classification tasks demonstrate the advantages of using local
features for image-text representation learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Generalization of Transfer Learning Across Domains Using Spatio-Temporal Features in Autonomous Driving. (arXiv:2103.08116v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08116">
<div class="article-summary-box-inner">
<span><p>Practical learning-based autonomous driving models must be capable of
generalizing learned behaviors from simulated to real domains, and from
training data to unseen domains with unusual image properties. In this paper,
we investigate transfer learning methods that achieve robustness to domain
shifts by taking advantage of the invariance of spatio-temporal features across
domains. In this paper, we propose a transfer learning method to improve
generalization across domains via transfer of spatio-temporal features and
salient data augmentation. Our model uses a CNN-LSTM network with Inception
modules for image feature extraction. Our method runs in two phases: Phase 1
involves training on source domain data, while Phase 2 performs training on
target domain data that has been supplemented by feature maps generated using
the Phase 1 model. Our model significantly improves performance in unseen test
cases for both simulation-to-simulation transfer as well as simulation-to-real
transfer by up to +37.3\% in test accuracy and up to +40.8\% in steering angle
prediction, compared to other SOTA methods across multiple datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stereo CenterNet based 3D Object Detection for Autonomous Driving. (arXiv:2103.11071v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11071">
<div class="article-summary-box-inner">
<span><p>Recently, three-dimensional (3D) detection based on stereo images has
progressed remarkably; however, most advanced methods adopt anchor-based
two-dimensional (2D) detection or depth estimation to address this problem.
Nevertheless, high computational cost inhibits these methods from achieving
real-time performance. In this study, we propose a 3D object detection method,
Stereo CenterNet (SC), using geometric information in stereo imagery. SC
predicts the four semantic key points of the 3D bounding box of the object in
space and utilizes 2D left and right boxes, 3D dimension, orientation, and key
points to restore the bounding box of the object in the 3D space. Subsequently,
we adopt an improved photometric alignment module to further optimize the
position of the 3D bounding box. Experiments conducted on the KITTI dataset
indicate that the proposed SC exhibits the best speed-accuracy trade-off among
advanced methods without using extra data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-view analysis of unregistered medical images using cross-view transformers. (arXiv:2103.11390v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11390">
<div class="article-summary-box-inner">
<span><p>Multi-view medical image analysis often depends on the combination of
information from multiple views. However, differences in perspective or other
forms of misalignment can make it difficult to combine views effectively, as
registration is not always possible. Without registration, views can only be
combined at a global feature level, by joining feature vectors after global
pooling. We present a novel cross-view transformer method to transfer
information between unregistered views at the level of spatial feature maps. We
demonstrate this method on multi-view mammography and chest X-ray datasets. On
both datasets, we find that a cross-view transformer that links spatial feature
maps can outperform a baseline model that joins feature vectors after global
pooling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Logit Adjustment Loss for Long-Tailed Visual Recognition. (arXiv:2104.06094v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06094">
<div class="article-summary-box-inner">
<span><p>Data in the real world tends to exhibit a long-tailed label distribution,
which poses great challenges for the training of neural networks in visual
recognition. Existing methods tackle this problem mainly from the perspective
of data quantity, i.e., the number of samples in each class. To be specific,
they pay more attention to tail classes, like applying larger adjustments to
the logit. However, in the training process, the quantity and difficulty of
data are two intertwined and equally crucial problems. For some tail classes,
the features of their instances are distinct and discriminative, which can also
bring satisfactory accuracy; for some head classes, although with sufficient
samples, the high semantic similarity with other classes and lack of
discriminative features will bring bad accuracy. Based on these observations,
we propose Adaptive Logit Adjustment Loss (ALA Loss) to apply an adaptive
adjusting term to the logit. The adaptive adjusting term is composed of two
complementary factors: 1) quantity factor, which pays more attention to tail
classes, and 2) difficulty factor, which adaptively pays more attention to hard
instances in the training process. The difficulty factor can alleviate the
over-optimization on tail yet easy instances and under-optimization on head yet
hard instances. The synergy of the two factors can not only advance the
performance on tail classes even further, but also promote the accuracy on head
classes. Unlike previous logit adjusting methods that only concerned about data
quantity, ALA Loss tackles the long-tailed problem from a more comprehensive,
fine-grained and adaptive perspective. Extensive experimental results show that
our method achieves the state-of-the-art performance on challenging recognition
benchmarks, including ImageNet-LT, iNaturalist 2018, and Places-LT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Informative and Representative Triplet Selection for Multi-Label Remote Sensing Image Retrieval. (arXiv:2105.03647v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03647">
<div class="article-summary-box-inner">
<span><p>Learning the similarity between remote sensing (RS) images forms the
foundation for content based RS image retrieval (CBIR). Recently, deep metric
learning approaches that map the semantic similarity of images into an
embedding (metric) space have been found very popular in RS. A common approach
for learning the metric space relies on the selection of triplets of similar
(positive) and dissimilar (negative) images to a reference image called as an
anchor. Choosing triplets is a difficult task particularly for multi-label RS
CBIR, where each training image is annotated by multiple class labels. To
address this problem, in this paper we propose a novel triplet sampling method
in the framework of deep neural networks (DNNs) defined for multi-label RS CBIR
problems. The proposed method selects a small set of the most representative
and informative triplets based on two main steps. In the first step, a set of
anchors that are diverse to each other in the embedding space is selected from
the current mini-batch using an iterative algorithm. In the second step,
different sets of positive and negative images are chosen for each anchor by
evaluating the relevancy, hardness and diversity of the images among each other
based on a novel strategy. Experimental results obtained on two multi-label
benchmark archives show that the selection of the most informative and
representative triplets in the context of DNNs results in: i) reducing the
computational complexity of the training phase of the DNNs without any
significant loss on the performance; and ii) an increase in learning speed
since informative triplets allow fast convergence. The code of the proposed
method is publicly available at
https://git.tu-berlin.de/rsim/image-retrieval-from-triplets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diffusion-Based Representation Learning. (arXiv:2105.14257v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14257">
<div class="article-summary-box-inner">
<span><p>Score-based methods represented as stochastic differential equations on a
continuous time domain have recently proven successful as a non-adversarial
generative model. Training such models relies on denoising score matching,
which can be seen as multi-scale denoising autoencoders. Here, we augment the
denoising score-matching framework to enable representation learning without
any supervised signal. GANs and VAEs learn representations by directly
transforming latent codes to data samples. In contrast, the introduced
diffusion based representation learning relies on a new formulation of the
denoising score-matching objective and thus encodes information needed for
denoising. We illustrate how this difference allows for manual control of the
level of details encoded in the representation. Using the same approach, we
propose to learn an infinite-dimensional latent code which achieves
improvements of state-of-the-art models on semi-supervised image
classification. As a side contribution, we show how adversarial training in
score-based models can improve sample quality and improve sampling speed using
a new approximation of the prior at smaller noise scales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Action Localization without Knowing Boundaries. (arXiv:2106.04150v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04150">
<div class="article-summary-box-inner">
<span><p>Learning to localize actions in long, cluttered, and untrimmed videos is a
hard task, that in the literature has typically been addressed assuming the
availability of large amounts of annotated training samples for each class --
either in a fully-supervised setting, where action boundaries are known, or in
a weakly-supervised setting, where only class labels are known for each video.
In this paper, we go a step further and show that it is possible to learn to
localize actions in untrimmed videos when a) only one/few trimmed examples of
the target action are available at test time, and b) when a large collection of
videos with only class label annotation (some trimmed and some weakly annotated
untrimmed ones) are available for training; with no overlap between the classes
used during training and testing. To do so, we propose a network that learns to
estimate Temporal Similarity Matrices (TSMs) that model a fine-grained
similarity pattern between pairs of videos (trimmed or untrimmed), and uses
them to generate Temporal Class Activation Maps (TCAMs) for seen or unseen
classes. The TCAMs serve as temporal attention mechanisms to extract
video-level representations of untrimmed videos, and to temporally localize
actions at test time. To the best of our knowledge, we are the first to propose
a weakly-supervised, one/few-shot action localization network that can be
trained in an end-to-end fashion. Experimental results on THUMOS14 and
ActivityNet1.2 datasets, show that our method achieves performance comparable
or better to state-of-the-art fully-supervised, few-shot learning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning. (arXiv:2106.05956v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05956">
<div class="article-summary-box-inner">
<span><p>Inspired by BatchNorm, there has been an explosion of normalization layers
for deep neural networks (DNNs). However, these alternative normalization
layers have seen minimal use, partially due to a lack of guiding principles
that can help identify when these layers can serve as a replacement for
BatchNorm. To address this problem, we take a theoretical approach,
generalizing the known beneficial mechanisms of BatchNorm to several recently
proposed normalization techniques. Our generalized theory leads to the
following set of principles: (i) similar to BatchNorm, activations-based
normalization layers can prevent exponential growth of activations in ResNets,
but parametric layers require explicit remedies; (ii) use of GroupNorm can
ensure informative forward propagation, with different samples being assigned
dissimilar activations, but increasing group size results in increasingly
indistinguishable activations for different samples, explaining slow
convergence speed in models with LayerNorm; (iii) small group sizes result in
large gradient norm in earlier layers, hence explaining training instability
issues in Instance Normalization and illustrating a speed-stability tradeoff in
GroupNorm. Overall, our analysis reveals a unified set of mechanisms that
underpin the success of normalization methods in deep learning, providing us
with a compass to systematically explore the vast design space of DNN
normalization layers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-guided Machine Learning for Remotely Sensed In-Season Crop Growth Estimation. (arXiv:2106.13323v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13323">
<div class="article-summary-box-inner">
<span><p>Advanced machine learning techniques have been used in remote sensing (RS)
applications such as crop mapping and yield prediction, but remain
under-utilized for tracking crop progress. In this study, we demonstrate the
use of agronomic knowledge of crop growth drivers in a Long Short-Term
Memory-based, domain-guided neural network (DgNN) for in-season crop progress
estimation. The DgNN uses a branched structure and attention to separate
independent crop growth drivers and capture their varying importance throughout
the growing season. The DgNN is implemented for corn, using RS data in Iowa for
the period 2003-2019, with USDA crop progress reports used as ground truth.
State-wide DgNN performance shows significant improvement over sequential and
dense-only NN structures, and a widely-used Hidden Markov Model method. The
DgNN had a 4.0% higher Nash-Sutfliffe efficiency over all growth stages and 39%
more weeks with highest cosine similarity than the next best NN during test
years. The DgNN and Sequential NN were more robust during periods of abnormal
crop progress, though estimating the Silking-Grainfill transition was difficult
for all methods. Finally, Uniform Manifold Approximation and Projection
visualizations of layer activations showed how LSTM-based NNs separate crop
growth time-series differently from a dense-only structure. Results from this
study exhibit both the viability of NNs in crop growth stage estimation (CGSE)
and the benefits of using domain knowledge. The DgNN methodology presented here
can be extended to provide near-real time CGSE of other crops.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weaving Attention U-net: A Novel Hybrid CNN and Attention-based Method for Organs-at-risk Segmentation in Head and Neck CT Images. (arXiv:2107.04847v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04847">
<div class="article-summary-box-inner">
<span><p>In radiotherapy planning, manual contouring is labor-intensive and
time-consuming. Accurate and robust automated segmentation models improve the
efficiency and treatment outcome. We aim to develop a novel hybrid deep
learning approach, combining convolutional neural networks (CNNs) and the
self-attention mechanism, for rapid and accurate multi-organ segmentation on
head and neck computed tomography (CT) images. Head and neck CT images with
manual contours of 115 patients were retrospectively collected and used. We set
the training/validation/testing ratio to 81/9/25 and used the 10-fold
cross-validation strategy to select the best model parameters. The proposed
hybrid model segmented ten organs-at-risk (OARs) altogether for each case. The
performance of the model was evaluated by three metrics, i.e., the Dice
Similarity Coefficient (DSC), Hausdorff distance 95% (HD95), and mean surface
distance (MSD). We also tested the performance of the model on the Head and
Neck 2015 challenge dataset and compared it against several state-of-the-art
automated segmentation algorithms. The proposed method generated contours that
closely resemble the ground truth for ten OARs. Our results of the new Weaving
Attention U-net demonstrate superior or similar performance on the segmentation
of head and neck CT images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Adversarially Robust and Domain Generalizable Stereo Matching by Rethinking DNN Feature Backbones. (arXiv:2108.00335v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00335">
<div class="article-summary-box-inner">
<span><p>Stereo matching has recently witnessed remarkable progress using Deep Neural
Networks (DNNs). But, how robust are they? Although it has been well-known that
DNNs often suffer from adversarial vulnerability with a catastrophic drop in
performance, the situation is even worse in stereo matching. This paper first
shows that a type of weak white-box attacks can overwhelm state-of-the-art
methods. The attack is learned by a proposed stereo-constrained projected
gradient descent (PGD) method in stereo matching. This observation raises
serious concerns for the deployment of DNN-based stereo matching. Parallel to
the adversarial vulnerability, DNN-based stereo matching is typically trained
under the so-called simulation to reality pipeline, and thus domain
generalizability is an important problem. This paper proposes to rethink the
learnable DNN-based feature backbone towards adversarially-robust and domain
generalizable stereo matching by completely removing it for matching. In
experiments, the proposed method is tested in the SceneFlow dataset and the
KITTI2015 benchmark, with promising results. We compute the matching cost
volume using the classic multi-scale census transform (i.e., local binary
pattern) of the raw input stereo images, followed by a stacked Hourglass head
sub-network solving the matching problem. It significantly improves the
adversarial robustness, while retaining accuracy performance comparable to
state-of-the-art methods. It also shows better generalizability from simulation
(SceneFlow) to real (KITTI) datasets when no fine-tuning is used.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting the Generalization Capability in Cross-Domain Few-shot Learning via Noise-enhanced Supervised Autoencoder. (arXiv:2108.05028v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05028">
<div class="article-summary-box-inner">
<span><p>State of the art (SOTA) few-shot learning (FSL) methods suffer significant
performance drop in the presence of domain differences between source and
target datasets. The strong discrimination ability on the source dataset does
not necessarily translate to high classification accuracy on the target
dataset. In this work, we address this cross-domain few-shot learning (CDFSL)
problem by boosting the generalization capability of the model. Specifically,
we teach the model to capture broader variations of the feature distributions
with a novel noise-enhanced supervised autoencoder (NSAE). NSAE trains the
model by jointly reconstructing inputs and predicting the labels of inputs as
well as their reconstructed pairs. Theoretical analysis based on intra-class
correlation (ICC) shows that the feature embeddings learned from NSAE have
stronger discrimination and generalization abilities in the target domain. We
also take advantage of NSAE structure and propose a two-step fine-tuning
procedure that achieves better adaption and improves classification performance
in the target domain. Extensive experiments and ablation studies are conducted
to demonstrate the effectiveness of the proposed method. Experimental results
show that our proposed method consistently outperforms SOTA methods under
various conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">D-DARTS: Distributed Differentiable Architecture Search. (arXiv:2108.09306v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09306">
<div class="article-summary-box-inner">
<span><p>Differentiable ARchiTecture Search (DARTS) is one of the most trending Neural
Architecture Search (NAS) methods, drastically reducing search cost by
resorting to Stochastic Gradient Descent (SGD) and weight-sharing. However, it
also greatly reduces the search space, thus excluding potential promising
architectures from being discovered. In this paper, we propose D-DARTS, a novel
solution that addresses this problem by nesting several neural networks at
cell-level instead of using weight-sharing to produce more diversified and
specialized architectures. Moreover, we introduce a novel algorithm which can
derive deeper architectures from a few trained cells, increasing performance
and saving computation time. Our solution is able to provide state-of-the-art
results on CIFAR-10, CIFAR-100 and ImageNet while using significantly less
parameters than previous baselines, resulting in more hardware-efficient neural
networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ultrafast Focus Detection for Automated Microscopy. (arXiv:2108.12050v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12050">
<div class="article-summary-box-inner">
<span><p>Recent advances in scientific instruments have resulted in dramatic increase
in the volumes and velocities of data being generated in every-day
laboratories. Scanning electron microscopy is one such example where
technological advancements are now overwhelming scientists with critical data
for montaging, alignment, and image segmentation -- key practices for many
scientific domains, including, for example, neuroscience, where they are used
to derive the anatomical relationships of the brain. These instruments now
necessitate equally advanced computing resources and techniques to realize
their full potential. Here we present a fast out-of-focus detection algorithm
for electron microscopy images collected serially and demonstrate that it can
be used to provide near-real time quality control for neurology research. Our
technique, Multi-scale Histologic Feature Detection, adapts classical computer
vision techniques and is based on detecting various fine-grained histologic
features. We further exploit the inherent parallelism in the technique by
employing GPGPU primitives in order to accelerate characterization. Tests are
performed that demonstrate near-real-time detection of out-of-focus conditions.
We deploy these capabilities as a funcX function and show that it can be
applied as data are collected using an automated pipeline . We discuss
extensions that enable scaling out to support multi-beam microscopes and
integration with existing focus systems for purposes of implementing
auto-focus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransforMesh: A Transformer Network for Longitudinal modeling of Anatomical Meshes. (arXiv:2109.00532v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00532">
<div class="article-summary-box-inner">
<span><p>The longitudinal modeling of neuroanatomical changes related to Alzheimer's
disease (AD) is crucial for studying the progression of the disease. To this
end, we introduce TransforMesh, a spatio-temporal network based on transformers
that models longitudinal shape changes on 3D anatomical meshes. While
transformer and mesh networks have recently shown impressive performances in
natural language processing and computer vision, their application to medical
image analysis has been very limited. To the best of our knowledge, this is the
first work that combines transformer and mesh networks. Our results show that
TransforMesh can model shape trajectories better than other baseline
architectures that do not capture temporal dependencies. Moreover, we also
explore the capabilities of TransforMesh in detecting structural anomalies of
the hippocampus in patients developing AD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stochastic Neural Radiance Fields:Quantifying Uncertainty in Implicit 3D Representations. (arXiv:2109.02123v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02123">
<div class="article-summary-box-inner">
<span><p>Neural Radiance Fields (NeRF) has become a popular framework for learning
implicit 3D representations and addressing different tasks such as novel-view
synthesis or depth-map estimation. However, in downstream applications where
decisions need to be made based on automatic predictions, it is critical to
leverage the confidence associated with the model estimations. Whereas
uncertainty quantification is a long-standing problem in Machine Learning, it
has been largely overlooked in the recent NeRF literature. In this context, we
propose Stochastic Neural Radiance Fields (S-NeRF), a generalization of
standard NeRF that learns a probability distribution over all the possible
radiance fields modeling the scene. This distribution allows to quantify the
uncertainty associated with the scene information provided by the model. S-NeRF
optimization is posed as a Bayesian learning problem which is efficiently
addressed using the Variational Inference framework. Exhaustive experiments
over benchmark datasets demonstrate that S-NeRF is able to provide more
reliable predictions and confidence values than generic approaches previously
proposed for uncertainty estimation in other domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WiSoSuper: Benchmarking Super-Resolution Methods on Wind and Solar Data. (arXiv:2109.08770v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08770">
<div class="article-summary-box-inner">
<span><p>The transition to green energy grids depends on detailed wind and solar
forecasts to optimize the siting and scheduling of renewable energy generation.
Operational forecasts from numerical weather prediction models, however, only
have a spatial resolution of 10 to 20-km, which leads to sub-optimal usage and
development of renewable energy farms. Weather scientists have been developing
super-resolution methods to increase the resolution, but often rely on simple
interpolation techniques or computationally expensive differential
equation-based models. Recently, machine learning-based models, specifically
the physics-informed resolution-enhancing generative adversarial network
(PhIREGAN), have outperformed traditional downscaling methods. We provide a
thorough and extensible benchmark of leading deep learning-based
super-resolution techniques, including the enhanced super-resolution generative
adversarial network (ESRGAN) and an enhanced deep super-resolution (EDSR)
network, on wind and solar data. We accompany the benchmark with a novel
public, processed, and machine learning-ready dataset for benchmarking
super-resolution methods on wind and solar data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Gesture Recognition. (arXiv:2109.09396v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09396">
<div class="article-summary-box-inner">
<span><p>The Human-Machine Interaction (HMI) research field is an important topic in
machine learning that has been deeply investigated thanks to the rise of
computing power in the last years. The first time, it is possible to use
machine learning to classify images and/or videos instead of the traditional
computer vision algorithms. The aim of this project is to builda symbiosis
between a convolutional neural network (CNN)[1] and a recurrent neural network
(RNN) [2] to recognize cultural/anthropological Italian sign language gestures
from videos. The CNN extracts important features that later areused by the RNN.
With RNNs we are able to store temporal information inside the model to provide
contextual information from previous frames to enhance the prediction accuracy.
Our novel approach uses different data augmentation techniquesand
regularization methods from only RGB frames to avoid overfitting and provide a
small generalization error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skin Deep Unlearning: Artefact and Instrument Debiasing in the Context of Melanoma Classification. (arXiv:2109.09818v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09818">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks have demonstrated dermatologist-level
performance in the classification of melanoma and other skin lesions, but
prediction irregularities due to biases seen within the training data are an
issue that should be addressed before widespread deployment is possible. In
this work, we robustly remove bias and spurious variation from an automated
melanoma classification pipeline using two leading bias unlearning techniques.
We show that the biases introduced by surgical markings and rulers presented in
previous studies can be reasonably mitigated using these bias removal methods.
We also demonstrate the generalisation benefits of unlearning spurious
variation relating to the imaging instrument used to capture lesion images.
Contributions of this work include the application of different debiasing
techniques for artefact bias removal and the concept of instrument bias
unlearning for domain generalisation in melanoma detection. Our experimental
results provide evidence that the effects of each of the aforementioned biases
are notably reduced, with different debiasing techniques excelling at different
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rapid detection and recognition of whole brain activity in a freely behaving Caenorhabditis elegans. (arXiv:2109.10474v2 [q-bio.QM] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10474">
<div class="article-summary-box-inner">
<span><p>Advanced volumetric imaging methods and genetically encoded activity
indicators have permitted a comprehensive characterization of whole brain
activity at single neuron resolution in \textit{Caenorhabditis elegans}. The
constant motion and deformation of the mollusc nervous system, however, impose
a great challenge for a consistent identification of densely packed neurons in
a behaving animal. Here, we propose a cascade solution for long-term and rapid
recognition of head ganglion neurons in a freely moving \textit{C. elegans}.
First, potential neuronal regions from a stack of fluorescence images are
detected by a deep learning algorithm. Second, 2 dimensional neuronal regions
are fused into 3 dimensional neuron entities. Third, by exploiting the neuronal
density distribution surrounding a neuron and relative positional information
between neurons, a multi-class artificial neural network transforms engineered
neuronal feature vectors into digital neuronal identities. Under the constraint
of a small number (20-40 volumes) of training samples, our bottom-up approach
is able to process each volume - $1024 \times 1024 \times 18$ in voxels - in
less than 1 second and achieves an accuracy of $91\%$ in neuronal detection and
$74\%$ in neuronal recognition. Our work represents an important development
towards a rapid and fully automated algorithm for decoding whole brain activity
underlying natural animal behaviors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving 360 Monocular Depth Estimation via Non-local Dense Prediction Transformer and Joint Supervised and Self-supervised Learning. (arXiv:2109.10563v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10563">
<div class="article-summary-box-inner">
<span><p>Due to difficulties in acquiring ground truth depth of equirectangular (360)
images, the quality and quantity of equirectangular depth data today is
insufficient to represent the various scenes in the world. Therefore, 360 depth
estimation studies, which relied solely on supervised learning, are destined to
produce unsatisfactory results. Although self-supervised learning methods
focusing on equirectangular images (EIs) are introduced, they often have
incorrect or non-unique solutions, causing unstable performance. In this paper,
we propose 360 monocular depth estimation methods which improve on the areas
that limited previous studies. First, we introduce a self-supervised 360 depth
learning method that only utilizes gravity-aligned videos, which has the
potential to eliminate the needs for depth data during the training procedure.
Second, we propose a joint learning scheme realized by combining supervised and
self-supervised learning. The weakness of each learning is compensated, thus
leading to more accurate depth estimation. Third, we propose a non-local fusion
block, which retains global information encoded by vision transformer when
reconstructing the depths. With the proposed methods, we successfully apply the
transformer to 360 depth estimations, to the best of our knowledge, which has
not been tried before. On several benchmarks, our approach achieves significant
improvements over previous works and establishes a state of the art.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-26 23:02:58.426998739 UTC">2021-09-26 23:02:58 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>