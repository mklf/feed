<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-16T01:30:00Z">09-16</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Decision-Focused Summarization. (arXiv:2109.06896v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06896">
<div class="article-summary-box-inner">
<span><p>Relevance in summarization is typically defined based on textual information
alone, without incorporating insights about a particular decision. As a result,
to support risk analysis of pancreatic cancer, summaries of medical notes may
include irrelevant information such as a knee injury. We propose a novel
problem, decision-focused summarization, where the goal is to summarize
relevant information for a decision. We leverage a predictive model that makes
the decision based on the full text to provide valuable insights on how a
decision can be inferred from text. To build a summary, we then select
representative sentences that lead to similar model decisions as using the full
text while accounting for textual non-redundancy. To evaluate our method
(DecSum), we build a testbed where the task is to summarize the first ten
reviews of a restaurant in support of predicting its future rating on Yelp.
DecSum substantially outperforms text-only summarization methods and
model-based explanation methods in decision faithfulness and
representativeness. We further demonstrate that DecSum is the only method that
enables humans to outperform random chance in predicting which restaurant will
be better rated in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">fairseq S^2: A Scalable and Integrable Speech Synthesis Toolkit. (arXiv:2109.06912v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06912">
<div class="article-summary-box-inner">
<span><p>This paper presents fairseq S^2, a fairseq extension for speech synthesis. We
implement a number of autoregressive (AR) and non-AR text-to-speech models, and
their multi-speaker variants. To enable training speech synthesis models with
less curated data, a number of preprocessing tools are built and their
importance is shown empirically. To facilitate faster iteration of development
and analysis, a suite of automatic metrics is included. Apart from the features
added specifically for this extension, fairseq S^2 also benefits from the
scalability offered by fairseq and can be easily integrated with other
state-of-the-art systems provided in this framework. The code, documentation,
and pre-trained models are available at
https://github.com/pytorch/fairseq/tree/master/examples/speech_synthesis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Language-specificity of Multilingual BERT and the Impact of Fine-tuning. (arXiv:2109.06935v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06935">
<div class="article-summary-box-inner">
<span><p>Recent work has shown evidence that the knowledge acquired by multilingual
BERT (mBERT) has two components: a language-specific and a language-neutral
one. This paper analyses the relationship between them, in the context of
fine-tuning on two tasks -- POS tagging and natural language inference -- which
require the model to bring to bear different degrees of language-specific
knowledge. Visualisations reveal that mBERT loses the ability to cluster
representations by language after fine-tuning, a result that is supported by
evidence from language identification experiments. However, further experiments
on 'unlearning' language-specific representations using gradient reversal and
iterative adversarial learning are shown not to add further improvement to the
language-independent component over and above the effect of fine-tuning. The
results presented here suggest that the process of fine-tuning causes a
reorganisation of the model's limited representational capacity, enhancing
language-independent representations at the expense of language-specific ones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders. (arXiv:2109.06939v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06939">
<div class="article-summary-box-inner">
<span><p>Multi-task learning with transformer encoders (MTL) has emerged as a powerful
technique to improve performance on closely-related tasks for both accuracy and
efficiency while a question still remains whether or not it would perform as
well on tasks that are distinct in nature. We first present MTL results on five
NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over
single-task learning. We then conduct an extensive pruning analysis to show
that a certain set of attention heads get claimed by most tasks during MTL, who
interfere with one another to fine-tune those heads for their own objectives.
Based on this finding, we propose the Stem Cell Hypothesis to reveal the
existence of attention heads naturally talented for many tasks that cannot be
jointly trained to create adequate embeddings for all of those tasks. Finally,
we design novel parameter-free probes to justify our hypothesis and demonstrate
how attention heads are transformed across the five tasks during MTL through
label analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatically Exposing Problems with Neural Dialog Models. (arXiv:2109.06950v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06950">
<div class="article-summary-box-inner">
<span><p>Neural dialog models are known to suffer from problems such as generating
unsafe and inconsistent responses. Even though these problems are crucial and
prevalent, they are mostly manually identified by model designers through
interactions. Recently, some research instructs crowdworkers to goad the bots
into triggering such problems. However, humans leverage superficial clues such
as hate speech, while leaving systematic problems undercover. In this paper, we
propose two methods including reinforcement learning to automatically trigger a
dialog model into generating problematic responses. We show the effect of our
methods in exposing safety and contradiction issues with state-of-the-art
dialog models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Residual Adapters for Parameter-Efficient ASR Adaptation to Atypical and Accented Speech. (arXiv:2109.06952v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06952">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Recognition (ASR) systems are often optimized to work best
for speakers with canonical speech patterns. Unfortunately, these systems
perform poorly when tested on atypical speech and heavily accented speech. It
has previously been shown that personalization through model fine-tuning
substantially improves performance. However, maintaining such large models per
speaker is costly and difficult to scale. We show that by adding a relatively
small number of extra parameters to the encoder layers via so-called residual
adapter, we can achieve similar adaptation gains compared to model fine-tuning,
while only updating a tiny fraction (less than 0.5%) of the model parameters.
We demonstrate this on two speech adaptation tasks (atypical and accented
speech) and for two state-of-the-art ASR architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for More Efficient Dynamic Programs. (arXiv:2109.06966v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06966">
<div class="article-summary-box-inner">
<span><p>Computational models of human language often involve combinatorial problems.
For instance, a probabilistic parser may marginalize over exponentially many
trees to make predictions. Algorithms for such problems often employ dynamic
programming and are not always unique. Finding one with optimal asymptotic
runtime can be unintuitive, time-consuming, and error-prone. Our work aims to
automate this laborious process. Given an initial correct declarative program,
we search for a sequence of semantics-preserving transformations to improve its
running time as much as possible. To this end, we describe a set of program
transformations, a simple metric for assessing the efficiency of a transformed
program, and a heuristic search procedure to improve this metric. We show that
in practice, automated search -- like the mental search performed by human
programmers -- can find substantial improvements to the initial program.
Empirically, we show that many common speed-ups described in the NLP literature
could have been discovered automatically by our system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable Identification of Dementia from Transcripts using Transformer Networks. (arXiv:2109.06980v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06980">
<div class="article-summary-box-inner">
<span><p>Alzheimer's disease (AD) is the main cause of dementia which is accompanied
by loss of memory and may lead to severe consequences in peoples' everyday life
if not diagnosed on time. Very few works have exploited transformer-based
networks and despite the high accuracy achieved, little work has been done in
terms of model interpretability. In addition, although Mini-Mental State Exam
(MMSE) scores are inextricably linked with the identification of dementia,
research works face the task of dementia identification and the task of the
prediction of MMSE scores as two separate tasks. In order to address these
limitations, we employ several transformer-based models, with BERT achieving
the highest accuracy accounting for 85.56%. Concurrently, we propose an
interpretable method to detect AD patients based on siamese networks reaching
accuracy up to 81.18%. Next, we introduce two multi-task learning models, where
the main task refers to the identification of dementia (binary classification),
while the auxiliary one corresponds to the identification of the severity of
dementia (multiclass classification). Our model obtains accuracy equal to
84.99% on the detection of AD patients in the multi-task learning setting.
Finally, we present some new methods to identify the linguistic patterns used
by AD patients and non-AD ones, including text statistics, vocabulary
uniqueness, word usage, correlations via a detailed linguistic analysis, and
explainability techniques (LIME). Findings indicate significant differences in
language between AD and non-AD patients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NOPE: A Corpus of Naturally-Occurring Presuppositions in English. (arXiv:2109.06987v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06987">
<div class="article-summary-box-inner">
<span><p>Understanding language requires grasping not only the overtly stated content,
but also making inferences about things that were left unsaid. These inferences
include presuppositions, a phenomenon by which a listener learns about new
information through reasoning about what a speaker takes as given.
Presuppositions require complex understanding of the lexical and syntactic
properties that trigger them as well as the broader conversational context. In
this work, we introduce the Naturally-Occurring Presuppositions in English
(NOPE) Corpus to investigate the context-sensitivity of 10 different types of
presupposition triggers and to evaluate machine learning models' ability to
predict human inferences. We find that most of the triggers we investigate
exhibit moderate variability. We further find that transformer-based models
draw correct inferences in simple cases involving presuppositions, but they
fail to capture the minority of exceptional cases in which human judgments
reveal complex interactions between context and triggers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Three Step Training Approach with Data Augmentation for Morphological Inflection. (arXiv:2109.07006v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07006">
<div class="article-summary-box-inner">
<span><p>We present the BME submission for the SIGMORPHON 2021 Task 0 Part 1,
Generalization Across Typologically Diverse Languages shared task. We use an
LSTM encoder-decoder model with three step training that is first trained on
all languages, then fine-tuned on each language families and finally finetuned
on individual languages. We use a different type of data augmentation technique
in the first two steps. Our system outperformed the only other submission.
Although it remains worse than the Transformer baseline released by the
organizers, our model is simpler and our data augmentation techniques are
easily applicable to new languages. We perform ablation studies and show that
the augmentation techniques and the three training steps often help but
sometimes have a negative effect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Will this Question be Answered? Question Filtering via Answer Model Distillation for Efficient Question Answering. (arXiv:2109.07009v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07009">
<div class="article-summary-box-inner">
<span><p>In this paper we propose a novel approach towards improving the efficiency of
Question Answering (QA) systems by filtering out questions that will not be
answered by them. This is based on an interesting new finding: the answer
confidence scores of state-of-the-art QA systems can be approximated well by
models solely using the input question text. This enables preemptive filtering
of questions that are not answered by the system due to their answer confidence
scores being lower than the system threshold. Specifically, we learn
Transformer-based question models by distilling Transformer-based answering
models. Our experiments on three popular QA datasets and one industrial QA
benchmark demonstrate the ability of our question models to approximate the
Precision/Recall curves of the target QA system well. These question models,
when used as filters, can effectively trade off lower computation cost of QA
systems for lower Recall, e.g., reducing computation by ~60%, while only losing
~3-4% of Recall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Written Justifications are Key to Aggregate Crowdsourced Forecasts. (arXiv:2109.07017v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07017">
<div class="article-summary-box-inner">
<span><p>This paper demonstrates that aggregating crowdsourced forecasts benefits from
modeling the written justifications provided by forecasters. Our experiments
show that the majority and weighted vote baselines are competitive, and that
the written justifications are beneficial to call a question throughout its
life except in the last quarter. We also conduct an error analysis shedding
light into the characteristics that make a justification unreliable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Frequency Effects on Syntactic Rule Learning in Transformers. (arXiv:2109.07020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07020">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models perform well on a variety of linguistic tasks
that require symbolic reasoning, raising the question of whether such models
implicitly represent abstract symbols and rules. We investigate this question
using the case study of BERT's performance on English subject-verb agreement.
Unlike prior work, we train multiple instances of BERT from scratch, allowing
us to perform a series of controlled interventions at pre-training time. We
show that BERT often generalizes well to subject-verb pairs that never occurred
in training, suggesting a degree of rule-governed behavior. We also find,
however, that performance is heavily influenced by word frequency, with
experiments showing that both the absolute frequency of a verb form, as well as
the frequency relative to the alternate inflection, are causally implicated in
the predictions BERT makes at inference time. Closer analysis of these
frequency effects reveals that BERT's behavior is consistent with a system that
correctly applies the SVA rule in general but struggles to overcome strong
training priors and to estimate agreement features (singular vs. plural) on
infrequent lexical items.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention Is Indeed All You Need: Semantically Attention-Guided Decoding for Data-to-Text NLG. (arXiv:2109.07043v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07043">
<div class="article-summary-box-inner">
<span><p>Ever since neural models were adopted in data-to-text language generation,
they have invariably been reliant on extrinsic components to improve their
semantic accuracy, because the models normally do not exhibit the ability to
generate text that reliably mentions all of the information provided in the
input. In this paper, we propose a novel decoding method that extracts
interpretable information from encoder-decoder models' cross-attention, and
uses it to infer which attributes are mentioned in the generated text, which is
subsequently used to rescore beam hypotheses. Using this decoding method with
T5 and BART, we show on three datasets its ability to dramatically reduce
semantic errors in the generated outputs, while maintaining their
state-of-the-art quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Conditional Generative Matching Model for Multi-lingual Reply Suggestion. (arXiv:2109.07046v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07046">
<div class="article-summary-box-inner">
<span><p>We study the problem of multilingual automated reply suggestions (RS) model
serving many languages simultaneously. Multilingual models are often challenged
by model capacity and severe data distribution skew across languages. While
prior works largely focus on monolingual models, we propose Conditional
Generative Matching models (CGM), optimized within a Variational Autoencoder
framework to address challenges arising from multi-lingual RS. CGM does so with
expressive message conditional priors, mixture densities to enhance
multi-lingual data representation, latent alignment for language
discrimination, and effective variational optimization techniques for training
multi-lingual RS. The enhancements result in performance that exceed
competitive baselines in relevance (ROUGE score) by more than 10\% on average,
and 16\% for low resource languages. CGM also shows remarkable improvements in
diversity (80\%) illustrating its expressiveness in representation of
multi-lingual data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ARCH: Efficient Adversarial Regularized Training with Caching. (arXiv:2109.07048v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07048">
<div class="article-summary-box-inner">
<span><p>Adversarial regularization can improve model generalization in many natural
language processing tasks. However, conventional approaches are computationally
expensive since they need to generate a perturbation for each sample in each
epoch. We propose a new adversarial regularization method ARCH (adversarial
regularization with caching), where perturbations are generated and cached once
every several epochs. As caching all the perturbations imposes memory usage
concerns, we adopt a K-nearest neighbors-based strategy to tackle this issue.
The strategy only requires caching a small amount of perturbations, without
introducing additional training time. We evaluate our proposed method on a set
of neural machine translation and natural language understanding tasks. We
observe that ARCH significantly eases the computational burden (saves up to
70\% of computational time in comparison with conventional approaches). More
surprisingly, by reducing the variance of stochastic gradients, ARCH produces a
notably better (in most of the tasks) or comparable model generalization. Our
code is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Training with Differentiable Teacher. (arXiv:2109.07049v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07049">
<div class="article-summary-box-inner">
<span><p>Self-training achieves enormous success in various semi-supervised and
weakly-supervised learning tasks. The method can be interpreted as a
teacher-student framework, where the teacher generates pseudo-labels, and the
student makes predictions. The two models are updated alternatingly. However,
such a straightforward alternating update rule leads to training instability.
This is because a small change in the teacher may result in a significant
change in the student. To address this issue, we propose {\ours}, short for
differentiable self-training, that treats teacher-student as a Stackelberg
game. In this game, a leader is always in a more advantageous position than a
follower. In self-training, the student contributes to the prediction
performance, and the teacher controls the training process by generating
pseudo-labels. Therefore, we treat the student as the leader and the teacher as
the follower. The leader procures its advantage by acknowledging the follower's
strategy, which involves differentiable pseudo-labels and differentiable sample
weights. Consequently, the leader-follower interaction can be effectively
captured via Stackelberg gradient, obtained by differentiating the follower's
strategy. Experimental results on semi- and weakly-supervised classification
and named entity recognition tasks show that our model outperforms existing
approaches by large margins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Text Auto-Completion with Next Phrase Prediction. (arXiv:2109.07067v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07067">
<div class="article-summary-box-inner">
<span><p>Language models such as GPT-2 have performed well on constructing
syntactically sound sentences for text auto-completion task. However, such
models often require considerable training effort to adapt to specific writing
domains (e.g., medical). In this paper, we propose an intermediate training
strategy to enhance pre-trained language models' performance in the text
auto-completion task and fastly adapt them to specific domains. Our strategy
includes a novel self-supervised training objective called Next Phrase
Prediction (NPP), which encourages a language model to complete the partial
query with enriched phrases and eventually improve the model's text
auto-completion performance. Preliminary experiments have shown that our
approach is able to outperform the baselines in auto-completion for email and
academic writing domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-based Lexically Constrained Headline Generation. (arXiv:2109.07080v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07080">
<div class="article-summary-box-inner">
<span><p>This paper explores a variant of automatic headline generation methods, where
a generated headline is required to include a given phrase such as a company or
a product name. Previous methods using Transformer-based models generate a
headline including a given phrase by providing the encoder with additional
information corresponding to the given phrase. However, these methods cannot
always include the phrase in the generated headline. Inspired by previous
RNN-based methods generating token sequences in backward and forward directions
from the given phrase, we propose a simple Transformer-based method that
guarantees to include the given phrase in the high-quality generated headline.
We also consider a new headline generation strategy that takes advantage of the
controllable generation order of Transformer. Our experiments with the Japanese
News Corpus demonstrate that our methods, which are guaranteed to include the
phrase in the generated headline, achieve ROUGE scores comparable to previous
Transformer-based methods. We also show that our generation strategy performs
better than previous strategies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Extraction of Word Embedding from Q-contexts. (arXiv:2109.07084v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07084">
<div class="article-summary-box-inner">
<span><p>The notion of word embedding plays a fundamental role in natural language
processing (NLP). However, pre-training word embedding for very large-scale
vocabulary is computationally challenging for most existing methods. In this
work, we show that with merely a small fraction of contexts (Q-contexts)which
are typical in the whole corpus (and their mutual information with words), one
can construct high-quality word embedding with negligible errors. Mutual
information between contexts and words can be encoded canonically as a sampling
state, thus, Q-contexts can be fast constructed. Furthermore, we present an
efficient and effective WEQ method, which is capable of extracting word
embedding directly from these typical contexts. In practical scenarios, our
algorithm runs 11$\sim$13 times faster than well-established methods. By
comparing with well-known methods such as matrix factorization, word2vec,
GloVeand fasttext, we demonstrate that our method achieves comparable
performance on a variety of downstream NLP tasks, and in the meanwhile
maintains run-time and resource advantages over all these baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Document-Level Paraphrase Generation with Sentence Rewriting and Reordering. (arXiv:2109.07095v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07095">
<div class="article-summary-box-inner">
<span><p>Paraphrase generation is an important task in natural language processing.
Previous works focus on sentence-level paraphrase generation, while ignoring
document-level paraphrase generation, which is a more challenging and valuable
task. In this paper, we explore the task of document-level paraphrase
generation for the first time and focus on the inter-sentence diversity by
considering sentence rewriting and reordering. We propose CoRPG (Coherence
Relationship guided Paraphrase Generation), which leverages graph GRU to encode
the coherence relationship graph and get the coherence-aware representation for
each sentence, which can be used for re-arranging the multiple (possibly
modified) input sentences. We create a pseudo document-level paraphrase dataset
for training CoRPG. Automatic evaluation results show CoRPG outperforms several
strong baseline models on the BERTScore and diversity scores. Human evaluation
also shows our model can generate document paraphrase with more diversity and
semantic preservation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Edge Probing Tasks Reveal Linguistic Knowledge in QA Models?. (arXiv:2109.07102v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07102">
<div class="article-summary-box-inner">
<span><p>There have been many efforts to try to understand what grammatical knowledge
(e.g., ability to understand the part of speech of a token) is encoded in large
pre-trained language models (LM). This is done through `Edge Probing' (EP)
tests: simple ML models that predict the grammatical properties of a span
(whether it has a particular part of speech) using \textit{only} the LM's token
representations. However, most NLP applications use \finetuned\ LMs. Here, we
ask: if a LM is \finetuned, does the encoding of linguistic information in it
change, as measured by EP tests? Conducting experiments on multiple
question-answering (QA) datasets, we answer that question negatively: the EP
test results do not change significantly when the fine-tuned QA model performs
well or in adversarial situations where the model is forced to learn wrong
correlations. However, a critical analysis of the EP task datasets reveals that
EP models may rely on spurious correlations to make predictions. This indicates
even if \finetuning\ changes the encoding of such knowledge, the EP tests might
fail to measure it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Resource Named Entity Recognition Based on Multi-hop Dependency Trigger. (arXiv:2109.07118v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07118">
<div class="article-summary-box-inner">
<span><p>This paper presents a simple and effective approach in low-resource named
entity recognition (NER) based on multi-hop dependency trigger. Dependency
trigger refer to salient nodes relative to a entity in the dependency graph of
a context sentence. Our main observation is that there often exists trigger
which play an important role to recognize the location and type of entity in
sentence. Previous research has used manual labelling of trigger. Our main
contribution is to propose use a syntactic parser to automatically annotate
trigger. Experiments on two English datasets (CONLL 2003 and BC5CDR) show that
the proposed method is comparable to the previous trigger-based NER model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Does The User Want? Information Gain for Hierarchical Dialogue Policy Optimisation. (arXiv:2109.07129v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07129">
<div class="article-summary-box-inner">
<span><p>The dialogue management component of a task-oriented dialogue system is
typically optimised via reinforcement learning (RL). Optimisation via RL is
highly susceptible to sample inefficiency and instability. The hierarchical
approach called Feudal Dialogue Management takes a step towards more efficient
learning by decomposing the action space. However, it still suffers from
instability due to the reward only being provided at the end of the dialogue.
We propose the usage of an intrinsic reward based on information gain to
address this issue. Our proposed reward favours actions that resolve
uncertainty or query the user whenever necessary. It enables the policy to
learn how to retrieve the users' needs efficiently, which is an integral aspect
in every task-oriented conversation. Our algorithm, which we call FeudalGain,
achieves state-of-the-art results in most environments of the PyDial framework,
outperforming much more complex approaches. We confirm the sample efficiency
and stability of our algorithm through experiments in simulation and a human
trial.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Universality of Deep COntextual Language Models. (arXiv:2109.07140v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07140">
<div class="article-summary-box-inner">
<span><p>Deep Contextual Language Models (LMs) like ELMO, BERT, and their successors
dominate the landscape of Natural Language Processing due to their ability to
scale across multiple tasks rapidly by pre-training a single model, followed by
task-specific fine-tuning. Furthermore, multilingual versions of such models
like XLM-R and mBERT have given promising results in zero-shot cross-lingual
transfer, potentially enabling NLP applications in many under-served and
under-resourced languages. Due to this initial success, pre-trained models are
being used as `Universal Language Models' as the starting point across diverse
tasks, domains, and languages. This work explores the notion of `Universality'
by identifying seven dimensions across which a universal model should be able
to scale, that is, perform equally well or reasonably well, to be useful across
diverse settings. We outline the current theoretical and empirical results that
support model performance across these dimensions, along with extensions that
may help address some of their current limitations. Through this survey, we lay
the foundation for understanding the capabilities and limitations of massive
contextual language models and help discern research gaps and directions for
future work to make these LMs inclusive and fair to diverse applications,
users, and linguistic phenomena.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Glass-Box Features: Uncertainty Quantification Enhanced Quality Estimation for Neural Machine Translation. (arXiv:2109.07141v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07141">
<div class="article-summary-box-inner">
<span><p>Quality Estimation (QE) plays an essential role in applications of Machine
Translation (MT). Traditionally, a QE system accepts the original source text
and translation from a black-box MT system as input. Recently, a few studies
indicate that as a by-product of translation, QE benefits from the model and
training data's information of the MT system where the translations come from,
and it is called the "glass-box QE". In this paper, we extend the definition of
"glass-box QE" generally to uncertainty quantification with both "black-box"
and "glass-box" approaches and design several features deduced from them to
blaze a new trial in improving QE's performance. We propose a framework to fuse
the feature engineering of uncertainty quantification into a pre-trained
cross-lingual language model to predict the translation quality. Experiment
results show that our method achieves state-of-the-art performances on the
datasets of WMT 2020 QE shared task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantics of European poetry is shaped by conservative forces: The relationship between poetic meter and meaning in accentual-syllabic verse. (arXiv:2109.07148v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07148">
<div class="article-summary-box-inner">
<span><p>Recent advances in cultural analytics and large-scale computational studies
of art, literature and film often show that long-term change in the features of
artistic works happens gradually. These findings suggest that conservative
forces that shape creative domains might be underestimated. To this end, we
provide the first large-scale formal evidence of the persistent association
between poetic meter and semantics in 18-19th European literatures, using
Czech, German and Russian collections with additional data from English poetry
and early modern Dutch songs. Our study traces this association through a
series of clustering experiments using the abstracted semantic features of
150,000 poems. With the aid of topic modeling we infer semantic features for
individual poems. Texts were also lexically simplified across collections to
increase generalizability and decrease the sparseness of word frequency
distributions. Topics alone enable recognition of the meters in each observed
language, as may be seen from highly robust clustering of same-meter samples
(median Adjusted Rand Index between 0.48 and 1). In addition, this study shows
that the strength of the association between form and meaning tends to decrease
over time. This may reflect a shift in aesthetic conventions between the 18th
and 19th centuries as individual innovation was increasingly favored in
literature. Despite this decline, it remains possible to recognize semantics of
the meters from past or future, which suggests the continuity of semantic
traditions while also revealing the historical variability of conditions across
languages. This paper argues that distinct metrical forms, which are often
copied in a language over centuries, also maintain long-term semantic inertia
in poetry. Our findings, thus, highlight the role of the formal features of
cultural items in influencing the pace and shape of cultural evolution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incorporating Residual and Normalization Layers into Analysis of Masked Language Models. (arXiv:2109.07152v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07152">
<div class="article-summary-box-inner">
<span><p>Transformer architecture has become ubiquitous in the natural language
processing field. To interpret the Transformer-based models, their attention
patterns have been extensively analyzed. However, the Transformer architecture
is not only composed of the multi-head attention; other components can also
contribute to Transformers' progressive performance. In this study, we extended
the scope of the analysis of Transformers from solely the attention patterns to
the whole attention block, i.e., multi-head attention, residual connection, and
layer normalization. Our analysis of Transformer-based masked language models
shows that the token-to-token interaction performed via attention has less
impact on the intermediate representations than previously assumed. These
results provide new intuitive explanations of existing reports; for example,
discarding the learned attention patterns tends not to adversely affect the
performance. The codes of our experiments are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Language Models be Biomedical Knowledge Bases?. (arXiv:2109.07154v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07154">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (LMs) have become ubiquitous in solving various
natural language processing (NLP) tasks. There has been increasing interest in
what knowledge these LMs contain and how we can extract that knowledge,
treating LMs as knowledge bases (KBs). While there has been much work on
probing LMs in the general domain, there has been little attention to whether
these powerful LMs can be used as domain-specific KBs. To this end, we create
the BioLAMA benchmark, which is comprised of 49K biomedical factual knowledge
triples for probing biomedical LMs. We find that biomedical LMs with recently
proposed probing methods can achieve up to 18.51% Acc@5 on retrieving
biomedical knowledge. Although this seems promising given the task difficulty,
our detailed analyses reveal that most predictions are highly correlated with
prompt templates without any subjects, hence producing similar results on each
relation and hindering their capabilities to be used as domain-specific KBs. We
hope that BioLAMA can serve as a challenging benchmark for biomedical factual
probing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Match Job Candidates Using Multilingual Bi-Encoder BERT. (arXiv:2109.07157v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07157">
<div class="article-summary-box-inner">
<span><p>In this talk, we will show how we used Randstad history of candidate
placements to generate labeled CV-vacancy pairs dataset. Afterwards we
fine-tune a multilingual BERT with bi encoder structure over this dataset, by
adding a cosine similarity log loss layer. We will explain how using the
mentioned structure helps us overcome most of the challenges described above,
and how it enables us to build a maintainable and scalable pipeline to match
CVs and vacancies. In addition, we show how we gain a better semantic
understanding, and learn to bridge the vocabulary gap. Finally, we highlight
how multilingual transformers help us handle cross language barrier and might
reduce discrimination.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling Generative Factors in Natural Language with Discrete Variational Autoencoders. (arXiv:2109.07169v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07169">
<div class="article-summary-box-inner">
<span><p>The ability of learning disentangled representations represents a major step
for interpretable NLP systems as it allows latent linguistic features to be
controlled. Most approaches to disentanglement rely on continuous variables,
both for images and text. We argue that despite being suitable for image
datasets, continuous variables may not be ideal to model features of textual
data, due to the fact that most generative factors in text are discrete. We
propose a Variational Autoencoder based method which models language features
as discrete variables and encourages independence between variables for
learning disentangled representations. The proposed model outperforms
continuous and discrete baselines on several qualitative and quantitative
benchmarks for disentanglement as well as on a text style transfer downstream
application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Mixing Policy for Relaxing Locally Linear Constraints in Mixup. (arXiv:2109.07177v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07177">
<div class="article-summary-box-inner">
<span><p>Mixup is a recent regularizer for current deep classification networks.
Through training a neural network on convex combinations of pairs of examples
and their labels, it imposes locally linear constraints on the model's input
space. However, such strict linear constraints often lead to under-fitting
which degrades the effects of regularization. Noticeably, this issue is getting
more serious when the resource is extremely limited. To address these issues,
we propose the Adversarial Mixing Policy (AMP), organized in a min-max-rand
formulation, to relax the Locally Linear Constraints in Mixup. Specifically,
AMP adds a small adversarial perturbation to the mixing coefficients rather
than the examples. Thus, slight non-linearity is injected in-between the
synthetic examples and synthetic labels. By training on these data, the deep
networks are further regularized, and thus achieve a lower predictive error
rate. Experiments on five text classification benchmarks and five backbone
models have empirically shown that our methods reduce the error rate over Mixup
variants in a significant margin (up to 31.3%), especially in low-resource
conditions (up to 17.5%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-based Language Models for Factoid Question Answering at BioASQ9b. (arXiv:2109.07185v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07185">
<div class="article-summary-box-inner">
<span><p>In this work, we describe our experiments and participating systems in the
BioASQ Task 9b Phase B challenge of biomedical question answering. We have
focused on finding the ideal answers and investigated multi-task fine-tuning
and gradual unfreezing techniques on transformer-based language models. For
factoid questions, our ALBERT-based systems ranked first in test batch 1 and
fourth in test batch 2. Our DistilBERT systems outperformed the ALBERT variants
in test batches 4 and 5 despite having 81% fewer parameters than ALBERT.
However, we observed that gradual unfreezing had no significant impact on the
model's accuracy compared to standard fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiagent Multimodal Categorization for Symbol Emergence: Emergent Communication via Interpersonal Cross-modal Inference. (arXiv:2109.07194v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07194">
<div class="article-summary-box-inner">
<span><p>This paper describes a computational model of multiagent multimodal
categorization that realizes emergent communication. We clarify whether the
computational model can reproduce the following functions in a symbol emergence
system, comprising two agents with different sensory modalities playing a
naming game. (1) Function for forming a shared lexical system that comprises
perceptual categories and corresponding signs, formed by agents through
individual learning and semiotic communication between agents. (2) Function to
improve the categorization accuracy in an agent via semiotic communication with
another agent, even when some sensory modalities of each agent are missing. (3)
Function that an agent infers unobserved sensory information based on a sign
sampled from another agent in the same manner as cross-modal inference. We
propose an interpersonal multimodal Dirichlet mixture (Inter-MDM), which is
derived by dividing an integrative probabilistic generative model, which is
obtained by integrating two Dirichlet mixtures (DMs). The Markov chain Monte
Carlo algorithm realizes emergent communication. The experimental results
demonstrated that Inter-MDM enables agents to form multimodal categories and
appropriately share signs between agents. It is shown that emergent
communication improves categorization accuracy, even when some sensory
modalities are missing. Inter-MDM enables an agent to predict unobserved
information based on a shared sign.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentiment Analysis in Poems in Misurata Sub-dialect -- A Sentiment Detection in an Arabic Sub-dialect. (arXiv:2109.07203v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07203">
<div class="article-summary-box-inner">
<span><p>Over the recent decades, there has been a significant increase and
development of resources for Arabic natural language processing. This includes
the task of exploring Arabic Language Sentiment Analysis (ALSA) from Arabic
utterances in both Modern Standard Arabic (MSA) and different Arabic dialects.
This study focuses on detecting sentiment in poems written in Misurata Arabic
sub-dialect spoken in Misurata, Libya. The tools used to detect sentiment from
the dataset are Sklearn as well as Mazajak sentiment tool 1. Logistic
Regression, Random Forest, Naive Bayes (NB), and Support Vector Machines (SVM)
classifiers are used with Sklearn, while the Convolutional Neural Network (CNN)
is implemented with Mazajak. The results show that the traditional classifiers
score a higher level of accuracy as compared to Mazajak which is built on an
algorithm that includes deep learning techniques. More research is suggested to
analyze Arabic sub-dialect poetry in order to investigate the aspects that
contribute to sentiments in these multi-line texts; for example, the use of
figurative language such as metaphors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Relation-Oriented Clustering Method for Open Relation Extraction. (arXiv:2109.07205v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07205">
<div class="article-summary-box-inner">
<span><p>The clustering-based unsupervised relation discovery method has gradually
become one of the important methods of open relation extraction (OpenRE).
However, high-dimensional vectors can encode complex linguistic information
which leads to the problem that the derived clusters cannot explicitly align
with the relational semantic classes. In this work, we propose a
relation-oriented clustering model and use it to identify the novel relations
in the unlabeled data. Specifically, to enable the model to learn to cluster
relational data, our method leverages the readily available labeled data of
pre-defined relations to learn a relation-oriented representation. We minimize
distance between the instance with same relation by gathering the instances
towards their corresponding relation centroids to form a cluster structure, so
that the learned representation is cluster-friendly. To reduce the clustering
bias on predefined classes, we optimize the model by minimizing a joint
objective on both labeled and unlabeled data. Experimental results show that
our method reduces the error rate by 29.2% and 15.7%, on two datasets
respectively, compared with current SOTA methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">{E}fficient{BERT}: Progressively Searching Multilayer Perceptron via Warm-up Knowledge Distillation. (arXiv:2109.07222v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07222">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have shown remarkable results on various NLP
tasks. Nevertheless, due to their bulky size and slow inference speed, it is
hard to deploy them on edge devices. In this paper, we have a critical insight
that improving the feed-forward network (FFN) in BERT has a higher gain than
improving the multi-head attention (MHA) since the computational cost of FFN is
2$\sim$3 times larger than MHA. Hence, to compact BERT, we are devoted to
designing efficient FFN as opposed to previous works that pay attention to MHA.
Since FFN comprises a multilayer perceptron (MLP) that is essential in BERT
optimization, we further design a thorough search space towards an advanced MLP
and perform a coarse-to-fine mechanism to search for an efficient BERT
architecture. Moreover, to accelerate searching and enhance model
transferability, we employ a novel warm-up knowledge distillation strategy at
each search stage. Extensive experiments show our searched EfficientBERT is
6.9$\times$ smaller and 4.4$\times$ faster than BERT$\rm_{BASE}$, and has
competitive performances on GLUE and SQuAD Benchmarks. Concretely,
EfficientBERT attains a 77.7 average score on GLUE \emph{test}, 0.7 higher than
MobileBERT$\rm_{TINY}$, and achieves an 85.3/74.5 F1 score on SQuAD v1.1/v2.0
\emph{dev}, 3.2/2.7 higher than TinyBERT$_4$ even without data augmentation.
The code is released at https://github.com/cheneydon/efficient-bert.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Much do Lyrics Matter? Analysing Lyrical Simplicity Preferences for Individuals At Risk of Depression. (arXiv:2109.07227v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07227">
<div class="article-summary-box-inner">
<span><p>Music affects and in some cases reflects one's emotional state. Key to this
influence is lyrics and their meaning in conjunction with the acoustic
properties of the track. Recent work has focused on analysing these acoustic
properties and showing that individuals prone to depression primarily consume
low valence and low energy music. However, no studies yet have explored lyrical
content preferences in relation to online music consumption of such
individuals. In the current study, we examine lyrical simplicity, measured as
the Compressibility and Absolute Information Content of the text, associated
with preferences of individuals at risk for depression. Using the six-month
listening history of 541 Last.fm users, we compare lyrical simplicity trends
for users grouped as being at risk (At-Risk) of depression from those that are
not (No-Risk). Our findings reveal that At-Risk individuals prefer songs with
greater information content (lower Compressibility) on average, especially for
songs characterised as Sad. Furthermore, we found that At-Risk individuals also
have greater variability of Absolute Information Content across their listening
history. We discuss the results in light of existing socio-psychological
lab-based research on music habits associated with depression and their
relevance to naturally occurring online music listening behaviour.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dialog speech sentiment classification for imbalanced datasets. (arXiv:2109.07228v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07228">
<div class="article-summary-box-inner">
<span><p>Speech is the most common way humans express their feelings, and sentiment
analysis is the use of tools such as natural language processing and
computational algorithms to identify the polarity of these feelings. Even
though this field has seen tremendous advancements in the last two decades, the
task of effectively detecting under represented sentiments in different kinds
of datasets is still a challenging task. In this paper, we use single and
bi-modal analysis of short dialog utterances and gain insights on the main
factors that aid in sentiment detection, particularly in the underrepresented
classes, in datasets with and without inherent sentiment component.
Furthermore, we propose an architecture which uses a learning rate scheduler
and different monitoring criteria and provides state-of-the-art results for the
SWITCHBOARD imbalanced sentiment dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Mathematical Properties of Integers. (arXiv:2109.07230v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07230">
<div class="article-summary-box-inner">
<span><p>Embedding words in high-dimensional vector spaces has proven valuable in many
natural language applications. In this work, we investigate whether
similarly-trained embeddings of integers can capture concepts that are useful
for mathematical applications. We probe the integer embeddings for mathematical
knowledge, apply them to a set of numerical reasoning tasks, and show that by
learning the representations from mathematical sequence data, we can
substantially improve over number embeddings learned from English text corpora.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SWEAT: Scoring Polarization of Topics across Different Corpora. (arXiv:2109.07231v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07231">
<div class="article-summary-box-inner">
<span><p>Understanding differences of viewpoints across corpora is a fundamental task
for computational social sciences. In this paper, we propose the Sliced Word
Embedding Association Test (SWEAT), a novel statistical measure to compute the
relative polarization of a topical wordset across two distributional
representations. To this end, SWEAT uses two additional wordsets, deemed to
have opposite valence, to represent two different poles. We validate our
approach and illustrate a case study to show the usefulness of the introduced
measure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Unreasonable Effectiveness of the Baseline: Discussing SVMs in Legal Text Classification. (arXiv:2109.07234v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07234">
<div class="article-summary-box-inner">
<span><p>We aim to highlight an interesting trend to contribute to the ongoing debate
around advances within legal Natural Language Processing. Recently, the focus
for most legal text classification tasks has shifted towards large pre-trained
deep learning models such as BERT. In this paper, we show that a more
traditional approach based on Support Vector Machine classifiers reaches
competitive performance with deep learning models. We also highlight that error
reduction obtained by using specialised BERT-based models over baselines is
noticeably smaller in the legal domain when compared to general language tasks.
We discuss some hypotheses for these results to support future discussions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regressive Ensemble for Machine Translation Quality Evaluation. (arXiv:2109.07242v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07242">
<div class="article-summary-box-inner">
<span><p>This work introduces a simple regressive ensemble for evaluating machine
translation quality based on a set of novel and established metrics. We
evaluate the ensemble using a correlation to expert-based MQM scores of the WMT
2021 Metrics workshop. In both monolingual and zero-shot cross-lingual
settings, we show a significant performance improvement over single metrics. In
the cross-lingual settings, we also demonstrate that an ensemble approach is
well-applicable to unseen languages. Furthermore, we identify a strong
reference-free baseline that consistently outperforms the commonly-used BLEU
and METEOR measures and significantly improves our ensemble's performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Clinical Information Extraction with Transferred Contextual Embeddings. (arXiv:2109.07243v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07243">
<div class="article-summary-box-inner">
<span><p>The Bidirectional Encoder Representations from Transformers (BERT) model has
achieved the state-of-the-art performance for many natural language processing
(NLP) tasks. Yet, limited research has been contributed to studying its
effectiveness when the target domain is shifted from the pre-training corpora,
for example, for biomedical or clinical NLP applications. In this paper, we
applied it to a widely studied a hospital information extraction (IE) task and
analyzed its performance under the transfer learning setting. Our application
became the new state-of-the-art result by a clear margin, compared with a range
of existing IE models. Specifically, on this nursing handover data set, the
macro-average F1 score from our model was 0.438, whilst the previous best deep
learning models had 0.416. In conclusion, we showed that BERT based
pre-training models can be transferred to health-related documents under mild
conditions and with a proper fine-tuning process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs. (arXiv:2109.07263v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07263">
<div class="article-summary-box-inner">
<span><p>We propose a novel problem within end-to-end learning of task-oriented
dialogs (TOD), in which the dialog system mimics a troubleshooting agent who
helps a user by diagnosing their problem (e.g., car not starting). Such dialogs
are grounded in domain-specific flowcharts, which the agent is supposed to
follow during the conversation. Our task exposes novel technical challenges for
neural TOD, such as grounding an utterance to the flowchart without explicit
annotation, referring to additional manual pages when user asks a clarification
question, and ability to follow unseen flowcharts at test time. We release a
dataset (FloDial) consisting of 2,738 dialogs grounded on 12 different
troubleshooting flowcharts. We also design a neural model, FloNet, which uses a
retrieval-augmented generation architecture to train the dialog agent. Our
experiments find that FloNet can do zero-shot transfer to unseen flowcharts,
and sets a strong baseline for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scope resolution of predicted negation cues: A two-step neural network-based approach. (arXiv:2109.07264v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07264">
<div class="article-summary-box-inner">
<span><p>Neural network-based methods are the state of the art in negation scope
resolution. However, they often use the unrealistic assumption that cue
information is completely accurate. Even if this assumption holds, there
remains a dependency on engineered features from state-of-the-art machine
learning methods. The current study adopted a two-step negation resolving
apporach to assess whether a Bidirectional Long Short-Term Memory-based method
can be used for cue detection as well, and how inaccurate cue predictions would
affect the scope resolution performance. Results suggest that this method is
not suitable for negation detection. Scope resolution performance is most
robust against inaccurate information for models with a recurrent layer only,
compared to extensions with a Conditional Random Fields layer or a
post-processing algorithm. We advocate for more research into the application
of deep learning on negation detection and the effect of imperfect information
on scope resolution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence Length is a Domain: Length-based Overfitting in Transformer Models. (arXiv:2109.07276v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07276">
<div class="article-summary-box-inner">
<span><p>Transformer-based sequence-to-sequence architectures, while achieving
state-of-the-art results on a large number of NLP tasks, can still suffer from
overfitting during training. In practice, this is usually countered either by
applying regularization methods (e.g. dropout, L2-regularization) or by
providing huge amounts of training data. Additionally, Transformer and other
architectures are known to struggle when generating very long sequences. For
example, in machine translation, the neural-based systems perform worse on very
long sequences when compared to the preceding phrase-based translation
approaches (Koehn and Knowles, 2017).
</p>
<p>We present results which suggest that the issue might also be in the mismatch
between the length distributions of the training and validation data combined
with the aforementioned tendency of the neural networks to overfit to the
training data. We demonstrate on a simple string editing task and a machine
translation task that the Transformer model performance drops significantly
when facing sequences of length diverging from the length distribution in the
training data. Additionally, we show that the observed drop in performance is
due to the hypothesis length corresponding to the lengths seen by the model
during training rather than the length of the input sequence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Keyphrase Extraction by Jointly Modeling Local and Global Context. (arXiv:2109.07293v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07293">
<div class="article-summary-box-inner">
<span><p>Embedding based methods are widely used for unsupervised keyphrase extraction
(UKE) tasks. Generally, these methods simply calculate similarities between
phrase embeddings and document embedding, which is insufficient to capture
different context for a more effective UKE model. In this paper, we propose a
novel method for UKE, where local and global contexts are jointly modeled. From
a global view, we calculate the similarity between a certain phrase and the
whole document in the vector space as transitional embedding based models do.
In terms of the local view, we first build a graph structure based on the
document where phrases are regarded as vertices and the edges are similarities
between vertices. Then, we proposed a new centrality computation method to
capture local salient information based on the graph structure. Finally, we
further combine the modeling of global and local context for ranking. We
evaluate our models on three public benchmarks (Inspec, DUC 2001, SemEval 2010)
and compare with existing state-of-the-art models. The results show that our
model outperforms most models while generalizing better on input documents with
different domains and length. Additional ablation study shows that both the
local and global information is crucial for unsupervised keyphrase extraction
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Vision-Language Models `See' when they See Scenes. (arXiv:2109.07301v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07301">
<div class="article-summary-box-inner">
<span><p>Images can be described in terms of the objects they contain, or in terms of
the types of scene or place that they instantiate. In this paper we address to
what extent pretrained Vision and Language models can learn to align
descriptions of both types with images. We compare 3 state-of-the-art models,
VisualBERT, LXMERT and CLIP. We find that (i) V&amp;L models are susceptible to
stylistic biases acquired during pretraining; (ii) only CLIP performs
consistently well on both object- and scene-level descriptions. A follow-up
ablation study shows that CLIP uses object-level information in the visual
modality to align with scene-level textual descriptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Allocating Large Vocabulary Capacity for Cross-lingual Language Model Pre-training. (arXiv:2109.07306v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07306">
<div class="article-summary-box-inner">
<span><p>Compared to monolingual models, cross-lingual models usually require a more
expressive vocabulary to represent all languages adequately. We find that many
languages are under-represented in recent cross-lingual language models due to
the limited vocabulary capacity. To this end, we propose an algorithm VoCap to
determine the desired vocabulary capacity of each language. However, increasing
the vocabulary size significantly slows down the pre-training speed. In order
to address the issues, we propose k-NN-based target sampling to accelerate the
expensive softmax. Our experiments show that the multilingual vocabulary
learned with VoCap benefits cross-lingual language model pre-training.
Moreover, k-NN-based target sampling mitigates the side-effects of increasing
the vocabulary size while achieving comparable performance and faster
pre-training speed. The code and the pretrained multilingual vocabularies are
available at https://github.com/bozheng-hit/VoCapXLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Embedding Convolutions for Short Text Extreme Classification with Millions of Labels. (arXiv:2109.07319v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07319">
<div class="article-summary-box-inner">
<span><p>Automatic annotation of short-text data to a large number of target labels,
referred to as Short Text Extreme Classification, has recently found numerous
applications in prediction of related searches and product recommendation
tasks. The conventional usage of Convolutional Neural Network (CNN) to capture
n-grams in text-classification relies heavily on uniformity in word-ordering
and the presence of long input sequences to convolve over. However, this is
missing in short and unstructured text sequences encountered in search and
recommendation. In order to tackle this, we propose an orthogonal approach by
recasting the convolution operation to capture coupled semantics along the
embedding dimensions, and develop a word-order agnostic embedding enhancement
module to deal with the lack of structure in such queries. Benefitting from the
computational efficiency of the convolution operation, Embedding Convolutions,
when applied on the enriched word embeddings, result in a light-weight and yet
powerful encoder (InceptionXML) that is robust to the inherent lack of
structure in short-text extreme classification.
</p>
<p>Towards scaling our model to problems with millions of labels, we also
propose InceptionXML+, which addresses the shortcomings of the dynamic
hard-negative mining framework in the recently proposed LightXML by improving
the alignment between the label-shortlister and extreme classifier. On popular
benchmark datasets, we empirically demonstrate that the proposed method
outperforms state-of-the-art deep extreme classifiers such as Astec by an
average of 5% and 8% on the P@k and propensity-scored PSP@k metrics
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mi{\dh}eind's WMT 2021 submission. (arXiv:2109.07343v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07343">
<div class="article-summary-box-inner">
<span><p>We present Mi{\dh}eind's submission for the English$\to$Icelandic and
Icelandic$\to$English subsets of the 2021 WMT news translation task.
Transformer-base models are trained for translation on parallel data to
generate backtranslations iteratively. A pretrained mBART-25 model is then
adapted for translation using parallel data as well as the last backtranslation
iteration. This adapted pretrained model is then used to re-generate
backtranslations, and the training of the adapted model is continued.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Introducing an Abusive Language Classification Framework for Telegram to Investigate the German Hater Community. (arXiv:2109.07346v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07346">
<div class="article-summary-box-inner">
<span><p>Since traditional social media platforms ban more and more actors that
distribute hate speech or other forms of abusive language (deplatforming),
these actors migrate to alternative platforms that do not moderate the users'
content. One known platform that is relevant for the German hater community is
Telegram, for which there have only been made limited research efforts so far.
</p>
<p>The goal of this study is to develop a broad framework that consists of (i)
an abusive language classification model for German Telegram messages and (ii)
a classification model for the hatefulness of Telegram channels. For the first
part, we employ existing abusive language datasets containing posts from other
platforms to build our classification models. For the channel classification
model, we develop a method that combines channel specific content information
coming from a topic model with a social graph to predict the hatefulness of
channels. Furthermore, we complement these two approaches for hate speech
detection with insightful results on the evolution of the hater community on
Telegram in Germany. Moreover, we propose methods to the hate speech research
community for scalable network analyses for social media platforms. As an
additional output of the study, we release an annotated abusive language
dataset containing 1,149 annotated Telegram messages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual Transfer of Monolingual Models. (arXiv:2109.07348v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07348">
<div class="article-summary-box-inner">
<span><p>Recent studies in zero-shot cross-lingual learning using multilingual models
have falsified the previous hypothesis that shared vocabulary and joint
pre-training are the keys to cross-lingual generalization. Inspired by this
advancement, we introduce a cross-lingual transfer method for monolingual
models based on domain adaptation. We study the effects of such transfer from
four different languages to English. Our experimental results on GLUE show that
the transferred models outperform the native English model independently of the
source language. After probing the English linguistic knowledge encoded in the
representations before and after transfer, we find that semantic information is
retained from the source language, while syntactic information is learned
during transfer. Additionally, the results of evaluating the transferred models
in source language tasks reveal that their performance in the source domain
deteriorates after transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The ELITR ECA Corpus. (arXiv:2109.07351v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07351">
<div class="article-summary-box-inner">
<span><p>We present the ELITR ECA corpus, a multilingual corpus derived from
publications of the European Court of Auditors. We use automatic translation
together with Bleualign to identify parallel sentence pairs in all 506
translation directions. The result is a corpus comprising 264k document pairs
and 41.9M sentence pairs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Incremental Transformers: An Empirical Analysis of Transformer Models for Incremental NLU. (arXiv:2109.07364v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07364">
<div class="article-summary-box-inner">
<span><p>Incremental processing allows interactive systems to respond based on partial
inputs, which is a desirable property e.g. in dialogue agents. The currently
popular Transformer architecture inherently processes sequences as a whole,
abstracting away the notion of time. Recent work attempts to apply Transformers
incrementally via restart-incrementality by repeatedly feeding, to an unchanged
model, increasingly longer input prefixes to produce partial outputs. However,
this approach is computationally costly and does not scale efficiently for long
sequences. In parallel, we witness efforts to make Transformers more efficient,
e.g. the Linear Transformer (LT) with a recurrence mechanism. In this work, we
examine the feasibility of LT for incremental NLU in English. Our results show
that the recurrent LT model has better incremental performance and faster
inference speed compared to the standard Transformer and LT with
restart-incrementality, at the cost of part of the non-incremental (full
sequence) quality. We show that the performance drop can be mitigated by
training the model to wait for right context before committing to an output and
that training with input prefixes is beneficial for delivering correct partial
outputs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniST: Unified End-to-end Model for Streaming and Non-streaming Speech Translation. (arXiv:2109.07368v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07368">
<div class="article-summary-box-inner">
<span><p>This paper presents a unified end-to-end frame-work for both streaming and
non-streamingspeech translation. While the training recipes for non-streaming
speech translation have been mature, the recipes for streaming
speechtranslation are yet to be built. In this work, wefocus on developing a
unified model (UniST) which supports streaming and non-streaming ST from the
perspective of fundamental components, including training objective, attention
mechanism and decoding policy. Experiments on the most popular speech-to-text
translation benchmark dataset, MuST-C, show that UniST achieves significant
improvement for non-streaming ST, and a better-learned trade-off for BLEU score
and latency metrics for streaming ST, compared with end-to-end baselines and
the cascaded models. We will make our codes and evaluation tools publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Transferable Table Question Answering. (arXiv:2109.07377v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07377">
<div class="article-summary-box-inner">
<span><p>Weakly-supervised table question-answering(TableQA) models have achieved
state-of-art performance by using pre-trained BERT transformer to jointly
encoding a question and a table to produce structured query for the question.
However, in practical settings TableQA systems are deployed over table corpora
having topic and word distributions quite distinct from BERT's pretraining
corpus. In this work we simulate the practical topic shift scenario by
designing novel challenge benchmarks WikiSQL-TS and WikiTQ-TS, consisting of
train-dev-test splits in five distinct topic groups, based on the popular
WikiSQL and WikiTableQuestions datasets. We empirically show that, despite
pre-training on large open-domain text, performance of models degrades
significantly when they are evaluated on unseen topics. In response, we propose
T3QA (Topic Transferable Table Question Answering) a pragmatic adaptation
framework for TableQA comprising of: (1) topic-specific vocabulary injection
into BERT, (2) a novel text-to-text transformer generator (such as T5, GPT2)
based natural language question generation pipeline focused on generating topic
specific training data, and (3) a logical form reranker. We show that T3QA
provides a reasonably good baseline for our topic shift benchmarks. We believe
our topic split benchmarks will lead to robust TableQA solutions that are
better suited for practical deployment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RankNAS: Efficient Neural Architecture Search by Pairwise Ranking. (arXiv:2109.07383v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07383">
<div class="article-summary-box-inner">
<span><p>This paper addresses the efficiency challenge of Neural Architecture Search
(NAS) by formulating the task as a ranking problem. Previous methods require
numerous training examples to estimate the accurate performance of
architectures, although the actual goal is to find the distinction between
"good" and "bad" candidates. Here we do not resort to performance predictors.
Instead, we propose a performance ranking method (RankNAS) via pairwise
ranking. It enables efficient architecture search using much fewer training
examples. Moreover, we develop an architecture selection method to prune the
search space and concentrate on more promising candidates. Extensive
experiments on machine translation and language modeling tasks show that
RankNAS can design high-performance architectures while being orders of
magnitude faster than state-of-the-art NAS systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constraint based Knowledge Base Distillation in End-to-End Task Oriented Dialogs. (arXiv:2109.07396v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07396">
<div class="article-summary-box-inner">
<span><p>End-to-End task-oriented dialogue systems generate responses based on dialog
history and an accompanying knowledge base (KB). Inferring those KB entities
that are most relevant for an utterance is crucial for response generation.
Existing state of the art scales to large KBs by softly filtering over
irrelevant KB information. In this paper, we propose a novel filtering
technique that consists of (1) a pairwise similarity based filter that
identifies relevant information by respecting the n-ary structure in a KB
record. and, (2) an auxiliary loss that helps in separating contextually
unrelated KB information. We also propose a new metric -- multiset entity F1
which fixes a correctness issue in the existing entity F1 metric. Experimental
results on three publicly available task-oriented dialog datasets show that our
proposed approach outperforms existing state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Matching with Transformers in MELT. (arXiv:2109.07401v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07401">
<div class="article-summary-box-inner">
<span><p>One of the strongest signals for automated matching of ontologies and
knowledge graphs are the textual descriptions of the concepts. The methods that
are typically applied (such as character- or token-based comparisons) are
relatively simple, and therefore do not capture the actual meaning of the
texts. With the rise of transformer-based language models, text comparison
based on meaning (rather than lexical features) is possible. In this paper, we
model the ontology matching task as classification problem and present
approaches based on transformer models. We further provide an easy to use
implementation in the MELT framework which is suited for ontology and knowledge
graph matching. We show that a transformer-based filter helps to choose the
correct correspondences given a high-recall alignment and already achieves a
good result with simple alignment post-processing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERT is Robust! A Case Against Synonym-Based Adversarial Examples in Text Classification. (arXiv:2109.07403v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07403">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks have taken Natural Language Processing by storm. While
this led to incredible improvements across many tasks, it also initiated a new
research field, questioning the robustness of these neural networks by
attacking them. In this paper, we investigate four word substitution-based
attacks on BERT. We combine a human evaluation of individual word substitutions
and a probabilistic analysis to show that between 96% and 99% of the analyzed
attacks do not preserve semantics, indicating that their success is mainly
based on feeding poor data to the model. To further confirm that, we introduce
an efficient data augmentation procedure and show that many adversarial
examples can be prevented by including data similar to the attacks during
training. An additional post-processing step reduces the success rates of
state-of-the-art attacks below 5%. Finally, by looking at more reasonable
thresholds on constraints for word substitutions, we conclude that BERT is a
lot more robust than research on attacks suggests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document. (arXiv:2109.07410v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07410">
<div class="article-summary-box-inner">
<span><p>Given the recent proliferation of false claims online, there has been a lot
of manual fact-checking effort. As this is very time-consuming, human
fact-checkers can benefit from tools that can support them and make them more
efficient. Here, we focus on building a system that could provide such support.
Given an input document, it aims to detect all sentences that contain a claim
that can be verified by some previously fact-checked claims (from a given
database). The output is a re-ranked list of the document sentences, so that
those that can be verified are ranked as high as possible, together with
corresponding evidence. Unlike previous work, which has looked into claim
retrieval, here we take a document-level perspective. We create a new manually
annotated dataset for the task, and we propose suitable evaluation measures. We
further experiment with a learning-to-rank approach, achieving sizable
performance gains over several strong baselines. Our analysis demonstrates the
importance of modeling text similarity and stance, while also taking into
account the veracity of the retrieved previously fact-checked claims. We
believe that this research would be of interest to fact-checkers, journalists,
media, and regulatory authorities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SupCL-Seq: Supervised Contrastive Learning for Downstream Optimized Sequence Representations. (arXiv:2109.07424v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07424">
<div class="article-summary-box-inner">
<span><p>While contrastive learning is proven to be an effective training strategy in
computer vision, Natural Language Processing (NLP) is only recently adopting it
as a self-supervised alternative to Masked Language Modeling (MLM) for
improving sequence representations. This paper introduces SupCL-Seq, which
extends the supervised contrastive learning from computer vision to the
optimization of sequence representations in NLP. By altering the dropout mask
probability in standard Transformer architectures, for every representation
(anchor), we generate augmented altered views. A supervised contrastive loss is
then utilized to maximize the system's capability of pulling together similar
samples (e.g., anchors and their altered views) and pushing apart the samples
belonging to the other classes. Despite its simplicity, SupCLSeq leads to large
gains in many sequence classification tasks on the GLUE benchmark compared to a
standard BERTbase, including 6% absolute improvement on CoLA, 5.4% on MRPC,
4.7% on RTE and 2.6% on STSB. We also show consistent gains over self
supervised contrastively learned representations, especially in non-semantic
tasks. Finally we show that these gains are not solely due to augmentation, but
rather to a downstream optimized sequence representation. Code:
https://github.com/hooman650/SupCL-Seq
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discriminative and Generative Transformer-based Models For Situation Entity Classification. (arXiv:2109.07434v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07434">
<div class="article-summary-box-inner">
<span><p>We re-examine the situation entity (SE) classification task with varying
amounts of available training data. We exploit a Transformer-based variational
autoencoder to encode sentences into a lower dimensional latent space, which is
used to generate the text and learn a SE classifier. Test set and cross-genre
evaluations show that when training data is plentiful, the proposed model can
improve over the previous discriminative state-of-the-art models. Our approach
performs disproportionately better with smaller amounts of training data, but
when faced with extremely small sets (4 instances per label), generative RNN
methods outperform transformers. Our work provides guidance for future efforts
on SE and semantic prediction tasks, and low-label training regimes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative. (arXiv:2109.07437v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07437">
<div class="article-summary-box-inner">
<span><p>Pre-training, where models are trained on an auxiliary objective with
abundant data before being fine-tuned on data from the downstream task, is now
the dominant paradigm in NLP. In general, the pre-training step relies on
little to no direct knowledge of the task on which the model will be
fine-tuned, even when the end-task is known in advance. Our work challenges
this status-quo of end-task agnostic pre-training. First, on three different
low-resource NLP tasks from two domains, we demonstrate that multi-tasking the
end-task and auxiliary objectives results in significantly better downstream
task performance than the widely-used task-agnostic continued pre-training
paradigm of Gururangan et al. (2020). We next introduce an online meta-learning
algorithm that learns a set of multi-task weights to better balance among our
multiple auxiliary objectives, achieving further improvements on end task
performance and data efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is "moby dick" a Whale or a Bird? Named Entities and Terminology in Speech Translation. (arXiv:2109.07439v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07439">
<div class="article-summary-box-inner">
<span><p>Automatic translation systems are known to struggle with rare words. Among
these, named entities (NEs) and domain-specific terms are crucial, since errors
in their translation can lead to severe meaning distortions. Despite their
importance, previous speech translation (ST) studies have neglected them, also
due to the dearth of publicly available resources tailored to their specific
evaluation. To fill this gap, we i) present the first systematic analysis of
the behavior of state-of-the-art ST systems in translating NEs and terminology,
and ii) release NEuRoparl-ST, a novel benchmark built from European Parliament
speeches annotated with NEs and terminology. Our experiments on the three
language directions covered by our benchmark (en-&gt;es/fr/it) show that ST
systems correctly translate 75-80% of terms and 65-70% of NEs, with very low
performance (37-40%) on person names.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Challenges in Detoxifying Language Models. (arXiv:2109.07445v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07445">
<div class="article-summary-box-inner">
<span><p>Large language models (LM) generate remarkably fluent text and can be
efficiently adapted across NLP tasks. Measuring and guaranteeing the quality of
generated text in terms of safety is imperative for deploying LMs in the real
world; to this end, prior work often relies on automatic evaluation of LM
toxicity. We critically discuss this approach, evaluate several toxicity
mitigation strategies with respect to both automatic and human evaluation, and
analyze consequences of toxicity mitigation in terms of model bias and LM
quality. We demonstrate that while basic intervention strategies can
effectively optimize previously established automatic metrics on the
RealToxicityPrompts dataset, this comes at the cost of reduced LM coverage for
both texts about, and dialects of, marginalized groups. Additionally, we find
that human raters often disagree with high automatic toxicity scores after
strong toxicity reduction interventions -- highlighting further the nuances
involved in careful evaluation of LM toxicity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Does Translation Require Context? A Data-driven, Multilingual Exploration. (arXiv:2109.07446v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07446">
<div class="article-summary-box-inner">
<span><p>Although proper handling of discourse phenomena significantly contributes to
the quality of machine translation (MT), common translation quality metrics do
not adequately capture them. Recent works in context-aware MT attempt to target
a small set of these phenomena during evaluation. In this paper, we propose a
new metric, P-CXMI, which allows us to identify translations that require
context systematically and confirm the difficulty of previously studied
phenomena as well as uncover new ones that have not been addressed in previous
work. We then develop the Multilingual Discourse-Aware (MuDA) benchmark, a
series of taggers for these phenomena in 14 different language pairs, which we
use to evaluate context-aware MT. We find that state-of-the-art context-aware
MT models find marginal improvements over context-agnostic models on our
benchmark, which suggests current models do not handle these ambiguities
effectively. We release code and data to invite the MT research community to
increase efforts on context-aware translation on discourse phenomena and
languages that are currently overlooked.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WikiGUM: Exhaustive Entity Linking for Wikification in 12 Genres. (arXiv:2109.07449v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07449">
<div class="article-summary-box-inner">
<span><p>Previous work on Entity Linking has focused on resources targeting non-nested
proper named entity mentions, often in data from Wikipedia, i.e. Wikification.
In this paper, we present and evaluate WikiGUM, a fully wikified dataset,
covering all mentions of named entities, including their non-named and
pronominal mentions, as well as mentions nested within other mentions. The
dataset covers a broad range of 12 written and spoken genres, most of which
have not been included in Entity Linking efforts to date, leading to poor
performance by a pretrained SOTA system in our evaluation. The availability of
a variety of other annotations for the same data also enables further research
on entities in context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Machines Read Coding Manuals Yet? -- A Benchmark for Building Better Language Models for Code Understanding. (arXiv:2109.07452v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07452">
<div class="article-summary-box-inner">
<span><p>Code understanding is an increasingly important application of Artificial
Intelligence. A fundamental aspect of understanding code is understanding text
about code, e.g., documentation and forum discussions. Pre-trained language
models (e.g., BERT) are a popular approach for various NLP tasks, and there are
now a variety of benchmarks, such as GLUE, to help improve the development of
such models for natural language understanding. However, little is known about
how well such models work on textual artifacts about code, and we are unaware
of any systematic set of downstream tasks for such an evaluation. In this
paper, we derive a set of benchmarks (BLANCA - Benchmarks for LANguage models
on Coding Artifacts) that assess code understanding based on tasks such as
predicting the best answer to a question in a forum post, finding related forum
posts, or predicting classes related in a hierarchy from class documentation.
We evaluate the performance of current state-of-the-art language models on
these tasks and show that there is a significant improvement on each task from
fine tuning. We also show that multi-task training over BLANCA tasks helps
build better language models for code understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Text Representations: A Theory-Driven Approach. (arXiv:2109.07458v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07458">
<div class="article-summary-box-inner">
<span><p>Much of the progress in contemporary NLP has come from learning
representations, such as masked language model (MLM) contextual embeddings,
that turn challenging problems into simple classification tasks. But how do we
quantify and explain this effect? We adapt general tools from computational
learning theory to fit the specific characteristics of text datasets and
present a method to evaluate the compatibility between representations and
tasks. Even though many tasks can be easily solved with simple bag-of-words
(BOW) representations, BOW does poorly on hard natural language inference
tasks. For one such task we find that BOW cannot distinguish between real and
randomized labelings, while pre-trained MLM representations show 72x greater
distinction between real and random labelings than BOW. This method provides a
calibrated, quantitative measure of the difficulty of a classification-based
NLP task, enabling comparisons between representations without requiring
empirical evaluations that may be sensitive to initializations and
hyperparameters. The method provides a fresh perspective on the patterns in a
dataset and the alignment of those patterns with specific labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Domain Adaptation of Language Models via Adaptive Tokenization. (arXiv:2109.07460v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07460">
<div class="article-summary-box-inner">
<span><p>Contextual embedding-based language models trained on large data sets, such
as BERT and RoBERTa, provide strong performance across a wide range of tasks
and are ubiquitous in modern NLP. It has been observed that fine-tuning these
models on tasks involving data from domains different from that on which they
were pretrained can lead to suboptimal performance. Recent work has explored
approaches to adapt pretrained language models to new domains by incorporating
additional pretraining using domain-specific corpora and task data. We propose
an alternative approach for transferring pretrained language models to new
domains by adapting their tokenizers. We show that domain-specific subword
sequences can be efficiently determined directly from divergences in the
conditional token distributions of the base and domain-specific corpora. In
datasets from four disparate domains, we find adaptive tokenization on a
pretrained RoBERTa model provides &gt;97% of the performance benefits of domain
specific pretraining. Our approach produces smaller models and less training
and inference time than other approaches using tokenizer augmentation. While
adaptive tokenization incurs a 6% increase in model parameters in our
experimentation, due to the introduction of 10k new domain-specific tokens, our
approach, using 64 vCPUs, is 72x faster than further pretraining the language
model on domain-specific corpora on 8 TPUs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AnnIE: An Annotation Platform for Constructing Complete Open Information Extraction Benchmark. (arXiv:2109.07464v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07464">
<div class="article-summary-box-inner">
<span><p>Open Information Extraction (OIE) is the task of extracting facts from
sentences in the form of relations and their corresponding arguments in
schema-free manner. Intrinsic performance of OIE systems is difficult to
measure due to the incompleteness of existing OIE benchmarks: the ground truth
extractions do not group all acceptable surface realizations of the same fact
that can be extracted from a sentence. To measure performance of OIE systems
more realistically, it is necessary to manually annotate complete facts (i.e.,
clusters of all acceptable surface realizations of the same fact) from input
sentences. We propose AnnIE: an interactive annotation platform that
facilitates such challenging annotation tasks and supports creation of complete
fact-oriented OIE evaluation benchmarks. AnnIE is modular and flexible in order
to support different use case scenarios (i.e., benchmarks covering different
types of facts). We use AnnIE to build two complete OIE benchmarks: one with
verb-mediated facts and another with facts encompassing named entities.
Finally, we evaluate several OIE systems on our complete benchmarks created
with AnnIE. Our results suggest that existing incomplete benchmarks are overly
lenient, and that OIE systems are not as robust as previously reported. We
publicly release AnnIE under non-restrictive license.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Limits of Minimal Pairs in Contrastive Evaluation. (arXiv:2109.07465v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07465">
<div class="article-summary-box-inner">
<span><p>Minimal sentence pairs are frequently used to analyze the behavior of
language models. It is often assumed that model behavior on contrastive pairs
is predictive of model behavior at large. We argue that two conditions are
necessary for this assumption to hold: First, a tested hypothesis should be
well-motivated, since experiments show that contrastive evaluation can lead to
false positives. Secondly, test data should be chosen such as to minimize
distributional discrepancy between evaluation time and deployment time. For a
good approximation of deployment-time decoding, we recommend that minimal pairs
are created based on machine-generated text, as opposed to human-written
references. We present a contrastive evaluation suite for English-German MT
that implements this recommendation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Negative Statements Considered Useful. (arXiv:2001.04425v5 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04425">
<div class="article-summary-box-inner">
<span><p>Knowledge bases (KBs) about notable entities and their properties are an
important asset in applications such as search, question answering and
dialogue. All popular KBs capture virtually only positive statements, and
abstain from taking any stance on statements not stored in the KB. This paper
makes the case for explicitly stating salient statements that do not hold.
Negative statements are useful to overcome limitations of question answering
systems that are mainly geared for positive questions; they can also contribute
to informative summaries of entities. Due to the abundance of such invalid
statements, any effort to compile them needs to address ranking by saliency. We
present a statisticalinference method for compiling and ranking negative
statements, based on expectations from positive statements of related entities
in peer groups. Experimental results, with a variety of datasets, show that the
method can effectively discover notable negative statements, and extrinsic
studies underline their usefulness for entity summarization. Datasets and code
are released as resources for further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimal Neural Program Synthesis from Multimodal Specifications. (arXiv:2010.01678v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01678">
<div class="article-summary-box-inner">
<span><p>Multimodal program synthesis, which leverages different types of user input
to synthesize a desired program, is an attractive way to scale program
synthesis to challenging settings; however, it requires integrating noisy
signals from the user, like natural language, with hard constraints on the
program's behavior. This paper proposes an optimal neural synthesis approach
where the goal is to find a program that satisfies user-provided constraints
while also maximizing the program's score with respect to a neural model.
Specifically, we focus on multimodal synthesis tasks in which the user intent
is expressed using a combination of natural language (NL) and input-output
examples. At the core of our method is a top-down recurrent neural model that
places distributions over abstract syntax trees conditioned on the NL input.
This model not only allows for efficient search over the space of syntactically
valid programs, but it allows us to leverage automated program analysis
techniques for pruning the search space based on infeasibility of partial
programs with respect to the user's constraints. The experimental results on a
multimodal synthesis dataset (StructuredRegex) show that our method
substantially outperforms prior state-of-the-art techniques in terms of
accuracy and efficiency, and finds model-optimal programs more frequently.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Infusing Multi-Source Knowledge with Heterogeneous Graph Neural Network for Emotional Conversation Generation. (arXiv:2012.04882v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04882">
<div class="article-summary-box-inner">
<span><p>The success of emotional conversation systems depends on sufficient
perception and appropriate expression of emotions. In a real-world
conversation, we firstly instinctively perceive emotions from multi-source
information, including the emotion flow of dialogue history, facial
expressions, and personalities of speakers, and then express suitable emotions
according to our personalities, but these multiple types of information are
insufficiently exploited in emotional conversation fields. To address this
issue, we propose a heterogeneous graph-based model for emotional conversation
generation. Specifically, we design a Heterogeneous Graph-Based Encoder to
represent the conversation content (i.e., the dialogue history, its emotion
flow, facial expressions, and speakers' personalities) with a heterogeneous
graph neural network, and then predict suitable emotions for feedback. After
that, we employ an Emotion-Personality-Aware Decoder to generate a response not
only relevant to the conversation context but also with appropriate emotions,
by taking the encoded graph representations, the predicted emotions from the
encoder and the personality of the current speaker as inputs. Experimental
results show that our model can effectively perceive emotions from multi-source
knowledge and generate a satisfactory response, which significantly outperforms
previous state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Synthetic Data Improves Neural Machine Translation with Knowledge Distillation. (arXiv:2012.15455v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15455">
<div class="article-summary-box-inner">
<span><p>This paper explores augmenting monolingual data for knowledge distillation in
neural machine translation. Source language monolingual text can be
incorporated as a forward translation. Interestingly, we find the best way to
incorporate target language monolingual text is to translate it to the source
language and round-trip translate it back to the target language, resulting in
a fully synthetic corpus. We find that combining monolingual data from both
source and target languages yields better performance than a corpus twice as
large only in one language. Moreover, experiments reveal that the improvement
depends upon the provenance of the test set. If the test set was originally in
the source language (with the target side written by translators), then forward
translating source monolingual data matters. If the test set was originally in
the target language (with the source written by translators), then
incorporating target monolingual data matters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-to-text Generation by Splicing Together Nearest Neighbors. (arXiv:2101.08248v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08248">
<div class="article-summary-box-inner">
<span><p>We propose to tackle data-to-text generation tasks by directly splicing
together retrieved segments of text from "neighbor" source-target pairs. Unlike
recent work that conditions on retrieved neighbors but generates text
token-by-token, left-to-right, we learn a policy that directly manipulates
segments of neighbor text, by inserting or replacing them in partially
constructed generations. Standard techniques for training such a policy require
an oracle derivation for each generation, and we prove that finding the
shortest such derivation can be reduced to parsing under a particular weighted
context-free grammar. We find that policies learned in this way perform on par
with strong baselines in terms of automatic and human evaluation, but allow for
more interpretable and controllable generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute. (arXiv:2102.12459v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12459">
<div class="article-summary-box-inner">
<span><p>Large language models have become increasingly difficult to train because of
the growing computation time and cost. In this work, we present SRU++, a
highly-efficient architecture that combines fast recurrence and attention for
sequence modeling. SRU++ exhibits strong modeling capacity and training
efficiency. On standard language modeling tasks such as Enwik8, Wiki-103 and
Billion Word datasets, our model obtains better bits-per-character and
perplexity while using 3x-10x less training cost compared to top-performing
Transformer models. For instance, our model achieves a state-of-the-art result
on the Enwik8 dataset using 1.6 days of training on an 8-GPU machine. We
further demonstrate that SRU++ requires minimal attention for near
state-of-the-art performance. Our results suggest jointly leveraging fast
recurrence with little attention as a promising direction for accelerating
model training and inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attribute Alignment: Controlling Text Generation from Pre-trained Language Models. (arXiv:2103.11070v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11070">
<div class="article-summary-box-inner">
<span><p>Large language models benefit from training with a large amount of unlabeled
text, which gives them increasingly fluent and diverse generation capabilities.
However, using these models for text generation that takes into account target
attributes, such as sentiment polarity or specific topics, remains a challenge.
We propose a simple and flexible method for controlling text generation by
aligning disentangled attribute representations. In contrast to recent efforts
on training a discriminator to perturb the token level distribution for an
attribute, we use the same data to learn an alignment function to guide the
pre-trained, non-controlled language model to generate texts with the target
attribute without changing the original language model parameters. We evaluate
our method on sentiment- and topic-controlled generation, and show large
performance gains over previous methods while retaining fluency and diversity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Explanations from Empirical Explainers. (arXiv:2103.15429v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15429">
<div class="article-summary-box-inner">
<span><p>Amid a discussion about Green AI in which we see explainability neglected, we
explore the possibility to efficiently approximate computationally expensive
explainers. To this end, we propose feature attribution modelling with
Empirical Explainers. Empirical Explainers learn from data to predict the
attribution maps of expensive explainers. We train and test Empirical
Explainers in the language domain and find that they model their expensive
counterparts surprisingly well, at a fraction of the cost. They could thus
mitigate the computational burden of neural explanations significantly, in
applications that tolerate an approximation error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Regularization as Stackelberg Game: An Unrolled Optimization Approach. (arXiv:2104.04886v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04886">
<div class="article-summary-box-inner">
<span><p>Adversarial regularization has been shown to improve the generalization
performance of deep learning models in various natural language processing
tasks. Existing works usually formulate the method as a zero-sum game, which is
solved by alternating gradient descent/ascent algorithms. Such a formulation
treats the adversarial and the defending players equally, which is undesirable
because only the defending player contributes to the generalization
performance. To address this issue, we propose Stackelberg Adversarial
Regularization (SALT), which formulates adversarial regularization as a
Stackelberg game. This formulation induces a competition between a leader and a
follower, where the follower generates perturbations, and the leader trains the
model subject to the perturbations. Different from conventional approaches, in
SALT, the leader is in an advantageous position. When the leader moves, it
recognizes the strategy of the follower and takes the anticipated follower's
outcomes into consideration. Such a leader's advantage enables us to improve
the model fitting to the unperturbed data. The leader's strategic information
is captured by the Stackelberg gradient, which is obtained using an unrolling
algorithm. Our experimental results on a set of machine translation and natural
language understanding tasks show that SALT outperforms existing adversarial
regularization baselines across all tasks. Our code is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Span Pointer Networks for Non-Autoregressive Task-Oriented Semantic Parsing. (arXiv:2104.07275v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07275">
<div class="article-summary-box-inner">
<span><p>An effective recipe for building seq2seq, non-autoregressive, task-oriented
parsers to map utterances to semantic frames proceeds in three steps: encoding
an utterance $x$, predicting a frame's length |y|, and decoding a |y|-sized
frame with utterance and ontology tokens. Though empirically strong, these
models are typically bottlenecked by length prediction, as even small
inaccuracies change the syntactic and semantic characteristics of resulting
frames. In our work, we propose span pointer networks, non-autoregressive
parsers which shift the decoding task from text generation to span prediction;
that is, when imputing utterance spans into frame slots, our model produces
endpoints (e.g., [i, j]) as opposed to text (e.g., "6pm"). This natural
quantization of the output space reduces the variability of gold frames,
therefore improving length prediction and, ultimately, exact match.
Furthermore, length prediction is now responsible for frame syntax and the
decoder is responsible for frame semantics, resulting in a coarse-to-fine
model. We evaluate our approach on several task-oriented semantic parsing
datasets. Notably, we bridge the quality gap between non-autogressive and
autoregressive parsers, achieving 87 EM on TOPv2 (Chen et al. 2020).
Furthermore, due to our more consistent gold frames, we show strong
improvements in model generalization in both cross-domain and cross-lingual
transfer in low-resource settings. Finally, due to our diminished output
vocabulary, we observe 70% reduction in latency and 83% reduction in memory at
beam size 5 compared to prior non-autoregressive parsers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Open-Vocabulary Translation from Visual Text Representations. (arXiv:2104.08211v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08211">
<div class="article-summary-box-inner">
<span><p>Machine translation models have discrete vocabularies and commonly use
subword segmentation techniques to achieve an 'open vocabulary.' This approach
relies on consistent and correct underlying unicode sequences, and makes models
susceptible to degradation from common types of noise and variation. Motivated
by the robustness of human language processing, we propose the use of visual
text representations, which dispense with a finite set of text embeddings in
favor of continuous vocabularies created by processing visually rendered text
with sliding windows. We show that models using visual text representations
approach or match performance of traditional text models on small and larger
datasets. More importantly, models with visual embeddings demonstrate
significant robustness to varied types of noise, achieving e.g., 25.9 BLEU on a
character permuted German-English task where subword models degrade to 1.9.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does language help generalization in vision models?. (arXiv:2104.08313v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08313">
<div class="article-summary-box-inner">
<span><p>Vision models trained on multimodal datasets can benefit from the wide
availability of large image-caption datasets. A recent model (CLIP) was found
to generalize well in zero-shot and transfer learning settings. This could
imply that linguistic or "semantic grounding" confers additional generalization
abilities to the visual feature space. Here, we systematically evaluate various
multimodal architectures and vision-only models in terms of unsupervised
clustering, few-shot learning, transfer learning and adversarial robustness. In
each setting, multimodal training produced no additional generalization
capability compared to standard supervised visual training. We conclude that
work is still required for semantic grounding to help improve vision models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLIPScore: A Reference-free Evaluation Metric for Image Captioning. (arXiv:2104.08718v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08718">
<div class="article-summary-box-inner">
<span><p>Image captioning has conventionally relied on reference-based automatic
evaluations, where machine captions are compared against captions written by
humans. This is in contrast to the reference-free manner in which humans assess
caption quality.
</p>
<p>In this paper, we report the surprising empirical finding that CLIP (Radford
et al., 2021), a cross-modal model pretrained on 400M image+caption pairs from
the web, can be used for robust automatic evaluation of image captioning
without the need for references. Experiments spanning several corpora
demonstrate that our new reference-free metric, CLIPScore, achieves the highest
correlation with human judgements, outperforming existing reference-based
metrics like CIDEr and SPICE. Information gain experiments demonstrate that
CLIPScore, with its tight focus on image-text compatibility, is complementary
to existing reference-based metrics that emphasize text-text similarities.
Thus, we also present a reference-augmented version, RefCLIPScore, which
achieves even higher correlation. Beyond literal description tasks, several
case studies reveal domains where CLIPScore performs well (clip-art images,
alt-text rating), but also where it is relatively weaker in comparison to
reference-based metrics, e.g., news captions that require richer contextual
knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters. (arXiv:2105.06232v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06232">
<div class="article-summary-box-inner">
<span><p>To diversify and enrich generated dialogue responses, knowledge-grounded
dialogue has been investigated in recent years. The existing methods tackle the
knowledge grounding challenge by retrieving the relevant sentences over a large
corpus and augmenting the dialogues with explicit extra information. Despite
their success, however, the existing works have drawbacks on the inference
efficiency. This paper proposes KnowExpert, an end-to-end framework to bypass
the explicit retrieval process and inject knowledge into the pre-trained
language models with lightweight adapters and adapt to the knowledge-grounded
dialogue task. To the best of our knowledge, this is the first attempt to
tackle this challenge without retrieval in this task under an open-domain
chit-chat scenario. The experimental results show that KknowExpert performs
comparably with some retrieval-based baselines while being time-efficient in
inference, demonstrating the potential of our proposed direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction. (arXiv:2105.06965v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06965">
<div class="article-summary-box-inner">
<span><p>When language models process syntactically complex sentences, do they use
their representations of syntax in a manner that is consistent with the grammar
of the language? We propose AlterRep, an intervention-based method to address
this question. For any linguistic feature of a given sentence, AlterRep
generates counterfactual representations by altering how the feature is
encoded, while leaving intact all other aspects of the original representation.
By measuring the change in a model's word prediction behavior when these
counterfactual representations are substituted for the original ones, we can
draw conclusions about the causal effect of the linguistic feature in question
on the model's behavior. We apply this method to study how BERT models of
different sizes process relative clauses (RCs). We find that BERT variants use
RC boundary information during word prediction in a manner that is consistent
with the rules of English grammar; this RC boundary information generalizes to
a considerable extent across different RC types, suggesting that BERT
represents RCs as an abstract linguistic category.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">See, Hear, Read: Leveraging Multimodality with Guided Attention for Abstractive Text Summarization. (arXiv:2105.09601v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09601">
<div class="article-summary-box-inner">
<span><p>In recent years, abstractive text summarization with multimodal inputs has
started drawing attention due to its ability to accumulate information from
different source modalities and generate a fluent textual summary. However,
existing methods use short videos as the visual modality and short summary as
the ground-truth, therefore, perform poorly on lengthy videos and long
ground-truth summary. Additionally, there exists no benchmark dataset to
generalize this task on videos of varying lengths. In this paper, we introduce
AVIATE, the first large-scale dataset for abstractive text summarization with
videos of diverse duration, compiled from presentations in well-known academic
conferences like NDSS, ICML, NeurIPS, etc. We use the abstract of corresponding
research papers as the reference summaries, which ensure adequate quality and
uniformity of the ground-truth. We then propose FLORAL, a factorized
multi-modal Transformer based decoder-only language model, which inherently
captures the intra-modal and inter-modal dynamics within various input
modalities for the text summarization task. FLORAL utilizes an increasing
number of self-attentions to capture multimodality and performs significantly
better than traditional encoder-decoder based networks. Extensive experiments
illustrate that FLORAL achieves significant improvement over the baselines in
both qualitative and quantitative evaluations on the existing How2 dataset for
short videos and newly introduced AVIATE dataset for videos with diverse
duration, beating the best baseline on the two datasets by $1.39$ and $2.74$
ROUGE-L points respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PTR: Prompt Tuning with Rules for Text Classification. (arXiv:2105.11259v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11259">
<div class="article-summary-box-inner">
<span><p>Fine-tuned pre-trained language models (PLMs) have achieved awesome
performance on almost all NLP tasks. By using additional prompts to fine-tune
PLMs, we can further stimulate the rich knowledge distributed in PLMs to better
serve downstream tasks. Prompt tuning has achieved promising results on some
few-class classification tasks such as sentiment classification and natural
language inference. However, manually designing lots of language prompts is
cumbersome and fallible. For those auto-generated prompts, it is also expensive
and time-consuming to verify their effectiveness in non-few-shot scenarios.
Hence, it is still challenging for prompt tuning to address many-class
classification tasks. To this end, we propose prompt tuning with rules (PTR)
for many-class text classification and apply logic rules to construct prompts
with several sub-prompts. In this way, PTR is able to encode prior knowledge of
each class into prompt tuning. We conduct experiments on relation
classification, a typical and complicated many-class classification task, and
the results show that PTR can significantly and consistently outperform
existing state-of-the-art baselines. This indicates that PTR is a promising
approach to take advantage of both human prior knowledge and PLMs for those
complicated classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Speaker Detection as a Multi-Objective Optimization with Uncertainty-based Multimodal Fusion. (arXiv:2106.03821v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03821">
<div class="article-summary-box-inner">
<span><p>It is now well established from a variety of studies that there is a
significant benefit from combining video and audio data in detecting active
speakers. However, either of the modalities can potentially mislead audiovisual
fusion by inducing unreliable or deceptive information. This paper outlines
active speaker detection as a multi-objective learning problem to leverage best
of each modalities using a novel self-attention, uncertainty-based multimodal
fusion scheme. Results obtained show that the proposed multi-objective learning
architecture outperforms traditional approaches in improving both mAP and AUC
scores. We further demonstrate that our fusion strategy surpasses, in active
speaker detection, other modality fusion methods reported in various
disciplines. We finally show that the proposed method significantly improves
the state-of-the-art on the AVA-ActiveSpeaker dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Grounding with 3D Objects. (arXiv:2107.12514v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12514">
<div class="article-summary-box-inner">
<span><p>Seemingly simple natural language requests to a robot are generally
underspecified, for example "Can you bring me the wireless mouse?" Flat images
of candidate mice may not provide the discriminative information needed for
"wireless." The world, and objects in it, are not flat images but complex 3D
shapes. If a human requests an object based on any of its basic properties,
such as color, shape, or texture, robots should perform the necessary
exploration to accomplish the task. In particular, while substantial effort and
progress has been made on understanding explicitly visual attributes like color
and category, comparatively little progress has been made on understanding
language about shapes and contours. In this work, we introduce a novel
reasoning task that targets both visual and non-visual language about 3D
objects. Our new benchmark, ShapeNet Annotated with Referring Expressions
(SNARE) requires a model to choose which of two objects is being referenced by
a natural language description. We introduce several CLIP-based models for
distinguishing objects and demonstrate that while recent advances in jointly
modeling vision and language are useful for robotic language understanding, it
is still the case that these image-based models are weaker at understanding the
3D nature of objects -- properties which play a key role in manipulation. We
find that adding view estimation to language grounding models improves accuracy
on both SNARE and when identifying objects referred to in language on a robot
platform, but note that a large gap remains between these models and human
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Continual Entity Learning in Language Models for Conversational Agents. (arXiv:2108.00082v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00082">
<div class="article-summary-box-inner">
<span><p>Neural language models (LM) trained on diverse corpora are known to work well
on previously seen entities, however, updating these models with dynamically
changing entities such as place names, song titles and shopping items requires
re-training from scratch and collecting full sentences containing these
entities. We aim to address this issue, by introducing entity-aware language
models (EALM), where we integrate entity models trained on catalogues of
entities into the pre-trained LMs. Our combined language model adaptively adds
information from the entity models into the pre-trained LM depending on the
sentence context. Our entity models can be updated independently of the
pre-trained LM, enabling us to influence the distribution of entities output by
the final LM, without any further training of the pre-trained LM. We show
significant perplexity improvements on task-oriented dialogue datasets,
especially on long-tailed utterances, with an ability to continually adapt to
new entities (to an extent).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing. (arXiv:2108.04990v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04990">
<div class="article-summary-box-inner">
<span><p>Interpretability methods like Integrated Gradient and LIME are popular
choices for explaining natural language model predictions with relative word
importance scores. These interpretations need to be robust for trustworthy NLP
applications in high-stake areas like medicine or finance. Our paper
demonstrates how interpretations can be manipulated by making simple word
perturbations on an input text. Via a small portion of word-level swaps, these
adversarial perturbations aim to make the resulting text semantically and
spatially similar to its seed input (therefore sharing similar
interpretations). Simultaneously, the generated examples achieve the same
prediction label as the seed yet are given a substantially different
explanation by the interpretation methods. Our experiments generate fragile
interpretations to attack two SOTA interpretation methods, across three popular
Transformer models and on two different NLP datasets. We observe that the rank
order correlation drops by over 20% when less than 10% of words are perturbed
on average. Further, rank-order correlation keeps decreasing as more words get
perturbed. Furthermore, we demonstrate that candidates generated from our
method have good quality metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Span Fine-tuning for Pre-trained Language Models. (arXiv:2108.12848v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12848">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PrLM) have to carefully manage input units when
training on a very large text with a vocabulary consisting of millions of
words. Previous works have shown that incorporating span-level information over
consecutive words in pre-training could further improve the performance of
PrLMs. However, given that span-level clues are introduced and fixed in
pre-training, previous methods are time-consuming and lack of flexibility. To
alleviate the inconvenience, this paper presents a novel span fine-tuning
method for PrLMs, which facilitates the span setting to be adaptively
determined by specific downstream tasks during the fine-tuning phase. In
detail, any sentences processed by the PrLM will be segmented into multiple
spans according to a pre-sampled dictionary. Then the segmentation information
will be sent through a hierarchical CNN module together with the representation
outputs of the PrLM and ultimately generate a span-enhanced representation.
Experiments on GLUE benchmark show that the proposed span fine-tuning method
significantly enhances the PrLM, and at the same time, offer more flexibility
in an efficient way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$\infty$-former: Infinite Memory Transformer. (arXiv:2109.00301v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00301">
<div class="article-summary-box-inner">
<span><p>Transformers struggle when attending to long contexts, since the amount of
computation grows with the context length, and therefore they cannot model
long-term memories effectively. Several variations have been proposed to
alleviate this problem, but they all have a finite memory capacity, being
forced to drop old information. In this paper, we propose the $\infty$-former,
which extends the vanilla transformer with an unbounded long-term memory. By
making use of a continuous-space attention mechanism to attend over the
long-term memory, the $\infty$-former's attention complexity becomes
independent of the context length. Thus, it is able to model arbitrarily long
contexts and maintain "sticky memories" while keeping a fixed computation
budget. Experiments on a synthetic sorting task demonstrate the ability of the
$\infty$-former to retain information from long sequences. We also perform
experiments on language modeling, by training a model from scratch and by
fine-tuning a pre-trained language model, which show benefits of unbounded
long-term memories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LegaLMFiT: Efficient Short Legal Text Classification with LSTM Language Model Pre-Training. (arXiv:2109.00993v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00993">
<div class="article-summary-box-inner">
<span><p>Large Transformer-based language models such as BERT have led to broad
performance improvements on many NLP tasks. Domain-specific variants of these
models have demonstrated excellent performance on a variety of specialised
tasks. In legal NLP, BERT-based models have led to new state-of-the-art results
on multiple tasks. The exploration of these models has demonstrated the
importance of capturing the specificity of the legal language and its
vocabulary. However, such approaches suffer from high computational costs,
leading to a higher ecological impact and lower accessibility. Our findings,
focusing on English language legal text, show that lightweight LSTM-based
Language Models are able to capture enough information from a small legal text
pretraining corpus and achieve excellent performance on short legal text
classification tasks. This is achieved with a significantly reduced
computational overhead compared to BERT-based models. However, our method also
shows degraded performance on a more complex task, multi-label classification
of longer documents, highlighting the limitations of this lightweight approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment. (arXiv:2109.02363v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02363">
<div class="article-summary-box-inner">
<span><p>Cross-lingual entity alignment (EA) aims to find the equivalent entities
between crosslingual KGs, which is a crucial step for integrating KGs.
Recently, many GNN-based EA methods are proposed and show decent performance
improvements on several public datasets. Meanwhile, existing GNN-based EA
methods inevitably inherit poor interpretability and low efficiency from neural
networks. Motivated by the isomorphic assumption of GNNbased methods, we
successfully transform the cross-lingual EA problem into the assignment
problem. Based on this finding, we propose a frustratingly Simple but Effective
Unsupervised entity alignment method (SEU) without neural networks. Extensive
experiments show that our proposed unsupervised method even beats advanced
supervised methods across all public datasets and has high efficiency,
interpretability, and stability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixed Attention Transformer for Leveraging Word-Level Knowledge to Neural Cross-Lingual Information Retrieval. (arXiv:2109.02789v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02789">
<div class="article-summary-box-inner">
<span><p>Pretrained contextualized representations offer great success for many
downstream tasks, including document ranking. The multilingual versions of such
pretrained representations provide a possibility of jointly learning many
languages with the same model. Although it is expected to gain big with such
joint training, in the case of cross lingual information retrieval (CLIR), the
models under a multilingual setting are not achieving the same level of
performance as those under a monolingual setting. We hypothesize that the
performance drop is due to the translation gap between query and documents. In
the monolingual retrieval task, because of the same lexical inputs, it is
easier for model to identify the query terms that occurred in documents.
However, in the multilingual pretrained models that the words in different
languages are projected into the same hyperspace, the model tends to translate
query terms into related terms, i.e., terms that appear in a similar context,
in addition to or sometimes rather than synonyms in the target language. This
property is creating difficulties for the model to connect terms that cooccur
in both query and document. To address this issue, we propose a novel Mixed
Attention Transformer (MAT) that incorporates external word level knowledge,
such as a dictionary or translation table. We design a sandwich like
architecture to embed MAT into the recent transformer based deep neural models.
By encoding the translation knowledge into an attention matrix, the model with
MAT is able to focus on the mutually translated words in the input sequence.
Experimental results demonstrate the effectiveness of the external knowledge
and the significant improvement of MAT embedded neural reranking model on CLIR
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Total Recall: a Customized Continual Learning Method for Neural Semantic Parsers. (arXiv:2109.05186v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05186">
<div class="article-summary-box-inner">
<span><p>This paper investigates continual learning for semantic parsing. In this
setting, a neural semantic parser learns tasks sequentially without accessing
full training data from previous tasks. Direct application of the SOTA
continual learning algorithms to this problem fails to achieve comparable
performance with re-training models with all seen tasks because they have not
considered the special properties of structured outputs yielded by semantic
parsers. Therefore, we propose TotalRecall, a continual learning method
designed for neural semantic parsers from two aspects: i) a sampling method for
memory replay that diversifies logical form templates and balances
distributions of parse actions in a memory; ii) a two-stage training method
that significantly improves generalization capability of the parsers across
tasks. We conduct extensive experiments to study the research problems involved
in continual semantic parsing and demonstrate that a neural semantic parser
trained with TotalRecall achieves superior performance than the one trained
directly with the SOTA continual learning algorithms and achieve a 3-6 times
speedup compared to re-training from scratch. Code and datasets are available
at: https://github.com/zhuang-li/cl_nsp.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Good-Enough Example Extrapolation. (arXiv:2109.05602v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05602">
<div class="article-summary-box-inner">
<span><p>This paper asks whether extrapolating the hidden space distribution of text
examples from one class onto another is a valid inductive bias for data
augmentation. To operationalize this question, I propose a simple data
augmentation protocol called "good-enough example extrapolation" (GE3). GE3 is
lightweight and has no hyperparameters. Applied to three text classification
datasets for various data imbalance scenarios, GE3 improves performance more
than upsampling and other hidden-space data augmentation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Not All Models Localize Linguistic Knowledge in the Same Place: A Layer-wise Probing on BERToids' Representations. (arXiv:2109.05958v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05958">
<div class="article-summary-box-inner">
<span><p>Most of the recent works on probing representations have focused on BERT,
with the presumption that the findings might be similar to the other models. In
this work, we extend the probing studies to two other models in the family,
namely ELECTRA and XLNet, showing that variations in the pre-training
objectives or architectural choices can result in different behaviors in
encoding linguistic information in the representations. Most notably, we
observe that ELECTRA tends to encode linguistic knowledge in the deeper layers,
whereas XLNet instead concentrates that in the earlier layers. Also, the former
model undergoes a slight change during fine-tuning, whereas the latter
experiences significant adjustments. Moreover, we show that drawing conclusions
based on the weight mixing evaluation strategy -- which is widely used in the
context of layer-wise probing -- can be misleading given the norm disparity of
the representations across different layers. Instead, we adopt an alternative
information-theoretic probing with minimum description length, which has
recently been proven to provide more reliable and informative results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Emergence of the Shape Bias Results from Communicative Efficiency. (arXiv:2109.06232v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06232">
<div class="article-summary-box-inner">
<span><p>By the age of two, children tend to assume that new word categories are based
on objects' shape, rather than their color or texture; this assumption is
called the shape bias. They are thought to learn this bias by observing that
their caregiver's language is biased towards shape based categories. This
presents a chicken and egg problem: if the shape bias must be present in the
language in order for children to learn it, how did it arise in language in the
first place? In this paper, we propose that communicative efficiency explains
both how the shape bias emerged and why it persists across generations. We
model this process with neural emergent language agents that learn to
communicate about raw pixelated images. First, we show that the shape bias
emerges as a result of efficient communication strategies employed by agents.
Second, we show that pressure brought on by communicative need is also
necessary for it to persist across generations; simply having a shape bias in
an agent's input language is insufficient. These results suggest that, over and
above the operation of other learning strategies, the shape bias in human
learners may emerge and be sustained by communicative pressures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Post-OCR Document Correction with large Ensembles of Character Sequence Models. (arXiv:2109.06264v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06264">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel method based on character
sequence-to-sequence models to correct documents already processed with Optical
Character Recognition (OCR) systems. The main contribution of this paper is a
set of strategies to accurately process strings much longer than the ones used
to train the sequence model while being sample- and resource-efficient,
supported by thorough experimentation. The strategy with the best performance
involves splitting the input document in character n-grams and combining their
individual corrections into the final output using a voting scheme that is
equivalent to an ensemble of a large number of sequence models. We further
investigate how to weigh the contributions from each one of the members of this
ensemble. We test our method on nine languages of the ICDAR 2019 competition on
post-OCR text correction and achieve a new state-of-the-art performance in five
of them. Our code for post-OCR correction is shared at
https://github.com/jarobyte91/post_ocr_correction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Expert Knowledge-Guided Length-Variant Hierarchical Label Generation for Proposal Classification. (arXiv:2109.06661v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06661">
<div class="article-summary-box-inner">
<span><p>To advance the development of science and technology, research proposals are
submitted to open-court competitive programs developed by government agencies
(e.g., NSF). Proposal classification is one of the most important tasks to
achieve effective and fair review assignments. Proposal classification aims to
classify a proposal into a length-variant sequence of labels. In this paper, we
formulate the proposal classification problem into a hierarchical multi-label
classification task. Although there are certain prior studies, proposal
classification exhibit unique features: 1) the classification result of a
proposal is in a hierarchical discipline structure with different levels of
granularity; 2) proposals contain multiple types of documents; 3) domain
experts can empirically provide partial labels that can be leveraged to improve
task performances. In this paper, we focus on developing a new deep proposal
classification framework to jointly model the three features. In particular, to
sequentially generate labels, we leverage previously-generated labels to
predict the label of next level; to integrate partial labels from experts, we
use the embedding of these empirical partial labels to initialize the state of
neural networks. Our model can automatically identify the best length of label
sequence to stop next label prediction. Finally, we present extensive results
to demonstrate that our method can jointly model partial labels, textual
information, and semantic dependencies in label sequences, and, thus, achieve
advanced performances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Fuzzy Attention for Structured Sentiment Analysis. (arXiv:2109.06719v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06719">
<div class="article-summary-box-inner">
<span><p>Attention scorers have achieved success in parsing tasks like semantic and
syntactic dependency parsing. However, in tasks modeled into parsing, like
structured sentiment analysis, "dependency edges" are very sparse which hinders
parser performance. Thus we propose a sparse and fuzzy attention scorer with
pooling layers which improves parser performance and sets the new
state-of-the-art on structured sentiment analysis. We further explore the
parsing modeling on structured sentiment analysis with second-order parsing and
introduce a novel sparse second-order edge building procedure that leads to
significant improvement in parsing performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language Understanding. (arXiv:2109.06838v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06838">
<div class="article-summary-box-inner">
<span><p>While large language models have shown exciting progress on several NLP
benchmarks, evaluating their ability for complex analogical reasoning remains
under-explored. Here, we introduce a high-quality crowdsourced dataset of
narratives for employing proverbs in context as a benchmark for abstract
language understanding. The dataset provides fine-grained annotation of aligned
spans between proverbs and narratives, and contains minimal lexical overlaps
between narratives and proverbs, ensuring that models need to go beyond
surface-level reasoning to succeed. We explore three tasks: (1) proverb
recommendation and alignment prediction, (2) narrative generation for a given
proverb and topic, and (3) identifying narratives with similar motifs. Our
experiments show that neural language models struggle in our tasks compared to
humans, and the tasks pose multiple learning challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Legal Transformer Models May Not Always Help. (arXiv:2109.06862v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06862">
<div class="article-summary-box-inner">
<span><p>Deep learning-based Natural Language Processing methods, especially
transformers, have achieved impressive performance in the last few years.
Applying those state-of-the-art NLP methods to legal activities to automate or
simplify some simple work is of great value. This work investigates the value
of domain adaptive pre-training and language adapters in legal NLP tasks. By
comparing the performance of language models with domain adaptive pre-training
on different tasks and different dataset splits, we show that domain adaptive
pre-training is only helpful with low-resource downstream tasks, thus far from
being a panacea. We also benchmark the performance of adapters in a typical
legal NLP task and show that they can yield similar performance to full model
tuning with much smaller training costs. As an additional result, we release
LegalRoBERTa, a RoBERTa model further pre-trained on legal corpora.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Scale Aligned Distillation for Low-Resolution Detection. (arXiv:2109.06875v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06875">
<div class="article-summary-box-inner">
<span><p>In instance-level detection tasks (e.g., object detection), reducing input
resolution is an easy option to improve runtime efficiency. However, this
option traditionally hurts the detection performance much. This paper focuses
on boosting the performance of low-resolution models by distilling knowledge
from a high- or multi-resolution model. We first identify the challenge of
applying knowledge distillation (KD) to teacher and student networks that act
on different input resolutions. To tackle it, we explore the idea of spatially
aligning feature maps between models of varying input resolutions by shifting
feature pyramid positions and introduce aligned multi-scale training to train a
multi-scale teacher that can distill its knowledge to a low-resolution student.
Further, we propose crossing feature-level fusion to dynamically fuse teacher's
multi-resolution features to guide the student better. On several
instance-level detection tasks and datasets, the low-resolution models trained
via our approach perform competitively with high-resolution models trained via
conventional multi-scale training, while outperforming the latter's
low-resolution models by 2.1% to 3.6% in terms of mAP. Our code is made
publicly available at https://github.com/dvlab-research/MSAD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hardware-aware Real-time Myocardial Segmentation Quality Control in Contrast Echocardiography. (arXiv:2109.06909v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06909">
<div class="article-summary-box-inner">
<span><p>Automatic myocardial segmentation of contrast echocardiography has shown
great potential in the quantification of myocardial perfusion parameters.
Segmentation quality control is an important step to ensure the accuracy of
segmentation results for quality research as well as its clinical application.
Usually, the segmentation quality control happens after the data acquisition.
At the data acquisition time, the operator could not know the quality of the
segmentation results. On-the-fly segmentation quality control could help the
operator to adjust the ultrasound probe or retake data if the quality is
unsatisfied, which can greatly reduce the effort of time-consuming manual
correction. However, it is infeasible to deploy state-of-the-art DNN-based
models because the segmentation module and quality control module must fit in
the limited hardware resource on the ultrasound machine while satisfying strict
latency constraints. In this paper, we propose a hardware-aware neural
architecture search framework for automatic myocardial segmentation and quality
control of contrast echocardiography. We explicitly incorporate the hardware
latency as a regularization term into the loss function during training. The
proposed method searches the best neural network architecture for the
segmentation module and quality prediction module with strict latency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A trainable monogenic ConvNet layer robust in front of large contrast changes in image classification. (arXiv:2109.06926v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06926">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks (ConvNets) at present achieve remarkable
performance in image classification tasks. However, current ConvNets cannot
guarantee the capabilities of the mammalian visual systems such as invariance
to contrast and illumination changes. Some ideas to overcome the illumination
and contrast variations usually have to be tuned manually and tend to fail when
tested with other types of data degradation. In this context, we present a new
bio-inspired {entry} layer, M6, which detects low-level geometric features
(lines, edges, and orientations) which are similar to patterns detected by the
V1 visual cortex. This new trainable layer is capable of coping with image
classification even with large contrast variations. The explanation for this
behavior is the monogenic signal geometry, which represents each pixel value in
a 3D space using quaternions, a fact that confers a degree of explainability to
the networks. We compare M6 with a conventional convolutional layer (C) and a
deterministic quaternion local phase layer (Q9). The experimental setup {is
designed to evaluate the robustness} of our M6 enriched ConvNet model and
includes three architectures, four datasets, three types of contrast
degradation (including non-uniform haze degradations). The numerical results
reveal that the models with M6 are the most robust in front of any kind of
contrast variations. This amounts to a significant enhancement of the C models,
which usually have reasonably good performance only when the same training and
test degradation are used, except for the case of maximum degradation.
Moreover, the Structural Similarity Index Measure (SSIM) is used to analyze and
explain the robustness effect of the M6 feature maps under any kind of contrast
degradations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal Wound Classification using Wound Image and Location by Deep Neural Network. (arXiv:2109.06969v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06969">
<div class="article-summary-box-inner">
<span><p>Wound classification is an essential step of wound diagnosis. An efficient
classifier can assist wound specialists in classifying wound types with less
financial and time costs and help them decide an optimal treatment procedure.
This study developed a deep neural network-based multi-modal classifier using
wound images and their corresponding locations to categorize wound images into
multiple classes, including diabetic, pressure, surgical, and venous ulcers. A
body map is also developed to prepare the location data, which can help wound
specialists tag wound locations more efficiently. Three datasets containing
images and their corresponding location information are designed with the help
of wound specialists. The multi-modal network is developed by concatenating the
image-based and location-based classifier's outputs with some other
modifications. The maximum accuracy on mixed-class classifications (containing
background and normal skin) varies from 77.33% to 100% on different
experiments. The maximum accuracy on wound-class classifications (containing
only diabetic, pressure, surgical, and venous) varies from 72.95% to 98.08% on
different experiments. The proposed multi-modal network also shows a
significant improvement in results from the previous works of literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining GEDI and Sentinel-2 for wall-to-wall mapping of tall and short crops. (arXiv:2109.06972v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06972">
<div class="article-summary-box-inner">
<span><p>High resolution crop type maps are an important tool for improving food
security, and remote sensing is increasingly used to create such maps in
regions that possess ground truth labels for model training. However, these
labels are absent in many regions, and models trained in other regions on
typical satellite features, such as those from optical sensors, often exhibit
low performance when transferred. Here we explore the use of NASA's Global
Ecosystem Dynamics Investigation (GEDI) spaceborne lidar instrument, combined
with Sentinel-2 optical data, for crop type mapping. Using data from three
major cropped regions (in China, France, and the United States) we first
demonstrate that GEDI energy profiles are capable of reliably distinguishing
maize, a crop typically above 2m in height, from crops like rice and soybean
that are shorter. We further show that these GEDI profiles provide much more
invariant features across geographies compared to spectral and phenological
features detected by passive optical sensors. GEDI is able to distinguish maize
from other crops within each region with accuracies higher than 84%, and able
to transfer across regions with accuracies higher than 82% compared to 64% for
transfer of optical features. Finally, we show that GEDI profiles can be used
to generate training labels for models based on optical imagery from
Sentinel-2, thereby enabling the creation of 10m wall-to-wall maps of tall
versus short crops in label-scarce regions. As maize is the second most widely
grown crop in the world and often the only tall crop grown within a landscape,
we conclude that GEDI offers great promise for improving global crop type maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZFlow: Gated Appearance Flow-based Virtual Try-on with 3D Priors. (arXiv:2109.07001v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07001">
<div class="article-summary-box-inner">
<span><p>Image-based virtual try-on involves synthesizing perceptually convincing
images of a model wearing a particular garment and has garnered significant
research interest due to its immense practical applicability. Recent methods
involve a two stage process: i) warping of the garment to align with the model
ii) texture fusion of the warped garment and target model to generate the
try-on output. Issues arise due to the non-rigid nature of garments and the
lack of geometric information about the model or the garment. It often results
in improper rendering of granular details. We propose ZFlow, an end-to-end
framework, which seeks to alleviate these concerns regarding geometric and
textural integrity (such as pose, depth-ordering, skin and neckline
reproduction) through a combination of gated aggregation of hierarchical flow
estimates termed Gated Appearance Flow, and dense structural priors at various
stage of the network. ZFlow achieves state-of-the-art results as observed
qualitatively, and on quantitative benchmarks of image quality (PSNR, SSIM, and
FID). The paper presents extensive comparisons with other existing solutions
including a detailed user study and ablation studies to gauge the effect of
each of our contributions on multiple datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seeking an Optimal Approach for Computer-Aided Pulmonary Embolism Detection. (arXiv:2109.07029v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07029">
<div class="article-summary-box-inner">
<span><p>Pulmonary embolism (PE) represents a thrombus ("blood clot"), usually
originating from a lower extremity vein, that travels to the blood vessels in
the lung, causing vascular obstruction and in some patients, death. This
disorder is commonly diagnosed using CT pulmonary angiography (CTPA). Deep
learning holds great promise for the computer-aided CTPA diagnosis (CAD) of PE.
However, numerous competing methods for a given task in the deep learning
literature exist, causing great confusion regarding the development of a CAD PE
system. To address this confusion, we present a comprehensive analysis of
competing deep learning methods applicable to PE diagnosis using CTPA at the
both image and exam levels. At the image level, we compare convolutional neural
networks (CNNs) with vision transformers, and contrast self-supervised learning
(SSL) with supervised learning, followed by an evaluation of transfer learning
compared with training from scratch. At the exam level, we focus on comparing
conventional classification (CC) with multiple instance learning (MIL). Our
extensive experiments consistently show: (1) transfer learning consistently
boosts performance despite differences between natural images and CT scans, (2)
transfer learning with SSL surpasses its supervised counterparts; (3) CNNs
outperform vision transformers, which otherwise show satisfactory performance;
and (4) CC is, surprisingly, superior to MIL. Compared with the state of the
art, our optimal approach provides an AUC gain of 0.2\% and 1.05\% for
image-level and exam-level, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PnP-DETR: Towards Efficient Visual Analysis with Transformers. (arXiv:2109.07036v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07036">
<div class="article-summary-box-inner">
<span><p>Recently, DETR~\cite{carion2020end} pioneered the solution of vision tasks
with transformers, it directly translates the image feature map into the object
detection result. Though effective, translating the full feature map can be
costly due to redundant computation on some area like the background. In this
work, we encapsulate the idea of reducing spatial redundancy into a novel poll
and pool (PnP) sampling module, with which we build an end-to-end PnP-DETR
architecture that adaptively allocates its computation spatially to be more
efficient. Concretely, the PnP module abstracts the image feature map into fine
foreground object feature vectors and a small number of coarse background
contextual feature vectors. The transformer models information interaction
within the fine-coarse feature space and translates the features into the
detection result. Moreover, the PnP-augmented model can instantly achieve
various desired trade-offs between performance and computation with a single
model by varying the sampled feature length, without requiring to train
multiple models as existing methods. Thus it offers greater flexibility for
deployment in diverse scenarios with varying computation constraint. We further
validate the generalizability of the PnP module on \textbf{panoptic
segmentation} and the recent transformer-based image recognition model
{\textbf{ViT}}~\cite{dosovitskiy2020image} and show consistent efficiency gain.
We believe our method makes a step for efficient visual analysis with
transformers, wherein spatial redundancy is commonly observed. Code will be
available at \url{https://github.com/twangnh/pnp-detr}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty Quantification in Medical Image Segmentation with Multi-decoder U-Net. (arXiv:2109.07045v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07045">
<div class="article-summary-box-inner">
<span><p>Accurate medical image segmentation is crucial for diagnosis and analysis.
However, the models without calibrated uncertainty estimates might lead to
errors in downstream analysis and exhibit low levels of robustness. Estimating
the uncertainty in the measurement is vital to making definite, informed
conclusions. Especially, it is difficult to make accurate predictions on
ambiguous areas and focus boundaries for both models and radiologists, even
harder to reach a consensus with multiple annotations. In this work, the
uncertainty under these areas is studied, which introduces significant
information with anatomical structure and is as important as segmentation
performance. We exploit the medical image segmentation uncertainty
quantification by measuring segmentation performance with multiple annotations
in a supervised learning manner and propose a U-Net based architecture with
multiple decoders, where the image representation is encoded with the same
encoder, and segmentation referring to each annotation is estimated with
multiple decoders. Nevertheless, a cross-loss function is proposed for bridging
the gap between different branches. The proposed architecture is trained in an
end-to-end manner and able to improve predictive uncertainty estimates. The
model achieves comparable performance with fewer parameters to the integrated
training model that ranked the runner-up in the MICCAI-QUBIQ 2020 challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Synthesis via Semantic Composition. (arXiv:2109.07053v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07053">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a novel approach to synthesize realistic images
based on their semantic layouts. It hypothesizes that for objects with similar
appearance, they share similar representation. Our method establishes
dependencies between regions according to their appearance correlation,
yielding both spatially variant and associated representations. Conditioning on
these features, we propose a dynamic weighted network constructed by spatially
conditional computation (with both convolution and normalization). More than
preserving semantic distinctions, the given dynamic network strengthens
semantic relevance, benefiting global structure and detail synthesis. We
demonstrate that our method gives the compelling generation performance
qualitatively and quantitatively with extensive experiments on benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">F-CAM: Full Resolution CAM via Guided Parametric Upscaling. (arXiv:2109.07069v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07069">
<div class="article-summary-box-inner">
<span><p>Class Activation Mapping (CAM) methods have recently gained much attention
for weakly-supervised object localization (WSOL) tasks, allowing for CNN
visualization and interpretation without training on fully annotated image
datasets. CAM methods are typically integrated within off-the-shelf CNN
backbones, such as ResNet50. Due to convolution and downsampling/pooling
operations, these backbones yield low resolution CAMs with a down-scaling
factor of up to 32, making accurate localization more difficult. Interpolation
is required to restore a full size CAMs, but without considering the
statistical properties of the objects, leading to activations with inconsistent
boundaries and inaccurate localizations. As an alternative, we introduce a
generic method for parametric upscaling of CAMs that allows constructing
accurate full resolution CAMs (F-CAMs). In particular, we propose a trainable
decoding architecture that can be connected to any CNN classifier to produce
more accurate CAMs. Given an original (low resolution) CAM, foreground and
background pixels are randomly sampled for fine-tuning the decoder. Additional
priors such as image statistics, and size constraints are also considered to
expand and refine object boundaries. Extensive experiments using three CNN
backbones and six WSOL baselines on the CUB-200-2011 and OpenImages datasets,
indicate that our F-CAM method yields a significant improvement in CAM
localization accuracy. F-CAM performance is competitive with state-of-art WSOL
methods, yet it requires fewer computational resources during inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DSOR: A Scalable Statistical Filter for Removing Falling Snow from LiDAR Point Clouds in Severe Winter Weather. (arXiv:2109.07078v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07078">
<div class="article-summary-box-inner">
<span><p>For autonomous vehicles to viably replace human drivers they must contend
with inclement weather. Falling rain and snow introduce noise in LiDAR returns
resulting in both false positive and false negative object detections. In this
article we introduce the Winter Adverse Driving dataSet (WADS) collected in the
snow belt region of Michigan's Upper Peninsula. WADS is the first multi-modal
dataset featuring dense point-wise labeled sequential LiDAR scans collected in
severe winter weather; weather that would cause an experienced driver to alter
their driving behavior. We have labelled and will make available over 7 GB or
3.6 billion labelled LiDAR points out of over 26 TB of total LiDAR and camera
data collected. We also present the Dynamic Statistical Outlier Removal (DSOR)
filter, a statistical PCL-based filter capable or removing snow with a higher
recall than the state of the art snow de-noising filter while being 28\%
faster. Further, the DSOR filter is shown to have a lower time complexity
compared to the state of the art resulting in an improved scalability.
</p>
<p>Our labeled dataset and DSOR filter will be made available at
https://bitbucket.org/autonomymtu/dsor_filter
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hybrid Local-Global Transformer for Image Dehazing. (arXiv:2109.07100v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07100">
<div class="article-summary-box-inner">
<span><p>Recently, the Vision Transformer (ViT) has shown impressive performance on
high-level and low-level vision tasks. In this paper, we propose a new ViT
architecture, named Hybrid Local-Global Vision Transformer (HyLoG-ViT), for
single image dehazing. The HyLoG-ViT block consists of two paths, the local ViT
path and the global ViT path, which are used to capture local and global
dependencies. The hybrid features are fused via convolution layers. As a
result, the HyLoG-ViT reduces the computational complexity and introduces
locality in the networks. Then, the HyLoG-ViT blocks are incorporated within
our dehazing networks, which jointly learn the intrinsic image decomposition
and image dehazing. Specifically, the network consists of one shared encoder
and three decoders for reflectance prediction, shading prediction, and
haze-free image generation. The tasks of reflectance and shading prediction can
produce meaningful intermediate features that can serve as complementary
features for haze-free image generation. To effectively aggregate the
complementary features, we propose a complementary features selection module
(CFSM) to select the useful ones for image dehazing. Extensive experiments on
homogeneous, non-homogeneous, and nighttime dehazing tasks reveal that our
proposed Transformer-based dehazing network can achieve comparable or even
better performance than CNNs-based dehazing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anchor DETR: Query Design for Transformer-Based Detector. (arXiv:2109.07107v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07107">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel query design for the transformer-based
detectors. In previous transformer-based detectors, the object queries are a
set of learned embeddings. However, each learned embedding does not have an
explicit physical meaning and we can not explain where it will focus on. It is
difficult to optimize as the prediction slot of each object query does not have
a specific mode. In other words, each object query will not focus on a specific
region. To solved these problems, in our query design, object queries are based
on anchor points, which are widely used in CNN-based detectors. So each object
query focus on the objects near the anchor point. Moreover, our query design
can predict multiple objects at one position to solve the difficulty: "one
region, multiple objects". In addition, we design an attention variant, which
can reduce the memory cost while achieving similar or better performance than
the standard attention in DETR. Thanks to the query design and the attention
variant, the proposed detector that we called Anchor DETR, can achieve better
performance and run faster than the DETR with 10$\times$ fewer training epochs.
For example, it achieves 44.2 AP with 16 FPS on the MSCOCO dataset when using
the ResNet50-DC5 feature for training 50 epochs. Extensive experiments on the
MSCOCO benchmark prove the effectiveness of the proposed methods. Code is
available at https://github.com/megvii-model/AnchorDETR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Patch-based medical image segmentation using Quantum Tensor Networks. (arXiv:2109.07138v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07138">
<div class="article-summary-box-inner">
<span><p>Tensor networks are efficient factorisations of high dimensional tensors into
a network of lower order tensors. They have been most commonly used to model
entanglement in quantum many-body systems and more recently are witnessing
increased applications in supervised machine learning. In this work, we
formulate image segmentation in a supervised setting with tensor networks. The
key idea is to first lift the pixels in image patches to exponentially high
dimensional feature spaces and using a linear decision hyper-plane to classify
the input pixels into foreground and background classes. The high dimensional
linear model itself is approximated using the matrix product state (MPS) tensor
network. The MPS is weight-shared between the non-overlapping image patches
resulting in our strided tensor network model. The performance of the proposed
model is evaluated on three 2D- and one 3D- biomedical imaging datasets. The
performance of the proposed tensor network segmentation model is compared with
relevant baseline methods. In the 2D experiments, the tensor network model
yeilds competitive performance compared to the baseline methods while being
more resource efficient.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resolution-robust Large Mask Inpainting with Fourier Convolutions. (arXiv:2109.07161v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07161">
<div class="article-summary-box-inner">
<span><p>Modern image inpainting systems, despite the significant progress, often
struggle with large missing areas, complex geometric structures, and
high-resolution images. We find that one of the main reasons for that is the
lack of an effective receptive field in both the inpainting network and the
loss function. To alleviate this issue, we propose a new method called large
mask inpainting (LaMa). LaMa is based on i) a new inpainting network
architecture that uses fast Fourier convolutions, which have the image-wide
receptive field; ii) a high receptive field perceptual loss; and iii) large
training masks, which unlocks the potential of the first two components. Our
inpainting network improves the state-of-the-art across a range of datasets and
achieves excellent performance even in challenging scenarios, e.g. completion
of periodic structures. Our model generalizes surprisingly well to resolutions
that are higher than those seen at train time, and achieves this at lower
parameter&amp;compute costs than the competitive baselines. The code is available
at https://github.com/saic-mdal/lama.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MISSFormer: An Effective Medical Image Segmentation Transformer. (arXiv:2109.07162v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07162">
<div class="article-summary-box-inner">
<span><p>The CNN-based methods have achieved impressive results in medical image
segmentation, but it failed to capture the long-range dependencies due to the
inherent locality of convolution operation. Transformer-based methods are
popular in vision tasks recently because of its capacity of long-range
dependencies and get a promising performance. However, it lacks in modeling
local context, although some works attempted to embed convolutional layer to
overcome this problem and achieved some improvement, but it makes the feature
inconsistent and fails to leverage the natural multi-scale features of
hierarchical transformer, which limit the performance of models. In this paper,
taking medical image segmentation as an example, we present MISSFormer, an
effective and powerful Medical Image Segmentation tranSFormer. MISSFormer is a
hierarchical encoder-decoder network and has two appealing designs: 1) A feed
forward network is redesigned with the proposed Enhanced Transformer Block,
which makes features aligned adaptively and enhances the long-range
dependencies and local context. 2) We proposed Enhanced Transformer Context
Bridge, a context bridge with the enhanced transformer block to model the
long-range dependencies and local context of multi-scale features generated by
our hierarchical transformer encoder. Driven by these two designs, the
MISSFormer shows strong capacity to capture more valuable dependencies and
context in medical image segmentation. The experiments on multi-organ and
cardiac segmentation tasks demonstrate the superiority, effectiveness and
robustness of our MISSFormer, the exprimental results of MISSFormer trained
from scratch even outperforms state-of-the-art methods pretrained on ImageNet,
and the core designs can be generalized to other visual segmentation tasks. The
code will be released in Github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Annotation Of Arbitrary Objects In The Wild. (arXiv:2109.07165v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07165">
<div class="article-summary-box-inner">
<span><p>Recent years have produced a variety of learning based methods in the context
of computer vision and robotics. Most of the recently proposed methods are
based on deep learning, which require very large amounts of data compared to
traditional methods. The performance of the deep learning methods are largely
dependent on the data distribution they were trained on, and it is important to
use data from the robot's actual operating domain during training. Therefore,
it is not possible to rely on pre-built, generic datasets when deploying robots
in real environments, creating a need for efficient data collection and
annotation in the specific operating conditions the robots will operate in. The
challenge is then: how do we reduce the cost of obtaining such datasets to a
point where we can easily deploy our robots in new conditions, environments and
to support new sensors? As an answer to this question, we propose a data
annotation pipeline based on SLAM, 3D reconstruction, and 3D-to-2D geometry.
The pipeline allows creating 3D and 2D bounding boxes, along with per-pixel
annotations of arbitrary objects without needing accurate 3D models of the
objects prior to data collection and annotation. Our results showcase almost
90% Intersection-over-Union (IoU) agreement on both semantic segmentation and
2D bounding box detection across a variety of objects and scenes, while
speeding up the annotation process by several orders of magnitude compared to
traditional manual annotation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FCA: Learning a 3D Full-coverage Vehicle Camouflage for Multi-view Physical Adversarial Attack. (arXiv:2109.07193v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07193">
<div class="article-summary-box-inner">
<span><p>Physical adversarial attacks in object detection have attracted increasing
attention. However, most previous works focus on hiding the objects from the
detector by generating an individual adversarial patch, which only covers the
planar part of the vehicle's surface and fails to attack the detector in
physical scenarios for multi-view, long-distance and partially occluded
objects. To bridge the gap between digital attacks and physical attacks, we
exploit the full 3D vehicle surface to propose a robust Full-coverage
Camouflage Attack (FCA) to fool detectors. Specifically, we first try rendering
the non-planar camouflage texture over the full vehicle surface. To mimic the
real-world environment conditions, we then introduce a transformation function
to transfer the rendered camouflaged vehicle into a photo-realistic scenario.
Finally, we design an efficient loss function to optimize the camouflage
texture. Experiments show that the full-coverage camouflage attack can not only
outperform state-of-the-art methods under various test cases but also
generalize to different environments, vehicles, and object detectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive Hard-case Mining across Pyramid Levels in Object Detection. (arXiv:2109.07217v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07217">
<div class="article-summary-box-inner">
<span><p>In object detection, multi-level prediction (e.g., FPN, YOLO) and resampling
skills (e.g., focal loss, ATSS) have drastically improved one-stage detector
performance. However, how to improve the performance by optimizing the feature
pyramid level-by-level remains unexplored. We find that, during training, the
ratio of positive over negative samples varies across pyramid levels
(\emph{level imbalance}), which is not addressed by current one-stage
detectors. To mediate the influence of level imbalance, we propose a Unified
Multi-level Optimization Paradigm (UMOP) consisting of two components: 1) an
independent classification loss supervising each pyramid level with individual
resampling considerations; 2) a progressive hard-case mining loss defining all
losses across the pyramid levels without extra level-wise settings. With UMOP
as a plug-and-play scheme, modern one-stage detectors can attain a ~1.5 AP
improvement with fewer training iterations and no additional computation
overhead. Our best model achieves 55.1 AP on COCO test-dev. Code is available
at https://github.com/zimoqingfeng/UMOP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Navigation-Oriented Scene Understanding for Robotic Autonomy: Learning to Segment Driveability in Egocentric Images. (arXiv:2109.07245v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07245">
<div class="article-summary-box-inner">
<span><p>This work tackles scene understanding for outdoor robotic navigation, solely
relying on images captured by an on-board camera. Conventional visual scene
understanding interprets the environment based on specific descriptive
categories. However, such a representation is not directly interpretable for
decision-making and constrains robot operation to a specific domain. Thus, we
propose to segment egocentric images directly in terms of how a robot can
navigate in them, and tailor the learning problem to an autonomous navigation
task. Building around an image segmentation network, we present a generic and
scalable affordance-based definition consisting of 3 driveability levels which
can be applied to arbitrary scenes. By encoding these levels with soft ordinal
labels, we incorporate inter-class distances during learning which improves
segmentation compared to standard one-hot labelling. In addition, we propose a
navigation-oriented pixel-wise loss weighting method which assigns higher
importance to safety-critical areas. We evaluate our approach on large-scale
public image segmentation datasets spanning off-road and urban scenes. In a
zero-shot cross-dataset generalization experiment, we show that our affordance
learning scheme can be applied across a diverse mix of datasets and improves
driveability estimation in unseen environments compared to general-purpose,
single-dataset segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RGB-D Saliency Detection via Cascaded Mutual Information Minimization. (arXiv:2109.07246v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07246">
<div class="article-summary-box-inner">
<span><p>Existing RGB-D saliency detection models do not explicitly encourage RGB and
depth to achieve effective multi-modal learning. In this paper, we introduce a
novel multi-stage cascaded learning framework via mutual information
minimization to "explicitly" model the multi-modal information between RGB
image and depth data. Specifically, we first map the feature of each mode to a
lower dimensional feature vector, and adopt mutual information minimization as
a regularizer to reduce the redundancy between appearance features from RGB and
geometric features from depth. We then perform multi-stage cascaded learning to
impose the mutual information minimization constraint at every stage of the
network. Extensive experiments on benchmark RGB-D saliency datasets illustrate
the effectiveness of our framework. Further, to prosper the development of this
field, we contribute the largest (7x larger than NJU2K) dataset, which contains
15,625 image pairs with high quality
polygon-/scribble-/object-/instance-/rank-level annotations. Based on these
rich labels, we additionally construct four new benchmarks with strong
baselines and observe some interesting phenomena, which can motivate future
model design. Source code and dataset are available at
"https://github.com/JingZhang617/cascaded_rgbd_sod".
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating Sensing and Communication in Cellular Networks via NR Sidelink. (arXiv:2109.07253v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07253">
<div class="article-summary-box-inner">
<span><p>RF-sensing, the analysis and interpretation of movement or
environment-induced patterns in received electromagnetic signals, has been
actively investigated for more than a decade. Since electromagnetic signals,
through cellular communication systems, are omnipresent, RF sensing has the
potential to become a universal sensing mechanism with applications in smart
home, retail, localization, gesture recognition, intrusion detection, etc.
Specifically, existing cellular network installations might be dual-used for
both communication and sensing. Such communications and sensing convergence is
envisioned for future communication networks. We propose the use of NR-sidelink
direct device-to-device communication to achieve device-initiated,flexible
sensing capabilities in beyond 5G cellular communication systems. In this
article, we specifically investigate a common issue related to sidelink-based
RF-sensing, which is its angle and rotation dependence. In particular, we
discuss transformations of mmWave point-cloud data which achieve rotational
invariance, as well as distributed processing based on such rotational
invariant inputs, at angle and distance diverse devices. To process the
distributed data, we propose a graph based encoder to capture spatio-temporal
features of the data and propose four approaches for multi-angle learning. The
approaches are compared on a newly recorded and openly available dataset
comprising 15 subjects, performing 21 gestures which are recorded from 8
angles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distract Your Attention: Multi-head Cross Attention Network for Facial Expression Recognition. (arXiv:2109.07270v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07270">
<div class="article-summary-box-inner">
<span><p>We present a novel facial expression recognition network, called Distract
your Attention Network (DAN). Our method is based on two key observations.
Firstly, multiple classes share inherently similar underlying facial
appearance, and their differences could be subtle. Secondly, facial expressions
exhibit themselves through multiple facial regions simultaneously, and the
recognition requires a holistic approach by encoding high-order interactions
among local features. To address these issues, we propose our DAN with three
key components: Feature Clustering Network (FCN), Multi-head cross Attention
Network (MAN), and Attention Fusion Network (AFN). The FCN extracts robust
features by adopting a large-margin learning objective to maximize class
separability. In addition, the MAN instantiates a number of attention heads to
simultaneously attend to multiple facial areas and build attention maps on
these regions. Further, the AFN distracts these attentions to multiple
locations before fusing the attention maps to a comprehensive one. Extensive
experiments on three public datasets (including AffectNet, RAF-DB, and SFEW
2.0) verified that the proposed method consistently achieves state-of-the-art
facial expression recognition performance. Code will be made available at
https://github.com/yaoing/DAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">New Perspective on Progressive GANs Distillationfor One-class Novelty Detection. (arXiv:2109.07295v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07295">
<div class="article-summary-box-inner">
<span><p>One-class novelty detection is conducted to iden-tify anomalous instances,
with different distributions from theexpected normal instances. In this paper,
the Generative Adver-sarial Network based on the Encoder-Decoder-Encoder
scheme(EDE-GAN) achieves state-of-the-art performance. The two fac-tors bellow
serve the above purpose: 1) The EDE-GAN calculatesthe distance between two
latent vectors as the anomaly score,which is unlike the previous methods by
utilizing the reconstruc-tion error between images. 2) The model obtains best
resultswhen the batch size is set to 1. To illustrate their superiority,we
design a new GAN architecture, and compareperformances according to different
batch sizes. Moreover, withexperimentation leads to discovery, our result
implies there is alsoevidence of just how beneficial constraint on the latent
space arewhen engaging in model training.In an attempt to learn compact and
fast models, we present anew technology, Progressive Knowledge Distillation
with GANs(P-KDGAN), which connects two standard GANs through thedesigned
distillation loss. Two-step progressive learning continu-ously augments the
performance of student GANs with improvedresults over single-step approach. Our
experimental results onCIFAR-10, MNIST, and FMNIST datasets illustrate that
P-KDGAN improves the performance of the student GAN by2.44%, 1.77%, and 1.73%
when compressing the computationat ratios of 24.45:1, 311.11:1, and 700:1,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FFAVOD: Feature Fusion Architecture for Video Object Detection. (arXiv:2109.07298v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07298">
<div class="article-summary-box-inner">
<span><p>A significant amount of redundancy exists between consecutive frames of a
video. Object detectors typically produce detections for one image at a time,
without any capabilities for taking advantage of this redundancy. Meanwhile,
many applications for object detection work with videos, including intelligent
transportation systems, advanced driver assistance systems and video
surveillance. Our work aims at taking advantage of the similarity between video
frames to produce better detections. We propose FFAVOD, standing for feature
fusion architecture for video object detection. We first introduce a novel
video object detection architecture that allows a network to share feature maps
between nearby frames. Second, we propose a feature fusion module that learns
to merge feature maps to enhance them. We show that using the proposed
architecture and the fusion module can improve the performance of three base
object detectors on two object detection benchmarks containing sequences of
moving road users. Additionally, to further increase performance, we propose an
improvement to the SpotNet attention module. Using our architecture on the
improved SpotNet detector, we obtain the state-of-the-art performance on the
UA-DETRAC public benchmark as well as on the UAVDT dataset. Code is available
at https://github.com/hu64/FFAVOD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MD-CSDNetwork: Multi-Domain Cross Stitched Network for Deepfake Detection. (arXiv:2109.07311v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07311">
<div class="article-summary-box-inner">
<span><p>The rapid progress in the ease of creating and spreading ultra-realistic
media over social platforms calls for an urgent need to develop a generalizable
deepfake detection technique. It has been observed that current deepfake
generation methods leave discriminative artifacts in the frequency spectrum of
fake images and videos. Inspired by this observation, in this paper, we present
a novel approach, termed as MD-CSDNetwork, for combining the features in the
spatial and frequency domains to mine a shared discriminative representation
for classifying \textit{deepfakes}. MD-CSDNetwork is a novel cross-stitched
network with two parallel branches carrying the spatial and frequency
information, respectively. We hypothesize that these multi-domain input data
streams can be considered as related supervisory signals. The supervision from
both branches ensures better performance and generalization. Further, the
concept of cross-stitch connections is utilized where they are inserted between
the two branches to learn an optimal combination of domain-specific and shared
representations from other domains automatically. Extensive experiments are
conducted on the popular benchmark dataset namely FaceForeniscs++ for forgery
classification. We report improvements over all the manipulation types in
FaceForensics++ dataset and comparable results with state-of-the-art methods
for cross-database evaluation on the Celeb-DF dataset and the Deepfake
Detection Dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeFungi: Direct Mycological Examination of Microscopic Fungi Images. (arXiv:2109.07322v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07322">
<div class="article-summary-box-inner">
<span><p>Traditionally, diagnosis and treatment of fungal infections in humans depend
heavily on face-to-face consultations or examinations made by specialized
laboratory scientists known as mycologists. In many cases, such as the recent
mucormycosis spread in the COVID-19 pandemic, an initial treatment can be
safely suggested to the patient during the earliest stage of the mycological
diagnostic process by performing a direct examination of biopsies or samples
through a microscope. Computer-aided diagnosis systems using deep learning
models have been trained and used for the late mycological diagnostic stages.
However, there are no reference literature works made for the early stages. A
mycological laboratory in Colombia donated the images used for the development
of this research work. They were manually labelled into five classes and
curated with a subject matter expert assistance. The images were later cropped
and patched with automated code routines to produce the final dataset. This
paper presents experimental results classifying five fungi types using two
different deep learning approaches and three different convolutional neural
network models, VGG16, Inception V3, and ResNet50. The first approach
benchmarks the classification performance for the models trained from scratch,
while the second approach benchmarks the classification performance using
pre-trained models based on the ImageNet dataset. Using k-fold cross-validation
testing on the 5-class dataset, the best performing model trained from scratch
was Inception V3, reporting 73.2% accuracy. Also, the best performing model
using transfer learning was VGG16 reporting 85.04%. The statistics provided by
the two approaches create an initial point of reference to encourage future
research works to improve classification performance. Furthermore, the dataset
built is published in Kaggle and GitHub to foster future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PointManifoldCut: Point-wise Augmentation in the Manifold for Point Clouds. (arXiv:2109.07324v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07324">
<div class="article-summary-box-inner">
<span><p>Augmentation can benefit point cloud learning due to the limited availability
of large-scale public datasets. This paper proposes a mix-up augmentation
approach, PointManifoldCut, which replaces the neural network embedded points,
rather than the Euclidean space coordinates. This approach takes the advantage
that points at the higher levels of the neural network are already trained to
embed its neighbors relations and mixing these representation will not mingle
the relation between itself and its label. This allows to regularize the
parameter space as the other augmentation methods but without worrying about
the proper label of the replaced points. The experiments show that our proposed
approach provides a competitive performance on point cloud classification and
segmentation when it is combined with the cutting-edge vanilla point cloud
networks. The result shows a consistent performance boosting compared to other
state-of-the-art point cloud augmentation method, such as PointMixup and
PointCutMix. The code of this paper is available at:
https://github.com/fun0515/PointManifoldCut.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">S3LAM: Structured Scene SLAM. (arXiv:2109.07339v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07339">
<div class="article-summary-box-inner">
<span><p>We propose a new general SLAM system that uses the semantic segmentation of
objects and structures in the scene. Semantic information is relevant as it
contains high level information which may make SLAM more accurate and robust.
Our contribution is threefold: i) A new SLAM system based on ORB-SLAM2 that
creates a semantic map made of clusters of points corresponding to objects
instances and structures in the scene. ii) A modification of the classical
Bundle Adjustment formulation to constrain each cluster using geometrical
priors, which improves both camera localization and reconstruction and enables
a better understanding of the scene. iii) A new Bundle Adjustment formulation
at the level of clusters to improve the convergence of classical Bundle
Adjustment. We evaluate our approach on several sequences from a public dataset
and show that, with respect to ORB-SLAM2 it improves camera pose estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Dynamical Human-Joint Affinity for 3D Pose Estimation in Videos. (arXiv:2109.07353v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07353">
<div class="article-summary-box-inner">
<span><p>Graph Convolution Network (GCN) has been successfully used for 3D human pose
estimation in videos. However, it is often built on the fixed human-joint
affinity, according to human skeleton. This may reduce adaptation capacity of
GCN to tackle complex spatio-temporal pose variations in videos. To alleviate
this problem, we propose a novel Dynamical Graph Network (DG-Net), which can
dynamically identify human-joint affinity, and estimate 3D pose by adaptively
learning spatial/temporal joint relations from videos. Different from
traditional graph convolution, we introduce Dynamical Spatial/Temporal Graph
convolution (DSG/DTG) to discover spatial/temporal human-joint affinity for
each video exemplar, depending on spatial distance/temporal movement similarity
between human joints in this video. Hence, they can effectively understand
which joints are spatially closer and/or have consistent motion, for reducing
depth ambiguity and/or motion uncertainty when lifting 2D pose to 3D pose. We
conduct extensive experiments on three popular benchmarks, e.g., Human3.6M,
HumanEva-I, and MPI-INF-3DHP, where DG-Net outperforms a number of recent SOTA
approaches with fewer input frames and model size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Direct and Sparse Deformable Tracking. (arXiv:2109.07370v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07370">
<div class="article-summary-box-inner">
<span><p>Deformable Monocular SLAM algorithms recover the localization of a camera in
an unknown deformable environment. Current approaches use a template-based
deformable tracking to recover the camera pose and the deformation of the map.
These template-based methods use an underlying global deformation model. In
this paper, we introduce a novel deformable camera tracking method with a local
deformation model for each point. Each map point is defined as a single
textured surfel that moves independently of the other map points. Thanks to a
direct photometric error cost function, we can track the position and
orientation of the surfel without an explicit global deformation model. In our
experiments, we validate the proposed system and observe that our local
deformation model estimates more accurately and robustly the targeted
deformations of the map in both laboratory-controlled experiments and in-body
scenarios undergoing non-isometric deformations, with changing topology or
discontinuities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Framework for Biphasic Facial Age Translation with Noisy-Semantic Guided Generative Adversarial Networks. (arXiv:2109.07373v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07373">
<div class="article-summary-box-inner">
<span><p>Biphasic facial age translation aims at predicting the appearance of the
input face at any age. Facial age translation has received considerable
research attention in the last decade due to its practical value in cross-age
face recognition and various entertainment applications. However, most existing
methods model age changes between holistic images, regardless of the human face
structure and the age-changing patterns of individual facial components.
Consequently, the lack of semantic supervision will cause infidelity of
generated faces in detail. To this end, we propose a unified framework for
biphasic facial age translation with noisy-semantic guided generative
adversarial networks. Structurally, we project the class-aware noisy semantic
layouts to soft latent maps for the following injection operation on the
individual facial parts. In particular, we introduce two sub-networks,
ProjectionNet and ConstraintNet. ProjectionNet introduces the low-level
structural semantic information with noise map and produces soft latent maps.
ConstraintNet disentangles the high-level spatial features to constrain the
soft latent maps, which endows more age-related context into the soft latent
maps. Specifically, attention mechanism is employed in ConstraintNet for
feature disentanglement. Meanwhile, in order to mine the strongest mapping
ability of the network, we embed two types of learning strategies in the
training procedure, supervised self-driven generation and unsupervised
condition-driven cycle-consistent generation. As a result, extensive
experiments conducted on MORPH and CACD datasets demonstrate the prominent
ability of our proposed method which achieves state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-supervised Contrastive Learning for Label-efficient Medical Image Segmentation. (arXiv:2109.07407v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07407">
<div class="article-summary-box-inner">
<span><p>The success of deep learning methods in medical image segmentation tasks
heavily depends on a large amount of labeled data to supervise the training. On
the other hand, the annotation of biomedical images requires domain knowledge
and can be laborious. Recently, contrastive learning has demonstrated great
potential in learning latent representation of images even without any label.
Existing works have explored its application to biomedical image segmentation
where only a small portion of data is labeled, through a pre-training phase
based on self-supervised contrastive learning without using any labels followed
by a supervised fine-tuning phase on the labeled portion of data only. In this
paper, we establish that by including the limited label in formation in the
pre-training phase, it is possible to boost the performance of contrastive
learning. We propose a supervised local contrastive loss that leverages limited
pixel-wise annotation to force pixels with the same label to gather around in
the embedding space. Such loss needs pixel-wise computation which can be
expensive for large images, and we further propose two strategies, downsampling
and block division, to address the issue. We evaluate our methods on two public
biomedical image datasets of different modalities. With different amounts of
labeled data, our methods consistently outperform the state-of-the-art
contrast-based methods and other semi-supervised learning techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Wide-area, Low-latency, and Power-efficient 6-DoF Pose Tracking System for Rigid Objects. (arXiv:2109.07428v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07428">
<div class="article-summary-box-inner">
<span><p>Position sensitive detectors (PSDs) offer possibility to track single active
marker's two (or three) degrees of freedom (DoF) position with a high accuracy,
while having a fast response time with high update frequency and low latency,
all using a very simple signal processing circuit. However they are not
particularly suitable for 6-DoF object pose tracking system due to lack of
orientation measurement, limited tracking range, and sensitivity to
environmental variation. We propose a novel 6-DoF pose tracking system for a
rigid object tracking requiring a single active marker. The proposed system
uses a stereo-based PSD pair and multiple Inertial Measurement Units (IMUs).
This is done based on a practical approach to identify and control the power of
Infrared-Light Emitting Diode (IR-LED) active markers, with an aim to increase
the tracking work space and reduce the power consumption. Our proposed tracking
system is validated with three different work space sizes and for static and
dynamic positional accuracy using robotic arm manipulator with three different
dynamic motion patterns. The results show that the static position
root-mean-square (RMS) error is 0.6mm. The dynamic position RMS error is
0.7-0.9mm. The orientation RMS error is between 0.04 and 0.9 degree at varied
dynamic motion. Overall, our proposed tracking system is capable of tracking a
rigid object pose with sub-millimeter accuracy at the mid range of the work
space and sub-degree accuracy for all work space under a lab setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contact-Aware Retargeting of Skinned Motion. (arXiv:2109.07431v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07431">
<div class="article-summary-box-inner">
<span><p>This paper introduces a motion retargeting method that preserves
self-contacts and prevents interpenetration. Self-contacts, such as when hands
touch each other or the torso or the head, are important attributes of human
body language and dynamics, yet existing methods do not model or preserve these
contacts. Likewise, interpenetration, such as a hand passing into the torso,
are a typical artifact of motion estimation methods. The input to our method is
a human motion sequence and a target skeleton and character geometry. The
method identifies self-contacts and ground contacts in the input motion, and
optimizes the motion to apply to the output skeleton, while preserving these
contacts and reducing interpenetration. We introduce a novel
geometry-conditioned recurrent network with an encoder-space optimization
strategy that achieves efficient retargeting while satisfying contact
constraints. In experiments, our results quantitatively outperform previous
methods and we conduct a user study where our retargeted motions are rated as
higher-quality than those produced by recent works. We also show our method
generalizes to motion estimated from human videos where we improve over
previous works that produce noticeable interpenetration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Human Performer: Learning Generalizable Radiance Fields for Human Performance Rendering. (arXiv:2109.07448v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07448">
<div class="article-summary-box-inner">
<span><p>In this paper, we aim at synthesizing a free-viewpoint video of an arbitrary
human performance using sparse multi-view cameras. Recently, several works have
addressed this problem by learning person-specific neural radiance fields
(NeRF) to capture the appearance of a particular human. In parallel, some work
proposed to use pixel-aligned features to generalize radiance fields to
arbitrary new scenes and objects. Adopting such generalization approaches to
humans, however, is highly challenging due to the heavy occlusions and dynamic
articulations of body parts. To tackle this, we propose Neural Human Performer,
a novel approach that learns generalizable neural radiance fields based on a
parametric human body model for robust performance capture. Specifically, we
first introduce a temporal transformer that aggregates tracked visual features
based on the skeletal body motion over time. Moreover, a multi-view transformer
is proposed to perform cross-attention between the temporally-fused features
and the pixel-aligned features at each time step to integrate observations on
the fly from multiple views. Experiments on the ZJU-MoCap and AIST datasets
show that our method significantly outperforms recent generalizable NeRF
methods on unseen identities and poses. The video results and code are
available at https://youngjoongunc.github.io/nhp.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Bregman Divergence for Contrastive Learning of Visual Representations. (arXiv:2109.07455v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07455">
<div class="article-summary-box-inner">
<span><p>Deep Bregman divergence measures divergence of data points using neural
networks which is beyond Euclidean distance and capable of capturing divergence
over distributions. In this paper, we propose deep Bregman divergences for
contrastive learning of visual representation and we aim to enhance contrastive
loss used in self-supervised learning by training additional networks based on
functional Bregman divergence. In contrast to the conventional contrastive
learning methods which are solely based on divergences between single points,
our framework can capture the divergence between distributions which improves
the quality of learned representation. By combining conventional contrastive
loss with the proposed divergence loss, our method outperforms baseline and
most of previous methods for self-supervised and semi-supervised learning on
multiple classifications and object detection tasks and datasets. The source
code of the method and of all the experiments are available at supplementary.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combo Loss: Handling Input and Output Imbalance in Multi-Organ Segmentation. (arXiv:1805.02798v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1805.02798">
<div class="article-summary-box-inner">
<span><p>Simultaneous segmentation of multiple organs from different medical imaging
modalities is a crucial task as it can be utilized for computer-aided
diagnosis, computer-assisted surgery, and therapy planning. Thanks to the
recent advances in deep learning, several deep neural networks for medical
image segmentation have been introduced successfully for this purpose. In this
paper, we focus on learning a deep multi-organ segmentation network that labels
voxels. In particular, we examine the critical choice of a loss function in
order to handle the notorious imbalance problem that plagues both the input and
output of a learning model. The input imbalance refers to the class-imbalance
in the input training samples (i.e., small foreground objects embedded in an
abundance of background voxels, as well as organs of varying sizes). The output
imbalance refers to the imbalance between the false positives and false
negatives of the inference model. In order to tackle both types of imbalance
during training and inference, we introduce a new curriculum learning based
loss function. Specifically, we leverage Dice similarity coefficient to deter
model parameters from being held at bad local minima and at the same time
gradually learn better model parameters by penalizing for false
positives/negatives using a cross entropy term. We evaluated the proposed loss
function on three datasets: whole body positron emission tomography (PET) scans
with 5 target organs, magnetic resonance imaging (MRI) prostate scans, and
ultrasound echocardigraphy images with a single target organ i.e., left
ventricular. We show that a simple network architecture with the proposed
integrative loss function can outperform state-of-the-art methods and results
of the competing methods can be improved when our proposed loss is used.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DAPnet: A Double Self-attention Convolutional Network for Point Cloud Semantic Labeling. (arXiv:2004.08596v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.08596">
<div class="article-summary-box-inner">
<span><p>Airborne Laser Scanning (ALS) point clouds have complex structures, and their
3D semantic labeling has been a challenging task. It has three problems: (1)
the difficulty of classifying point clouds around boundaries of objects from
different classes, (2) the diversity of shapes within the same class, and (3)
the scale differences between classes. In this study, we propose a novel double
self-attention convolutional network called the DAPnet. The double
self-attention includes the point attention module (PAM) and the group
attention module (GAM). For problem (1), the PAM can effectively assign
different weights based on the relevance of point clouds in adjacent areas.
Meanwhile, for the problem (2), the GAM enhances the correlation between
groups, i.e., grouped features within the same classes. To solve the problem
(3), we adopt a multiscale radius to construct the groups and concatenate
extracted hierarchical features with the output of the corresponding upsampling
process. Under the ISPRS 3D Semantic Labeling Contest dataset, the DAPnet
outperforms the benchmark by 85.2\% with an overall accuracy of 90.7\%. By
conducting ablation comparisons, we find that the PAM effectively improves the
model than the GAM. The incorporation of the double self-attention module has
an average of 7\% improvement on the pre-class accuracy. Plus, the DAPnet
consumes a similar training time to those without the attention modules for
model convergence. The DAPnet can assign different weights to features based on
the relevance between point clouds and their neighbors, which effectively
improves classification performance. The source codes are available at:
https://github.com/RayleighChen/point-attention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Detection of Aedes aegypti Breeding Grounds Based on Deep Networks with Spatio-Temporal Consistency. (arXiv:2007.14863v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14863">
<div class="article-summary-box-inner">
<span><p>Every year, the Aedes aegypti mosquito infects millions of people with
diseases such as dengue, zika, chikungunya, and urban yellow fever. The main
form to combat these diseases is to avoid mosquito reproduction by searching
for and eliminating the potential mosquito breeding grounds. In this work, we
introduce a comprehensive dataset of aerial videos, acquired with an unmanned
aerial vehicle, containing possible mosquito breeding sites. All frames of the
video dataset were manually annotated with bounding boxes identifying all
objects of interest. This dataset was employed to develop an automatic
detection system of such objects based on deep convolutional networks. We
propose the exploitation of the temporal information contained in the videos by
the incorporation, in the object detection pipeline, of a spatio-temporal
consistency module that can register the detected objects, minimizing most
false-positive and false-negative occurrences. Using the ResNet-50-FPN as a
backbone, we achieve F$_1$-scores of 0.65 and 0.77 on the object-level
detection of `tires' and `water tanks', respectively, illustrating the system
capabilities to properly locate potential mosquito breeding objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Efficient Quantitative Approach for Optimizing Convolutional Neural Networks. (arXiv:2009.05236v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05236">
<div class="article-summary-box-inner">
<span><p>With the increasing popularity of deep learning, Convolutional Neural
Networks (CNNs) have been widely applied in various domains, such as image
classification and object detection, and achieve stunning success in terms of
their high accuracy over the traditional statistical methods. To exploit the
potential of CNN models, a huge amount of research and industry efforts have
been devoted to optimizing CNNs. Among these endeavors, CNN architecture design
has attracted tremendous attention because of its great potential of improving
model accuracy or reducing model complexity. However, existing work either
introduces repeated training overhead in the search process or lacks an
interpretable metric to guide the design. To clear these hurdles, we propose
3D-Receptive Field (3DRF), an explainable and easy-to-compute metric, to
estimate the quality of a CNN architecture and guide the search process of
designs. To validate the effectiveness of 3DRF, we build a static optimizer to
improve the CNN architectures at both the stage level and the kernel level. Our
optimizer not only provides a clear and reproducible procedure but also
mitigates unnecessary training efforts in the architecture search process.
Extensive experiments and studies show that the models generated by our
optimizer can achieve up to 5.47% accuracy improvement and up to 65.38%
parameters deduction, compared with state-of-the-art CNN structures like
MobileNet and ResNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Likelihood-Based Diverse Sampling for Trajectory Forecasting. (arXiv:2011.15084v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.15084">
<div class="article-summary-box-inner">
<span><p>Forecasting complex vehicle and pedestrian multi-modal distributions requires
powerful probabilistic approaches. Normalizing flows (NF) have recently emerged
as an attractive tool to model such distributions. However, a key drawback is
that independent samples drawn from a flow model often do not adequately
capture all the modes in the underlying distribution. We propose
Likelihood-Based Diverse Sampling (LDS), a method for improving the quality and
the diversity of trajectory samples from a pre-trained flow model. Rather than
producing individual samples, LDS produces a set of trajectories in one shot.
Given a pre-trained forecasting flow model, we train LDS using gradients from
the model, to optimize an objective function that rewards high likelihood for
individual trajectories in the predicted set, together with high spatial
separation among trajectories. LDS outperforms state-of-art post-hoc neural
diverse forecasting methods for various pre-trained flow models as well as
conditional variational autoencoder (CVAE) models. Crucially, it can also be
used for transductive trajectory forecasting, where the diverse forecasts are
trained on-the-fly on unlabeled test examples. LDS is easy to implement, and we
show that it offers a simple plug-in improvement over baselines on two
challenging benchmarks. Code is at: https://github.com/JasonMa2016/LDS
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making Contrastive Learning Robust to Shortcuts. (arXiv:2012.09962v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09962">
<div class="article-summary-box-inner">
<span><p>Contrastive learning is one of the fastest growing research areas in machine
learning due to its ability to learn useful representations without labeled
data. However, contrastive learning is susceptible to shortcuts - i.e., it may
learn shortcut features irrelevant to the task of interest, and discard
relevant information. Past work has addressed this limitation via handcrafted
data augmentations that eliminate the shortcut. But, manually crafted
augmentations do not work across all datasets and tasks. Further, data
augmentations fail in addressing shortcuts in multi-attribute classification
when one attribute acts as a shortcut around other attributes. In this paper,
we analyze the objective function of contrastive learning and formally prove
that it is vulnerable to shortcuts. We then present reconstructive contrastive
learning (RCL), a framework for learning unsupervised representations that are
robust to shortcuts. The key idea is to force the learned representation to
reconstruct the input, which naturally counters potential shortcuts. Extensive
experiments verify that RCL is highly robust to shortcuts and outperforms
state-of-the-art contrastive learning methods on a variety of datasets and
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Aware Body Composition Analysis with Deep Regression Ensembles on UK Biobank MRI. (arXiv:2101.06963v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06963">
<div class="article-summary-box-inner">
<span><p>Along with rich health-related metadata, medical images have been acquired
for over 40,000 male and female UK Biobank participants, aged 44-82, since
2014. Phenotypes derived from these images, such as measurements of body
composition from MRI, can reveal new links between genetics, cardiovascular
disease, and metabolic conditions. In this work, six measurements of body
composition and adipose tissues were automatically estimated by image-based,
deep regression with ResNet50 neural networks from neck-to-knee body MRI.
Despite the potential for high speed and accuracy, these networks produce no
output segmentations that could indicate the reliability of individual
measurements. The presented experiments therefore examine uncertainty
quantification with mean-variance regression and ensembling to estimate
individual measurement errors and thereby identify potential outliers,
anomalies, and other failure cases automatically. In 10-fold cross-validation
on data of about 8,500 subjects, mean-variance regression and ensembling showed
complementary benefits, reducing the mean absolute error across all predictions
by 12%. Both improved the calibration of uncertainties and their ability to
identify high prediction errors. With intra-class correlation coefficients
(ICC) above 0.97, all targets except the liver fat content yielded relative
measurement errors below 5%. Testing on another 1,000 subjects showed
consistent performance, and the method was finally deployed for inference to
30,000 subjects with missing reference values. The results indicate that deep
regression ensembles could ultimately provide automated, uncertainty-aware
measurements of body composition for more than 120,000 UK Biobank neck-to-knee
body MRI that are to be acquired within the coming years.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AGRNet: Adaptive Graph Representation Learning and Reasoning for Face Parsing. (arXiv:2101.07034v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07034">
<div class="article-summary-box-inner">
<span><p>Face parsing infers a pixel-wise label to each facial component, which has
drawn much attention recently.Previous methods have shown their success in face
parsing, which however overlook the correlation among facial components.As a
matter of fact, the component-wise relationship is a critical clue in
discriminating ambiguous pixels in facial area.To address this issue, we
propose adaptive graph representation learning and reasoning over facial
components, aiming to learn representative vertices that describe each
component, exploit the component-wise relationship and thereby produce accurate
parsing results against ambiguity. In particular, we devise an adaptive and
differentiable graph abstraction method to represent the components on a graph
via pixel-to-vertex projection under the initial condition of a predicted
parsing map, where pixel features within a certain facial region are aggregated
onto a vertex. Further, we explicitly incorporate the image edge as a prior in
the model, which helps to discriminate edge and non-edge pixels during the
projection, thus leading to refined parsing results along the edges.Then, our
model learns and reasons over the relations among components by propagating
information across vertices on the graph. Finally, the refined vertex features
are projected back to pixel grids for the prediction of the final parsing
map.To train our model, we propose a discriminative loss to penalize small
distances between vertices in the feature space, which leads to distinct
vertices with strong semantics. Experimental results show the superior
performance of the proposed model on multiple face parsing datasets, along with
the validation on the human parsing task to demonstrate the generalizability of
our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Salient Object Detection via Integrity Learning. (arXiv:2101.07663v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07663">
<div class="article-summary-box-inner">
<span><p>Albeit current salient object detection (SOD) works have achieved fantastic
progress, they are cast into the shade when it comes to the integrity of the
predicted salient regions. We define the concept of integrity at both the micro
and macro level. Specifically, at the micro level, the model should highlight
all parts that belong to a certain salient object, while at the macro level,
the model needs to discover all salient objects from the given image scene. To
facilitate integrity learning for salient object detection, we design a novel
Integrity Cognition Network (ICON), which explores three important components
to learn strong integrity features. 1) Unlike the existing models that focus
more on feature discriminability, we introduce a diverse feature aggregation
(DFA) component to aggregate features with various receptive fields (i.e.,,
kernel shape and context) and increase the feature diversity. Such diversity is
the foundation for mining the integral salient objects. 2) Based on the DFA
features, we introduce the integrity channel enhancement (ICE) component with
the goal of enhancing feature channels that highlight the integral salient
objects at the macro level, while suppressing the other distracting ones. 3)
After extracting the enhanced features, the part-whole verification (PWV)
method is employed to determine whether the part and whole object features have
strong agreement. Such part-whole agreements can further improve the
micro-level integrity for each salient object. To demonstrate the effectiveness
of ICON, comprehensive experiments are conducted on seven challenging
benchmarks, where promising results are achieved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solid Texture Synthesis using Generative Adversarial Networks. (arXiv:2102.03973v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03973">
<div class="article-summary-box-inner">
<span><p>Solid texture synthesis (STS), as an effective way to extend 2D exemplar to a
3D solid volume, exhibits advantages in numerous application domains. However,
existing methods generally synthesize solid texture with specific features,
which may result in the failure of capturing diversified textural information.
In this paper, we propose a novel generative adversarial nets-based approach
(STS-GAN) to hierarchically learn solid texture with a feature-free nature. Our
multi-scale discriminators evaluate the similarity between patch from exemplar
and slice from the generated volume, promoting the generator to synthesize
realistic solid textures. Experimental results demonstrate that the proposed
method can generate high-quality solid textures with similar visual
characteristics to the exemplar.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Direct Estimation of Appearance Models for Segmentation. (arXiv:2102.11121v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11121">
<div class="article-summary-box-inner">
<span><p>Image segmentation algorithms often depend on appearance models that
characterize the distribution of pixel values in different image regions. We
describe a new approach for estimating appearance models directly from an
image, without explicit consideration of the pixels that make up each region.
Our approach is based on novel algebraic expressions that relate local image
statistics to the appearance of spatially coherent regions. We describe two
algorithms that can use the aforementioned algebraic expressions to estimate
appearance models directly from an image. The first algorithm solves a system
of linear and quadratic equations using a least squares formulation. The second
algorithm is a spectral method based on an eigenvector computation. We present
experimental results that demonstrate the proposed methods work well in
practice and lead to effective image segmentation algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Land Cover Mapping in Limited Labels Scenario: A Survey. (arXiv:2103.02429v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02429">
<div class="article-summary-box-inner">
<span><p>Land cover mapping is essential for monitoring global environmental change
and managing natural resources. Unfortunately, traditional classification
models are plagued by limited training data available in existing land cover
products and data heterogeneity over space and time. In this survey, we provide
a structured and comprehensive overview of challenges in land cover mapping and
machine learning methods used to address these problems. We also discuss the
gaps and opportunities that exist for advancing research in this promising
direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast and Accurate: Video Enhancement using Sparse Depth. (arXiv:2103.08764v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08764">
<div class="article-summary-box-inner">
<span><p>This paper presents a general framework to build fast and accurate algorithms
for video enhancement tasks such as super-resolution, deblurring, and
denoising. Essential to our framework is the realization that the accuracy,
rather than the density, of pixel flows is what is required for high-quality
video enhancement. Most of prior works take the opposite approach: they
estimate dense (per-pixel)-but generally less robust-flows, mostly using
computationally costly algorithms. Instead, we propose a lightweight flow
estimation algorithm; it fuses the sparse point cloud data and (even sparser
and less reliable) IMU data available in modern autonomous agents to estimate
the flow information. Building on top of the flow estimation, we demonstrate a
general framework that integrates the flows in a plug-and-play fashion with
different task-specific layers. Algorithms built in our framework achieve 1.78x
- 187.41x speedup while providing a 0.42 dB - 6.70 dB quality improvement over
competing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Training Enhances Online Continual Learning. (arXiv:2103.14010v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14010">
<div class="article-summary-box-inner">
<span><p>In continual learning, a system must incrementally learn from a
non-stationary data stream without catastrophic forgetting. Recently, multiple
methods have been devised for incrementally learning classes on large-scale
image classification tasks, such as ImageNet. State-of-the-art continual
learning methods use an initial supervised pre-training phase, in which the
first 10% - 50% of the classes in a dataset are used to learn representations
in an offline manner before continual learning of new classes begins. We
hypothesize that self-supervised pre-training could yield features that
generalize better than supervised learning, especially when the number of
samples used for pre-training is small. We test this hypothesis using the
self-supervised MoCo-V2, Barlow Twins, and SwAV algorithms. On ImageNet, we
find that these methods outperform supervised pre-training considerably for
online continual learning, and the gains are larger when fewer samples are
available. Our findings are consistent across three online continual learning
algorithms. Our best system achieves a 14.95% relative increase in top-1
accuracy on class incremental ImageNet over the prior state of the art for
online continual learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Describing and Localizing Multiple Changes with Transformers. (arXiv:2103.14146v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14146">
<div class="article-summary-box-inner">
<span><p>Change captioning tasks aim to detect changes in image pairs observed before
and after a scene change and generate a natural language description of the
changes. Existing change captioning studies have mainly focused on a single
change.However, detecting and describing multiple changed parts in image pairs
is essential for enhancing adaptability to complex scenarios. We solve the
above issues from three aspects: (i) We propose a simulation-based multi-change
captioning dataset; (ii) We benchmark existing state-of-the-art methods of
single change captioning on multi-change captioning; (iii) We further propose
Multi-Change Captioning transformers (MCCFormers) that identify change regions
by densely correlating different regions in image pairs and dynamically
determines the related change regions with words in sentences. The proposed
method obtained the highest scores on four conventional change captioning
evaluation metrics for multi-change captioning. Additionally, our proposed
method can separate attention maps for each change and performs well with
respect to change localization. Moreover, the proposed framework outperformed
the previous state-of-the-art methods on an existing change captioning
benchmark, CLEVR-Change, by a large margin (+6.1 on BLEU-4 and +9.7 on CIDEr
scores), indicating its general ability in change captioning tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">D2C-SR: A Divergence to Convergence Approach for Real-World Image Super-Resolution. (arXiv:2103.14373v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14373">
<div class="article-summary-box-inner">
<span><p>In this paper, we present D2C-SR, a novel framework for the task of
real-world image super-resolution. As an ill-posed problem, the key challenge
in super-resolution related tasks is there can be multiple predictions for a
given low-resolution input. Most classical deep learning based approaches
ignored the fundamental fact and lack explicit modeling of the underlying
high-frequency distribution which leads to blurred results. Recently, some
methods of GAN-based or learning super-resolution space can generate simulated
textures but do not promise the accuracy of the textures which have low
quantitative performance. Rethinking both, we learn the distribution of
underlying high-frequency details in a discrete form and propose a two-stage
pipeline: divergence stage to convergence stage. At divergence stage, we
propose a tree-based structure deep network as our divergence backbone.
Divergence loss is proposed to encourage the generated results from the
tree-based network to diverge into possible high-frequency representations,
which is our way of discretely modeling the underlying high-frequency
distribution. At convergence stage, we assign spatial weights to fuse these
divergent predictions to obtain the final output with more accurate details.
Our approach provides a convenient end-to-end manner to inference. We conduct
evaluations on several real-world benchmarks, including a new proposed
D2CRealSR dataset with x8 scaling factor. Our experiments demonstrate that
D2C-SR achieves better accuracy and visual improvements against
state-of-the-art methods, with a significantly less parameters number.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VR3Dense: Voxel Representation Learning for 3D Object Detection and Monocular Dense Depth Reconstruction. (arXiv:2104.05932v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05932">
<div class="article-summary-box-inner">
<span><p>3D object detection and dense depth estimation are one of the most vital
tasks in autonomous driving. Multiple sensor modalities can jointly attribute
towards better robot perception, and to that end, we introduce a method for
jointly training 3D object detection and monocular dense depth reconstruction
neural networks. It takes as inputs, a LiDAR point-cloud, and a single RGB
image during inference and produces object pose predictions as well as a
densely reconstructed depth map. LiDAR point-cloud is converted into a set of
voxels, and its features are extracted using 3D convolution layers, from which
we regress object pose parameters. Corresponding RGB image features are
extracted using another 2D convolutional neural network. We further use these
combined features to predict a dense depth map. While our object detection is
trained in a supervised manner, the depth prediction network is trained with
both self-supervised and supervised loss functions. We also introduce a loss
function, edge-preserving smooth loss, and show that this results in better
depth estimation compared to the edge-aware smooth loss function, frequently
used in depth prediction works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental Multi-Target Domain Adaptation for Object Detection with Efficient Domain Transfer. (arXiv:2104.06476v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06476">
<div class="article-summary-box-inner">
<span><p>Recent advances in unsupervised domain adaptation have significantly improved
the recognition accuracy of CNNs by alleviating the domain shift between
(labeled) source and (unlabeled) target data distributions. While the problem
of single-target domain adaptation (STDA) for object detection has recently
received much attention, multi-target domain adaptation (MTDA) remains largely
unexplored, despite its practical relevance in several real-world applications,
such as multi-camera video surveillance. Compared to the STDA problem that may
involve large domain shifts between complex source and target distributions,
MTDA faces additional challenges, most notably the computational requirements
and catastrophic forgetting of previously-learned targets, which can depend on
the order of target adaptations. STDA for detection can be applied to MTDA by
adapting one model per target, or one common model with a mixture of data from
target domains. However, these approaches are either costly or inaccurate. The
only state-of-art MTDA method specialized for detection learns targets
incrementally, one target at a time, and mitigates the loss of knowledge by
using a duplicated detection model for knowledge distillation, which is
computationally expensive and does not scale well to many domains. In this
paper, we introduce an efficient approach for incremental learning that
generalizes well to multiple target domains. Our MTDA approach is more suitable
for real-world applications since it allows updating the detection model
incrementally, without storing data from previous-learned target domains, nor
retraining when a new target domain becomes available. Our proposed method,
MTDA-DTM, achieved the highest level of detection accuracy compared against
state-of-the-art approaches on several MTDA detection benchmarks and Wildtrack,
a benchmark for multi-camera pedestrian detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does language help generalization in vision models?. (arXiv:2104.08313v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08313">
<div class="article-summary-box-inner">
<span><p>Vision models trained on multimodal datasets can benefit from the wide
availability of large image-caption datasets. A recent model (CLIP) was found
to generalize well in zero-shot and transfer learning settings. This could
imply that linguistic or "semantic grounding" confers additional generalization
abilities to the visual feature space. Here, we systematically evaluate various
multimodal architectures and vision-only models in terms of unsupervised
clustering, few-shot learning, transfer learning and adversarial robustness. In
each setting, multimodal training produced no additional generalization
capability compared to standard supervised visual training. We conclude that
work is still required for semantic grounding to help improve vision models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLIPScore: A Reference-free Evaluation Metric for Image Captioning. (arXiv:2104.08718v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08718">
<div class="article-summary-box-inner">
<span><p>Image captioning has conventionally relied on reference-based automatic
evaluations, where machine captions are compared against captions written by
humans. This is in contrast to the reference-free manner in which humans assess
caption quality.
</p>
<p>In this paper, we report the surprising empirical finding that CLIP (Radford
et al., 2021), a cross-modal model pretrained on 400M image+caption pairs from
the web, can be used for robust automatic evaluation of image captioning
without the need for references. Experiments spanning several corpora
demonstrate that our new reference-free metric, CLIPScore, achieves the highest
correlation with human judgements, outperforming existing reference-based
metrics like CIDEr and SPICE. Information gain experiments demonstrate that
CLIPScore, with its tight focus on image-text compatibility, is complementary
to existing reference-based metrics that emphasize text-text similarities.
Thus, we also present a reference-augmented version, RefCLIPScore, which
achieves even higher correlation. Beyond literal description tasks, several
case studies reveal domains where CLIPScore performs well (clip-art images,
alt-text rating), but also where it is relatively weaker in comparison to
reference-based metrics, e.g., news captions that require richer contextual
knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VideoGPT: Video Generation using VQ-VAE and Transformers. (arXiv:2104.10157v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10157">
<div class="article-summary-box-inner">
<span><p>We present VideoGPT: a conceptually simple architecture for scaling
likelihood based generative modeling to natural videos. VideoGPT uses VQ-VAE
that learns downsampled discrete latent representations of a raw video by
employing 3D convolutions and axial self-attention. A simple GPT-like
architecture is then used to autoregressively model the discrete latents using
spatio-temporal position encodings. Despite the simplicity in formulation and
ease of training, our architecture is able to generate samples competitive with
state-of-the-art GAN models for video generation on the BAIR Robot dataset, and
generate high fidelity natural videos from UCF-101 and Tumbler GIF Dataset
(TGIF). We hope our proposed architecture serves as a reproducible reference
for a minimalistic implementation of transformer based video generation models.
Samples and code are available at
https://wilson1yan.github.io/videogpt/index.html
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Unified Stereo Stimuli based Binocular Eye-Tracking System for Accurate 3D Gaze Estimation. (arXiv:2104.12167v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12167">
<div class="article-summary-box-inner">
<span><p>In addition to the high cost and complex setup, the main reason for the
limitation of the three-dimensional (3D) display is the problem of accurately
estimating the user's current point-of-gaze (PoG) in a 3D space. In this paper,
we present a novel noncontact technique for the PoG estimation in a
stereoscopic environment, which integrates a 3D stereoscopic display system and
an eye-tracking system. The 3D stereoscopic display system can provide users
with a friendly and immersive high-definition viewing experience without
wearing any equipment. To accurately locate the user's 3D PoG in the field of
view, we build a regression-based 3D eye-tracking model with the eye movement
data and stereo stimulus videos as input. Besides, to train an optimal
regression model, we also design and annotate a dataset that contains 30 users'
eye-tracking data corresponding to two designed stereo test scenes.
Innovatively, this dataset introduces feature vectors between eye region
landmarks for the gaze vector estimation and a combined feature set for the
gaze depth estimation. Moreover, five traditional regression models are trained
and evaluated based on this dataset. Experimental results show that the average
errors of the 3D PoG are about 0.90~cm on the X-axis, 0.83~cm on the Y-axis,
and 1.48~cm$/$0.12~m along the Z-axis with the scene-depth range in
75~cm$/$8~m, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Improving Semantic Perception for Indoor Localisation. (arXiv:2105.01595v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01595">
<div class="article-summary-box-inner">
<span><p>We propose a novel robotic system that can improve its perception during
deployment. Contrary to the established approach of learning semantics from
large datasets and deploying fixed models, we propose a framework in which
semantic models are continuously updated on the robot to adapt to the
deployment environments. By combining continual learning with self-supervision,
our robotic system learns online during deployment without external
supervision. We conduct real-world experiments with robots localising in 3D
floorplans. Our experiments show how the robot's semantic perception improves
during deployment and how this translates into improved localisation, even
across drastically different environments. We further study the risk of
catastrophic forgetting that such a continuous learning setting poses. We find
memory replay an effective measure to reduce forgetting and show how the
robotic system can improve even when switching between different environments.
On average, our system improves by 60% in segmentation and 10% in localisation
accuracy compared to deployment of a fixed model, and it maintains this
improvement while adapting to further environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MOTR: End-to-End Multiple-Object Tracking with TRansformer. (arXiv:2105.03247v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03247">
<div class="article-summary-box-inner">
<span><p>The key challenge in multiple-object tracking task is temporal modeling of
the object under track. Existing tracking-by-detection methods adopt simple
heuristics, such as spatial or appearance similarity. Such methods, in spite of
their commonality, are overly simple and lack the ability to learn temporal
variations from data in an end-to-end manner. In this paper, we present MOTR, a
fully end-to-end multiple-object tracking framework. It learns to model the
long-range temporal variation of the objects. It performs temporal association
implicitly and avoids previous explicit heuristics. Built upon DETR, MOTR
introduces the concept of "track query". Each track query models the entire
track of an object. It is transferred and updated frame-by-frame to perform
iterative predictions in a seamless manner. Tracklet-aware label assignment is
proposed for one-to-one assignment between track queries and object tracks.
Temporal aggregation network together with collective average loss is further
proposed to enhance the long-range temporal relation. Experimental results show
that MOTR achieves competitive performance and can serve as a strong
Transformer-based baseline for future research. Code is available at
\url{https://github.com/megvii-model/MOTR}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SA-GAN: Structure-Aware GAN for Organ-Preserving Synthetic CT Generation. (arXiv:2105.07044v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07044">
<div class="article-summary-box-inner">
<span><p>In medical image synthesis, model training could be challenging due to the
inconsistencies between images of different modalities even with the same
patient, typically caused by internal status/tissue changes as different
modalities are usually obtained at a different time. This paper proposes a
novel deep learning method, Structure-aware Generative Adversarial Network
(SA-GAN), that preserves the shapes and locations of in-consistent structures
when generating medical images. SA-GAN is employed to generate synthetic
computed tomography (synCT) images from magnetic resonance imaging (MRI) with
two parallel streams: the global stream translates the input from the MRI to
the CT domain while the local stream automatically segments the inconsistent
organs, maintains their locations and shapes in MRI, and translates the organ
intensities to CT. Through extensive experiments on a pelvic dataset, we
demonstrate that SA-GAN provides clinically acceptable accuracy on both synCTs
and organ segmentation and supports MR-only treatment planning in disease sites
with internal organ status changes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Polarimetric Spatio-Temporal Light Transport Probing. (arXiv:2105.11609v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11609">
<div class="article-summary-box-inner">
<span><p>Light emitted from a source into a scene can undergo complex interactions
with scene surfaces of different material types before being reflected. During
this transport, every surface reflection is encoded in the properties of the
photons that reach the detector, including time, direction, intensity,
wavelength and polarization. Conventional imaging systems capture intensity by
integrating over all other dimensions of the light, hiding this rich scene
information. Existing methods are capable of untangling these measurements into
their spatial and temporal dimensions, fueling geometric scene understanding
tasks. However, examining material properties jointly with geometric properties
is an open challenge that could enable unprecedented capabilities beyond
geometric scene understanding, allowing for material-dependent scene
understanding and imaging through complex transport. In this work, we close
this gap, and propose a computational light transport imaging method that
captures the spatially- and temporally-resolved complete polarimetric response
of a scene. Our method hinges on a 7D tensor theory of light transport. We
discover low-rank structure in the polarimetric tensor dimension and propose a
data-driven rotating ellipsometry method that learns to exploit redundancy of
polarimetric structure. We instantiate our theory with two prototypes:
spatio-polarimetric imaging and coaxial temporal-polarimetric imaging. This
allows us, for the first time, to decompose scene light transport into
temporal, spatial, and complete polarimetric dimensions that unveil scene
properties hidden to conventional methods. We validate the applicability of our
method on diverse tasks, including shape reconstruction with subsurface
scattering, seeing through scattering media, untangling multi-bounce light
transport, breaking metamerism, and decomposition of crystals.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Stylize Novel Views. (arXiv:2105.13509v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13509">
<div class="article-summary-box-inner">
<span><p>We tackle a 3D scene stylization problem - generating stylized images of a
scene from arbitrary novel views given a set of images of the same scene and a
reference image of the desired style as inputs. Direct solution of combining
novel view synthesis and stylization approaches lead to results that are blurry
or not consistent across different views. We propose a point cloud-based method
for consistent 3D scene stylization. First, we construct the point cloud by
back-projecting the image features to the 3D space. Second, we develop point
cloud aggregation modules to gather the style information of the 3D scene, and
then modulate the features in the point cloud with a linear transformation
matrix. Finally, we project the transformed features to 2D space to obtain the
novel views. Experimental results on two diverse datasets of real-world scenes
validate that our method generates consistent stylized novel view synthesis
results against other alternative approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">New Encoder Learning for Captioning Heavy Rain Images via Semantic Visual Feature Matching. (arXiv:2105.13753v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13753">
<div class="article-summary-box-inner">
<span><p>Image captioning generates text that describes scenes from input images. It
has been developed for high quality images taken in clear weather. However, in
bad weather conditions, such as heavy rain, snow, and dense fog, the poor
visibility owing to rain streaks, rain accumulation, and snowflakes causes a
serious degradation of image quality. This hinders the extraction of useful
visual features and results in deteriorated image captioning performance. To
address practical issues, this study introduces a new encoder for captioning
heavy rain images. The central idea is to transform output features extracted
from heavy rain input images into semantic visual features associated with
words and sentence context. To achieve this, a target encoder is initially
trained in an encoder-decoder framework to associate visual features with
semantic words. Subsequently, the objects in a heavy rain image are rendered
visible by using an initial reconstruction subnetwork (IRS) based on a heavy
rain model. The IRS is then combined with another semantic visual feature
matching subnetwork (SVFMS) to match the output features of the IRS with the
semantic visual features of the pretrained target encoder. The proposed encoder
is based on the joint learning of the IRS and SVFMS. It is is trained in an
end-to-end manner, and then connected to the pretrained decoder for image
captioning. It is experimentally demonstrated that the proposed encoder can
generate semantic visual features associated with words even from heavy rain
images, thereby increasing the accuracy of the generated captions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepChange: A Long-Term Person Re-Identification Benchmark. (arXiv:2105.14685v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14685">
<div class="article-summary-box-inner">
<span><p>Existing person re-identification (Re-ID) works mostly consider a short-term
search problem assuming unchanged clothes and personal appearance. However, in
real-world we often dress differently across locations, time, dates, seasons,
weather, and events. As a result, the existing methods are unsuitable for
long-term person Re-ID with clothes change involved. Whilst there are several
recent long-term Re-ID attempts, a large realistic dataset with clothes change
is lacking and indispensable for enabling extensive study as already
experienced in short-term Re-ID setting. In this work, we contribute a large,
realistic long-term person identification benchmark. It consists of 178K
bounding boxes from 1.1K person identities, collected and constructed over 12
months. Unique characteristics of this dataset include: (1) Natural/native
personal appearance (e.g., clothes and hair style) variations: The
clothes-change and dressing styles all are highly diverse, with the reappearing
gap in time ranging from minutes, hours, and days to weeks, months, seasons,
and years. (2) Diverse walks of life: Persons across a wide range of ages and
professions appear in different weather conditions (e.g., sunny, cloudy, windy,
rainy, snowy, extremely cold) and events (e.g., working, leisure, daily
activities). (3) Rich camera setups: The raw videos were recorded by 17 outdoor
security cameras with various resolutions operating in a real-world
surveillance system for a wide and dense block. (4) Largest scale: It covers
the largest number of (17) cameras, (1, 121) identities, and (178, 407)
bounding boxes, as compared to alternative datasets. Our dataset and benchmark
codes are available on https://github.com/PengBoXiangShang/deepchange.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Speaker Detection as a Multi-Objective Optimization with Uncertainty-based Multimodal Fusion. (arXiv:2106.03821v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03821">
<div class="article-summary-box-inner">
<span><p>It is now well established from a variety of studies that there is a
significant benefit from combining video and audio data in detecting active
speakers. However, either of the modalities can potentially mislead audiovisual
fusion by inducing unreliable or deceptive information. This paper outlines
active speaker detection as a multi-objective learning problem to leverage best
of each modalities using a novel self-attention, uncertainty-based multimodal
fusion scheme. Results obtained show that the proposed multi-objective learning
architecture outperforms traditional approaches in improving both mAP and AUC
scores. We further demonstrate that our fusion strategy surpasses, in active
speaker detection, other modality fusion methods reported in various
disciplines. We finally show that the proposed method significantly improves
the state-of-the-art on the AVA-ActiveSpeaker dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Harnessing Unrecognizable Faces for Improving Face Recognition. (arXiv:2106.04112v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04112">
<div class="article-summary-box-inner">
<span><p>The common implementation of face recognition systems as a cascade of a
detection stage and a recognition or verification stage can cause problems
beyond failures of the detector. When the detector succeeds, it can detect
faces that cannot be recognized, no matter how capable the recognition system.
Recognizability, a latent variable, should therefore be factored into the
design and implementation of face recognition systems. We propose a measure of
recognizability of a face image that leverages a key empirical observation: an
embedding of face images, implemented by a deep neural network trained using
mostly recognizable identities, induces a partition of the hypersphere whereby
unrecognizable identities cluster together. This occurs regardless of the
phenomenon that causes a face to be unrecognizable, it be optical or motion
blur, partial occlusion, spatial quantization, poor illumination. Therefore, we
use the distance from such an "unrecognizable identity" as a measure of
recognizability, and incorporate it in the design of the over-all system. We
show that accounting for recognizability reduces error rate of single-image
face recognition by 58% at FAR=1e-5 on the IJB-C Covariate Verification
benchmark, and reduces verification error rate by 24% at FAR=1e-5 in set-based
recognition on the IJB-C benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoAtNet: Marrying Convolution and Attention for All Data Sizes. (arXiv:2106.04803v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04803">
<div class="article-summary-box-inner">
<span><p>Transformers have attracted increasing interests in computer vision, but they
still fall behind state-of-the-art convolutional networks. In this work, we
show that while Transformers tend to have larger model capacity, their
generalization can be worse than convolutional networks due to the lack of the
right inductive bias. To effectively combine the strengths from both
architectures, we present CoAtNets(pronounced "coat" nets), a family of hybrid
models built from two key insights: (1) depthwise Convolution and
self-Attention can be naturally unified via simple relative attention; (2)
vertically stacking convolution layers and attention layers in a principled way
is surprisingly effective in improving generalization, capacity and efficiency.
Experiments show that our CoAtNets achieve state-of-the-art performance under
different resource constraints across various datasets: Without extra data,
CoAtNet achieves 86.0% ImageNet top-1 accuracy; When pre-trained with 13M
images from ImageNet-21K, our CoAtNet achieves 88.56% top-1 accuracy, matching
ViT-huge pre-trained with 300M images from JFT-300M while using 23x less data;
Notably, when we further scale up CoAtNet with JFT-3B, it achieves 90.88% top-1
accuracy on ImageNet, establishing a new state-of-the-art result.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CUDA-GHR: Controllable Unsupervised Domain Adaptation for Gaze and Head Redirection. (arXiv:2106.10852v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10852">
<div class="article-summary-box-inner">
<span><p>The robustness of gaze and head pose estimation models is highly dependent on
the amount of labeled data. Recently, generative modeling has shown excellent
results in generating photo-realistic images, which can alleviate the need for
labeled data. However, adopting such generative models to new domains while
maintaining their ability to provide fine-grained control over different image
attributes, e.g., gaze and head pose directions, has been a challenging
problem. This paper proposes CUDA-GHR, an unsupervised domain adaptation
framework that enables fine-grained control over gaze and head pose directions
while preserving the appearance-related factors of the person. Our framework
simultaneously learns to adapt to new domains and disentangle image attributes
such as appearance, gaze direction, and head orientation by utilizing a
label-rich source domain and an unlabeled target domain. Extensive experiments
on the benchmarking datasets show that the proposed method can outperform
state-of-the-art techniques on both quantitative and qualitative evaluations.
Furthermore, we show that the generated image-label pairs in the target domain
effectively transfer knowledge and boost the downstream tasks' performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RATCHET: Medical Transformer for Chest X-ray Diagnosis and Reporting. (arXiv:2107.02104v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02104">
<div class="article-summary-box-inner">
<span><p>Chest radiographs are one of the most common diagnostic modalities in
clinical routine. It can be done cheaply, requires minimal equipment, and the
image can be diagnosed by every radiologists. However, the number of chest
radiographs obtained on a daily basis can easily overwhelm the available
clinical capacities. We propose RATCHET: RAdiological Text Captioning for Human
Examined Thoraces. RATCHET is a CNN-RNN-based medical transformer that is
trained end-to-end. It is capable of extracting image features from chest
radiographs, and generates medically accurate text reports that fit seamlessly
into clinical work flows. The model is evaluated for its natural language
generation ability using common metrics from NLP literature, as well as its
medically accuracy through a surrogate report classification task. The model is
available for download at: <a href="http://www.github.com/farrell236/RATCHET.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning based Micro-expression Recognition: A Survey. (arXiv:2107.02823v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02823">
<div class="article-summary-box-inner">
<span><p>Micro-expressions (MEs) are involuntary facial movements revealing people's
hidden feelings in high-stake situations and have practical importance in
medical treatment, national security, interrogations and many human-computer
interaction systems. Early methods for MER mainly based on traditional
appearance and geometry features. Recently, with the success of deep learning
(DL) in various fields, neural networks have received increasing interests in
MER. Different from macro-expressions, MEs are spontaneous, subtle, and rapid
facial movements, leading to difficult data collection, thus have small-scale
datasets. DL based MER becomes challenging due to above ME characters. To date,
various DL approaches have been proposed to solve the ME issues and improve MER
performance. In this survey, we provide a comprehensive review of deep
micro-expression recognition (MER), including datasets, deep MER pipeline, and
the bench-marking of most influential methods. This survey defines a new
taxonomy for the field, encompassing all aspects of MER based on DL. For each
aspect, the basic approaches and advanced developments are summarized and
discussed. In addition, we conclude the remaining challenges and and potential
directions for the design of robust deep MER systems. To the best of our
knowledge, this is the first survey of deep MER methods, and this survey can
serve as a reference point for future MER research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teaching Agents how to Map: Spatial Reasoning for Multi-Object Navigation. (arXiv:2107.06011v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06011">
<div class="article-summary-box-inner">
<span><p>In the context of visual navigation, the capacity to map a novel environment
is necessary for an agent to exploit its observation history in the considered
place and efficiently reach known goals. This ability can be associated with
spatial reasoning, where an agent is able to perceive spatial relationships and
regularities, and discover object characteristics. In classical Reinforcement
Learning (RL) setups, this capacity is learned from reward alone. We introduce
supplementary supervision in the form of auxiliary tasks designed to favor the
emergence of spatial perception capabilities in agents trained for a
goal-reaching downstream objective. We show that learning to estimate metrics
quantifying the spatial relationships between an agent at a given location and
a goal to reach has a high positive impact in Multi-Object Navigation settings.
Our method significantly improves the performance of different baseline agents,
that either build an explicit or implicit representation of the environment,
even matching the performance of incomparable oracle agents taking ground-truth
maps as input.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CalCROP21: A Georeferenced multi-spectral dataset of Satellite Imagery and Crop Labels. (arXiv:2107.12499v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12499">
<div class="article-summary-box-inner">
<span><p>Mapping and monitoring crops is a key step towards sustainable
intensification of agriculture and addressing global food security. A dataset
like ImageNet that revolutionized computer vision applications can accelerate
development of novel crop mapping techniques. Currently, the United States
Department of Agriculture (USDA) annually releases the Cropland Data Layer
(CDL) which contains crop labels at 30m resolution for the entire United States
of America. While CDL is state of the art and is widely used for a number of
agricultural applications, it has a number of limitations (e.g., pixelated
errors, labels carried over from previous errors and absence of input imagery
along with class labels). In this work, we create a new semantic segmentation
benchmark dataset, which we call CalCROP21, for the diverse crops in the
Central Valley region of California at 10m spatial resolution using a Google
Earth Engine based robust image processing pipeline and a novel attention based
spatio-temporal semantic segmentation algorithm STATT. STATT uses re-sampled
(interpolated) CDL labels for training, but is able to generate a better
prediction than CDL by leveraging spatial and temporal patterns in Sentinel2
multi-spectral image series to effectively capture phenologic differences
amongst crops and uses attention to reduce the impact of clouds and other
atmospheric disturbances. We also present a comprehensive evaluation to show
that STATT has significantly better results when compared to the resampled CDL
labels. We have released the dataset and the processing pipeline code for
generating the benchmark dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Grounding with 3D Objects. (arXiv:2107.12514v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12514">
<div class="article-summary-box-inner">
<span><p>Seemingly simple natural language requests to a robot are generally
underspecified, for example "Can you bring me the wireless mouse?" Flat images
of candidate mice may not provide the discriminative information needed for
"wireless." The world, and objects in it, are not flat images but complex 3D
shapes. If a human requests an object based on any of its basic properties,
such as color, shape, or texture, robots should perform the necessary
exploration to accomplish the task. In particular, while substantial effort and
progress has been made on understanding explicitly visual attributes like color
and category, comparatively little progress has been made on understanding
language about shapes and contours. In this work, we introduce a novel
reasoning task that targets both visual and non-visual language about 3D
objects. Our new benchmark, ShapeNet Annotated with Referring Expressions
(SNARE) requires a model to choose which of two objects is being referenced by
a natural language description. We introduce several CLIP-based models for
distinguishing objects and demonstrate that while recent advances in jointly
modeling vision and language are useful for robotic language understanding, it
is still the case that these image-based models are weaker at understanding the
3D nature of objects -- properties which play a key role in manipulation. We
find that adding view estimation to language grounding models improves accuracy
on both SNARE and when identifying objects referred to in language on a robot
platform, but note that a large gap remains between these models and human
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Free Lunch for Co-Saliency Detection: Context Adjustment. (arXiv:2108.02093v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02093">
<div class="article-summary-box-inner">
<span><p>We unveil a long-standing problem in the prevailing co-saliency detection
systems: there is indeed inconsistency between training and testing.
Constructing a high-quality co-saliency detection dataset involves
time-consuming and labor-intensive pixel-level labeling, which has forced most
recent works to rely instead on semantic segmentation or saliency detection
datasets for training. However, the lack of proper co-saliency and the absence
of multiple foreground objects in these datasets can lead to spurious
variations and inherent biases learned by models. To tackle this, we introduce
the idea of counterfactual training through context adjustment and propose a
"cost-free" group-cut-paste (GCP) procedure to leverage off-the-shelf images
and synthesize new samples. Following GCP, we collect a novel dataset called
Context Adjustment Training (CAT). CAT consists of 33,500 images, which is four
times larger than the current co-saliency detection datasets. All samples are
automatically annotated with high-quality mask annotations, object categories,
and edge maps. Extensive experiments on recent benchmarks are conducted, show
that CAT can improve various state-of-the-art models by a large margin (5% ~
25%). We hope that the scale, diversity, and quality of our dataset can benefit
researchers in this area and beyond. Our dataset will be publicly accessible
through our project page.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models. (arXiv:2108.02938v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02938">
<div class="article-summary-box-inner">
<span><p>Denoising diffusion probabilistic models (DDPM) have shown remarkable
performance in unconditional image generation. However, due to the
stochasticity of the generative process in DDPM, it is challenging to generate
images with the desired semantics. In this work, we propose Iterative Latent
Variable Refinement (ILVR), a method to guide the generative process in DDPM to
generate high-quality images based on a given reference image. Here, the
refinement of the generative process in DDPM enables a single DDPM to sample
images from various sets directed by the reference image. The proposed ILVR
method generates high-quality images while controlling the generation. The
controllability of our method allows adaptation of a single DDPM without any
additional learning in various image generation tasks, such as generation from
various downsampling factors, multi-domain image translation, paint-to-image,
and editing with scribbles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instance-weighted Central Similarity for Multi-label Image Retrieval. (arXiv:2108.05274v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05274">
<div class="article-summary-box-inner">
<span><p>Deep hashing has been widely applied to large-scale image retrieval by
encoding high-dimensional data points into binary codes for efficient
retrieval. Compared with pairwise/triplet similarity based hash learning,
central similarity based hashing can more efficiently capture the global data
distribution. For multi-label image retrieval, however, previous methods only
use multiple hash centers with equal weights to generate one centroid as the
learning target, which ignores the relationship between the weights of hash
centers and the proportion of instance regions in the image. To address the
above issue, we propose a two-step alternative optimization approach,
Instance-weighted Central Similarity (ICS), to automatically learn the center
weight corresponding to a hash code. Firstly, we apply the maximum entropy
regularizer to prevent one hash center from dominating the loss function, and
compute the center weights via projection gradient descent. Secondly, we update
neural network parameters by standard back-propagation with fixed center
weights. More importantly, the learned center weights can well reflect the
proportion of foreground instances in the image. Our method achieves the
state-of-the-art performance on the image retrieval benchmarks, and especially
improves the mAP by 1.6%-6.4% on the MS COCO dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Target Adversarial Frameworks for Domain Adaptation in Semantic Segmentation. (arXiv:2108.06962v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06962">
<div class="article-summary-box-inner">
<span><p>In this work, we address the task of unsupervised domain adaptation (UDA) for
semantic segmentation in presence of multiple target domains: The objective is
to train a single model that can handle all these domains at test time. Such a
multi-target adaptation is crucial for a variety of scenarios that real-world
autonomous systems must handle. It is a challenging setup since one faces not
only the domain gap between the labeled source set and the unlabeled target
set, but also the distribution shifts existing within the latter among the
different target domains. To this end, we introduce two adversarial frameworks:
(i) multi-discriminator, which explicitly aligns each target domain to its
counterparts, and (ii) multi-target knowledge transfer, which learns a
target-agnostic model thanks to a multi-teacher/single-student distillation
mechanism.The evaluation is done on four newly-proposed multi-target benchmarks
for UDA in semantic segmentation. In all tested scenarios, our approaches
consistently outperform baselines, setting competitive standards for the novel
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LOKI: Long Term and Key Intentions for Trajectory Prediction. (arXiv:2108.08236v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08236">
<div class="article-summary-box-inner">
<span><p>Recent advances in trajectory prediction have shown that explicit reasoning
about agents' intent is important to accurately forecast their motion. However,
the current research activities are not directly applicable to intelligent and
safety critical systems. This is mainly because very few public datasets are
available, and they only consider pedestrian-specific intents for a short
temporal horizon from a restricted egocentric view. To this end, we propose
LOKI (LOng term and Key Intentions), a novel large-scale dataset that is
designed to tackle joint trajectory and intention prediction for heterogeneous
traffic agents (pedestrians and vehicles) in an autonomous driving setting. The
LOKI dataset is created to discover several factors that may affect intention,
including i) agent's own will, ii) social interactions, iii) environmental
constraints, and iv) contextual information. We also propose a model that
jointly performs trajectory and intention prediction, showing that recurrently
reasoning about intention can assist with trajectory prediction. We show our
method outperforms state-of-the-art trajectory prediction methods by upto
$27\%$ and also provide a baseline for frame-wise intention estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CenterPoly: real-time instance segmentation using bounding polygons. (arXiv:2108.08923v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08923">
<div class="article-summary-box-inner">
<span><p>We present a novel method, called CenterPoly, for real-time instance
segmentation using bounding polygons. We apply it to detect road users in dense
urban environments, making it suitable for applications in intelligent
transportation systems like automated vehicles. CenterPoly detects objects by
their center keypoint while predicting a fixed number of polygon vertices for
each object, thus performing detection and segmentation in parallel. Most of
the network parameters are shared by the network heads, making it fast and
lightweight enough to run at real-time speed. To properly convert mask
ground-truth to polygon ground-truth, we designed a vertex selection strategy
to facilitate the learning of the polygons. Additionally, to better segment
overlapping objects in dense urban scenes, we also train a relative depth
branch to determine which instances are closer and which are further, using
available weak annotations. We propose several models with different backbones
to show the possible speed / accuracy trade-offs. The models were trained and
evaluated on Cityscapes, KITTI and IDD and the results are reported on their
public benchmark, which are state-of-the-art at real-time speeds. Code is
available at https://github.com/hu64/CenterPoly
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving 3D Object Detection with Channel-wise Transformer. (arXiv:2108.10723v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10723">
<div class="article-summary-box-inner">
<span><p>Though 3D object detection from point clouds has achieved rapid progress in
recent years, the lack of flexible and high-performance proposal refinement
remains a great hurdle for existing state-of-the-art two-stage detectors.
Previous works on refining 3D proposals have relied on human-designed
components such as keypoints sampling, set abstraction and multi-scale feature
fusion to produce powerful 3D object representations. Such methods, however,
have limited ability to capture rich contextual dependencies among points. In
this paper, we leverage the high-quality region proposal network and a
Channel-wise Transformer architecture to constitute our two-stage 3D object
detection framework (CT3D) with minimal hand-crafted design. The proposed CT3D
simultaneously performs proposal-aware embedding and channel-wise context
aggregation for the point features within each proposal. Specifically, CT3D
uses proposal's keypoints for spatial contextual modelling and learns attention
propagation in the encoding module, mapping the proposal to point embeddings.
Next, a new channel-wise decoding module enriches the query-key interaction via
channel-wise re-weighting to effectively merge multi-level contexts, which
contributes to more accurate object predictions. Extensive experiments
demonstrate that our CT3D method has superior performance and excellent
scalability. Remarkably, CT3D achieves the AP of 81.77% in the moderate car
category on the KITTI test 3D detection benchmark, outperforms state-of-the-art
3D detectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Tutorial on Learning Disentangled Representations in the Imaging Domain. (arXiv:2108.12043v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12043">
<div class="article-summary-box-inner">
<span><p>Disentangled representation learning has been proposed as an approach to
learning general representations. This can be done in the absence of, or with
limited, annotations. A good general representation can be readily fine-tuned
for new target tasks using modest amounts of data, or even be used directly in
unseen domains achieving remarkable performance in the corresponding task. This
alleviation of the data and annotation requirements offers tantalising
prospects for tractable and affordable applications in computer vision and
healthcare. Finally, disentangled representations can offer model
explainability and can help us understand the underlying causal relations of
the factors of variation, increasing their suitability for real-world
deployment. In this tutorial paper, we will offer an overview of the
disentangled representation learning, its building blocks and criteria, and
discuss applications in computer vision and medical imaging. We conclude our
tutorial by presenting the identified opportunities for the integration of
recent machine learning advances into disentanglement, as well as the remaining
challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YouRefIt: Embodied Reference Understanding with Language and Gesture. (arXiv:2109.03413v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03413">
<div class="article-summary-box-inner">
<span><p>We study the understanding of embodied reference: One agent uses both
language and gesture to refer to an object to another agent in a shared
physical environment. Of note, this new visual task requires understanding
multimodal cues with perspective-taking to identify which object is being
referred to. To tackle this problem, we introduce YouRefIt, a new crowd-sourced
dataset of embodied reference collected in various physical scenes; the dataset
contains 4,195 unique reference clips in 432 indoor scenes. To the best of our
knowledge, this is the first embodied reference dataset that allows us to study
referring expressions in daily physical scenes to understand referential
behavior, human communication, and human-robot interaction. We further devise
two benchmarks for image-based and video-based embodied reference
understanding. Comprehensive baselines and extensive experiments provide the
very first result of machine perception on how the referring expressions and
gestures affect the embodied reference understanding. Our results provide
essential evidence that gestural cues are as critical as language cues in
understanding the embodied reference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RobustART: Benchmarking Robustness on Architecture Design and Training Techniques. (arXiv:2109.05211v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05211">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) are vulnerable to adversarial noises, which
motivates the benchmark of model robustness. Existing benchmarks mainly focus
on evaluating the defenses, but there are no comprehensive studies of how
architecture design and general training techniques affect robustness.
Comprehensively benchmarking their relationships will be highly beneficial for
better understanding and developing robust DNNs. Thus, we propose RobustART,
the first comprehensive Robustness investigation benchmark on ImageNet
(including open-source toolkit, pre-trained model zoo, datasets, and analyses)
regarding ARchitecture design (44 human-designed off-the-shelf architectures
and 1200+ networks from neural architecture search) and Training techniques
(10+ general techniques, e.g., data augmentation) towards diverse noises
(adversarial, natural, and system noises). Extensive experiments revealed and
substantiated several insights for the first time, for example: (1) adversarial
training largely improves the clean accuracy and all types of robustness for
Transformers and MLP-Mixers; (2) with comparable sizes, CNNs &gt; Transformers &gt;
MLP-Mixers on robustness against natural and system noises; Transformers &gt;
MLP-Mixers &gt; CNNs on adversarial robustness; (3) for some light-weight
architectures (e.g., EfficientNet, MobileNetV2, and MobileNetV3), increasing
model sizes or using extra training data cannot improve robustness. Our
benchmark <a href="http://robust.art/">this http URL</a> : (1) presents an open-source platform for
conducting comprehensive evaluation on diverse robustness types; (2) provides a
variety of pre-trained models with different training techniques to facilitate
robustness evaluation; (3) proposes a new view to better understand the
mechanism towards designing robust DNN architectures, backed up by the
analysis. We will continuously contribute to building this ecosystem for the
community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MLFW: A Database for Face Recognition on Masked Faces. (arXiv:2109.05804v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05804">
<div class="article-summary-box-inner">
<span><p>As more and more people begin to wear masks due to current COVID-19 pandemic,
existing face recognition systems may encounter severe performance degradation
when recognizing masked faces. To figure out the impact of masks on face
recognition model, we build a simple but effective tool to generate masked
faces from unmasked faces automatically, and construct a new database called
Masked LFW (MLFW) based on Cross-Age LFW (CALFW) database. The mask on the
masked face generated by our method has good visual consistency with the
original face. Moreover, we collect various mask templates, covering most of
the common styles appeared in the daily life, to achieve diverse generation
effects. Considering realistic scenarios, we design three kinds of combinations
of face pairs. The recognition accuracy of SOTA models declines 5%-16% on MLFW
database compared with the accuracy on the original images. MLFW database can
be viewed and downloaded at \url{<a href="http://whdeng.cn/mlfw">this http URL</a>}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Few-shot Segmentation by Redefinition of the Roles of Multi-level CNN Features. (arXiv:2109.06432v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06432">
<div class="article-summary-box-inner">
<span><p>This study is concerned with few-shot segmentation, i.e., segmenting the
region of an unseen object class in a query image, given support image(s) of
its instances. The current methods rely on the pretrained CNN features of the
support and query images. The key to good performance depends on the proper
fusion of their mid-level and high-level features; the former contains
shape-oriented information, while the latter has class-oriented information.
Current state-of-the-art methods follow the approach of Tian et al., which
gives the mid-level features the primary role and the high-level features the
secondary role. In this paper, we reinterpret this widely employed approach by
redifining the roles of the multi-level features; we swap the primary and
secondary roles. Specifically, we regard that the current methods improve the
initial estimate generated from the high-level features using the mid-level
features. This reinterpretation suggests a new application of the current
methods: to apply the same network multiple times to iteratively update the
estimate of the object's region, starting from its initial estimate. Our
experiments show that this method is effective and has updated the previous
state-of-the-art on COCO-20$^i$ in the 1-shot and 5-shot settings and on
PASCAL-5$^i$ in the 1-shot setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-Fidelity GAN Inversion for Image Attribute Editing. (arXiv:2109.06590v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06590">
<div class="article-summary-box-inner">
<span><p>We present a novel high-fidelity generative adversarial network (GAN)
inversion framework that enables attribute editing with image-specific details
well-preserved (e.g., background, appearance and illumination). We first
formulate GAN inversion as a lossy data compression problem and carefully
discuss the Rate-Distortion-Edit trade-off. Due to this trade-off, previous
works fail to achieve high-fidelity reconstruction while keeping compelling
editing ability with a low bit-rate latent code only. In this work, we propose
a distortion consultation approach that employs the distortion map as a
reference for reconstruction. In the distortion consultation inversion (DCI),
the distortion map is first projected to a high-rate latent map, which then
complements the basic low-rate latent code with (lost) details via consultation
fusion. To achieve high-fidelity editing, we propose an adaptive distortion
alignment (ADA) module with a self-supervised training scheme. Extensive
experiments in the face and car domains show a clear improvement in terms of
both inversion and editing quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sampling Network Guided Cross-Entropy Method for Unsupervised Point Cloud Registration. (arXiv:2109.06619v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06619">
<div class="article-summary-box-inner">
<span><p>In this paper, by modeling the point cloud registration task as a Markov
decision process, we propose an end-to-end deep model embedded with the
cross-entropy method (CEM) for unsupervised 3D registration. Our model consists
of a sampling network module and a differentiable CEM module. In our sampling
network module, given a pair of point clouds, the sampling network learns a
prior sampling distribution over the transformation space. The learned sampling
distribution can be used as a "good" initialization of the differentiable CEM
module. In our differentiable CEM module, we first propose a maximum consensus
criterion based alignment metric as the reward function for the point cloud
registration task. Based on the reward function, for each state, we then
construct a fused score function to evaluate the sampled transformations, where
we weight the current and future rewards of the transformations. Particularly,
the future rewards of the sampled transforms are obtained by performing the
iterative closest point (ICP) algorithm on the transformed state. By selecting
the top-k transformations with the highest scores, we iteratively update the
sampling distribution. Furthermore, in order to make the CEM differentiable, we
use the sparsemax function to replace the hard top-$k$ selection. Finally, we
formulate a Geman-McClure estimator based loss to train our end-to-end
registration model. Extensive experimental results demonstrate the good
registration performance of our method on benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learnable Discrete Wavelet Pooling (LDW-Pooling) For Convolutional Networks. (arXiv:2109.06638v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06638">
<div class="article-summary-box-inner">
<span><p>Pooling is a simple but essential layer in modern deep CNN architectures for
feature aggregation and extraction. Typical CNN design focuses on the conv
layers and activation functions, while leaving the pooling layers with fewer
options. We introduce the Learning Discrete Wavelet Pooling (LDW-Pooling) that
can be applied universally to replace standard pooling operations to better
extract features with improved accuracy and efficiency. Motivated from the
wavelet theory, we adopt the low-pass (L) and high-pass (H) filters
horizontally and vertically for pooling on a 2D feature map. Feature signals
are decomposed into four (LL, LH, HL, HH) subbands to retain features better
and avoid information dropping. The wavelet transform ensures features after
pooling can be fully preserved and recovered. We next adopt an energy-based
attention learning to fine-select crucial and representative features.
LDW-Pooling is effective and efficient when compared with other
state-of-the-art pooling techniques such as WaveletPooling and LiftPooling.
Extensive experimental validation shows that LDW-Pooling can be applied to a
wide range of standard CNN architectures and consistently outperform standard
(max, mean, mixed, and stochastic) pooling operations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying partial mouse brain microscopy images from Allen reference atlas using a contrastively learned semantic space. (arXiv:2109.06662v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06662">
<div class="article-summary-box-inner">
<span><p>Precise identification of mouse brain microscopy images is a crucial first
step when anatomical structures in the mouse brain are to be registered to a
reference atlas. Practitioners usually rely on manual comparison of images or
tools that assume the presence of complete images. This work explores Siamese
Networks as the method for finding corresponding 2D reference atlas plates for
given partial 2D mouse brain images. Siamese networks are a class of
convolutional neural networks (CNNs) that use weight-shared paths to obtain low
dimensional embeddings of pairs of input images. The correspondence between the
partial mouse brain image and reference atlas plate is determined based on the
distance between low dimensional embeddings of brain slices and atlas plates
that are obtained from Siamese networks using contrastive learning. Experiments
showed that Siamese CNNs can precisely identify brain slices using the Allen
mouse brain atlas when training and testing images come from the same source.
They achieved TOP-1 and TOP-5 accuracy of 25% and 100%, respectively, taking
only 7.2 seconds to identify 29 images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MotionHint: Self-Supervised Monocular Visual Odometry with Motion Constraints. (arXiv:2109.06768v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06768">
<div class="article-summary-box-inner">
<span><p>We present a novel self-supervised algorithm named MotionHint for monocular
visual odometry (VO) that takes motion constraints into account. A key aspect
of our approach is to use an appropriate motion model that can help existing
self-supervised monocular VO (SSM-VO) algorithms to overcome issues related to
the local minima within their self-supervised loss functions. The motion model
is expressed with a neural network named PPnet. It is trained to coarsely
predict the next pose of the camera and the uncertainty of this prediction. Our
self-supervised approach combines the original loss and the motion loss, which
is the weighted difference between the prediction and the generated ego-motion.
Taking two existing SSM-VO systems as our baseline, we evaluate our MotionHint
algorithm on the standard KITTI benchmark. Experimental results show that our
MotionHint algorithm can be easily applied to existing open-sourced
state-of-the-art SSM-VO systems to greatly improve the performance by reducing
the resulting ATE by up to 28.73%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Domain Adaptive Learning via Synthetic Data for Person Re-identification. (arXiv:2109.05542v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05542">
<div class="article-summary-box-inner">
<span><p>Person re-identification (re-ID) has gained more and more attention due to
its widespread applications in intelligent video surveillance. Unfortunately,
the mainstream deep learning methods still need a large quantity of labeled
data to train models, and annotating data is an expensive work in real-world
scenarios. In addition, due to domain gaps between different datasets, the
performance is dramatically decreased when re-ID models pre-trained on
label-rich datasets (source domain) are directly applied to other unlabeled
datasets (target domain). In this paper, we attempt to remedy these problems
from two aspects, namely data and methodology. Firstly, we develop a data
collector to automatically generate synthetic re-ID samples in a computer game,
and construct a data labeler to simultaneously annotate them, which free humans
from heavy data collections and annotations. Based on them, we build two
synthetic person re-ID datasets with different scales, "GSPR" and "mini-GSPR"
datasets. Secondly, we propose a synthesis-based multi-domain collaborative
refinement (SMCR) network, which contains a synthetic pretraining module and
two collaborative-refinement modules to implement sufficient learning for the
valuable knowledge from multiple domains. Extensive experiments show that our
proposed framework obtains significant performance improvements over the
state-of-the-art methods on multiple unsupervised domain adaptation tasks of
person re-ID.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-16 23:02:23.692316857 UTC">2021-09-16 23:02:23 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>