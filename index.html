<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-02-04T01:30:00Z">02-04</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">A Flexible Clustering Pipeline for Mining Text Intentions. (arXiv:2202.01211v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01211">
<div class="article-summary-box-inner">
<span><p>Mining the latent intentions from large volumes of natural language inputs is
a key step to help data analysts design and refine Intelligent Virtual
Assistants (IVAs) for customer service and sales support. We created a flexible
and scalable clustering pipeline within the Verint Intent Manager (VIM) that
integrates the fine-tuning of language models, a high performing k-NN library
and community detection techniques to help analysts quickly surface and
organize relevant user intentions from conversational texts. The fine-tuning
step is necessary because pre-trained language models cannot encode texts to
efficiently surface particular clustering structures when the target texts are
from an unseen domain or the clustering task is not topic detection. We
describe the pipeline and demonstrate its performance using BERT on three
real-world text mining tasks. As deployed in the VIM application, this
clustering pipeline produces high quality results, improving the performance of
data analysts and reducing the time it takes to surface intentions from
customer service data, thereby reducing the time it takes to build and deploy
IVAs in new domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts. (arXiv:2202.01279v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01279">
<div class="article-summary-box-inner">
<span><p>PromptSource is a system for creating, sharing, and using natural language
prompts. Prompts are functions that map an example from a dataset to a natural
language input and target output. Using prompts to train and query language
models is an emerging area in NLP that requires new tools that let users
develop and refine these prompts collaboratively. PromptSource addresses the
emergent challenges in this new setting with (1) a templating language for
defining data-linked prompts, (2) an interface that lets users quickly iterate
on prompt development by observing outputs of their prompts on many examples,
and (3) a community-driven set of guidelines for contributing new prompts to a
common pool. Over 2,000 prompts for roughly 170 datasets are already available
in PromptSource. PromptSource is available at
https://github.com/bigscience-workshop/promptsource.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASR-Aware End-to-end Neural Diarization. (arXiv:2202.01286v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01286">
<div class="article-summary-box-inner">
<span><p>We present a Conformer-based end-to-end neural diarization (EEND) model that
uses both acoustic input and features derived from an automatic speech
recognition (ASR) model. Two categories of features are explored: features
derived directly from ASR output (phones, position-in-word and word boundaries)
and features derived from a lexical speaker change detection model, trained by
fine-tuning a pretrained BERT model on the ASR output. Three modifications to
the Conformer-based EEND architecture are proposed to incorporate the features.
First, ASR features are concatenated with acoustic features. Second, we propose
a new attention mechanism called contextualized self-attention that utilizes
ASR features to build robust speaker representations. Finally, multi-task
learning is used to train the model to minimize classification loss for the ASR
features along with diarization loss. Experiments on the two-speaker English
conversations of Switchboard+SRE data sets show that multi-task learning with
position-in-word information is the most effective way of utilizing ASR
features, reducing the diarization error rate (DER) by 20% relative to the
baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparison of Online Hate on Reddit and 4chan: A Case Study of the 2020 US Election. (arXiv:2202.01302v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01302">
<div class="article-summary-box-inner">
<span><p>The rapid integration of the Internet into our daily lives has led to many
benefits but also to a number of new, wide-spread threats such as online hate,
trolling, bullying, and generally aggressive behaviours. While research has
traditionally explored online hate, in particular, on one platform, the reality
is that such hate is a phenomenon that often makes use of multiple online
networks. In this article, we seek to advance the discussion into online hate
by harnessing a comparative approach, where we make use of various Natural
Language Processing (NLP) techniques to computationally analyse hateful content
from Reddit and 4chan relating to the 2020 US Presidential Elections. Our
findings show how content and posting activity can differ depending on the
platform being used. Through this, we provide initial comparison into the
platform-specific behaviours of online hate, and how different platforms can
serve specific purposes. We further provide several avenues for future research
utilising a cross-platform approach so as to gain a more comprehensive
understanding of the global hate ecosystem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regression Transformer: Concurrent Conditional Generation and Regression by Blending Numerical and Textual Tokens. (arXiv:2202.01338v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01338">
<div class="article-summary-box-inner">
<span><p>We report the Regression Transformer (RT), a method that abstracts regression
as a conditional sequence modeling problem. The RT casts continuous properties
as sequences of numerical tokens and encodes them jointly with conventional
tokens. This yields a dichotomous model that can seamlessly transition between
solving regression tasks and conditional generation tasks; solely governed by
the mask location. We propose several extensions to the XLNet objective and
adopt an alternating training scheme to concurrently optimize property
prediction and conditional text generation based on a self-consistency loss.
</p>
<p>Our experiments on both chemical and protein languages demonstrate that the
performance of traditional regression models can be surpassed despite training
with cross entropy loss. Importantly, priming the same model with continuous
properties yields a highly competitive conditional generative models that
outperforms specialized approaches in a constrained property optimization
benchmark. In sum, the Regression Transformer opens the door for "swiss army
knife" models that excel at both regression and conditional generation. This
finds application particularly in property-driven, local exploration of the
chemical or protein space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mSLAM: Massively multilingual joint pre-training for speech and text. (arXiv:2202.01374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01374">
<div class="article-summary-box-inner">
<span><p>We present mSLAM, a multilingual Speech and LAnguage Model that learns
cross-lingual cross-modal representations of speech and text by pre-training
jointly on large amounts of unlabeled speech and text in multiple languages.
mSLAM combines w2v-BERT pre-training on speech with SpanBERT pre-training on
character-level text, along with Connectionist Temporal Classification (CTC)
losses on paired speech and transcript data, to learn a single model capable of
learning from and representing both speech and text signals in a shared
representation space. We evaluate mSLAM on several downstream speech
understanding tasks and find that joint pre-training with text improves quality
on speech translation, speech intent classification and speech language-ID
while being competitive on multilingual ASR, when compared against speech-only
pre-training. Our speech translation model demonstrates zero-shot text
translation without seeing any text translation data, providing evidence for
cross-modal alignment of representations. mSLAM also benefits from multi-modal
fine-tuning, further improving the quality of speech translation by directly
leveraging text translation data during the fine-tuning process. Our empirical
analysis highlights several opportunities and challenges arising from
large-scale multimodal pre-training, suggesting directions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Speech Recognition and Audio Captioning. (arXiv:2202.01405v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01405">
<div class="article-summary-box-inner">
<span><p>Speech samples recorded in both indoor and outdoor environments are often
contaminated with secondary audio sources. Most end-to-end monaural speech
recognition systems either remove these background sounds using speech
enhancement or train noise-robust models. For better model interpretability and
holistic understanding, we aim to bring together the growing field of automated
audio captioning (AAC) and the thoroughly studied automatic speech recognition
(ASR). The goal of AAC is to generate natural language descriptions of contents
in audio samples. We propose several approaches for end-to-end joint modeling
of ASR and AAC tasks and demonstrate their advantages over traditional
approaches, which model these tasks independently. A major hurdle in evaluating
our proposed approach is the lack of labeled audio datasets with both speech
transcriptions and audio captions. Therefore we also create a multi-task
dataset by mixing the clean speech Wall Street Journal corpus with multiple
levels of background noises chosen from the AudioCaps dataset. We also perform
extensive experimental evaluation and show improvements of our proposed methods
as compared to existing state-of-the-art ASR and AAC methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MFA: TDNN with Multi-scale Frequency-channel Attention for Text-independent Speaker Verification with Short Utterances. (arXiv:2202.01624v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01624">
<div class="article-summary-box-inner">
<span><p>The time delay neural network (TDNN) represents one of the state-of-the-art
of neural solutions to text-independent speaker verification. However, they
require a large number of filters to capture the speaker characteristics at any
local frequency region. In addition, the performance of such systems may
degrade under short utterance scenarios. To address these issues, we propose a
multi-scale frequency-channel attention (MFA), where we characterize speakers
at different scales through a novel dual-path design which consists of a
convolutional neural network and TDNN. We evaluate the proposed MFA on the
VoxCeleb database and observe that the proposed framework with MFA can achieve
state-of-the-art performance while reducing parameters and computation
complexity. Further, the MFA mechanism is found to be effective for speaker
verification with short test utterances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The relationship between sentiment score and COVID-19 cases in the United States. (arXiv:2202.01708v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01708">
<div class="article-summary-box-inner">
<span><p>The coronavirus disease (COVID-19) continues to have devastating effects
across the globe. No nation has been free from the uncertainty brought by this
pandemic. The health, social and economic tolls associated with it are causing
strong emotions and spreading fear in people of all ages, genders, and races.
Since the beginning of the COVID-19 pandemic, many have expressed their
feelings and opinions related to a wide range of aspects of their lives via
Twitter. In this study, we consider a framework for extracting sentiment scores
and opinions from COVID-19 related tweets. We connect users' sentiment with
COVID-19 cases across the USA and investigate the effect of specific COVID-19
milestones on public sentiment. The results of this work may help with the
development of pandemic-related legislation, serve as a guide for scientific
work, as well as inform and educate the public on core issues related to the
pandemic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Coherent and Consistent Use of Entities in Narrative Generation. (arXiv:2202.01709v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01709">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (LMs) have demonstrated impressive
capabilities in generating long, fluent text; however, there is little to no
analysis on their ability to maintain entity coherence and consistency. In this
work, we focus on the end task of narrative generation and systematically
analyse the long-range entity coherence and consistency in generated stories.
First, we propose a set of automatic metrics for measuring model performance in
terms of entity usage. Given these metrics, we quantify the limitations of
current LMs. Next, we propose augmenting a pre-trained LM with a dynamic entity
memory in an end-to-end manner by using an auxiliary entity-related loss for
guiding the reads and writes to the memory. We demonstrate that the dynamic
entity memory increases entity coherence according to both automatic and human
judgment and helps preserving entity-related information especially in settings
with a limited context window. Finally, we also validate that our automatic
metrics are correlated with human ratings and serve as a good indicator of the
quality of generated stories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JaQuAD: Japanese Question Answering Dataset for Machine Reading Comprehension. (arXiv:2202.01764v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01764">
<div class="article-summary-box-inner">
<span><p>Question Answering (QA) is a task in which a machine understands a given
document and a question to find an answer. Despite impressive progress in the
NLP area, QA is still a challenging problem, especially for non-English
languages due to the lack of annotated datasets. In this paper, we present the
Japanese Question Answering Dataset, JaQuAD, which is annotated by humans.
JaQuAD consists of 39,696 extractive question-answer pairs on Japanese
Wikipedia articles. We finetuned a baseline model which achieves 78.92% for F1
score and 63.38% for EM on test set. The dataset and our experiments are
available at https://github.com/SkelterLabsInc/JaQuAD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-Trained Language Models for Interactive Decision-Making. (arXiv:2202.01771v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01771">
<div class="article-summary-box-inner">
<span><p>Language model (LM) pre-training has proven useful for a wide variety of
language processing tasks, but can such pre-training be leveraged for more
general machine learning problems? We investigate the effectiveness of language
modeling to scaffold learning and generalization in autonomous decision-making.
We describe a framework for imitation learning in which goals and observations
are represented as a sequence of embeddings, and translated into actions using
a policy network initialized with a pre-trained transformer LM. We demonstrate
that this framework enables effective combinatorial generalization across
different environments, such as VirtualHome and BabyAI. In particular, for test
tasks involving novel goals or novel scenes, initializing policies with
language models improves task completion rates by 43.6% in VirtualHome. We
hypothesize and investigate three possible factors underlying the effectiveness
of LM-based policy initialization. We find that sequential representations (vs.
fixed-dimensional feature vectors) and the LM objective (not just the
transformer architecture) are both important for generalization. Surprisingly,
however, the format of the policy inputs encoding (e.g. as a natural language
string vs. an arbitrary sequential encoding) has little influence. Together,
these results suggest that language modeling induces representations that are
useful for modeling not just language, but also goals and plans; these
representations can aid learning and generalization even outside of language
processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Wrong Answer or a Wrong Question? An Intricate Relationship between Question Reformulation and Answer Selection in Conversational Question Answering. (arXiv:2010.06835v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06835">
<div class="article-summary-box-inner">
<span><p>The dependency between an adequate question formulation and correct answer
selection is a very intriguing but still underexplored area. In this paper, we
show that question rewriting (QR) of the conversational context allows to shed
more light on this phenomenon and also use it to evaluate robustness of
different answer selection approaches. We introduce a simple framework that
enables an automated analysis of the conversational question answering (QA)
performance using question rewrites, and present the results of this analysis
on the TREC CAsT and QuAC (CANARD) datasets. Our experiments uncover
sensitivity to question formulation of the popular state-of-the-art models for
reading comprehension and passage ranking. Our results demonstrate that the
reading comprehension model is insensitive to question formulation, while the
passage ranking changes dramatically with a little variation in the input
question. The benefit of QR is that it allows us to pinpoint and group such
cases automatically. We show how to use this methodology to verify whether QA
models are really learning the task or just finding shortcuts in the dataset,
and better understand the frequent types of error they make.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Knowledge Enhanced Pre-trained Models. (arXiv:2110.00269v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00269">
<div class="article-summary-box-inner">
<span><p>Pre-trained models learn contextualized word representations on large-scale
text corpus through a self-supervised learning method, which has achieved
promising performance after fine-tuning. These models, however, suffer from
poor robustness and lack of interpretability. Pre-trained models with knowledge
injection, which we call knowledge enhanced pre-trained models (KEPTMs),
possess deep understanding and logical reasoning and introduce interpretability
to some extent. In this survey, we provide a comprehensive overview of KEPTMs
for natural language processing. We first introduce the progress of pre-trained
models and knowledge representation learning. Then we systematically categorize
existing KEPTMs from three different perspectives. Finally, we outline some
potential directions of KEPTMs for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpreting intermediate convolutional layers in unsupervised acoustic word classification. (arXiv:2110.02375v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02375">
<div class="article-summary-box-inner">
<span><p>Understanding how deep convolutional neural networks classify data has been
subject to extensive research. This paper proposes a technique to visualize and
interpret intermediate layers of unsupervised deep convolutional networks by
averaging over individual feature maps in each convolutional layer and
inferring underlying distributions of words with non-linear regression
techniques. A GAN-based architecture (ciwGAN <a href="/abs/2006.02951">arXiv:2006.02951</a>) that includes a
Generator, a Discriminator, and a classifier was trained on unlabeled sliced
lexical items from TIMIT. The training process results in a deep convolutional
network that learns to classify words into discrete classes only from the
requirement of the Generator to output informative data. This classifier
network has no access to the training data -- only to the generated data. We
propose a technique to visualize individual convolutional layers in the
classifier that yields highly informative time-series data for each
convolutional layer and apply it to unobserved test data. Using non-linear
regression, we infer underlying distributions for each word which allows us to
analyze both absolute values and shapes of individual words at different
convolutional layers, as well as perform hypothesis testing on their acoustic
properties. The technique also allows us to test individual phone contrasts and
how they are represented at each layer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recent Advances in End-to-End Automatic Speech Recognition. (arXiv:2111.01690v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01690">
<div class="article-summary-box-inner">
<span><p>Recently, the speech community is seeing a significant trend of moving from
deep neural network based hybrid modeling to end-to-end (E2E) modeling for
automatic speech recognition (ASR). While E2E models achieve the
state-of-the-art results in most benchmarks in terms of ASR accuracy, hybrid
models are still used in a large proportion of commercial ASR systems at the
current time. There are lots of practical factors that affect the production
model deployment decision. Traditional hybrid models, being optimized for
production for decades, are usually good at these factors. Without providing
excellent solutions to all these factors, it is hard for E2E models to be
widely commercialized. In this paper, we will overview the recent advances in
E2E models, focusing on technologies addressing those challenges from the
industry's perspective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text classification problems via BERT embedding method and graph convolutional neural network. (arXiv:2111.15379v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.15379">
<div class="article-summary-box-inner">
<span><p>This paper presents the novel way combining the BERT embedding method and the
graph convolutional neural network. This combination is employed to solve the
text classification problem. Initially, we apply the BERT embedding method to
the texts (in the BBC news dataset and the IMDB movie reviews dataset) in order
to transform all the texts to numerical vector. Then, the graph convolutional
neural network will be applied to these numerical vectors to classify these
texts into their ap-propriate classes/labels. Experiments show that the
performance of the graph convolutional neural network model is better than the
perfor-mances of the combination of the BERT embedding method with clas-sical
machine learning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Structured Inference with Randomization. (arXiv:2112.03638v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03638">
<div class="article-summary-box-inner">
<span><p>Deep discrete structured models have seen considerable progress recently, but
traditional inference using dynamic programming (DP) typically works with a
small number of states (less than hundreds), which severely limits model
capacity. At the same time, across machine learning, there is a recent trend of
using randomized truncation techniques to accelerate computations involving
large sums. Here, we propose a family of randomized dynamic programming (RDP)
algorithms for scaling structured models to tens of thousands of latent states.
Our method is widely applicable to classical DP-based inference (partition,
marginal, reparameterization, entropy) and different graph structures (chains,
trees, and more general hypergraphs). It is also compatible with automatic
differentiation: it can be integrated with neural networks seamlessly and
learned with gradient-based optimizers. Our core technique approximates the
sum-product by restricting and reweighting DP on a small subset of nodes, which
reduces computation by orders of magnitude. We further achieve low bias and
variance via Rao-Blackwellization and importance sampling. Experiments over
different graphs demonstrate the accuracy and efficiency of our approach.
Furthermore, when using RDP for training a structured variational autoencoder
with a scaled inference network, we achieve better test likelihood than
baselines and successfully prevent posterior collapse
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Ultrasound Speed-of-Sound Reconstruction: Impacts of Training Data Diversity on Stability and Robustness. (arXiv:2202.01208v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01208">
<div class="article-summary-box-inner">
<span><p>Ultrasound b-mode imaging is a qualitative approach and diagnostic quality
strongly depends on operators' training and experience. Quantitative approaches
can provide information about tissue properties; therefore, can be used for
identifying various tissue types, e.g., speed-of-sound in the tissue can be
used as a biomarker for tissue malignancy, especially in breast imaging. Recent
studies showed the possibility of speed-of-sound reconstruction using deep
neural networks that are fully trained on simulated data. However, because of
the ever present domain shift between simulated and measured data, the
stability and performance of these models in real setups are still under
debate. In this study, we investigated the impacts of training data diversity
on the robustness of these networks by using multiple kinds of geometrical and
natural simulated phantom structures. On the simulated data, we investigated
the performance of the networks on out-of-domain echogenicity, geometries, and
in the presence of noise. We further inspected the stability of employing such
tissue modeling in a real data acquisition setup. We demonstrated that training
the network with a joint set of datasets including both geometrical and natural
tissue models improves the stability of the predicted speed-of-sound values
both on simulated and measured data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Semantic Descriptors for Image-Based Localization. (arXiv:2202.01212v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01212">
<div class="article-summary-box-inner">
<span><p>Vision based solutions for the localization of vehicles have become popular
recently. We employ an image retrieval based visual localization approach. The
database images are kept with GPS coordinates and the location of the retrieved
database image serves as an approximate position of the query image. We show
that localization can be performed via descriptors solely extracted from
semantically segmented images. It is reliable especially when the environment
is subjected to severe illumination and seasonal changes. Our experiments
reveal that the localization performance of a semantic descriptor can increase
up to the level of state-of-the-art RGB image based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated processing of X-ray computed tomography images via panoptic segmentation for modeling woven composite textiles. (arXiv:2202.01265v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01265">
<div class="article-summary-box-inner">
<span><p>A new, machine learning-based approach for automatically generating 3D
digital geometries of woven composite textiles is proposed to overcome the
limitations of existing analytical descriptions and segmentation methods. In
this approach, panoptic segmentation is leveraged to produce instance segmented
semantic masks from X-ray computed tomography (CT) images. This effort
represents the first deep learning based automated process for segmenting
unique yarn instances in a woven composite textile. Furthermore, it improves on
existing methods by providing instance-level segmentation on low contrast CT
datasets. Frame-to-frame instance tracking is accomplished via an
intersection-over-union (IoU) approach adopted from video panoptic segmentation
for assembling a 3D geometric model. A corrective recognition algorithm is
developed to improve the recognition quality (RQ). The panoptic quality (PQ)
metric is adopted to provide a new universal evaluation metric for
reconstructed woven composite textiles. It is found that the panoptic
segmentation network generalizes well to new CT images that are similar to the
training set but does not extrapolate well to CT images of differing geometry,
texture, and contrast. The utility of this approach is demonstrated by
capturing yarn flow directions, contact regions between individual yarns, and
the spatially varying cross-sectional areas of the yarns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Images: Label Noise Transition Matrix Estimation for Tasks with Lower-Quality Features. (arXiv:2202.01273v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01273">
<div class="article-summary-box-inner">
<span><p>The label noise transition matrix, denoting the transition probabilities from
clean labels to noisy labels, is crucial knowledge for designing statistically
robust solutions. Existing estimators for noise transition matrices, e.g.,
using either anchor points or clusterability, focus on computer vision tasks
that are relatively easier to obtain high-quality representations. However, for
other tasks with lower-quality features, the uninformative variables may
obscure the useful counterpart and make anchor-point or clusterability
conditions hard to satisfy. We empirically observe the failures of these
approaches on a number of commonly used datasets. In this paper, to handle this
issue, we propose a generally practical information-theoretic approach to
down-weight the less informative parts of the lower-quality features. The
salient technical challenge is to compute the relevant information-theoretical
metrics using only noisy labels instead of clean ones. We prove that the
celebrated $f$-mutual information measure can often preserve the order when
calculated using noisy labels. The necessity and effectiveness of the proposed
method is also demonstrated by evaluating the estimation error on a varied set
of tabular data and text classification tasks with lower-quality features. Code
is available at github.com/UCSC-REAL/Est-T-MI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cyclical Pruning for Sparse Neural Networks. (arXiv:2202.01290v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01290">
<div class="article-summary-box-inner">
<span><p>Current methods for pruning neural network weights iteratively apply
magnitude-based pruning on the model weights and re-train the resulting model
to recover lost accuracy. In this work, we show that such strategies do not
allow for the recovery of erroneously pruned weights. To enable weight
recovery, we propose a simple strategy called \textit{cyclical pruning} which
requires the pruning schedule to be periodic and allows for weights pruned
erroneously in one cycle to recover in subsequent ones. Experimental results on
both linear models and large-scale deep neural networks show that cyclical
pruning outperforms existing pruning algorithms, especially at high sparsity
ratios. Our approach is easy to tune and can be readily incorporated into
existing pruning pipelines to boost performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Resolution Factor Graph Based Stereo Correspondence Algorithm. (arXiv:2202.01309v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01309">
<div class="article-summary-box-inner">
<span><p>A dense depth-map of a scene at an arbitrary view orientation can be
estimated from dense view correspondences among multiple lower-dimensional
views of the scene. These low-dimensional view correspondences are dependent on
the geometrical relationship among the views and the scene. Determining dense
view correspondences is difficult in part due to presence of homogeneous
regions in the scene and due to presence of occluded regions and illumination
differences among the views. We present a new multi-resolution factor
graph-based stereo matching algorithm (MR-FGS) that utilizes both intra- and
inter-resolution dependencies among the views as well as among the disparity
estimates. The proposed framework allows exchange of information among multiple
resolutions of the correspondence problem and is useful for handling larger
homogeneous regions in a scene. The MR-FGS algorithm was evaluated
qualitatively and quantitatively using stereo pairs in the Middlebury stereo
benchmark dataset based on commonly used performance measures. When compared to
a recently developed factor graph model (FGS), the MR-FGS algorithm provided
more accurate disparity estimates without requiring the commonly used
post-processing procedure known as the left-right consistency check. The
multi-resolution dependency constraint within the factor-graph model
significantly improved contrast along depth boundaries in the MR-FGS generated
disparity maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PanoDepth: A Two-Stage Approach for Monocular Omnidirectional Depth Estimation. (arXiv:2202.01323v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01323">
<div class="article-summary-box-inner">
<span><p>Omnidirectional 3D information is essential for a wide range of applications
such as Virtual Reality, Autonomous Driving, Robotics, etc. In this paper, we
propose a novel, model-agnostic, two-stage pipeline for omnidirectional
monocular depth estimation. Our proposed framework PanoDepth takes one 360
image as input, produces one or more synthesized views in the first stage, and
feeds the original image and the synthesized images into the subsequent stereo
matching stage. In the second stage, we propose a differentiable Spherical
Warping Layer to handle omnidirectional stereo geometry efficiently and
effectively. By utilizing the explicit stereo-based geometric constraints in
the stereo matching stage, PanoDepth can generate dense high-quality depth. We
conducted extensive experiments and ablation studies to evaluate PanoDepth with
both the full pipeline as well as the individual modules in each stage. Our
results show that PanoDepth outperforms the state-of-the-art approaches by a
large margin for 360 monocular depth estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalizability of Machine Learning Models: Quantitative Evaluation of Three Methodological Pitfalls. (arXiv:2202.01337v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01337">
<div class="article-summary-box-inner">
<span><p>Despite the great potential of machine learning, the lack of generalizability
has hindered the widespread adoption of these technologies in routine clinical
practice. We investigate three methodological pitfalls: (1) violation of
independence assumption, (2) model evaluation with an inappropriate performance
indicator, and (3) batch effect and how these pitfalls could affect the
generalizability of machine learning models. We implement random forest and
deep convolutional neural network models using several medical imaging
datasets, including head and neck CT, lung CT, chest X-Ray, and
histopathological images, to quantify and illustrate the effect of these
pitfalls. We develop these models with and without the pitfall and compare the
performance of the resulting models in terms of accuracy, precision, recall,
and F1 score. Our results showed that violation of the independence assumption
could substantially affect model generalizability. More specifically, (I)
applying oversampling before splitting data into train, validation and test
sets; (II) performing data augmentation before splitting data; (III)
distributing data points for a subject across training, validation, and test
sets; and (IV) applying feature selection before splitting data led to
superficial boosts in model performance. We also observed that inappropriate
performance indicators could lead to erroneous conclusions. Also, batch effect
could lead to developing models that lack generalizability. The aforementioned
methodological pitfalls lead to machine learning models with over-optimistic
performance. These errors, if made, cannot be captured using internal model
evaluation, and the inaccurate predictions made by the model may lead to wrong
conclusions and interpretations. Therefore, avoiding these pitfalls is a
necessary condition for developing generalizable models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Sub-skeleton Trajectories for Interpretable Recognition of Sign Language. (arXiv:2202.01390v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01390">
<div class="article-summary-box-inner">
<span><p>Recent advances in tracking sensors and pose estimation software enable smart
systems to use trajectories of skeleton joint locations for supervised
learning. We study the problem of accurately recognizing sign language words,
which is key to narrowing the communication gap between hard and non-hard of
hearing people.
</p>
<p>Our method explores a geometric feature space that we call `sub-skeleton'
aspects of movement. We assess similarity of feature space trajectories using
natural, speed invariant distance measures, which enables clear and insightful
nearest neighbor classification. The simplicity and scalability of our basic
method allows for immediate application in different data domains with little
to no parameter tuning.
</p>
<p>We demonstrate the effectiveness of our basic method, and a boosted
variation, with experiments on data from different application domains and
tracking technologies. Surprisingly, our simple methods improve sign
recognition over recent, state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DocBed: A Multi-Stage OCR Solution for Documents with Complex Layouts. (arXiv:2202.01414v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01414">
<div class="article-summary-box-inner">
<span><p>Digitization of newspapers is of interest for many reasons including
preservation of history, accessibility and search ability, etc. While
digitization of documents such as scientific articles and magazines is
prevalent in literature, one of the main challenges for digitization of
newspaper lies in its complex layout (e.g. articles spanning multiple columns,
text interrupted by images) analysis, which is necessary to preserve human
read-order. This work provides a major breakthrough in the digitization of
newspapers on three fronts: first, releasing a dataset of 3000 fully-annotated,
real-world newspaper images from 21 different U.S. states representing an
extensive variety of complex layouts for document layout analysis; second,
proposing layout segmentation as a precursor to existing optical character
recognition (OCR) engines, where multiple state-of-the-art image segmentation
models and several post-processing methods are explored for document layout
segmentation; third, providing a thorough and structured evaluation protocol
for isolated layout segmentation and end-to-end OCR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterization of Semantic Segmentation Models on Mobile Platforms for Self-Navigation in Disaster-Struck Zones. (arXiv:2202.01421v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01421">
<div class="article-summary-box-inner">
<span><p>The role of unmanned vehicles for searching and localizing the victims in
disaster impacted areas such as earthquake-struck zones is getting more
important. Self-navigation on an earthquake zone has a unique challenge of
detecting irregularly shaped obstacles such as road cracks, debris on the
streets, and water puddles. In this paper, we characterize a number of
state-of-the-art FCN models on mobile embedded platforms for self-navigation at
these sites containing extremely irregular obstacles. We evaluate the models in
terms of accuracy, performance, and energy efficiency. We present a few
optimizations for our designed vision system. Lastly, we discuss the trade-offs
of these models for a couple of mobile platforms that can each perform
self-navigation. To enable vehicles to safely navigate earthquake-struck zones,
we compiled a new annotated image database of various earthquake impacted
regions that is different than traditional road damage databases. We train our
database with a number of state-of-the-art semantic segmentation models in
order to identify obstacles unique to earthquake-struck zones. Based on the
statistics and tradeoffs, an optimal CNN model is selected for the mobile
vehicular platforms, which we apply to both low-power and extremely low-power
configurations of our design. To our best knowledge, this is the first study
that identifies unique challenges and discusses the accuracy, performance, and
energy impact of edge-based self-navigation mobile vehicles for
earthquake-struck zones. Our proposed database and trained models are publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimized Potential Initialization for Low-latency Spiking Neural Networks. (arXiv:2202.01440v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01440">
<div class="article-summary-box-inner">
<span><p>Spiking Neural Networks (SNNs) have been attached great importance due to the
distinctive properties of low power consumption, biological plausibility, and
adversarial robustness. The most effective way to train deep SNNs is through
ANN-to-SNN conversion, which have yielded the best performance in deep network
structure and large-scale datasets. However, there is a trade-off between
accuracy and latency. In order to achieve high precision as original ANNs, a
long simulation time is needed to match the firing rate of a spiking neuron
with the activation value of an analog neuron, which impedes the practical
application of SNN. In this paper, we aim to achieve high-performance converted
SNNs with extremely low latency (fewer than 32 time-steps). We start by
theoretically analyzing ANN-to-SNN conversion and show that scaling the
thresholds does play a similar role as weight normalization. Instead of
introducing constraints that facilitate ANN-to-SNN conversion at the cost of
model capacity, we applied a more direct way by optimizing the initial membrane
potential to reduce the conversion loss in each layer. Besides, we demonstrate
that optimal initialization of membrane potentials can implement expected
error-free ANN-to-SNN conversion. We evaluate our algorithm on the CIFAR-10,
CIFAR-100 and ImageNet datasets and achieve state-of-the-art accuracy, using
fewer time-steps. For example, we reach top-1 accuracy of 93.38\% on CIFAR-10
with 16 time-steps. Moreover, our method can be applied to other ANN-SNN
conversion methodologies and remarkably promote performance when the time-steps
is small.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Concept Bottleneck Model with Additional Unsupervised Concepts. (arXiv:2202.01459v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01459">
<div class="article-summary-box-inner">
<span><p>With the increasing demands for accountability, interpretability is becoming
an essential capability for real-world AI applications. However, most methods
utilize post-hoc approaches rather than training the interpretable model. In
this article, we propose a novel interpretable model based on the concept
bottleneck model (CBM). CBM uses concept labels to train an intermediate layer
as the additional visible layer. However, because the number of concept labels
restricts the dimension of this layer, it is difficult to obtain high accuracy
with a small number of labels. To address this issue, we integrate supervised
concepts with unsupervised ones trained with self-explaining neural networks
(SENNs). By seamlessly training these two types of concepts while reducing the
amount of computation, we can obtain both supervised and unsupervised concepts
simultaneously, even for large-sized images. We refer to the proposed model as
the concept bottleneck model with additional unsupervised concepts (CBM-AUC).
We experimentally confirmed that the proposed model outperformed CBM and SENN.
We also visualized the saliency map of each concept and confirmed that it was
consistent with the semantic meanings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Monocular Depth Estimation with Sparse Guided Points. (arXiv:2202.01470v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01470">
<div class="article-summary-box-inner">
<span><p>Existing monocular depth estimation shows excellent robustness in the wild,
but the affine-invariant prediction requires aligning with the ground truth
globally while being converted into the metric depth. In this work, we firstly
propose a modified locally weighted linear regression strategy to leverage
sparse ground truth and generate a flexible depth transformation to correct the
coarse misalignment brought by global recovery strategy. Applying this
strategy, we achieve significant improvement (more than 50% at most) over most
recent state-of-the-art methods on five zero-shot datasets. Moreover, we train
a robust depth estimation model with 6.3 million data and analyze the training
process by decoupling the inaccuracy into coarse misalignment inaccuracy and
detail missing inaccuracy. As a result, our model based on ResNet50 even
outperforms the state-of-the-art DPT ViT-Large model with the help of our
recovery strategy. In addition to accuracy, the consistency is also boosted for
simple per-frame video depth estimation. Compared with monocular depth
estimation, robust video depth estimation, and depth completion methods, our
pipeline obtains state-of-the-art performance on video depth estimation without
any post-processing. Experiments of 3D scene reconstruction from consistent
video depth are conducted for intuitive comparison as well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trajectory Forecasting from Detection with Uncertainty-Aware Motion Encoding. (arXiv:2202.01478v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01478">
<div class="article-summary-box-inner">
<span><p>Trajectory forecasting is critical for autonomous platforms to make safe
planning and actions. Currently, most trajectory forecasting methods assume
that object trajectories have been extracted and directly develop trajectory
predictors based on the ground truth trajectories. However, this assumption
does not hold in practical situations. Trajectories obtained from object
detection and tracking are inevitably noisy, which could cause serious
forecasting errors to predictors built on ground truth trajectories. In this
paper, we propose a trajectory predictor directly based on detection results
without relying on explicitly formed trajectories. Different from the
traditional methods which encode the motion cue of an agent based on its
clearly defined trajectory, we extract the motion information only based on the
affinity cues among detection results, in which an affinity-aware state update
mechanism is designed to take the uncertainty of association into account. In
addition, considering that there could be multiple plausible matching
candidates, we aggregate the states of them. This design relaxes the
undesirable effect of noisy trajectory obtained from data association.
Extensive ablation experiments validate the effectiveness of our method and its
generalization ability on different detectors. Cross-comparison to other
forecasting schemes further proves the superiority of our method. Code will be
released upon acceptance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial Computing and Intuitive Interaction: Bringing Mixed Reality and Robotics Together. (arXiv:2202.01493v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01493">
<div class="article-summary-box-inner">
<span><p>Spatial computing -- the ability of devices to be aware of their surroundings
and to represent this digitally -- offers novel capabilities in human-robot
interaction. In particular, the combination of spatial computing and egocentric
sensing on mixed reality devices enables them to capture and understand human
actions and translate these to actions with spatial meaning, which offers
exciting new possibilities for collaboration between humans and robots. This
paper presents several human-robot systems that utilize these capabilities to
enable novel robot use cases: mission planning for inspection, gesture-based
control, and immersive teleoperation. These works demonstrate the power of
mixed reality as a tool for human-robot interaction, and the potential of
spatial computing and mixed reality to drive the future of human-robot
interaction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PARCEL: Physics-based unsupervised contrastive representation learning for parallel MR imaging. (arXiv:2202.01494v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01494">
<div class="article-summary-box-inner">
<span><p>With the successful application of deep learning in magnetic resonance
imaging, parallel imaging techniques based on neural networks have attracted
wide attentions. However, without high-quality fully sampled datasets for
training, the performance of these methods tends to be limited. To address this
issue, this paper proposes a physics based unsupervised contrastive
representation learning (PARCEL) method to speed up parallel MR imaging.
Specifically, PARCEL has three key ingredients to achieve direct deep learning
from the undersampled k-space data. Namely, a parallel framework has been
developed by learning two branches of model-based networks unrolled with the
conjugate gradient algorithm; Augmented undersampled k-space data randomly
drawn from the obtained k-space data are used to help the parallel network to
capture the detailed information. A specially designed co-training loss is
designed to guide the two networks to capture the inherent features and
representations of the-to-be-reconstructed MR image. The proposed method has
been evaluated on in vivo datasets and compared to five state-of-the-art
methods, whose results show PARCEL is able to learn useful representations for
more accurate MR reconstructions without the reliance on the fully-sampled
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bending Graphs: Hierarchical Shape Matching using Gated Optimal Transport. (arXiv:2202.01537v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01537">
<div class="article-summary-box-inner">
<span><p>Shape matching has been a long-studied problem for the computer graphics and
vision community. The objective is to predict a dense correspondence between
meshes that have a certain degree of deformation. Existing methods either
consider the local description of sampled points or discover correspondences
based on global shape information. In this work, we investigate a hierarchical
learning design, to which we incorporate local patch-level information and
global shape-level structures. This flexible representation enables
correspondence prediction and provides rich features for the matching stage.
Finally, we propose a novel optimal transport solver by recurrently updating
features on non-confident nodes to learn globally consistent correspondences
between the shapes. Our results on publicly available datasets suggest robust
performance in presence of severe deformations without the need for extensive
training or refinement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Nuclei Segmentation via Instance Learning. (arXiv:2202.01564v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01564">
<div class="article-summary-box-inner">
<span><p>Weakly supervised nuclei segmentation is a critical problem for pathological
image analysis and greatly benefits the community due to the significant
reduction of labeling cost. Adopting point annotations, previous methods mostly
rely on less expressive representations for nuclei instances and thus have
difficulty in handling crowded nuclei. In this paper, we propose to decouple
weakly supervised semantic and instance segmentation in order to enable more
effective subtask learning and to promote instance-aware representation
learning. To achieve this, we design a modular deep network with two branches:
a semantic proposal network and an instance encoding network, which are trained
in a two-stage manner with an instance-sensitive loss. Empirical results show
that our approach achieves the state-of-the-art performance on two public
benchmarks of pathological images from different types of organs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FORML: Learning to Reweight Data for Fairness. (arXiv:2202.01719v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01719">
<div class="article-summary-box-inner">
<span><p>Deployed machine learning models are evaluated by multiple metrics beyond
accuracy, such as fairness and robustness. However, such models are typically
trained to minimize the average loss for a single metric, which is typically a
proxy for accuracy. Training to optimize a single metric leaves these models
prone to fairness violations, especially when the population of sub-groups in
the training data are imbalanced. This work addresses the challenge of jointly
optimizing fairness and predictive performance in the multi-class
classification setting by introducing Fairness Optimized Reweighting via
Meta-Learning (FORML), a training algorithm that balances fairness constraints
and accuracy by jointly optimizing training sample weights and a neural
network's parameters. The approach increases fairness by learning to weight
each training datum's contribution to the loss according to its impact on
reducing fairness violations, balancing the contributions from both over- and
under-represented sub-groups. We empirically validate FORML on a range of
benchmark and real-world classification datasets and show that our approach
improves equality of opportunity fairness criteria over existing
state-of-the-art reweighting methods by approximately 1% on image
classification tasks and by approximately 5% on a face attribute prediction
task. This improvement is achieved without pre-processing data or
post-processing model outputs, without learning an additional weighting
function, and while maintaining accuracy on the original predictive metric.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skeleton-Based Action Segmentation with Multi-Stage Spatial-Temporal Graph Convolutional Neural Networks. (arXiv:2202.01727v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01727">
<div class="article-summary-box-inner">
<span><p>The ability to identify and temporally segment fine-grained actions in motion
capture sequences is crucial for applications in human movement analysis.
Motion capture is typically performed with optical or inertial measurement
systems, which encode human movement as a time series of human joint locations
and orientations or their higher-order representations. State-of-the-art action
segmentation approaches use multiple stages of temporal convolutions. The main
idea is to generate an initial prediction with several layers of temporal
convolutions and refine these predictions over multiple stages, also with
temporal convolutions. Although these approaches capture long-term temporal
patterns, the initial predictions do not adequately consider the spatial
hierarchy among the human joints. To address this limitation, we present
multi-stage spatial-temporal graph convolutional neural networks (MS-GCN). Our
framework decouples the architecture of the initial prediction generation stage
from the refinement stages. Specifically, we replace the initial stage of
temporal convolutions with spatial-temporal graph convolutions, which better
exploit the spatial configuration of the joints and their temporal dynamics.
Our framework was compared to four strong baselines on five tasks. Experimental
results demonstrate that our framework achieves state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Online Video Super-Resolution with Deformable Attention Pyramid. (arXiv:2202.01731v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01731">
<div class="article-summary-box-inner">
<span><p>Video super-resolution (VSR) has many applications that pose strict causal,
real-time, and latency constraints, including video streaming and TV. We
address the VSR problem under these settings, which poses additional important
challenges since information from future frames are unavailable. Importantly,
designing efficient, yet effective frame alignment and fusion modules remain
central problems. In this work, we propose a recurrent VSR architecture based
on a deformable attention pyramid (DAP). Our DAP aligns and integrates
information from the recurrent state into the current frame prediction. To
circumvent the computational cost of traditional attention-based methods, we
only attend to a limited number of spatial locations, which are dynamically
predicted by the DAP. Comprehensive experiments and analysis of the proposed
key innovations show the effectiveness of our approach. We significantly reduce
processing time in comparison to state-of-the-art methods, while maintaining a
high performance. We surpass state-of-the-art method EDVR-M on two standard
benchmarks with a speed-up of over 3x.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Met Dataset: Instance-level Recognition for Artworks. (arXiv:2202.01747v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01747">
<div class="article-summary-box-inner">
<span><p>This work introduces a dataset for large-scale instance-level recognition in
the domain of artworks. The proposed benchmark exhibits a number of different
challenges such as large inter-class similarity, long tail distribution, and
many classes. We rely on the open access collection of The Met museum to form a
large training set of about 224k classes, where each class corresponds to a
museum exhibit with photos taken under studio conditions. Testing is primarily
performed on photos taken by museum guests depicting exhibits, which introduces
a distribution shift between training and testing. Testing is additionally
performed on a set of images not related to Met exhibits making the task
resemble an out-of-distribution detection problem. The proposed benchmark
follows the paradigm of other recent datasets for instance-level recognition on
different domains to encourage research on domain independent approaches. A
number of suitable approaches are evaluated to offer a testbed for future
comparisons. Self-supervised and supervised contrastive learning are
effectively combined to train the backbone which is used for non-parametric
classification that is shown as a promising direction. Dataset webpage:
<a href="http://cmp.felk.cvut.cz/met/">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Forecasting future action sequences with attention: a new approach to weakly supervised action forecasting. (arXiv:1912.04608v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.04608">
<div class="article-summary-box-inner">
<span><p>Future human action forecasting from partial observations of activities is an
important problem in many practical applications such as assistive robotics,
video surveillance and security. We present a method to forecast actions for
the unseen future of the video using a neural machine translation technique
that uses encoder-decoder architecture. The input to this model is the observed
RGB video, and the objective is to forecast the correct future symbolic action
sequence. Unlike prior methods that make action predictions for some unseen
percentage of video one for each frame, we predict the complete action sequence
that is required to accomplish the activity. We coin this task action sequence
forecasting. To cater for two types of uncertainty in the future predictions,
we propose a novel loss function. We show a combination of optimal transport
and future uncertainty losses help to improve results.
</p>
<p>We extend our action sequence forecasting model to perform weakly supervised
action forecasting on two challenging datasets, the Breakfast and the 50Salads.
Specifically, we propose a model to predict actions of future unseen frames
without using frame level annotations during training. Using Fisher vector
features, our supervised model outperforms the state-of-the-art action
forecasting model by 0.83% and 7.09% on the Breakfast and the 50Salads datasets
respectively. Our weakly supervised model is only 0.6% behind the most recent
state-of-the-art supervised model and obtains comparable results to other
published fully supervised methods, and sometimes even outperforms them on the
Breakfast dataset. Most interestingly, our weakly supervised model outperforms
prior models by 1.04% leveraging on proposed weakly supervised architecture,
and effective use of attention mechanism and loss functions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Rain Attack and Defensive Deraining for DNN Perception. (arXiv:2009.09205v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.09205">
<div class="article-summary-box-inner">
<span><p>Rain often poses inevitable threats to deep neural network (DNN) based
perception systems, and a comprehensive investigation of the potential risks of
the rain to DNNs is of great importance. However, it is rather difficult to
collect or synthesize rainy images that can represent all rain situations that
would possibly occur in the real world. To this end, in this paper, we start
from a new perspective and propose to combine two totally different studies,
i.e., rainy image synthesis and adversarial attack. We first present an
adversarial rain attack, with which we could simulate various rain situations
with the guidance of deployed DNNs and reveal the potential threat factors that
can be brought by rain. In particular, we design a factor-aware rain generation
that synthesizes rain streaks according to the camera exposure process and
models the learnable rain factors for adversarial attack. With this generator,
we perform the adversarial rain attack against the image classification and
object detection. To defend the DNNs from the negative rain effect, we also
present a defensive deraining strategy, for which we design an adversarial rain
augmentation that uses mixed adversarial rain layers to enhance deraining
models for downstream DNN perception. Our large-scale evaluation on various
datasets demonstrates that our synthesized rainy images with realistic
appearances not only exhibit strong adversarial capability against DNNs, but
also boost the deraining models for defensive purposes, building the foundation
for further rain-robust perception studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Boundary Loss for Semantic Segmentation. (arXiv:2102.02696v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02696">
<div class="article-summary-box-inner">
<span><p>This paper proposes a novel active boundary loss for semantic segmentation.
It can progressively encourage the alignment between predicted boundaries and
ground-truth boundaries during end-to-end training, which is not explicitly
enforced in commonly used cross-entropy loss. Based on the predicted boundaries
detected from the segmentation results using current network parameters, we
formulate the boundary alignment problem as a differentiable direction vector
prediction problem to guide the movement of predicted boundaries in each
iteration. Our loss is model-agnostic and can be plugged in to the training of
segmentation networks to improve the boundary details. Experimental results
show that training with the active boundary loss can effectively improve the
boundary F-score and mean Intersection-over-Union on challenging image and
video object segmentation datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated freezing of gait assessment with marker-based motion capture and multi-stage spatial-temporal graph convolutional neural networks. (arXiv:2103.15449v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15449">
<div class="article-summary-box-inner">
<span><p>Freezing of gait (FOG) is a common and debilitating gait impairment in
Parkinson's disease. Further insight into this phenomenon is hampered by the
difficulty to objectively assess FOG. To meet this clinical need, this paper
proposes an automated motion-capture-based FOG assessment method driven by a
novel deep neural network. Automated FOG assessment can be formulated as an
action segmentation problem, where temporal models are tasked to recognize and
temporally localize the FOG segments in untrimmed motion capture trials. This
paper takes a closer look at the performance of state-of-the-art action
segmentation models when tasked to automatically assess FOG. Furthermore, a
novel deep neural network architecture is proposed that aims to better capture
the spatial and temporal dependencies than the state-of-the-art baselines. The
proposed network, termed multi-stage spatial-temporal graph convolutional
network (MS-GCN), combines the spatial-temporal graph convolutional network
(ST-GCN) and the multi-stage temporal convolutional network (MS-TCN). The
ST-GCN captures the hierarchical spatial-temporal motion among the joints
inherent to motion capture, while the multi-stage component reduces
over-segmentation errors by refining the predictions over multiple stages. The
experiments indicate that the proposed model outperforms four state-of-the-art
baselines. Moreover, FOG outcomes derived from MS-GCN predictions had an
excellent (r=0.93 [0.87, 0.97]) and moderately strong (r=0.75 [0.55, 0.87])
linear relationship with FOG outcomes derived from manual annotations. The
proposed MS-GCN may provide an automated and objective alternative to
labor-intensive clinician-based FOG assessment. Future work is now possible
that aims to assess the generalization of MS-GCN to a larger and more varied
verification cohort.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prototype Memory for Large-scale Face Representation Learning. (arXiv:2105.02103v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02103">
<div class="article-summary-box-inner">
<span><p>Face representation learning using datasets with a massive number of
identities requires appropriate training methods. Softmax-based approach,
currently the state-of-the-art in face recognition, in its usual "full softmax"
form is not suitable for datasets with millions of persons. Several methods,
based on the "sampled softmax" approach, were proposed to remove this
limitation. These methods, however, have a set of disadvantages. One of them is
a problem of "prototype obsolescence": classifier weights (prototypes) of the
rarely sampled classes receive too scarce gradients and become outdated and
detached from the current encoder state, resulting in incorrect training
signals. This problem is especially serious in ultra-large-scale datasets. In
this paper, we propose a novel face representation learning model called
Prototype Memory, which alleviates this problem and allows training on a
dataset of any size. Prototype Memory consists of the limited-size memory
module for storing recent class prototypes and employs a set of algorithms to
update it in appropriate way. New class prototypes are generated on the fly
using exemplar embeddings in the current mini-batch. These prototypes are
enqueued to the memory and used in a role of classifier weights for softmax
classification-based training. To prevent obsolescence and keep the memory in
close connection with the encoder, prototypes are regularly refreshed, and
oldest ones are dequeued and disposed of. Prototype Memory is computationally
efficient and independent of dataset size. It can be used with various loss
functions, hard example mining algorithms and encoder architectures. We prove
the effectiveness of the proposed model by extensive experiments on popular
face recognition benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trust It or Not: Confidence-Guided Automatic Radiology Report Generation. (arXiv:2106.10887v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10887">
<div class="article-summary-box-inner">
<span><p>Medical imaging plays a pivotal role in diagnosis and treatment in clinical
practice. Inspired by the significant progress in automatic image captioning,
various deep learning (DL)-based methods have been proposed to generate
radiology reports for medical images. Despite promising results, previous works
overlook the uncertainties of their models and are thus unable to provide
clinicians with the reliability/confidence of the generated radiology reports
to assist their decision-making. In this paper, we propose a novel method to
explicitly quantify both the visual uncertainty and the textual uncertainty for
DL-based radiology report generation. Such multi-modal uncertainties can
sufficiently capture the model confidence degree at both the report level and
the sentence level, and thus they are further leveraged to weight the losses
for more comprehensive model optimization. Experimental results have
demonstrated that the proposed method for model uncertainty characterization
and estimation can produce more reliable confidence scores for radiology report
generation, and the modified loss function, which takes into account the
uncertainties, leads to better model performance on two public radiology report
datasets. In addition, the quality of the automatically generated reports was
manually evaluated by human raters and the results also indicate that the
proposed uncertainties can reflect the variance of clinical diagnosis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Adversarial Training incorporating Forgery Attention for Image Forgery Localization. (arXiv:2107.02434v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02434">
<div class="article-summary-box-inner">
<span><p>Image editing techniques enable people to modify the content of an image
without leaving visual traces and thus may cause serious security risks. Hence
the detection and localization of these forgeries become quite necessary and
challenging. Furthermore, unlike other tasks with extensive data, there is
usually a lack of annotated forged images for training due to annotation
difficulties. In this paper, we propose a self-adversarial training strategy
and a reliable coarse-to-fine network that utilizes a self-attention mechanism
to localize forged regions in forgery images. The self-attention module is
based on a Channel-Wise High Pass Filter block (CW-HPF). CW-HPF leverages
inter-channel relationships of features and extracts noise features by high
pass filters. Based on the CW-HPF, a self-attention mechanism, called forgery
attention, is proposed to capture rich contextual dependencies of intrinsic
inconsistency extracted from tampered regions. Specifically, we append two
types of attention modules on top of CW-HPF respectively to model internal
interdependencies in spatial dimension and external dependencies among
channels. We exploit a coarse-to-fine network to enhance the noise
inconsistency between original and tampered regions. More importantly, to
address the issue of insufficient training data, we design a self-adversarial
training strategy that expands training data dynamically to achieve more robust
performance. Specifically, in each training iteration, we perform adversarial
attacks against our network to generate adversarial examples and train our
model on them. Extensive experimental results demonstrate that our proposed
algorithm steadily outperforms state-of-the-art methods by a clear margin in
different benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Sparse Interaction Graphs of Partially Detected Pedestrians for Trajectory Prediction. (arXiv:2107.07056v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07056">
<div class="article-summary-box-inner">
<span><p>Multi-pedestrian trajectory prediction is an indispensable element of
autonomous systems that safely interact with crowds in unstructured
environments. Many recent efforts in trajectory prediction algorithms have
focused on understanding social norms behind pedestrian motions. Yet we observe
these works usually hold two assumptions, which prevent them from being
smoothly applied to robot applications: (1) positions of all pedestrians are
consistently tracked, and (2) the target agent pays attention to all
pedestrians in the scene. The first assumption leads to biased interaction
modeling with incomplete pedestrian data. The second assumption introduces
aggregation of redundant surrounding information, and the target agent may be
affected by unimportant neighbors or present overly conservative motion. Thus,
we propose Gumbel Social Transformer, in which an Edge Gumbel Selector samples
a sparse interaction graph of partially detected pedestrians at each time step.
A Node Transformer Encoder and a Masked LSTM encode pedestrian features with
sampled sparse graphs to predict trajectories. We demonstrate that our model
overcomes potential problems caused by the aforementioned assumptions, and our
approach outperforms related works in trajectory prediction benchmarks. Code is
available at \url{https://github.com/tedhuang96/gst}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Study of Deep Learning Classification Methods on a Small Environmental Microorganism Image Dataset (EMDS-6): from Convolutional Neural Networks to Visual Transformers. (arXiv:2107.07699v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07699">
<div class="article-summary-box-inner">
<span><p>In recent years, deep learning has made brilliant achievements in
Environmental Microorganism (EM) image classification. However, image
classification of small EM datasets has still not obtained good research
results. Therefore, researchers need to spend a lot of time searching for
models with good classification performance and suitable for the current
equipment working environment. To provide reliable references for researchers,
we conduct a series of comparison experiments on 21 deep learning models. The
experiment includes direct classification, imbalanced training, and
hyperparameter tuning experiments. During the experiments, we find
complementarities among the 21 models, which is the basis for feature fusion
related experiments. We also find that the data augmentation method of
geometric deformation is difficult to improve the performance of VTs (ViT,
DeiT, BotNet and T2T-ViT) series models. In terms of model performance,
Xception has the best classification performance, the ViT model consumes the
least time for training, and the ShuffleNet-V2 model has the least number of
parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Branch with Attention Network for Hand-Based Person Recognition. (arXiv:2108.02234v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02234">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel hand-based person recognition method for
the purpose of criminal investigations since the hand image is often the only
available information in cases of serious crime such as sexual abuse. Our
proposed method, Multi-Branch with Attention Network (MBA-Net), incorporates
both channel and spatial attention modules in branches in addition to a global
(without attention) branch to capture global structural information for
discriminative feature learning. The attention modules focus on the relevant
features of the hand image while suppressing the irrelevant backgrounds. In
order to overcome the weakness of the attention mechanisms, equivariant to
pixel shuffling, we integrate relative positional encodings into the spatial
attention module to capture the spatial positions of pixels. Extensive
evaluations on two large multi-ethnic and publicly available hand datasets
demonstrate that our proposed method achieves state-of-the-art performance,
surpassing the existing hand-based identification methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras. (arXiv:2108.10869v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10869">
<div class="article-summary-box-inner">
<span><p>We introduce DROID-SLAM, a new deep learning based SLAM system. DROID-SLAM
consists of recurrent iterative updates of camera pose and pixelwise depth
through a Dense Bundle Adjustment layer. DROID-SLAM is accurate, achieving
large improvements over prior work, and robust, suffering from substantially
fewer catastrophic failures. Despite training on monocular video, it can
leverage stereo or RGB-D video to achieve improved performance at test time.
The URL to our open source code is https://github.com/princeton-vl/DROID-SLAM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging the Gap between Events and Frames through Unsupervised Domain Adaptation. (arXiv:2109.02618v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02618">
<div class="article-summary-box-inner">
<span><p>Reliable perception during fast motion maneuvers or in high dynamic range
environments is crucial for robotic systems. Since event cameras are robust to
these challenging conditions, they have great potential to increase the
reliability of robot vision. However, event-based vision has been held back by
the shortage of labeled datasets due to the novelty of event cameras. To
overcome this drawback, we propose a task transfer method to train models
directly with labeled images and unlabeled event data. Compared to previous
approaches, (i) our method transfers from single images to events instead of
high frame rate videos, and (ii) does not rely on paired sensor data. To
achieve this, we leverage the generative event model to split event features
into content and motion features. This split enables efficient matching between
latent spaces for events and images, which is crucial for successful task
transfer. Thus, our approach unlocks the vast amount of existing image datasets
for the training of event-based neural networks. Our task transfer method
consistently outperforms methods targeting Unsupervised Domain Adaptation for
object detection by 0.26 mAP (increase by 93%) and classification by 2.7%
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global-Local Dynamic Feature Alignment Network for Person Re-Identification. (arXiv:2109.05759v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05759">
<div class="article-summary-box-inner">
<span><p>The misalignment of human images caused by bounding box detection errors or
partial occlusions is one of the main challenges in person Re-Identification
(Re-ID) tasks. Previous local-based methods mainly focus on learning local
features in predefined semantic regions of pedestrians. These methods usually
use local hard alignment methods or introduce auxiliary information such as key
human pose points to match local features, which are often not applicable when
large scene differences are encountered. To solve these problems, we propose a
simple and efficient Local Sliding Alignment (LSA) strategy to dynamically
align the local features of two images by setting a sliding window on the local
stripes of the pedestrian. LSA can effectively suppress spatial misalignment
and does not need to introduce extra supervision information. Then, we design a
Global-Local Dynamic Feature Alignment Network (GLDFA-Net) framework, which
contains both global and local branches. We introduce LSA into the local branch
of GLDFA-Net to guide the computation of distance metrics, which can further
improve the accuracy of the testing phase. Evaluation experiments on several
mainstream evaluation datasets including Market-1501, DukeMTMC-reID, CUHK03 and
MSMT17 show that our method has competitive accuracy over the several
state-of-the-art person Re-ID methods. Specifically, it achieves 86.1% mAP and
94.8% Rank-1 accuracy on Market1501.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Dimensional Collapse in Contrastive Self-supervised Learning. (arXiv:2110.09348v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09348">
<div class="article-summary-box-inner">
<span><p>Self-supervised visual representation learning aims to learn useful
representations without relying on human annotations. Joint embedding approach
bases on maximizing the agreement between embedding vectors from different
views of the same image. Various methods have been proposed to solve the
collapsing problem where all embedding vectors collapse to a trivial constant
solution. Among these methods, contrastive learning prevents collapse via
negative sample pairs. It has been shown that non-contrastive methods suffer
from a lesser collapse problem of a different nature: dimensional collapse,
whereby the embedding vectors end up spanning a lower-dimensional subspace
instead of the entire available embedding space. Here, we show that dimensional
collapse also happens in contrastive learning. In this paper, we shed light on
the dynamics at play in contrastive learning that leads to dimensional
collapse. Inspired by our theory, we propose a novel contrastive learning
method, called DirectCLR, which directly optimizes the representation space
without relying on a trainable projector. Experiments show that DirectCLR
outperforms SimCLR with a trainable linear projector on ImageNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Bayesian Models for Organ Contouring in Head and Neck Radiotherapy. (arXiv:2111.01134v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01134">
<div class="article-summary-box-inner">
<span><p>Deep learning models for organ contouring in radiotherapy are poised for
clinical usage, but currently, there exist few tools for automated quality
assessment (QA) of the predicted contours. Using Bayesian models and their
associated uncertainty, one can potentially automate the process of detecting
inaccurate predictions. We investigate two Bayesian models for auto-contouring,
DropOut and FlipOut, using a quantitative measure - expected calibration error
(ECE) and a qualitative measure - region-based accuracy-vs-uncertainty (R-AvU)
graphs. It is well understood that a model should have low ECE to be considered
trustworthy. However, in a QA context, a model should also have high
uncertainty in inaccurate regions and low uncertainty in accurate regions. Such
behaviour could direct visual attention of expert users to potentially
inaccurate regions, leading to a speed up in the QA process. Using R-AvU
graphs, we qualitatively compare the behaviour of different models in accurate
and inaccurate regions. Experiments are conducted on the MICCAI2015 Head and
Neck Segmentation Challenge and on the DeepMindTCIA CT dataset using three
models: DropOut-DICE, Dropout-CE (Cross Entropy) and FlipOut-CE. Quantitative
results show that DropOut-DICE has the highest ECE, while Dropout-CE and
FlipOut-CE have the lowest ECE. To better understand the difference between
DropOut-CE and FlipOut-CE, we use the R-AvU graph which shows that FlipOut-CE
has better uncertainty coverage in inaccurate regions than DropOut-CE. Such a
combination of quantitative and qualitative metrics explores a new approach
that helps to select which model can be deployed as a QA tool in clinical
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HRNET: AI on Edge for mask detection and social distancing. (arXiv:2111.15208v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.15208">
<div class="article-summary-box-inner">
<span><p>The purpose of the paper is to provide innovative emerging technology
framework for community to combat epidemic situations. The paper proposes a
unique outbreak response system framework based on artificial intelligence and
edge computing for citizen centric services to help track and trace people
eluding safety policies like mask detection and social distancing measure in
public or workplace setup. The framework further provides implementation
guideline in industrial setup as well for governance and contact tracing tasks.
The adoption will thus lead in smart city planning and development focusing on
citizen health systems contributing to improved quality of life. The conceptual
framework presented is validated through quantitative data analysis via
secondary data collection from researcher's public websites, GitHub
repositories and renowned journals and further benchmarking were conducted for
experimental results in Microsoft Azure cloud environment. The study includes
selective AI-models for benchmark analysis and were assessed on performance and
accuracy in edge computing environment for large scale societal setup. Overall
YOLO model Outperforms in object detection task and is faster enough for mask
detection and HRNetV2 outperform semantic segmentation problem applied to solve
social distancing task in AI-Edge inferencing environmental setup. The paper
proposes new Edge-AI algorithm for building technology-oriented solutions for
detecting mask in human movement and social distance. The paper enriches the
technological advancement in artificial intelligence and edge-computing applied
to problems in society and healthcare systems. The framework further equips
government agency, system providers to design and constructs
technology-oriented models in community setup to Increase the quality of life
using emerging technologies into smart urban environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image-to-Image Translation-based Data Augmentation for Robust EV Charging Inlet Detection. (arXiv:2112.05290v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.05290">
<div class="article-summary-box-inner">
<span><p>This work addresses the task of electric vehicle (EV) charging inlet
detection for autonomous EV charging robots. Recently, automated EV charging
systems have received huge attention to improve users' experience and to
efficiently utilize charging infrastructures and parking lots. However, most
related works have focused on system design, robot control, planning, and
manipulation. Towards robust EV charging inlet detection, we propose a new
dataset (EVCI dataset) and a novel data augmentation method that is based on
image-to-image translation where typical image-to-image translation methods
synthesize a new image in a different domain given an image. To the best of our
knowledge, the EVCI dataset is the first EV charging inlet dataset. For the
data augmentation method, we focus on being able to control synthesized images'
captured environments (e.g., time, lighting) in an intuitive way. To achieve
this, we first propose the environment guide vector that humans can intuitively
interpret. We then propose a novel image-to-image translation network that
translates a given image towards the environment described by the vector.
Accordingly, it aims to synthesize a new image that has the same content as the
given image while looking like captured in the provided environment by the
environment guide vector. Lastly, we train a detection method using the
augmented dataset. Through experiments on the EVCI dataset, we demonstrate that
the proposed method outperforms the state-of-the-art methods. We also show that
the proposed method is able to control synthesized images using an image and
environment guide vectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Persistent Object Identification Leveraging Non-Visual Markers. (arXiv:2112.06809v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06809">
<div class="article-summary-box-inner">
<span><p>Our objective is to locate and provide a unique identifier for each mouse in
a cluttered home-cage environment through time, as a precursor to automated
behaviour recognition for biological research. This is a very challenging
problem due to (i) the lack of distinguishing visual features for each mouse,
and (ii) the close confines of the scene with constant occlusion, making
standard visual tracking approaches unusable. However, a coarse estimate of
each mouse's location is available from a unique RFID implant, so there is the
potential to optimally combine information from (weak) tracking with coarse
information on identity. To achieve our objective, we make the following key
contributions: (a) the formulation of the object identification problem as an
assignment problem (solved using Integer Linear Programming), and (b) a novel
probabilistic model of the affinity between tracklets and RFID data. The latter
is a crucial part of the model, as it provides a principled probabilistic
treatment of object detections given coarse localisation. Our approach achieves
77% accuracy on this animal identification problem, and is able to reject
spurious detections when the animals are hidden.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JoJoGAN: One Shot Face Stylization. (arXiv:2112.11641v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11641">
<div class="article-summary-box-inner">
<span><p>A style mapper applies some fixed style to its input images (so, for example,
taking faces to cartoons). This paper describes a simple procedure -- JoJoGAN
-- to learn a style mapper from a single example of the style. JoJoGAN uses a
GAN inversion procedure and StyleGAN's style-mixing property to produce a
substantial paired dataset from a single example style. The paired dataset is
then used to fine-tune a StyleGAN. An image can then be style mapped by
GAN-inversion followed by the fine-tuned StyleGAN. JoJoGAN needs just one
reference and as little as 30 seconds of training time. JoJoGAN can use extreme
style references (say, animal faces) successfully. Furthermore, one can control
what aspects of the style are used and how much of the style is applied.
Qualitative and quantitative evaluation show that JoJoGAN produces high quality
high resolution images that vastly outperform the current state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TPC: Transformation-Specific Smoothing for Point Cloud Models. (arXiv:2201.12733v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12733">
<div class="article-summary-box-inner">
<span><p>Point cloud models with neural network architectures have achieved great
success and have been widely used in safety-critical applications, such as
Lidar-based recognition systems in autonomous vehicles. However, such models
are shown vulnerable against adversarial attacks which aim to apply stealthy
semantic transformations such as rotation and tapering to mislead model
predictions. In this paper, we propose a transformation-specific smoothing
framework TPC, which provides tight and scalable robustness guarantees for
point cloud models against semantic transformation attacks. We first categorize
common 3D transformations into three categories: additive (e.g., shearing),
composable (e.g., rotation), and indirectly composable (e.g., tapering), and we
present generic robustness certification strategies for all categories
respectively. We then specify unique certification protocols for a range of
specific semantic transformations and their compositions. Extensive experiments
on several common 3D transformations show that TPC significantly outperforms
the state of the art. For example, our framework boosts the certified accuracy
against twisting transformation along z-axis (within 20$^\circ$) from 20.3$\%$
to 83.8$\%$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sim2Real Object-Centric Keypoint Detection and Description. (arXiv:2202.00448v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00448">
<div class="article-summary-box-inner">
<span><p>Keypoint detection and description play a central role in computer vision.
Most existing methods are in the form of scene-level prediction, without
returning the object classes of different keypoints. In this paper, we propose
the object-centric formulation, which, beyond the conventional setting,
requires further identifying which object each interest point belongs to. With
such fine-grained information, our framework enables more downstream
potentials, such as object-level matching and pose estimation in a clustered
environment. To get around the difficulty of label collection in the real
world, we develop a sim2real contrastive learning mechanism that can generalize
the model trained in simulation to real-world applications. The novelties of
our training method are three-fold: (i) we integrate the uncertainty into the
learning framework to improve feature description of hard cases, e.g.,
less-textured or symmetric patches; (ii) we decouple the object descriptor into
two output branches -- intra-object salience and inter-object distinctness,
resulting in a better pixel-wise description; (iii) we enforce cross-view
semantic consistency for enhanced robustness in representation learning.
Comprehensive experiments on image matching and 6D pose estimation verify the
encouraging generalization ability of our method from simulation to reality.
Particularly for 6D pose estimation, our method significantly outperforms
typical unsupervised/sim2real methods, achieving a closer gap with the fully
supervised counterpart. Additional results and videos can be found at
https://zhongcl-thu.github.io/rock/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Embarrassingly Simple Consistency Regularization Method for Semi-Supervised Medical Image Segmentation. (arXiv:2202.00677v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00677">
<div class="article-summary-box-inner">
<span><p>The scarcity of pixel-level annotation is a prevalent problem in medical
image segmentation tasks. In this paper, we introduce a novel regularization
strategy involving interpolation-based mixing for semi-supervised medical image
segmentation. The proposed method is a new consistency regularization strategy
that encourages segmentation of interpolation of two unlabelled data to be
consistent with the interpolation of segmentation maps of those data. This
method represents a specific type of data-adaptive regularization paradigm
which aids to minimize the overfitting of labelled data under high confidence
values. The proposed method is advantageous over adversarial and generative
models as it requires no additional computation. Upon evaluation on two
publicly available MRI datasets: ACDC and MMWHS, experimental results
demonstrate the superiority of the proposed method in comparison to existing
semi-supervised models. Code is available at:
https://github.com/hritam-98/ICT-MedSeg
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auto-Transfer: Learning to Route Transferrable Representations. (arXiv:2202.01011v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01011">
<div class="article-summary-box-inner">
<span><p>Knowledge transfer between heterogeneous source and target networks and tasks
has received a lot of attention in recent times as large amounts of quality
labelled data can be difficult to obtain in many applications. Existing
approaches typically constrain the target deep neural network (DNN) feature
representations to be close to the source DNNs feature representations, which
can be limiting. We, in this paper, propose a novel adversarial multi-armed
bandit approach which automatically learns to route source representations to
appropriate target representations following which they are combined in
meaningful ways to produce accurate target models. We see upwards of 5%
accuracy improvements compared with the state-of-the-art knowledge transfer
methods on four benchmark (target) image datasets CUB200, Stanford Dogs, MIT67,
and Stanford40 where the source dataset is ImageNet. We qualitatively analyze
the goodness of our transfer scheme by showing individual examples of the
important features our target network focuses on in different layers compared
with the (closest) competitors. We also observe that our improvement over other
methods is higher for smaller target datasets making it an effective tool for
small data applications that may benefit from transfer learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VOS: Learning What You Don't Know by Virtual Outlier Synthesis. (arXiv:2202.01197v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01197">
<div class="article-summary-box-inner">
<span><p>Out-of-distribution (OOD) detection has received much attention lately due to
its importance in the safe deployment of neural networks. One of the key
challenges is that models lack supervision signals from unknown data, and as a
result, can produce overconfident predictions on OOD data. Previous approaches
rely on real outlier datasets for model regularization, which can be costly and
sometimes infeasible to obtain in practice. In this paper, we present VOS, a
novel framework for OOD detection by adaptively synthesizing virtual outliers
that can meaningfully regularize the model's decision boundary during training.
Specifically, VOS samples virtual outliers from the low-likelihood region of
the class-conditional distribution estimated in the feature space. Alongside,
we introduce a novel unknown-aware training objective, which contrastively
shapes the uncertainty space between the ID data and synthesized outlier data.
VOS achieves state-of-the-art performance on both object detection and image
classification models, reducing the FPR95 by up to 7.87% compared to the
previous best method. Code is available at
https://github.com/deeplearning-wisc/vos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unpaired Image Super-Resolution with Optimal Transport Maps. (arXiv:2202.01116v1 [eess.IV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01116">
<div class="article-summary-box-inner">
<span><p>Real-world image super-resolution (SR) tasks often do not have paired
datasets limiting the application of supervised techniques. As a result, the
tasks are usually approached by unpaired techniques based on Generative
Adversarial Networks (GANs) which yield complex training losses with several
regularization terms such as content and identity losses. We theoretically
investigate the optimization problems which arise in such models and find two
surprising observations. First, the learned SR map is always an optimal
transport (OT) map. Second, we empirically show that the learned map is biased,
i.e., it may not actually transform the distribution of low-resolution images
to high-resolution images. Inspired by these findings, we propose an algorithm
for unpaired SR which learns an unbiased OT map for the perceptual transport
cost. Unlike existing GAN-based alternatives, our algorithm has a simple
optimization objective reducing the neccesity to perform complex hyperparameter
selection and use additional regularizations. At the same time, it provides
nearly state-of-the-art performance on the large-scale unpaired AIM-19 dataset.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-02-05 23:11:23.326905534 UTC">2022-02-05 23:11:23 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>