<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-06-08T01:30:00Z">06-08</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Job-Transition-Tag Graph for a Better Job Title Representation Learning. (arXiv:2206.02782v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02782">
<div class="article-summary-box-inner">
<span><p>Works on learning job title representation are mainly based on
\textit{Job-Transition Graph}, built from the working history of talents.
However, since these records are usually messy, this graph is very sparse,
which affects the quality of the learned representation and hinders further
analysis. To address this specific issue, we propose to enrich the graph with
additional nodes that improve the quality of job title representation.
Specifically, we construct \textit{Job-Transition-Tag Graph}, a heterogeneous
graph containing two types of nodes, i.e., job titles and tags (i.e., words
related to job responsibilities or functionalities). Along this line, we
reformulate job title representation learning as the task of learning node
embedding on the \textit{Job-Transition-Tag Graph}. Experiments on two datasets
show the interest of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FedNST: Federated Noisy Student Training for Automatic Speech Recognition. (arXiv:2206.02797v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02797">
<div class="article-summary-box-inner">
<span><p>Federated Learning (FL) enables training state-of-the-art Automatic Speech
Recognition (ASR) models on user devices (clients) in distributed systems,
hence preventing transmission of raw user data to a central server. A key
challenge facing practical adoption of FL for ASR is obtaining ground-truth
labels on the clients. Existing approaches rely on clients to manually
transcribe their speech, which is impractical for obtaining large training
corpora. A promising alternative is using semi-/self-supervised learning
approaches to leverage unlabelled user data. To this end, we propose a new
Federated ASR method called FedNST for noisy student training of distributed
ASR models with private unlabelled user data. We explore various facets of
FedNST , such as training models with different proportions of unlabelled and
labelled data, and evaluate the proposed approach on 1173 simulated clients.
Evaluating FedNST on LibriSpeech, where 960 hours of speech data is split
equally into server (labelled) and client (unlabelled) data, showed a 22.5%
relative word error rate reduction (WERR) over a supervised baseline trained
only on server data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Bird's-Eye Tutorial of Graph Attention Architectures. (arXiv:2206.02849v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02849">
<div class="article-summary-box-inner">
<span><p>Graph Neural Networks (GNNs) have shown tremendous strides in performance for
graph-structured problems especially in the domains of natural language
processing, computer vision and recommender systems. Inspired by the success of
the transformer architecture, there has been an ever-growing body of work on
attention variants of GNNs attempting to advance the state of the art in many
of these problems. Incorporating "attention" into graph mining has been viewed
as a way to overcome the noisiness, heterogenity and complexity associated with
graph-structured data as well as to encode soft-inductive bias. It is hence
crucial and advantageous to study these variants from a bird's-eye view to
assess their strengths and weaknesses. We provide a systematic and focused
tutorial centered around attention based GNNs in a hope to benefit researchers
dealing with graph-structured problems. Our tutorial looks at GNN variants from
the point of view of the attention function and iteratively builds the reader's
understanding of different graph attention variants.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">No Parameter Left Behind: How Distillation and Model Size Affect Zero-Shot Retrieval. (arXiv:2206.02873v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02873">
<div class="article-summary-box-inner">
<span><p>Recent work has shown that small distilled language models are strong
competitors to models that are orders of magnitude larger and slower in a wide
range of information retrieval tasks. This has made distilled and dense models,
due to latency constraints, the go-to choice for deployment in real-world
retrieval applications. In this work, we question this practice by showing that
the number of parameters and early query-document interaction play a
significant role in the generalization ability of retrieval models. Our
experiments show that increasing model size results in marginal gains on
in-domain test sets, but much larger gains in new domains never seen during
fine-tuning. Furthermore, we show that rerankers largely outperform dense ones
of similar size in several tasks. Our largest reranker reaches the state of the
art in 12 of the 18 datasets of the Benchmark-IR (BEIR) and surpasses the
previous state of the art by 3 average points. Finally, we confirm that
in-domain effectiveness is not a good indicator of zero-shot effectiveness.
Code is available at
https://github.com/guilhermemr04/scaling-zero-shot-retrieval.git
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Norm Participation Grounds Language. (arXiv:2206.02885v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02885">
<div class="article-summary-box-inner">
<span><p>The striking recent advances in eliciting seemingly meaningful language
behaviour from language-only machine learning models have only made more
apparent, through the surfacing of clear limitations, the need to go beyond the
language-only mode and to ground these models "in the world". Proposals for
doing so vary in the details, but what unites them is that the solution is
sought in the addition of non-linguistic data types such as images or video
streams, while largely keeping the mode of learning constant. I propose a
different, and more wide-ranging conception of how grounding should be
understood: What grounds language is its normative nature. There are standards
for doing things right, these standards are public and authoritative, while at
the same time acceptance of authority can and must be disputed and negotiated,
in interactions in which only bearers of normative status can rightfully
participate. What grounds language, then, is the determined use that language
users make of it, and what it is grounded in is the community of language
users. I sketch this idea, and draw some conclusions for work on computational
modelling of meaningful language use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discriminative Models Can Still Outperform Generative Models in Aspect Based Sentiment Analysis. (arXiv:2206.02892v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02892">
<div class="article-summary-box-inner">
<span><p>Aspect-based Sentiment Analysis (ABSA) helps to explain customers' opinions
towards products and services. In the past, ABSA models were discriminative,
but more recently generative models have been used to generate aspects and
polarities directly from text. In contrast, discriminative models commonly
first select aspects from the text, and then classify the aspect's polarity.
Previous results showed that generative models outperform discriminative models
on several English ABSA datasets. Here, we evaluate and contrast two
state-of-the-art discriminative and generative models in several settings:
cross-lingual, cross-domain, and cross-lingual and domain, to understand
generalizability in settings other than English mono-lingual in-domain. Our
more thorough evaluation shows that, contrary to previous studies,
discriminative models can still outperform generative models in almost all
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Schema-Guided Event Graph Completion. (arXiv:2206.02921v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02921">
<div class="article-summary-box-inner">
<span><p>We tackle a new task, event graph completion, which aims to predict missing
event nodes for event graphs. Existing link prediction or graph completion
methods have difficulty dealing with event graphs because they are usually
designed for a single large graph such as a social network or a knowledge
graph, rather than multiple small dynamic event graphs. Moreover, they can only
predict missing edges rather than missing nodes. In this work, we propose to
utilize event schema, a template that describes the stereotypical structure of
event graphs, to address the above issues. Our schema-guided event graph
completion approach first maps an instance event graph to a subgraph of the
schema graph by a heuristic subgraph matching algorithm. Then it predicts
whether a candidate event node in the schema graph should be added to the
instantiated schema subgraph by characterizing two types of local topology of
the schema graph: neighbors of the candidate node and the subgraph, and paths
that connect the candidate node and the subgraph. These two modules are later
combined together for the final prediction. We also propose a self-supervised
strategy to construct training samples, as well as an inference algorithm that
is specifically designed to complete event graphs. Extensive experimental
results on four datasets demonstrate that our proposed method achieves
state-of-the-art performance, with 4.3% to 19.4% absolute F1 gains over the
best baseline method on the four datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neuro-Symbolic Causal Language Planning with Commonsense Prompting. (arXiv:2206.02928v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02928">
<div class="article-summary-box-inner">
<span><p>Language planning aims to implement complex high-level goals by decomposition
into sequential simpler low-level steps. Such procedural reasoning ability is
essential for applications such as household robots and virtual assistants.
Although language planning is a basic skill set for humans in daily life, it
remains a challenge for large language models (LLMs) that lack deep-level
commonsense knowledge in the real world. Previous methods require either manual
exemplars or annotated programs to acquire such ability from LLMs. In contrast,
this paper proposes Neuro-Symbolic Causal Language Planner (CLAP) that elicits
procedural knowledge from the LLMs with commonsense-infused prompting.
Pre-trained knowledge in LLMs is essentially an unobserved confounder that
causes spurious correlations between tasks and action plans. Through the lens
of a Structural Causal Model (SCM), we propose an effective strategy in CLAP to
construct prompts as a causal intervention toward our SCM. Using graph sampling
techniques and symbolic program executors, our strategy formalizes the
structured causal prompts from commonsense knowledge bases. CLAP obtains
state-of-the-art performance on WikiHow and RobotHow, achieving a relative
improvement of 5.28% in human evaluations under the counterfactual setting.
This indicates the superiority of CLAP in causal language planning semantically
and sequentially.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Knowledge Graph Embedding via Iterative Self-Semantic Knowledge Distillation. (arXiv:2206.02963v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02963">
<div class="article-summary-box-inner">
<span><p>Knowledge graph embedding (KGE) has been intensively investigated for link
prediction by projecting entities and relations into continuous vector spaces.
Current popular high-dimensional KGE methods obtain quite slight performance
gains while require enormous computation and memory costs. In contrast to
high-dimensional KGE models, training low-dimensional models is more efficient
and worthwhile for better deployments to practical intelligent systems.
However, the model expressiveness of semantic information in knowledge graphs
(KGs) is highly limited in the low dimension parameter space. In this paper, we
propose iterative self-semantic knowledge distillation strategy to improve the
KGE model expressiveness in the low dimension space. KGE model combined with
our proposed strategy plays the teacher and student roles alternatively during
the whole training process. Specifically, at a certain iteration, the model is
regarded as a teacher to provide semantic information for the student. At next
iteration, the model is regard as a student to incorporate the semantic
information transferred from the teacher. We also design a novel semantic
extraction block to extract iteration-based semantic information for the
training model self-distillation. Iteratively incorporating and accumulating
iteration-based semantic information enables the low-dimensional model to be
more expressive for better link prediction in KGs. There is only one model
during the whole training, which alleviates the increase of computational
expensiveness and memory requirements. Furthermore, the proposed strategy is
model-agnostic and can be seamlessly combined with other KGE models. Consistent
and significant performance gains in experimental evaluations on four standard
datasets demonstrate the effectiveness of the proposed self-distillation
strategy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Dual-Encoders with Question and Answer Cross-Embeddings for Answer Retrieval. (arXiv:2206.02978v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02978">
<div class="article-summary-box-inner">
<span><p>Dual-Encoders is a promising mechanism for answer retrieval in question
answering (QA) systems. Currently most conventional Dual-Encoders learn the
semantic representations of questions and answers merely through matching
score. Researchers proposed to introduce the QA interaction features in scoring
function but at the cost of low efficiency in inference stage. To keep
independent encoding of questions and answers during inference stage,
variational auto-encoder is further introduced to reconstruct answers
(questions) from question (answer) embeddings as an auxiliary task to enhance
QA interaction in representation learning in training stage. However, the needs
of text generation and answer retrieval are different, which leads to hardness
in training. In this work, we propose a framework to enhance the Dual-Encoders
model with question answer cross-embeddings and a novel Geometry Alignment
Mechanism (GAM) to align the geometry of embeddings from Dual-Encoders with
that from Cross-Encoders. Extensive experimental results show that our
framework significantly improves Dual-Encoders model and outperforms the
state-of-the-art method on multiple answer retrieval datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DynaMaR: Dynamic Prompt with Mask Token Representation. (arXiv:2206.02982v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02982">
<div class="article-summary-box-inner">
<span><p>Recent research has shown that large language models pretrained using
unsupervised approaches can achieve significant performance improvement on many
downstream tasks. Typically when adapting these language models to downstream
tasks, like a classification or regression task, we employ a fine-tuning
paradigm in which the sentence representation from the language model is input
to a task-specific head; the model is then fine-tuned end-to-end. However, with
the emergence of models like GPT-3, prompt-based fine-tuning has been proven to
be a successful approach for few-shot tasks. Inspired by this work, we study
discrete prompt technologies in practice. There are two issues that arise with
the standard prompt approach. First, it can overfit on the prompt template.
Second, it requires manual effort to formulate the downstream task as a
language model problem. In this paper, we propose an improvement to
prompt-based fine-tuning that addresses these two issues. We refer to our
approach as DynaMaR -- Dynamic Prompt with Mask Token Representation. Results
show that DynaMaR can achieve an average improvement of 10% in few-shot
settings and improvement of 3.7% in data-rich settings over the standard
fine-tuning approach on four e-commerce applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Insight into The Intricacies of Lingual Paraphrasing Pragmatic Discourse on The Purpose of Synonyms. (arXiv:2206.02983v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02983">
<div class="article-summary-box-inner">
<span><p>The term "paraphrasing" refers to the process of presenting the sense of an
input text in a new way while preserving fluency. Scientific research
distribution is gaining traction, allowing both rookie and experienced
scientists to participate in their respective fields. As a result, there is now
a massive demand for paraphrase tools that may efficiently and effectively
assist scientists in modifying statements in order to avoid plagiarism. Natural
Language Processing (NLP) is very much important in the realm of the process of
document paraphrasing. We analyze and discuss existing studies on paraphrasing
in the English language in this paper. Finally, we develop an algorithm to
paraphrase any text document or paragraphs using WordNet and Natural Language
Tool Kit (NLTK) and maintain "Using Synonyms" techniques to achieve our result.
For 250 paragraphs, our algorithm achieved a paraphrase accuracy of 94.8%
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiMS: Distilling Multiple Steps of Iterative Non-Autoregressive Transformers. (arXiv:2206.02999v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02999">
<div class="article-summary-box-inner">
<span><p>The computational benefits of iterative non-autoregressive transformers
decrease as the number of decoding steps increases. As a remedy, we introduce
Distill Multiple Steps (DiMS), a simple yet effective distillation technique to
decrease the number of required steps to reach a certain translation quality.
The distilled model enjoys the computational benefits of early iterations while
preserving the enhancements from several iterative steps. DiMS relies on two
models namely student and teacher. The student is optimized to predict the
output of the teacher after multiple decoding steps while the teacher follows
the student via a slow-moving average. The moving average keeps the teacher's
knowledge updated and enhances the quality of the labels provided by the
teacher. During inference, the student is used for translation and no
additional computation is added. We verify the effectiveness of DiMS on various
models obtaining improvements of up to 7 BLEU points on distilled and 12 BLEU
points on raw WMT datasets for single-step translation. We release our code at
https://github.com/layer6ai-labs/DiMS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plot Writing From Pre-Trained Language Models. (arXiv:2206.03021v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03021">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) fail to generate long-form narrative text
because they do not consider global structure. As a result, the generated texts
are often incohesive, repetitive, or lack content. Recent work in story
generation reintroduced explicit content planning in the form of prompts,
keywords, or semantic frames. Trained on large parallel corpora, these models
can generate more logical event sequences and thus more contentful stories.
However, these intermediate representations are often not in natural language
and cannot be utilized by PLMs without fine-tuning. We propose generating story
plots using off-the-shelf PLMs while maintaining the benefit of content
planning to generate cohesive and contentful stories. Our proposed method,
ScratchPlot, first prompts a PLM to compose a content plan. Then, we generate
the story's body and ending conditioned on the content plan. Furthermore, we
take a generate-and-rank approach by using additional PLMs to rank the
generated (story, ending) pairs. We benchmark our method with various baselines
and achieved superior results in both human and automatic evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OCHADAI at SemEval-2022 Task 2: Adversarial Training for Multilingual Idiomaticity Detection. (arXiv:2206.03025v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03025">
<div class="article-summary-box-inner">
<span><p>We propose a multilingual adversarial training model for determining whether
a sentence contains an idiomatic expression. Given that a key challenge with
this task is the limited size of annotated data, our model relies on
pre-trained contextual representations from different multi-lingual
state-of-the-art transformer-based language models (i.e., multilingual BERT and
XLM-RoBERTa), and on adversarial training, a training method for further
enhancing model generalization and robustness. Without relying on any
human-crafted features, knowledge bases, or additional datasets other than the
target datasets, our model achieved competitive results and ranked 6th place in
SubTask A (zero-shot) setting and 15th place in SubTask A (one-shot) setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CitySpec: An Intelligent Assistant System for Requirement Specification in Smart Cities. (arXiv:2206.03132v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03132">
<div class="article-summary-box-inner">
<span><p>An increasing number of monitoring systems have been developed in smart
cities to ensure that real-time operations of a city satisfy safety and
performance requirements. However, many existing city requirements are written
in English with missing, inaccurate, or ambiguous information. There is a high
demand for assisting city policy makers in converting human-specified
requirements to machine-understandable formal specifications for monitoring
systems. To tackle this limitation, we build CitySpec, the first intelligent
assistant system for requirement specification in smart cities. To create
CitySpec, we first collect over 1,500 real-world city requirements across
different domains from over 100 cities and extract city-specific knowledge to
generate a dataset of city vocabulary with 3,061 words. We also build a
translation model and enhance it through requirement synthesis and develop a
novel online learning framework with validation under uncertainty. The
evaluation results on real-world city requirements show that CitySpec increases
the sentence-level accuracy of requirement specification from 59.02% to 86.64%,
and has strong adaptability to a new city and a new domain (e.g., F1 score for
requirements in Seattle increases from 77.6% to 93.75% with online learning).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intra-agent speech permits zero-shot task acquisition. (arXiv:2206.03139v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03139">
<div class="article-summary-box-inner">
<span><p>Human language learners are exposed to a trickle of informative,
context-sensitive language, but a flood of raw sensory data. Through both
social language use and internal processes of rehearsal and practice, language
learners are able to build high-level, semantic representations that explain
their perceptions. Here, we take inspiration from such processes of "inner
speech" in humans (Vygotsky, 1934) to better understand the role of intra-agent
speech in embodied behavior. First, we formally pose intra-agent speech as a
semi-supervised problem and develop two algorithms that enable visually
grounded captioning with little labeled language data. We then experimentally
compute scaling curves over different amounts of labeled data and compare the
data efficiency against a supervised learning baseline. Finally, we incorporate
intra-agent speech into an embodied, mobile manipulator agent operating in a 3D
virtual world, and show that with as few as 150 additional image captions,
intra-agent speech endows the agent with the ability to manipulate and answer
questions about a new object without any related task-directed experience
(zero-shot). Taken together, our experiments suggest that modelling intra-agent
speech is effective in enabling embodied agents to learn new tasks efficiently
and without direct interaction experience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speaker-Guided Encoder-Decoder Framework for Emotion Recognition in Conversation. (arXiv:2206.03173v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03173">
<div class="article-summary-box-inner">
<span><p>The emotion recognition in conversation (ERC) task aims to predict the
emotion label of an utterance in a conversation. Since the dependencies between
speakers are complex and dynamic, which consist of intra- and inter-speaker
dependencies, the modeling of speaker-specific information is a vital role in
ERC. Although existing researchers have proposed various methods of speaker
interaction modeling, they cannot explore dynamic intra- and inter-speaker
dependencies jointly, leading to the insufficient comprehension of context and
further hindering emotion prediction. To this end, we design a novel speaker
modeling scheme that explores intra- and inter-speaker dependencies jointly in
a dynamic manner. Besides, we propose a Speaker-Guided Encoder-Decoder (SGED)
framework for ERC, which fully exploits speaker information for the decoding of
emotion. We use different existing methods as the conversational context
encoder of our framework, showing the high scalability and flexibility of the
proposed framework. Experimental results demonstrate the superiority and
effectiveness of SGED.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fooling Explanations in Text Classifiers. (arXiv:2206.03178v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03178">
<div class="article-summary-box-inner">
<span><p>State-of-the-art text classification models are becoming increasingly reliant
on deep neural networks (DNNs). Due to their black-box nature, faithful and
robust explanation methods need to accompany classifiers for deployment in
real-life scenarios. However, it has been shown in vision applications that
explanation methods are susceptible to local, imperceptible perturbations that
can significantly alter the explanations without changing the predicted
classes. We show here that the existence of such perturbations extends to text
classifiers as well. Specifically, we introduceTextExplanationFooler (TEF), a
novel explanation attack algorithm that alters text input samples imperceptibly
so that the outcome of widely-used explanation methods changes considerably
while leaving classifier predictions unchanged. We evaluate the performance of
the attribution robustness estimation performance in TEF on five sequence
classification datasets, utilizing three DNN architectures and three
transformer architectures for each dataset. TEF can significantly decrease the
correlation between unchanged and perturbed input attributions, which shows
that all models and explanation methods are susceptible to TEF perturbations.
Moreover, we evaluate how the perturbations transfer to other model
architectures and attribution methods, and show that TEF perturbations are also
effective in scenarios where the target model and explanation method are
unknown. Finally, we introduce a semi-universal attack that is able to compute
fast, computationally light perturbations with no knowledge of the attacked
classifier nor explanation method. Overall, our work shows that explanations in
text classifiers are very fragile and users need to carefully address their
robustness before relying on them in critical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Governance in the Age of Large-Scale Data-Driven Language Technology. (arXiv:2206.03216v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03216">
<div class="article-summary-box-inner">
<span><p>The recent emergence and adoption of Machine Learning technology, and
specifically of Large Language Models, has drawn attention to the need for
systematic and transparent management of language data. This work proposes an
approach to global language data governance that attempts to organize data
management amongst stakeholders, values, and rights. Our proposal is informed
by prior work on distributed governance that accounts for human values and
grounded by an international research collaboration that brings together
researchers and practitioners from 60 countries. The framework we present is a
multi-party international governance structure focused on language data, and
incorporating technical and organizational tools needed to support its work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rites de Passage: Elucidating Displacement to Emplacement of Refugees. (arXiv:2206.03248v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03248">
<div class="article-summary-box-inner">
<span><p>Social media deliberations allow to explore refugee-related is-sues. AI-based
studies have investigated refugee issues mostly around a specific event and
considered unimodal approaches. Contrarily, we have employed a multimodal
architecture for probing the refugee journeys from their home to host nations.
We draw insights from Arnold van Gennep's anthropological work 'Les Rites de
Passage', which systematically analyzed an individual's transition from one
group or society to another. Based on Gennep's
separation-transition-incorporation framework, we have identified four phases
of refugee journeys: Arrival of Refugees, Temporal stay at Asylums,
Rehabilitation, and Integration of Refugees into the host nation. We collected
0.23 million multimodal tweets from April 2020 to March 2021 for testing this
proposed frame-work. We find that a combination of transformer-based language
models and state-of-the-art image recognition models, such as fusion of
BERT+LSTM and InceptionV4, can out-perform unimodal models. Subsequently, to
test the practical implication of our proposed model in real-time, we have
considered 0.01 million multimodal tweets related to the 2022 Ukrainian refugee
crisis. An F1-score of 71.88 % for this 2022 crisis confirms the
generalizability of our proposed framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LegoNN: Building Modular Encoder-Decoder Models. (arXiv:2206.03318v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03318">
<div class="article-summary-box-inner">
<span><p>State-of-the-art encoder-decoder models (e.g. for machine translation (MT) or
speech recognition (ASR)) are constructed and trained end-to-end as an atomic
unit. No component of the model can be (re-)used without the others. We
describe LegoNN, a procedure for building encoder-decoder architectures with
decoder modules that can be reused across various MT and ASR tasks, without the
need for any fine-tuning. To achieve reusability, the interface between each
encoder and decoder modules is grounded to a sequence of marginal distributions
over a discrete vocabulary pre-defined by the model designer. We present two
approaches for ingesting these marginals; one is differentiable, allowing the
flow of gradients across the entire network, and the other is
gradient-isolating. To enable portability of decoder modules between MT tasks
for different source languages and across other tasks like ASR, we introduce a
modality agnostic encoder which consists of a length control mechanism to
dynamically adapt encoders' output lengths in order to match the expected input
length range of pre-trained decoders. We present several experiments to
demonstrate the effectiveness of LegoNN models: a trained language generation
LegoNN decoder module from German-English (De-En) MT task can be reused with no
fine-tuning for the Europarl English ASR and the Romanian-English (Ro-En) MT
tasks to match or beat respective baseline models. When fine-tuned towards the
target task for few thousand updates, our LegoNN models improved the Ro-En MT
task by 1.5 BLEU points, and achieved 12.5% relative WER reduction for the
Europarl ASR task. Furthermore, to show its extensibility, we compose a LegoNN
ASR model from three modules -- each has been learned within different
end-to-end trained models on three different datasets -- boosting the WER
reduction to 19.5%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for Optimal Subword Tokenization in Cross-domain NER. (arXiv:2206.03352v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03352">
<div class="article-summary-box-inner">
<span><p>Input distribution shift is one of the vital problems in unsupervised domain
adaptation (UDA). The most popular UDA approaches focus on domain-invariant
representation learning, trying to align the features from different domains
into similar feature distributions. However, these approaches ignore the direct
alignment of input word distributions between domains, which is a vital factor
in word-level classification tasks such as cross-domain NER. In this work, we
shed new light on cross-domain NER by introducing a subword-level solution,
X-Piece, for input word-level distribution shift in NER. Specifically, we
re-tokenize the input words of the source domain to approach the target subword
distribution, which is formulated and solved as an optimal transport problem.
As this approach focuses on the input level, it can also be combined with
previous DIRL methods for further improvement. Experimental results show the
effectiveness of the proposed method based on BERT-tagger on four benchmark NER
datasets. Also, the proposed method is proved to benefit DIRL methods such as
DANN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">cViL: Cross-Lingual Training of Vision-Language Models using Knowledge Distillation. (arXiv:2206.03354v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03354">
<div class="article-summary-box-inner">
<span><p>Vision-and-language tasks are gaining popularity in the research community,
but the focus is still mainly on English. We propose a pipeline that utilizes
English-only vision-language models to train a monolingual model for a target
language. We propose to extend OSCAR+, a model which leverages object tags as
anchor points for learning image-text alignments, to train on visual question
answering datasets in different languages. We propose a novel approach to
knowledge distillation to train the model in other languages using parallel
sentences. Compared to other models that use the target language in the
pretraining corpora, we can leverage an existing English model to transfer the
knowledge to the target language using significantly lesser resources. We also
release a large-scale visual question answering dataset in Japanese and Hindi
language. Though we restrict our work to visual question answering, our model
can be extended to any sequence-level classification task, and it can be
extended to other languages as well. This paper focuses on two languages for
the visual question answering task - Japanese and Hindi. Our pipeline
outperforms the current state-of-the-art models by a relative increase of 4.4%
and 13.4% respectively in accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAAT: Relation-Augmented Attention Transformer for Relation Modeling in Document-Level Event Extraction. (arXiv:2206.03377v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03377">
<div class="article-summary-box-inner">
<span><p>In document-level event extraction (DEE) task, event arguments always scatter
across sentences (across-sentence issue) and multiple events may lie in one
document (multi-event issue). In this paper, we argue that the relation
information of event arguments is of great significance for addressing the
above two issues, and propose a new DEE framework which can model the relation
dependencies, called Relation-augmented Document-level Event Extraction
(ReDEE). More specifically, this framework features a novel and tailored
transformer, named as Relation-augmented Attention Transformer (RAAT). RAAT is
scalable to capture multi-scale and multi-amount argument relations. To further
leverage relation information, we introduce a separate event relation
prediction task and adopt multi-task learning method to explicitly enhance
event extraction performance. Extensive experiments demonstrate the
effectiveness of the proposed method, which can achieve state-of-the-art
performance on two public datasets. Our code is available at https://github.
com/TencentYoutuResearch/RAAT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tutel: Adaptive Mixture-of-Experts at Scale. (arXiv:2206.03382v1 [cs.DC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03382">
<div class="article-summary-box-inner">
<span><p>In recent years, Mixture-of-Experts (MoE) has emerged as a promising
technique for deep learning that can scale the model capacity to trillion-plus
parameters while reducing the computing cost via sparse computation. While MoE
opens a new frontier of exceedingly large models, its implementation over
thousands of GPUs has been limited due to mismatch between the dynamic nature
of MoE and static parallelism/pipelining of the system. We present Tutel, a
highly scalable stack design and implementation for MoE with dynamically
adaptive parallelism and pipelining. Tutel delivers adaptive parallelism
switching and adaptive pipelining at runtime, which achieves up to 1.74x and
2.00x single MoE layer speedup, respectively. We also propose a novel
two-dimensional hierarchical algorithm for MoE communication speedup that
outperforms the previous state-of-the-art up to 20.7x over 2,048 GPUs.
Aggregating all techniques, Tutel finally delivers 4.96x and 5.75x speedup of a
single MoE layer on 16 GPUs and 2,048 GPUs, respectively, over Fairseq: Meta's
Facebook AI Research Sequence-to-Sequence Toolkit (Tutel is now partially
adopted by Fairseq). Tutel source code is available in public:
https://github.com/microsoft/tutel . Our evaluation shows that Tutel
efficiently and effectively runs a real-world MoE-based model named SwinV2-MoE,
built upon Swin Transformer V2, a state-of-the-art computer vision
architecture. On efficiency, Tutel accelerates SwinV2-MoE, achieving up to
1.55x and 2.11x speedup in training and inference over Fairseq, respectively.
On effectiveness, the SwinV2-MoE model achieves superior accuracy in both
pre-training and down-stream computer vision tasks such as COCO object
detection than the counterpart dense model, indicating the readiness of Tutel
for end-to-end real-world model training and inference. SwinV2-MoE is open
sourced in https://github.com/microsoft/Swin-Transformer .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gender Bias in Word Embeddings: A Comprehensive Analysis of Frequency, Syntax, and Semantics. (arXiv:2206.03390v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03390">
<div class="article-summary-box-inner">
<span><p>The statistical regularities in language corpora encode well-known social
biases into word embeddings. Here, we focus on gender to provide a
comprehensive analysis of group-based biases in widely-used static English word
embeddings trained on internet corpora (GloVe 2014, fastText 2017). Using the
Single-Category Word Embedding Association Test, we demonstrate the widespread
prevalence of gender biases that also show differences in: (1) frequencies of
words associated with men versus women; (b) part-of-speech tags in
gender-associated words; (c) semantic categories in gender-associated words;
and (d) valence, arousal, and dominance in gender-associated words.
</p>
<p>First, in terms of word frequency: we find that, of the 1,000 most frequent
words in the vocabulary, 77% are more associated with men than women, providing
direct evidence of a masculine default in the everyday language of the
English-speaking world. Second, turning to parts-of-speech: the top
male-associated words are typically verbs (e.g., fight, overpower) while the
top female-associated words are typically adjectives and adverbs (e.g., giving,
emotionally). Gender biases in embeddings also permeate parts-of-speech. Third,
for semantic categories: bottom-up, cluster analyses of the top 1,000 words
associated with each gender. The top male-associated concepts include roles and
domains of big tech, engineering, religion, sports, and violence; in contrast,
the top female-associated concepts are less focused on roles, including,
instead, female-specific slurs and sexual content, as well as appearance and
kitchen terms. Fourth, using human ratings of word valence, arousal, and
dominance from a ~20,000 word lexicon, we find that male-associated words are
higher on arousal and dominance, while female-associated words are higher on
valence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Influence of Dataset Partitioning on Dysfluency Detection Systems. (arXiv:2206.03400v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03400">
<div class="article-summary-box-inner">
<span><p>This paper empirically investigates the influence of different data splits
and splitting strategies on the performance of dysfluency detection systems.
For this, we perform experiments using wav2vec 2.0 models with a classification
head as well as support vector machines (SVM) in conjunction with the features
extracted from the wav2vec 2.0 model to detect dysfluencies. We train and
evaluate the systems with different non-speaker-exclusive and speaker-exclusive
splits of the Stuttering Events in Podcasts (SEP-28k) dataset to shed some
light on the variability of results w.r.t. to the partition method used.
Furthermore, we show that the SEP-28k dataset is dominated by only a few
speakers, making it difficult to evaluate. To remedy this problem, we created
SEP-28k-Extended (SEP-28k-E), containing semi-automatically generated speaker
and gender information for the SEP-28k corpus, and suggest different data
splits, each useful for evaluating other aspects of methods for dysfluency
detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revealing Single Frame Bias for Video-and-Language Learning. (arXiv:2206.03428v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03428">
<div class="article-summary-box-inner">
<span><p>Training an effective video-and-language model intuitively requires multiple
frames as model inputs. However, it is unclear whether using multiple frames is
beneficial to downstream tasks, and if yes, whether the performance gain is
worth the drastically-increased computation and memory costs resulting from
using more frames. In this work, we explore single-frame models for
video-and-language learning. On a diverse set of video-and-language tasks
(including text-to-video retrieval and video question answering), we show the
surprising result that, with large-scale pre-training and a proper frame
ensemble strategy at inference time, a single-frame trained model that does not
consider temporal information can achieve better performance than existing
methods that use multiple frames for training. This result reveals the
existence of a strong "static appearance bias" in popular video-and-language
datasets. Therefore, to allow for a more comprehensive evaluation of
video-and-language models, we propose two new retrieval tasks based on existing
fine-grained action recognition datasets that encourage temporal modeling. Our
code is available at https://github.com/jayleicn/singularity
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Correcting Sociodemographic Selection Biases for Population Prediction from Social Media. (arXiv:1911.03855v4 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.03855">
<div class="article-summary-box-inner">
<span><p>Social media is increasingly used for large-scale population predictions,
such as estimating community health statistics. However, social media users are
not typically a representative sample of the intended population -- a
"selection bias". Within the social sciences, such a bias is typically
addressed with restratification techniques, where observations are reweighted
according to how under- or over-sampled their socio-demographic groups are.
Yet, restratifaction is rarely evaluated for improving prediction. In this
two-part study, we first evaluate standard, "out-of-the-box" restratification
techniques, finding they provide no improvement and often even degraded
prediction accuracies across four tasks of esimating U.S. county population
health statistics from Twitter. The core reasons for degraded performance seem
to be tied to their reliance on either sparse or shrunken estimates of each
population's socio-demographics. In the second part of our study, we develop
and evaluate Robust Poststratification, which consists of three methods to
address these problems: (1) estimator redistribution to account for shrinking,
as well as (2) adaptive binning and (3) informed smoothing to handle sparse
socio-demographic estimates. We show that each of these methods leads to
significant improvement in prediction accuracies over the standard
restratification approaches. Taken together, Robust Poststratification enables
state-of-the-art prediction accuracies, yielding a 53.0% increase in variance
explained (R^2) in the case of surveyed life satisfaction, and a 17.8% average
increase across all tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Twitter Corpus of the #BlackLivesMatter Movement And Counter Protests: 2013 to 2021. (arXiv:2009.00596v3 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00596">
<div class="article-summary-box-inner">
<span><p>Black Lives Matter (BLM) is a decentralized social movement protesting
violence against Black individuals and communities, with a focus on police
brutality. The movement gained significant attention following the killings of
Ahmaud Arbery, Breonna Taylor, and George Floyd in 2020. The #BlackLivesMatter
social media hashtag has come to represent the grassroots movement, with
similar hashtags counter protesting the BLM movement, such as #AllLivesMatter,
and #BlueLivesMatter. We introduce a data set of 63.9 million tweets from 13.0
million users from over 100 countries which contain one of the following
keywords: BlackLivesMatter, AllLivesMatter, and BlueLivesMatter. This data set
contains all currently available tweets from the beginning of the BLM movement
in 2013 to 2021. We summarize the data set and show temporal trends in use of
both the BlackLivesMatter keyword and keywords associated with counter
movements. Additionally, for each keyword, we create and release a set of
Latent Dirichlet Allocation (LDA) topics (i.e., automatically clustered groups
of semantically co-occuring words) to aid researchers in identifying linguistic
patterns across the three keywords.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SummScreen: A Dataset for Abstractive Screenplay Summarization. (arXiv:2104.07091v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07091">
<div class="article-summary-box-inner">
<span><p>We introduce SummScreen, a summarization dataset comprised of pairs of TV
series transcripts and human written recaps. The dataset provides a challenging
testbed for abstractive summarization for several reasons. Plot details are
often expressed indirectly in character dialogues and may be scattered across
the entirety of the transcript. These details must be found and integrated to
form the succinct plot descriptions in the recaps. Also, TV scripts contain
content that does not directly pertain to the central plot but rather serves to
develop characters or provide comic relief. This information is rarely
contained in recaps. Since characters are fundamental to TV series, we also
propose two entity-centric evaluation metrics. Empirically, we characterize the
dataset by evaluating several methods, including neural models and those based
on nearest neighbors. An oracle extractive approach outperforms all benchmarked
models according to automatic metrics, showing that the neural models are
unable to fully exploit the input transcripts. Human evaluation and qualitative
analysis reveal that our non-oracle models are competitive with their oracle
counterparts in terms of generating faithful plot events and can benefit from
better content selectors. Both oracle and non-oracle models generate unfaithful
facts, suggesting future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SAS: Self-Augmentation Strategy for Language Model Pre-training. (arXiv:2106.07176v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07176">
<div class="article-summary-box-inner">
<span><p>The core of self-supervised learning for pre-training language models
includes pre-training task design as well as appropriate data augmentation.
Most data augmentations in language model pre-training are context-independent.
A seminal contextualized augmentation was recently proposed in ELECTRA and
achieved state-of-the-art performance by introducing an auxiliary generation
network (generator) to produce contextualized data augmentation for the
training of a main discrimination network (discriminator). This design,
however, introduces extra computation cost of the generator and a need to
adjust the relative capability between the generator and the discriminator. In
this paper, we propose a self-augmentation strategy (SAS) where a single
network is utilized for both regular pre-training and contextualized data
augmentation for the training in later epochs. Essentially, this strategy
eliminates a separate generator and uses the single network to jointly conduct
two pre-training tasks with MLM (Masked Language Modeling) and RTD (Replaced
Token Detection) heads. It avoids the challenge to search for an appropriate
size of the generator, which is critical to the performance as evidenced in
ELECTRA and its subsequent variant models. In addition, SAS is a general
strategy that can be seamlessly combined with many new techniques emerging
recently or in the future, such as the disentangled attention mechanism from
DeBERTa. Our experiments show that SAS is able to outperform ELECTRA and other
state-of-the-art models in the GLUE tasks with similar or less computation
cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Search Engines with Interactive Agents. (arXiv:2109.00527v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00527">
<div class="article-summary-box-inner">
<span><p>This paper presents first successful steps in designing search agents that
learn meta-strategies for iterative query refinement in information-seeking
tasks. Our approach uses machine reading to guide the selection of refinement
terms from aggregated search results. Agents are then empowered with simple but
effective search operators to exert fine-grained and transparent control over
queries and search results. We develop a novel way of generating synthetic
search sessions, which leverages the power of transformer-based language models
through (self-)supervised learning. We also present a reinforcement learning
agent with dynamically constrained actions that learns interactive search
strategies from scratch. Our search agents obtain retrieval and answer quality
performance comparable to recent neural methods, using only a traditional
term-based BM25 ranking function and interpretable discrete reranking and
filtering actions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Resource Named Entity Recognition Based on Multi-hop Dependency Trigger. (arXiv:2109.07118v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07118">
<div class="article-summary-box-inner">
<span><p>This paper presents a simple and effective approach in low-resource named
entity recognition (NER) based on multi-hop dependency trigger. Dependency
trigger refer to salient nodes relative to a entity in the dependency graph of
a context sentence. Our main observation is that there often exists trigger
which play an important role to recognize the location and type of entity in
sentence. Previous research has used manual labelling of trigger. Our main
contribution is to propose use a syntactic parser to automatically annotate
trigger. Experiments on two English datasets (CONLL 2003 and BC5CDR) show that
the proposed method is comparable to the previous trigger-based NER model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Theories on Styles to their Transfer in Text: Bridging the Gap with a Hierarchical Survey. (arXiv:2110.15871v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15871">
<div class="article-summary-box-inner">
<span><p>Humans are naturally endowed with the ability to write in a particular style.
They can, for instance, re-phrase a formal letter in an informal way, convey a
literal message with the use of figures of speech or edit a novel mimicking the
style of some well-known authors. Automating this form of creativity
constitutes the goal of style transfer. As a natural language generation task,
style transfer aims at rewriting existing texts, and specifically, it creates
paraphrases that exhibit some desired stylistic attributes. From a practical
perspective, it envisions beneficial applications, like chat-bots that modulate
their communicative style to appear empathetic, or systems that automatically
simplify technical articles for a non-expert audience. Several style-aware
paraphrasing methods have attempted to tackle style transfer. A handful of
surveys give a methodological overview of the field, but they do not support
researchers to focus on specific styles. With this paper, we aim at providing a
comprehensive discussion of the styles that have received attention in the
transfer task. We organize them in a hierarchy, highlighting the challenges for
the definition of each of them, and pointing out gaps in the current research
landscape. The hierarchy comprises two main groups. One encompasses styles that
people modulate arbitrarily, along the lines of registers and genres. The other
group corresponds to unintentionally expressed styles, due to an author's
personal characteristics. Hence, our review shows how these groups relate to
one another, and where specific styles, including some that have not yet been
explored, belong in the hierarchy. Moreover, we summarize the methods employed
for different stylistic families, hinting researchers towards those that would
be the most fitting for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">First is Better Than Last for Training Data Influence. (arXiv:2202.11844v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11844">
<div class="article-summary-box-inner">
<span><p>The ability to identify influential training examples enables us to debug
training data and explain model behavior. Existing techniques to do so are
based on the flow of training data influence through the model parameters. For
large models in NLP applications, it is often computationally infeasible to
study this flow through all model parameters, therefore techniques usually pick
the last layer of weights. However, we observe that since the activation
connected to the last layer of weights contains ``shared logic'', the data
influenced calculated via the last layer weights prone to a ``cancellation
effect'', where the data influence of different examples have large magnitude
that contradicts each other. The cancellation effect lowers the discriminative
power of the influence score, and deleting influential examples according to
this measure often does not change the model's behavior by much. To mitigate
this, we propose a technique called TracIn-WE that modifies a method called
TracIn to operate on the word embedding layer instead of the last layer, where
the cancellation effect is less severe. One potential concern is that influence
based on the word embedding layer may not encode sufficient high level
information. However, we find that gradients (unlike embeddings) do not suffer
from this, possibly because they chain through higher layers. We show that
TracIn-WE significantly outperforms other data influence methods applied on the
last layer by 4-10 on the case deletion evaluation on three language
classification tasks. In addition, TracIn-WE can produce scores not just at the
level of the overall training input, but also at the level of words within the
training input, a further aid in debugging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep neural networks for fine-grained surveillance of overdose mortality. (arXiv:2202.12448v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.12448">
<div class="article-summary-box-inner">
<span><p>Surveillance of drug overdose deaths relies on death certificates for
identification of the substances that caused death. Drugs and drug classes can
be identified through the International Classification of Diseases, 10th
Revision (ICD-10) codes present on death certificates. However, ICD-10 codes do
not always provide high levels of specificity in drug identification. To
achieve more fine-grained identification of substances on a death certificate,
the free-text cause of death section, completed by the medical certifier, must
be analyzed. Current methods for analyzing free-text death certificates rely
solely on look-up tables for identifying specific substances, which must be
frequently updated and maintained. To improve identification of drugs on death
certificates, a deep learning named-entity recognition model was developed,
which achieved an F1-score of 99.13%. This model can identify new drug
misspellings and novel substances that are not present on current surveillance
look-up tables, enhancing the surveillance of drug overdose deaths.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neuro-symbolic Natural Logic with Introspective Revision for Natural Language Inference. (arXiv:2203.04857v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.04857">
<div class="article-summary-box-inner">
<span><p>We introduce a neuro-symbolic natural logic framework based on reinforcement
learning with introspective revision. The model samples and rewards specific
reasoning paths through policy gradient, in which the introspective revision
algorithm modifies intermediate symbolic reasoning steps to discover
reward-earning operations as well as leverages external knowledge to alleviate
spurious reasoning and training inefficiency. The framework is supported by
properly designed local relation models to avoid input entangling, which helps
ensure the interpretability of the proof paths. The proposed model has built-in
interpretability and shows superior capability in monotonicity inference,
systematic generalization, and interpretability, compared to previous models on
the existing datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relevant CommonSense Subgraphs for "What if..." Procedural Reasoning. (arXiv:2203.11187v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.11187">
<div class="article-summary-box-inner">
<span><p>We study the challenge of learning causal reasoning over procedural text to
answer "What if..." questions when external commonsense knowledge is required.
We propose a novel multi-hop graph reasoning model to 1) efficiently extract a
commonsense subgraph with the most relevant information from a large knowledge
graph; 2) predict the causal answer by reasoning over the representations
obtained from the commonsense subgraph and the contextual interactions between
the questions and context. We evaluate our model on WIQA benchmark and achieve
state-of-the-art performance compared to the recent models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving In-Context Few-Shot Learning via Self-Supervised Training. (arXiv:2205.01703v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01703">
<div class="article-summary-box-inner">
<span><p>Self-supervised pretraining has made few-shot learning possible for many NLP
tasks. But the pretraining objectives are not typically adapted specifically
for in-context few-shot learning. In this paper, we propose to use
self-supervision in an intermediate training stage between pretraining and
downstream few-shot usage with the goal to teach the model to perform
in-context few shot learning. We propose and evaluate four self-supervised
objectives on two benchmarks. We find that the intermediate self-supervision
stage produces models that outperform strong baselines. Ablation study shows
that several factors affect the downstream performance, such as the amount of
training data and the diversity of the self-supervised objectives.
Human-annotated cross-task supervision and self-supervision are complementary.
Qualitative analysis suggests that the self-supervised-trained models are
better at following task requirements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Conditional Hidden Markov Model for Weakly Supervised Named Entity Recognition. (arXiv:2205.14228v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14228">
<div class="article-summary-box-inner">
<span><p>Weakly supervised named entity recognition methods train label models to
aggregate the token annotations of multiple noisy labeling functions (LFs)
without seeing any manually annotated labels. To work well, the label model
needs to contextually identify and emphasize well-performed LFs while
down-weighting the under-performers. However, evaluating the LFs is challenging
due to the lack of ground truths. To address this issue, we propose the sparse
conditional hidden Markov model (Sparse-CHMM). Instead of predicting the entire
emission matrix as other HMM-based methods, Sparse-CHMM focuses on estimating
its diagonal elements, which are considered as the reliability scores of the
LFs. The sparse scores are then expanded to the full-fledged emission matrix
with pre-defined expansion functions. We also augment the emission with
weighted XOR scores, which track the probabilities of an LF observing incorrect
entities. Sparse-CHMM is optimized through unsupervised learning with a
three-stage training pipeline that reduces the training difficulty and prevents
the model from falling into local optima. Compared with the baselines in the
Wrench benchmark, Sparse-CHMM achieves a 3.01 average F1 score improvement on
five comprehensive datasets. Experiments show that each component of
Sparse-CHMM is effective, and the estimated LF reliabilities strongly correlate
with true LF F1 scores.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Pre-Trained Language Models to Streamline Natural Language Interaction for Self-Tracking. (arXiv:2205.15503v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.15503">
<div class="article-summary-box-inner">
<span><p>Current natural language interaction for self-tracking tools largely depends
on bespoke implementation optimized for a specific tracking theme and data
format, which is neither generalizable nor scalable to a tremendous design
space of self-tracking. However, training machine learning models in the
context of self-tracking is challenging due to the wide variety of tracking
topics and data formats. In this paper, we propose a novel NLP task for
self-tracking that extracts close- and open-ended information from a
retrospective activity log described as a plain text, and a domain-agnostic,
GPT-3-based NLU framework that performs this task. The framework augments the
prompt using synthetic samples to transform the task into 10-shot learning, to
address a cold-start problem in bootstrapping a new tracking topic. Our
preliminary evaluation suggests that our approach significantly outperforms the
baseline QA models. Going further, we discuss future application domains toward
which the NLP and HCI researchers can collaborate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variable-rate hierarchical CPC leads to acoustic unit discovery in speech. (arXiv:2206.02211v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02211">
<div class="article-summary-box-inner">
<span><p>The success of deep learning comes from its ability to capture the
hierarchical structure of data by learning high-level representations defined
in terms of low-level ones. In this paper we explore self-supervised learning
of hierarchical representations of speech by applying multiple levels of
Contrastive Predictive Coding (CPC). We observe that simply stacking two CPC
models does not yield significant improvements over single-level architectures.
Inspired by the fact that speech is often described as a sequence of discrete
units unevenly distributed in time, we propose a model in which the output of a
low-level CPC module is non-uniformly downsampled to directly minimize the loss
of a high-level CPC module. The latter is designed to also enforce a prior of
separability and discreteness in its representations by enforcing dissimilarity
of successive high-level representations through focused negative sampling, and
by quantization of the prediction targets. Accounting for the structure of the
speech signal improves upon single-level CPC features and enhances the
disentanglement of the learned representations, as measured by downstream
speech recognition tasks, while resulting in a meaningful segmentation of the
signal that closely resembles phone boundaries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Advance of Making Language Models Better Reasoners. (arXiv:2206.02336v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02336">
<div class="article-summary-box-inner">
<span><p>Large language models such as GPT-3 and PaLM have shown remarkable
performance in few-shot learning. However, they still struggle with reasoning
tasks such as the arithmetic benchmark GSM8K. Recent advances deliberately
guide the language model to generate a chain of reasoning steps before
producing the final answer, successfully boosting the GSM8K benchmark from
17.9% to 58.1% in terms of problem solving rate. In this paper, we propose a
new approach, DiVeRSe (Diverse Verifier on Reasoning Step), to further advance
their reasoning capability. DiVeRSe first explores different prompts to enhance
the diversity in reasoning paths. Second, DiVeRSe introduces a verifier to
distinguish good answers from bad answers for a better weighted voting.
Finally, DiVeRSe verifies the correctness of each single step rather than all
the steps in a whole. We conduct extensive experiments using the latest
language model code-davinci-002 and demonstrate that DiVeRSe can achieve new
state-of-the-art performance on six out of eight reasoning benchmarks (e.g.,
GSM8K 74.4% to 83.2%), outperforming the PaLM model with 540B parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UTTS: Unsupervised TTS with Conditional Disentangled Sequential Variational Auto-encoder. (arXiv:2206.02512v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02512">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel unsupervised text-to-speech (UTTS)
framework which does not require text-audio pairs for the TTS acoustic modeling
(AM). UTTS is a multi-speaker speech synthesizer developed from the perspective
of disentangled speech representation learning. The framework offers a flexible
choice of a speaker's duration model, timbre feature (identity) and content for
TTS inference. We leverage recent advancements in self-supervised speech
representation learning as well as speech synthesis front-end techniques for
the system development. Specifically, we utilize a lexicon to map input text to
the phoneme sequence, which is expanded to the frame-level forced alignment
(FA) with a speaker-dependent duration model. Then, we develop an alignment
mapping module that converts the FA to the unsupervised alignment (UA).
Finally, a Conditional Disentangled Sequential Variational Auto-encoder
(C-DSVAE), serving as the self-supervised TTS AM, takes the predicted UA and a
target speaker embedding to generate the mel spectrogram, which is ultimately
converted to waveform with a neural vocoder. We show how our method enables
speech synthesis without using a paired TTS corpus. Experiments demonstrate
that UTTS can synthesize speech of high naturalness and intelligibility
measured by human and objective evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Dysfluencies in Stuttering Therapy Using wav2vec 2.0. (arXiv:2204.03417v1 [eess.AS] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03417">
<div class="article-summary-box-inner">
<span><p>Stuttering is a varied speech disorder that harms an individual's
communication ability. Persons who stutter (PWS) often use speech therapy to
cope with their condition. Improving speech recognition systems for people with
such non-typical speech or tracking the effectiveness of speech therapy would
require systems that can detect dysfluencies while at the same time being able
to detect speech techniques acquired in therapy.
</p>
<p>This paper shows that fine-tuning wav2vec 2.0 for the classification of
stuttering on a sizeable English corpus containing stuttered speech, in
conjunction with multi-task learning, boosts the effectiveness of the
general-purpose wav2vec 2.0 features for detecting stuttering in speech; both
within and across languages. We evaluate our method on Fluencybank and the
German therapy-centric Kassel State of Fluency (KSoF) dataset by training
Support Vector Machine classifiers using features extracted from the fine-tuned
models for six different stuttering-related events types: blocks,
prolongations, sound repetitions, word repetitions, interjections, and -
specific to therapy - speech modifications. Using embeddings from the
fine-tuned models leads to relative classification performance gains up to 27\%
w.r.t. F1-score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Vocal Fatigue with Neural Embeddings. (arXiv:2204.03428v1 [eess.AS] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03428">
<div class="article-summary-box-inner">
<span><p>Vocal fatigue refers to the feeling of tiredness and weakness of voice due to
extended utilization. This paper investigates the effectiveness of neural
embeddings for the detection of vocal fatigue. We compare x-vectors,
ECAPA-TDNN, and wav2vec 2.0 embeddings on a corpus of academic spoken English.
Low-dimensional mappings of the data reveal that neural embeddings capture
information about the change in vocal characteristics of a speaker during
prolonged voice usage. We show that vocal fatigue can be reliably predicted
using all three kinds of neural embeddings after only 50 minutes of continuous
speaking when temporal smoothing and normalization are applied to the extracted
embeddings. We employ support vector machines for classification and achieve
accuracy scores of 81% using x-vectors, 85% using ECAPA-TDNN embeddings, and
82% using wav2vec 2.0 embeddings as input features. We obtain an accuracy score
of 76%, when the trained system is applied to a different speaker and recording
environment without any adaptation.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">FIFA: Making Fairness More Generalizable in Classifiers Trained on Imbalanced Data. (arXiv:2206.02792v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02792">
<div class="article-summary-box-inner">
<span><p>Algorithmic fairness plays an important role in machine learning and imposing
fairness constraints during learning is a common approach. However, many
datasets are imbalanced in certain label classes (e.g. "healthy") and sensitive
subgroups (e.g. "older patients"). Empirically, this imbalance leads to a lack
of generalizability not only of classification, but also of fairness
properties, especially in over-parameterized models. For example,
fairness-aware training may ensure equalized odds (EO) on the training data,
but EO is far from being satisfied on new users. In this paper, we propose a
theoretically-principled, yet Flexible approach that is
Imbalance-Fairness-Aware (FIFA). Specifically, FIFA encourages both
classification and fairness generalization and can be flexibly combined with
many existing fair learning methods with logits-based losses. While our main
focus is on EO, FIFA can be directly applied to achieve equalized opportunity
(EqOpt); and under certain conditions, it can also be applied to other fairness
notions. We demonstrate the power of FIFA by combining it with a popular fair
classification algorithm, and the resulting algorithm achieves significantly
better fairness generalization on several real-world datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FedNST: Federated Noisy Student Training for Automatic Speech Recognition. (arXiv:2206.02797v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02797">
<div class="article-summary-box-inner">
<span><p>Federated Learning (FL) enables training state-of-the-art Automatic Speech
Recognition (ASR) models on user devices (clients) in distributed systems,
hence preventing transmission of raw user data to a central server. A key
challenge facing practical adoption of FL for ASR is obtaining ground-truth
labels on the clients. Existing approaches rely on clients to manually
transcribe their speech, which is impractical for obtaining large training
corpora. A promising alternative is using semi-/self-supervised learning
approaches to leverage unlabelled user data. To this end, we propose a new
Federated ASR method called FedNST for noisy student training of distributed
ASR models with private unlabelled user data. We explore various facets of
FedNST , such as training models with different proportions of unlabelled and
labelled data, and evaluate the proposed approach on 1173 simulated clients.
Evaluating FedNST on LibriSpeech, where 960 hours of speech data is split
equally into server (labelled) and client (unlabelled) data, showed a 22.5%
relative word error rate reduction (WERR) over a supervised baseline trained
only on server data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EVC-Net: Multi-scale V-Net with Conditional Random Fields for Brain Extraction. (arXiv:2206.02837v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02837">
<div class="article-summary-box-inner">
<span><p>Brain extraction is one of the first steps of pre-processing 3D brain MRI
data. It is a prerequisite for any forthcoming brain imaging analyses. However,
it is not a simple segmentation problem due to the complex structure of the
brain and human head. Although multiple solutions have been proposed in the
literature, we are still far from having truly robust methods. While previous
methods have used machine learning with structural/geometric priors, with the
development of deep learning in computer vision tasks, there has been an
increase in proposed convolutional neural network architectures for this
semantic segmentation task. Yet, most models focus on improving the training
data and loss functions with little change in the architecture. In this paper,
we propose a novel architecture we call EVC-Net. EVC-Net adds lower scale
inputs on each encoder block. This enhances the multi-scale scheme of the V-Net
architecture, hence increasing the efficiency of the model. Conditional Random
Fields, a popular approach for image segmentation before the deep learning era,
are re-introduced here as an additional step for refining the network's output
to capture fine-grained results in segmentation. We compare our model to
state-of-the-art methods such as HD-BET, Synthstrip and brainy. Results show
that even with limited training resources, EVC-Net achieves higher Dice
Coefficient and Jaccard Index along with lower surface distance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Invertible Sharpening Network for MRI Reconstruction Enhancement. (arXiv:2206.02838v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02838">
<div class="article-summary-box-inner">
<span><p>High-quality MRI reconstruction plays a critical role in clinical
applications. Deep learning-based methods have achieved promising results on
MRI reconstruction. However, most state-of-the-art methods were designed to
optimize the evaluation metrics commonly used for natural images, such as PSNR
and SSIM, whereas the visual quality is not primarily pursued. Compared to the
fully-sampled images, the reconstructed images are often blurry, where
high-frequency features might not be sharp enough for confident clinical
diagnosis. To this end, we propose an invertible sharpening network
(InvSharpNet) to improve the visual quality of MRI reconstructions. During
training, unlike the traditional methods that learn to map the input data to
the ground truth, InvSharpNet adapts a backward training strategy that learns a
blurring transform from the ground truth (fully-sampled image) to the input
data (blurry reconstruction). During inference, the learned blurring transform
can be inverted to a sharpening transform leveraging the network's
invertibility. The experiments on various MRI datasets demonstrate that
InvSharpNet can improve reconstruction sharpness with few artifacts. The
results were also evaluated by radiologists, indicating better visual quality
and diagnostic confidence of our proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial Acoustic Projection for 3D Imaging Sonar Reconstruction. (arXiv:2206.02840v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02840">
<div class="article-summary-box-inner">
<span><p>In this work we present a novel method for reconstructing 3D surfaces using a
multi-beam imaging sonar. We integrate the intensities measured by the sonar
from different viewpoints for fixed cell positions in a 3D grid. For each cell
we integrate a feature vector that holds the mean intensity for a discretized
range of viewpoints. Based on the feature vectors and independent sparse range
measurements that act as ground truth information, we train convolutional
neural networks that allow us to predict the signed distance and direction to
the nearest surface for each cell. The predicted signed distances can be
projected into a truncated signed distance field (TSDF) along the predicted
directions. Utilizing the marching cubes algorithm, a polygon mesh can be
rendered from the TSDF. Our method allows a dense 3D reconstruction from a
limited set of viewpoints and was evaluated on three real-world datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying Static vs. Dynamic Information. (arXiv:2206.02846v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02846">
<div class="article-summary-box-inner">
<span><p>Deep spatiotemporal models are used in a variety of computer vision tasks,
such as action recognition and video object segmentation. Currently, there is a
limited understanding of what information is captured by these models in their
intermediate representations. For example, while it has been observed that
action recognition algorithms are heavily influenced by visual appearance in
single static frames, there is no quantitative methodology for evaluating such
static bias in the latent representation compared to bias toward dynamic
information (e.g. motion). We tackle this challenge by proposing a novel
approach for quantifying the static and dynamic biases of any spatiotemporal
model. To show the efficacy of our approach, we analyse two widely studied
tasks, action recognition and video object segmentation. Our key findings are
threefold: (i) Most examined spatiotemporal models are biased toward static
information; although, certain two-stream architectures with cross-connections
show a better balance between the static and dynamic information captured. (ii)
Some datasets that are commonly assumed to be biased toward dynamics are
actually biased toward static information. (iii) Individual units (channels) in
an architecture can be biased toward static, dynamic or a combination of the
two.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Potential of SAR Data for Cloud Removal in Optical Satellite Imagery. (arXiv:2206.02850v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02850">
<div class="article-summary-box-inner">
<span><p>The challenge of the cloud removal task can be alleviated with the aid of
Synthetic Aperture Radar (SAR) images that can penetrate cloud cover. However,
the large domain gap between optical and SAR images as well as the severe
speckle noise of SAR images may cause significant interference in SAR-based
cloud removal, resulting in performance degeneration. In this paper, we propose
a novel global-local fusion based cloud removal (GLF-CR) algorithm to leverage
the complementary information embedded in SAR images. Exploiting the power of
SAR information to promote cloud removal entails two aspects. The first, global
fusion, guides the relationship among all local optical windows to maintain the
structure of the recovered region consistent with the remaining cloud-free
regions. The second, local fusion, transfers complementary information embedded
in the SAR image that corresponds to cloudy areas to generate reliable texture
details of the missing regions, and uses dynamic filtering to alleviate the
performance degradation caused by speckle noise. Extensive evaluation
demonstrates that the proposed algorithm can yield high quality cloud-free
images and performs favorably against state-of-the-art cloud removal
algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SpikiLi: A Spiking Simulation of LiDAR based Real-time Object Detection for Autonomous Driving. (arXiv:2206.02876v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02876">
<div class="article-summary-box-inner">
<span><p>Spiking Neural Networks are a recent and new neural network design approach
that promises tremendous improvements in power efficiency, computation
efficiency, and processing latency. They do so by using asynchronous
spike-based data flow, event-based signal generation, processing, and modifying
the neuron model to resemble biological neurons closely. While some initial
works have shown significant initial evidence of applicability to common deep
learning tasks, their applications in complex real-world tasks has been
relatively low. In this work, we first illustrate the applicability of spiking
neural networks to a complex deep learning task namely Lidar based 3D object
detection for automated driving. Secondly, we make a step-by-step demonstration
of simulating spiking behavior using a pre-trained convolutional neural
network. We closely model essential aspects of spiking neural networks in
simulation and achieve equivalent run-time and accuracy on a GPU. When the
model is realized on a neuromorphic hardware, we expect to have significantly
improved power efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mesh-based Dynamics with Occlusion Reasoning for Cloth Manipulation. (arXiv:2206.02881v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02881">
<div class="article-summary-box-inner">
<span><p>Self-occlusion is challenging for cloth manipulation, as it makes it
difficult to estimate the full state of the cloth. Ideally, a robot trying to
unfold a crumpled or folded cloth should be able to reason about the cloth's
occluded regions. We leverage recent advances in pose estimation for cloth to
build a system that uses explicit occlusion reasoning to unfold a crumpled
cloth. Specifically, we first learn a model to reconstruct the mesh of the
cloth. However, the model will likely have errors due to the complexities of
the cloth configurations and due to ambiguities from occlusions. Our main
insight is that we can further refine the predicted reconstruction by
performing test-time finetuning with self-supervised losses. The obtained
reconstructed mesh allows us to use a mesh-based dynamics model for planning
while reasoning about occlusions. We evaluate our system both on cloth
flattening as well as on cloth canonicalization, in which the objective is to
manipulate the cloth into a canonical pose. Our experiments show that our
method significantly outperforms prior methods that do not explicitly account
for occlusions or perform test-time optimization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Polymorphic-GAN: Generating Aligned Samples across Multiple Domains with Learned Morph Maps. (arXiv:2206.02903v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02903">
<div class="article-summary-box-inner">
<span><p>Modern image generative models show remarkable sample quality when trained on
a single domain or class of objects. In this work, we introduce a generative
adversarial network that can simultaneously generate aligned image samples from
multiple related domains. We leverage the fact that a variety of object classes
share common attributes, with certain geometric differences. We propose
Polymorphic-GAN which learns shared features across all domains and a
per-domain morph layer to morph shared features according to each domain. In
contrast to previous works, our framework allows simultaneous modelling of
images with highly varying geometries, such as images of human faces, painted
and artistic faces, as well as multiple different animal faces. We demonstrate
that our model produces aligned samples for all domains and show how it can be
used for applications such as segmentation transfer and cross-domain image
editing, as well as training in low-data regimes. Additionally, we apply our
Polymorphic-GAN on image-to-image translation tasks and show that we can
greatly surpass previous approaches in cases where the geometric differences
between domains are large.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Treatment Plan Representations for Content Based Image Retrieval. (arXiv:2206.02912v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02912">
<div class="article-summary-box-inner">
<span><p>Objective: Knowledge based planning (KBP) typically involves training an
end-to-end deep learning model to predict dose distributions. However, training
end-to-end KBP methods may be associated with practical limitations due to the
limited size of medical datasets that are often used. To address these
limitations, we propose a content based image retrieval (CBIR) method for
retrieving dose distributions of previously planned patients based on
anatomical similarity. Approach: Our proposed CBIR method trains a
representation model that produces latent space embeddings of a patient's
anatomical information. The latent space embeddings of new patients are then
compared against those of previous patients in a database for image retrieval
of dose distributions. Summary metrics (e.g. dose-volume histogram, conformity
index, homogeneity index, etc.) are computed and can then be utilized in
subsequent automated planning. All source code for this project is available on
github. Main Results: The retrieval performance of various CBIR methods is
evaluated on a dataset consisting of both publicly available plans and clinical
plans from our institution. This study compares various encoding methods,
ranging from simple autoencoders to more recent Siamese networks like SimSiam,
and the best performance was observed for the multitask Siamese network.
Significance: Applying CBIR to inform subsequent treatment planning potentially
addresses many limitations associated with end-to-end KBP. Our current results
demonstrate that excellent image retrieval performance can be obtained through
slight changes to previously developed Siamese networks. We hope to integrate
CBIR into automated planning workflow in future works, potentially through
methods like the MetaPlanner framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks. (arXiv:2206.02916v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02916">
<div class="article-summary-box-inner">
<span><p>We propose an algorithm that compresses the critical information of a large
dataset into compact addressable memories. These memories can then be recalled
to quickly re-train a neural network and recover the performance (instead of
storing and re-training on the full original dataset).
</p>
<p>Building upon the dataset distillation framework, we make a key observation
that a shared common representation allows for more efficient and effective
distillation. Concretely, we learn a set of bases (aka "memories") which are
shared between classes and combined through learned flexible addressing
functions to generate a diverse set of training examples. This leads to several
benefits: 1) the size of compressed data does not necessarily grow linearly
with the number of classes; 2) an overall higher compression rate with more
effective distillation is achieved; and 3) more generalized queries are allowed
beyond recalling the original classes.
</p>
<p>We demonstrate state-of-the-art results on the dataset distillation task
across five benchmarks, including up to 16.5% and 9.7% in retained accuracy
improvement when distilling CIFAR10 and CIFAR100 respectively. We then leverage
our framework to perform continual learning, achieving state-of-the-art results
on four benchmarks, with 23.2% accuracy improvement on MANY.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Faithfulness: A Framework to Characterize and Compare Saliency Methods. (arXiv:2206.02958v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02958">
<div class="article-summary-box-inner">
<span><p>Saliency methods calculate how important each input feature is to a machine
learning model's prediction, and are commonly used to understand model
reasoning. "Faithfulness", or how fully and accurately the saliency output
reflects the underlying model, is an oft-cited desideratum for these methods.
However, explanation methods must necessarily sacrifice certain information in
service of user-oriented goals such as simplicity. To that end, and akin to
performance metrics, we frame saliency methods as abstractions: individual
tools that provide insight into specific aspects of model behavior and entail
tradeoffs. Using this framing, we describe a framework of nine dimensions to
characterize and compare the properties of saliency methods. We group these
dimensions into three categories that map to different phases of the
interpretation process: methodology, or how the saliency is calculated;
sensitivity, or relationships between the saliency result and the underlying
model or input; and, perceptibility, or how a user interprets the result. As we
show, these dimensions give us a granular vocabulary for describing and
comparing saliency methods -- for instance, allowing us to develop "saliency
cards" as a form of documentation, or helping downstream users understand
tradeoffs and choose a method for a particular use case. Moreover, by situating
existing saliency methods within this framework, we identify opportunities for
future work, including filling gaps in the landscape and developing new
evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HMRNet: High and Multi-Resolution Network with Bidirectional Feature Calibration for Brain Structure Segmentation in Radiotherapy. (arXiv:2206.02959v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02959">
<div class="article-summary-box-inner">
<span><p>Accurate segmentation of Anatomical brain Barriers to Cancer spread (ABCs)
plays an important role for automatic delineation of Clinical Target Volume
(CTV) of brain tumors in radiotherapy. Despite that variants of U-Net are
state-of-the-art segmentation models, they have limited performance when
dealing with ABCs structures with various shapes and sizes, especially thin
structures (e.g., the falx cerebri) that span only few slices. To deal with
this problem, we propose a High and Multi-Resolution Network (HMRNet) that
consists of a multi-scale feature learning branch and a high-resolution branch,
which can maintain the high-resolution contextual information and extract more
robust representations of anatomical structures with various scales. We further
design a Bidirectional Feature Calibration (BFC) block to enable the two
branches to generate spatial attention maps for mutual feature calibration.
Considering the different sizes and positions of ABCs structures, our network
was applied after a rough localization of each structure to obtain fine
segmentation results. Experiments on the MICCAI 2020 ABCs challenge dataset
showed that: 1) Our proposed two-stage segmentation strategy largely
outperformed methods segmenting all the structures in just one stage; 2) The
proposed HMRNet with two branches can maintain high-resolution representations
and is effective to improve the performance on thin structures; 3) The proposed
BFC block outperformed existing attention methods using monodirectional feature
calibration. Our method won the second place of ABCs 2020 challenge and has a
potential for more accurate and reasonable delineation of CTV of brain tumors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masked Unsupervised Self-training for Zero-shot Image Classification. (arXiv:2206.02967v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02967">
<div class="article-summary-box-inner">
<span><p>State-of-the-art computer vision models are mostly trained with supervised
learning using human-labeled images, which limits their scalability due to the
expensive annotation cost. While self-supervised representation learning has
achieved impressive progress, it still requires a second stage of finetuning on
labeled data. On the other hand, models pre-trained with large-scale text-image
supervision (e.g., CLIP) have enabled zero-shot transfer to downstream image
classification tasks. However, the zero-shot performance of CLIP-like models
are often insufficient for real-world adoption. In this paper, we aim to
leverage the abundant unlabeled data to improve the performance of a
pre-trained zero-shot classifier on downstream tasks. We propose Masked
Unsupervised Self-Training (MUST), a new approach which leverages two different
and complimentary sources of supervision: pseudo-labels and raw images. MUST
jointly optimizes three objectives to learn both class-level global feature and
pixel-level local feature and enforces a regularization between the two. We
demonstrate the efficacy of MUST on 8 downstream tasks across a variety of
domains, where it improves upon CLIP by a large margin and narrows the
performance gap between unsupervised and supervised classification. For
instance, MUST achieves a zero-shot top-1 accuracy of 77.7% on ImageNet using
ViT-B, +9.4% higher than CLIP. Our code is available at
https://github.com/salesforce/MUST.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DETR++: Taming Your Multi-Scale Detection Transformer. (arXiv:2206.02977v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02977">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks (CNN) have dominated the field of detection
ever since the success of AlexNet in ImageNet classification [12]. With the
sweeping reform of Transformers [27] in natural language processing, Carion et
al. [2] introduce the Transformer-based detection method, i.e., DETR. However,
due to the quadratic complexity in the self-attention mechanism in the
Transformer, DETR is never able to incorporate multi-scale features as
performed in existing CNN-based detectors, leading to inferior results in small
object detection. To mitigate this issue and further improve performance of
DETR, in this work, we investigate different methods to incorporate multi-scale
features and find that a Bi-directional Feature Pyramid (BiFPN) works best with
DETR in further raising the detection precision. With this discovery, we
propose DETR++, a new architecture that improves detection results by 1.9% AP
on MS COCO 2017, 11.5% AP on RICO icon detection, and 9.1% AP on RICO layout
extraction over existing baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Context Transformer for Generic Event Boundary Detection. (arXiv:2206.02985v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02985">
<div class="article-summary-box-inner">
<span><p>Generic Event Boundary Detection (GEBD) aims to detect moments where humans
naturally perceive as event boundaries. In this paper, we present Structured
Context Transformer (or SC-Transformer) to solve the GEBD task, which can be
trained in an end-to-end fashion. Specifically, we use the backbone
convolutional neural network (CNN) to extract the features of each video frame.
To capture temporal context information of each frame, we design the structure
context transformer (SC-Transformer) by re-partitioning input frame sequence.
Note that, the overall computation complexity of SC-Transformer is linear to
the video length. After that, the group similarities are computed to capture
the differences between frames. Then, a lightweight fully convolutional network
is used to determine the event boundaries based on the grouped similarity maps.
To remedy the ambiguities of boundary annotations, the Gaussian kernel is
adopted to preprocess the ground-truth event boundaries to further boost the
accuracy. Extensive experiments conducted on the challenging Kinetics-GEBD and
TAPOS datasets demonstrate the effectiveness of the proposed method compared to
the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TadML: A fast temporal action detection with Mechanics-MLP. (arXiv:2206.02997v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02997">
<div class="article-summary-box-inner">
<span><p>Temporal Action Detection(TAD) is a crucial but challenging task in video
understanding.It is aimed at detecting both the type and start-end frame for
each action instance in a long, untrimmed video.Most current models adopt both
RGB and Optical-Flow streams for the TAD task. Thus, original RGB frames must
be converted manually into Optical-Flow frames with additional computation and
time cost, which is an obstacle to achieve real-time processing. At present,
many models adopt two-stage strategies, which would slow the inference speed
down and complicatedly tuning on proposals generating.By comparison, we propose
a one-stage anchor-free temporal localization method with RGB stream only, in
which a novel Newtonian \emph{Mechanics-MLP} architecture is established. It
has comparable accuracy with all existing state-of-the-art models, while
surpasses the inference speed of these methods by a large margin. The typical
inference speed in this paper is astounding 4.44 video per second on THUMOS14.
In applications, because there is no need to convert optical flow, the
inference speed will be faster.It also proves that \emph{MLP} has great
potential in downstream tasks such as TAD. The source code is available at
\url{https://github.com/BonedDeng/TadML}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR System. (arXiv:2206.03001v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03001">
<div class="article-summary-box-inner">
<span><p>Optical character recognition (OCR) technology has been widely used in
various scenes, as shown in Figure 1. Designing a practical OCR system is still
a meaningful but challenging task. In previous work, considering the efficiency
and accuracy, we proposed a practical ultra lightweight OCR system (PP-OCR),
and an optimized version PP-OCRv2. In order to further improve the performance
of PP-OCRv2, a more robust OCR system PP-OCRv3 is proposed in this paper.
PP-OCRv3 upgrades the text detection model and text recognition model in 9
aspects based on PP-OCRv2. For text detector, we introduce a PAN module with
large receptive field named LK-PAN, a FPN module with residual attention
mechanism named RSE-FPN, and DML distillation strategy. For text recognizer,
the base model is replaced from CRNN to SVTR, and we introduce lightweight text
recognition network SVTR LCNet, guided training of CTC by attention, data
augmentation strategy TextConAug, better pre-trained model by self-supervised
TextRotNet, UDML, and UIM to accelerate the model and improve the effect.
Experiments on real data show that the hmean of PP-OCRv3 is 5% higher than
PP-OCRv2 under comparable inference speed. All the above mentioned models are
open-sourced and the code is available in the GitHub repository PaddleOCR which
is powered by PaddlePaddle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-based Personalized Attention Mechanism (PersAM) for Medical Images with Clinical Records. (arXiv:2206.03003v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03003">
<div class="article-summary-box-inner">
<span><p>In medical image diagnosis, identifying the attention region, i.e., the
region of interest for which the diagnosis is made, is an important task.
Various methods have been developed to automatically identify target regions
from given medical images. However, in actual medical practice, the diagnosis
is made based not only on the images but also on a variety of clinical records.
This means that pathologists examine medical images with some prior knowledge
of the patients and that the attention regions may change depending on the
clinical records. In this study, we propose a method called the Personalized
Attention Mechanism (PersAM), by which the attention regions in medical images
are adaptively changed according to the clinical records. The primary idea of
the PersAM method is to encode the relationships between the medical images and
clinical records using a variant of Transformer architecture. To demonstrate
the effectiveness of the PersAM method, we applied it to a large-scale digital
pathology problem of identifying the subtypes of 842 malignant lymphoma
patients based on their gigapixel whole slide images and clinical records.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Knowledge Distillation based Self-Supervised Learning for Covid-19 Detection from Chest X-Ray Images. (arXiv:2206.03009v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03009">
<div class="article-summary-box-inner">
<span><p>The global outbreak of the Coronavirus 2019 (COVID-19) has overloaded
worldwide healthcare systems. Computer-aided diagnosis for COVID-19 fast
detection and patient triage is becoming critical. This paper proposes a novel
self-knowledge distillation based self-supervised learning method for COVID-19
detection from chest X-ray images. Our method can use self-knowledge of images
based on similarities of their visual features for self-supervised learning.
Experimental results show that our method achieved an HM score of 0.988, an AUC
of 0.999, and an accuracy of 0.957 on the largest open COVID-19 chest X-ray
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MS-RNN: A Flexible Multi-Scale Framework for Spatiotemporal Predictive Learning. (arXiv:2206.03010v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03010">
<div class="article-summary-box-inner">
<span><p>Spatiotemporal predictive learning is to predict future frames changes
through historical prior knowledge. Previous work improves prediction
performance by making the network wider and deeper, but this also brings huge
memory overhead, which seriously hinders the development and application of the
technology. Scale is another dimension to improve model performance in common
computer vision task, which can decrease the computing requirements and better
sense of context. Such an important improvement point has not been considered
and explored by recent RNN models. In this paper, learning from the benefit of
multi-scale, we propose a general framework named Multi-Scale RNN (MS-RNN) to
boost recent RNN models. We verify the MS-RNN framework by exhaustive
experiments on 4 different datasets (Moving MNIST, KTH, TaxiBJ, and HKO-7) and
multiple popular RNN models (ConvLSTM, TrajGRU, PredRNN, PredRNN++, MIM, and
MotionRNN). The results show the efficiency that the RNN models incorporating
our framework have much lower memory cost but better performance than before.
Our code is released at \url{https://github.com/mazhf/MS-RNN}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TriBYOL: Triplet BYOL for Self-Supervised Representation Learning. (arXiv:2206.03012v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03012">
<div class="article-summary-box-inner">
<span><p>This paper proposes a novel self-supervised learning method for learning
better representations with small batch sizes. Many self-supervised learning
methods based on certain forms of the siamese network have emerged and received
significant attention. However, these methods need to use large batch sizes to
learn good representations and require heavy computational resources. We
present a new triplet network combined with a triple-view loss to improve the
performance of self-supervised representation learning with small batch sizes.
Experimental results show that our method can drastically outperform
state-of-the-art self-supervised learning methods on several datasets in
small-batch cases. Our method provides a feasible solution for self-supervised
learning with real-world high-resolution images that uses small batch sizes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Devil is in the Labels: Noisy Label Correction for Robust Scene Graph Generation. (arXiv:2206.03014v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03014">
<div class="article-summary-box-inner">
<span><p>Unbiased SGG has achieved significant progress over recent years. However,
almost all existing SGG models have overlooked the ground-truth annotation
qualities of prevailing SGG datasets, i.e., they always assume: 1) all the
manually annotated positive samples are equally correct; 2) all the
un-annotated negative samples are absolutely background. In this paper, we
argue that both assumptions are inapplicable to SGG: there are numerous "noisy"
groundtruth predicate labels that break these two assumptions, and these noisy
samples actually harm the training of unbiased SGG models. To this end, we
propose a novel model-agnostic NoIsy label CorrEction strategy for SGG: NICE.
NICE can not only detect noisy samples but also reassign more high-quality
predicate labels to them. After the NICE training, we can obtain a cleaner
version of SGG dataset for model training. Specifically, NICE consists of three
components: negative Noisy Sample Detection (Neg-NSD), positive NSD (Pos-NSD),
and Noisy Sample Correction (NSC). Firstly, in Neg-NSD, we formulate this task
as an out-of-distribution detection problem, and assign pseudo labels to all
detected noisy negative samples. Then, in Pos-NSD, we use a clustering-based
algorithm to divide all positive samples into multiple sets, and treat the
samples in the noisiest set as noisy positive samples. Lastly, in NSC, we use a
simple but effective weighted KNN to reassign new predicate labels to noisy
positive samples. Extensive results on different backbones and tasks have
attested to the effectiveness and generalization abilities of each component of
NICE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Development of Automatic Endotracheal Tube and Carina Detection on Portable Supine Chest Radiographs using Artificial Intelligence. (arXiv:2206.03017v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03017">
<div class="article-summary-box-inner">
<span><p>The image quality of portable supine chest radiographs is inherently poor due
to low contrast and high noise. The endotracheal intubation detection requires
the locations of the endotracheal tube (ETT) tip and carina. The goal is to
find the distance between the ETT tip and the carina in chest radiography. To
overcome such a problem, we propose a feature extraction method with Mask
R-CNN. The Mask R-CNN predicts a tube and a tracheal bifurcation in an image.
Then, the feature extraction method is used to find the feature point of the
ETT tip and that of the carina. Therefore, the ETT-carina distance can be
obtained. In our experiments, our results can exceed 96\% in terms of recall
and precision. Moreover, the object error is less than $4.7751\pm 5.3420$ mm,
and the ETT-carina distance errors are less than $5.5432\pm 6.3100$ mm. The
external validation shows that the proposed method is a high-robustness system.
According to the Pearson correlation coefficient, we have a strong correlation
between the board-certified intensivists and our result in terms of ETT-carina
distance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Techniques for Visual Counting. (arXiv:2206.03033v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03033">
<div class="article-summary-box-inner">
<span><p>In this thesis, I investigated and enhanced the visual counting task, which
automatically estimates the number of objects in still images or video frames.
Recently, due to the growing interest in it, several CNN-based solutions have
been suggested by the scientific community. These artificial neural networks
provide a way to automatically learn effective representations from raw visual
data and can be successfully employed to address typical challenges
characterizing this task, such as different illuminations and object scales.
But apart from these difficulties, I targeted some other crucial limitations in
the adoption of CNNs, proposing solutions that I experimentally evaluated in
the context of the counting task which turns out to be particularly affected by
these shortcomings.
</p>
<p>In particular, I tackled the problem related to the lack of data needed for
training current CNN-based solutions. Given that the budget for labeling is
limited, data scarcity still represents an open problem, particularly evident
in tasks such as the counting one, where the objects to be labeled are
thousands per image. Specifically, I introduced synthetic datasets gathered
from virtual environments, where the training labels are automatically
collected. I proposed Domain Adaptation strategies aiming at mitigating the
domain gap existing between the training and test data distributions. I
presented a counting strategy where I took advantage of the redundant
information characterizing datasets labeled by multiple annotators. Moreover, I
tackled the engineering challenges coming out of the adoption of CNN techniques
in environments with limited power resources. I introduced solutions for
counting vehicles directly onboard embedded vision systems. Finally, I designed
an embedded modular Computer Vision-based system that can carry out several
tasks to help monitor individual and collective human safety rules.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVIDx CT-3: A Large-scale, Multinational, Open-Source Benchmark Dataset for Computer-aided COVID-19 Screening from Chest CT Images. (arXiv:2206.03043v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03043">
<div class="article-summary-box-inner">
<span><p>Computed tomography (CT) has been widely explored as a COVID-19 screening and
assessment tool to complement RT-PCR testing. To assist radiologists with
CT-based COVID-19 screening, a number of computer-aided systems have been
proposed; however, many proposed systems are built using CT data which is
limited in both quantity and diversity. Motivated to support efforts in the
development of machine learning-driven screening systems, we introduce COVIDx
CT-3, a large-scale multinational benchmark dataset for detection of COVID-19
cases from chest CT images. COVIDx CT-3 includes 431,205 CT slices from 6,068
patients across at least 17 countries, which to the best of our knowledge
represents the largest, most diverse dataset of COVID-19 CT images in
open-access form. Additionally, we examine the data diversity and potential
biases of the COVIDx CT-3 dataset, finding that significant geographic and
class imbalances remain despite efforts to curate data from a wide variety of
sources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layered Depth Refinement with Mask Guidance. (arXiv:2206.03048v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03048">
<div class="article-summary-box-inner">
<span><p>Depth maps are used in a wide range of applications from 3D rendering to 2D
image effects such as Bokeh. However, those predicted by single image depth
estimation (SIDE) models often fail to capture isolated holes in objects and/or
have inaccurate boundary regions. Meanwhile, high-quality masks are much easier
to obtain, using commercial auto-masking tools or off-the-shelf methods of
segmentation and matting or even by manual editing. Hence, in this paper, we
formulate a novel problem of mask-guided depth refinement that utilizes a
generic mask to refine the depth prediction of SIDE models. Our framework
performs layered refinement and inpainting/outpainting, decomposing the depth
map into two separate layers signified by the mask and the inverse mask. As
datasets with both depth and mask annotations are scarce, we propose a
self-supervised learning scheme that uses arbitrary masks and RGB-D datasets.
We empirically show that our method is robust to different types of masks and
initial depth predictions, accurately refining depth values in inner and outer
mask boundary regions. We further analyze our model with an ablation study and
demonstrate results on real applications. More information can be found at
https://sooyekim.github.io/MaskDepth/ .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Siamese Encoder-based Spatial-Temporal Mixer for Growth Trend Prediction of Lung Nodules on CT Scans. (arXiv:2206.03049v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03049">
<div class="article-summary-box-inner">
<span><p>In the management of lung nodules, we are desirable to predict nodule
evolution in terms of its diameter variation on Computed Tomography (CT) scans
and then provide a follow-up recommendation according to the predicted result
of the growing trend of the nodule. In order to improve the performance of
growth trend prediction for lung nodules, it is vital to compare the changes of
the same nodule in consecutive CT scans. Motivated by this, we screened out
4,666 subjects with more than two consecutive CT scans from the National Lung
Screening Trial (NLST) dataset to organize a temporal dataset called NLSTt. In
specific, we first detect and pair regions of interest (ROIs) covering the same
nodule based on registered CT scans. After that, we predict the texture
category and diameter size of the nodules through models. Last, we annotate the
evolution class of each nodule according to its changes in diameter. Based on
the built NLSTt dataset, we propose a siamese encoder to simultaneously exploit
the discriminative features of 3D ROIs detected from consecutive CT scans. Then
we novelly design a spatial-temporal mixer (STM) to leverage the interval
changes of the same nodule in sequential 3D ROIs and capture spatial
dependencies of nodule regions and the current 3D ROI. According to the
clinical diagnosis routine, we employ hierarchical loss to pay more attention
to growing nodules. The extensive experiments on our organized dataset
demonstrate the advantage of our proposed method. We also conduct experiments
on an in-house dataset to evaluate the clinical utility of our method by
comparing it against skilled clinicians.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial Parsing and Dynamic Temporal Pooling networks for Human-Object Interaction detection. (arXiv:2206.03061v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03061">
<div class="article-summary-box-inner">
<span><p>The key of Human-Object Interaction(HOI) recognition is to infer the
relationship between human and objects. Recently, the image's Human-Object
Interaction(HOI) detection has made significant progress. However, there is
still room for improvement in video HOI detection performance. Existing
one-stage methods use well-designed end-to-end networks to detect a video
segment and directly predict an interaction.
</p>
<p>It makes the model learning and further optimization of the network more
complex. This paper introduces the Spatial Parsing and Dynamic Temporal Pooling
(SPDTP) network, which takes the entire video as a spatio-temporal graph with
human and object nodes as input. Unlike existing methods, our proposed network
predicts the difference between interactive and non-interactive pairs through
explicit spatial parsing, and then performs interaction recognition. Moreover,
we propose a learnable and differentiable Dynamic Temporal Module(DTM) to
emphasize the keyframes of the video and suppress the redundant frame.
Furthermore, the experimental results show that SPDTP can pay more attention to
active human-object pairs and valid keyframes. Overall, we achieve
state-of-the-art performance on CAD-120 dataset and Something-Else dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object Scan Context: Object-centric Spatial Descriptor for Place Recognition within 3D Point Cloud Map. (arXiv:2206.03062v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03062">
<div class="article-summary-box-inner">
<span><p>Place recognition technology endows a SLAM algorithm with the ability to
eliminate accumulated errors and to relocalize itself. Existing methods on
point cloud-based place recognition often leverage the matching of global
descriptors which are lidar-centric. These methods have the following two major
defects: place recognition cannot be performed when the distance between the
two point clouds is far, and only the rotation angle can be calculated without
the offset in the X and Y direction. To solve these two problems, we propose a
novel global descriptor, which is built around the Main Object, in this way,
descriptors are no longer dependent on the observation position. We analyze the
theory that this method can perfectly solve the above two problems, and conduct
a lot of experiments in KITTI and some extreme scenarios, which show that our
method has obvious advantages over traditional methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Minimum Efforts to Build an End-to-End Spatial-Temporal Action Detector. (arXiv:2206.03064v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03064">
<div class="article-summary-box-inner">
<span><p>Spatial-temporal action detection is a vital part of video understanding.
Current spatial-temporal action detection methods will first use an object
detector to obtain person candidate proposals. Then, the model will classify
the person candidates into different action categories. So-called two-stage
methods are heavy and hard to apply in real-world applications. Some existing
methods use a unified model structure, But they perform badly with the vanilla
model and often need extra modules to boost the performance. In this paper, we
explore the strategy to build an end-to-end spatial-temporal action detector
with minimal modifications. To this end, we propose a new method named ME-STAD,
which solves the spatial-temporal action detection problem in an end-to-end
manner. Besides the model design, we propose a novel labeling strategy to deal
with sparse annotations in spatial-temporal datasets. The proposed ME-STAD
achieves better results (2.2% mAP boost) than original two-stage detectors and
around 80% FLOPs reduction. Moreover, our proposed ME-STAD only has minimum
modifications with previous methods and does not require extra components. Our
code will be made public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recent Advances for Quantum Neural Networks in Generative Learning. (arXiv:2206.03066v1 [quant-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03066">
<div class="article-summary-box-inner">
<span><p>Quantum computers are next-generation devices that hold promise to perform
calculations beyond the reach of classical computers. A leading method towards
achieving this goal is through quantum machine learning, especially quantum
generative learning. Due to the intrinsic probabilistic nature of quantum
mechanics, it is reasonable to postulate that quantum generative learning
models (QGLMs) may surpass their classical counterparts. As such, QGLMs are
receiving growing attention from the quantum physics and computer science
communities, where various QGLMs that can be efficiently implemented on
near-term quantum machines with potential computational advantages are
proposed. In this paper, we review the current progress of QGLMs from the
perspective of machine learning. Particularly, we interpret these QGLMs,
covering quantum circuit born machines, quantum generative adversarial
networks, quantum Boltzmann machines, and quantum autoencoders, as the quantum
extension of classical generative learning models. In this context, we explore
their intrinsic relation and their fundamental differences. We further
summarize the potential applications of QGLMs in both conventional machine
learning tasks and quantum physics. Last, we discuss the challenges and further
research directions for QGLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pushing the Limits of Learning-based Traversability Analysis for Autonomous Driving on CPU. (arXiv:2206.03083v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03083">
<div class="article-summary-box-inner">
<span><p>Self-driving vehicles and autonomous ground robots require a reliable and
accurate method to analyze the traversability of the surrounding environment
for safe navigation. This paper proposes and evaluates a real-time machine
learning-based Traversability Analysis method that combines geometric features
with appearance-based features in a hybrid approach based on a SVM classifier.
In particular, we show that integrating a new set of geometric and visual
features and focusing on important implementation details enables a noticeable
boost in performance and reliability. The proposed approach has been compared
with state-of-the-art Deep Learning approaches on a public dataset of outdoor
driving scenarios. It reaches an accuracy of 89.2% in scenarios of varying
complexity, demonstrating its effectiveness and robustness. The method runs
fully on CPU and reaches comparable results with respect to the other methods,
operates faster, and requires fewer hardware resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Deep Clustering with Video Track Consistency. (arXiv:2206.03086v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03086">
<div class="article-summary-box-inner">
<span><p>Several unsupervised and self-supervised approaches have been developed in
recent years to learn visual features from large-scale unlabeled datasets.
Their main drawback however is that these methods are hardly able to recognize
visual features of the same object if it is simply rotated or the perspective
of the camera changes. To overcome this limitation and at the same time exploit
a useful source of supervision, we take into account video object tracks.
Following the intuition that two patches in a track should have similar visual
representations in a learned feature space, we adopt an unsupervised
clustering-based approach and constrain such representations to be labeled as
the same category since they likely belong to the same object or object part.
Experimental results on two downstream tasks on different datasets demonstrate
the effectiveness of our Online Deep Clustering with Video Track Consistency
(ODCT) approach compared to prior work, which did not leverage temporal
information. In addition we show that exploiting an unsupervised
class-agnostic, yet noisy, track generator yields to better accuracy compared
to relying on costly and precise track annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Critical Regularizations for Neural Surface Reconstruction in the Wild. (arXiv:2206.03087v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03087">
<div class="article-summary-box-inner">
<span><p>Neural implicit functions have recently shown promising results on surface
reconstructions from multiple views. However, current methods still suffer from
excessive time complexity and poor robustness when reconstructing unbounded or
complex scenes. In this paper, we present RegSDF, which shows that proper point
cloud supervisions and geometry regularizations are sufficient to produce
high-quality and robust reconstruction results. Specifically, RegSDF takes an
additional oriented point cloud as input, and optimizes a signed distance field
and a surface light field within a differentiable rendering framework. We also
introduce the two critical regularizations for this optimization. The first one
is the Hessian regularization that smoothly diffuses the signed distance values
to the entire distance field given noisy and incomplete input. And the second
one is the minimal surface regularization that compactly interpolates and
extrapolates the missing geometry. Extensive experiments are conducted on DTU,
BlendedMVS, and Tanks and Temples datasets. Compared with recent neural surface
reconstruction approaches, RegSDF is able to reconstruct surfaces with fine
details even for open scenes with complex topologies and unstructured camera
trajectories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Swin-Transformer based Mutual Interactive Network for RGB-D Salient Object Detection. (arXiv:2206.03105v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03105">
<div class="article-summary-box-inner">
<span><p>Salient Object Detection is the task of predicting the human attended region
in a given scene. Fusing depth information has been proven effective in this
task. The main challenge of this problem is how to aggregate the complementary
information from RGB modality and depth modality. However, conventional deep
models heavily rely on CNN feature extractors, and the long-range contextual
dependencies are usually ignored. In this work, we propose Dual
Swin-Transformer based Mutual Interactive Network. We adopt Swin-Transformer as
the feature extractor for both RGB and depth modality to model the long-range
dependencies in visual inputs. Before fusing the two branches of features into
one, attention-based modules are applied to enhance features from each
modality. We design a self-attention-based cross-modality interaction module
and a gated modality attention module to leverage the complementary information
between the two modalities. For the saliency decoding, we create different
stages enhanced with dense connections and keep a decoding memory while the
multi-level encoding features are considered simultaneously. Considering the
inaccurate depth map issue, we collect the RGB features of early stages into a
skip convolution module to give more guidance from RGB modality to the final
saliency prediction. In addition, we add edge supervision to regularize the
feature learning process. Comprehensive experiments on five standard RGB-D SOD
benchmark datasets over four evaluation metrics demonstrate the superiority of
the proposed DTMINet method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MIRNF: Medical Image Registration via Neural Fields. (arXiv:2206.03111v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03111">
<div class="article-summary-box-inner">
<span><p>Image registration is widely used in medical image analysis to provide
spatial correspondences between two images. Recently learning-based methods
utilizing convolutional neural networks (CNNs) have been proposed for solving
image registration problems. The learning-based methods tend to be much faster
than traditional optimization-based methods, but the accuracy improvements
gained from the complex CNN-based methods are modest. Here we introduce a new
deep-neural net-based image registration framework, named \textbf{MIRNF}, which
represents the correspondence mapping with a continuous function implemented
via Neural Fields. MIRNF outputs either a deformation vector or velocity vector
given a 3D coordinate as input. To ensure the mapping is diffeomorphic, the
velocity vector output from MIRNF is integrated using the Neural ODE solver to
derive the correspondences between two images. Furthermore, we propose a hybrid
coordinate sampler along with a cascaded architecture to achieve the
high-similarity mapping performance and low-distortion deformation fields. We
conduct experiments on two 3D MR brain scan datasets, showing that our proposed
framework provides state-of-art registration performance while maintaining
comparable optimization time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Wavelet Prior Attention Learning in Axial Inpainting Network. (arXiv:2206.03113v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03113">
<div class="article-summary-box-inner">
<span><p>Image inpainting is the task of filling masked or unknown regions of an image
with visually realistic contents, which has been remarkably improved by Deep
Neural Networks (DNNs) recently. Essentially, as an inverse problem, the
inpainting has the underlying challenges of reconstructing semantically
coherent results without texture artifacts. Many previous efforts have been
made via exploiting attention mechanisms and prior knowledge, such as edges and
semantic segmentation. However, these works are still limited in practice by an
avalanche of learnable prior parameters and prohibitive computational burden.
To this end, we propose a novel model -- Wavelet prior attention learning in
Axial Inpainting Network (WAIN), whose generator contains the encoder, decoder,
as well as two key components of Wavelet image Prior Attention (WPA) and
stacked multi-layer Axial-Transformers (ATs). Particularly, the WPA guides the
high-level feature aggregation in the multi-scale frequency domain, alleviating
the textual artifacts. Stacked ATs employ unmasked clues to help model
reasonable features along with low-level features of horizontal and vertical
axes, improving the semantic coherence. Extensive quantitative and qualitative
experiments on Celeba-HQ and Places2 datasets are conducted to validate that
our WAIN can achieve state-of-the-art performance over the competitors. The
codes and models will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Training of Handwritten Word Recognition for Synthetic-to-Real Adaptation. (arXiv:2206.03149v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03149">
<div class="article-summary-box-inner">
<span><p>Performances of Handwritten Text Recognition (HTR) models are largely
determined by the availability of labeled and representative training samples.
However, in many application scenarios labeled samples are scarce or costly to
obtain. In this work, we propose a self-training approach to train a HTR model
solely on synthetic samples and unlabeled data. The proposed training scheme
uses an initial model trained on synthetic data to make predictions for the
unlabeled target dataset. Starting from this initial model with rather poor
performance, we show that a considerable adaptation is possible by training
against the predicted pseudo-labels. Moreover, the investigated self-training
strategy does not require any manually annotated training samples. We evaluate
the proposed method on four widely used benchmark datasets and show its
effectiveness on closing the gap to a model trained in a fully-supervised
manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Utility of Equivariant Message Passing in Cortical Mesh Segmentation. (arXiv:2206.03164v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03164">
<div class="article-summary-box-inner">
<span><p>The automated segmentation of cortical areas has been a long-standing
challenge in medical image analysis. The complex geometry of the cortex is
commonly represented as a polygon mesh, whose segmentation can be addressed by
graph-based learning methods. When cortical meshes are misaligned across
subjects, current methods produce significantly worse segmentation results,
limiting their ability to handle multi-domain data. In this paper, we
investigate the utility of E(n)-equivariant graph neural networks (EGNNs),
comparing their performance against plain graph neural networks (GNNs). Our
evaluation shows that GNNs outperform EGNNs on aligned meshes, due to their
ability to leverage the presence of a global coordinate system. On misaligned
meshes, the performance of plain GNNs drop considerably, while E(n)-equivariant
message passing maintains the same segmentation results. The best results can
also be obtained by using plain GNNs on realigned data (co-registered meshes in
a global coordinate system).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Image Captioning with Control Signal of Sentence Quality. (arXiv:2206.03196v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03196">
<div class="article-summary-box-inner">
<span><p>In the dataset of image captioning, each image is aligned with several
captions. Despite the fact that the quality of these descriptions varies,
existing captioning models treat them equally in the training process. In this
paper, we propose a new control signal of sentence quality, which is taken as
an additional input to the captioning model. By integrating the control signal
information, captioning models are aware of the quality level of the target
sentences and handle them differently. Moreover, we propose a novel
reinforcement training method specially designed for the control signal of
sentence quality: Quality-oriented Self-Annotated Training (Q-SAT). Equipped
with R-Drop strategy, models controlled by the highest quality level surpass
baseline models a lot on accuracy-based evaluation metrics, which validates the
effectiveness of our proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Omnivision forecasting: combining satellite observations with sky images for improved intra-hour solar energy predictions. (arXiv:2206.03207v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03207">
<div class="article-summary-box-inner">
<span><p>Integration of intermittent renewable energy sources into electric grids in
large proportions is challenging. A well-established approach aimed at
addressing this difficulty involves the anticipation of the upcoming energy
supply variability to adapt the response of the grid. In solar energy,
short-term changes in electricity production caused by occluding clouds can be
predicted at different time scales from all-sky cameras (up to 30-min ahead)
and satellite observations (up to 6h ahead). In this study, we integrate these
two complementary points of view on the cloud cover in a single machine
learning framework to improve intra-hour (up to 60-min ahead) irradiance
forecasting. Both deterministic and probabilistic predictions are evaluated in
different weather conditions (clear-sky, cloudy, overcast) and with different
input configurations (sky images, satellite observations and/or past irradiance
values). Our results show that the hybrid model benefits predictions in
clear-sky conditions and improves longer-term forecasting. This study lays the
groundwork for future novel approaches of combining sky images and satellite
observations in a single learning framework to advance solar nowcasting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Neural Patchworks: Coping with Large Segmentation Tasks. (arXiv:2206.03210v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03210">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks are the way to solve arbitrary image
segmentation tasks. However, when images are large, memory demands often exceed
the available resources, in particular on a common GPU. Especially in
biomedical imaging, where 3D images are common, the problems are apparent. A
typical approach to solve this limitation is to break the task into smaller
subtasks by dividing images into smaller image patches. Another approach, if
applicable, is to look at the 2D image sections separately, and to solve the
problem in 2D. Often, the loss of global context makes such approaches less
effective; important global information might not be present in the current
image patch, or the selected 2D image section. Here, we propose Deep Neural
Patchworks (DNP), a segmentation framework that is based on hierarchical and
nested stacking of patch-based networks that solves the dilemma between global
context and memory limitations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards better Interpretable and Generalizable AD detection using Collective Artificial Intelligence. (arXiv:2206.03247v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03247">
<div class="article-summary-box-inner">
<span><p>Accurate diagnosis and prognosis of Alzheimer's disease are crucial for
developing new therapies and reducing the associated costs. Recently, with the
advances of convolutional neural networks, deep learning methods have been
proposed to automate these two tasks using structural MRI. However, these
methods often suffer from a lack of interpretability and generalization and
have limited prognosis performance. In this paper, we propose a novel deep
framework designed to overcome these limitations. Our pipeline consists of two
stages. In the first stage, 125 3D U-Nets are used to estimate voxelwise grade
scores over the whole brain. The resulting 3D maps are then fused to construct
an interpretable 3D grading map indicating the disease severity at the
structure level. As a consequence, clinicians can use this map to detect the
brain structures affected by the disease. In the second stage, the grading map
and subject's age are used to perform classification with a graph convolutional
neural network. Experimental results based on 2106 subjects demonstrated
competitive performance of our deep framework compared to state-of-the-art
methods on different datasets for both AD diagnosis and prognosis. Moreover, we
found that using a large number of U-Nets processing different overlapping
brain areas improved the generalization capacity of the proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning. (arXiv:2206.03271v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03271">
<div class="article-summary-box-inner">
<span><p>Intelligent agents should have the ability to leverage knowledge from
previously learned tasks in order to learn new ones quickly and efficiently.
Meta-learning approaches have emerged as a popular solution to achieve this.
However, meta-reinforcement learning (meta-RL) algorithms have thus far been
restricted to simple environments with narrow task distributions. Moreover, the
paradigm of pretraining followed by fine-tuning to adapt to new tasks has
emerged as a simple yet effective solution in supervised and self-supervised
learning. This calls into question the benefits of meta-learning approaches
also in reinforcement learning, which typically come at the cost of high
complexity. We hence investigate meta-RL approaches in a variety of
vision-based benchmarks, including Procgen, RLBench, and Atari, where
evaluations are made on completely novel tasks. Our findings show that when
meta-learning approaches are evaluated on different tasks (rather than
different variations of the same task), multi-task pretraining with fine-tuning
on new tasks performs equally as well, or better, than meta-pretraining with
meta test-time adaptation. This is encouraging for future research, as
multi-task pretraining tends to be simpler and computationally cheaper than
meta-RL. From these findings, we advocate for evaluating future meta-RL methods
on more challenging tasks and including multi-task pretraining with fine-tuning
as a simple, yet strong baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeMF: Neural Motion Fields for Kinematic Animation. (arXiv:2206.03287v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03287">
<div class="article-summary-box-inner">
<span><p>We present an implicit neural representation to learn the spatio-temporal
space of kinematic motions. Unlike previous work that represents motion as
discrete sequential samples, we propose to express the vast motion space as a
continuous function over time, hence the name Neural Motion Fields (NeMF).
Specifically, we use a neural network to learn this function for miscellaneous
sets of motions, which is designed to be a generative model conditioned on a
temporal coordinate $t$ and a random vector $z$ for controlling the style. The
model is then trained as a Variational Autoencoder (VAE) with motion encoders
to sample the latent space. We train our model with diverse human motion
dataset and quadruped dataset to prove its versatility, and finally deploy it
as a generic motion prior to solve task-agnostic problems and show its
superiority in different motion generation and editing applications, such as
motion interpolation, in-betweening, and re-navigating.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parotid Gland MRI Segmentation Based on Swin-Unet and Multimodal Images. (arXiv:2206.03336v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03336">
<div class="article-summary-box-inner">
<span><p>Parotid gland tumors account for approximately 2% to 10% of head and neck
tumors. Preoperative tumor localization, differential diagnosis, and subsequent
selection of appropriate treatment for parotid gland tumors is critical.
However, the relative rarity of these tumors and the highly dispersed tissue
types have left an unmet need for a subtle differential diagnosis of such
neoplastic lesions based on preoperative radiomics. Recently, deep learning
methods have developed rapidly, especially Transformer beats the traditional
convolutional neural network in computer vision. Many new Transformer-based
networks have been proposed for computer vision tasks. In this study,
multicenter multimodal parotid gland MRI images were collected. The Swin-Unet
which was based on Transformer was used. MRI images of STIR, T1 and T2
modalities were combined into a three-channel data to train the network. We
achieved segmentation of the region of interest for parotid gland and tumor.
The DSC of the model on the test set was 88.63%, MPA was 99.31%, MIoU was
83.99%, and HD was 3.04. Then a series of comparison experiments were designed
in this paper to further validate the segmentation performance of the
algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">cViL: Cross-Lingual Training of Vision-Language Models using Knowledge Distillation. (arXiv:2206.03354v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03354">
<div class="article-summary-box-inner">
<span><p>Vision-and-language tasks are gaining popularity in the research community,
but the focus is still mainly on English. We propose a pipeline that utilizes
English-only vision-language models to train a monolingual model for a target
language. We propose to extend OSCAR+, a model which leverages object tags as
anchor points for learning image-text alignments, to train on visual question
answering datasets in different languages. We propose a novel approach to
knowledge distillation to train the model in other languages using parallel
sentences. Compared to other models that use the target language in the
pretraining corpora, we can leverage an existing English model to transfer the
knowledge to the target language using significantly lesser resources. We also
release a large-scale visual question answering dataset in Japanese and Hindi
language. Though we restrict our work to visual question answering, our model
can be extended to any sequence-level classification task, and it can be
extended to other languages as well. This paper focuses on two languages for
the visual question answering task - Japanese and Hindi. Our pipeline
outperforms the current state-of-the-art models by a relative increase of 4.4%
and 13.4% respectively in accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An efficient semi-supervised quality control system trained using physics-based MRI-artefact generators and adversarial training. (arXiv:2206.03359v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03359">
<div class="article-summary-box-inner">
<span><p>Large medical imaging data sets are becoming increasingly available. A common
challenge in these data sets is to ensure that each sample meets minimum
quality requirements devoid of significant artefacts. Despite a wide range of
existing automatic methods having been developed to identify imperfections and
artefacts in medical imaging, they mostly rely on data-hungry methods. In
particular, the lack of sufficient scans with artefacts available for training
has created a barrier in designing and deploying machine learning in clinical
research. To tackle this problem, we propose a novel framework having four main
components: (1) a set of artefact generators inspired by magnetic resonance
physics to corrupt brain MRI scans and augment a training dataset, (2) a set of
abstract and engineered features to represent images compactly, (3) a feature
selection process that depends on the class of artefact to improve
classification performance, and (4) a set of Support Vector Machine (SVM)
classifiers trained to identify artefacts. Our novel contributions are
threefold: first, we use the novel physics-based artefact generators to
generate synthetic brain MRI scans with controlled artefacts as a data
augmentation technique. This will avoid the labour-intensive collection and
labelling process of scans with rare artefacts. Second, we propose a large pool
of abstract and engineered image features developed to identify 9 different
artefacts for structural MRI. Finally, we use an artefact-based feature
selection block that, for each class of artefacts, finds the set of features
that provide the best classification performance. We performed validation
experiments on a large data set of scans with artificially-generated artefacts,
and in a multiple sclerosis clinical trial where real artefacts were identified
by experts, showing that the proposed pipeline outperforms traditional methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Similarity Learning for Aliasing Suppression Image Super-Resolution. (arXiv:2206.03361v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03361">
<div class="article-summary-box-inner">
<span><p>As a highly ill-posed issue, single image super-resolution (SISR) has been
widely investigated in recent years. The main task of SISR is to recover the
information loss caused by the degradation procedure. According to the Nyquist
sampling theory, the degradation leads to aliasing effect and makes it hard to
restore the correct textures from low-resolution (LR) images. In practice,
there are correlations and self-similarities among the adjacent patches in the
natural images. This paper considers the self-similarity and proposes a
hierarchical image super-resolution network (HSRNet) to suppress the influence
of aliasing. We consider the SISR issue in the optimization perspective, and
propose an iterative solution pattern based on the half-quadratic splitting
(HQS) method. To explore the texture with local image prior, we design a
hierarchical exploration block (HEB) and progressive increase the receptive
field. Furthermore, multi-level spatial attention (MSA) is devised to obtain
the relations of adjacent feature and enhance the high-frequency information,
which acts as a crucial role for visual experience. Experimental result shows
HSRNet achieves better quantitative and visual performance than other works,
and remits the aliasing more effectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Localizing Semantic Patches for Accelerating Image Classification. (arXiv:2206.03367v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03367">
<div class="article-summary-box-inner">
<span><p>Existing works often focus on reducing the architecture redundancy for
accelerating image classification but ignore the spatial redundancy of the
input image. This paper proposes an efficient image classification pipeline to
solve this problem. We first pinpoint task-aware regions over the input image
by a lightweight patch proposal network called AnchorNet. We then feed these
localized semantic patches with much smaller spatial redundancy into a general
classification network. Unlike the popular design of deep CNN, we aim to
carefully design the Receptive Field of AnchorNet without intermediate
convolutional paddings. This ensures the exact mapping from a high-level
spatial location to the specific input image patch. The contribution of each
patch is interpretable. Moreover, AnchorNet is compatible with any downstream
architecture. Experimental results on ImageNet show that our method outperforms
SOTA dynamic inference methods with fewer inference costs. Our code is
available at https://github.com/winycg/AnchorNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IL-MCAM: An interactive learning and multi-channel attention mechanism-based weakly supervised colorectal histopathology image classification approach. (arXiv:2206.03368v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03368">
<div class="article-summary-box-inner">
<span><p>In recent years, colorectal cancer has become one of the most significant
diseases that endanger human health. Deep learning methods are increasingly
important for the classification of colorectal histopathology images. However,
existing approaches focus more on end-to-end automatic classification using
computers rather than human-computer interaction. In this paper, we propose an
IL-MCAM framework. It is based on attention mechanisms and interactive
learning. The proposed IL-MCAM framework includes two stages: automatic
learning (AL) and interactivity learning (IL). In the AL stage, a multi-channel
attention mechanism model containing three different attention mechanism
channels and convolutional neural networks is used to extract multi-channel
features for classification. In the IL stage, the proposed IL-MCAM framework
continuously adds misclassified images to the training set in an interactive
approach, which improves the classification ability of the MCAM model. We
carried out a comparison experiment on our dataset and an extended experiment
on the HE-NCT-CRC-100K dataset to verify the performance of the proposed
IL-MCAM framework, achieving classification accuracies of 98.98% and 99.77%,
respectively. In addition, we conducted an ablation experiment and an
interchangeability experiment to verify the ability and interchangeability of
the three channels. The experimental results show that the proposed IL-MCAM
framework has excellent performance in the colorectal histopathological image
classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Garment Avatars: Realistic Cloth Driving using Pattern Registration. (arXiv:2206.03373v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03373">
<div class="article-summary-box-inner">
<span><p>Virtual telepresence is the future of online communication. Clothing is an
essential part of a person's identity and self-expression. Yet, ground truth
data of registered clothes is currently unavailable in the required resolution
and accuracy for training telepresence models for realistic cloth animation.
Here, we propose an end-to-end pipeline for building drivable representations
for clothing. The core of our approach is a multi-view patterned cloth tracking
algorithm capable of capturing deformations with high accuracy. We further rely
on the high-quality data produced by our tracking method to build a Garment
Avatar: an expressive and fully-drivable geometry model for a piece of
clothing. The resulting model can be animated using a sparse set of views and
produces highly realistic reconstructions which are faithful to the driving
signals. We demonstrate the efficacy of our pipeline on a realistic virtual
telepresence application, where a garment is being reconstructed from two
views, and a user can pick and swap garment design as they wish. In addition,
we show a challenging scenario when driven exclusively with body pose, our
drivable garment avatar is capable of producing realistic cloth geometry of
significantly higher quality than the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shape, Light & Material Decomposition from Images using Monte Carlo Rendering and Denoising. (arXiv:2206.03380v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03380">
<div class="article-summary-box-inner">
<span><p>Recent advances in differentiable rendering have enabled high-quality
reconstruction of 3D scenes from multi-view images. Most methods rely on simple
rendering algorithms: pre-filtered direct lighting or learned representations
of irradiance. We show that a more realistic shading model, incorporating ray
tracing and Monte Carlo integration, substantially improves decomposition into
shape, materials &amp; lighting. Unfortunately, Monte Carlo integration provides
estimates with significant noise, even at large sample counts, which makes
gradient-based inverse rendering very challenging. To address this, we
incorporate multiple importance sampling and denoising in a novel inverse
rendering pipeline. This substantially improves convergence and enables
gradient-based optimization at low sample counts. We present an efficient
method to jointly reconstruct geometry (explicit triangle meshes), materials,
and lighting, which substantially improves material and light separation
compared to previous work. We argue that denoising can become an integral part
of high quality inverse rendering pipelines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tutel: Adaptive Mixture-of-Experts at Scale. (arXiv:2206.03382v1 [cs.DC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03382">
<div class="article-summary-box-inner">
<span><p>In recent years, Mixture-of-Experts (MoE) has emerged as a promising
technique for deep learning that can scale the model capacity to trillion-plus
parameters while reducing the computing cost via sparse computation. While MoE
opens a new frontier of exceedingly large models, its implementation over
thousands of GPUs has been limited due to mismatch between the dynamic nature
of MoE and static parallelism/pipelining of the system. We present Tutel, a
highly scalable stack design and implementation for MoE with dynamically
adaptive parallelism and pipelining. Tutel delivers adaptive parallelism
switching and adaptive pipelining at runtime, which achieves up to 1.74x and
2.00x single MoE layer speedup, respectively. We also propose a novel
two-dimensional hierarchical algorithm for MoE communication speedup that
outperforms the previous state-of-the-art up to 20.7x over 2,048 GPUs.
Aggregating all techniques, Tutel finally delivers 4.96x and 5.75x speedup of a
single MoE layer on 16 GPUs and 2,048 GPUs, respectively, over Fairseq: Meta's
Facebook AI Research Sequence-to-Sequence Toolkit (Tutel is now partially
adopted by Fairseq). Tutel source code is available in public:
https://github.com/microsoft/tutel . Our evaluation shows that Tutel
efficiently and effectively runs a real-world MoE-based model named SwinV2-MoE,
built upon Swin Transformer V2, a state-of-the-art computer vision
architecture. On efficiency, Tutel accelerates SwinV2-MoE, achieving up to
1.55x and 2.11x speedup in training and inference over Fairseq, respectively.
On effectiveness, the SwinV2-MoE model achieves superior accuracy in both
pre-training and down-stream computer vision tasks such as COCO object
detection than the counterpart dense model, indicating the readiness of Tutel
for end-to-end real-world model training and inference. SwinV2-MoE is open
sourced in https://github.com/microsoft/Swin-Transformer .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a General Purpose CNN for Long Range Dependencies in $\mathrm{N}$D. (arXiv:2206.03398v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03398">
<div class="article-summary-box-inner">
<span><p>The use of Convolutional Neural Networks (CNNs) is widespread in Deep
Learning due to a range of desirable model properties which result in an
efficient and effective machine learning framework. However, performant CNN
architectures must be tailored to specific tasks in order to incorporate
considerations such as the input length, resolution, and dimentionality. In
this work, we overcome the need for problem-specific CNN architectures with our
Continuous Convolutional Neural Network (CCNN): a single CNN architecture
equipped with continuous convolutional kernels that can be used for tasks on
data of arbitrary resolution, dimensionality and length without structural
changes. Continuous convolutional kernels model long range dependencies at
every layer, and remove the need for downsampling layers and task-dependent
depths needed in current CNN architectures. We show the generality of our
approach by applying the same CCNN to a wide set of tasks on sequential
(1$\mathrm{D}$) and visual data (2$\mathrm{D}$). Our CCNN performs
competitively and often outperforms the current state-of-the-art across all
tasks considered.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast and Robust Non-Rigid Registration Using Accelerated Majorization-Minimization. (arXiv:2206.03410v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03410">
<div class="article-summary-box-inner">
<span><p>Non-rigid registration, which deforms a source shape in a non-rigid way to
align with a target shape, is a classical problem in computer vision. Such
problems can be challenging because of imperfect data (noise, outliers and
partial overlap) and high degrees of freedom. Existing methods typically adopt
the $\ell_{p}$ type robust norm to measure the alignment error and regularize
the smoothness of deformation, and use a proximal algorithm to solve the
resulting non-smooth optimization problem. However, the slow convergence of
such algorithms limits their wide applications. In this paper, we propose a
formulation for robust non-rigid registration based on a globally smooth robust
norm for alignment and regularization, which can effectively handle outliers
and partial overlaps. The problem is solved using the majorization-minimization
algorithm, which reduces each iteration to a convex quadratic problem with a
closed-form solution. We further apply Anderson acceleration to speed up the
convergence of the solver, enabling the solver to run efficiently on devices
with limited compute capability. Extensive experiments demonstrate the
effectiveness of our method for non-rigid alignment between two shapes with
outliers and partial overlaps, with quantitative evaluation showing that it
outperforms state-of-the-art methods in terms of registration accuracy and
computational speed. The source code is available at
https://github.com/yaoyx689/AMM_NRR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the combination of deep-learning based direct segmentation and deformable image registration for cone-beam CT based auto-segmentation for adaptive radiotherapy. (arXiv:2206.03413v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03413">
<div class="article-summary-box-inner">
<span><p>CBCT-based online adaptive radiotherapy (ART) calls for accurate
auto-segmentation models to reduce the time cost for physicians to edit
contours, since the patient is immobilized on the treatment table waiting for
treatment to start. However, auto-segmentation of CBCT images is a difficult
task, majorly due to low image quality and lack of true labels for training a
deep learning (DL) model. Meanwhile CBCT auto-segmentation in ART is a unique
task compared to other segmentation problems, where manual contours on planning
CT (pCT) are available. To make use of this prior knowledge, we propose to
combine deformable image registration (DIR) and direct segmentation (DS) on
CBCT for head and neck patients. First, we use deformed pCT contours derived
from multiple DIR methods between pCT and CBCT as pseudo labels for training.
Second, we use deformed pCT contours as bounding box to constrain the region of
interest for DS. Meanwhile deformed pCT contours are used as pseudo labels for
training, but are generated from different DIR algorithms from bounding box.
Third, we fine-tune the model with bounding box on true labels. We found that
DS on CBCT trained with pseudo labels and without utilizing any prior knowledge
has very poor segmentation performance compared to DIR-only segmentation.
However, adding deformed pCT contours as bounding box in the DS network can
dramatically improve segmentation performance, comparable to DIR-only
segmentation. The DS model with bounding box can be further improved by
fine-tuning it with some real labels. Experiments showed that 7 out of 19
structures have at least 0.2 dice similarity coefficient increase compared to
DIR-only segmentation. Utilizing deformed pCT contours as pseudo labels for
training and as bounding box for shape and location feature extraction in a DS
model is a good way to combine DIR and DS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revealing Single Frame Bias for Video-and-Language Learning. (arXiv:2206.03428v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03428">
<div class="article-summary-box-inner">
<span><p>Training an effective video-and-language model intuitively requires multiple
frames as model inputs. However, it is unclear whether using multiple frames is
beneficial to downstream tasks, and if yes, whether the performance gain is
worth the drastically-increased computation and memory costs resulting from
using more frames. In this work, we explore single-frame models for
video-and-language learning. On a diverse set of video-and-language tasks
(including text-to-video retrieval and video question answering), we show the
surprising result that, with large-scale pre-training and a proper frame
ensemble strategy at inference time, a single-frame trained model that does not
consider temporal information can achieve better performance than existing
methods that use multiple frames for training. This result reveals the
existence of a strong "static appearance bias" in popular video-and-language
datasets. Therefore, to allow for a more comprehensive evaluation of
video-and-language models, we propose two new retrieval tasks based on existing
fine-grained action recognition datasets that encourage temporal modeling. Our
code is available at https://github.com/jayleicn/singularity
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Long Videos of Dynamic Scenes. (arXiv:2206.03429v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03429">
<div class="article-summary-box-inner">
<span><p>We present a video generation model that accurately reproduces object motion,
changes in camera viewpoint, and new content that arises over time. Existing
video generation methods often fail to produce new content as a function of
time while maintaining consistencies expected in real environments, such as
plausible dynamics and object persistence. A common failure case is for content
to never change due to over-reliance on inductive biases to provide temporal
consistency, such as a single latent code that dictates content for the entire
video. On the other extreme, without long-term consistency, generated videos
may morph unrealistically between different scenes. To address these
limitations, we prioritize the time axis by redesigning the temporal latent
representation and learning long-term consistency from data by training on
longer videos. To this end, we leverage a two-phase training strategy, where we
separately train using longer videos at a low resolution and shorter videos at
a high resolution. To evaluate the capabilities of our model, we introduce two
new benchmark datasets with explicit focus on long-term temporal dynamics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robot Self-Calibration Using Actuated 3D Sensors. (arXiv:2206.03430v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03430">
<div class="article-summary-box-inner">
<span><p>Both, robot and hand-eye calibration haven been object to research for
decades. While current approaches manage to precisely and robustly identify the
parameters of a robot's kinematic model, they still rely on external devices,
such as calibration objects, markers and/or external sensors. Instead of trying
to fit the recorded measurements to a model of a known object, this paper
treats robot calibration as an offline SLAM problem, where scanning poses are
linked to a fixed point in space by a moving kinematic chain. As such, the
presented framework allows robot calibration using nothing but an arbitrary
eye-in-hand depth sensor, thus enabling fully autonomous self-calibration
without any external tools. My new approach is utilizes a modified version of
the Iterative Closest Point algorithm to run bundle adjustment on multiple 3D
recordings estimating the optimal parameters of the kinematic model. A detailed
evaluation of the system is shown on a real robot with various attached 3D
sensors. The presented results show that the system reaches precision
comparable to a dedicated external tracking system at a fraction of its cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Domain Adaptation in Crowd Counting. (arXiv:2206.03431v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03431">
<div class="article-summary-box-inner">
<span><p>Self-training crowd counting has not been attentively explored though it is
one of the important challenges in computer vision. In practice, the fully
supervised methods usually require an intensive resource of manual annotation.
In order to address this challenge, this work introduces a new approach to
utilize existing datasets with ground truth to produce more robust predictions
on unlabeled datasets, named domain adaptation, in crowd counting. While the
network is trained with labeled data, samples without labels from the target
domain are also added to the training process. In this process, the entropy map
is computed and minimized in addition to the adversarial training process
designed in parallel. Experiments on Shanghaitech, UCF_CC_50, and UCF-QNRF
datasets prove a more generalized improvement of our method over the other
state-of-the-arts in the cross-domain setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can CNNs Be More Robust Than Transformers?. (arXiv:2206.03452v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03452">
<div class="article-summary-box-inner">
<span><p>The recent success of Vision Transformers is shaking the long dominance of
Convolutional Neural Networks (CNNs) in image recognition for a decade.
Specifically, in terms of robustness on out-of-distribution samples, recent
research finds that Transformers are inherently more robust than CNNs,
regardless of different training setups. Moreover, it is believed that such
superiority of Transformers should largely be credited to their
self-attention-like architectures per se. In this paper, we question that
belief by closely examining the design of Transformers. Our findings lead to
three highly effective architecture designs for boosting robustness, yet simple
enough to be implemented in several lines of code, namely a) patchifying input
images, b) enlarging kernel size, and c) reducing activation layers and
normalization layers. Bringing these components together, we are able to build
pure CNN architectures without any attention-like operations that is as robust
as, or even more robust than, Transformers. We hope this work can help the
community better understand the design of robust neural architectures. The code
is publicly available at https://github.com/UCSC-VLAA/RobustCNN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Unsupervised Brain Anomaly Detection and Segmentation with Diffusion Models. (arXiv:2206.03461v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03461">
<div class="article-summary-box-inner">
<span><p>Deep generative models have emerged as promising tools for detecting
arbitrary anomalies in data, dispensing with the necessity for manual
labelling. Recently, autoregressive transformers have achieved state-of-the-art
performance for anomaly detection in medical imaging. Nonetheless, these models
still have some intrinsic weaknesses, such as requiring images to be modelled
as 1D sequences, the accumulation of errors during the sampling process, and
the significant inference times associated with transformers. Denoising
diffusion probabilistic models are a class of non-autoregressive generative
models recently shown to produce excellent samples in computer vision
(surpassing Generative Adversarial Networks), and to achieve log-likelihoods
that are competitive with transformers while having fast inference times.
Diffusion models can be applied to the latent representations learnt by
autoencoders, making them easily scalable and great candidates for application
to high dimensional data, such as medical images. Here, we propose a method
based on diffusion models to detect and segment anomalies in brain imaging. By
training the models on healthy data and then exploring its diffusion and
reverse steps across its Markov chain, we can identify anomalous areas in the
latent space and hence identify anomalies in the pixel space. Our diffusion
models achieve competitive performance compared with autoregressive approaches
across a series of experiments with 2D CT and MRI data involving synthetic and
real pathological lesions with much reduced inference times, making their usage
clinically viable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SHRED: 3D Shape Region Decomposition with Learned Local Operations. (arXiv:2206.03480v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03480">
<div class="article-summary-box-inner">
<span><p>We present SHRED, a method for 3D SHape REgion Decomposition. SHRED takes a
3D point cloud as input and uses learned local operations to produce a
segmentation that approximates fine-grained part instances. We endow SHRED with
three decomposition operations: splitting regions, fixing the boundaries
between regions, and merging regions together. Modules are trained
independently and locally, allowing SHRED to generate high-quality
segmentations for categories not seen during training. We train and evaluate
SHRED with fine-grained segmentations from PartNet; using its merge-threshold
hyperparameter, we show that SHRED produces segmentations that better respect
ground-truth annotations compared with baseline methods, at any desired
decomposition granularity. Finally, we demonstrate that SHRED is useful for
downstream applications, out-performing all baselines on zero-shot fine-grained
part instance segmentation and few-shot fine-grained semantic segmentation when
combined with methods that learn to label shape regions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detection Hub: Unifying Object Detection Datasets via Query Adaptation on Language Embedding. (arXiv:2206.03484v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03484">
<div class="article-summary-box-inner">
<span><p>Leveraging large-scale data can introduce performance gains on many computer
vision tasks. Unfortunately, this does not happen in object detection when
training a single model under multiple datasets together. We observe two main
obstacles: taxonomy difference and bounding box annotation inconsistency, which
introduces domain gaps in different datasets that prevents us from joint
training. In this paper, we show that these two challenges can be effectively
addressed by simply adapting object queries on language embedding of categories
per dataset. We design a detection hub to dynamically adapt queries on category
embedding based on the different distributions of datasets. Unlike previous
methods attempted to learn a joint embedding for all datasets, our adaptation
method can utilize the language embedding as semantic centers for common
categories, while learning the semantic bias towards specific categories
belonging to different datasets to handle annotation differences and make up
the domain gaps. These novel improvements enable us to end-to-end train a
single detector on multiple datasets simultaneously to fully take their
advantages. Further experiments on joint training on multiple datasets
demonstrate the significant performance gains over separate individual
fine-tuned detectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attending Category Disentangled Global Context for Image Classification. (arXiv:1812.06663v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1812.06663">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a general framework for image classification using
the attention mechanism and global context, which could incorporate with
various network architectures to improve their performance. To investigate the
capability of the global context, we compare four mathematical models and
observe the global context encoded in the category disentangled conditional
generative model could give more guidance as "know what is task irrelevant will
also know what is relevant". Based on this observation, we define a novel
Category Disentangled Global Context (CDGC) and devise a deep network to obtain
it. By attending CDGC, the baseline networks could identify the objects of
interest more accurately, thus improving the performance. We apply the
framework to many different network architectures and compare with the
state-of-the-art on four publicly available datasets. Extensive results
validate the effectiveness and superiority of our approach. Code will be made
public upon paper acceptance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stratified Rule-Aware Network for Abstract Visual Reasoning. (arXiv:2002.06838v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.06838">
<div class="article-summary-box-inner">
<span><p>Abstract reasoning refers to the ability to analyze information, discover
rules at an intangible level, and solve problems in innovative ways. Raven's
Progressive Matrices (RPM) test is typically used to examine the capability of
abstract reasoning. The subject is asked to identify the correct choice from
the answer set to fill the missing panel at the bottom right of RPM (e.g., a
3$\times$3 matrix), following the underlying rules inside the matrix. Recent
studies, taking advantage of Convolutional Neural Networks (CNNs), have
achieved encouraging progress to accomplish the RPM test. However, they partly
ignore necessary inductive biases of RPM solver, such as order sensitivity
within each row/column and incremental rule induction. To address this problem,
in this paper we propose a Stratified Rule-Aware Network (SRAN) to generate the
rule embeddings for two input sequences. Our SRAN learns multiple granularity
rule embeddings at different levels, and incrementally integrates the
stratified embedding flows through a gated fusion module. With the help of
embeddings, a rule similarity metric is applied to guarantee that SRAN can not
only be trained using a tuplet loss but also infer the best answer efficiently.
We further point out the severe defects existing in the popular RAVEN dataset
for RPM test, which prevent from the fair evaluation of the abstract reasoning
ability. To fix the defects, we propose an answer set generation algorithm
called Attribute Bisection Tree (ABT), forming an improved dataset named
Impartial-RAVEN (I-RAVEN for short). Extensive experiments are conducted on
both PGM and I-RAVEN datasets, showing that our SRAN outperforms the
state-of-the-art models by a considerable margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Segment Human Body Parts with Synthetically Trained Deep Convolutional Networks. (arXiv:2102.01460v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01460">
<div class="article-summary-box-inner">
<span><p>This paper presents a new framework for human body part segmentation based on
Deep Convolutional Neural Networks trained using only synthetic data. The
proposed approach achieves cutting-edge results without the need of training
the models with real annotated data of human body parts. Our contributions
include a data generation pipeline, that exploits a game engine for the
creation of the synthetic data used for training the network, and a novel
pre-processing module, that combines edge response maps and adaptive histogram
equalization to guide the network to learn the shape of the human body parts
ensuring robustness to changes in the illumination conditions. For selecting
the best candidate architecture, we perform exhaustive tests on manually
annotated images of real human body limbs. We further compare our method
against several high-end commercial segmentation tools on the body parts
segmentation task. The results show that our method outperforms the other
models by a significant margin. Finally, we present an ablation study to
validate our pre-processing module. With this paper, we release an
implementation of the proposed approach along with the acquired datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Look, Cast and Mold: Learning 3D Shape Manifold from Single-view Synthetic Data. (arXiv:2103.04789v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04789">
<div class="article-summary-box-inner">
<span><p>Inferring the stereo structure of objects in the real world is a challenging
yet practical task. To equip deep models with this ability usually requires
abundant 3D supervision which is hard to acquire. It is promising that we can
simply benefit from synthetic data, where pairwise ground-truth is easy to
access. Nevertheless, the domain gaps are nontrivial considering the variant
texture, shape and context. To overcome these difficulties, we propose a
Visio-Perceptual Adaptive Network for single-view 3D reconstruction, dubbed
VPAN. To generalize the model towards a real scenario, we propose to fulfill
several aspects: (1) Look: visually incorporate spatial structure from the
single view to enhance the expressiveness of representation; (2) Cast:
perceptually align the 2D image features to the 3D shape priors with
cross-modal semantic contrastive mapping; (3) Mold: reconstruct stereo-shape of
target by transforming embeddings into the desired manifold. Extensive
experiments on several benchmarks demonstrate the effectiveness and robustness
of the proposed method in learning the 3D shape manifold from synthetic data
via a single-view. The proposed method outperforms state-of-the-arts on Pix3D
dataset with IoU 0.292 and CD 0.108, and reaches IoU 0.329 and CD 0.104 on
Pascal 3D+.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deformable Capsules for Object Detection. (arXiv:2104.05031v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05031">
<div class="article-summary-box-inner">
<span><p>In this study, we introduce a new family of capsule networks, deformable
capsules (DeformCaps), to address a very important problem in computer vision:
object detection. We propose two new algorithms associated with our DeformCaps:
a novel capsule structure (SplitCaps), and a novel dynamic routing algorithm
(SE-Routing), which balance computational efficiency with the need for modeling
a large number of objects and classes, which have never been achieved with
capsule networks before. We demonstrate that the proposed methods allow
capsules to efficiently scale-up to large-scale computer vision tasks for the
first time, and create the first-ever capsule network for object detection in
the literature. Our proposed architecture is a one-stage detection framework
and obtains results on MS COCO which are on-par with state-of-the-art one-stage
CNN-based methods, while producing fewer false positive detections,
generalizing to unusual poses/viewpoints of objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Common Limitations of Image Processing Metrics: A Picture Story. (arXiv:2104.05642v5 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05642">
<div class="article-summary-box-inner">
<span><p>While the importance of automatic image analysis is continuously increasing,
recent meta-research revealed major flaws with respect to algorithm validation.
Performance metrics are particularly key for meaningful, objective, and
transparent performance assessment and validation of the used automatic
algorithms, but relatively little attention has been given to the practical
pitfalls when using specific metrics for a given image analysis task. These are
typically related to (1) the disregard of inherent metric properties, such as
the behaviour in the presence of class imbalance or small target structures,
(2) the disregard of inherent data set properties, such as the non-independence
of the test cases, and (3) the disregard of the actual biomedical domain
interest that the metrics should reflect. This living dynamically document has
the purpose to illustrate important limitations of performance metrics commonly
applied in the field of image analysis. In this context, it focuses on
biomedical image analysis problems that can be phrased as image-level
classification, semantic segmentation, instance segmentation, or object
detection task. The current version is based on a Delphi process on metrics
conducted by an international consortium of image analysis experts from more
than 60 institutions worldwide.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistency Regularization for Variational Auto-Encoders. (arXiv:2105.14859v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14859">
<div class="article-summary-box-inner">
<span><p>Variational auto-encoders (VAEs) are a powerful approach to unsupervised
learning. They enable scalable approximate posterior inference in
latent-variable models using variational inference (VI). A VAE posits a
variational family parameterized by a deep neural network called an encoder
that takes data as input. This encoder is shared across all the observations,
which amortizes the cost of inference. However the encoder of a VAE has the
undesirable property that it maps a given observation and a
semantics-preserving transformation of it to different latent representations.
This "inconsistency" of the encoder lowers the quality of the learned
representations, especially for downstream tasks, and also negatively affects
generalization. In this paper, we propose a regularization method to enforce
consistency in VAEs. The idea is to minimize the Kullback-Leibler (KL)
divergence between the variational distribution when conditioning on the
observation and the variational distribution when conditioning on a random
semantic-preserving transformation of this observation. This regularization is
applicable to any VAE. In our experiments we apply it to four different VAE
variants on several benchmark datasets and found it always improves the quality
of the learned representations but also leads to better generalization. In
particular, when applied to the Nouveau Variational Auto-Encoder (NVAE), our
regularization method yields state-of-the-art performance on MNIST and
CIFAR-10. We also applied our method to 3D data and found it learns
representations of superior quality as measured by accuracy on a downstream
classification task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tikhonov Regularization of Circle-Valued Signals. (arXiv:2108.02602v3 [math.OC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02602">
<div class="article-summary-box-inner">
<span><p>It is common to have to process signals or images whose values are cyclic and
can be represented as points on the complex circle, like wrapped phases,
angles, orientations, or color hues. We consider a Tikhonov-type regularization
model to smoothen or interpolate circle-valued signals defined on arbitrary
graphs. We propose a convex relaxation of this nonconvex problem as a
semidefinite program, and an efficient algorithm to solve it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepMTS: Deep Multi-task Learning for Survival Prediction in Patients with Advanced Nasopharyngeal Carcinoma using Pretreatment PET/CT. (arXiv:2109.07711v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07711">
<div class="article-summary-box-inner">
<span><p>Nasopharyngeal Carcinoma (NPC) is a malignant epithelial cancer arising from
the nasopharynx. Survival prediction is a major concern for NPC patients, as it
provides early prognostic information to plan treatments. Recently, deep
survival models based on deep learning have demonstrated the potential to
outperform traditional radiomics-based survival prediction models. Deep
survival models usually use image patches covering the whole target regions
(e.g., nasopharynx for NPC) or containing only segmented tumor regions as the
input. However, the models using the whole target regions will also include
non-relevant background information, while the models using segmented tumor
regions will disregard potentially prognostic information existing out of
primary tumors (e.g., local lymph node metastasis and adjacent tissue
invasion). In this study, we propose a 3D end-to-end Deep Multi-Task Survival
model (DeepMTS) for joint survival prediction and tumor segmentation in
advanced NPC from pretreatment PET/CT. Our novelty is the introduction of a
hard-sharing segmentation backbone to guide the extraction of local features
related to the primary tumors, which reduces the interference from non-relevant
background information. In addition, we also introduce a cascaded survival
network to capture the prognostic information existing out of primary tumors
and further leverage the global tumor information (e.g., tumor size, shape, and
locations) derived from the segmentation backbone. Our experiments with two
clinical datasets demonstrate that our DeepMTS can consistently outperform
traditional radiomics-based survival prediction models and existing deep
survival models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learn to Ignore: Domain Adaptation for Multi-Site MRI Analysis. (arXiv:2110.06803v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06803">
<div class="article-summary-box-inner">
<span><p>The limited availability of large image datasets, mainly due to data privacy
and differences in acquisition protocols or hardware, is a significant issue in
the development of accurate and generalizable machine learning methods in
medicine. This is especially the case for Magnetic Resonance (MR) images, where
different MR scanners introduce a bias that limits the performance of a machine
learning model. We present a novel method that learns to ignore the
scanner-related features present in MR images, by introducing specific
additional constraints on the latent space. We focus on a real-world
classification scenario, where only a small dataset provides images of all
classes. Our method \textit{Learn to Ignore (L2I)} outperforms state-of-the-art
domain adaptation methods on a multi-site MR dataset for a classification task
between multiple sclerosis patients and healthy controls.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Guided Lung Nodule Segmentation with Feature-Aware Attention. (arXiv:2110.12372v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12372">
<div class="article-summary-box-inner">
<span><p>Since radiologists have different training and clinical experiences, they may
provide various segmentation annotations for a lung nodule. Conventional
studies choose a single annotation as the learning target by default, but they
waste valuable information of consensus or disagreements ingrained in the
multiple annotations. This paper proposes an Uncertainty-Guided Segmentation
Network (UGS-Net), which learns the rich visual features from the regions that
may cause segmentation uncertainty and contributes to a better segmentation
result. With an Uncertainty-Aware Module, this network can provide a
Multi-Confidence Mask (MCM), pointing out regions with different segmentation
uncertainty levels. Moreover, this paper introduces a Feature-Aware Attention
Module to enhance the learning of the nodule boundary and density differences.
Experimental results show that our method can predict the nodule regions with
different uncertainty levels and achieve superior performance in LIDC-IDRI
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated skin lesion segmentation using multi-scale feature extraction scheme and dual-attention mechanism. (arXiv:2111.08708v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08708">
<div class="article-summary-box-inner">
<span><p>Segmenting skin lesions from dermoscopic images is essential for diagnosing
skin cancer. But the automatic segmentation of these lesions is complicated due
to the poor contrast between the background and the lesion, image artifacts,
and unclear lesion boundaries. In this work, we present a deep learning model
for the segmentation of skin lesions from dermoscopic images. To deal with the
challenges of skin lesion characteristics, we designed a multi-scale feature
extraction module for extracting the discriminative features. Further in this
work, two attention mechanisms are developed to refine the post-upsampled
features and the features extracted by the encoder. This model is evaluated
using the ISIC2018 and ISBI2017 datasets. The proposed model outperformed all
the existing works and the top-ranked models in two competitions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Graph-Convolutional Variational AutoEncoding for Generative Modelling of Human Motion. (arXiv:2111.12602v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12602">
<div class="article-summary-box-inner">
<span><p>Models of human motion commonly focus either on trajectory prediction or
action classification but rarely both. The marked heterogeneity and intricate
compositionality of human motion render each task vulnerable to the data
degradation and distributional shift common to real-world scenarios. A
sufficiently expressive generative model of action could in theory enable data
conditioning and distributional resilience within a unified framework
applicable to both tasks. Here we propose a novel architecture based on
hierarchical variational autoencoders and deep graph convolutional neural
networks for generating a holistic model of action over multiple time-scales.
We show this Hierarchical Graph-convolutional Variational Autoencoder (HG-VAE)
to be capable of generating coherent actions, detecting out-of-distribution
data, and imputing missing data by gradient ascent on the model's posterior.
Trained and evaluated on H3.6M and the largest collection of open source human
motion data, AMASS, we show HG-VAE can facilitate downstream discriminative
learning better than baseline models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for Efficient Object Detection. (arXiv:2111.13336v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13336">
<div class="article-summary-box-inner">
<span><p>In object detection, the detection backbone consumes more than half of the
overall inference cost. Recent researches attempt to reduce this cost by
optimizing the backbone architecture with the help of Neural Architecture
Search (NAS). However, existing NAS methods for object detection require
hundreds to thousands of GPU hours of searching, making them impractical in
fast-paced research and development. In this work, we propose a novel zero-shot
NAS method to address this issue. The proposed method, named MAE-DET,
automatically designs efficient detection backbones via the Maximum Entropy
Principle without training network parameters, reducing the architecture design
cost to nearly zero yet delivering the state-of-the-art (SOTA) performance.
Under the hood, MAE-DET maximizes the differential entropy of detection
backbones, leading to a better feature extractor for object detection under the
same computational budgets. After merely one GPU day of fully automatic design,
MAE-DET innovates SOTA detection backbones on multiple detection benchmark
datasets with little human intervention. Comparing to ResNet-50 backbone,
MAE-DET is $+2.0\%$ better in mAP when using the same amount of
FLOPs/parameters, and is $1.54$ times faster on NVIDIA V100 at the same mAP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Point Light Fields. (arXiv:2112.01473v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01473">
<div class="article-summary-box-inner">
<span><p>We introduce Neural Point Light Fields that represent scenes implicitly with
a light field living on a sparse point cloud. Combining differentiable volume
rendering with learned implicit density representations has made it possible to
synthesize photo-realistic images for novel views of small scenes. As neural
volumetric rendering methods require dense sampling of the underlying
functional scene representation, at hundreds of samples along a ray cast
through the volume, they are fundamentally limited to small scenes with the
same objects projected to hundreds of training views. Promoting sparse point
clouds to neural implicit light fields allows us to represent large scenes
effectively with only a single radiance evaluation per ray. These point light
fields are a function of the ray direction, and local point feature
neighborhood, allowing us to interpolate the light field conditioned training
images without dense object coverage and parallax. We assess the proposed
method for novel view synthesis on large driving scenarios, where we synthesize
realistic unseen views that existing implicit approaches fail to represent. We
validate that Neural Point Light Fields make it possible to predict videos
along unseen trajectories previously only feasible to generate by explicitly
modeling the scene.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hybrid Instance-aware Temporal Fusion for Online Video Instance Segmentation. (arXiv:2112.01695v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01695">
<div class="article-summary-box-inner">
<span><p>Recently, transformer-based image segmentation methods have achieved notable
success against previous solutions. While for video domains, how to effectively
model temporal context with the attention of object instances across frames
remains an open problem. In this paper, we propose an online video instance
segmentation framework with a novel instance-aware temporal fusion method. We
first leverages the representation, i.e., a latent code in the global context
(instance code) and CNN feature maps to represent instance- and pixel-level
features. Based on this representation, we introduce a cropping-free temporal
fusion approach to model the temporal consistency between video frames.
Specifically, we encode global instance-specific information in the instance
code and build up inter-frame contextual fusion with hybrid attentions between
the instance codes and CNN feature maps. Inter-frame consistency between the
instance codes are further enforced with order constraints. By leveraging the
learned hybrid temporal consistency, we are able to directly retrieve and
maintain instance identities across frames, eliminating the complicated
frame-wise instance matching in prior methods. Extensive experiments have been
conducted on popular VIS datasets, i.e. Youtube-VIS-19/21. Our model achieves
the best performance among all online VIS methods. Notably, our model also
eclipses all offline methods when using the ResNet-50 backbone.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GradMax: Growing Neural Networks using Gradient Information. (arXiv:2201.05125v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05125">
<div class="article-summary-box-inner">
<span><p>The architecture and the parameters of neural networks are often optimized
independently, which requires costly retraining of the parameters whenever the
architecture is modified. In this work we instead focus on growing the
architecture without requiring costly retraining. We present a method that adds
new neurons during training without impacting what is already learned, while
improving the training dynamics. We achieve the latter by maximizing the
gradients of the new weights and find the optimal initialization efficiently by
means of the singular value decomposition (SVD). We call this technique
Gradient Maximizing Growth (GradMax) and demonstrate its effectiveness in
variety of vision tasks and architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vertical Federated Edge Learning with Distributed Integrated Sensing and Communication. (arXiv:2201.08512v2 [eess.SP] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08512">
<div class="article-summary-box-inner">
<span><p>This letter studies a vertical federated edge learning (FEEL) system for
collaborative objects/human motion recognition by exploiting the distributed
integrated sensing and communication (ISAC). In this system, distributed edge
devices first send wireless signals to sense targeted objects/human, and then
exchange intermediate computed vectors (instead of raw sensing data) for
collaborative recognition while preserving data privacy. To boost the spectrum
and hardware utilization efficiency for FEEL, we exploit ISAC for both target
sensing and data exchange, by employing dedicated frequency-modulated
continuous-wave (FMCW) signals at each edge device. Under this setup, we
propose a vertical FEEL framework for realizing the recognition based on the
collected multi-view wireless sensing data. In this framework, each edge device
owns an individual local L-model to transform its sensing data into an
intermediate vector with relatively low dimensions, which is then transmitted
to a coordinating edge device for final output via a common downstream S-model.
By considering a human motion recognition task, experimental results show that
our vertical FEEL based approach achieves recognition accuracy up to 98\% with
an improvement up to 8\% compared to the benchmarks, including on-device
training and horizontal FEEL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks. (arXiv:2201.12179v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12179">
<div class="article-summary-box-inner">
<span><p>Model inversion attacks (MIAs) aim to create synthetic images that reflect
the class-wise characteristics from a target classifier's private training data
by exploiting the model's learned knowledge. Previous research has developed
generative MIAs that use generative adversarial networks (GANs) as image priors
tailored to a specific target model. This makes the attacks time- and
resource-consuming, inflexible, and susceptible to distributional shifts
between datasets. To overcome these drawbacks, we present Plug &amp; Play Attacks,
which relax the dependency between the target model and image prior, and enable
the use of a single GAN to attack a wide range of targets, requiring only minor
adjustments to the attack. Moreover, we show that powerful MIAs are possible
even with publicly available pre-trained GANs and under strong distributional
shifts, for which previous approaches fail to produce meaningful results. Our
extensive evaluation confirms the improved robustness and flexibility of Plug &amp;
Play Attacks and their ability to create high-quality images revealing
sensitive class characteristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Debiased Self-Training for Semi-Supervised Learning. (arXiv:2202.07136v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07136">
<div class="article-summary-box-inner">
<span><p>Deep neural networks achieve remarkable performances on a wide range of tasks
with the aid of large-scale labeled datasets. Yet these datasets are
time-consuming and labor-exhaustive to obtain on realistic tasks. To mitigate
the requirement for labeled data, self-training is widely used in
semi-supervised learning by iteratively assigning pseudo labels to unlabeled
samples. Despite its popularity, self-training is well-believed to be
unreliable and often leads to training instability. Our experimental studies
further reveal that the bias in semi-supervised learning arises from both the
problem itself and the inappropriate training with potentially incorrect pseudo
labels, which accumulates the error in the iterative self-training process. To
reduce the above bias, we propose Debiased Self-Training (DST). First, the
generation and utilization of pseudo labels are decoupled by two
parameter-independent classifier heads to avoid direct error accumulation.
Second, we estimate the worst case of self-training bias, where the pseudo
labeling function is accurate on labeled samples, yet makes as many mistakes as
possible on unlabeled samples. We then adversarially optimize the
representations to improve the quality of pseudo labels by avoiding the worst
case. Extensive experiments justify that DST achieves an average improvement of
6.3% against state-of-the-art methods on standard semi-supervised learning
benchmark datasets and 18.9%$ against FixMatch on 13 diverse tasks.
Furthermore, DST can be seamlessly adapted to other self-training methods and
help stabilize their training and balance performance across classes in both
cases of training from scratch and finetuning from pre-trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deconstructing Distributions: A Pointwise Framework of Learning. (arXiv:2202.09931v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09931">
<div class="article-summary-box-inner">
<span><p>In machine learning, we traditionally evaluate the performance of a single
model, averaged over a collection of test inputs. In this work, we propose a
new approach: we measure the performance of a collection of models when
evaluated on a $\textit{single input point}$. Specifically, we study a point's
$\textit{profile}$: the relationship between models' average performance on the
test distribution and their pointwise performance on this individual point. We
find that profiles can yield new insights into the structure of both models and
data -- in and out-of-distribution. For example, we empirically show that real
data distributions consist of points with qualitatively different profiles. On
one hand, there are "compatible" points with strong correlation between the
pointwise and average performance. On the other hand, there are points with
weak and even $\textit{negative}$ correlation: cases where improving overall
model accuracy actually $\textit{hurts}$ performance on these inputs. We prove
that these experimental observations are inconsistent with the predictions of
several simplified models of learning proposed in prior work. As an
application, we use profiles to construct a dataset we call CIFAR-10-NEG: a
subset of CINIC-10 such that for standard models, accuracy on CIFAR-10-NEG is
$\textit{negatively correlated}$ with accuracy on CIFAR-10 test. This
illustrates, for the first time, an OOD dataset that completely inverts
"accuracy-on-the-line" (Miller, Taori, Raghunathan, Sagawa, Koh, Shankar,
Liang, Carmon, and Schmidt 2021)
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syntax-Aware Network for Handwritten Mathematical Expression Recognition. (arXiv:2203.01601v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01601">
<div class="article-summary-box-inner">
<span><p>Handwritten mathematical expression recognition (HMER) is a challenging task
that has many potential applications. Recent methods for HMER have achieved
outstanding performance with an encoder-decoder architecture. However, these
methods adhere to the paradigm that the prediction is made "from one character
to another", which inevitably yields prediction errors due to the complicated
structures of mathematical expressions or crabbed handwritings. In this paper,
we propose a simple and efficient method for HMER, which is the first to
incorporate syntax information into an encoder-decoder network. Specifically,
we present a set of grammar rules for converting the LaTeX markup sequence of
each expression into a parsing tree; then, we model the markup sequence
prediction as a tree traverse process with a deep neural network. In this way,
the proposed method can effectively describe the syntax context of expressions,
alleviating the structure prediction errors of HMER. Experiments on three
benchmark datasets demonstrate that our method achieves better recognition
performance than prior arts. To further validate the effectiveness of our
method, we create a large-scale dataset consisting of 100k handwritten
mathematical expression images acquired from ten thousand writers. The source
code, new dataset, and pre-trained models of this work will be publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Click-based Interactive Video Object Segmentation. (arXiv:2203.01784v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01784">
<div class="article-summary-box-inner">
<span><p>While current methods for interactive Video Object Segmentation (iVOS) rely
on scribble-based interactions to generate precise object masks, we propose a
Click-based interactive Video Object Segmentation (CiVOS) framework to simplify
the required user workload as much as possible. CiVOS builds on de-coupled
modules reflecting user interaction and mask propagation. The interaction
module converts click-based interactions into an object mask, which is then
inferred to the remaining frames by the propagation module. Additional user
interactions allow for a refinement of the object mask. The approach is
extensively evaluated on the popular interactive~DAVIS dataset, but with an
inevitable adaptation of scribble-based interactions with click-based
counterparts. We consider several strategies for generating clicks during our
evaluation to reflect various user inputs and adjust the DAVIS performance
metric to perform a hardware-independent comparison. The presented CiVOS
pipeline achieves competitive results, although requiring a lower user
workload.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation with Transformers. (arXiv:2203.10726v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.10726">
<div class="article-summary-box-inner">
<span><p>Combining information from multi-view images is crucial to improve the
performance and robustness of automated methods for disease diagnosis. However,
due to the non-alignment characteristics of multi-view images, building
correlation and data fusion across views largely remain an open problem. In
this study, we present TransFusion, a Transformer-based architecture to merge
divergent multi-view imaging information using convolutional layers and
powerful attention mechanisms. In particular, the Divergent Fusion Attention
(DiFA) module is proposed for rich cross-view context modeling and semantic
dependency mining, addressing the critical issue of capturing long-range
correlations between unaligned data from different image views. We further
propose the Multi-Scale Attention (MSA) to collect global correspondence of
multi-scale feature representations. We evaluate TransFusion on the
Multi-Disease, Multi-View \&amp; Multi-Center Right Ventricular Segmentation in
Cardiac MRI (M\&amp;Ms-2) challenge cohort. TransFusion demonstrates leading
performance against the state-of-the-art methods and opens up new perspectives
for multi-view imaging integration towards robust medical image segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cell segmentation from telecentric bright-field transmitted light microscopy images using a Residual Attention U-Net: a case study on HeLa line. (arXiv:2203.12290v2 [q-bio.QM] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12290">
<div class="article-summary-box-inner">
<span><p>Living cell segmentation from bright-field light microscopy images is
challenging due to the image complexity and temporal changes in the living
cells. Recently developed deep learning (DL)-based methods became popular in
medical and microscopy image segmentation tasks due to their success and
promising outcomes. The main objective of this paper is to develop a deep
learning, U-Net-based method to segment the living cells of the HeLa line in
bright-field transmitted light microscopy. To find the most suitable
architecture for our datasets, a residual attention U-Net was proposed and
compared with an attention and a simple U-Net architecture.
</p>
<p>The attention mechanism highlights the remarkable features and suppresses
activations in the irrelevant image regions. The residual mechanism overcomes
with vanishing gradient problem. The Mean-IoU score for our datasets reaches
0.9505, 0.9524, and 0.9530 for the simple, attention, and residual attention
U-Net, respectively. The most accurate semantic segmentation results was
achieved in the Mean-IoU and Dice metrics by applying the residual and
attention mechanisms together. The watershed method applied to this best --
Residual Attention -- semantic segmentation result gave the segmentation with
the specific information for each cell.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eventor: An Efficient Event-Based Monocular Multi-View Stereo Accelerator on FPGA Platform. (arXiv:2203.15439v2 [cs.AR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.15439">
<div class="article-summary-box-inner">
<span><p>Event cameras are bio-inspired vision sensors that asynchronously represent
pixel-level brightness changes as event streams. Event-based monocular
multi-view stereo (EMVS) is a technique that exploits the event streams to
estimate semi-dense 3D structure with known trajectory. It is a critical task
for event-based monocular SLAM. However, the required intensive computation
workloads make it challenging for real-time deployment on embedded platforms.
In this paper, Eventor is proposed as a fast and efficient EMVS accelerator by
realizing the most critical and time-consuming stages including event
back-projection and volumetric ray-counting on FPGA. Highly paralleled and
fully pipelined processing elements are specially designed via FPGA and
integrated with the embedded ARM as a heterogeneous system to improve the
throughput and reduce the memory footprint. Meanwhile, the EMVS algorithm is
reformulated to a more hardware-friendly manner by rescheduling, approximate
computing and hybrid data quantization. Evaluation results on DAVIS dataset
show that Eventor achieves up to $24\times$ improvement in energy efficiency
compared with Intel i5 CPU platform.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Vehicle Detection in Satellite Video. (arXiv:2204.06828v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.06828">
<div class="article-summary-box-inner">
<span><p>This work presents a deep learning approach for vehicle detection in
satellite video. Vehicle detection is perhaps impossible in single EO satellite
images due to the tininess of vehicles (4-10 pixel) and their similarity to the
background. Instead, we consider satellite video which overcomes the lack of
spatial information by temporal consistency of vehicle movement. A new
spatiotemporal model of a compact $3 \times 3$ convolutional, neural network is
proposed which neglects pooling layers and uses leaky ReLUs. Then we use a
reformulation of the output heatmap including Non-Maximum-Suppression (NMS) for
the final segmentation. Empirical results on two new annotated satellite videos
reconfirm the applicability of this approach for vehicle detection. They more
importantly indicate that pre-training on WAMI data and then fine-tuning on few
annotated video frames for a new video is sufficient. In our experiment only
five annotated images yield a $F_1$ score of 0.81 on a new video showing more
complex traffic patterns than the Las Vegas video. Our best result on Las Vegas
is a $F_1$ score of 0.87 which makes the proposed approach a leading method for
this benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Zooming for Multiple Instance Learning on Whole-Slide Images. (arXiv:2204.12454v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12454">
<div class="article-summary-box-inner">
<span><p>Multiple Instance Learning (MIL) methods have become increasingly popular for
classifying giga-pixel sized Whole-Slide Images (WSIs) in digital pathology.
Most MIL methods operate at a single WSI magnification, by processing all the
tissue patches. Such a formulation induces high computational requirements, and
constrains the contextualization of the WSI-level representation to a single
scale. A few MIL methods extend to multiple scales, but are computationally
more demanding. In this paper, inspired by the pathological diagnostic process,
we propose ZoomMIL, a method that learns to perform multi-level zooming in an
end-to-end manner. ZoomMIL builds WSI representations by aggregating
tissue-context information from multiple magnifications. The proposed method
outperforms the state-of-the-art MIL methods in WSI classification on two large
datasets, while significantly reducing the computational demands with regard to
Floating-Point Operations (FLOPs) and processing time by up to 40x.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework. (arXiv:2205.03860v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03860">
<div class="article-summary-box-inner">
<span><p>Vision-language pre-training (VLP) on large-scale datasets has shown premier
performance on various downstream tasks. A complete and fair benchmark (i.e.,
including large-scale pre-training datasets and diverse downstream tasks) is
essential for VLP. While there are plenty of benchmarks with English corpus,
building a rich benchmark for VLP with other languages, such as Chinese,
remains a critical problem. To this end, we build a large-scale Chinese
cross-modal benchmark called Zero for the research community to fairly compare
VLP models. We release two pre-training datasets and five fine-tuning datasets
for downstream tasks. Alongside, we propose a novel pre-training framework of
pre-Ranking + Ranking for cross-modal learning. Specifically, we apply global
contrastive pre-ranking to learn the individual representations of images and
texts, respectively. We then fuse the representations in a fine-grained ranking
manner via an image-text cross encoder and a text-image cross encoder. To
further enhance the capability of the model, we propose a two-way distillation
strategy consisting of target-guided Distillation and feature-guided
Distillation. For brevity, we name our model R2D2. We achieve state-of-the-art
performance on four public cross-modal datasets and the proposed five
downstream datasets. When conducting zero-shot tasks on Flickr30k-CN, COCO-CN,
and MUGE, R2D2 pre-trained on a 250 million dataset achieves significant
improvements of 4.7%, 5.4%, and 6.3% in mean recall compared to the
state-of-the-art. The datasets, models, and codes are available at
https://github.com/yuxie11/R2D2
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Effective Transformer-based Solution for RSNA Intracranial Hemorrhage Detection Competition. (arXiv:2205.07556v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07556">
<div class="article-summary-box-inner">
<span><p>We present an effective method for Intracranial Hemorrhage Detection (IHD)
which exceeds the performance of the winner solution in RSNA-IHD competition
(2019). Meanwhile, our model only takes quarter parameters and ten percent
FLOPs compared to the winner's solution. The IHD task needs to predict the
hemorrhage category of each slice for the input brain CT. We review the top-5
solutions for the IHD competition held by the Radiological Society of North
America(RSNA) in 2019. Nearly all the top solutions rely on 2D convolutional
networks and sequential models (Bidirectional GRU or LSTM) to extract
intra-slice and inter-slice features, respectively. All the top solutions
enhance the performance by leveraging the model ensemble, and the model number
varies from 7 to 31. In the past years, since much progress has been made in
the computer vision regime especially Transformer-based models, we introduce
the Transformer-based techniques to extract the features in both intra-slice
and inter-slice views for IHD tasks. Additionally, a semi-supervised method is
embedded into our workflow to further improve the performance. The code is
available in the manuscript.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ColonFormer: An Efficient Transformer based Method for Colon Polyp Segmentation. (arXiv:2205.08473v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08473">
<div class="article-summary-box-inner">
<span><p>Identifying polyps is challenging for automatic analysis of endoscopic images
in computer-aided clinical support systems. Models based on convolutional
networks (CNN), transformers, and their combinations have been proposed to
segment polyps with promising results. However, those approaches have
limitations either in modeling the local appearance of the polyps only or lack
of multi-level features for spatial dependency in the decoding process. This
paper proposes a novel network, namely ColonFormer, to address these
limitations. ColonFormer is an encoder-decoder architecture capable of modeling
long-range semantic information at both encoder and decoder branches. The
encoder is a lightweight architecture based on transformers for modeling global
semantic relations at multi scales. The decoder is a hierarchical network
structure designed for learning multi-level features to enrich feature
representation. Besides, a refinement module is added with a new skip
connection technique to refine the boundary of polyp objects in the global map
for accurate segmentation. Extensive experiments have been conducted on five
popular benchmark datasets for polyp segmentation, including Kvasir, CVC-Clinic
DB, CVC-ColonDB, CVC-T, and ETIS-Larib. Experimental results show that our
ColonFormer outperforms other state-of-the-art methods on all benchmark
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video. (arXiv:2205.09382v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09382">
<div class="article-summary-box-inner">
<span><p>Predicting fetal weight at birth is an important aspect of perinatal care,
particularly in the context of antenatal management, which includes the planned
timing and the mode of delivery. Accurate prediction of weight using prenatal
ultrasound is challenging as it requires images of specific fetal body parts
during advanced pregnancy which is difficult to capture due to poor quality of
images caused by the lack of amniotic fluid. As a consequence, predictions
which rely on standard methods often suffer from significant errors. In this
paper we propose the Residual Transformer Module which extends a 3D
ResNet-based network for analysis of 2D+t spatio-temporal ultrasound video
scans. Our end-to-end method, called BabyNet, automatically predicts fetal
birth weight based on fetal ultrasound video scans. We evaluate BabyNet using a
dedicated clinical set comprising 225 2D fetal ultrasound videos of pregnancies
from 75 patients performed one day prior to delivery. Experimental results show
that BabyNet outperforms several state-of-the-art methods and estimates the
weight at birth with accuracy comparable to human experts. Furthermore,
combining estimates provided by human experts with those computed by BabyNet
yields the best results, outperforming either of other methods by a significant
margin. The source code of BabyNet is available at
https://github.com/SanoScience/BabyNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SelfReformer: Self-Refined Network with Transformer for Salient Object Detection. (arXiv:2205.11283v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11283">
<div class="article-summary-box-inner">
<span><p>The global and local contexts significantly contribute to the integrity of
predictions in Salient Object Detection (SOD). Unfortunately, existing methods
still struggle to generate complete predictions with fine details. There are
two major problems in conventional approaches: first, for global context,
high-level CNN-based encoder features cannot effectively catch long-range
dependencies, resulting in incomplete predictions. Second, downsampling the
ground truth to fit the size of predictions will introduce inaccuracy as the
ground truth details are lost during interpolation or pooling. Thus, in this
work, we developed a Transformer-based network and framed a supervised task for
a branch to learn the global context information explicitly. Besides, we adopt
Pixel Shuffle from Super-Resolution (SR) to reshape the predictions back to the
size of ground truth instead of the reverse. Thus details in the ground truth
are untouched. In addition, we developed a two-stage Context Refinement Module
(CRM) to fuse global context and automatically locate and refine the local
details in the predictions. The proposed network can guide and correct itself
based on the global and local context generated, thus is named, Self-Refined
Transformer (SelfReformer). Extensive experiments and evaluation results on
five benchmark datasets demonstrate the outstanding performance of the network,
and we achieved the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepRM: Deep Recurrent Matching for 6D Pose Refinement. (arXiv:2205.14474v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14474">
<div class="article-summary-box-inner">
<span><p>Precise 6D pose estimation of rigid objects from RGB images is a critical but
challenging task in robotics and augmented reality. To address this problem, we
propose DeepRM, a novel recurrent network architecture for 6D pose refinement.
DeepRM leverages initial coarse pose estimates to render synthetic images of
target objects. The rendered images are then matched with the observed images
to predict a rigid transform for updating the previous pose estimate. This
process is repeated to incrementally refine the estimate at each iteration.
LSTM units are used to propagate information through each refinement step,
significantly improving overall performance. In contrast to many 2-stage
Perspective-n-Point based solutions, DeepRM is trained end-to-end, and uses a
scalable backbone that can be tuned via a single parameter for accuracy and
efficiency. During training, a multi-scale optical flow head is added to
predict the optical flow between the observed and synthetic images. Optical
flow prediction stabilizes the training process, and enforces the learning of
features that are relevant to the task of pose estimation. Our results
demonstrate that DeepRM achieves state-of-the-art performance on two widely
accepted challenging datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Harnessing spectral representations for subgraph alignment. (arXiv:2205.14938v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14938">
<div class="article-summary-box-inner">
<span><p>With the rise and advent of graph learning techniques, graph data has become
ubiquitous. However, while several efforts are being devoted to the design of
new convolutional architectures, pooling or positional encoding schemes, less
effort is being spent on problems involving maps between (possibly very large)
graphs, such as signal transfer, graph isomorphism and subgraph correspondence.
With this paper, we anticipate the need for a convenient framework to deal with
such problems, and focus in particular on the challenging subgraph alignment
scenario. We claim that, first and foremost, the representation of a map plays
a central role on how these problems should be modeled. Taking the hint from
recent work in geometry processing, we propose the adoption of a spectral
representation for maps that is compact, easy to compute, robust to topological
changes, easy to plug into existing pipelines, and is especially effective for
subgraph alignment problems. We report for the first time a surprising
phenomenon where the partiality arising in the subgraph alignment task is
manifested as a special structure of the map coefficients, even in the absence
of exact subgraph isomorphism, and which is consistently observed over
different families of graphs up to several thousand nodes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Pre-training of Vision Transformers for Dense Prediction Tasks. (arXiv:2205.15173v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.15173">
<div class="article-summary-box-inner">
<span><p>We present a new self-supervised pre-training of Vision Transformers for
dense prediction tasks. It is based on a contrastive loss across views that
compares pixel-level representations to global image representations. This
strategy produces better local features suitable for dense prediction tasks as
opposed to contrastive pre-training based on global image representation only.
Furthermore, our approach does not suffer from a reduced batch size since the
number of negative examples needed in the contrastive loss is in the order of
the number of local features. We demonstrate the effectiveness of our
pre-training strategy on two dense prediction tasks: semantic segmentation and
monocular depth estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Mapping Necessary for Realistic PointGoal Navigation?. (arXiv:2206.00997v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.00997">
<div class="article-summary-box-inner">
<span><p>Can an autonomous agent navigate in a new environment without building an
explicit map?
</p>
<p>For the task of PointGoal navigation ('Go to $\Delta x$, $\Delta y$') under
idealized settings (no RGB-D and actuation noise, perfect GPS+Compass), the
answer is a clear 'yes' - map-less neural models composed of task-agnostic
components (CNNs and RNNs) trained with large-scale reinforcement learning
achieve 100% Success on a standard dataset (Gibson). However, for PointNav in a
realistic setting (RGB-D and actuation noise, no GPS+Compass), this is an open
question; one we tackle in this paper. The strongest published result for this
task is 71.7% Success.
</p>
<p>First, we identify the main (perhaps, only) cause of the drop in performance:
the absence of GPS+Compass. An agent with perfect GPS+Compass faced with RGB-D
sensing and actuation noise achieves 99.8% Success (Gibson-v2 val). This
suggests that (to paraphrase a meme) robust visual odometry is all we need for
realistic PointNav; if we can achieve that, we can ignore the sensing and
actuation noise.
</p>
<p>With that as our operating hypothesis, we scale the dataset and model size,
and develop human-annotation-free data-augmentation techniques to train models
for visual odometry. We advance the state of art on the Habitat Realistic
PointNav Challenge from 71% to 94% Success (+23, 31% relative) and 53% to 74%
SPL (+21, 40% relative). While our approach does not saturate or 'solve' this
dataset, this strong improvement combined with promising zero-shot sim2real
transfer (to a LoCoBot) provides evidence consistent with the hypothesis that
explicit mapping may not be necessary for navigation, even in a realistic
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Spike Gating Flow: A Hierarchical Structure Based Spiking Neural Network for Online Gesture Recognition. (arXiv:2206.01910v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01910">
<div class="article-summary-box-inner">
<span><p>Action recognition is an exciting research avenue for artificial intelligence
since it may be a game changer in the emerging industrial fields such as
robotic visions and automobiles. However, current deep learning faces major
challenges for such applications because of the huge computational cost and the
inefficient learning. Hence, we develop a novel brain-inspired Spiking Neural
Network (SNN) based system titled Spiking Gating Flow (SGF) for online action
learning. The developed system consists of multiple SGF units which assembled
in a hierarchical manner. A single SGF unit involves three layers: a feature
extraction layer, an event-driven layer and a histogram-based training layer.
To demonstrate the developed system capabilities, we employ a standard Dynamic
Vision Sensor (DVS) gesture classification as a benchmark. The results indicate
that we can achieve 87.5% accuracy which is comparable with Deep Learning (DL),
but at smaller training/inference data number ratio 1.5:1. And only a single
training epoch is required during the learning process. Meanwhile, to the best
of our knowledge, this is the highest accuracy among the non-backpropagation
algorithm based SNNs. At last, we conclude the few-shot learning paradigm of
the developed network: 1) a hierarchical structure-based network design
involves human prior knowledge; 2) SNNs for content based global dynamic
feature detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CAINNFlow: Convolutional block Attention modules and Invertible Neural Networks Flow for anomaly detection and localization tasks. (arXiv:2206.01992v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01992">
<div class="article-summary-box-inner">
<span><p>Detection of object anomalies is crucial in industrial processes, but
unsupervised anomaly detection and localization is particularly important due
to the difficulty of obtaining a large number of defective samples and the
unpredictable types of anomalies in real life. Among the existing unsupervised
anomaly detection and localization methods, the NF-based scheme has achieved
better results. However, the two subnets (complex functions) $s_{i}(u_{i})$ and
$t_{i}(u_{i})$ in NF are usually multilayer perceptrons, which need to squeeze
the input visual features from 2D flattening to 1D, destroying the spatial
location relationship in the feature map and losing the spatial structure
information. In order to retain and effectively extract spatial structure
information, we design in this study a complex function model with alternating
CBAM embedded in a stacked $3\times3$ full convolution, which is able to retain
and effectively extract spatial structure information in the normalized flow
model. Extensive experimental results on the MVTec AD dataset show that
CAINNFlow achieves advanced levels of accuracy and inference efficiency based
on CNN and Transformer backbone networks as feature extractors, and CAINNFlow
achieves a pixel-level AUC of $98.64\%$ for anomaly detection in MVTec AD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Annotation and Learning for 3D Hand Pose Estimation: A Survey. (arXiv:2206.02257v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02257">
<div class="article-summary-box-inner">
<span><p>In this survey, we present comprehensive analysis of 3D hand pose estimation
from the perspective of efficient annotation and learning. In particular, we
study recent approaches for 3D hand pose annotation and learning methods with
limited annotated data. In 3D hand pose estimation, collecting 3D hand pose
annotation is a key step in developing hand pose estimators and their
applications, such as video understanding, AR/VR, and robotics. However,
acquiring annotated 3D hand poses is cumbersome, e.g., due to the difficulty of
accessing 3D information and occlusion. Motivated by elucidating how recent
works address the annotation issue, we investigated annotation methods
classified as manual, synthetic-model-based, hand-sensor-based, and
computational approaches. Since these annotation methods are not always
available on a large scale, we examined methods of learning 3D hand poses when
we do not have enough annotated data, namely self-supervised pre-training,
semi-supervised learning, and domain adaptation. Based on the analysis of these
efficient annotation and learning, we further discuss limitations and possible
future directions of this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SealID: Saimaa ringed seal re-identification dataset. (arXiv:2206.02260v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02260">
<div class="article-summary-box-inner">
<span><p>Wildlife camera traps and crowd-sourced image material provide novel
possibilities to monitor endangered animal species. However, massive image
volumes that these methods produce are overwhelming for researchers to go
through manually which calls for automatic systems to perform the analysis. The
analysis task that has gained the most attention is the re-identification of
individuals, as it allows, for example, to study animal migration or to
estimate the population size. The Saimaa ringed seal (Pusa hispida saimensis)
is an endangered subspecies only found in the Lake Saimaa, Finland, and is one
of the few existing freshwater seal species. Ringed seals have permanent pelage
patterns that are unique to each individual which can be used for the
identification of individuals. Large variation in poses further exacerbated by
the deformable nature of seals together with varying appearance and low
contrast between the ring pattern and the rest of the pelage makes the Saimaa
ringed seal re-identification task very challenging, providing a good benchmark
to evaluate state-of-the-art re-identification methods. Therefore, we make our
Saimaa ringed seal image (SealID) dataset (N=57) publicly available for
research purposes. In this paper, the dataset is described, the evaluation
protocol for re-identification methods is proposed, and the results for two
baseline methods HotSpotter and NORPPA are provided. The SealID dataset has
been made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NORPPA: NOvel Ringed seal re-identification by Pelage Pattern Aggregation. (arXiv:2206.02498v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02498">
<div class="article-summary-box-inner">
<span><p>We propose a method for Saimaa ringed seal (Pusa hispida saimensis)
re-identification. Access to large image volumes through camera trapping and
crowdsourcing provides novel possibilities for animal monitoring and
conservation and calls for automatic methods for analysis, in particular, when
re-identifying individual animals from the images. The proposed method NOvel
Ringed seal re-identification by Pelage Pattern Aggregation (NORPPA) utilizes
the permanent and unique pelage pattern of Saimaa ringed seals and
content-based image retrieval techniques. First, the query image is
preprocessed, and each seal instance is segmented. Next, the seal's pelage
pattern is extracted using a U-net encoder-decoder based method. Then,
CNN-based affine invariant features are embedded and aggregated into Fisher
Vectors. Finally, the cosine distance between the Fisher Vectors is used to
find the best match from a database of known individuals. We perform extensive
experiments of various modifications of the method on a new challenging Saimaa
ringed seals re-identification dataset. The proposed method is shown to produce
the best re-identification accuracy on our dataset in comparisons with
alternative approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Decomposition of Convex Optimization Layers for Consistent Attention in Medical Images. (arXiv:2206.02761v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02761">
<div class="article-summary-box-inner">
<span><p>A key concern in integrating machine learning models in medicine is the
ability to interpret their reasoning. Popular explainability methods have
demonstrated satisfactory results in natural image recognition, yet in medical
image analysis, many of these approaches provide partial and noisy
explanations. Recently, attention mechanisms have shown compelling results both
in their predictive performance and in their interpretable qualities. A
fundamental trait of attention is that it leverages salient parts of the input
which contribute to the model's prediction. To this end, our work focuses on
the explanatory value of attention weight distributions. We propose a
multi-layer attention mechanism that enforces consistent interpretations
between attended convolutional layers using convex optimization. We apply
duality to decompose the consistency constraints between the layers by
reparameterizing their attention probability distributions. We further suggest
learning the dual witness by optimizing with respect to our objective; thus,
our implementation uses standard back-propagation, hence it is highly
efficient. While preserving predictive performance, our proposed method
leverages weakly annotated medical imaging data and provides complete and
faithful explanations to the model's prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low Power Neuromorphic EMG Gesture Classification. (arXiv:2206.02061v1 [eess.SP] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02061">
<div class="article-summary-box-inner">
<span><p>EMG (Electromyograph) signal based gesture recognition can prove vital for
applications such as smart wearables and bio-medical neuro-prosthetic control.
Spiking Neural Networks (SNNs) are promising for low-power, real-time EMG
gesture recognition, owing to their inherent spike/event driven spatio-temporal
dynamics. In literature, there are limited demonstrations of neuromorphic
hardware implementation (at full chip/board/system scale) for EMG gesture
classification. Moreover, most literature attempts exploit primitive SNNs based
on LIF (Leaky Integrate and Fire) neurons. In this work, we address the
aforementioned gaps with following key contributions: (1) Low-power, high
accuracy demonstration of EMG-signal based gesture recognition using
neuromorphic Recurrent Spiking Neural Networks (RSNN). In particular, we
propose a multi-time scale recurrent neuromorphic system based on special
double-exponential adaptive threshold (DEXAT) neurons. Our network achieves
state-of-the-art classification accuracy (90%) while using ~53% lesser neurons
than best reported prior art on Roshambo EMG dataset. (2) A new multi-channel
spike encoder scheme for efficient processing of real-valued EMG data on
neuromorphic systems. (3) Unique multi-compartment methodology to implement
complex adaptive neurons on Intel's dedicated neuromorphic Loihi chip is shown.
(4) RSNN implementation on Loihi (Nahuku 32) achieves significant
energy/latency benefits of ~983X/19X compared to GPU for batch size as 50.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-06-08 23:08:05.921276546 UTC">2022-06-08 23:08:05 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>