<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-07T01:30:00Z">10-07</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Contextual Adaptation with Neural Associative Memory for On-Device Personalized Speech Recognition. (arXiv:2110.02220v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02220">
<div class="article-summary-box-inner">
<span><p>Fast contextual adaptation has shown to be effective in improving Automatic
Speech Recognition (ASR) of rare words and when combined with an on-device
personalized training, it can yield an even better recognition result. However,
the traditional re-scoring approaches based on an external language model is
prone to diverge during the personalized training. In this work, we introduce a
model-based end-to-end contextual adaptation approach that is decoder-agnostic
and amenable to on-device personalization. Our on-device simulation experiments
demonstrate that the proposed approach outperforms the traditional re-scoring
technique by 12% relative WER and 15.7% entity mention specific F1-score in a
continues personalization scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disambiguation-BERT for N-best Rescoring in Low-Resource Conversational ASR. (arXiv:2110.02267v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02267">
<div class="article-summary-box-inner">
<span><p>We study the inclusion of past conversational context through BERT language
models into a CTC-based Automatic Speech Recognition (ASR) system via N-best
rescoring. We introduce a data-efficient strategy to fine-tune BERT on
transcript disambiguation without external data. Our results show word error
rate recoveries up to 37.2% with context-augmented BERT rescoring. We do this
in low-resource data domains, both in language (Norwegian), tone (spontaneous,
conversational), and topics (parliament proceedings and customer service phone
calls). We show how the nature of the data greatly affects the performance of
context-augmented N-best rescoring.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Co-training an Unsupervised Constituency Parser with Weak Supervision. (arXiv:2110.02283v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02283">
<div class="article-summary-box-inner">
<span><p>We introduce a method for unsupervised parsing that relies on bootstrapping
classifiers to identify if a node dominates a specific span in a sentence.
There are two types of classifiers, an inside classifier that acts on a span,
and an outside classifier that acts on everything outside of a given span.
Through self-training and co-training with the two classifiers, we show that
the interplay between them helps improve the accuracy of both, and as a result,
effectively parse. A seed bootstrapping technique prepares the data to train
these classifiers. Our analyses further validate that such an approach in
conjunction with weak supervision using prior branching knowledge of a known
language (left/right-branching) and minimal heuristics injects strong inductive
bias into the parser, achieving 63.1 F$_1$ on the English (PTB) test set. In
addition, we show the effectiveness of our architecture by evaluating on
treebanks for Chinese (CTB) and Japanese (KTB) and achieve new state-of-the-art
results.\footnote{For code or data, please contact the authors.}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-19 India Dataset: Parsing Detailed COVID-19 Data in Daily Health Bulletins from States in India. (arXiv:2110.02311v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02311">
<div class="article-summary-box-inner">
<span><p>While India remains one of the hotspots of the COVID-19 pandemic, data about
the pandemic from the country has proved to be largely inaccessible for use at
scale. Much of the data exists in an unstructured form on the web, and limited
aspects of such data are available through public APIs maintained manually
through volunteer efforts. This has proved to be difficult both in terms of
ease of access to detailed data as well as with regards to the maintenance of
manual data-keeping over time. This paper reports on a recently launched
project aimed at automating the extraction of such data from public health
bulletins with the help of a combination of classical PDF parsers as well as
state-of-the-art ML-based documents extraction APIs. In this paper, we will
describe the automated data-extraction technique, the nature of the generated
data, and exciting avenues of ongoing work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Conditional Text Generation for Aspect-Based Sentiment Analysis. (arXiv:2110.02334v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02334">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis (ABSA) is an NLP task that entails processing
user-generated reviews to determine (i) the target being evaluated, (ii) the
aspect category to which it belongs, and (iii) the sentiment expressed towards
the target and aspect pair. In this article, we propose transforming ABSA into
an abstract summary-like conditional text generation task that uses targets,
aspects, and polarities to generate auxiliary statements. To demonstrate the
efficacy of our task formulation and a proposed system, we fine-tune a
pre-trained model for conditional text generation tasks to get new
state-of-the-art results on a few restaurant domains and urban neighborhoods
domain benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EntQA: Entity Linking as Question Answering. (arXiv:2110.02369v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02369">
<div class="article-summary-box-inner">
<span><p>A conventional approach to entity linking is to first find mentions in a
given document and then infer their underlying entities in the knowledge base.
A well-known limitation of this approach is that it requires finding mentions
without knowing their entities, which is unnatural and difficult. We present a
new model that does not suffer from this limitation called EntQA, which stands
for Entity linking as Question Answering. EntQA first proposes candidate
entities with a fast retrieval module, and then scrutinizes the document to
find mentions of each candidate with a powerful reader module. Our approach
combines progress in entity linking with that in open-domain question answering
and capitalizes on pretrained models for dense entity retrieval and reading
comprehension. Unlike in previous works, we do not rely on a mention-candidates
dictionary or large-scale weak supervision. EntQA achieves strong results on
the GERBIL benchmarking platform.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning. (arXiv:2110.02370v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02370">
<div class="article-summary-box-inner">
<span><p>Large natural language models (such as GPT-3 or T5) demonstrate impressive
abilities across a range of general NLP tasks. Here, we show that the knowledge
embedded in such models provides a useful inductive bias, not just on
traditional NLP tasks, but also in the nontraditional task of training a
symbolic reasoning engine. We observe that these engines learn quickly and
generalize in a natural way that reflects human intuition. For example,
training such a system to model block-stacking might naturally generalize to
stacking other types of objects because of structure in the real world that has
been partially captured by the language describing it. We study several
abstract textual reasoning tasks, such as object manipulation and navigation,
and demonstrate multiple types of generalization to novel scenarios and the
symbols that comprise them. We also demonstrate the surprising utility of
\textit{compositional learning}, where a learner dedicated to mastering a
complicated task gains an advantage by training on relevant simpler tasks
instead of jumping straight to the complicated task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpreting intermediate convolutional layers in unsupervised acoustic word classification. (arXiv:2110.02375v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02375">
<div class="article-summary-box-inner">
<span><p>Understanding how deep convolutional neural networks classify data has been
subject to extensive research. This paper proposes a technique to visualize and
interpret intermediate layers of unsupervised deep convolutional neural
networks by averaging over individual feature maps in each convolutional layer
and inferring underlying distributions of words with non-linear regression
techniques. A GAN-based architecture (ciwGAN <a href="/abs/2006.02951">arXiv:2006.02951</a>) that includes
three convolutional networks (a Generator, a Discriminator, and a classifier)
was trained on unlabeled sliced lexical items from TIMIT. The training results
in a deep convolutional network that learns to classify words into discrete
classes only from the requirement of the Generator to output informative data.
The classifier network has no access to the training data -- only to the
generated data -- which means lexical learning needs to emerge in a fully
unsupervised manner. We propose a technique to visualize individual
convolutional layers in the classifier that yields highly informative
time-series data for each convolutional layer and apply it to unobserved test
data. Using non-linear regression, we infer underlying distributions for each
word which allows us to analyze both absolute values and shapes of individual
words at different convolutional layers as well as perform hypothesis testing
on their acoustic properties. The technique also allows us to tests individual
phone contrasts and how they are represented at each layer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing the Effects of Reasoning Types on Cross-Lingual Transfer Performance. (arXiv:2110.02386v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02386">
<div class="article-summary-box-inner">
<span><p>Multilingual language models achieve impressive zero-shot accuracies in many
languages in complex tasks such as Natural Language Inference (NLI). Examples
in NLI (and equivalent complex tasks) often pertain to various types of
sub-tasks, requiring different kinds of reasoning. Certain types of reasoning
have proven to be more difficult to learn in a monolingual context, and in the
crosslingual context, similar observations may shed light on zero-shot transfer
efficiency and few-shot sample selection. Hence, to investigate the effects of
types of reasoning on transfer performance, we propose a category-annotated
multilingual NLI dataset and discuss the challenges to scale monolingual
annotations to multiple languages. We statistically observe interesting effects
that the confluence of reasoning types and language similarities have on
transfer performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Modeling using LMUs: 10x Better Data Efficiency or Improved Scaling Compared to Transformers. (arXiv:2110.02402v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02402">
<div class="article-summary-box-inner">
<span><p>Recent studies have demonstrated that the performance of transformers on the
task of language modeling obeys a power-law relationship with model size over
six orders of magnitude. While transformers exhibit impressive scaling, their
performance hinges on processing large amounts of data, and their computational
and memory requirements grow quadratically with sequence length. Motivated by
these considerations, we construct a Legendre Memory Unit based model that
introduces a general prior for sequence processing and exhibits an $O(n)$ and
$O(n \ln n)$ (or better) dependency for memory and computation respectively.
Over three orders of magnitude, we show that our new architecture attains the
same accuracy as transformers with 10x fewer tokens. We also show that for the
same amount of training our model improves the loss over transformers about as
much as transformers improve over LSTMs. Additionally, we demonstrate that
adding global self-attention complements our architecture and the augmented
model improves performance even further.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Word Acquisition in Neural Language Models. (arXiv:2110.02406v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02406">
<div class="article-summary-box-inner">
<span><p>We investigate how neural language models acquire individual words during
training, extracting learning curves and ages of acquisition for over 600 words
on the MacArthur-Bates Communicative Development Inventory (Fenson et al.,
2007). Drawing on studies of word acquisition in children, we evaluate multiple
predictors for words' ages of acquisition in LSTMs, BERT, and GPT-2. We find
that the effects of concreteness, word length, and lexical class are pointedly
different in children and language models, reinforcing the importance of
interaction and sensorimotor experience in child language acquisition. Language
models rely far more on word frequency than children, but like children, they
exhibit slower learning of words in longer utterances. Interestingly, models
follow consistent patterns during training for both unidirectional and
bidirectional models, and for both LSTM and Transformer architectures. Models
predict based on unigram token frequencies early in training, before
transitioning loosely to bigram probabilities, eventually converging on more
nuanced predictions. These results shed light on the role of distributional
learning mechanisms in children, while also providing insights for more
human-like language acquisition in language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Voice Aging with Audio-Visual Style Transfer. (arXiv:2110.02411v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02411">
<div class="article-summary-box-inner">
<span><p>Face aging techniques have used generative adversarial networks (GANs) and
style transfer learning to transform one's appearance to look younger/older.
Identity is maintained by conditioning these generative networks on a learned
vector representation of the source content. In this work, we apply a similar
approach to age a speaker's voice, referred to as voice aging. We first analyze
the classification of a speaker's age by training a convolutional neural
network (CNN) on the speaker's voice and face data from Common Voice and
VoxCeleb datasets. We generate aged voices from style transfer to transform an
input spectrogram to various ages and demonstrate our method on a mobile app.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Federated Distillation of Natural Language Understanding with Confident Sinkhorns. (arXiv:2110.02432v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02432">
<div class="article-summary-box-inner">
<span><p>Enhancing the user experience is an essential task for application service
providers. For instance, two users living wide apart may have different tastes
of food. A food recommender mobile application installed on an edge device
might want to learn from user feedback (reviews) to satisfy the client's needs
pertaining to distinct domains. Retrieving user data comes at the cost of
privacy while asking for model parameters trained on a user device becomes
space inefficient at a large scale. In this work, we propose an approach to
learn a central (global) model from the federation of (local) models which are
trained on user-devices, without disclosing the local data or model parameters
to the server. We propose a federation mechanism for the problems with natural
similarity metric between the labels which commonly appear in natural language
understanding (NLU) tasks. To learn the global model, the objective is to
minimize the optimal transport cost of the global model's predictions from the
confident sum of soft-targets assigned by local models. The confidence (a model
weighting scheme) score of a model is defined as the L2 distance of a model's
prediction from its probability bias. The method improves the global model's
performance over the baseline designed on three NLU tasks with intrinsic label
space semantics, i.e., fine-grained sentiment analysis, emotion recognition in
conversation, and natural language inference. We make our codes public at
https://github.com/declare-lab/sinkhorn-loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PoNet: Pooling Network for Efficient Token Mixing in Long Sequences. (arXiv:2110.02442v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02442">
<div class="article-summary-box-inner">
<span><p>Transformer-based models have achieved great success in various NLP, vision,
and speech tasks. However, the core of Transformer, the self-attention
mechanism, has a quadratic time and memory complexity with respect to the
sequence length, which hinders applications of Transformer-based models to long
sequences. Many approaches have been proposed to mitigate this problem, such as
sparse attention mechanisms, low-rank matrix approximations and scalable
kernels, and token mixing alternatives to self-attention. We propose a novel
Pooling Network (PoNet) for token mixing in long sequences with linear
complexity. We design multi-granularity pooling and pooling fusion to capture
different levels of contextual information and combine their interactions with
tokens. On the Long Range Arena benchmark, PoNet significantly outperforms
Transformer and achieves competitive accuracy, while being only slightly slower
than the fastest model, FNet, across all sequence lengths measured on GPUs. We
also conduct systematic studies on the transfer learning capability of PoNet
and observe that PoNet achieves 96.0% of the accuracy of BERT on the GLUE
benchmark, outperforming FNet by 4.5% relative. Comprehensive ablation analysis
demonstrates effectiveness of the designed multi-granularity pooling and
pooling fusion for token mixing in long sequences and efficacy of the designed
pre-training tasks for PoNet to learn transferable contextualized language
representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models. (arXiv:2110.02467v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02467">
<div class="article-summary-box-inner">
<span><p>Pre-trained Natural Language Processing (NLP) models can be easily adapted to
a variety of downstream language tasks. This significantly accelerates the
development of language models. However, NLP models have been shown to be
vulnerable to backdoor attacks, where a pre-defined trigger word in the input
text causes model misprediction. Previous NLP backdoor attacks mainly focus on
some specific tasks. This makes those attacks less general and applicable to
other kinds of NLP models and tasks. In this work, we propose \Name, the first
task-agnostic backdoor attack against the pre-trained NLP models. The key
feature of our attack is that the adversary does not need prior information
about the downstream tasks when implanting the backdoor to the pre-trained
model. When this malicious model is released, any downstream models transferred
from it will also inherit the backdoor, even after the extensive transfer
learning process. We further design a simple yet effective strategy to bypass a
state-of-the-art defense. Experimental results indicate that our approach can
compromise a wide range of downstream NLP tasks in an effective and stealthy
way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ABC: Attention with Bounded-memory Control. (arXiv:2110.02488v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02488">
<div class="article-summary-box-inner">
<span><p>Transformer architectures have achieved state-of-the-art results on a variety
of sequence modeling tasks. However, their attention mechanism comes with a
quadratic complexity in sequence lengths, making the computational overhead
prohibitive, especially for long sequences. Attention context can be seen as a
random-access memory with each token taking a slot. Under this perspective, the
memory size grows linearly with the sequence length, and so does the overhead
of reading from it. One way to improve the efficiency is to bound the memory
size. We show that disparate approaches can be subsumed into one abstraction,
attention with bounded-memory control (ABC), and they vary in their
organization of the memory. ABC reveals new, unexplored possibilities. First,
it connects several efficient attention variants that would otherwise seem
apart. Second, this abstraction gives new insights--an established approach
(Wang et al., 2020b) previously thought to be not applicable in causal
attention, actually is. Last, we present a new instance of ABC, which draws
inspiration from existing ABC approaches, but replaces their heuristic
memory-organizing functions with a learned, contextualized one. Our experiments
on language modeling, machine translation, and masked language model finetuning
show that our approach outperforms previous efficient attention models;
compared to the strong transformer baselines, it significantly improves the
inference time and space efficiency with no or negligible accuracy loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KNN-BERT: Fine-Tuning Pre-Trained Models with KNN Classifier. (arXiv:2110.02523v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02523">
<div class="article-summary-box-inner">
<span><p>Pre-trained models are widely used in fine-tuning downstream tasks with
linear classifiers optimized by the cross-entropy loss, which might face
robustness and stability problems. These problems can be improved by learning
representations that focus on similarities in the same class and contradictions
in different classes when making predictions. In this paper, we utilize the
K-Nearest Neighbors Classifier in pre-trained model fine-tuning. For this KNN
classifier, we introduce a supervised momentum contrastive learning framework
to learn the clustered representations of the supervised downstream tasks.
Extensive experiments on text classification tasks and robustness tests show
that by incorporating KNNs with the traditional fine-tuning process, we can
obtain significant improvements on the clean accuracy in both rich-source and
few-shot settings and can improve the robustness against adversarial attacks.
\footnote{all codes is available at https://github.com/LinyangLee/KNN-BERT}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Multi-Modal Embeddings from Structured Data. (arXiv:2110.02577v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02577">
<div class="article-summary-box-inner">
<span><p>Multi-modal word semantics aims to enhance embeddings with perceptual input,
assuming that human meaning representation is grounded in sensory experience.
Most research focuses on evaluation involving direct visual input, however,
visual grounding can contribute to linguistic applications as well. Another
motivation for this paper is the growing need for more interpretable models and
for evaluating model efficiency regarding size and performance. This work
explores the impact of visual information for semantics when the evaluation
involves no direct visual input, specifically semantic similarity and
relatedness. We investigate a new embedding type in-between linguistic and
visual modalities, based on the structured annotations of Visual Genome. We
compare uni- and multi-modal models including structured, linguistic and image
based representations. We measure the efficiency of each model with regard to
data and model size, modality / data distribution and information gain. The
analysis includes an interpretation of embedding structures. We found that this
new embedding conveys complementary information for text based embeddings. It
achieves comparable performance in an economic way, using orders of magnitude
less resources than visual models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly-supervised Text Classification Based on Keyword Graph. (arXiv:2110.02591v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02591">
<div class="article-summary-box-inner">
<span><p>Weakly-supervised text classification has received much attention in recent
years for it can alleviate the heavy burden of annotating massive data. Among
them, keyword-driven methods are the mainstream where user-provided keywords
are exploited to generate pseudo-labels for unlabeled texts. However, existing
methods treat keywords independently, thus ignore the correlation among them,
which should be useful if properly exploited. In this paper, we propose a novel
framework called ClassKG to explore keyword-keyword correlation on keyword
graph by GNN. Our framework is an iterative process. In each iteration, we
first construct a keyword graph, so the task of assigning pseudo labels is
transformed to annotating keyword subgraphs. To improve the annotation quality,
we introduce a self-supervised task to pretrain a subgraph annotator, and then
finetune it. With the pseudo labels generated by the subgraph annotator, we
then train a text classifier to classify the unlabeled texts. Finally, we
re-extract keywords from the classified texts. Extensive experiments on both
long-text and short-text datasets show that our method substantially
outperforms the existing ones
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning. (arXiv:2110.02600v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02600">
<div class="article-summary-box-inner">
<span><p>Multilingual models jointly pretrained on multiple languages have achieved
remarkable performance on various multilingual downstream tasks. Moreover,
models finetuned on a single monolingual downstream task have shown to
generalize to unseen languages. In this paper, we first show that it is crucial
for those tasks to align gradients between them in order to maximize knowledge
transfer while minimizing negative transfer. Despite its importance, the
existing methods for gradient alignment either have a completely different
purpose, ignore inter-task alignment, or aim to solve continual learning
problems in rather inefficient ways. As a result of the misaligned gradients
between tasks, the model suffers from severe negative transfer in the form of
catastrophic forgetting of the knowledge acquired from the pretraining. To
overcome the limitations, we propose a simple yet effective method that can
efficiently align gradients between tasks. Specifically, we perform each
inner-optimization by sequentially sampling batches from all the tasks,
followed by a Reptile outer update. Thanks to the gradients aligned between
tasks by our method, the model becomes less vulnerable to negative transfer and
catastrophic forgetting. We extensively validate our method on various
multi-task learning and zero-shot cross-lingual transfer tasks, where our
method largely outperforms all the relevant baselines we consider.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Application of the interactive Leipzig Corpus Miner as a generic research platform for the use in the social sciences. (arXiv:2110.02708v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02708">
<div class="article-summary-box-inner">
<span><p>This article introduces to the interactive Leipzig Corpus Miner (iLCM) - a
newly released, open-source software to perform automatic content analysis.
Since the iLCM is based on the R-programming language, its generic text mining
procedures provided via a user-friendly graphical user interface (GUI) can
easily be extended using the integrated IDE RStudio-Server or numerous other
interfaces in the tool. Furthermore, the iLCM offers various possibilities to
use quantitative and qualitative research approaches in combination. Some of
these possibilities will be presented in more detail in the following.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How BPE Affects Memorization in Transformers. (arXiv:2110.02782v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02782">
<div class="article-summary-box-inner">
<span><p>Training data memorization in NLP can both be beneficial (e.g., closed-book
QA) and undesirable (personal data extraction). In any case, successful model
training requires a non-trivial amount of memorization to store word spellings,
various linguistic idiosyncrasies and common knowledge. However, little is
known about what affects the memorization behavior of NLP models, as the field
tends to focus on the equally important question of generalization. In this
work, we demonstrate that the size of the subword vocabulary learned by
Byte-Pair Encoding (BPE) greatly affects both ability and tendency of standard
Transformer models to memorize training data, even when we control for the
number of learned parameters. We find that with a large subword vocabulary
size, Transformer models fit random mappings more easily and are more
vulnerable to membership inference attacks. Similarly, given a prompt,
Transformer-based language models with large subword vocabularies reproduce the
training data more often. We conjecture this effect is caused by reduction in
the sequences' length that happens as the BPE vocabulary grows. Our findings
can allow a more informed choice of hyper-parameters, that is better tailored
for a particular use-case.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spell my name: keyword boosted speech recognition. (arXiv:2110.02791v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02791">
<div class="article-summary-box-inner">
<span><p>Recognition of uncommon words such as names and technical terminology is
important to understanding conversations in context. However, the ability to
recognise such words remains a challenge in modern automatic speech recognition
(ASR) systems.
</p>
<p>In this paper, we propose a simple but powerful ASR decoding method that can
better recognise these uncommon keywords, which in turn enables better
readability of the results. The method boosts the probabilities of given
keywords in a beam search based on acoustic model predictions. The method does
not require any training in advance.
</p>
<p>We demonstrate the effectiveness of our method on the LibriSpeeech test sets
and also internal data of real-world conversations. Our method significantly
boosts keyword accuracy on the test sets, while maintaining the accuracy of the
other words, and as well as providing significant qualitative improvements.
This method is applicable to other tasks such as machine translation, or
wherever unseen and difficult keywords need to be recognised in beam search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-conditioning pre-trained language models. (arXiv:2110.02802v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02802">
<div class="article-summary-box-inner">
<span><p>We study the presence of expert units in pre-trained Transformer-based
Language Models (TLMs), and how they can be used to condition text generation
to contain specific concepts. We define expert units to be neurons that are
able to detect a concept in the input with a given average precision. A concept
is represented with a set of sentences that either do or do not contain the
concept. Leveraging the OneSec dataset, we compile a dataset of 1344 concepts
that allows diverse expert units in TLMs to be discovered. Our experiments
demonstrate that off-the-shelf pre-trained TLMs can be conditioned on their own
knowledge (self-conditioning) to generate text that contains a given concept.
To this end, we intervene on the top expert units by fixing their output during
inference, and we show experimentally that this is an effective method to
condition TLMs. Our method does not require fine-tuning the model or using
additional parameters, which allows conditioning large TLM with minimal compute
resources. Furthermore, by intervening on a small number of experts in GPT2, we
can achieve parity with respect to two concepts at generation time. The
specific case of gender bias is explored, and we show that, for given contexts,
gender parity is achieved while maintaining the model's perplexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation Prediction as an Auxiliary Training Objective for Improving Multi-Relational Graph Representations. (arXiv:2110.02834v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02834">
<div class="article-summary-box-inner">
<span><p>Learning good representations on multi-relational graphs is essential to
knowledge base completion (KBC). In this paper, we propose a new
self-supervised training objective for multi-relational graph representation
learning, via simply incorporating relation prediction into the commonly used
1vsAll objective. The new training objective contains not only terms for
predicting the subject and object of a given triple, but also a term for
predicting the relation type. We analyse how this new objective impacts
multi-relational learning in KBC: experiments on a variety of datasets and
models show that relation prediction can significantly improve entity ranking,
the most widely used evaluation task for KBC, yielding a 6.1% increase in MRR
and 9.9% increase in Hits@1 on FB15k-237 as well as a 3.1% increase in MRR and
3.4% in Hits@1 on Aristo-v4. Moreover, we observe that the proposed objective
is especially effective on highly multi-relational datasets, i.e. datasets with
a large number of predicates, and generates better representations when larger
embedding sizes are used.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parallel Composition of Weighted Finite-State Transducers. (arXiv:2110.02848v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02848">
<div class="article-summary-box-inner">
<span><p>Finite-state transducers (FSTs) are frequently used in speech recognition.
Transducer composition is an essential operation for combining different
sources of information at different granularities. However, composition is also
one of the more computationally expensive operations. Due to the heterogeneous
structure of FSTs, parallel algorithms for composition are suboptimal in
efficiency, generality, or both. We propose an algorithm for parallel
composition and implement it on graphics processing units. We benchmark our
parallel algorithm on the composition of random graphs and the composition of
graphs commonly used in speech recognition. The parallel composition scales
better with the size of the input graphs and for large graphs can be as much as
10 to 30 times faster than a sequential CPU algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PSG HASOC-Dravidian CodeMixFIRE2021: Pretrained Transformers for Offensive Language Identification in Tanglish. (arXiv:2110.02852v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02852">
<div class="article-summary-box-inner">
<span><p>This paper describes the system submitted to Dravidian-Codemix-HASOC2021:
Hate Speech and Offensive Language Identification in Dravidian Languages
(Tamil-English and Malayalam-English). This task aims to identify offensive
content in code-mixed comments/posts in Dravidian Languages collected from
social media. Our approach utilizes pooling the last layers of pretrained
transformer multilingual BERT for this task which helped us achieve rank nine
on the leaderboard with a weighted average score of 0.61 for the Tamil-English
dataset in subtask B. After the task deadline, we sampled the dataset uniformly
and used the MuRIL pretrained model, which helped us achieve a weighted average
score of 0.67, the top score in the leaderboard. Furthermore, our approach to
utilizing the pretrained models helps reuse our models for the same task with a
different dataset. Our code and models are available in GitHub 1
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence-to-Sequence Lexical Normalization with Multilingual Transformers. (arXiv:2110.02869v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02869">
<div class="article-summary-box-inner">
<span><p>Current benchmark tasks for natural language processing contain text that is
qualitatively different from the text used in informal day to day digital
communication. This discrepancy has led to severe performance degradation of
state-of-the-art NLP models when fine-tuned on real-world data. One way to
resolve this issue is through lexical normalization, which is the process of
transforming non-standard text, usually from social media, into a more
standardized form. In this work, we propose a sentence-level
sequence-to-sequence model based on mBART, which frames the problem as a
machine translation problem. As the noisy text is a pervasive problem across
languages, not just English, we leverage the multi-lingual pre-training of
mBART to fine-tune it to our data. While current approaches mainly operate at
the word or subword level, we argue that this approach is straightforward from
a technical standpoint and builds upon existing pre-trained transformer
networks. Our results show that while word-level, intrinsic, performance
evaluation is behind other methods, our model improves performance on
extrinsic, downstream tasks through normalization compared to models operating
on raw, unprocessed, social media text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capturing Structural Locality in Non-parametric Language Models. (arXiv:2110.02870v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02870">
<div class="article-summary-box-inner">
<span><p>Structural locality is a ubiquitous feature of real-world datasets, wherein
data points are organized into local hierarchies. Some examples include topical
clusters in text or project hierarchies in source code repositories. In this
paper, we explore utilizing this structural locality within non-parametric
language models, which generate sequences that reference retrieved examples
from an external source. We propose a simple yet effective approach for adding
locality information into such models by adding learned parameters that improve
the likelihood of retrieving examples from local neighborhoods. Experiments on
two different domains, Java source code and Wikipedia text, demonstrate that
locality features improve model efficacy over models without access to these
features, with interesting differences. We also perform an analysis of how and
where locality features contribute to improved performance and why the
traditionally used contextual similarity metrics alone are not enough to grasp
the locality structure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human-in-the-Loop Refinement of Word Embeddings. (arXiv:2110.02884v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02884">
<div class="article-summary-box-inner">
<span><p>Word embeddings are a fixed, distributional representation of the context of
words in a corpus learned from word co-occurrences. Despite their proven
utility in machine learning tasks, word embedding models may capture uneven
semantic and syntactic representations, and can inadvertently reflect various
kinds of bias present within corpora upon which they were trained. It has been
demonstrated that post-processing of word embeddings to apply information found
in lexical dictionaries can improve the semantic associations, thus improving
their quality. Building on this idea, we propose a system that incorporates an
adaptation of word embedding post-processing, which we call "interactive
refitting", to address some of the most daunting qualitative problems found in
word embeddings. Our approach allows a human to identify and address potential
quality issues with word embeddings interactively. This has the advantage of
negating the question of who decides what constitutes bias or what other
quality issues may affect downstream tasks. It allows each organization or
entity to address concerns they may have at a fine grained level and to do so
in an iterative and interactive fashion. It also allows for better insight into
what effect word embeddings, and refinements to word embeddings, have on
machine learning pipelines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Optimal Transport as Alignment Objective for fine-tuning Multilingual Contextualized Embeddings. (arXiv:2110.02887v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02887">
<div class="article-summary-box-inner">
<span><p>Recent studies have proposed different methods to improve multilingual word
representations in contextualized settings including techniques that align
between source and target embedding spaces. For contextualized embeddings,
alignment becomes more complex as we additionally take context into
consideration. In this work, we propose using Optimal Transport (OT) as an
alignment objective during fine-tuning to further improve multilingual
contextualized representations for downstream cross-lingual transfer. This
approach does not require word-alignment pairs prior to fine-tuning that may
lead to sub-optimal matching and instead learns the word alignments within
context in an unsupervised manner. It also allows different types of mappings
due to soft matching between source and target sentences. We benchmark our
proposed method on two tasks (XNLI and XQuAD) and achieve improvements over
baselines as well as competitive results compared to similar recent works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Knowledge Assimilation for Expert-Layman Text Style Transfer. (arXiv:2110.02950v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02950">
<div class="article-summary-box-inner">
<span><p>Expert-layman text style transfer technologies have the potential to improve
communication between members of scientific communities and the general public.
High-quality information produced by experts is often filled with difficult
jargon laypeople struggle to understand. This is a particularly notable issue
in the medical domain, where layman are often confused by medical text online.
At present, two bottlenecks interfere with the goal of building high-quality
medical expert-layman style transfer systems: a dearth of pretrained
medical-domain language models spanning both expert and layman terminologies
and a lack of parallel corpora for training the transfer task itself. To
mitigate the first issue, we propose a novel language model (LM) pretraining
task, Knowledge Base Assimilation, to synthesize pretraining data from the
edges of a graph of expert- and layman-style medical terminology terms into an
LM during self-supervised learning. To mitigate the second issue, we build a
large-scale parallel corpus in the medical expert-layman domain using a
margin-based criterion. Our experiments show that transformer-based models
pretrained on knowledge base assimilation and other well-established
pretraining tasks fine-tuning on our new parallel corpus leads to considerable
improvement against expert-layman transfer benchmarks, gaining an average
relative improvement of our human evaluation, the Overall Success Rate (OSR),
by 106%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical prosody modeling and control in non-autoregressive parallel neural TTS. (arXiv:2110.02952v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02952">
<div class="article-summary-box-inner">
<span><p>Neural text-to-speech (TTS) synthesis can generate speech that is
indistinguishable from natural speech. However, the synthetic speech often
represents the average prosodic style of the database instead of having more
versatile prosodic variation. Moreover, many models lack the ability to control
the output prosody, which does not allow for different styles for the same text
input. In this work, we train a non-autoregressive parallel neural TTS model
hierarchically conditioned on both coarse and fine-grained acoustic speech
features to learn a latent prosody space with intuitive and meaningful
dimensions. Experiments show that a non-autoregressive TTS model hierarchically
conditioned on utterance-wise pitch, pitch range, duration, energy, and
spectral tilt can effectively control each prosodic dimension, generate a wide
variety of speaking styles, and provide word-wise emphasis control, while
maintaining equal or better quality to the baseline model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On learning an interpreted language with recurrent models. (arXiv:1809.04128v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1809.04128">
<div class="article-summary-box-inner">
<span><p>Can recurrent neural nets, inspired by human sequential data processing,
learn to understand language? We construct simplified datasets reflecting core
properties of natural language as modeled in formal syntax and semantics:
recursive syntactic structure and compositionality. We find LSTM and GRU
networks to generalise to compositional interpretation well, but only in the
most favorable learning settings, with a well-paced curriculum, extensive
training data, and left-to-right (but not right-to-left) composition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From SCAN to Real Data: Systematic Generalization via Meaningful Learning. (arXiv:2003.06658v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06658">
<div class="article-summary-box-inner">
<span><p>Humans can systematically generalize to novel compositions of existing
concepts. There have been extensive conjectures into the extent to which neural
networks can do the same. Recent arguments supported by evidence on the SCAN
dataset claim that neural networks are inherently ineffective in such cognitive
capacity. In this paper, we revisit systematic generalization from the
perspective of meaningful learning, an exceptional capability of humans to
learn new concepts by connecting them with other previously known knowledge. We
propose to augment a training dataset in either an inductive or deductive
manner to build semantic links between new and old concepts. Our observations
on SCAN suggest that, following the meaningful learning principle, modern
sequence-to-sequence models, including RNNs, CNNs, and Transformers, can
successfully generalize to compositions of new concepts. We further validate
our findings on two real-world datasets on semantic parsing and consistent
compositional generalization is also observed. Moreover, our experiments
demonstrate that both prior knowledge and semantic linking play a key role to
achieve systematic generalization. Meanwhile, inductive learning generally
works better than deductive learning in our experiments. Finally, we provide an
explanation for data augmentation techniques by concluding them into either
inductive-based or deductive-based meaningful learning. We hope our findings
will encourage excavating existing neural networks' potential in systematic
generalization through more advanced learning schemes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HittER: Hierarchical Transformers for Knowledge Graph Embeddings. (arXiv:2008.12813v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.12813">
<div class="article-summary-box-inner">
<span><p>This paper examines the challenging problem of learning representations of
entities and relations in a complex multi-relational knowledge graph. We
propose HittER, a Hierarchical Transformer model to jointly learn
Entity-relation composition and Relational contextualization based on a source
entity's neighborhood. Our proposed model consists of two different Transformer
blocks: the bottom block extracts features of each entity-relation pair in the
local neighborhood of the source entity and the top block aggregates the
relational information from outputs of the bottom block. We further design a
masked entity prediction task to balance information from the relational
context and the source entity itself. Experimental results show that HittER
achieves new state-of-the-art results on multiple link prediction datasets. We
additionally propose a simple approach to integrate HittER into BERT and
demonstrate its effectiveness on two Freebase factoid question answering
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdapterDrop: On the Efficiency of Adapters in Transformers. (arXiv:2010.11918v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11918">
<div class="article-summary-box-inner">
<span><p>Massively pre-trained transformer models are computationally expensive to
fine-tune, slow for inference, and have large storage requirements. Recent
approaches tackle these shortcomings by training smaller models, dynamically
reducing the model size, and by training light-weight adapters. In this paper,
we propose AdapterDrop, removing adapters from lower transformer layers during
training and inference, which incorporates concepts from all three directions.
We show that AdapterDrop can dynamically reduce the computational overhead when
performing inference over multiple tasks simultaneously, with minimal decrease
in task performances. We further prune adapters from AdapterFusion, which
improves the inference efficiency while maintaining the task performances
entirely.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MPG: A Multi-ingredient Pizza Image Generator with Conditional StyleGANs. (arXiv:2012.02821v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02821">
<div class="article-summary-box-inner">
<span><p>Multilabel conditional image generation is a challenging problem in computer
vision. In this work we propose Multi-ingredient Pizza Generator (MPG), a
conditional Generative Neural Network (GAN) framework for synthesizing
multilabel images. We design MPG based on a state-of-the-art GAN structure
called StyleGAN2, in which we develop a new conditioning technique by enforcing
intermediate feature maps to learn scalewise label information. Because of the
complex nature of the multilabel image generation problem, we also regularize
synthetic image by predicting the corresponding ingredients as well as
encourage the discriminator to distinguish between matched image and mismatched
image. To verify the efficacy of MPG, we test it on Pizza10, which is a
carefully annotated multi-ingredient pizza image dataset. MPG can successfully
generate photo-realist pizza images with desired ingredients. The framework can
be easily extend to other multilabel image generation scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast WordPiece Tokenization. (arXiv:2012.15524v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15524">
<div class="article-summary-box-inner">
<span><p>Tokenization is a fundamental preprocessing step for almost all NLP tasks. In
this paper, we propose efficient algorithms for the WordPiece tokenization used
in BERT, from single-word tokenization to general text (e.g., sentence)
tokenization. When tokenizing a single word, WordPiece uses a
longest-match-first strategy, known as maximum matching. The best known
algorithms so far are O(n^2) (where n is the input length) or O(nm) (where m is
the maximum vocabulary token length). We propose a novel algorithm whose
tokenization complexity is strictly O(n). Our method is inspired by the
Aho-Corasick algorithm. We introduce additional linkages on top of the trie
built from the vocabulary, allowing smart transitions when the trie matching
cannot continue. For general text, we further propose an algorithm that
combines pre-tokenization (splitting the text into words) and our linear-time
WordPiece method into a single pass. Experimental results show that our method
is 8.2x faster than HuggingFace Tokenizers and 5.1x faster than TensorFlow Text
on average for general text tokenization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MUFASA: Multimodal Fusion Architecture Search for Electronic Health Records. (arXiv:2102.02340v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02340">
<div class="article-summary-box-inner">
<span><p>One important challenge of applying deep learning to electronic health
records (EHR) is the complexity of their multimodal structure. EHR usually
contains a mixture of structured (codes) and unstructured (free-text) data with
sparse and irregular longitudinal features -- all of which doctors utilize when
making decisions. In the deep learning regime, determining how different
modality representations should be fused together is a difficult problem, which
is often addressed by handcrafted modeling and intuition. In this work, we
extend state-of-the-art neural architecture search (NAS) methods and propose
MUltimodal Fusion Architecture SeArch (MUFASA) to simultaneously search across
multimodal fusion strategies and modality-specific architectures for the first
time. We demonstrate empirically that our MUFASA method outperforms established
unimodal NAS on public EHR data with comparable computation costs. In addition,
MUFASA produces architectures that outperform Transformer and Evolved
Transformer. Compared with these baselines on CCS diagnosis code prediction,
our discovered models improve top-5 recall from 0.88 to 0.91 and demonstrate
the ability to generalize to other EHR tasks. Studying our top architecture in
depth, we provide empirical evidence that MUFASA's improvements are derived
from its ability to both customize modeling for each data modality and find
effective fusion strategies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Attention with Linear Units. (arXiv:2104.07012v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07012">
<div class="article-summary-box-inner">
<span><p>Recently, it has been argued that encoder-decoder models can be made more
interpretable by replacing the softmax function in the attention with its
sparse variants. In this work, we introduce a novel, simple method for
achieving sparsity in attention: we replace the softmax activation with a ReLU,
and show that sparsity naturally emerges from such a formulation. Training
stability is achieved with layer normalization with either a specialized
initialization or an additional gating function. Our model, which we call
Rectified Linear Attention (ReLA), is easy to implement and more efficient than
previously proposed sparse attention mechanisms. We apply ReLA to the
Transformer and conduct experiments on five machine translation tasks. ReLA
achieves translation performance comparable to several strong baselines, with
training and decoding speed similar to that of the vanilla attention. Our
analysis shows that ReLA delivers high sparsity rate and head diversity, and
the induced cross attention achieves better accuracy with respect to
source-target word alignment than recent sparsified softmax-based models.
Intriguingly, ReLA heads also learn to attend to nothing (i.e. 'switch off')
for some queries, which is not possible with sparsified softmax alternatives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visually grounded models of spoken language: A survey of datasets, architectures and evaluation techniques. (arXiv:2104.13225v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13225">
<div class="article-summary-box-inner">
<span><p>This survey provides an overview of the evolution of visually grounded models
of spoken language over the last 20 years. Such models are inspired by the
observation that when children pick up a language, they rely on a wide range of
indirect and noisy clues, crucially including signals from the visual modality
co-occurring with spoken utterances. Several fields have made important
contributions to this approach to modeling or mimicking the process of learning
language: Machine Learning, Natural Language and Speech Processing, Computer
Vision and Cognitive Science. The current paper brings together these
contributions in order to provide a useful introduction and overview for
practitioners in all these areas. We discuss the central research questions
addressed, the timeline of developments, and the datasets which enabled much of
this work. We then summarize the main modeling architectures and offer an
exhaustive overview of the evaluation metrics and analysis techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Ackermannian lower bound for the Petri nets reachability problem. (arXiv:2105.08551v3 [cs.FL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08551">
<div class="article-summary-box-inner">
<span><p>Petri nets, equivalently presentable as vector addition systems with states,
are an established model of concurrency with widespread applications. The
reachability problem, where we ask whether from a given initial configuration
there exists a sequence of valid execution steps reaching a given final
configuration, is the central algorithmic problem for this model. The
complexity of the problem has remained, until recently, one of the hardest open
questions in verification of concurrent systems. A first upper bound has been
provided only in 2015 by Leroux and Schmitz, then refined by the same authors
to non-primitive recursive Ackermannian upper bound in 2019. The exponential
space lower bound, shown by Lipton already in 1976, remained the only known for
over 40 years until a breakthrough non-elementary lower bound by
Czerwi{\'n}ski, Lasota, Lazic, Leroux and Mazowiecki in 2019. Finally, a
matching Ackermannian lower bound announced this year by Czerwi{\'n}ski and
Orlikowski, and independently by Leroux, established the complexity of the
problem.
</p>
<p>Our contribution is an improvement of the former construction, making it
conceptually simpler and more direct. On the way we improve the lower bound for
vector addition systems with states in fixed dimension (or, equivalently, Petri
nets with fixed number of places): while Czerwi{\'n}ski and Orlikowski prove
$F_k$-hardness (hardness for $k$th level in Grzegorczyk Hierarchy) in dimension
$6k$, and Leroux in dimension $4k+5$, our simplified construction yields
$F_k$-hardness already in dimension $3k+2$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Itihasa: A large-scale corpus for Sanskrit to English translation. (arXiv:2106.03269v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03269">
<div class="article-summary-box-inner">
<span><p>This work introduces Itihasa, a large-scale translation dataset containing
93,000 pairs of Sanskrit shlokas and their English translations. The shlokas
are extracted from two Indian epics viz., The Ramayana and The Mahabharata. We
first describe the motivation behind the curation of such a dataset and follow
up with empirical analysis to bring out its nuances. We then benchmark the
performance of standard translation models on this corpus and show that even
state-of-the-art transformer architectures perform poorly, emphasizing the
complexity of the dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Generation with Efficient (Soft) Q-Learning. (arXiv:2106.07704v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07704">
<div class="article-summary-box-inner">
<span><p>Maximum likelihood estimation (MLE) is the predominant algorithm for training
text generation models. This paradigm relies on direct supervision examples,
which is not applicable to many emerging applications, such as generating
adversarial attacks or generating prompts to control language models.
Reinforcement learning (RL) on the other hand offers a more flexible solution
by allowing users to plug in arbitrary task metrics as reward. Yet previous RL
algorithms for text generation, such as policy gradient (on-policy RL) and
Q-learning (off-policy RL), are often notoriously inefficient or unstable to
train due to the large sequence space and the sparse reward received only at
the end of sequences. In this paper, we introduce a new RL formulation for text
generation from the soft Q-learning (SQL) perspective. It enables us to draw
from the latest RL advances, such as path consistency learning, to combine the
best of on-/off-policy updates, and learn effectively from sparse reward. We
apply the approach to a wide range of text generation tasks, including learning
from noisy/negative examples, adversarial attacks, and prompt generation.
Experiments show our approach consistently outperforms both task-specialized
algorithms and the previous RL methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't Take It Literally: An Edit-Invariant Sequence Loss for Text Generation. (arXiv:2106.15078v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15078">
<div class="article-summary-box-inner">
<span><p>Neural text generation models are typically trained by maximizing
log-likelihood with the sequence cross entropy loss, which encourages an exact
token-by-token match between a target sequence with a generated sequence. Such
training objective is sub-optimal when the target sequence is not perfect,
e.g., when the target sequence is corrupted with noises, or when only weak
sequence supervision is available. To address this challenge, we propose a
novel Edit-Invariant Sequence Loss (EISL), which computes the matching loss of
a target n-gram with all n-grams in the generated sequence. Drawing
inspirations from the classical convolutional networks (ConvNets) which capture
shift-invariance in image modeling, EISL is designed to be robust to the shift
of n-grams to tolerate various noises and edits in the target sequences.
Moreover, the EISL computation is essentially a convolution operation with
target n-grams as kernels, which is easy to implement and efficient to compute
with existing libraries. To demonstrate the effectiveness of EISL, we conduct
experiments on a wide range of tasks, including machine translation with noisy
target sequences, unsupervised text style transfer with only weak training
signals, and non-autoregressive generation with non-predefined generation
order. Experimental results show our method significantly outperforms the
common cross-entropy loss and other strong baselines on all the tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An automated domain-independent text reading, interpreting and extracting approach for reviewing the scientific literature. (arXiv:2107.14638v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14638">
<div class="article-summary-box-inner">
<span><p>It is presented here a machine learning-based (ML) natural language
processing (NLP) approach capable to automatically recognize and extract
categorical and numerical parameters from a corpus of articles. The approach
(named a.RIX) operates with a concomitant/interchangeable use of ML models such
as neuron networks (NNs), latent semantic analysis (LSA), naive-Bayes
classifiers (NBC), and a pattern recognition model using regular expression
(REGEX). A corpus of 7,873 scientific articles dealing with natural products
(NPs) was used to demonstrate the efficiency of the a.RIX engine. The engine
automatically extracts categorical and numerical parameters such as (i) the
plant species from which active molecules are extracted, (ii) the
microorganisms species for which active molecules can act against, and (iii)
the values of minimum inhibitory concentration (MIC) against these
microorganisms. The parameters are extracted without part-of-speech tagging
(POS) and named entity recognition (NER) approaches (i.e. without the need of
text annotation), and the models training is performed with unsupervised
approaches. In this way, a.RIX can be essentially used on articles from any
scientific field. Finally, it can potentially make obsolete the current article
reviewing process in some areas, especially those in which machine learning
models capture texts structure, text semantics, and latent knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution. (arXiv:2108.12777v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12777">
<div class="article-summary-box-inner">
<span><p>Recent studies have shown that deep neural networks are vulnerable to
intentionally crafted adversarial examples, and various methods have been
proposed to defend against adversarial word-substitution attacks for neural NLP
models. However, there is a lack of systematic study on comparing different
defense approaches under the same attacking setting. In this paper, we seek to
fill the gap of systematic studies through comprehensive researches on
understanding the behavior of neural text classifiers trained by various
defense methods under representative adversarial attacks. In addition, we
propose an effective method to further improve the robustness of neural text
classifiers against such attacks and achieved the highest accuracy on both
clean and adversarial examples on AGNEWS and IMDB datasets by a significant
margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners. (arXiv:2108.13161v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13161">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models have contributed significantly to
natural language processing by demonstrating remarkable abilities as few-shot
learners. However, their effectiveness depends mainly on scaling the model
parameters and prompt design, hindering their implementation in most real-world
applications. This study proposes a novel pluggable, extensible, and efficient
approach named DifferentiAble pRompT (DART), which can convert small language
models into better few-shot learners without any prompt engineering. The main
principle behind this approach involves reformulating potential natural
language processing tasks into the task of a pre-trained language model and
differentially optimizing the prompt template as well as the target label with
backpropagation. Furthermore, the proposed approach can be: (i) Plugged to any
pre-trained language models; (ii) Extended to widespread classification tasks.
A comprehensive evaluation of standard NLP tasks demonstrates that the proposed
approach achieves a better few-shot performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Variational Graph Autoencoders for Unsupervised Cross-domain Prerequisite Chains. (arXiv:2109.08722v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08722">
<div class="article-summary-box-inner">
<span><p>Prerequisite chain learning helps people acquire new knowledge efficiently.
While people may quickly determine learning paths over concepts in a domain,
finding such paths in other domains can be challenging. We introduce
Domain-Adversarial Variational Graph Autoencoders (DAVGAE) to solve this
cross-domain prerequisite chain learning task efficiently. Our novel model
consists of a variational graph autoencoder (VGAE) and a domain discriminator.
The VGAE is trained to predict concept relations through link prediction, while
the domain discriminator takes both source and target domain data as input and
is trained to predict domain labels. Most importantly, this method only needs
simple homogeneous graphs as input, compared with the current state-of-the-art
model. We evaluate our model on the LectureBankCD dataset, and results show
that our model outperforms recent graph-based benchmarks while using only 1/10
of graph scale and 1/3 computation time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tipping the Scales: A Corpus-Based Reconstruction of Adjective Scales in the McGill Pain Questionnaire. (arXiv:2109.14788v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14788">
<div class="article-summary-box-inner">
<span><p>Modern medical diagnosis relies on precise pain assessment tools in
translating clinical information from patient to physician. The McGill Pain
Questionnaire (MPQ) is a clinical pain assessment technique that utilizes 78
adjectives of different intensities in 20 different categories to quantity a
patient's pain. The questionnaire's efficacy depends on a predictable pattern
of adjective use by patients experiencing pain. In this study, I recreate the
MPQ's adjective intensity orderings using data gathered from patient forums and
modern NLP techniques. I extract adjective intensity relationships by searching
for key linguistic contexts, and then combine the relationship information to
form robust adjective scales. Of 17 adjective relationships predicted by this
research, only 4 diverge from the MPQ's orderings, which is statistically
significant at the 0.1 alpha level. The results suggest predictable patterns of
adjective use by people experiencing pain, but call into question the MPQ's
categories for grouping adjectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large-scale ASR Domain Adaptation using Self- and Semi-supervised Learning. (arXiv:2110.00165v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00165">
<div class="article-summary-box-inner">
<span><p>Self- and semi-supervised learning methods have been actively investigated to
reduce labeled training data or enhance the model performance. However, the
approach mostly focus on in-domain performance for public datasets. In this
study, we utilize the combination of self- and semi-supervised learning methods
to solve unseen domain adaptation problem in a large-scale production setting
for online ASR model. This approach demonstrates that using the source domain
data with a small fraction of the target domain data (3%) can recover the
performance gap compared to a full data baseline: relative 13.5% WER
improvement for target domain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factorized Neural Transducer for Efficient Language Model Adaptation. (arXiv:2110.01500v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01500">
<div class="article-summary-box-inner">
<span><p>In recent years, end-to-end (E2E) based automatic speech recognition (ASR)
systems have achieved great success due to their simplicity and promising
performance. Neural Transducer based models are increasingly popular in
streaming E2E based ASR systems and have been reported to outperform the
traditional hybrid system in some scenarios. However, the joint optimization of
acoustic model, lexicon and language model in neural Transducer also brings
about challenges to utilize pure text for language model adaptation. This
drawback might prevent their potential applications in practice. In order to
address this issue, in this paper, we propose a novel model, factorized neural
Transducer, by factorizing the blank and vocabulary prediction, and adopting a
standalone language model for the vocabulary prediction. It is expected that
this factorization can transfer the improvement of the standalone language
model to the Transducer for speech recognition, which allows various language
model adaptation techniques to be applied. We demonstrate that the proposed
factorized neural Transducer yields 15% to 20% WER improvements when
out-of-domain text data is used for language model adaptation, at the cost of a
minor degradation in WER on a general test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rerunning OCR -- A Machine Learning Approach to Quality Assessment and Enhancement Prediction. (arXiv:2110.01661v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01661">
<div class="article-summary-box-inner">
<span><p>Iterating with new and improved OCR solutions enforces decisions to be taken
when it comes to targeting the right reprocessing candidates. This especially
applies when the underlying data collection is of considerable size and rather
diverse in terms of fonts, languages, periods of publication and consequently
OCR quality. This article captures the efforts of the National Library of
Luxembourg to support those exact decisions. They are crucial in order to
guarantee low computational overhead and reduced quality degradation risks,
combined with a more quantifiable OCR improvement. In particular, this work
explains the methodology of the library with respect to text block level
quality assessment. As an extension of this technique, another contribution
comes in the form of a regression model that takes the enhancement potential of
a new OCR engine into account. They both mark promising approaches, especially
for cultural institutions dealing with historic data of lower quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DistilHuBERT: Speech Representation Learning by Layer-wise Distillation of Hidden-unit BERT. (arXiv:2110.01900v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01900">
<div class="article-summary-box-inner">
<span><p>Self-supervised speech representation learning methods like wav2vec 2.0 and
Hidden-unit BERT (HuBERT) leverage unlabeled speech data for pre-training and
offer good representations for numerous speech processing tasks. Despite the
success of these methods, they require large memory and high pre-training
costs, making them inaccessible for researchers in academia and small
companies. Therefore, this paper introduces DistilHuBERT, a novel multi-task
learning framework to distill hidden representations from a HuBERT model
directly. This method reduces HuBERT's size by 75% and 73% faster while
retaining most performance in ten different tasks. Moreover, DistilHuBERT
required little training time and data, opening the possibilities of
pre-training personal and on-device SSL models for speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactively Generating Explanations for Transformer Language Models. (arXiv:2110.02058v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02058">
<div class="article-summary-box-inner">
<span><p>Transformer language models are state-of-the-art in a multitude of NLP tasks.
Despite these successes, their opaqueness remains problematic. Recent methods
aiming to provide interpretability and explainability to black-box models
primarily focus on post-hoc explanations of (sometimes spurious) input-output
correlations. Instead, we emphasize using prototype networks directly
incorporated into the model architecture and hence explain the reasoning
process behind the network's decisions. Moreover, while our architecture
performs on par with several language models, it enables one to learn from user
interactions. This not only offers a better understanding of language models
but uses human capabilities to incorporate knowledge outside of the rigid range
of purely data-driven approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Sense-Specific Static Embeddings using Contextualised Word Embeddings as a Proxy. (arXiv:2110.02204v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02204">
<div class="article-summary-box-inner">
<span><p>Contextualised word embeddings generated from Neural Language Models (NLMs),
such as BERT, represent a word with a vector that considers the semantics of
the target word as well its context. On the other hand, static word embeddings
such as GloVe represent words by relatively low-dimensional, memory- and
compute-efficient vectors but are not sensitive to the different senses of the
word. We propose Context Derived Embeddings of Senses (CDES), a method that
extracts sense related information from contextualised embeddings and injects
it into static embeddings to create sense-specific static embeddings.
Experimental results on multiple benchmarks for word sense disambiguation and
sense discrimination tasks show that CDES can accurately learn sense-specific
static embeddings reporting comparable performance to the current
state-of-the-art sense embeddings.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Hybrid Classical-Quantum method for Diabetic Foot Ulcer Classification. (arXiv:2110.02222v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02222">
<div class="article-summary-box-inner">
<span><p>Diabetes is a raising problem that affects many people globally. Diabetic
patients are at risk of developing foot ulcer that usually leads to limb
amputation, causing significant morbidity, and psychological distress. In order
to develop a self monitoring mobile application, it is necessary to be able to
classify such ulcers into either of the following classes: Infection,
Ischaemia, None, or Both. In this work, we compare the performance of a
classical transfer-learning-based method, with the performance of a hybrid
classical-quantum Classifier on diabetic foot ulcer classification task. As
such, we merge the pre-trained Xception network with a multi-class variational
classifier. Thus, after modifying and re-training the Xception network, we
extract the output of a mid-layer and employ it as deep-features presenters of
the given images. Finally, we use those deep-features to train multi-class
variational classifier, where each classifier is implemented on an individual
variational circuit. The method is then evaluated on the blind test set
DFUC2021. The results proves that our proposed hybrid classical-quantum
Classifier leads to considerable improvement compared to solely relying on
transfer learning concept through training the modified version of Xception
network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Assisted Convolutional Network for Cell Instance Segmentation. (arXiv:2110.02270v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02270">
<div class="article-summary-box-inner">
<span><p>Region proposal based methods like R-CNN and Faster R-CNN models have proven
to be extremely successful in object detection and segmentation tasks.
Recently, Transformers have also gained popularity in the domain of Computer
Vision, and are being utilised to improve the performance of conventional
models. In this paper, we present a relatively new transformer based approach
to enhance the performance of the conventional convolutional feature extractor
in the existing region proposal based methods. Our approach merges the
convolutional feature maps with transformer-based token embeddings by applying
a projection operation similar to self-attention in transformers. The results
of our experiments show that transformer assisted feature extractor achieves a
significant improvement in mIoU (mean Intersection over Union) scores compared
to vanilla convolutional backbone.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bilevel Imaging Learning Problems as Mathematical Programs with Complementarity Constraints. (arXiv:2110.02273v1 [math.OC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02273">
<div class="article-summary-box-inner">
<span><p>We investigate a family of bilevel imaging learning problems where the
lower-level instance corresponds to a convex variational model involving first-
and second-order nonsmooth regularizers. By using geometric properties of the
primal-dual reformulation of the lower-level problem and introducing suitable
changes of variables, we are able to reformulate the original bilevel problems
as Mathematical Programs with Complementarity Constraints (MPCC). For the
latter, we prove tight constraint qualification conditions (MPCC-MFCQ and
partial MPCC-LICQ) and derive Mordukovich (M-) and Strong (S-) stationarity
conditions. The S-stationarity system for the MPCC turns also into
S-stationarity conditions for the original formulation. Second-order sufficient
optimality conditions are derived as well. The proposed reformulation may be
extended to problems in function spaces, leading to MPCC's with additional
constraints on the gradient of the state. Finally, we report on some numerical
results obtained by using the proposed MPCC reformulations together with
available large-scale nonlinear programming solvers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling up instance annotation via label propagation. (arXiv:2110.02277v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02277">
<div class="article-summary-box-inner">
<span><p>Manually annotating object segmentation masks is very time-consuming. While
interactive segmentation methods offer a more efficient alternative, they
become unaffordable at a large scale because the cost grows linearly with the
number of annotated masks. In this paper, we propose a highly efficient
annotation scheme for building large datasets with object segmentation masks.
At a large scale, images contain many object instances with similar appearance.
We exploit these similarities by using hierarchical clustering on mask
predictions made by a segmentation model. We propose a scheme that efficiently
searches through the hierarchy of clusters and selects which clusters to
annotate. Humans manually verify only a few masks per cluster, and the labels
are propagated to the whole cluster. Through a large-scale experiment to
populate 1M unlabeled images with object segmentation masks for 80 object
classes, we show that (1) we obtain 1M object segmentation masks with an total
annotation time of only 290 hours; (2) we reduce annotation time by 76x
compared to manual annotation; (3) the segmentation quality of our masks is on
par with those from manually annotated datasets. Code, data, and models are
available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Turing approximations, toric isometric embeddings & manifold convolutions. (arXiv:2110.02279v1 [math.DG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02279">
<div class="article-summary-box-inner">
<span><p>Convolutions are fundamental elements in deep learning architectures. Here,
we present a theoretical framework for combining extrinsic and intrinsic
approaches to manifold convolution through isometric embeddings into tori. In
this way, we define a convolution operator for a manifold of arbitrary topology
and dimension. We also explain geometric and topological conditions that make
some local definitions of convolutions which rely on translating filters along
geodesic paths on a manifold, computationally intractable. A result of Alan
Turing from 1938 underscores the need for such a toric isometric embedding
approach to achieve a global definition of convolution on computable, finite
metric space approximations to a smooth manifold.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prediction of the Facial Growth Direction is Challenging. (arXiv:2110.02316v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02316">
<div class="article-summary-box-inner">
<span><p>Facial dysmorphology or malocclusion is frequently associated with abnormal
growth of the face. The ability to predict facial growth (FG) direction would
allow clinicians to prepare individualized therapy to increase the chance for
successful treatment. Prediction of FG direction is a novel problem in the
machine learning (ML) domain. In this paper, we perform feature selection and
point the attribute that plays a central role in the abovementioned problem.
Then we successfully apply data augmentation (DA) methods and improve the
previously reported classification accuracy by 2.81%. Finally, we present the
results of two experienced clinicians that were asked to solve a similar task
to ours and show how tough is solving this problem for human experts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancement of Anime Imaging Enlargement using Modified Super-Resolution CNN. (arXiv:2110.02321v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02321">
<div class="article-summary-box-inner">
<span><p>Anime is a storytelling medium similar to movies and books. Anime images are
a kind of artworks, which are almost entirely drawn by hand. Hence, reproducing
existing Anime with larger sizes and higher quality images is expensive.
Therefore, we proposed a model based on convolutional neural networks to
extract outstanding features of images, enlarge those images, and enhance the
quality of Anime images. We trained the model with a training set of 160 images
and a validation set of 20 images. We tested the trained model with a testing
set of 20 images. The experimental results indicated that our model
successfully enhanced the image quality with a larger image-size when compared
with the common existing image enlargement and the original SRCNN method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shape-aware Multi-Person Pose Estimation from Multi-View Images. (arXiv:2110.02330v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02330">
<div class="article-summary-box-inner">
<span><p>In this paper we contribute a simple yet effective approach for estimating 3D
poses of multiple people from multi-view images. Our proposed coarse-to-fine
pipeline first aggregates noisy 2D observations from multiple camera views into
3D space and then associates them into individual instances based on a
confidence-aware majority voting technique. The final pose estimates are
attained from a novel optimization scheme which links high-confidence
multi-view 2D observations and 3D joint candidates. Moreover, a statistical
parametric body model such as SMPL is leveraged as a regularizing prior for
these 3D joint candidates. Specifically, both 3D poses and SMPL parameters are
optimized jointly in an alternating fashion. Here the parametric models help in
correcting implausible 3D pose estimates and filling in missing joint
detections while updated 3D poses in turn guide obtaining better SMPL
estimations. By linking 2D and 3D observations, our method is both accurate and
generalizes to different data sources because it better decouples the final 3D
pose from the inter-person constellation and is more robust to noisy 2D
detections. We systematically evaluate our method on public datasets and
achieve state-of-the-art performance. The code and video will be available on
the project page: https://ait.ethz.ch/projects/2021/multi-human-pose/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geometric Algebra Attention Networks for Small Point Clouds. (arXiv:2110.02393v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02393">
<div class="article-summary-box-inner">
<span><p>Much of the success of deep learning is drawn from building architectures
that properly respect underlying symmetry and structure in the data on which
they operate - a set of considerations that have been united under the banner
of geometric deep learning. Often problems in the physical sciences deal with
relatively small sets of points in two- or three-dimensional space wherein
translation, rotation, and permutation equivariance are important or even vital
for models to be useful in practice. In this work, we present rotation- and
permutation-equivariant architectures for deep learning on these small point
clouds, composed of a set of products of terms from the geometric algebra and
reductions over those products using an attention mechanism. The geometric
algebra provides valuable mathematical structure by which to combine vector,
scalar, and other types of geometric inputs in a systematic way to account for
rotation invariance or covariance, while attention yields a powerful way to
impose permutation equivariance. We demonstrate the usefulness of these
architectures by training models to solve sample problems relevant to physics,
chemistry, and biology.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task Affinity with Maximum Bipartite Matching in Few-Shot Learning. (arXiv:2110.02399v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02399">
<div class="article-summary-box-inner">
<span><p>We propose an asymmetric affinity score for representing the complexity of
utilizing the knowledge of one task for learning another one. Our method is
based on the maximum bipartite matching algorithm and utilizes the Fisher
Information matrix. We provide theoretical analyses demonstrating that the
proposed score is mathematically well-defined, and subsequently use the
affinity score to propose a novel algorithm for the few-shot learning problem.
In particular, using this score, we find relevant training data labels to the
test data and leverage the discovered relevant data for episodically
fine-tuning a few-shot model. Results on various few-shot benchmark datasets
demonstrate the efficacy of the proposed approach by improving the
classification accuracy over the state-of-the-art methods even when using
smaller models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D-MOV: Audio-Visual LSTM Autoencoder for 3D Reconstruction of Multiple Objects from Video. (arXiv:2110.02404v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02404">
<div class="article-summary-box-inner">
<span><p>3D object reconstructions of transparent and concave structured objects, with
inferred material properties, remains an open research problem for robot
navigation in unstructured environments. In this paper, we propose a multimodal
single- and multi-frame neural network for 3D reconstructions using
audio-visual inputs. Our trained reconstruction LSTM autoencoder 3D-MOV accepts
multiple inputs to account for a variety of surface types and views. Our neural
network produces high-quality 3D reconstructions using voxel representation.
Based on Intersection-over-Union (IoU), we evaluate against other baseline
methods using synthetic audio-visual datasets ShapeNet and Sound20K with impact
sounds and bounding box annotations. To the best of our knowledge, our single-
and multi-frame model is the first audio-visual reconstruction neural network
for 3D geometry and material representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Echo-Reconstruction: Audio-Augmented 3D Scene Reconstruction. (arXiv:2110.02405v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02405">
<div class="article-summary-box-inner">
<span><p>Reflective and textureless surfaces such as windows, mirrors, and walls can
be a challenge for object and scene reconstruction. These surfaces are often
poorly reconstructed and filled with depth discontinuities and holes, making it
difficult to cohesively reconstruct scenes that contain these planar
discontinuities. We propose Echoreconstruction, an audio-visual method that
uses the reflections of sound to aid in geometry and audio reconstruction for
virtual conferencing, teleimmersion, and other AR/VR experience. The mobile
phone prototype emits pulsed audio, while recording video for RGB-based 3D
reconstruction and audio-visual classification. Reflected sound and images from
the video are input into our audio (EchoCNN-A) and audio-visual (EchoCNN-AV)
convolutional neural networks for surface and sound source detection, depth
estimation, and material classification. The inferences from these
classifications enhance scene 3D reconstructions containing open spaces and
reflective surfaces by depth filtering, inpainting, and placement of unmixed
sound sources in the scene. Our prototype, VR demo, and experimental results
from real-world and virtual scenes with challenging surfaces and sound indicate
high success rates on classification of material, depth estimation, and
closed/open surfaces, leading to considerable visual and audio improvement in
3D scenes (see Figure 1).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-Scale A Contrario method for Unsupervised Image Anomaly Detection. (arXiv:2110.02407v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02407">
<div class="article-summary-box-inner">
<span><p>Anomalies can be defined as any non-random structure which deviates from
normality. Anomaly detection methods reported in the literature are numerous
and diverse, as what is considered anomalous usually varies depending on
particular scenarios and applications. In this work we propose an a contrario
framework to detect anomalies in images applying statistical analysis to
feature maps obtained via convolutions. We evaluate filters learned from the
image under analysis via patch PCA, Gabor filters and the feature maps obtained
from a pre-trained deep neural network (Resnet). The proposed method is
multi-scale and fully unsupervised and is able to detect anomalies in a wide
variety of scenarios. While the end goal of this work is the detection of
subtle defects in leather samples for the automotive industry, we show that the
same algorithm achieves state of the art results in public anomalies datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CADA: Multi-scale Collaborative Adversarial Domain Adaptation for Unsupervised Optic Disc and Cup Segmentation. (arXiv:2110.02417v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02417">
<div class="article-summary-box-inner">
<span><p>The diversity of retinal imaging devices poses a significant challenge:
domain shift, which leads to performance degradation when applying the deep
learning models trained on one domain to new testing domains. In this paper, we
propose a multi-scale input along with multiple domain adaptors applied
hierarchically in both feature and output spaces. The proposed training
strategy and novel unsupervised domain adaptation framework, called
Collaborative Adversarial Domain Adaptation (CADA), can effectively overcome
the challenge. Multi-scale inputs can reduce the information loss due to the
pooling layers used in the network for feature extraction, while our proposed
CADA is an interactive paradigm that presents an exquisite collaborative
adaptation through both adversarial learning and ensembling weights at
different network layers. In particular, to produce a better prediction for the
unlabeled target domain data, we simultaneously achieve domain invariance and
model generalizability via adversarial learning at multi-scale outputs from
different levels of network layers and maintaining an exponential moving
average (EMA) of the historical weights during training. Without annotating any
sample from the target domain, multiple adversarial losses in encoder and
decoder layers guide the extraction of domain-invariant features to confuse the
domain classifier. Meanwhile, the ensembling of weights via EMA reduces the
uncertainty of adapting multiple discriminator learning. Comprehensive
experimental results demonstrate that our CADA model incorporating multi-scale
input training can overcome performance degradation and outperform
state-of-the-art domain adaptation methods in segmenting retinal optic disc and
cup from fundus images stemming from the REFUGE, Drishti-GS, and Rim-One-r3
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Influence-Balanced Loss for Imbalanced Visual Classification. (arXiv:2110.02444v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02444">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a balancing training method to address problems in
imbalanced data learning. To this end, we derive a new loss used in the
balancing training phase that alleviates the influence of samples that cause an
overfitted decision boundary. The proposed loss efficiently improves the
performance of any type of imbalance learning methods. In experiments on
multiple benchmark data sets, we demonstrate the validity of our method and
reveal that the proposed loss outperforms the state-of-the-art cost-sensitive
loss methods. Furthermore, since our loss is not restricted to a specific task,
model, or training method, it can be easily used in combination with other
recent re-sampling, meta-learning, and cost-sensitive learning methods for
class-imbalance problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ripple Attention for Visual Perception with Sub-quadratic Complexity. (arXiv:2110.02453v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02453">
<div class="article-summary-box-inner">
<span><p>Transformer architectures are now central to modeling in natural language
processing tasks. At its heart is the attention mechanism, which enables
effective modeling of long-term dependencies in a sequence. Recently,
transformers have been successfully applied in the computer vision domain,
where 2D images are first segmented into patches and then treated as 1D
sequences. Such linearization, however, impairs the notion of spatial locality
in images, which bears important visual clues. To bridge the gap, we propose
ripple attention, a sub-quadratic attention mechanism for visual perception. In
ripple attention, contributions of different tokens to a query are weighted
with respect to their relative spatial distances in the 2D space. To favor
correlations with vicinal tokens yet permit long-term dependencies, we derive
the spatial weights through a stick-breaking transformation. We further design
a dynamic programming algorithm that computes weighted contributions for all
queries in linear observed time, taking advantage of the summed-area table and
recent advances in linearized attention. Extensive experiments and analyses
demonstrate the effectiveness of ripple attention on various visual tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Post-hoc Models for Performance Estimation of Machine Learning Inference. (arXiv:2110.02459v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02459">
<div class="article-summary-box-inner">
<span><p>Estimating how well a machine learning model performs during inference is
critical in a variety of scenarios (for example, to quantify uncertainty, or to
choose from a library of available models). However, the standard accuracy
estimate of softmax confidence is not versatile and cannot reliably predict
different performance metrics (e.g., F1-score, recall) or the performance in
different application scenarios or input domains. In this work, we
systematically generalize performance estimation to a diverse set of metrics
and scenarios and discuss generalized notions of uncertainty calibration. We
propose the use of post-hoc models to accomplish this goal and investigate
design parameters, including the model type, feature engineering, and
performance metric, to achieve the best estimation quality. Emphasis is given
to object detection problems and, unlike prior work, our approach enables the
estimation of per-image metrics such as recall and F1-score. Through extensive
experiments with computer vision models and datasets in three use cases --
mobile edge offloading, model selection, and dataset shift -- we find that
proposed post-hoc models consistently outperform the standard calibrated
confidence baselines. To the best of our knowledge, this is the first work to
develop a unified framework to address different performance estimation
problems for machine learning inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TSN-CA: A Two-Stage Network with Channel Attention for Low-Light Image Enhancement. (arXiv:2110.02477v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02477">
<div class="article-summary-box-inner">
<span><p>Low-light image enhancement is a challenging low-level computer vision task
because after we enhance the brightness of the image, we have to deal with
amplified noise, color distortion, detail loss, blurred edges, shadow blocks
and halo artifacts. In this paper, we propose a Two-Stage Network with Channel
Attention (denoted as TSN-CA) to enhance the brightness of the low-light image
and restore the enhanced images from various kinds of degradation. In the first
stage, we enhance the brightness of the low-light image in HSV space and use
the information of H and S channels to help the recovery of details in V
channel. In the second stage, we integrate Channel Attention (CA) mechanism
into the skip connection of U-Net in order to restore the brightness-enhanced
image from severe kinds of degradation in RGB space. We train and evaluate the
performance of our proposed model on the LOL real-world and synthetic datasets.
In addition, we test our model on several other commonly used datasets without
Ground-Truth. We conduct extensive experiments to demonstrate that our method
achieves excellent effect on brightness enhancement as well as denoising,
details preservation and halo artifacts elimination. Our method outperforms
many other state-of-the-art methods qualitatively and quantitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attack as the Best Defense: Nullifying Image-to-image Translation GANs via Limit-aware Adversarial Attack. (arXiv:2110.02516v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02516">
<div class="article-summary-box-inner">
<span><p>With the successful creation of high-quality image-to-image (Img2Img)
translation GANs comes the non-ethical applications of DeepFake and DeepNude.
Such misuses of img2img techniques present a challenging problem for society.
In this work, we tackle the problem by introducing the Limit-Aware Self-Guiding
Gradient Sliding Attack (LaS-GSA). LaS-GSA follows the Nullifying Attack to
cancel the img2img translation process under a black-box setting. In other
words, by processing input images with the proposed LaS-GSA before publishing,
any targeted img2img GANs can be nullified, preventing the model from
maliciously manipulating the images. To improve efficiency, we introduce the
limit-aware random gradient-free estimation and the gradient sliding mechanism
to estimate the gradient that adheres to the adversarial limit, i.e., the pixel
value limitations of the adversarial example. Theoretical justifications
validate how the above techniques prevent inefficiency caused by the
adversarial limit in both the direction and the step length. Furthermore, an
effective self-guiding prior is extracted solely from the threat model and the
target image to efficiently leverage the prior information and guide the
gradient estimation process. Extensive experiments demonstrate that LaS-GSA
requires fewer queries to nullify the image translation process with higher
success rates than 4 state-of-the-art black-box methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ActiveMatch: End-to-end Semi-supervised Active Representation Learning. (arXiv:2110.02521v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02521">
<div class="article-summary-box-inner">
<span><p>Semi-supervised learning (SSL) is an efficient framework that can train
models with both labeled and unlabeled data. However, constrained by the
limited number of labels, the learned representations of SSL are ambiguous and
not distinguishable for inter-class samples. Moreover, the performance of SSL
is also largely dependent on the model initialization. To deal with the
drawbacks of SSL, in this paper, we propose a novel end-to-end representation
learning method, namely ActiveMatch, which combines SSL with contrastive
learning and active learning to fully leverage the limited labels. Starting
from a small amount of labeled data with unsupervised contrastive learning as a
warm-up, ActiveMatch then combines SSL and supervised contrastive learning, and
actively selects the most representative samples for labeling during the
training, resulting in better representations towards the classification.
Compared with MixMatch and FixMatch, we show that ActiveMatch achieves the
state-of-the-art performance, with 89.24 accuracy on CIFAR-10 with 100
collected labels, and 92.20 accuracy with 200 collected labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coarse-to-Fine Reasoning for Visual Question Answering. (arXiv:2110.02526v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02526">
<div class="article-summary-box-inner">
<span><p>Bridging the semantic gap between image and question is an important step to
improve the accuracy of the Visual Question Answering (VQA) task. However, most
of the existing VQA methods focus on attention mechanisms or visual relations
for reasoning the answer, while the features at different semantic levels are
not fully utilized. In this paper, we present a new reasoning framework to fill
the gap between visual features and semantic clues in the VQA task. Our method
first extracts the features and predicates from the image and question. We then
propose a new reasoning framework to effectively jointly learn these features
and predicates in a coarse-to-fine manner. The intensively experimental results
on three large-scale VQA datasets show that our proposed approach achieves
superior accuracy comparing with other state-of-the-art methods. Furthermore,
our reasoning framework also provides an explainable way to understand the
decision of the deep neural network when predicting the answer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Importance of Firth Bias Reduction in Few-Shot Classification. (arXiv:2110.02529v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02529">
<div class="article-summary-box-inner">
<span><p>Learning accurate classifiers for novel categories from very few examples,
known as few-shot image classification, is a challenging task in statistical
machine learning and computer vision. The performance in few-shot
classification suffers from the bias in the estimation of classifier
parameters; however, an effective underlying bias reduction technique that
could alleviate this issue in training few-shot classifiers has been
overlooked. In this work, we demonstrate the effectiveness of Firth bias
reduction in few-shot classification. Theoretically, Firth bias reduction
removes the first order term $O(N^{-1})$ from the small-sample bias of the
Maximum Likelihood Estimator. Here we show that the general Firth bias
reduction technique simplifies to encouraging uniform class assignment
probabilities for multinomial logistic classification, and almost has the same
effect in cosine classifiers. We derive the optimization objective for Firth
penalized multinomial logistic and cosine classifiers, and empirically evaluate
that it is consistently effective across the board for few-shot image
classification, regardless of (1) the feature representations from different
backbones, (2) the number of samples per class, and (3) the number of classes.
Finally, we show the robustness of Firth bias reduction, in the case of
imbalanced data distribution. Our implementation is available at
https://github.com/ehsansaleh/firth_bias_reduction
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D-FCT: Simultaneous 3D Object Detection and Tracking Using Feature Correlation. (arXiv:2110.02531v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02531">
<div class="article-summary-box-inner">
<span><p>3D object detection using LiDAR data remains a key task for applications like
autonomous driving and robotics. Unlike in the case of 2D images, LiDAR data is
almost always collected over a period of time. However, most work in this area
has focused on performing detection independent of the temporal domain. In this
paper we present 3D-FCT, a Siamese network architecture that utilizes temporal
information to simultaneously perform the related tasks of 3D object detection
and tracking. The network is trained to predict the movement of an object based
on the correlation features of extracted keypoints across time. Calculating
correlation across keypoints only allows for real-time object detection. We
further extend the multi-task objective to include a tracking regression loss.
Finally, we produce high accuracy detections by linking short-term object
tracklets into long term tracks based on the predicted tracks. Our proposed
method is evaluated on the KITTI tracking dataset where it is shown to provide
an improvement of 5.57% mAP over a state-of-the-art approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">See Yourself in Others: Attending Multiple Tasks for Own Failure Detection. (arXiv:2110.02549v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02549">
<div class="article-summary-box-inner">
<span><p>Autonomous robots deal with unexpected scenarios in real environments. Given
input images, various visual perception tasks can be performed, e.g., semantic
segmentation, depth estimation and normal estimation. These different tasks
provide rich information for the whole robotic perception system. All tasks
have their own characteristics while sharing some latent correlations. However,
some of the task predictions may suffer from the unreliability dealing with
complex scenes and anomalies. We propose an attention-based failure detection
approach by exploiting the correlations among multiple tasks. The proposed
framework infers task failures by evaluating the individual prediction, across
multiple visual perception tasks for different regions in an image. The
formulation of the evaluations is based on an attention network supervised by
multi-task uncertainty estimation and their corresponding prediction errors.
Our proposed framework generates more accurate estimations of the prediction
error for the different task's predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Review of Computer Vision Technologies for Fish Tracking. (arXiv:2110.02551v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02551">
<div class="article-summary-box-inner">
<span><p>Fish tracking based on computer vision is a complex and challenging task in
fishery production and ecological studies. Most of the applications of fish
tracking use classic filtering algorithms, which lack in accuracy and
efficiency. To solve this issue, deep learning methods utilized deep neural
networks to extract the features, which achieve a good performance in the fish
tracking. Some one-stage detection algorithms have gradually been adopted in
this area for the real-time applications. The transfer learning to fish target
is the current development direction. At present, fish tracking technology is
not enough to cover actual application requirements. According to the
literature data collected by us, there has not been any extensive review about
vision-based fish tracking in the community. In this paper, we introduced the
development and application prospects of fish tracking technology in last ten
years. Firstly, we introduced the open source datasets of fish, and summarized
the preprocessing technologies of underwater images. Secondly, we analyzed the
detection and tracking algorithms for fish, and sorted out some transferable
frontier tracking model. Thirdly, we listed the actual applications, metrics
and bottlenecks of the fish tracking such as occlusion and multi-scale.
Finally, we give the discussion for fish tracking datasets, solutions of the
bottlenecks, and improvements. We expect that our work can help the fish
tracking models to achieve higher accuracy and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MTCD: Cataract Detection via Near Infrared Eye Images. (arXiv:2110.02564v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02564">
<div class="article-summary-box-inner">
<span><p>Globally, cataract is a common eye disease and one of the leading causes of
blindness and vision impairment. The traditional process of detecting cataracts
involves eye examination using a slit-lamp microscope or ophthalmoscope by an
ophthalmologist, who checks for clouding of the normally clear lens of the eye.
The lack of resources and unavailability of a sufficient number of experts pose
a burden to the healthcare system throughout the world, and researchers are
exploring the use of AI solutions for assisting the experts. Inspired by the
progress in iris recognition, in this research, we present a novel algorithm
for cataract detection using near-infrared eye images. The NIR cameras, which
are popularly used in iris recognition, are of relatively low cost and easy to
operate compared to ophthalmoscope setup for data capture. However, such NIR
images have not been explored for cataract detection. We present deep
learning-based eye segmentation and multitask network classification networks
for cataract detection using NIR images as input. The proposed segmentation
algorithm efficiently and effectively detects non-ideal eye boundaries and is
cost-effective, and the classification network yields very high classification
performance on the cataract dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Multi-Modal Embeddings from Structured Data. (arXiv:2110.02577v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02577">
<div class="article-summary-box-inner">
<span><p>Multi-modal word semantics aims to enhance embeddings with perceptual input,
assuming that human meaning representation is grounded in sensory experience.
Most research focuses on evaluation involving direct visual input, however,
visual grounding can contribute to linguistic applications as well. Another
motivation for this paper is the growing need for more interpretable models and
for evaluating model efficiency regarding size and performance. This work
explores the impact of visual information for semantics when the evaluation
involves no direct visual input, specifically semantic similarity and
relatedness. We investigate a new embedding type in-between linguistic and
visual modalities, based on the structured annotations of Visual Genome. We
compare uni- and multi-modal models including structured, linguistic and image
based representations. We measure the efficiency of each model with regard to
data and model size, modality / data distribution and information gain. The
analysis includes an interpretation of embedding structures. We found that this
new embedding conveys complementary information for text based embeddings. It
achieves comparable performance in an economic way, using orders of magnitude
less resources than visual models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoupled Adaptation for Cross-Domain Object Detection. (arXiv:2110.02578v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02578">
<div class="article-summary-box-inner">
<span><p>Cross-domain object detection is more challenging than object classification
since multiple objects exist in an image and the location of each object is
unknown in the unlabeled target domain. As a result, when we adapt features of
different objects to enhance the transferability of the detector, the features
of the foreground and the background are easy to be confused, which may hurt
the discriminability of the detector. Besides, previous methods focused on
category adaptation but ignored another important part for object detection,
i.e., the adaptation on bounding box regression. To this end, we propose
D-adapt, namely Decoupled Adaptation, to decouple the adversarial adaptation
and the training of the detector. Besides, we fill the blank of regression
domain adaptation in object detection by introducing a bounding box adaptor.
Experiments show that D-adapt achieves state-of-the-art results on four
cross-domain object detection tasks and yields 17% and 21% relative improvement
on benchmark datasets Clipart1k and Comic2k in particular.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Transfer Learning for Land Use Land Cover Classification: A Comparative Study. (arXiv:2110.02580v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02580">
<div class="article-summary-box-inner">
<span><p>Efficiently implementing remote sensing image classification with high
spatial resolution imagery can provide great significant value in land-use
land-cover classification (LULC). The developments in remote sensing and deep
learning technologies have facilitated the extraction of spatiotemporal
information for LULC classification. Moreover, the diverse disciplines of
science, including remote sensing, have utilised tremendous improvements in
image classification by CNNs with Transfer Learning. In this study, instead of
training CNNs from scratch, we make use of transfer learning to fine-tune
pre-trained networks a) VGG16 and b) Wide Residual Networks (WRNs), by
replacing the final layer with additional layers, for LULC classification with
EuroSAT dataset. Further, the performance and computational time were compared
and optimized with techniques like early stopping, gradient clipping, adaptive
learning rates and data augmentation. With the proposed approaches we were able
to address the limited-data problem and achieved very good accuracy.
Comprehensive comparisons over the EuroSAT RGB version benchmark have
successfully established that our method outperforms the previous best-stated
results, with a significant improvement over the accuracy from 98.57% to
99.17%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FADNet++: Real-Time and Accurate Disparity Estimation with Configurable Networks. (arXiv:2110.02582v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02582">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) have achieved great success in the area of
computer vision. The disparity estimation problem tends to be addressed by DNNs
which achieve much better prediction accuracy than traditional hand-crafted
feature-based methods. However, the existing DNNs hardly serve both efficient
computation and rich expression capability, which makes them difficult for
deployment in real-time and high-quality applications, especially on mobile
devices. To this end, we propose an efficient, accurate, and configurable deep
network for disparity estimation named FADNet++. Leveraging several liberal
network design and training techniques, FADNet++ can boost its accuracy with a
fast model inference speed for real-time applications. Besides, it enables
users to easily configure different sizes of models for balancing accuracy and
inference efficiency. We conduct extensive experiments to demonstrate the
effectiveness of FADNet++ on both synthetic and realistic datasets among six
GPU devices varying from server to mobile platforms. Experimental results show
that FADNet++ and its variants achieve state-of-the-art prediction accuracy,
and run at a significant order of magnitude faster speed than existing 3D
models. With the constraint of running at above 15 frames per second (FPS) on a
mobile GPU, FADNet++ achieves a new state-of-the-art result for the SceneFlow
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Focus on the Common Good: Group Distributional Robustness Follows. (arXiv:2110.02619v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02619">
<div class="article-summary-box-inner">
<span><p>We consider the problem of training a classification model with group
annotated training data. Recent work has established that, if there is
distribution shift across different groups, models trained using the standard
empirical risk minimization (ERM) objective suffer from poor performance on
minority groups and that group distributionally robust optimization (Group-DRO)
objective is a better alternative. The starting point of this paper is the
observation that though Group-DRO performs better than ERM on minority groups
for some benchmark datasets, there are several other datasets where it performs
much worse than ERM. Inspired by ideas from the closely related problem of
domain generalization, this paper proposes a new and simple algorithm that
explicitly encourages learning of features that are shared across various
groups. The key insight behind our proposed algorithm is that while Group-DRO
focuses on groups with worst regularized loss, focusing instead, on groups that
enable better performance even on other groups, could lead to learning of
shared/common features, thereby enhancing minority performance beyond what is
achieved by Group-DRO. Empirically, we show that our proposed algorithm matches
or achieves better performance compared to strong contemporary baselines
including ERM and Group-DRO on standard benchmarks on both minority groups and
across all groups. Theoretically, we show that the proposed algorithm is a
descent method and finds first order stationary points of smooth nonconvex
functions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is An Image Worth Five Sentences? A New Look into Semantics for Image-Text Matching. (arXiv:2110.02623v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02623">
<div class="article-summary-box-inner">
<span><p>The task of image-text matching aims to map representations from different
modalities into a common joint visual-textual embedding. However, the most
widely used datasets for this task, MSCOCO and Flickr30K, are actually image
captioning datasets that offer a very limited set of relationships between
images and sentences in their ground-truth annotations. This limited ground
truth information forces us to use evaluation metrics based on binary
relevance: given a sentence query we consider only one image as relevant.
However, many other relevant images or captions may be present in the dataset.
In this work, we propose two metrics that evaluate the degree of semantic
relevance of retrieved items, independently of their annotated binary
relevance. Additionally, we incorporate a novel strategy that uses an image
captioning metric, CIDEr, to define a Semantic Adaptive Margin (SAM) to be
optimized in a standard triplet loss. By incorporating our formulation to
existing models, a \emph{large} improvement is obtained in scenarios where
available training data is limited. We also demonstrate that the performance on
the annotated image-caption pairs is maintained while improving on other
non-annotated relevant items when employing the full training set. Code with
our metrics and adaptive margin formulation will be made public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation. (arXiv:2110.02624v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02624">
<div class="article-summary-box-inner">
<span><p>While recent progress has been made in text-to-image generation,
text-to-shape generation remains a challenging problem due to the
unavailability of paired text and shape data at a large scale. We present a
simple yet effective method for zero-shot text-to-shape generation based on a
two-stage training process, which only depends on an unlabelled shape dataset
and a pre-trained image-text network such as CLIP. Our method not only
demonstrates promising zero-shot generalization, but also avoids expensive
inference time optimization and can generate multiple shapes for a given text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MovingFashion: a Benchmark for the Video-to-Shop Challenge. (arXiv:2110.02627v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02627">
<div class="article-summary-box-inner">
<span><p>Retrieving clothes which are worn in social media videos (Instagram, TikTok)
is the latest frontier of e-fashion, referred to as "video-to-shop" in the
computer vision literature. In this paper we present MovingFashion, the first
publicly available dataset to cope with this challenge. MovingFashion is
composed of 14855 social videos, each one of them associated to e-commerce
"shop" images where the corresponding clothing items are clearly portrayed. In
addition, we present a network for retrieving the shop images in this scenario,
dubbed SEAM Match-RCNN. The model is trained by image-to-video domain
adaptation, allowing to use video sequences where only their association with a
shop image is given, eliminating the need of millions of annotated bounding
boxes. SEAM Match-RCNN builds an embedding, where an attention-based weighted
sum of few frames (10) of a social video is enough to individuate the correct
product within the first 5 retrieved items in a 14K+ shop element gallery with
an accuracy of 80%. This provides the best performance on MovingFashion,
comparing exhaustively against the related state-of-the-art approaches and
alternative baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Sparse Masks for Diffusion-based Image Inpainting. (arXiv:2110.02636v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02636">
<div class="article-summary-box-inner">
<span><p>Diffusion-based inpainting is a powerful tool for the reconstruction of
images from sparse data. Its quality strongly depends on the choice of known
data. Optimising their spatial location -- the inpainting mask -- is
challenging. A commonly used tool for this task are stochastic optimisation
strategies. However, they are slow as they compute multiple inpainting results.
We provide a remedy in terms of a learned mask generation model. By emulating
the complete inpainting pipeline with two networks for mask generation and
neural surrogate inpainting, we obtain a model for highly efficient adaptive
mask generation. Experiments indicate that our model can achieve competitive
quality with an acceleration by as much as four orders of magnitude. Our
findings serve as a basis for making diffusion-based inpainting more attractive
for various applications such as image compression, where fast encoding is
highly desirable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">2nd Place Solution to Google Landmark Recognition Competition 2021. (arXiv:2110.02638v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02638">
<div class="article-summary-box-inner">
<span><p>As Transformer-based architectures have recently shown encouraging progresses
in computer vision. In this work, we present the solution to the Google
Landmark Recognition 2021 Challenge held on Kaggle, which is an improvement on
our last year's solution by changing three designs, including (1) Using Swin
and CSWin as backbone for feature extraction, (2) Train on full GLDv2, and (3)
Using full GLDv2 images as index image set for kNN search.
</p>
<p>With these modifications, our solution significantly improves last year
solution on this year competition. Our full pipeline, after ensembling Swin,
CSWin, EfficientNet B7 models, scores 0.4907 on the private leaderboard which
help us to get the 2nd place in the competition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Weighted Generalized Coherence Approach for Sensing Matrix Design. (arXiv:2110.02645v1 [cs.IT])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02645">
<div class="article-summary-box-inner">
<span><p>As compared to using randomly generated sensing matrices, optimizing the
sensing matrix w.r.t. a carefully designed criterion is known to lead to better
quality signal recovery given a set of compressive measurements. In this paper,
we propose generalizations of the well-known mutual coherence criterion for
optimizing sensing matrices starting from random initial conditions. We term
these generalizations as bi-coherence or tri-coherence and they are based on a
criterion that discourages any one column of the sensing matrix from being
close to a sparse linear combination of other columns. We also incorporate
training data to further improve the sensing matrices through weighted
coherence, weighted bi-coherence, or weighted tri-coherence criteria, which
assign weights to sensing matrix columns as per their importance. An algorithm
is also presented to solve the optimization problems. Finally, the
effectiveness of the proposed algorithm is demonstrated through empirical
results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weak Novel Categories without Tears: A Survey on Weak-Shot Learning. (arXiv:2110.02651v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02651">
<div class="article-summary-box-inner">
<span><p>Deep learning is a data-hungry approach, which requires massive training
data. However, it is time-consuming and labor-intensive to collect abundant
fully-annotated training data for all categories. Assuming the existence of
base categories with adequate fully-annotated training samples, different
paradigms requiring fewer training samples or weaker annotations for novel
categories have attracted growing research interest. Among them, zero-shot
(resp., few-shot) learning explores using zero (resp., a few) training samples
for novel categories, which lowers the quantity requirement for novel
categories. Instead, weak-shot learning lowers the quality requirement for
novel categories. Specifically, sufficient training samples are collected for
novel categories but they only have weak annotations. In different tasks, weak
annotations are presented in different forms (e.g., noisy labels for image
classification, image labels for object detection, bounding boxes for
segmentation), similar to the definitions in weakly supervised learning.
Therefore, weak-shot learning can also be treated as weakly supervised learning
with auxiliary fully supervised categories. In this paper, we discuss the
existing weak-shot learning methodologies in different tasks and summarize the
codes at https://github.com/bcmi/Awesome-Weak-Shot-Learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robotic Knee Arthroscopy: Multi-Scale Network for Tissue-Tool Segmentation. (arXiv:2110.02657v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02657">
<div class="article-summary-box-inner">
<span><p>Tissue awareness has a great demand to improve surgical accuracy in minimally
invasive procedures. In arthroscopy, it is one of the challenging tasks due to
surgical sites exhibit limited features and textures. Moreover, arthroscopic
surgical video shows high intra-class variations. Arthroscopic videos are
recorded with endoscope known as arthroscope which records tissue structures at
proximity, therefore, frames contain minimal joint structure. As consequences,
fully conventional network-based segmentation model suffers from long- and
short- term dependency problems. In this study, we present a densely connected
shape aware multi-scale segmentation model which captures multi-scale features
and integrates shape features to achieve tissue-tool segmentations. The model
has been evaluated with three distinct datasets. Moreover, with the publicly
available polyp dataset our proposed model achieved 5.09 % accuracy
improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">S-Extension Patch: A simple and efficient way to extend an object detection model. (arXiv:2110.02670v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02670">
<div class="article-summary-box-inner">
<span><p>While building convolutional network-based systems, the toll it takes to
train the network is something that cannot be ignored. In cases where we need
to append additional capabilities to the existing model, the attention
immediately goes towards retraining techniques. In this paper, I show how to
leverage knowledge about the dataset to append the class faster while
maintaining the speed of inference as well as the accuracies; while reducing
the amount of time and data required. The method can extend a class in the
existing object detection model in 1/10th of the time compared to the other
existing methods. S-Extension patch not only offers faster training but also
speed and ease of adaptation, as it can be appended to any existing system,
given it fulfills the similarity threshold condition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long-tailed Distribution Adaptation. (arXiv:2110.02686v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02686">
<div class="article-summary-box-inner">
<span><p>Recognizing images with long-tailed distributions remains a challenging
problem while there lacks an interpretable mechanism to solve this problem. In
this study, we formulate Long-tailed recognition as Domain Adaption (LDA), by
modeling the long-tailed distribution as an unbalanced domain and the general
distribution as a balanced domain. Within the balanced domain, we propose to
slack the generalization error bound, which is defined upon the empirical risks
of unbalanced and balanced domains and the divergence between them. We propose
to jointly optimize empirical risks of the unbalanced and balanced domains and
approximate their domain divergence by intra-class and inter-class distances,
with the aim to adapt models trained on the long-tailed distribution to general
distributions in an interpretable way. Experiments on benchmark datasets for
image recognition, object detection, and instance segmentation validate that
our LDA approach, beyond its interpretability, achieves state-of-the-art
performance. Code is available at https://github.com/pengzhiliang/LDA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Objects in Semantic Topology. (arXiv:2110.02687v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02687">
<div class="article-summary-box-inner">
<span><p>A more realistic object detection paradigm, Open-World Object Detection, has
arisen increasing research interests in the community recently. A qualified
open-world object detector can not only identify objects of known categories,
but also discover unknown objects, and incrementally learn to categorize them
when their annotations progressively arrive. Previous works rely on independent
modules to recognize unknown categories and perform incremental learning,
respectively. In this paper, we provide a unified perspective: Semantic
Topology. During the life-long learning of an open-world object detector, all
object instances from the same category are assigned to their corresponding
pre-defined node in the semantic topology, including the `unknown' category.
This constraint builds up discriminative feature representations and consistent
relationships among objects, thus enabling the detector to distinguish unknown
objects out of the known categories, as well as making learned features of
known objects undistorted when learning new categories incrementally. Extensive
experiments demonstrate that semantic topology, either randomly-generated or
derived from a well-trained language model, could outperform the current
state-of-the-art open-world object detectors by a large margin, e.g., the
absolute open-set error is reduced from 7832 to 2546, exhibiting the inherent
superiority of semantic topology on open-world object detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reversible adversarial examples against local visual perturbation. (arXiv:2110.02700v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02700">
<div class="article-summary-box-inner">
<span><p>Recently, studies have indicated that adversarial attacks pose a threat to
deep learning systems. However, when there are only adversarial examples,
people cannot get the original images, so there is research on reversible
adversarial attacks. However, the existing strategies are aimed at invisible
adversarial perturbation, and do not consider the case of locally visible
adversarial perturbation. In this article, we generate reversible adversarial
examples for local visual adversarial perturbation, and use reversible data
embedding technology to embed the information needed to restore the original
image into the adversarial examples to generate examples that are both
adversarial and reversible. Experiments on ImageNet dataset show that our
method can restore the original image losslessly while ensuring the attack
capability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models. (arXiv:2110.02711v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02711">
<div class="article-summary-box-inner">
<span><p>Diffusion models are recent generative models that have shown great success
in image generation with the state-of-the-art performance. However, only a few
researches have been conducted for image manipulation with diffusion models.
Here, we present a novel DiffusionCLIP which performs text-driven image
manipulation with diffusion models using Contrastive Language-Image
Pre-training (CLIP) loss. Our method has a performance comparable to that of
the modern GAN-based image processing methods for in and out-of-domain image
processing tasks, with the advantage of almost perfect inversion even without
additional encoders or optimization. Furthermore, our method can be easily used
for various novel applications, enabling image translation from an unseen
domain to another unseen domain or stroke-conditioned image generation in an
unseen domain, etc. Finally, we present a novel multiple attribute control with
DiffusionCLIPby combining multiple fine-tuned diffusion models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ParaDiS: Parallelly Distributable Slimmable Neural Networks. (arXiv:2110.02724v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02724">
<div class="article-summary-box-inner">
<span><p>When several limited power devices are available, one of the most efficient
ways to make profit of these resources, while reducing the processing latency
and communication load, is to run in parallel several neural sub-networks and
to fuse the result at the end of processing. However, such a combination of
sub-networks must be trained specifically for each particular configuration of
devices (characterized by number of devices and their capacities) which may
vary over different model deployments and even within the same deployment. In
this work we introduce parallelly distributable slimmable (ParaDiS) neural
networks that are splittable in parallel among various device configurations
without retraining. While inspired by slimmable networks allowing instant
adaptation to resources on just one device, ParaDiS networks consist of several
multi-device distributable configurations or switches that strongly share the
parameters between them. We evaluate ParaDiS framework on MobileNet v1 and
ResNet-50 architectures on ImageNet classification task. We show that ParaDiS
switches achieve similar or better accuracy than the individual models, i.e.,
distributed models of the same structure trained individually. Moreover, we
show that, as compared to universally slimmable networks that are not
distributable, the accuracy of distributable ParaDiS switches either does not
drop at all or drops by a maximum of 1 % only in the worst cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Step Towards Efficient Evaluation of Complex Perception Tasks in Simulation. (arXiv:2110.02739v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02739">
<div class="article-summary-box-inner">
<span><p>There has been increasing interest in characterising the error behaviour of
systems which contain deep learning models before deploying them into any
safety-critical scenario. However, characterising such behaviour usually
requires large-scale testing of the model that can be extremely computationally
expensive for complex real-world tasks. For example, tasks involving compute
intensive object detectors as one of their components. In this work, we propose
an approach that enables efficient large-scale testing using simplified
low-fidelity simulators and without the computational cost of executing
expensive deep learning models. Our approach relies on designing an efficient
surrogate model corresponding to the compute intensive components of the task
under test. We demonstrate the efficacy of our methodology by evaluating the
performance of an autonomous driving task in the Carla simulator with reduced
computational expense by training efficient surrogate models for PIXOR and
CenterPoint LiDAR detectors, whilst demonstrating that the accuracy of the
simulation is maintained.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Learning for Unsupervised Radar Place Recognition. (arXiv:2110.02744v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02744">
<div class="article-summary-box-inner">
<span><p>We learn, in an unsupervised way, an embedding from sequences of radar images
that is suitable for solving the place recognition problem with complex radar
data. Our method is based on invariant instance feature learning but is
tailored for the task of re-localisation by exploiting for data augmentation
the temporal successivity of data as collected by a mobile platform moving
through the scene smoothly. We experiment across two prominent urban radar
datasets totalling over 400 km of driving and show that we achieve a new radar
place recognition state-of-the-art. Specifically, the proposed system proves
correct for 98.38% of the queries that it is presented with over a challenging
re-localisation sequence, using only the single nearest neighbour in the
learned metric space. We also find that our learned model shows better
understanding of out-of-lane loop closures at arbitrary orientation than
non-learned radar scan descriptors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extensions of Karger's Algorithm: Why They Fail in Theory and How They Are Useful in Practice. (arXiv:2110.02750v1 [cs.DS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02750">
<div class="article-summary-box-inner">
<span><p>The minimum graph cut and minimum $s$-$t$-cut problems are important
primitives in the modeling of combinatorial problems in computer science,
including in computer vision and machine learning. Some of the most efficient
algorithms for finding global minimum cuts are randomized algorithms based on
Karger's groundbreaking contraction algorithm. Here, we study whether Karger's
algorithm can be successfully generalized to other cut problems. We first prove
that a wide class of natural generalizations of Karger's algorithm cannot
efficiently solve the $s$-$t$-mincut or the normalized cut problem to
optimality. However, we then present a simple new algorithm for seeded
segmentation / graph-based semi-supervised learning that is closely based on
Karger's original algorithm, showing that for these problems, extensions of
Karger's algorithm can be useful. The new algorithm has linear asymptotic
runtime and yields a potential that can be interpreted as the posterior
probability of a sample belonging to a given seed / class. We clarify its
relation to the random walker algorithm / harmonic energy minimization in terms
of distributions over spanning forests. On classical problems from seeded image
segmentation and graph-based semi-supervised learning on image data, the method
performs at least as well as the random walker / harmonic energy minimization /
Gaussian processes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Challenge of Appearance-Free Object Tracking with Feedforward Neural Networks. (arXiv:2110.02772v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02772">
<div class="article-summary-box-inner">
<span><p>Nearly all models for object tracking with artificial neural networks depend
on appearance features extracted from a "backbone" architecture, designed for
object recognition. Indeed, significant progress on object tracking has been
spurred by introducing backbones that are better able to discriminate objects
by their appearance. However, extensive neurophysiology and psychophysics
evidence suggests that biological visual systems track objects using both
appearance and motion features. Here, we introduce $\textit{PathTracker}$, a
visual challenge inspired by cognitive psychology, which tests the ability of
observers to learn to track objects solely by their motion. We find that
standard 3D-convolutional deep network models struggle to solve this task when
clutter is introduced into the generated scenes, or when objects travel long
distances. This challenge reveals that tracing the path of object motion is a
blind spot of feedforward neural networks. We expect that strategies for
appearance-free object tracking from biological vision can inspire solutions
these failures of deep neural networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SIRe-Networks: Skip Connections over Interlaced Multi-Task Learning and Residual Connections for Structure Preserving Object Classification. (arXiv:2110.02776v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02776">
<div class="article-summary-box-inner">
<span><p>Improving existing neural network architectures can involve several design
choices such as manipulating the loss functions, employing a diverse learning
strategy, exploiting gradient evolution at training time, optimizing the
network hyper-parameters, or increasing the architecture depth. The latter
approach is a straightforward solution, since it directly enhances the
representation capabilities of a network; however, the increased depth
generally incurs in the well-known vanishing gradient problem. In this paper,
borrowing from different methods addressing this issue, we introduce an
interlaced multi-task learning strategy, defined SIRe, to reduce the vanishing
gradient in relation to the object classification task. The presented
methodology directly improves a convolutional neural network (CNN) by enforcing
the input image structure preservation through interlaced auto-encoders, and
further refines the base network architecture by means of skip and residual
connections. To validate the presented methodology, a simple CNN and various
implementations of famous networks are extended via the SIRe strategy and
extensively tested on the CIFAR100 dataset; where the SIRe-extended
architectures achieve significantly increased performances across all models,
thus confirming the presented approach effectiveness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Study on Transfer Learning Capabilities for Pneumonia Classification in Chest-X-Rays Image. (arXiv:2110.02780v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02780">
<div class="article-summary-box-inner">
<span><p>Over the last year, the severe acute respiratory syndrome coronavirus-2
(SARS-CoV-2) and its variants have highlighted the importance of screening
tools with high diagnostic accuracy for new illnesses such as COVID-19. To that
regard, deep learning approaches have proven as effective solutions for
pneumonia classification, especially when considering chest-x-rays images.
However, this lung infection can also be caused by other viral, bacterial or
fungi pathogens. Consequently, efforts are being poured toward distinguishing
the infection source to help clinicians to diagnose the correct disease origin.
Following this tendency, this study further explores the effectiveness of
established neural network architectures on the pneumonia classification task
through the transfer learning paradigm. To present a comprehensive comparison,
12 well-known ImageNet pre-trained models were fine-tuned and used to
discriminate among chest-x-rays of healthy people, and those showing pneumonia
symptoms derived from either a viral (i.e., generic or SARS-CoV-2) or bacterial
source. Furthermore, since a common public collection distinguishing between
such categories is currently not available, two distinct datasets of
chest-x-rays images, describing the aforementioned sources, were combined and
employed to evaluate the various architectures. The experiments were performed
using a total of 6330 images split between train, validation and test sets. For
all models, common classification metrics were computed (e.g., precision,
f1-score) and most architectures obtained significant performances, reaching,
among the others, up to 84.46% average f1-score when discriminating the 4
identified classes. Moreover, confusion matrices and activation maps computed
via the Grad-CAM algorithm were also reported to present an informed discussion
on the networks classifications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3rd Place Solution to Google Landmark Recognition Competition 2021. (arXiv:2110.02794v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02794">
<div class="article-summary-box-inner">
<span><p>In this paper, we show our solution to the Google Landmark Recognition 2021
Competition. Firstly, embeddings of images are extracted via various
architectures (i.e. CNN-, Transformer- and hybrid-based), which are optimized
by ArcFace loss. Then we apply an efficient pipeline to re-rank predictions by
adjusting the retrieval score with classification logits and non-landmark
distractors. Finally, the ensembled model scores 0.489 on the private
leaderboard, achieving the 3rd place in the 2021 edition of the Google Landmark
Recognition Competition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Robustness Comparison of Vision Transformer and MLP-Mixer to CNNs. (arXiv:2110.02797v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02797">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks (CNNs) have become the de facto gold standard
in computer vision applications in the past years. Recently, however, new model
architectures have been proposed challenging the status quo. The Vision
Transformer (ViT) relies solely on attention modules, while the MLP-Mixer
architecture substitutes the self-attention modules with Multi-Layer
Perceptrons (MLPs). Despite their great success, CNNs have been widely known to
be vulnerable to adversarial attacks, causing serious concerns for
security-sensitive applications. Thus, it is critical for the community to know
whether the newly proposed ViT and MLP-Mixer are also vulnerable to adversarial
attacks. To this end, we empirically evaluate their adversarial robustness
under several adversarial attack setups and benchmark them against the widely
used CNNs. Overall, we find that the two architectures, especially ViT, are
more robust than their CNN models. Using a toy example, we also provide
empirical evidence that the lower adversarial robustness of CNNs can be
partially attributed to their shift-invariant property. Our frequency analysis
suggests that the most robust ViT architectures tend to rely more on
low-frequency features compared with CNNs. Additionally, we have an intriguing
finding that MLP-Mixer is extremely vulnerable to universal adversarial
perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerated First Order Methods for Variational Imaging. (arXiv:2110.02813v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02813">
<div class="article-summary-box-inner">
<span><p>In this thesis, we offer a thorough investigation of different regularisation
terms used in variational imaging problems, together with detailed optimisation
processes of these problems. We begin by studying smooth problems and partially
non-smooth problems in the form of Tikhonov denoising and Total Variation (TV)
denoising, respectively.
</p>
<p>For Tikhonov denoising, we study an accelerated gradient method with adaptive
restart, which shows a very rapid convergence rate. However, it is not
straightforward to apply this fast algorithm to TV denoising, due to the
non-smoothness of its built-in regularisation. To tackle this issue, we propose
to utilise duality to convert such a non-smooth problem into a smooth one so
that the accelerated gradient method with restart applies naturally.
</p>
<p>However, we notice that both Tikhonov and TV regularisations have drawbacks,
in the form of blurred image edges and staircase artefacts, respectively. To
overcome these drawbacks, we propose a novel adaption to Total Generalised
Variation (TGV) regularisation called Total Smooth Variation (TSV), which
retains edges and meanwhile does not produce results which contain staircase
artefacts. To optimise TSV effectively, we then propose the Accelerated
Proximal Gradient Algorithm (APGA) which also utilises adaptive restart
techniques. Compared to existing state-of-the-art regularisations (e.g. TV),
TSV is shown to obtain more effective results on denoising problems as well as
advanced imaging applications such as magnetic resonance imaging (MRI)
reconstruction and optical flow. TSV removes the staircase artefacts observed
when using TV regularisation, but has the added advantage over TGV that it can
be efficiently optimised using gradient based methods with Nesterov
acceleration and adaptive restart. Code is available at
https://github.com/Jbartlett6/Accelerated-First-Order-Method-for-Variational-Imaging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Prediction: Which One Should Come First, Recognition or Prediction?. (arXiv:2110.02829v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02829">
<div class="article-summary-box-inner">
<span><p>The ultimate goal of video prediction is not forecasting future pixel-values
given some previous frames. Rather, the end goal of video prediction is to
discover valuable internal representations from the vast amount of available
unlabeled video data in a self-supervised fashion for downstream tasks. One of
the primary downstream tasks is interpreting the scene's semantic composition
and using it for decision-making. For example, by predicting human movements,
an observer can anticipate human activities and collaborate in a shared
workspace. There are two main ways to achieve the same outcome, given a
pre-trained video prediction and pre-trained semantic extraction model; one can
first apply predictions and then extract semantics or first extract semantics
and then predict. We investigate these configurations using the Local Frequency
Domain Transformer Network (LFDTN) as the video prediction model and U-Net as
the semantic extraction model on synthetic and real datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shallow Features Guide Unsupervised Domain Adaptation for Semantic Segmentation at Class Boundaries. (arXiv:2110.02833v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02833">
<div class="article-summary-box-inner">
<span><p>Although deep neural networks have achieved remarkable results for the task
of semantic segmentation, they usually fail to generalize towards new domains,
especially when performing synthetic-to-real adaptation. Such domain shift is
particularly noticeable along class boundaries, invalidating one of the main
goals of semantic segmentation that consists in obtaining sharp segmentation
masks. In this work, we specifically address this core problem in the context
of Unsupervised Domain Adaptation and present a novel low-level adaptation
strategy that allows us to obtain sharp predictions. Moreover, inspired by
recent self-training techniques, we introduce an effective data augmentation
that alleviates the noise typically present at semantic boundaries when
employing pseudo-labels for self-training. Our contributions can be easily
integrated into other popular adaptation frameworks, and extensive experiments
show that they effectively improve performance along class boundaries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WHO-Hand Hygiene Gesture Classification System. (arXiv:2110.02842v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02842">
<div class="article-summary-box-inner">
<span><p>The recent ongoing coronavirus pandemic highlights the importance of hand
hygiene practices in our daily lives, with governments and worldwide health
authorities promoting good hand hygiene practices. More than one million cases
of hospital-acquired infections occur in Europe annually. Hand hygiene
compliance may reduce the risk of transmission by reducing the number of
infections as well as healthcare expenditures. In this paper, the World Health
Organization, hand hygiene gestures are recorded and analyzed with the
construction of an aluminum frame, placed at the laboratory sink. The hand
hygiene gestures are recorded for thirty participants after conducting a
training session about hand hygiene gestures demonstration. The video
recordings are converted into image files and are organized into six different
hand hygiene classes. The Resnet50 framework selection for the classification
of multiclass hand hygiene stages. The model is trained with the first set of
classes; Fingers Interlaced, P2PFingers Interlaced, and Rotational Rub for 25
epochs. An accuracy of 44 percent for the first set of experiments with a loss
score greater than 1.5 in the validation set is achieved. The training steps
for the second set of classes; Rub hands palm to palm, Fingers Interlocked,
Thumb Rub are 50 epochs. An accuracy of 72 percent is achieved for the second
set with a loss score of less than 0.8 for the validation set. In this work, a
preliminary analysis of a robust hand hygiene dataset with transfer learning
takes place. The future aim for deploying a hand hygiene prediction system for
healthcare workers in real-time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Identification of the End-Diastolic and End-Systolic Cardiac Frames from Invasive Coronary Angiography Videos. (arXiv:2110.02844v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02844">
<div class="article-summary-box-inner">
<span><p>Automatic identification of proper image frames at the end-diastolic (ED) and
end-systolic (ES) frames during the review of invasive coronary angiograms
(ICA) is important to assess blood flow during a cardiac cycle, reconstruct the
3D arterial anatomy from bi-planar views, and generate the complementary fusion
map with myocardial images. The current identification method primarily relies
on visual interpretation, making it not only time-consuming but also less
reproducible. In this paper, we propose a new method to automatically identify
angiographic image frames associated with the ED and ES cardiac phases by using
the trajectories of key vessel points (i.e. landmarks). More specifically, a
detection algorithm is first used to detect the key points of coronary
arteries, and then an optical flow method is employed to track the trajectories
of the selected key points. The ED and ES frames are identified based on all
these trajectories. Our method was tested with 62 ICA videos from two separate
medical centers (22 and 9 patients in sites 1 and 2, respectively). Comparing
consensus interpretations by two human expert readers, excellent agreement was
achieved by the proposed algorithm: the agreement rates within a one-frame
range were 92.99% and 92.73% for the automatic identification of the ED and ES
image frames, respectively. In conclusion, the proposed automated method showed
great potential for being an integral part of automated ICA image analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seed Classification using Synthetic Image Datasets Generated from Low-Altitude UAV Imagery. (arXiv:2110.02846v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02846">
<div class="article-summary-box-inner">
<span><p>Plant breeding programs extensively monitor the evolution of seed kernels for
seed certification, wherein lies the need to appropriately label the seed
kernels by type and quality. However, the breeding environments are large where
the monitoring of seed kernels can be challenging due to the minuscule size of
seed kernels. The use of unmanned aerial vehicles aids in seed monitoring and
labeling since they can capture images at low altitudes whilst being able to
access even the remotest areas in the environment. A key bottleneck in the
labeling of seeds using UAV imagery is drone altitude i.e. the classification
accuracy decreases as the altitude increases due to lower image detail.
Convolutional neural networks are a great tool for multi-class image
classification when there is a training dataset that closely represents the
different scenarios that the network might encounter during evaluation. The
article addresses the challenge of training data creation using Domain
Randomization wherein synthetic image datasets are generated from a meager
sample of seeds captured by the bottom camera of an autonomously driven Parrot
AR Drone 2.0. Besides, the article proposes a seed classification framework as
a proof-of-concept using the convolutional neural networks of Microsoft's
ResNet-100, Oxford's VGG-16, and VGG-19. To enhance the classification accuracy
of the framework, an ensemble model is developed resulting in an overall
accuracy of 94.6%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Convolutional Cross-Scale-Flows for Image-based Defect Detection. (arXiv:2110.02855v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02855">
<div class="article-summary-box-inner">
<span><p>In industrial manufacturing processes, errors frequently occur at
unpredictable times and in unknown manifestations. We tackle the problem of
automatic defect detection without requiring any image samples of defective
parts. Recent works model the distribution of defect-free image data, using
either strong statistical priors or overly simplified data representations. In
contrast, our approach handles fine-grained representations incorporating the
global and local image context while flexibly estimating the density. To this
end, we propose a novel fully convolutional cross-scale normalizing flow
(CS-Flow) that jointly processes multiple feature maps of different scales.
Using normalizing flows to assign meaningful likelihoods to input samples
allows for efficient defect detection on image-level. Moreover, due to the
preserved spatial arrangement the latent space of the normalizing flow is
interpretable which enables to localize defective regions in the image. Our
work sets a new state-of-the-art in image-level defect detection on the
benchmark datasets Magnetic Tile Defects and MVTec AD showing a 100% AUROC on 4
out of 15 classes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Common Principal Subspace of Deep Features in Neural Networks. (arXiv:2110.02863v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02863">
<div class="article-summary-box-inner">
<span><p>We find that different Deep Neural Networks (DNNs) trained with the same
dataset share a common principal subspace in latent spaces, no matter in which
architectures (e.g., Convolutional Neural Networks (CNNs), Multi-Layer
Preceptors (MLPs) and Autoencoders (AEs)) the DNNs were built or even whether
labels have been used in training (e.g., supervised, unsupervised, and
self-supervised learning). Specifically, we design a new metric
$\mathcal{P}$-vector to represent the principal subspace of deep features
learned in a DNN, and propose to measure angles between the principal subspaces
using $\mathcal{P}$-vectors. Small angles (with cosine close to $1.0$) have
been found in the comparisons between any two DNNs trained with different
algorithms/architectures. Furthermore, during the training procedure from
random scratch, the angle decrease from a larger one ($70^\circ-80^\circ$
usually) to the small one, which coincides the progress of feature space
learning from scratch to convergence. Then, we carry out case studies to
measure the angle between the $\mathcal{P}$-vector and the principal subspace
of training dataset, and connect such angle with generalization performance.
Extensive experiments with practically-used Multi-Layer Perceptron (MLPs), AEs
and CNNs for classification, image reconstruction, and self-supervised learning
tasks on MNIST, CIFAR-10 and CIFAR-100 datasets have been done to support our
claims with solid evidences.
</p>
<p>Interpretability of Deep Learning, Feature Learning, and Subspaces of Deep
Features
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spike-inspired Rank Coding for Fast and Accurate Recurrent Neural Networks. (arXiv:2110.02865v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02865">
<div class="article-summary-box-inner">
<span><p>Biological spiking neural networks (SNNs) can temporally encode information
in their outputs, e.g. in the rank order in which neurons fire, whereas
artificial neural networks (ANNs) conventionally do not. As a result, models of
SNNs for neuromorphic computing are regarded as potentially more rapid and
efficient than ANNs when dealing with temporal input. On the other hand, ANNs
are simpler to train, and usually achieve superior performance. Here we show
that temporal coding such as rank coding (RC) inspired by SNNs can also be
applied to conventional ANNs such as LSTMs, and leads to computational savings
and speedups. In our RC for ANNs, we apply backpropagation through time using
the standard real-valued activations, but only from a strategically early time
step of each sequential input example, decided by a threshold-crossing event.
Learning then incorporates naturally also _when_ to produce an output, without
other changes to the model or the algorithm. Both the forward and the backward
training pass can be significantly shortened by skipping the remaining input
sequence after that first event. RC-training also significantly reduces
time-to-insight during inference, with a minimal decrease in accuracy. The
desired speed-accuracy trade-off is tunable by varying the threshold or a
regularization parameter that rewards output entropy. We demonstrate these in
two toy problems of sequence classification, and in a temporally-encoded MNIST
dataset where our RC model achieves 99.19% accuracy after the first input
time-step, outperforming the state of the art in temporal coding with SNNs, as
well as in spoken-word classification of Google Speech Commands, outperforming
non-RC-trained early inference with LSTMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods. (arXiv:2110.02871v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02871">
<div class="article-summary-box-inner">
<span><p>Climate change is a major threat to humanity, and the actions required to
prevent its catastrophic consequences include changes in both policy-making and
individual behaviour. However, taking action requires understanding the effects
of climate change, even though they may seem abstract and distant. Projecting
the potential consequences of extreme climate events such as flooding in
familiar places can help make the abstract impacts of climate change more
concrete and encourage action. As part of a larger initiative to build a
website that projects extreme climate events onto user-chosen photos, we
present our solution to simulate photo-realistic floods on authentic images. To
address this complex task in the absence of suitable training data, we propose
ClimateGAN, a model that leverages both simulated and real data for
unsupervised domain adaptation and conditional image generation. In this paper,
we describe the details of our framework, thoroughly evaluate components of our
architecture and demonstrate that our model is capable of robustly generating
photo-realistic flooding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SDA-GAN: Unsupervised Image Translation Using Spectral Domain Attention-Guided Generative Adversarial Network. (arXiv:2110.02873v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02873">
<div class="article-summary-box-inner">
<span><p>This work introduced a novel GAN architecture for unsupervised image
translation on the task of face style transform. A spectral attention-based
mechanism is embedded into the design along with spatial attention on the image
contents. We proved that neural network has the potential of learning complex
transformations such as Fourier transform, within considerable computational
cost. The model is trained and tested in comparison to the baseline model,
which only uses spatial attention. The performance improvement of our approach
is significant especially when the source and target domain include different
complexity (reduced FID to 49.18 from 142.84). In the translation process, a
spectra filling effect was introduced due to the implementation of FFT and
spectral attention. Another style transfer task and real-world object
translation are also studied in this paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta Internal Learning. (arXiv:2110.02900v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02900">
<div class="article-summary-box-inner">
<span><p>Internal learning for single-image generation is a framework, where a
generator is trained to produce novel images based on a single image. Since
these models are trained on a single image, they are limited in their scale and
application. To overcome these issues, we propose a meta-learning approach that
enables training over a collection of images, in order to model the internal
statistics of the sample image more effectively. In the presented meta-learning
approach, a single-image GAN model is generated given an input image, via a
convolutional feedforward hypernetwork $f$. This network is trained over a
dataset of images, allowing for feature sharing among different models, and for
interpolation in the space of generative models. The generated single-image
model contains a hierarchy of multiple generators and discriminators. It is
therefore required to train the meta-learner in an adversarial manner, which
requires careful design choices that we justify by a theoretical analysis. Our
results show that the models obtained are as suitable as single-image GANs for
many common image applications, significantly reduce the training time per
image without loss in performance, and introduce novel capabilities, such as
interpolation and feedforward modeling of novel images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SAIC_Cambridge-HuPBA-FBK Submission to the EPIC-Kitchens-100 Action Recognition Challenge 2021. (arXiv:2110.02902v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02902">
<div class="article-summary-box-inner">
<span><p>This report presents the technical details of our submission to the
EPIC-Kitchens-100 Action Recognition Challenge 2021. To participate in the
challenge we deployed spatio-temporal feature extraction and aggregation models
we have developed recently: GSF and XViT. GSF is an efficient spatio-temporal
feature extracting module that can be plugged into 2D CNNs for video action
recognition. XViT is a convolution free video feature extractor based on
transformer architecture. We design an ensemble of GSF and XViT model families
with different backbones and pretraining to generate the prediction scores. Our
submission, visible on the public leaderboard, achieved a top-1 action
recognition accuracy of 44.82%, using only RGB.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grasp-Oriented Fine-grained Cloth Segmentation without Real Supervision. (arXiv:2110.02903v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02903">
<div class="article-summary-box-inner">
<span><p>Automatically detecting graspable regions from a single depth image is a key
ingredient in cloth manipulation. The large variability of cloth deformations
has motivated most of the current approaches to focus on identifying specific
grasping points rather than semantic parts, as the appearance and depth
variations of local regions are smaller and easier to model than the larger
ones. However, tasks like cloth folding or assisted dressing require
recognising larger segments, such as semantic edges that carry more information
than points. The first goal of this paper is therefore to tackle the problem of
fine-grained region detection in deformed clothes using only a depth image. As
a proof of concept, we implement an approach for T-shirts, and define up to 6
semantic regions of varying extent, including edges on the neckline, sleeve
cuffs, and hem, plus top and bottom grasping points. We introduce a U-net based
network to segment and label these parts. The second contribution of our work
is concerned with the level of supervision that we require to train the
proposed network. While most approaches learn to detect grasping points by
combining real and synthetic annotations, in this work we defy the limitations
of the synthetic data, and propose a multilayered domain adaptation (DA)
strategy that does not use real annotations at all. We thoroughly evaluate our
approach on real depth images of a T-shirt annotated with fine-grained labels.
We show that training our network solely with synthetic data and the proposed
DA yields results competitive with models trained on real data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shifting Capsule Networks from the Cloud to the Deep Edge. (arXiv:2110.02911v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02911">
<div class="article-summary-box-inner">
<span><p>Capsule networks (CapsNets) are an emerging trend in image processing. In
contrast to a convolutional neural network, CapsNets are not vulnerable to
object deformation, as the relative spatial information of the objects is
preserved across the network. However, their complexity is mainly related with
the capsule structure and the dynamic routing mechanism, which makes it almost
unreasonable to deploy a CapsNet, in its original form, in a
resource-constrained device powered by a small microcontroller (MCU). In an era
where intelligence is rapidly shifting from the cloud to the edge, this high
complexity imposes serious challenges to the adoption of CapsNets at the very
edge. To tackle this issue, we present an API for the execution of quantized
CapsNets in Cortex-M and RISC-V MCUs. Our software kernels extend the Arm
CMSIS-NN and RISC-V PULP-NN, to support capsule operations with 8-bit integers
as operands. Along with it, we propose a framework to perform post training
quantization of a CapsNet. Results show a reduction in memory footprint of
almost 75%, with a maximum accuracy loss of 1%. In terms of throughput, our
software kernels for the Arm Cortex-M are, at least, 5.70x faster than a
pre-quantized CapsNet running on an NVIDIA GTX 980 Ti graphics card. For
RISC-V, the throughout gain increases to 26.28x and 56.91x for a single- and
octa-core configuration, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting RANSAC via Dual Principal Component Pursuit. (arXiv:2110.02918v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02918">
<div class="article-summary-box-inner">
<span><p>In this paper, we revisit the problem of local optimization in RANSAC. Once a
so-far-the-best model has been found, we refine it via Dual Principal Component
Pursuit (DPCP), a robust subspace learning method with strong theoretical
support and efficient algorithms. The proposed DPCP-RANSAC has far fewer
parameters than existing methods and is scalable. Experiments on estimating
two-view homographies, fundamental and essential matrices, and three-view
homographic tensors using large-scale datasets show that our approach
consistently has higher accuracy than state-of-the-art alternatives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Attacks on Spiking Convolutional Networks for Event-based Vision. (arXiv:2110.02929v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02929">
<div class="article-summary-box-inner">
<span><p>Event-based sensing using dynamic vision sensors is gaining traction in
low-power vision applications. Spiking neural networks work well with the
sparse nature of event-based data and suit deployment on low-power neuromorphic
hardware. Being a nascent field, the sensitivity of spiking neural networks to
potentially malicious adversarial attacks has received very little attention so
far. In this work, we show how white-box adversarial attack algorithms can be
adapted to the discrete and sparse nature of event-based visual data, and to
the continuous-time setting of spiking neural networks. We test our methods on
the N-MNIST and IBM Gestures neuromorphic vision datasets and show adversarial
perturbations achieve a high success rate, by injecting a relatively small
number of appropriately placed events. We also verify, for the first time, the
effectiveness of these perturbations directly on neuromorphic hardware.
Finally, we discuss the properties of the resulting perturbations and possible
future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Cropped versus Uncropped Training Sets in Tabular Structure Detection. (arXiv:2110.02933v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02933">
<div class="article-summary-box-inner">
<span><p>Automated document processing for tabular information extraction is highly
desired in many organizations, from industry to government. Prior works have
addressed this problem under table detection and table structure detection
tasks. Proposed solutions leveraging deep learning approaches have been giving
promising results in these tasks. However, the impact of dataset structures on
table structure detection has not been investigated. In this study, we provide
a comparison of table structure detection performance with cropped and
uncropped datasets. The cropped set consists of only table images that are
cropped from documents assuming tables are detected perfectly. The uncropped
set consists of regular document images. Experiments show that deep learning
models can improve the detection performance by up to 9% in average precision
and average recall on the cropped versions. Furthermore, the impact of cropped
images is negligible under the Intersection over Union (IoU) values of 50%-70%
when compared to the uncropped versions. However, beyond 70% IoU thresholds,
cropped datasets provide significantly higher detection performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topologically Consistent Multi-View Face Inference Using Volumetric Sampling. (arXiv:2110.02948v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02948">
<div class="article-summary-box-inner">
<span><p>High-fidelity face digitization solutions often combine multi-view stereo
(MVS) techniques for 3D reconstruction and a non-rigid registration step to
establish dense correspondence across identities and expressions. A common
problem is the need for manual clean-up after the MVS step, as 3D scans are
typically affected by noise and outliers and contain hairy surface regions that
need to be cleaned up by artists. Furthermore, mesh registration tends to fail
for extreme facial expressions. Most learning-based methods use an underlying
3D morphable model (3DMM) to ensure robustness, but this limits the output
accuracy for extreme facial expressions. In addition, the global bottleneck of
regression architectures cannot produce meshes that tightly fit the ground
truth surfaces. We propose ToFu, Topologically consistent Face from multi-view,
a geometry inference framework that can produce topologically consistent meshes
across facial identities and expressions using a volumetric representation
instead of an explicit underlying 3DMM. Our novel progressive mesh generation
network embeds the topological structure of the face in a feature volume,
sampled from geometry-aware local features. A coarse-to-fine architecture
facilitates dense and accurate facial mesh predictions in a consistent mesh
topology. ToFu further captures displacement maps for pore-level geometric
details and facilitates high-quality rendering in the form of albedo and
specular reflectance maps. These high-quality assets are readily usable by
production studios for avatar creation, animation and physically-based skin
rendering. We demonstrate state-of-the-art geometric and correspondence
accuracy, while only taking 0.385 seconds to compute a mesh with 10K vertices,
which is three orders of magnitude faster than traditional techniques. The code
and the model are available for research purposes at
https://tianyeli.github.io/tofu.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Autoencoder: self-supervised disentanglement of static 3D structure and motion. (arXiv:2110.02951v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02951">
<div class="article-summary-box-inner">
<span><p>A video autoencoder is proposed for learning disentan- gled representations
of 3D structure and camera pose from videos in a self-supervised manner.
Relying on temporal continuity in videos, our work assumes that the 3D scene
structure in nearby video frames remains static. Given a sequence of video
frames as input, the video autoencoder extracts a disentangled representation
of the scene includ- ing: (i) a temporally-consistent deep voxel feature to
represent the 3D structure and (ii) a 3D trajectory of camera pose for each
frame. These two representations will then be re-entangled for rendering the
input video frames. This video autoencoder can be trained directly using a
pixel reconstruction loss, without any ground truth 3D or camera pose
annotations. The disentangled representation can be applied to a range of
tasks, including novel view synthesis, camera pose estimation, and video
generation by motion following. We evaluate our method on several large- scale
natural video datasets, and show generalization results on out-of-domain
images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MEDIRL: Predicting the Visual Attention of Drivers via Maximum Entropy Deep Inverse Reinforcement Learning. (arXiv:1912.07773v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.07773">
<div class="article-summary-box-inner">
<span><p>Inspired by human visual attention, we propose a novel inverse reinforcement
learning formulation using Maximum Entropy Deep Inverse Reinforcement Learning
(MEDIRL) for predicting the visual attention of drivers in accident-prone
situations. MEDIRL predicts fixation locations that lead to maximal rewards by
learning a task-sensitive reward function from eye fixation patterns recorded
from attentive drivers. Additionally, we introduce EyeCar, a new driver
attention dataset in accident-prone situations. We conduct comprehensive
experiments to evaluate our proposed model on three common benchmarks:
(DR(eye)VE, BDD-A, DADA-2000), and our EyeCar dataset. Results indicate that
MEDIRL outperforms existing models for predicting attention and achieves
state-of-the-art performance. We present extensive ablation studies to provide
more insights into different features of our proposed model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MORPH-DSLAM: Model Order Reduction for PHysics-based Deformable SLAM. (arXiv:2009.00576v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00576">
<div class="article-summary-box-inner">
<span><p>We propose a new methodology to estimate the 3D displacement field of
deformable objects from video sequences using standard monocular cameras. We
solve in real time the complete (possibly visco-)hyperelasticity problem to
properly describe the strain and stress fields that are consistent with the
displacements captured by the images, constrained by real physics. We do not
impose any ad-hoc prior or energy minimization in the external surface, since
the real and complete mechanics problem is solved. This means that we can also
estimate the internal state of the objects, even in occluded areas, just by
observing the external surface and the knowledge of material properties and
geometry. Solving this problem in real time using a realistic constitutive law,
usually non-linear, is out of reach for current systems. To overcome this
difficulty, we solve off-line a parametrized problem that considers each source
of variability in the problem as a new parameter and, consequently, as a new
dimension in the formulation. Model Order Reduction methods allow us to reduce
the dimensionality of the problem, and therefore, its computational cost, while
preserving the visualization of the solution in the high-dimensionality space.
This allows an accurate estimation of the object deformations, improving also
the robustness in the 3D points estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Similarity-Based Clustering for Enhancing Image Classification Architectures. (arXiv:2011.04728v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04728">
<div class="article-summary-box-inner">
<span><p>Convolutional networks are at the center of best-in-class computer vision
applications for a wide assortment of undertakings. Since 2014, a profound
amount of work began to make better convolutional architectures, yielding
generous additions in different benchmarks. Albeit expanded model size and
computational cost will, in general, mean prompt quality increases for most
undertakings but, the architectures now need to have some additional
information to increase the performance. I show evidence that with the
amalgamation of content-based image similarity and deep learning models, we can
provide the flow of information which can be used in making clustered learning
possible. The paper shows how training of sub-dataset clusters not only reduces
the cost of computation but also increases the speed of evaluating and tuning a
model on the given dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learnable Gabor modulated complex-valued networks for orientation robustness. (arXiv:2011.11734v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11734">
<div class="article-summary-box-inner">
<span><p>Robustness to transformation is desirable in many computer vision tasks,
given that input data often exhibits pose variance. While translation
invariance and equivariance is a documented phenomenon of CNNs, sensitivity to
other transformations is typically encouraged through data augmentation. We
investigate the modulation of complex valued convolutional weights with learned
Gabor filters to enable orientation robustness. The resulting network can
generate orientation dependent features free of interpolation with a single set
of learnable rotation-governing parameters. By choosing to either retain or
pool orientation channels, the choice of equivariance versus invariance can be
directly controlled. Moreover, we introduce rotational weight-tying through a
proposed cyclic Gabor convolution, further enabling generalisation over
rotations. We combine these innovations into Learnable Gabor Convolutional
Networks (LGCNs), that are parameter-efficient and offer increased model
complexity. We demonstrate their rotation invariance and equivariance on MNIST,
BSD and a dataset of simulated and real astronomical images of Galactic cirri.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$DA^3$:Dynamic Additive Attention Adaption for Memory-EfficientOn-Device Multi-Domain Learning. (arXiv:2012.01362v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01362">
<div class="article-summary-box-inner">
<span><p>Nowadays, one practical limitation of deep neural network (DNN) is its high
degree of specialization to a single task or domain (e.g., one visual domain).
It motivates researchers to develop algorithms that can adapt DNN model to
multiple domains sequentially, while still performing well on the past domains,
which is known as multi-domain learning. Almost all conventional methods only
focus on improving accuracy with minimal parameter update, while ignoring high
computing and memory cost during training, which makes it difficult to deploy
multi-domain learning into more and more widely used resource-limited edge
devices, like mobile phones, IoT, embedded systems, etc. We observe that large
memory used for activation storage is the bottleneck that largely limits the
training time and cost on edge devices. To reduce training memory usage, while
keeping the domain adaption accuracy performance, we propose Dynamic Additive
Attention Adaption ($DA^3$), a novel memory-efficient on-device multi-domain
learning method. $DA^3$ learns a novel additive attention adaptor module, while
freezing the weights of the pre-trained backbone model for each domain.
Differentiating from prior works, such module not only mitigates activation
memory buffering for reducing memory usage during training but also serves as a
dynamic gating mechanism to reduce the computation cost for fast inference. We
validate $DA^3$ on multiple datasets against state-of-the-art methods, which
shows great improvement in both accuracy and training time. Moreover, we
deployed $DA^3$ into the popular NIVDIA Jetson Nano edge GPU, where the
measured experimental results show our proposed $DA^3$ reduces the on-device
training memory consumption by 19-37x, and training time by 2x, in comparison
to the baseline methods (e.g., standard fine-tuning, Parallel and Series Res.
adaptor, and Piggyback).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MPG: A Multi-ingredient Pizza Image Generator with Conditional StyleGANs. (arXiv:2012.02821v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02821">
<div class="article-summary-box-inner">
<span><p>Multilabel conditional image generation is a challenging problem in computer
vision. In this work we propose Multi-ingredient Pizza Generator (MPG), a
conditional Generative Neural Network (GAN) framework for synthesizing
multilabel images. We design MPG based on a state-of-the-art GAN structure
called StyleGAN2, in which we develop a new conditioning technique by enforcing
intermediate feature maps to learn scalewise label information. Because of the
complex nature of the multilabel image generation problem, we also regularize
synthetic image by predicting the corresponding ingredients as well as
encourage the discriminator to distinguish between matched image and mismatched
image. To verify the efficacy of MPG, we test it on Pizza10, which is a
carefully annotated multi-ingredient pizza image dataset. MPG can successfully
generate photo-realist pizza images with desired ingredients. The framework can
be easily extend to other multilabel image generation scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantically Robust Unpaired Image Translation for Data with Unmatched Semantics Statistics. (arXiv:2012.04932v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04932">
<div class="article-summary-box-inner">
<span><p>Many applications of unpaired image-to-image translation require the input
contents to be preserved semantically during translations. Unaware of the
inherently unmatched semantics distributions between source and target domains,
existing distribution matching methods (i.e., GAN-based) can give undesired
solutions. In particular, although producing visually reasonable outputs, the
learned models usually flip the semantics of the inputs. To tackle this without
using extra supervision, we propose to enforce the translated outputs to be
semantically invariant w.r.t. small perceptual variations of the inputs, a
property we call "semantic robustness". By optimizing a robustness loss w.r.t.
multi-scale feature space perturbations of the inputs, our method effectively
reduces semantics flipping and produces translations that outperform existing
methods both quantitatively and qualitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Disentanglement of Structured Latent Representations. (arXiv:2101.04041v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04041">
<div class="article-summary-box-inner">
<span><p>We introduce the first metric for evaluating disentanglement at individual
hierarchy levels of a structured latent representation. Applied to
object-centric generative models, this offers a systematic, unified approach to
evaluating (i) object separation between latent slots (ii) disentanglement of
object properties inside individual slots (iii) disentanglement of intrinsic
and extrinsic object properties. We theoretically show that our framework gives
stronger guarantees of selecting a good model than previous disentanglement
metrics. Experimentally, we demonstrate that viewing object compositionality as
a disentanglement problem addresses several issues with prior visual metrics of
object separation. As a core technical component, we present the first
representation probing algorithm handling slot permutation invariance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hand-Based Person Identification using Global and Part-Aware Deep Feature Representation Learning. (arXiv:2101.05260v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05260">
<div class="article-summary-box-inner">
<span><p>In cases of serious crime, including sexual abuse, often the only available
information with demonstrated potential for identification is images of the
hands. Since this evidence is captured in uncontrolled situations, it is
difficult to analyse. As global approaches to feature comparison are limited in
this case, it is important to extend to consider local information. In this
work, we propose hand-based person identification by learning both global and
local deep feature representation. Our proposed method, Global and Part-Aware
Network (GPA-Net), creates global and local branches on the conv-layer for
learning robust discriminative global and part-level features. For learning the
local (part-level) features, we perform uniform partitioning on the conv-layer
in both horizontal and vertical directions. We retrieve the parts by conducting
a soft partition without explicitly partitioning the images or requiring
external cues such as pose estimation. We make extensive evaluations on two
large multi-ethnic and publicly available hand datasets, demonstrating that our
proposed method significantly outperforms competing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Text-to-Image Synthesis: A Review. (arXiv:2101.09983v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09983">
<div class="article-summary-box-inner">
<span><p>With the advent of generative adversarial networks, synthesizing images from
textual descriptions has recently become an active research area. It is a
flexible and intuitive way for conditional image generation with significant
progress in the last years regarding visual realism, diversity, and semantic
alignment. However, the field still faces several challenges that require
further research efforts such as enabling the generation of high-resolution
images with multiple objects, and developing suitable and reliable evaluation
metrics that correlate with human judgement. In this review, we contextualize
the state of the art of adversarial text-to-image synthesis models, their
development since their inception five years ago, and propose a taxonomy based
on the level of supervision. We critically examine current strategies to
evaluate text-to-image synthesis models, highlight shortcomings, and identify
new areas of research, ranging from the development of better datasets and
evaluation metrics to possible improvements in architectural design and model
training. This review complements previous surveys on generative adversarial
networks with a focus on text-to-image synthesis which we believe will help
researchers to further advance the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scattering Networks on the Sphere for Scalable and Rotationally Equivariant Spherical CNNs. (arXiv:2102.02828v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02828">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) constructed natively on the sphere have
been developed recently and shown to be highly effective for the analysis of
spherical data. While an efficient framework has been formulated, spherical
CNNs are nevertheless highly computationally demanding; typically they cannot
scale beyond spherical signals of thousands of pixels. We develop scattering
networks constructed natively on the sphere that provide a powerful
representational space for spherical data. Spherical scattering networks are
computationally scalable and exhibit rotational equivariance, while their
representational space is invariant to isometries and provides efficient and
stable signal representations. By integrating scattering networks as an
additional type of layer in the generalized spherical CNN framework, we show
how they can be leveraged to scale spherical CNNs to the high-resolution data
typical of many practical applications, with spherical signals of many tens of
megapixels and beyond.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Models Are More Interpretable Because Attributions Look Normal. (arXiv:2103.11257v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11257">
<div class="article-summary-box-inner">
<span><p>Recent work has found that adversarially-robust deep networks used for image
classification are more interpretable: their feature attributions tend to be
sharper, and are more concentrated on the objects associated with the image's
ground-truth class. We show that smooth decision boundaries play an important
role in this enhanced interpretability, as the model's input gradients around
data points will more closely align with boundaries' normal vectors when they
are smooth. Thus, because robust models have smoother boundaries, the results
of gradient-based attribution methods, like Integrated Gradients and DeepLift,
will capture more accurate information about nearby decision boundaries. This
understanding of robust interpretability leads to our second contribution:
\emph{boundary attributions}, which aggregate information about the normal
vectors of local decision boundaries to explain a classification outcome. We
show that by leveraging the key factors underpinning robust interpretability,
boundary attributions produce sharper, more concentrated visual explanations --
even on non-robust models. Any example implementation can be found at
\url{https://github.com/zifanw/boundary}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimization for Arbitrary-Oriented Object Detection via Representation Invariance Loss. (arXiv:2103.11636v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11636">
<div class="article-summary-box-inner">
<span><p>Arbitrary-oriented objects exist widely in natural scenes, and thus the
oriented object detection has received extensive attention in recent years. The
mainstream rotation detectors use oriented bounding boxes (OBB) or
quadrilateral bounding boxes (QBB) to represent the rotating objects. However,
these methods suffer from the representation ambiguity for oriented object
definition, which leads to suboptimal regression optimization and the
inconsistency between the loss metric and the localization accuracy of the
predictions. In this paper, we propose a Representation Invariance Loss (RIL)
to optimize the bounding box regression for the rotating objects. Specifically,
RIL treats multiple representations of an oriented object as multiple
equivalent local minima, and hence transforms bounding box regression into an
adaptive matching process with these local minima. Then, the Hungarian matching
algorithm is adopted to obtain the optimal regression strategy. We also propose
a normalized rotation loss to alleviate the weak correlation between different
variables and their unbalanced loss contribution in OBB representation.
Extensive experiments on remote sensing datasets and scene text datasets show
that our method achieves consistent and substantial improvement. The source
code and trained models are available at https://github.com/ming71/RIDet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning a Sketch Tensor Space for Image Inpainting of Man-made Scenes. (arXiv:2103.15087v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15087">
<div class="article-summary-box-inner">
<span><p>This paper studies the task of inpainting man-made scenes. It is very
challenging due to the difficulty in preserving the visual patterns of images,
such as edges, lines, and junctions. Especially, most previous works are failed
to restore the object/building structures for images of man-made scenes. To
this end, this paper proposes learning a Sketch Tensor (ST) space for
inpainting man-made scenes. Such a space is learned to restore the edges,
lines, and junctions in images, and thus makes reliable predictions of the
holistic image structures. To facilitate the structure refinement, we propose a
Multi-scale Sketch Tensor inpainting (MST) network, with a novel
encoder-decoder structure. The encoder extracts lines and edges from the input
images to project them into an ST space. From this space, the decoder is
learned to restore the input images. Extensive experiments validate the
efficacy of our model. Furthermore, our model can also achieve competitive
performance in inpainting general nature images over the competitors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LatentCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions. (arXiv:2104.00820v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00820">
<div class="article-summary-box-inner">
<span><p>Recent research has shown that it is possible to find interpretable
directions in the latent spaces of pre-trained Generative Adversarial Networks
(GANs). These directions enable controllable image generation and support a
wide range of semantic editing operations, such as zoom or rotation. The
discovery of such directions is often done in a supervised or semi-supervised
manner and requires manual annotations which limits their use in practice. In
comparison, unsupervised discovery allows finding subtle directions that are
difficult to detect a priori. In this work, we propose a contrastive
learning-based approach to discover semantic directions in the latent space of
pre-trained GANs in a self-supervised manner. Our approach finds semantically
meaningful dimensions comparable with state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantically Stealthy Adversarial Attacks against Segmentation Models. (arXiv:2104.01732v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01732">
<div class="article-summary-box-inner">
<span><p>Segmentation models have been found to be vulnerable to targeted/non-targeted
adversarial attacks. However, damaged predictions make it easy to unearth an
attack. In this paper, we propose semantically stealthy adversarial attacks
which can manipulate targeted labels as designed and preserve non-targeted
labels at the same time. In this way, we may hide the corresponding attack
behaviors. One challenge is making semantically meaningful manipulations across
datasets/models. Another challenge is avoiding damaging non-targeted labels. To
solve the above challenges, we consider each input image as prior knowledge to
generate perturbations. We also design a special regularizer to help extract
features. To evaluate our model's performance, we design three basic attack
types, namely `vanishing into the context', `embedding fake labels', and
`displacing target objects'. The experiments show that our stealthy adversarial
model can attack segmentation models with a relatively high success rate on
Cityscapes, Mapillary, and BDD100K. Finally, our framework also shows good
generalizations across datasets/models empirically.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relating Adversarially Robust Generalization to Flat Minima. (arXiv:2104.04448v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04448">
<div class="article-summary-box-inner">
<span><p>Adversarial training (AT) has become the de-facto standard to obtain models
robust against adversarial examples. However, AT exhibits severe robust
overfitting: cross-entropy loss on adversarial examples, so-called robust loss,
decreases continuously on training examples, while eventually increasing on
test examples. In practice, this leads to poor robust generalization, i.e.,
adversarial robustness does not generalize well to new examples. In this paper,
we study the relationship between robust generalization and flatness of the
robust loss landscape in weight space, i.e., whether robust loss changes
significantly when perturbing weights. To this end, we propose average- and
worst-case metrics to measure flatness in the robust loss landscape and show a
correlation between good robust generalization and flatness. For example,
throughout training, flatness reduces significantly during overfitting such
that early stopping effectively finds flatter minima in the robust loss
landscape. Similarly, AT variants achieving higher adversarial robustness also
correspond to flatter minima. This holds for many popular choices, e.g.,
AT-AWP, TRADES, MART, AT with self-supervision or additional unlabeled
examples, as well as simple regularization techniques, e.g., AutoAugment,
weight decay or label noise. For fair comparison across these approaches, our
flatness measures are specifically designed to be scale-invariant and we
conduct extensive experiments to validate our findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Augmented Contrastive Learning for Abnormality Classification and Localization in Chest X-rays with Radiomics using a Feedback Loop. (arXiv:2104.04968v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04968">
<div class="article-summary-box-inner">
<span><p>Building a highly accurate predictive model for these tasks usually requires
a large number of manually annotated labels and pixel regions (bounding boxes)
of abnormalities. However, it is expensive to acquire such annotations,
especially the bounding boxes. Recently, contrastive learning has shown strong
promise in leveraging unlabeled natural images to produce highly generalizable
and discriminative features. However, extending its power to the medical image
domain is under-explored and highly non-trivial, since medical images are much
less amendable to data augmentations. In contrast, their prior knowledge, as
well as radiomic features, is often crucial. To bridge this gap, we propose an
end-to-end semi-supervised knowledge-augmented contrastive learning framework,
that simultaneously performs disease classification and localization tasks. The
key knob of our framework is a unique positive sampling approach tailored for
the medical images, by seamlessly integrating radiomic features as a knowledge
augmentation. Specifically, we first apply an image encoder to classify the
chest X-rays and to generate the image features. We next leverage Grad-CAM to
highlight the crucial (abnormal) regions for chest X-rays (even when
unannotated), from which we extract radiomic features. The radiomic features
are then passed through another dedicated encoder to act as the positive sample
for the image features generated from the same chest X-ray. In this way, our
framework constitutes a feedback loop for image and radiomic modality features
to mutually reinforce each other. Their contrasting yields knowledge-augmented
representations that are both robust and interpretable. Extensive experiments
on the NIH Chest X-ray dataset demonstrate that our approach outperforms
existing baselines in both classification and localization tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The hidden label-marginal biases of segmentation losses. (arXiv:2104.08717v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08717">
<div class="article-summary-box-inner">
<span><p>Most segmentation losses are arguably variants of the Cross-Entropy (CE) or
Dice losses. In the abundant segmentation literature, there is no clear
consensus as to which of these losses is a better choice, with varying
performances for each across different benchmarks and applications. In this
work, we develop a theoretical analysis that links these two types of losses,
exposing their advantages and weaknesses. First, we provide a
constrained-optimization perspective showing that CE and Dice share a much
deeper connection than previously thought: They both decompose into
label-marginal penalties and closely related ground-truth matching penalties.
Then, we provide bound relationships and an information-theoretic analysis,
which uncover hidden label-marginal biases: Dice has an intrinsic bias towards
specific extremely imbalanced solutions, whereas CE implicitly encourages the
ground-truth region proportions. Our theoretical results explain the wide
experimental evidence in the medical-imaging literature, whereby Dice losses
bring improvements for imbalanced segmentation. It also explains why CE
dominates natural-image problems with diverse class proportions, in which case
Dice might have difficulty adapting to different label-marginal distributions.
Based on our theoretical analysis, we propose a principled and simple solution,
which enables to control explicitly the label-marginal bias. Our loss
integrates CE with explicit ${\cal L}_1$ regularization, which encourages label
marginals to match target class proportions, thereby mitigating class imbalance
but without losing generality. Comprehensive experiments and ablation studies
over different losses and applications validate our theoretical analysis, as
well as the effectiveness of our explicit label-marginal regularizers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust 3D Cell Segmentation: Extending the View of Cellpose. (arXiv:2105.00794v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00794">
<div class="article-summary-box-inner">
<span><p>Increasing data set sizes of 3D microscopy imaging experiments demand for an
automation of segmentation processes to be able to extract meaningful
biomedical information. Due to the shortage of annotated 3D image data that can
be used for machine learning-based approaches, 3D segmentation approaches are
required to be robust and to generalize well to unseen data. The Cellpose
approach proposed by Stringer \textit{et al.} \cite{stringer2020} proved to be
such a generalist approach for cell instance segmentation tasks. In this paper,
we extend the Cellpose approach to improve segmentation accuracy on 3D image
data and we further show how the formulation of the gradient maps can be
simplified while still being robust and reaching similar segmentation accuracy.
The code is publicly available and was integrated into two established
open-source applications that allow using the 3D extension of Cellpose without
any programming knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Fast Partial Video Copy Detection Using KNN and Global Feature Database. (arXiv:2105.01713v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01713">
<div class="article-summary-box-inner">
<span><p>We propose a fast partial video copy detection framework in this paper. In
this framework all frame features of the reference videos are organized in a
KNN searchable database. Instead of scanning all reference videos, the query
video segment does a fast KNN search in the global feature database. The
returned results are used to generate a short list of candidate videos. A
modified temporal network is then used to localize the copy segment in the
candidate videos. We evaluate different choice of CNN features on the VCDB
dataset. Our benchmark F1 score exceeds the state of the art by a big margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Training with Rectified Rejection. (arXiv:2105.14785v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14785">
<div class="article-summary-box-inner">
<span><p>Adversarial training (AT) is one of the most effective strategies for
promoting model robustness, whereas even the state-of-the-art adversarially
trained models struggle to exceed 65% robust test accuracy on CIFAR-10 without
additional data, which is far from practical. A natural way to improve beyond
this accuracy bottleneck is to introduce a rejection option, where confidence
is a commonly used certainty proxy. However, the vanilla confidence can
overestimate the model certainty if the input is wrongly classified. To this
end, we propose to use true confidence (T-Con) (i.e., predicted probability of
the true class) as a certainty oracle, and learn to predict T-Con by rectifying
confidence. Intriguingly, we prove that under mild conditions, a rectified
confidence (R-Con) rejector and a confidence rejector can be coupled to
distinguish any wrongly classified input from correctly classified ones. We
also quantify that training R-Con to be aligned with T-Con could be an easier
task than learning robust classifiers. In our experiments, we evaluate our
rectified rejection (RR) module on CIFAR-10, CIFAR-10-C, and CIFAR-100 under
several attacks, and demonstrate that the RR module is well compatible with
different AT frameworks on improving robustness, with little extra computation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RL-DARTS: Differentiable Architecture Search for Reinforcement Learning. (arXiv:2106.02229v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02229">
<div class="article-summary-box-inner">
<span><p>Recently, Differentiable Architecture Search (DARTS) has become one of the
most popular Neural Architecture Search (NAS) methods successfully applied in
supervised learning (SL). However, its applications in other domains, in
particular for reinforcement learning (RL), has seldom been studied. This is
due in part to RL possessing a significantly different optimization paradigm
than SL, especially with regards to the notion of replay data, which is
continually generated via inference in RL. In this paper, we introduce
RL-DARTS, one of the first applications of end-to-end DARTS in RL to search for
convolutional cells, applied to the challenging, infinitely procedurally
generated Procgen benchmark. We demonstrate that the benefits of DARTS become
amplified when applied to RL, namely search efficiency in terms of time and
compute, as well as simplicity in integration with complex preexisting RL code
via simply replacing the image encoder with a DARTS supernet, compatible with
both off-policy and on-policy RL algorithms. At the same time however, we
provide one of the first extensive studies of DARTS outside of the standard
fixed dataset setting in SL via RL-DARTS. We show that throughout training, the
supernet gradually learns better cells, leading to alternative architectures
which can be highly competitive against manually designed policies, but also
verify previous design choices for RL policies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental False Negative Detection for Contrastive Learning. (arXiv:2106.03719v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03719">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning has recently shown great potential in vision tasks
through contrastive learning which aims to discriminate each image, or
instance, in the dataset. However, such instance-level learning ignores the
semantic relationship among instances and sometimes undesirably repels the
anchor from the semantically similar samples, termed as "false negatives". In
this work, we show that the unfavorable effect from false negatives is more
significant for the large-scale datasets with more semantic concepts. To
address the issue, we propose a novel self-supervised contrastive learning
framework that incrementally detects and explicitly removes the false negative
samples. Specifically, following the training process, our method dynamically
detects increasing high-quality false negatives considering that the encoder
gradually improves and the embedding space becomes more semantically
structural. Next, we discuss two strategies to explicitly remove the detected
false negatives during contrastive learning. Extensive experiments show that
our framework outperforms other self-supervised contrastive learning methods on
multiple benchmarks in a limited resource setup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Semantic Hallucination for Domain Generalized Semantic Segmentation. (arXiv:2106.04144v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04144">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks may perform poorly when the test and train data
are from different domains. While this problem can be mitigated by using the
target domain data to align the source and target domain feature
representations, the target domain data may be unavailable due to privacy
concerns. Consequently, there is a need for methods that generalize well
without access to target domain data during training. In this work, we propose
an adversarial hallucination approach, which combines a class-wise
hallucination module and a semantic segmentation module. Since the segmentation
performance varies across different classes, we design a semantic-conditioned
style hallucination layer to adaptively stylize each class. The classwise
stylization parameters are generated from the semantic knowledge in the
segmentation probability maps of the source domain image. Both modules compete
adversarially, with the hallucination module generating increasingly
'difficult' style images to challenge the segmentation module. In response, the
segmentation module improves its performance as it is trained with generated
samples at an appropriate class-wise difficulty level. Experiments on state of
the art domain adaptation work demonstrate the efficacy of our proposed method
when no target domain data are available for training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Wavelet-Packet Powered Deepfake Image Detection. (arXiv:2106.09369v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09369">
<div class="article-summary-box-inner">
<span><p>As neural networks become able to generate realistic artificial images, they
have the potential to improve movies, music, video games and make the internet
an even more creative and inspiring place. Yet, at the same time, the latest
technology potentially enables new digital ways to lie. In response, the need
for a diverse and reliable method toolbox arises to identify artificial images
and other content. Previous work primarily relies on pixel-space CNN or the
Fourier transform. To the best of our knowledge, synthesized fake image
analysis and detection methods based on a multi-scale wavelet representation,
which is localized in both space and frequency, have been absent thus far. This
paper proposes to learn a model for the detection of synthetic images based on
the wavelet-packet representation of natural and GAN-generated images. We
evaluate our method on FFHQ, CelebA, and LSUN source identification problems
and find improved or competitive performance. Our forensic classifier has a
small network size and can be learned efficiently. Furthermore, a comparison of
the wavelet coefficients from these two sources of images allows an
interpretation and identifies significant differences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Visual Robustness by Causal Intervention. (arXiv:2106.09534v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09534">
<div class="article-summary-box-inner">
<span><p>Adversarial training is the de facto most promising defense against
adversarial examples. Yet, its passive nature inevitably prevents it from being
immune to unknown attackers. To achieve a proactive defense, we need a more
fundamental understanding of adversarial examples, beyond the popular bounded
threat model. In this paper, we provide a causal viewpoint of adversarial
vulnerability: the cause is the spurious correlation ubiquitously existing in
learning, i.e., the confounding effect, where attackers are precisely
exploiting these effects. Therefore, a fundamental solution for adversarial
robustness is by causal intervention. As these visual confounders are
imperceptible in general, we propose to use the instrumental variable that
achieves causal intervention without the need for confounder observation. We
term our robust training method as Causal intervention by instrumental Variable
(CiiV). It's a causal regularization that 1) augments the image with multiple
retinotopic centers and 2) encourages the model to learn causal features,
rather than local confounding patterns, by favoring features linearly
responding to spatial interpolations. Extensive experiments on a wide spectrum
of attackers and settings applied in CIFAR-10, CIFAR-100, and mini-ImageNet
demonstrate that CiiV is robust to adaptive attacks, including the recent
AutoAttack. Besides, as a general causal regularization, it can be easily
plugged into other methods to further boost the robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Correspondence Hallucination. (arXiv:2106.09711v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09711">
<div class="article-summary-box-inner">
<span><p>Given a pair of partially overlapping source and target images and a keypoint
in the source image, the keypoint's correspondent in the target image can be
either visible, occluded or outside the field of view. Local feature matching
methods are only able to identify the correspondent's location when it is
visible, while humans can also hallucinate its location when it is occluded or
outside the field of view through geometric reasoning. In this paper, we bridge
this gap by training a network to output a peaked probability distribution over
the correspondent's location, regardless of this correspondent being visible,
occluded, or outside the field of view. We experimentally demonstrate that this
network is indeed able to hallucinate correspondences on pairs of images
captured in scenes that were not seen at training-time. We also apply this
network to an absolute camera pose estimation problem and find it is
significantly more robust than state-of-the-art local feature matching-based
competitors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Steerable 3D Spherical Neurons. (arXiv:2106.13863v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13863">
<div class="article-summary-box-inner">
<span><p>Emerging from low-level vision theory, steerable filters found their
counterpart in prior work on steerable convolutional neural networks
equivariant to rigid transformations. In our work, we propose a steerable
feed-forward learning-based approach that consists of spherical decision
surfaces and operates on point clouds. Focusing on 3D geometry, we derive a 3D
steerability constraint for hypersphere neurons, which are obtained by
conformal embedding of Euclidean space and have recently been revisited in the
context of learning representations of point sets. Exploiting the rotational
equivariance, we show how our model parameters are fully steerable at inference
time. We use a synthetic point set and real-world 3D skeleton data to show how
the proposed spherical filter banks enable making equivariant and, after online
optimization, invariant class predictions for known point sets in unknown
orientations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Technical Document Classification. (arXiv:2106.14269v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14269">
<div class="article-summary-box-inner">
<span><p>In large technology companies, the requirements for managing and organizing
technical documents created by engineers and managers in supporting relevant
decision making have increased dramatically in recent years, which has led to a
higher demand for more scalable, accurate, and automated document
classification. Prior studies have only focused on processing text for
classification, whereas technical documents often contain multimodal
information. This paper presents a novel multimodal deep learning architecture,
TechDoc, for technical document classification, which utilizes three types of
information, including natural language texts and descriptive images within
documents and the associations among the documents. The architecture
synthesizes the convolutional neural network, recurrent neural network, and
graph neural network through an integrated multimodal training process. We
applied the architecture to a large multimodal technical document database and
trained the model for classifying documents based on the hierarchical
International Patent Classification system. Our results show that TechDoc
presents a greater classification accuracy than the unimodal methods and other
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Clothing as a Separate Layer for an Animatable Human Avatar. (arXiv:2106.14879v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14879">
<div class="article-summary-box-inner">
<span><p>We have recently seen great progress in building photorealistic animatable
full-body codec avatars, but generating high-fidelity animation of clothing is
still difficult. To address these difficulties, we propose a method to build an
animatable clothed body avatar with an explicit representation of the clothing
on the upper body from multi-view captured videos. We use a two-layer mesh
representation to register each 3D scan separately with the body and clothing
templates. In order to improve the photometric correspondence across different
frames, texture alignment is then performed through inverse rendering of the
clothing geometry and texture predicted by a variational autoencoder. We then
train a new two-layer codec avatar with separate modeling of the upper clothing
and the inner body layer. To learn the interaction between the body dynamics
and clothing states, we use a temporal convolution network to predict the
clothing latent code based on a sequence of input skeletal poses. We show
photorealistic animation output for three different actors, and demonstrate the
advantage of our clothed-body avatars over the single-layer avatars used in
previous work. We also show the benefit of an explicit clothing model that
allows the clothing texture to be edited in the animation output.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?. (arXiv:2107.00166v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00166">
<div class="article-summary-box-inner">
<span><p>There have been long-standing controversies and inconsistencies over the
experiment setup and criteria for identifying the "winning ticket" in
literature. To reconcile such, we revisit the definition of lottery ticket
hypothesis, with comprehensive and more rigorous conditions. Under our new
definition, we show concrete evidence to clarify whether the winning ticket
exists across the major DNN architectures and/or applications. Through
extensive experiments, we perform quantitative analysis on the correlations
between winning tickets and various experimental factors, and empirically study
the patterns of our observations. We find that the key training
hyperparameters, such as learning rate and training epochs, as well as the
architecture characteristics such as capacities and residual connections, are
all highly correlated with whether and when the winning tickets can be
identified. Based on our analysis, we summarize a guideline for parameter
settings in regards of specific architecture characteristics, which we hope to
catalyze the research progress on the topic of lottery ticket hypothesis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating Large Circular Kernels into CNNs through Neural Architecture Search. (arXiv:2107.02451v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02451">
<div class="article-summary-box-inner">
<span><p>The square kernel is a standard unit for contemporary Convolutional Neural
Networks (CNNs), as it fits well on the tensor computation for the convolution
operation. However, the retinal ganglion cells in the biological visual system
have approximately concentric receptive fields. Motivated by this observation,
we propose using the circular kernel with a concentric and isotropic receptive
field as an option for convolution operation. We first substitute the $3 \times
3$ square kernels with the corresponding circular kernels or our proposed
integrated kernels in the typical ResNet architecture, and the modified models
after training yield similar or even competitive performance. We then show the
advantages of large circular kernels over the corresponding square kernels in
that the difference and the improvement are more distinct. Hence, we speculate
that large circular kernels would help find advanced neural network models by
the Neural Architecture Search (NAS). To validate our hypothesis, we expand the
operation space in several typical NAS methods with convolutions of large
circular kernels. Experimental results show that the searched new neural
network models contain large circular kernels and significantly outperform the
original searched models. The additional empirical analysis also reveals that
the large circular kernel help the model to be more robust to rotated or
sheared images due to its rotation invariance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">iPOKE: Poking a Still Image for Controlled Stochastic Video Synthesis. (arXiv:2107.02790v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02790">
<div class="article-summary-box-inner">
<span><p>How would a static scene react to a local poke? What are the effects on other
parts of an object if you could locally push it? There will be distinctive
movement, despite evident variations caused by the stochastic nature of our
world. These outcomes are governed by the characteristic kinematics of objects
that dictate their overall motion caused by a local interaction. Conversely,
the movement of an object provides crucial information about its underlying
distinctive kinematics and the interdependencies between its parts. This
two-way relation motivates learning a bijective mapping between object
kinematics and plausible future image sequences. Therefore, we propose iPOKE --
invertible Prediction of Object Kinematics -- that, conditioned on an initial
frame and a local poke, allows to sample object kinematics and establishes a
one-to-one correspondence to the corresponding plausible videos, thereby
providing a controlled stochastic video synthesis. In contrast to previous
works, we do not generate arbitrary realistic videos, but provide efficient
control of movements, while still capturing the stochastic nature of our
environment and the diversity of plausible outcomes it entails. Moreover, our
approach can transfer kinematics onto novel object instances and is not
confined to particular object classes. Our project page is available at
https://bit.ly/3dJN4Lf.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SoftHebb: Bayesian inference in unsupervised Hebbian soft winner-take-all networks. (arXiv:2107.05747v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05747">
<div class="article-summary-box-inner">
<span><p>State-of-the-art artificial neural networks (ANNs) require labelled data or
feedback between layers, are often biologically implausible, and are vulnerable
to adversarial attacks that humans are not susceptible to. On the other hand,
Hebbian learning in winner-take-all (WTA) networks, is unsupervised,
feed-forward, and biologically plausible. However, a modern objective
optimization theory for WTA networks has been missing, except under very
limiting assumptions. Here we derive formally such a theory, based on
biologically plausible but generic ANN elements. Through Hebbian learning,
network parameters maintain a Bayesian generative model of the data. There is
no supervisory loss function, but the network does minimize cross-entropy
between its activations and the input distribution. The key is a "soft" WTA
where there is no absolute "hard" winner neuron, and a specific type of
Hebbian-like plasticity of weights and biases. We confirm our theory in
practice, where, in handwritten digit (MNIST) recognition, our Hebbian
algorithm, SoftHebb, minimizes cross-entropy without having access to it, and
outperforms the more frequently used, hard-WTA-based method. Strikingly, it
even outperforms supervised end-to-end backpropagation, under certain
conditions. Specifically, in a two-layered network, SoftHebb outperforms
backpropagation when the training dataset is only presented once, when the
testing data is noisy, and under gradient-based adversarial attacks. Notably,
adversarial attacks that confuse SoftHebb are also confusing to the human eye.
Finally, the model can generate interpolations of objects from its input
distribution. All in all, SoftHebb extends Hebbian WTA theory with modern
machine learning tools, thus making these networks relevant to pertinent issues
in deep learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Domain Adaptation in LiDAR Semantic Segmentation with Self-Supervision and Gated Adapters. (arXiv:2107.09783v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09783">
<div class="article-summary-box-inner">
<span><p>In this paper, we focus on a less explored, but more realistic and complex
problem of domain adaptation in LiDAR semantic segmentation. There is a
significant drop in performance of an existing segmentation model when training
(source domain) and testing (target domain) data originate from different LiDAR
sensors. To overcome this shortcoming, we propose an unsupervised domain
adaptation framework that leverages unlabeled target domain data for
self-supervision, coupled with an unpaired mask transfer strategy to mitigate
the impact of domain shifts. Furthermore, we introduce gated adapter modules
with a small number of parameters into the network to account for target
domain-specific information. Experiments adapting from both real-to-real and
synthetic-to-real LiDAR semantic segmentation benchmarks demonstrate the
significant improvement over prior arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Self-Supervised Learning Can be Used for Fine-Grained Head Pose Estimation?. (arXiv:2108.04893v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04893">
<div class="article-summary-box-inner">
<span><p>The cost of Head View point labels is the main hurdle in the improving of
fine-grained Head Pose estimation algorithm. One solution to the lack of huge
number of labels is using Self-Supervised Learning (SSL). SSL can extract good
features from unlabeled data for a downstream task. Accordingly, this article
has tried to answer a question: How Self-Supervised Learning (SSL) can be used
for Head Pose estimation? In general, there are two main approaches to use SSL:
(1) Using it to pre-train the weights, (2) Leveraging SSL as an auxiliary task
besides of Supervised Learning (SL) in one training session. In this study, we
compared two approaches by designing a Hybrid Multi-Task Learning (HMTL)
architecture and assessing it with two SSL pre-text tasks, the rotation and
puzzling. Results showed that the combination of both methods in which using
rotation for pre-training and using puzzling for auxiliary head were the best.
Together, the error rate was reduced up to 13% compared to the baseline which
is comparable with current SOTA methods. Finally, we compared the impact of
initial weights on the HMTL and SL. Subsequently, by HMTL, the error was
reduced with all kinds of initial weights: random, ImageNet and SSL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Self-supervised Learning with Hardness-aware Dynamic Curriculum Learning: An Application to Digital Pathology. (arXiv:2108.07183v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07183">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) has recently shown tremendous potential to
learn generic visual representations useful for many image analysis tasks.
Despite their notable success, the existing SSL methods fail to generalize to
downstream tasks when the number of labeled training instances is small or if
the domain shift between the transfer domains is significant. In this paper, we
attempt to improve self-supervised pretrained representations through the lens
of curriculum learning by proposing a hardness-aware dynamic curriculum
learning (HaDCL) approach. To improve the robustness and generalizability of
SSL, we dynamically leverage progressive harder examples via easy-to-hard and
hard-to-very-hard samples during mini-batch downstream fine-tuning. We discover
that by progressive stage-wise curriculum learning, the pretrained
representations are significantly enhanced and adaptable to both in-domain and
out-of-domain distribution data.
</p>
<p>We performed extensive validation on three histology benchmark datasets on
both patch-wise and slide-level classification problems. Our curriculum based
fine-tuning yields a significant improvement over standard fine-tuning, with a
minimum improvement in area-under-the-curve (AUC) score of 1.7% and 2.2% on
in-domain and out-of-domain distribution data, respectively. Further, we
empirically show that our approach is more generic and adaptable to any SSL
methods and does not impose any additional overhead complexity. Besides, we
also outline the role of patch-based versus slide-based curriculum learning in
histopathology to provide practical insights into the success of curriculum
based fine-tuning of SSL methods. Code is released at
https://github.com/srinidhiPY/ICCV-CDPATH2021-ID-8
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DKM: Differentiable K-Means Clustering Layer for Neural Network Compression. (arXiv:2108.12659v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12659">
<div class="article-summary-box-inner">
<span><p>Deep neural network (DNN) model compression for efficient on-device inference
is becoming increasingly important to reduce memory requirements and keep user
data on-device. To this end, we propose a novel differentiable k-means
clustering layer (DKM) and its application to train-time weight
clustering-based DNN model compression. DKM casts k-means clustering as an
attention problem and enables joint optimization of the DNN parameters and
clustering centroids. Unlike prior works that rely on additional regularizers
and parameters, DKM-based compression keeps the original loss function and
model architecture fixed. We evaluated DKM-based compression on various DNN
models for computer vision and natural language processing (NLP) tasks. Our
results demonstrate that DKM delivers superior compression and accuracy
trade-off on ImageNet1k and GLUE benchmarks. For example, DKM-based compression
can offer 74.5% top-1 ImageNet1k accuracy on ResNet50 DNN model with 3.3MB
model size (29.4x model compression factor). For MobileNet-v1, which is a
challenging DNN to compress, DKM delivers 63.9% top-1 ImageNet1k accuracy with
0.72 MB model size (22.4x model compression factor). This result is 6.8% higher
top-1accuracy and 33% relatively smaller model size than the current
state-of-the-art DNN compression algorithms. Additionally, DKM enables
compression of DistilBERT model by 11.8x with minimal (1.1%) accuracy loss on
GLUE NLP benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does deep learning model calibration improve performance in class-imbalanced medical image classification?. (arXiv:2110.00918v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00918">
<div class="article-summary-box-inner">
<span><p>In medical image classification tasks, it is common to find that the number
of normal samples far exceeds the number of abnormal samples. In such
class-imbalanced situations, reliable training of deep neural networks
continues to be a major challenge. Under these circumstances, the predicted
class probabilities may be biased toward the majority class. Calibration has
been suggested to alleviate some of these effects. However, there is
insufficient analysis explaining when and whether calibrating a model would be
beneficial in improving performance. In this study, we perform a systematic
analysis of the effect of model calibration on its performance on two medical
image modalities, namely, chest X-rays and fundus images, using various deep
learning classifier backbones. For this, we study the following variations: (i)
the degree of imbalances in the dataset used for training; (ii) calibration
methods; and (iii) two classification thresholds, namely, default decision
threshold of 0.5, and optimal threshold from precision-recall curves. Our
results indicate that at the default operating threshold of 0.5, the
performance achieved through calibration is significantly superior (p &lt; 0.05)
to using uncalibrated probabilities. However, at the PR-guided threshold, these
gains are not significantly different (p &gt; 0.05). This finding holds for both
image modalities and at varying degrees of imbalance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Unfolding Total Variation Network for Low-Light Image Enhancement. (arXiv:2110.00984v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00984">
<div class="article-summary-box-inner">
<span><p>Real-world low-light images suffer from two main degradations, namely,
inevitable noise and poor visibility. Since the noise exhibits different
levels, its estimation has been implemented in recent works when enhancing
low-light images from raw Bayer space. When it comes to sRGB color space, the
noise estimation becomes more complicated due to the effect of the image
processing pipeline. Nevertheless, most existing enhancing algorithms in sRGB
space only focus on the low visibility problem or suppress the noise under a
hypothetical noise level, leading them impractical due to the lack of
robustness. To address this issue,we propose an adaptive unfolding total
variation network (UTVNet), which approximates the noise level from the real
sRGB low-light image by learning the balancing parameter in the model-based
denoising method with total variation regularization. Meanwhile, we learn the
noise level map by unrolling the corresponding minimization process for
providing the inferences of smoothness and fidelity constraints. Guided by the
noise level map, our UTVNet can recover finer details and is more capable to
suppress noise in real captured low-light scenes. Extensive experiments on
real-world low-light images clearly demonstrate the superior performance of
UTVNet over state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A new weakly supervised approach for ALS point cloud semantic segmentation. (arXiv:2110.01462v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01462">
<div class="article-summary-box-inner">
<span><p>While there are novel point cloud semantic segmentation schemes that
continuously surpass state-of-the-art results, the success of learning an
effective model usually rely on the availability of abundant labeled data.
However, data annotation is a time-consuming and labor-intensive task,
particularly for large-scale airborne laser scanning (ALS) point clouds
involving multiple classes in urban areas. Thus, how to attain promising
results while largely reducing labeling works become an essential issue. In
this study, we propose a deep-learning based weakly supervised framework for
semantic segmentation of ALS point clouds, exploiting potential information
from unlabeled data subject to incomplete and sparse labels. Entropy
regularization is introduced to penalize the class overlap in predictive
probability. Additionally, a consistency constraint by minimizing the
discrepancy distance between instant and ensemble predictions is designed to
improve the robustness of predictions. Finally, we propose an online soft
pseudo-labeling strategy to create extra supervisory sources in an efficient
and nonpaprametric way. Extensive experimental analysis using three benchmark
datasets demonstrates that in case of sparse point annotations, our proposed
method significantly boosts the classification performance without compromising
the computational efficiency. It outperforms current weakly supervised methods
and achieves a comparable result against full supervision competitors. For the
ISPRS 3D Labeling Vaihingen data, by using only 0.1% of labels, our method
achieves an overall accuracy of 83.0% and an average F1 score of 70.0%, which
have increased by 6.9% and 12.8% respectively, compared to model trained by
sparse label information only.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breast Cancer Diagnosis in Two-View Mammography Using End-to-End Trained EfficientNet-Based Convolutional Network. (arXiv:2110.01606v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01606">
<div class="article-summary-box-inner">
<span><p>Some recent studies have described deep convolutional neural networks to
diagnose breast cancer in mammograms with similar or even superior performance
to that of human experts. Shen et al. (2019) present one of the best techniques
that consists of two transfer learnings. The first uses a model trained on
natural images to create a "patch classifier" that categorizes small subimages.
The second uses the patch classifier to scan the whole mammogram and create the
"single-view whole-image classifier". We propose to make a third transfer
learning to obtain a "two-view classifier" to use the two mammographic views:
bilateral craniocaudal and mediolateral oblique. We use modern EfficientNet as
the basis of our model. We "end-to-end" train the entire system using CBIS-DDSM
dataset. To ensure statistical robustness, we test our system twice using: (a)
5-fold cross validation; and (b) the original training/test division of the
dataset. Our technique reached an AUC of 0.934 using 5-fold cross validation
(sensitivity and specificity are 85.13% at the equal error rate of ROC). Using
the original dataset division, our technique achieved an AUC of 0.8483, the
largest AUC reported for this problem, as far as we know.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning of Perceptually Optimized Block Motion Estimates for Video Compression. (arXiv:2110.01805v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01805">
<div class="article-summary-box-inner">
<span><p>Block based motion estimation is integral to inter prediction processes
performed in hybrid video codecs. Prevalent block matching based methods that
are used to compute block motion vectors (MVs) rely on computationally
intensive search procedures. They also suffer from the aperture problem, which
can worsen as the block size is reduced. Moreover, the block matching criteria
used in typical codecs do not account for the resulting levels of perceptual
quality of the motion compensated pictures that are created upon decoding.
Towards achieving the elusive goal of perceptually optimized motion estimation,
we propose a search-free block motion estimation framework using a multi-stage
convolutional neural network, which is able to conduct motion estimation on
multiple block sizes simultaneously, using a triplet of frames as input. This
composite block translation network (CBT-Net) is trained in a self-supervised
manner on a large database that we created from publicly available uncompressed
video content. We deploy the multi-scale structural similarity (MS-SSIM) loss
function to optimize the perceptual quality of the motion compensated predicted
frames. Our experimental results highlight the computational efficiency of our
proposed model relative to conventional block matching based motion estimation
algorithms, for comparable prediction errors. Further, when used to perform
inter prediction in AV1, the MV predictions of the perceptually optimized model
result in average Bjontegaard-delta rate (BD-rate) improvements of -1.70% and
-1.52% with respect to the MS-SSIM and Video Multi-Method Assessment Fusion
(VMAF) quality metrics, respectively as compared to the block matching based
motion estimation system employed in the SVT-AV1 encoder.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine learning attack on copy detection patterns: are 1x1 patterns cloneable?. (arXiv:2110.02176v2 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02176">
<div class="article-summary-box-inner">
<span><p>Nowadays, the modern economy critically requires reliable yet cheap
protection solutions against product counterfeiting for the mass market. Copy
detection patterns (CDP) are considered as such solution in several
applications. It is assumed that being printed at the maximum achievable limit
of a printing resolution of an industrial printer with the smallest symbol size
1x1 elements, the CDP cannot be copied with sufficient accuracy and thus are
unclonable. In this paper, we challenge this hypothesis and consider a copy
attack against the CDP based on machine learning. The experimental based on
samples produced on two industrial printers demonstrate that simple detection
metrics used in the CDP authentication cannot reliably distinguish the original
CDP from their fakes. Thus, the paper calls for a need of careful
reconsideration of CDP cloneability and search for new authentication
techniques and CDP optimization because of the current attack.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-07 23:02:06.947496525 UTC">2021-10-07 23:02:06 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>