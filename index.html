<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-04T01:30:00Z">10-04</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Variance of Twitter Embeddings and Temporal Trends of COVID-19 cases. (arXiv:2110.00031v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00031">
<div class="article-summary-box-inner">
<span><p>The severity of the coronavirus pandemic necessitates the need of effective
administrative decisions. Over 4 lakh people in India succumbed to COVID-19,
with over 3 crore confirmed cases, and still counting. The threat of a
plausible third wave continues to haunt millions. In this ever changing dynamic
of the virus, predictive modeling methods can serve as an integral tool. The
pandemic has further triggered an unprecedented usage of social media. This
paper aims to propose a method for harnessing social media, specifically
Twitter, to predict the upcoming scenarios related to COVID-19 cases. In this
study, we seek to understand how the surges in COVID-19 related tweets can
indicate rise in the cases. This prospective analysis can be utilised to aid
administrators about timely resource allocation to lessen the severity of the
damage. Using word embeddings to capture the semantic meaning of tweets, we
identify Significant Dimensions (SDs).Our methodology predicts the rise in
cases with a lead time of 15 days and 30 days with R2 scores of 0.80 and 0.62
respectively. Finally, we explain the thematic utility of the SDs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">#ContextMatters: Advantages and Limitations of Using Machine Learning to Support Women in Politics. (arXiv:2110.00116v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00116">
<div class="article-summary-box-inner">
<span><p>The United Nations identified gender equality as a Sustainable Development
Goal in 2015, recognizing the underrepresentation of women in politics as a
specific barrier to achieving gender equality. Political systems around the
world experience gender inequality across all levels of elected government as
fewer women run for office than men. This is due in part to online abuse,
particularly on social media platforms like Twitter, where women seeking or in
power tend to be targeted with more toxic maltreatment than their male
counterparts. In this paper, we present reflections on ParityBOT - the first
natural language processing-based intervention designed to affect online
discourse for women in politics for the better, at scale. Deployed across
elections in Canada, the United States and New Zealand, ParityBOT was used to
analyse and classify more than 12 million tweets directed at women candidates
and counter toxic tweets with supportive ones. From these elections we present
three case studies highlighting the current limitations of, and future research
and application opportunities for, using a natural language processing-based
system to detect online toxicity, specifically with regards to contextually
important microaggressions. We examine the rate of false negatives, where
ParityBOT failed to pick up on insults directed at specific high profile women,
which would be obvious to human users. We examine the unaddressed harms of
microaggressions and the potential of yet unseen damage they cause for women in
these communities, and for progress towards gender equality overall, in light
of these technological blindspots. This work concludes with a discussion on the
benefits of partnerships between nonprofit social groups and technology experts
to develop responsible, socially impactful approaches to addressing online
hate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tree-Constrained Graph Neural Networks For Argument Mining. (arXiv:2110.00124v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00124">
<div class="article-summary-box-inner">
<span><p>We propose a novel architecture for Graph Neural Networks that is inspired by
the idea behind Tree Kernels of measuring similarity between trees by taking
into account their common substructures, named fragments. By imposing a series
of regularization constraints to the learning problem, we exploit a pooling
mechanism that incorporates such notion of fragments within the node soft
assignment function that produces the embeddings. We present an extensive
experimental evaluation on a collection of sentence classification tasks
conducted on several argument mining corpora, showing that the proposed
approach performs well with respect to state-of-the-art techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MemBERT: Injecting Unstructured Knowledge into BERT. (arXiv:2110.00125v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00125">
<div class="article-summary-box-inner">
<span><p>Transformers changed modern NLP in many ways. However, they can hardly
exploit domain knowledge, and like other blackbox models, they lack
interpretability. Unfortunately, structured knowledge injection, in the long
run, risks to suffer from a knowledge acquisition bottleneck. We thus propose a
memory enhancement of transformer models that makes use of unstructured domain
knowledge expressed in plain natural language. An experimental evaluation
conducted on two challenging NLP tasks demonstrates that our approach yields
better performance and model interpretability than baseline transformer-based
architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UserIdentifier: Implicit User Representations for Simple and Effective Personalized Sentiment Analysis. (arXiv:2110.00135v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00135">
<div class="article-summary-box-inner">
<span><p>Global models are trained to be as generalizable as possible, with user
invariance considered desirable since the models are shared across multitudes
of users. As such, these models are often unable to produce personalized
responses for individual users, based on their data. Contrary to widely-used
personalization techniques based on few-shot learning, we propose
UserIdentifier, a novel scheme for training a single shared model for all
users. Our approach produces personalized responses by adding fixed,
non-trainable user identifiers to the input data. We empirically demonstrate
that this proposed method outperforms the prefix-tuning based state-of-the-art
approach by up to 13%, on a suite of sentiment analysis datasets. We also show
that, unlike prior work, this method needs neither any additional model
parameters nor any extra rounds of few-shot fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Span Labeling Approach for Vietnamese and Chinese Word Segmentation. (arXiv:2110.00156v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00156">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a span labeling approach to model n-gram
information for Vietnamese word segmentation, namely SPAN SEG. We compare the
span labeling approach with the conditional random field by using encoders with
the same architecture. Since Vietnamese and Chinese have similar linguistic
phenomena, we evaluated the proposed method on the Vietnamese treebank
benchmark dataset and five Chinese benchmark datasets. Through our experimental
results, the proposed approach SpanSeg achieves higher performance than the
sequence tagging approach with the state-of-the-art F-score of 98.31% on the
Vietnamese treebank benchmark, when they both apply the contextual pre-trained
language model XLM-RoBERTa and the predicted word boundary information.
Besides, we do fine-tuning experiments for the span labeling approach on BERT
and ZEN pre-trained language model for Chinese with fewer parameters, faster
inference time, and competitive or higher F-scores than the previous
state-of-the-art approach, word segmentation with word-hood memory networks, on
five Chinese benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Under the Microscope: Interpreting Readability Assessment Models for Filipino. (arXiv:2110.00157v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00157">
<div class="article-summary-box-inner">
<span><p>Readability assessment is the process of identifying the level of ease or
difficulty of a certain piece of text for its intended audience. Approaches
have evolved from the use of arithmetic formulas to more complex
pattern-recognizing models trained using machine learning algorithms. While
using these approaches provide competitive results, limited work is done on
analyzing how linguistic variables affect model inference quantitatively. In
this work, we dissect machine learning-based readability assessment models in
Filipino by performing global and local model interpretation to understand the
contributions of varying linguistic features and discuss its implications in
the context of the Filipino language. Results show that using a model trained
with top features from global interpretation obtained higher performance than
the ones using features selected by Spearman correlation. Likewise, we also
empirically observed local feature weight boundaries for discriminating reading
difficulty at an extremely fine-grained level and their corresponding effects
if values are perturbed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building an Efficient and Effective Retrieval-based Dialogue System via Mutual Learning. (arXiv:2110.00159v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00159">
<div class="article-summary-box-inner">
<span><p>Establishing retrieval-based dialogue systems that can select appropriate
responses from the pre-built index has gained increasing attention from
researchers. For this task, the adoption of pre-trained language models (such
as BERT) has led to remarkable progress in a number of benchmarks. There exist
two common approaches, including cross-encoders which perform full attention
over the inputs, and bi-encoders that encode the context and response
separately. The former gives considerable improvements in accuracy but is often
inapplicable in practice for large-scale retrieval given the cost of the full
attention required for each sample at test time. The latter is efficient for
billions of indexes but suffers from sub-optimal performance. In this work, we
propose to combine the best of both worlds to build a retrieval system.
Specifically, we employ a fast bi-encoder to replace the traditional
feature-based pre-retrieval model (such as BM25) and set the response
re-ranking model as a more complicated architecture (such as cross-encoder). To
further improve the effectiveness of our framework, we train the pre-retrieval
model and the re-ranking model at the same time via mutual learning, which
enables two models to learn from each other throughout the training process. We
conduct experiments on two benchmarks and evaluation results demonstrate the
efficiency and effectiveness of our proposed framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large-scale ASR Domain Adaptation by Self- and Semi-supervised Learning. (arXiv:2110.00165v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00165">
<div class="article-summary-box-inner">
<span><p>Self- and Semi-supervised learning methods have been actively investigated to
reduce labeled training data or enhance the model performance. However, the
approach mostly focus on in-domain performance for public datasets. In this
study, we utilize the combination of self- and semi-supervised learning methods
to solve unseen domain adaptation problem in a large-scale production setting
for online ASR model. This approach demonstrates that using the source domain
data with a small fraction of the target domain data (3%) can recover the
performance gap compared to a full data baseline: relative 13.5% WER
improvement for target domain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERT4GCN: Using BERT Intermediate Layers to Augment GCN for Aspect-based Sentiment Classification. (arXiv:2110.00171v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00171">
<div class="article-summary-box-inner">
<span><p>Graph-based Aspect-based Sentiment Classification (ABSC) approaches have
yielded state-of-the-art results, expecially when equipped with contextual word
embedding from pre-training language models (PLMs). However, they ignore
sequential features of the context and have not yet made the best of PLMs. In
this paper, we propose a novel model, BERT4GCN, which integrates the
grammatical sequential features from the PLM of BERT, and the syntactic
knowledge from dependency graphs. BERT4GCN utilizes outputs from intermediate
layers of BERT and positional information between words to augment GCN (Graph
Convolutional Network) to better encode the dependency graphs for the
downstream classification. Experimental results demonstrate that the proposed
BERT4GCN outperforms all state-of-the-art baselines, justifying that augmenting
GCN with the grammatical features from intermediate layers of BERT can
significantly empower ABSC models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Knowledge Enhanced Pre-trained Models. (arXiv:2110.00269v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00269">
<div class="article-summary-box-inner">
<span><p>Pre-trained models learn contextualized word representations on large-scale
text corpus through a self-supervised learning method, which has achieved
promising performance after fine-tuning. These models, however, suffer from
poor robustness and lack of interpretability. Pre-trained models with knowledge
injection, which we call knowledge enhanced pre-trained models (KEPTMs),
possess deep understanding and logical reasoning and introduce interpretability
to some extent. In this survey, we provide a comprehensive overview of KEPTMs
for natural language processing. We first introduce the progress of pre-trained
models and knowledge representation learning. Then we systematically categorize
existing KEPTMs from three different perspectives. Finally, we outline some
potential directions of KEPTMs for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Harmful Memes and Their Targets. (arXiv:2110.00413v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00413">
<div class="article-summary-box-inner">
<span><p>Among the various modes of communication in social media, the use of Internet
memes has emerged as a powerful means to convey political, psychological, and
socio-cultural opinions. Although memes are typically humorous in nature,
recent days have witnessed a proliferation of harmful memes targeted to abuse
various social entities. As most harmful memes are highly satirical and
abstruse without appropriate contexts, off-the-shelf multimodal models may not
be adequate to understand their underlying semantics. In this work, we propose
two novel problem formulations: detecting harmful memes and the social entities
that these harmful memes target. To this end, we present HarMeme, the first
benchmark dataset, containing 3,544 memes related to COVID-19. Each meme went
through a rigorous two-stage annotation process. In the first stage, we labeled
a meme as very harmful, partially harmful, or harmless; in the second stage, we
further annotated the type of target(s) that each harmful meme points to:
individual, organization, community, or society/general public/other. The
evaluation results using ten unimodal and multimodal models highlight the
importance of using multimodal signals for both tasks. We further discuss the
limitations of these models and we argue that more research is needed to
address these problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FiLMing Multimodal Sarcasm Detection with Attention. (arXiv:2110.00416v1 [cs.MM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00416">
<div class="article-summary-box-inner">
<span><p>Sarcasm detection identifies natural language expressions whose intended
meaning is different from what is implied by its surface meaning. It finds
applications in many NLP tasks such as opinion mining, sentiment analysis, etc.
Today, social media has given rise to an abundant amount of multimodal data
where users express their opinions through text and images. Our paper aims to
leverage multimodal data to improve the performance of the existing systems for
sarcasm detection. So far, various approaches have been proposed that uses text
and image modality and a fusion of both. We propose a novel architecture that
uses the RoBERTa model with a co-attention layer on top to incorporate context
incongruity between input text and image attributes. Further, we integrate
feature-wise affine transformation by conditioning the input image through
FiLMed ResNet blocks with the textual features using the GRU network to capture
the multimodal information. The output from both the models and the CLS token
from RoBERTa is concatenated and used for the final prediction. Our results
demonstrate that our proposed model outperforms the existing state-of-the-art
method by 6.14% F1 score on the public Twitter multimodal sarcasm detection
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of Non-Negative Matrix Factorization and n-stage Latent Dirichlet Allocation for Emotion Analysis in Turkish Tweets. (arXiv:2110.00418v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00418">
<div class="article-summary-box-inner">
<span><p>With the development of technology, the use of social media has become quite
common. Analyzing comments on social media in areas such as media and
advertising plays an important role today. For this reason, new and traditional
natural language processing methods are used to detect the emotion of these
shares. In this paper, the Latent Dirichlet Allocation, namely LDA, and
Non-Negative Matrix Factorization methods in topic modeling were used to
determine which emotion the Turkish tweets posted via Twitter. In addition, the
accuracy of a proposed n-level method based on LDA was analyzed. Dataset
consists of 5 emotions, namely angry, fear, happy, sad and confused. NMF was
the most successful method among all topic modeling methods in this study.
Then, the F1-measure of Random Forest, Naive Bayes and Support Vector Machine
methods was analyzed by obtaining a file suitable for Weka by using the word
weights and class labels of the topics. Among the Weka results, the most
successful method was n-stage LDA, and the most successful algorithm was Random
Forest.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Web Scale Entity Extraction System. (arXiv:2110.00423v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00423">
<div class="article-summary-box-inner">
<span><p>Understanding the semantic meaning of content on the web through the lens of
entities and concepts has many practical advantages. However, when building
large-scale entity extraction systems, practitioners are facing unique
challenges involving finding the best ways to leverage the scale and variety of
data available on internet platforms. We present learnings from our efforts in
building an entity extraction system for multiple document types at large scale
using multi-modal Transformers. We empirically demonstrate the effectiveness of
multi-lingual, multi-task and cross-document type learning. We also discuss the
label collection schemes that help to minimize the amount of noise in the
collected data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rumor Detection on Social Media with Hierarchical Adversarial Training. (arXiv:2110.00425v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00425">
<div class="article-summary-box-inner">
<span><p>The proliferation of rumors on social media has a huge impact on society.
However, natural language text is high-dimensional and sparse, and the same
rumor may be expressed in hundreds of ways on social media. As such, the
robustness and generalization of the current rumor detection model are put into
question. We propose a new hierarchical model called HAT-RD, which is divided
into two categories: post-level modules and event-level modules. HAT-RD adopts
a novel hierarchical adversarial training method based on gradient ascent by
adding adversarial perturbations to the embedding layers both of post-level
modules and event-level modules to deceive the detector. At the same time, the
detector uses stochastic gradient descent to minimize the adversarial risk to
learn a more robust model. In this way, the post-level and event-level sample
spaces are enhanced, and experiments indicate that the model drift into an area
with a flat loss landscape that leads to better generalization. Experiments on
two real-world datasets demonstrate that our model achieves better results than
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-shot Natural Language Video Localization. (arXiv:2110.00428v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00428">
<div class="article-summary-box-inner">
<span><p>Understanding videos to localize moments with natural language often requires
large expensive annotated video regions paired with language queries. To
eliminate the annotation costs, we make a first attempt to train a natural
language video localization model in zero-shot manner. Inspired by unsupervised
image captioning setup, we merely require random text corpora, unlabeled video
collections, and an off-the-shelf object detector to train a model. With the
unpaired data, we propose to generate pseudo-supervision of candidate temporal
regions and corresponding query sentences, and develop a simple NLVL model to
train with the pseudo-supervision. Our empirical validations show that the
proposed pseudo-supervised method outperforms several baseline approaches and a
number of methods using stronger supervision on Charades-STA and
ActivityNet-Captions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">External knowledge transfer deployment inside a simple double agent Viterbi algorithm. (arXiv:2110.00433v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00433">
<div class="article-summary-box-inner">
<span><p>We consider in this paper deploying external knowledge transfer inside a
simple double agent Viterbi algorithm which is an algorithm firstly introduced
by the author in his preprint "Hidden Markov Based Mathematical Model dedicated
to Extract Ingredients from Recipe Text". The key challenge of this work lies
in discovering the reason why our old model does have bad performances when it
is confronted with estimating ingredient state for unknown words and see if
deploying external knowledge transfer directly on calculating state matrix
could be the solution instead of deploying it only on back propagating step.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention based Sequence to Sequence Learning for Machine Translation of Low Resourced Indic Languages -- A case of Sanskrit to Hindi. (arXiv:2110.00435v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00435">
<div class="article-summary-box-inner">
<span><p>Deep Learning techniques are powerful in mimicking humans in a particular set
of problems. They have achieved a remarkable performance in complex learning
tasks. Deep learning inspired Neural Machine Translation (NMT) is a proficient
technique that outperforms traditional machine translation. Performing
machine-aided translation on Indic languages has always been a challenging task
considering their rich and diverse grammar. The neural machine translation has
shown quality results compared to the traditional machine translation
approaches. The fully automatic machine translation becomes problematic when it
comes to low-resourced languages, especially with Sanskrit. This paper presents
attention mechanism based neural machine translation by selectively focusing on
a particular part of language sentences during translation. The work shows the
construction of Sanskrit to Hindi bilingual parallel corpus with nearly 10K
samples and having 178,000 tokens. The neural translation model equipped with
an attention mechanism has been trained on Sanskrit to Hindi parallel corpus.
The approach has shown the significance of attention mechanisms to overcome
long-term dependencies, primarily associated with low resources Indic
languages. The paper shows the attention plots on testing data to demonstrate
the alignment between source and translated words. For the evaluation of the
translated sentences, manual score based human evaluation and automatic
evaluation metric based techniques have been adopted. The attention mechanism
based neural translation has achieved 88% accuracy in human evaluation and a
BLEU score of 0.92 on Sanskrit to Hindi translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phonology Recognition in American Sign Language. (arXiv:2110.00453v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00453">
<div class="article-summary-box-inner">
<span><p>Inspired by recent developments in natural language processing, we propose a
novel approach to sign language processing based on phonological properties
validated by American Sign Language users. By taking advantage of datasets
composed of phonological data and people speaking sign language, we use a
pretrained deep model based on mesh reconstruction to extract the 3D
coordinates of the signers keypoints. Then, we train standard statistical and
deep machine learning models in order to assign phonological classes to each
temporal sequence of coordinates.
</p>
<p>Our paper introduces the idea of exploiting the phonological properties
manually assigned by sign language users to classify videos of people
performing signs by regressing a 3D mesh. We establish a new baseline for this
problem based on the statistical distribution of 725 different signs. Our
best-performing models achieve a micro-averaged F1-score of 58% for the major
location class and 70% for the sign type using statistical and deep learning
algorithms, compared to their corresponding baselines of 35% and 39%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Ask for Data-Efficient Event Argument Extraction. (arXiv:2110.00479v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00479">
<div class="article-summary-box-inner">
<span><p>Event argument extraction (EAE) is an important task for information
extraction to discover specific argument roles. In this study, we cast EAE as a
question-based cloze task and empirically analyze fixed discrete token template
performance. As generating human-annotated question templates is often
time-consuming and labor-intensive, we further propose a novel approach called
"Learning to Ask," which can learn optimized question templates for EAE without
human annotations. Experiments using the ACE-2005 dataset demonstrate that our
method based on optimized questions achieves state-of-the-art performance in
both the few-shot and supervised settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEMON: Explainable Entity Matching. (arXiv:2110.00516v1 [cs.DB])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00516">
<div class="article-summary-box-inner">
<span><p>State-of-the-art entity matching (EM) methods are hard to interpret, and
there is significant value in bringing explainable AI to EM. Unfortunately,
most popular explainability methods do not work well out of the box for EM and
need adaptation. In this paper, we identify three challenges of applying local
post hoc feature attribution methods to entity matching: cross-record
interaction effects, non-match explanations, and variation in sensitivity. We
propose our novel model-agnostic and schema-flexible method LEMON that
addresses all three challenges by (i) producing dual explanations to avoid
cross-record interaction effects, (ii) introducing the novel concept of
attribution potential to explain how two records could have matched, and (iii)
automatically choosing explanation granularity to match the sensitivity of the
matcher and record pair in question. Experiments on public datasets demonstrate
that the proposed method is more faithful to the matcher and does a better job
of helping users understand the decision boundary of the matcher than previous
work. Furthermore, user studies show that the rate at which human subjects can
construct counterfactual examples after seeing an explanation from our proposed
method increases from 54% to 64% for matches and from 15% to 49% for
non-matches compared to explanations from a standard adaptation of LIME.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrating Concepts and Operations: Towards Symbolic Reasoning on Real Images. (arXiv:2110.00519v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00519">
<div class="article-summary-box-inner">
<span><p>While neural symbolic methods demonstrate impressive performance in visual
question answering on synthetic images, their performance suffers on real
images. We identify that the long-tail distribution of visual concepts and
unequal importance of reasoning steps in real data are the two key obstacles
that limit the models' real-world potentials. To address these challenges, we
propose a new paradigm, Calibrating Concepts and Operations (CCO), which
enables neural symbolic models to capture underlying data characteristics and
to reason with hierarchical importance. Specifically, we introduce an executor
with learnable concept embedding magnitudes for handling distribution
imbalance, and an operation calibrator for highlighting important operations
and suppressing redundant ones. Our experiments show CCO substantially boosts
the performance of neural symbolic methods on real images. By evaluating models
on the real world dataset GQA, CCO helps the neural symbolic method NSCL
outperforms its vanilla counterpart by 9.1% (from 47.0% to 56.1%); this result
also largely reduces the performance gap between symbolic and non-symbolic
methods. Additionally, we create a perturbed test set for better understanding
and analyzing model performance on real images. Code is available at
https://github.com/Lizw14/CaliCO.git .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unpacking the Interdependent Systems of Discrimination: Ableist Bias in NLP Systems through an Intersectional Lens. (arXiv:2110.00521v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00521">
<div class="article-summary-box-inner">
<span><p>Much of the world's population experiences some form of disability during
their lifetime. Caution must be exercised while designing natural language
processing (NLP) systems to prevent systems from inadvertently perpetuating
ableist bias against people with disabilities, i.e., prejudice that favors
those with typical abilities. We report on various analyses based on word
predictions of a large-scale BERT language model. Statistically significant
results demonstrate that people with disabilities can be disadvantaged.
Findings also explore overlapping forms of discrimination related to
interconnected gender and race identities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TEACh: Task-driven Embodied Agents that Chat. (arXiv:2110.00534v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00534">
<div class="article-summary-box-inner">
<span><p>Robots operating in human spaces must be able to engage in natural language
interaction with people, both understanding and executing instructions, and
using conversation to resolve ambiguity and recover from mistakes. To study
this, we introduce TEACh, a dataset of over 3,000 human--human, interactive
dialogues to complete household tasks in simulation. A Commander with access to
oracle information about a task communicates in natural language with a
Follower. The Follower navigates through and interacts with the environment to
complete tasks varying in complexity from "Make Coffee" to "Prepare Breakfast",
asking questions and getting additional information from the Commander. We
propose three benchmarks using TEACh to study embodied intelligence challenges,
and we evaluate initial models' abilities in dialogue understanding, language
grounding, and task execution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural language understanding for logical games. (arXiv:2110.00558v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00558">
<div class="article-summary-box-inner">
<span><p>We developed a system able to automatically solve logical puzzles in natural
language. Our solution is composed by a parser and an inference module. The
parser translates the text into first order logic (FOL), while the MACE4 model
finder is used to compute the models of the given FOL theory. We also empower
our software agent with the capability to provide Yes/No answers to natural
language questions related to each puzzle. Moreover, in line with Explainalbe
Artificial Intelligence (XAI), the agent can back its answer, providing a
graphical representation of the proof. The advantage of using reasoning for
Natural Language Understanding (NLU) instead of Machine learning is that the
user can obtain an explanation of the reasoning chain. We illustrate how the
system performs on various types of natural language puzzles, including 382
knights and knaves puzzles. These features together with the overall
performance rate of 80.89\% makes the proposed solution an improvement upon
similar solvers for natural language understanding in the puzzles domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Punctuation Restoration for Speech Transcripts via External Data. (arXiv:2110.00560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00560">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Recognition (ASR) systems generally do not produce
punctuated transcripts. To make transcripts more readable and follow the
expected input format for downstream language models, it is necessary to add
punctuation marks. In this paper, we tackle the punctuation restoration problem
specifically for the noisy text (e.g., phone conversation scenarios). To
leverage the available written text datasets, we introduce a data sampling
technique based on an n-gram language model to sample more training data that
are similar to our in-domain data. Moreover, we propose a two-stage fine-tuning
approach that utilizes the sampled external data as well as our in-domain
dataset for models based on BERT. Extensive experiments show that the proposed
approach outperforms the baseline with an improvement of 1:12% F1 score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Paraphrases as Foreign Languages in Multilingual Neural Machine Translation. (arXiv:1808.08438v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1808.08438">
<div class="article-summary-box-inner">
<span><p>Paraphrases, the rewordings of the same semantic meaning, are useful for
improving generalization and translation. However, prior works only explore
paraphrases at the word or phrase level, not at the sentence or corpus level.
Unlike previous works that only explore paraphrases at the word or phrase
level, we use different translations of the whole training data that are
consistent in structure as paraphrases at the corpus level. We train on
parallel paraphrases in multiple languages from various sources. We treat
paraphrases as foreign languages, tag source sentences with paraphrase labels,
and train on parallel paraphrases in the style of multilingual Neural Machine
Translation (NMT). Our multi-paraphrase NMT that trains only on two languages
outperforms the multilingual baselines. Adding paraphrases improves the rare
word translation and increases entropy and diversity in lexical choice. Adding
the source paraphrases boosts performance better than adding the target ones.
Combining both the source and the target paraphrases lifts performance further;
combining paraphrases with multilingual data helps but has mixed performance.
We achieve a BLEU score of 57.2 for French-to-English translation using 24
corpus-level paraphrases of the Bible, which outperforms the multilingual
baselines and is +34.7 above the single-source single-target NMT baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergence of Pragmatics from Referential Game between Theory of Mind Agents. (arXiv:2001.07752v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.07752">
<div class="article-summary-box-inner">
<span><p>Pragmatics studies how context can contribute to language meanings. In human
communication, language is never interpreted out of context, and sentences can
usually convey more information than their literal meanings. However, this
mechanism is missing in most multi-agent systems, restricting the communication
efficiency and the capability of human-agent interaction. In this paper, we
propose an algorithm, using which agents can spontaneously learn the ability to
"read between lines" without any explicit hand-designed rules. We integrate the
theory of mind (ToM) in a cooperative multi-agent pedagogical situation and
propose an adaptive reinforcement learning (RL) algorithm to develop a
communication protocol. ToM is a profound cognitive science concept, claiming
that people regularly reason about other's mental states, including beliefs,
goals, and intentions, to obtain performance advantage in competition,
cooperation or coalition. With this ability, agents consider language as not
only messages but also rational acts reflecting others' hidden states. Our
experiments demonstrate the advantage of pragmatic protocols over non-pragmatic
protocols. We also show the teaching complexity following the pragmatic
protocol empirically approximates to recursive teaching dimension (RTD).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Self-Training for Sentiment Analysis of Code-Switched Data. (arXiv:2103.14797v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14797">
<div class="article-summary-box-inner">
<span><p>Sentiment analysis is an important task in understanding social media content
like customer reviews, Twitter and Facebook feeds etc. In multilingual
communities around the world, a large amount of social media text is
characterized by the presence of Code-Switching. Thus, it has become important
to build models that can handle code-switched data. However, annotated
code-switched data is scarce and there is a need for unsupervised models and
algorithms. We propose a general framework called Unsupervised Self-Training
and show its applications for the specific use case of sentiment analysis of
code-switched data. We use the power of pre-trained BERT models for
initialization and fine-tune them in an unsupervised manner, only using pseudo
labels produced by zero-shot transfer. We test our algorithm on multiple
code-switched languages and provide a detailed analysis of the learning
dynamics of the algorithm with the aim of answering the question - `Does our
unsupervised model understand the Code-Switched languages or does it just learn
its representations?'. Our unsupervised models compete well with their
supervised counterparts, with their performance reaching within 1-7\% (weighted
F1 scores) when compared to supervised models trained for a two class problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Timers and Such: A Practical Benchmark for Spoken Language Understanding with Numbers. (arXiv:2104.01604v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01604">
<div class="article-summary-box-inner">
<span><p>This paper introduces Timers and Such, a new open source dataset of spoken
English commands for common voice control use cases involving numbers. We
describe the gap in existing spoken language understanding datasets that Timers
and Such fills, the design and creation of the dataset, and experiments with a
number of ASR-based and end-to-end baseline models, the code for which has been
made available as part of the SpeechBrain toolkit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FRAKE: Fusional Real-time Automatic Keyword Extraction. (arXiv:2104.04830v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04830">
<div class="article-summary-box-inner">
<span><p>Keyword extraction is the process of identifying the words or phrases that
express the main concepts of text to the best of one's ability. Electronic
infrastructure creates a considerable amount of text every day and at all
times. This massive volume of documents makes it practically impossible for
human resources to study and manage them. Nevertheless, the need for these
documents to be accessed efficiently and effectively is evident in numerous
purposes. A blog, news article, or technical note is considered a relatively
long text since the reader aims to learn the subject based on keywords or
topics. Our approach consists of a combination of two models: graph centrality
features and textural features. The proposed method has been used to extract
the best keyword among the candidate keywords with an optimal combination of
graph centralities, such as degree, betweenness, eigenvector, closeness
centrality and etc, and textural, such as Casing, Term position, Term frequency
normalization, Term different sentence, Part Of Speech tagging. There have also
been attempts to distinguish keywords from candidate phrases and consider them
on separate keywords. For evaluating the proposed method, seven datasets were
used: Semeval2010, SemEval2017, Inspec, fao30, Thesis100, pak2018, and
Wikinews, with results reported as Precision, Recall, and F- measure. Our
proposed method performed much better in terms of evaluation metrics in all
reviewed datasets compared with available methods in literature. An approximate
16.9% increase was witnessed in F-score metric and this was much more for the
Inspec in English datasets and WikiNews in forgone languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Family of Origin and Family of Choice: Massively Parallel Lexiconized Iterative Pretraining for Severely Low Resource Machine Translation. (arXiv:2104.05848v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05848">
<div class="article-summary-box-inner">
<span><p>We translate a closed text that is known in advance into a severely low
resource language by leveraging massive source parallelism. In other words,
given a text in 124 source languages, we translate it into a severely low
resource language using only ~1,000 lines of low resource data without any
external help. Firstly, we propose a systematic method to rank and choose
source languages that are close to the low resource language. We call the
linguistic definition of language family Family of Origin (FAMO), and we call
the empirical definition of higher-ranked languages using our metrics Family of
Choice (FAMC). Secondly, we build an Iteratively Pretrained Multilingual
Order-preserving Lexiconized Transformer (IPML) to train on ~1,000 lines
(~3.5%) of low resource data. To translate named entities correctly, we build a
massive lexicon table for 2,939 Bible named entities in 124 source languages,
and include many that occur once and covers more than 66 severely low resource
languages. Moreover, we also build a novel method of combining translations
from different source languages into one. Using English as a hypothetical low
resource language, we get a +23.9 BLEU increase over a multilingual baseline,
and a +10.3 BLEU increase over our asymmetric baseline in the Bible dataset. We
get a 42.8 BLEU score for Portuguese-English translation on the medical EMEA
dataset. We also have good results for a real severely low resource Mayan
language, Eastern Pokomchi.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Moving on from OntoNotes: Coreference Resolution Model Transfer. (arXiv:2104.08457v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08457">
<div class="article-summary-box-inner">
<span><p>Academic neural models for coreference resolution (coref) are typically
trained on a single dataset, OntoNotes, and model improvements are benchmarked
on that same dataset. However, real-world applications of coref depend on the
annotation guidelines and the domain of the target dataset, which often differ
from those of OntoNotes. We aim to quantify transferability of coref models
based on the number of annotated documents available in the target dataset. We
examine eleven target datasets and find that continued training is consistently
effective and especially beneficial when there are few target documents. We
establish new benchmarks across several datasets, including state-of-the-art
results on PreCo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP. (arXiv:2104.08835v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08835">
<div class="article-summary-box-inner">
<span><p>Humans can learn a new language task efficiently with only few examples, by
leveraging their knowledge obtained when learning prior tasks. In this paper,
we explore whether and how such cross-task generalization ability can be
acquired, and further applied to build better few-shot learners across diverse
NLP tasks. We introduce CrossFit, a problem setup for studying cross-task
generalization ability, which standardizes seen/unseen task partitions, data
access during different learning stages, and the evaluation protocols. To
instantiate different seen/unseen task partitions in CrossFit and facilitate
in-depth analysis, we present the NLP Few-shot Gym, a repository of 160 diverse
few-shot NLP tasks created from open-access NLP datasets and converted to a
unified text-to-text format. Our analysis reveals that the few-shot learning
ability on unseen tasks can be improved via an upstream learning stage using a
set of seen tasks. We also observe that the selection of upstream learning
tasks can significantly influence few-shot performance on unseen tasks, asking
further analysis on task similarity and transferability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Influence of Masking Policies in Intermediate Pre-training. (arXiv:2104.08840v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08840">
<div class="article-summary-box-inner">
<span><p>Current NLP models are predominantly trained through a two-stage "pre-train
then fine-tune" pipeline. Prior work has shown that inserting an intermediate
pre-training stage, using heuristic masking policies for masked language
modeling (MLM), can significantly improve final performance. However, it is
still unclear (1) in what cases such intermediate pre-training is helpful, (2)
whether hand-crafted heuristic objectives are optimal for a given task, and (3)
whether a masking policy designed for one task is generalizable beyond that
task. In this paper, we perform a large-scale empirical study to investigate
the effect of various masking policies in intermediate pre-training with nine
selected tasks across three categories. Crucially, we introduce methods to
automate the discovery of optimal masking policies via direct supervision or
meta-learning. We conclude that the success of intermediate pre-training is
dependent on appropriate pre-train corpus, selection of output format (i.e.,
masked spans or full sentence), and clear understanding of the role that MLM
plays for the downstream task. In addition, we find our learned masking
policies outperform the heuristic of masking named entities on TriviaQA, and
policies learned from one task can positively transfer to other tasks in
certain cases, inviting future research in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-based Clinical Note Summarization. (arXiv:2104.08942v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08942">
<div class="article-summary-box-inner">
<span><p>The trend of deploying digital systems in numerous industries has induced a
hike in recording digital information. The health sector has observed an
extensive adoption of digital devices and systems that generate large volumes
of personal medical records. Electronic health records contain valuable
information for retrospective and prospective analysis that is often not
entirely exploited because of the dense information storage. The crude purpose
of condensing health records is to select the information that holds most
characteristics of the original documents based on reported disease. These
summaries may boost diagnosis and extend a doctor's time with the patient
during a high workload situation like the COVID-19 pandemic. In this paper, we
propose applying a multi-head attention-based mechanism to perform extractive
summarization of meaningful phrases in clinical notes. This method finds major
sentences for a summary by correlating tokens, segments, and positional
embeddings. The model outputs attention scores that are statistically
transformed to extract key phrases and can be used to projection on the
heat-mapping tool for visual and human use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition. (arXiv:2105.03842v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03842">
<div class="article-summary-box-inner">
<span><p>Error correction techniques have been used to refine the output sentences
from automatic speech recognition (ASR) models and achieve a lower word error
rate (WER) than original ASR outputs. Previous works usually use a
sequence-to-sequence model to correct an ASR output sentence autoregressively,
which causes large latency and cannot be deployed in online ASR services. A
straightforward solution to reduce latency, inspired by non-autoregressive
(NAR) neural machine translation, is to use an NAR sequence generation model
for ASR error correction, which, however, comes at the cost of significantly
increased ASR error rate. In this paper, observing distinctive error patterns
and correction operations (i.e., insertion, deletion, and substitution) in ASR,
we propose FastCorrect, a novel NAR error correction model based on edit
alignment. In training, FastCorrect aligns each source token from an ASR output
sentence to the target tokens from the corresponding ground-truth sentence
based on the edit distance between the source and target sentences, and
extracts the number of target tokens corresponding to each source token during
edition/correction, which is then used to train a length predictor and to
adjust the source tokens to match the length of the target sentence for
parallel generation. In inference, the token number predicted by the length
predictor is used to adjust the source tokens for target sequence generation.
Experiments on the public AISHELL-1 dataset and an internal industrial-scale
ASR dataset show the effectiveness of FastCorrect for ASR error correction: 1)
it speeds up the inference by 6-9 times and maintains the accuracy (8-14% WER
reduction) compared with the autoregressive correction model; and 2) it
outperforms the popular NAR models adopted in neural machine translation and
text edition by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding. (arXiv:2105.09996v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09996">
<div class="article-summary-box-inner">
<span><p>We present a simplified, task-agnostic multi-modal pre-training approach that
can accept either video or text input, or both for a variety of end tasks.
Existing pre-training are task-specific by adopting either a single cross-modal
encoder that requires both modalities, limiting their use for retrieval-style
end tasks or more complex multitask learning with two unimodal encoders,
limiting early cross-modal fusion. We instead introduce new pretraining masking
schemes that better mix across modalities (e.g. by forcing masks for text to
predict the closest video embeddings) while also maintaining separability (e.g.
unimodal predictions are sometimes required, without using all the input).
Experimental results show strong performance across a wider range of tasks than
any previous methods, often outperforming task-specific pre-training. Code is
made available at https://github.com/pytorch/fairseq/tree/main/examples/MMPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Annotation Inconsistency and Entity Bias in MultiWOZ. (arXiv:2105.14150v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14150">
<div class="article-summary-box-inner">
<span><p>MultiWOZ is one of the most popular multi-domain task-oriented dialog
datasets, containing 10K+ annotated dialogs covering eight domains. It has been
widely accepted as a benchmark for various dialog tasks, e.g., dialog state
tracking (DST), natural language generation (NLG), and end-to-end (E2E) dialog
modeling. In this work, we identify an overlooked issue with dialog state
annotation inconsistencies in the dataset, where a slot type is tagged
inconsistently across similar dialogs leading to confusion for DST modeling. We
propose an automated correction for this issue, which is present in a whopping
70% of the dialogs. Additionally, we notice that there is significant entity
bias in the dataset (e.g., "cambridge" appears in 50% of the destination cities
in the train domain). The entity bias can potentially lead to named entity
memorization in generative models, which may go unnoticed as the test set
suffers from a similar entity bias as well. We release a new test set with all
entities replaced with unseen entities. Finally, we benchmark joint goal
accuracy (JGA) of the state-of-the-art DST baselines on these modified versions
of the data. Our experiments show that the annotation inconsistency corrections
lead to 7-10% improvement in JGA. On the other hand, we observe a 29% drop in
JGA when models are evaluated on the new test set with unseen entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-utterance Reranking Models with BERT and Graph Convolutional Networks for Conversational Speech Recognition. (arXiv:2106.06922v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06922">
<div class="article-summary-box-inner">
<span><p>How to effectively incorporate cross-utterance information cues into a neural
language model (LM) has emerged as one of the intriguing issues for automatic
speech recognition (ASR). Existing research efforts on improving
contextualization of an LM typically regard previous utterances as a sequence
of additional input and may fail to capture complex global structural
dependencies among these utterances. In view of this, we in this paper seek to
represent the historical context information of an utterance as
graph-structured data so as to distill cross-utterances, global word
interaction relationships. To this end, we apply a graph convolutional network
(GCN) on the resulting graph to obtain the corresponding GCN embeddings of
historical words. GCN has recently found its versatile applications on
social-network analysis, text summarization, and among others due mainly to its
ability of effectively capturing rich relational information among elements.
However, GCN remains largely underexplored in the context of ASR, especially
for dealing with conversational speech. In addition, we frame ASR N-best
reranking as a prediction problem, leveraging bidirectional encoder
representations from transformers (BERT) as the vehicle to not only seize the
local intrinsic word regularity patterns inherent in a candidate hypothesis but
also incorporate the cross-utterance, historical word interaction cues
distilled by GCN for promoting performance. Extensive experiments conducted on
the AMI benchmark dataset seem to confirm the pragmatic utility of our methods,
in relation to some current top-of-the-line methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Translation of Low-Resource Indo-European Languages. (arXiv:2108.03739v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03739">
<div class="article-summary-box-inner">
<span><p>In this work, we investigate methods for the challenging task of translating
between low-resource language pairs that exhibit some level of similarity. In
particular, we consider the utility of transfer learning for translating
between several Indo-European low-resource languages from the Germanic and
Romance language families. In particular, we build two main classes of
transfer-based systems to study how relatedness can benefit the translation
performance. The primary system fine-tunes a model pre-trained on a related
language pair and the contrastive system fine-tunes one pre-trained on an
unrelated language pair. Our experiments show that although relatedness is not
necessary for transfer learning to work, it does benefit model performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition. (arXiv:2108.07789v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07789">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) pre-trained on massive amounts of text, in particular
bidirectional encoder representations from Transformers (BERT), generative
pre-training (GPT), and GPT-2, have become a key technology for many natural
language processing tasks. In this paper, we present results using fine-tuned
GPT, GPT-2, and their combination for automatic speech recognition (ASR).
Unlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct
product of the output probabilities is no longer a valid language prior
probability. A conversion method is proposed to compute the correct language
prior probability based on bidirectional LM outputs in a mathematically exact
way. Experimental results on the widely used AMI and Switchboard ASR tasks
showed that the combination of the fine-tuned GPT and GPT-2 outperformed the
combination of three neural LMs with different architectures trained from
scratch on the in-domain text by up to a 12% relative word error rate reduction
(WERR). Furthermore, on the AMI corpus, the proposed conversion for language
prior probabilities enables BERT to obtain an extra 3% relative WERR, and the
combination of BERT, GPT and GPT-2 results in further improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Guided Generative Pre-trained Language Models for Multimodal Abstractive Summarization. (arXiv:2109.02401v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02401">
<div class="article-summary-box-inner">
<span><p>Multimodal abstractive summarization (MAS) models that summarize videos
(vision modality) and their corresponding transcripts (text modality) are able
to extract the essential information from massive multimodal data on the
Internet. Recently, large-scale generative pre-trained language models (GPLMs)
have been shown to be effective in text generation tasks. However, existing MAS
models cannot leverage GPLMs' powerful generation ability. To fill this
research gap, we aim to study two research questions: 1) how to inject visual
information into GPLMs without hurting their generation ability; and 2) where
is the optimal place in GPLMs to inject the visual information? In this paper,
we present a simple yet effective method to construct vision guided (VG) GPLMs
for the MAS task using attention-based add-on layers to incorporate visual
information while maintaining their original text generation ability. Results
show that our best model significantly surpasses the prior state-of-the-art
model by 5.7 ROUGE-1, 5.3 ROUGE-2, and 5.1 ROUGE-L scores on the How2 dataset,
and our visual guidance method contributes 83.6% of the overall improvement.
Furthermore, we conduct thorough ablation studies to analyze the effectiveness
of various modality fusion methods and fusion locations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast-Slow Transformer for Visually Grounding Speech. (arXiv:2109.08186v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08186">
<div class="article-summary-box-inner">
<span><p>We present Fast-Slow Transformer for Visually Grounding Speech, or FaST-VGS.
FaST-VGS is a Transformer-based model for learning the associations between raw
speech waveforms and visual images. The model unifies dual-encoder and
cross-attention architectures into a single model, reaping the superior
retrieval speed of the former along with the accuracy of the latter. FaST-VGS
achieves state-of-the-art speech-image retrieval accuracy on benchmark
datasets, and its learned representations exhibit strong performance on the
ZeroSpeech 2021 phonetic and semantic tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Invariant Properties in Natural Language Processing. (arXiv:2109.13037v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13037">
<div class="article-summary-box-inner">
<span><p>Meaning is context-dependent, but many properties of language (should) remain
the same even if we transform the context. For example, sentiment, entailment,
or speaker properties should be the same in a translation and original of a
text. We introduce language invariant properties: i.e., properties that should
not change when we transform text, and how they can be used to quantitatively
evaluate the robustness of transformation algorithms. We use translation and
paraphrasing as transformation examples, but our findings apply more broadly to
any transformation. Our results indicate that many NLP transformations change
properties like author characteristics, i.e., make them sound more male. We
believe that studying these properties will allow NLP to address both social
factors and pragmatic aspects of language. We also release an application suite
that can be used to evaluate the invariance of transformation applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition. (arXiv:2109.13226v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13226">
<div class="article-summary-box-inner">
<span><p>We summarize the results of a host of efforts using giant automatic speech
recognition (ASR) models pre-trained using large, diverse unlabeled datasets
containing approximately a million hours of audio. We find that the combination
of pre-training, self-training and scaling up model size greatly increases data
efficiency, even for extremely large tasks with tens of thousands of hours of
labeled data. In particular, on an ASR task with 34k hours of labeled data, by
fine-tuning an 8 billion parameter pre-trained Conformer model we can match
state-of-the-art (SoTA) performance with only 3% of the training data and
significantly improve SoTA with the full training set. We also report on the
universal benefits gained from using big pre-trained and self-trained models
for a large set of downstream tasks that cover a wide range of speech domains
and span multiple orders of magnitudes of dataset sizes, including obtaining
SoTA performance on many public benchmarks. In addition, we utilize the learned
representation of pre-trained networks to achieve SoTA results on non-ASR
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stochastic Transformer Networks with Linear Competing Units: Application to end-to-end SL Translation. (arXiv:2109.13318v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13318">
<div class="article-summary-box-inner">
<span><p>Automating sign language translation (SLT) is a challenging real world
application. Despite its societal importance, though, research progress in the
field remains rather poor. Crucially, existing methods that yield viable
performance necessitate the availability of laborious to obtain gloss sequence
groundtruth. In this paper, we attenuate this need, by introducing an
end-to-end SLT model that does not entail explicit use of glosses; the model
only needs text groundtruth. This is in stark contrast to existing end-to-end
models that use gloss sequence groundtruth, either in the form of a modality
that is recognized at an intermediate model stage, or in the form of a parallel
output process, jointly trained with the SLT model. Our approach constitutes a
Transformer network with a novel type of layers that combines: (i) local
winner-takes-all (LWTA) layers with stochastic winner sampling, instead of
conventional ReLU layers, (ii) stochastic weights with posterior distributions
estimated via variational inference, and (iii) a weight compression technique
at inference time that exploits estimated posterior variance to perform
massive, almost lossless compression. We demonstrate that our approach can
reach the currently best reported BLEU-4 score on the PHOENIX 2014T benchmark,
but without making use of glosses for model training, and with a memory
footprint reduced by more than 70%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding. (arXiv:2109.14084v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14084">
<div class="article-summary-box-inner">
<span><p>We present VideoCLIP, a contrastive approach to pre-train a unified model for
zero-shot video and text understanding, without using any labels on downstream
tasks. VideoCLIP trains a transformer for video and text by contrasting
temporally overlapping positive video-text pairs with hard negatives from
nearest neighbor retrieval. Our experiments on a diverse series of downstream
tasks, including sequence-level text-video retrieval, VideoQA, token-level
action localization, and action segmentation reveal state-of-the-art
performance, surpassing prior work, and in some cases even outperforming
supervised approaches. Code is made available at
https://github.com/pytorch/fairseq/tree/main/examples/MMPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Fact Linking. (arXiv:2109.14364v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14364">
<div class="article-summary-box-inner">
<span><p>Knowledge-intensive NLP tasks can benefit from linking natural language text
with facts from a Knowledge Graph (KG). Although facts themselves are
language-agnostic, the fact labels (i.e., language-specific representation of
the fact) in the KG are often present only in a few languages. This makes it
challenging to link KG facts to sentences in languages other than the limited
set of languages. To address this problem, we introduce the task of
Multilingual Fact Linking (MFL) where the goal is to link fact expressed in a
sentence to corresponding fact in the KG, even when the fact label in the KG is
not available in the language of the sentence. To facilitate research in this
area, we present a new evaluation dataset, IndicLink. This dataset contains
11,293 linked WikiData facts and 6,429 sentences spanning English and six
Indian languages. We propose a Retrieval+Generation model, ReFCoG, that can
scale to millions of KG facts by combining Dual Encoder based retrieval with a
Seq2Seq based generation model which is constrained to output only valid KG
facts. ReFCoG outperforms standard Retrieval+Re-ranking models by 10.7 pts in
Precision@1. In spite of this gain, the model achieves an overall score of
52.1, showing ample scope for improvement in the task.ReFCoG code and IndicLink
data are available at https://github.com/SaiKeshav/mfl
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EDGAR-CORPUS: Billions of Tokens Make The World Go Round. (arXiv:2109.14394v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14394">
<div class="article-summary-box-inner">
<span><p>We release EDGAR-CORPUS, a novel corpus comprising annual reports from all
the publicly traded companies in the US spanning a period of more than 25
years. To the best of our knowledge, EDGAR-CORPUS is the largest financial NLP
corpus available to date. All the reports are downloaded, split into their
corresponding items (sections), and provided in a clean, easy-to-use JSON
format. We use EDGAR-CORPUS to train and release EDGAR-W2V, which are WORD2VEC
embeddings for the financial domain. We employ these embeddings in a battery of
financial NLP tasks and showcase their superiority over generic GloVe
embeddings and other existing financial word embeddings. We also open-source
EDGAR-CRAWLER, a toolkit that facilitates downloading and extracting future
annual reports.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FastCorrect 2: Fast Error Correction on Multiple Candidates for Automatic Speech Recognition. (arXiv:2109.14420v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14420">
<div class="article-summary-box-inner">
<span><p>Error correction is widely used in automatic speech recognition (ASR) to
post-process the generated sentence, and can further reduce the word error rate
(WER). Although multiple candidates are generated by an ASR system through beam
search, current error correction approaches can only correct one sentence at a
time, failing to leverage the voting effect from multiple candidates to better
detect and correct error tokens. In this work, we propose FastCorrect 2, an
error correction model that takes multiple ASR candidates as input for better
correction accuracy. FastCorrect 2 adopts non-autoregressive generation for
fast inference, which consists of an encoder that processes multiple source
sentences and a decoder that generates the target sentence in parallel from the
adjusted source sentence, where the adjustment is based on the predicted
duration of each source token. However, there are some issues when handling
multiple source sentences. First, it is non-trivial to leverage the voting
effect from multiple source sentences since they usually vary in length. Thus,
we propose a novel alignment algorithm to maximize the degree of token
alignment among multiple sentences in terms of token and pronunciation
similarity. Second, the decoder can only take one adjusted source sentence as
input, while there are multiple source sentences. Thus, we develop a candidate
predictor to detect the most suitable candidate for the decoder. Experiments on
our inhouse dataset and AISHELL-1 show that FastCorrect 2 can further reduce
the WER over the previous correction model with single candidate by 3.2% and
2.6%, demonstrating the effectiveness of leveraging multiple candidates in ASR
error correction. FastCorrect 2 achieves better performance than the cascaded
re-scoring and correction pipeline and can serve as a unified post-processing
module for ASR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-19 Fake News Detection Using Bidirectional Encoder Representations from Transformers Based Models. (arXiv:2109.14816v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14816">
<div class="article-summary-box-inner">
<span><p>Nowadays, the development of social media allows people to access the latest
news easily. During the COVID-19 pandemic, it is important for people to access
the news so that they can take corresponding protective measures. However, the
fake news is flooding and is a serious issue especially under the global
pandemic. The misleading fake news can cause significant loss in terms of the
individuals and the society. COVID-19 fake news detection has become a novel
and important task in the NLP field. However, fake news always contain the
correct portion and the incorrect portion. This fact increases the difficulty
of the classification task. In this paper, we fine tune the pre-trained
Bidirectional Encoder Representations from Transformers (BERT) model as our
base model. We add BiLSTM layers and CNN layers on the top of the finetuned
BERT model with frozen parameters or not frozen parameters methods
respectively. The model performance evaluation results showcase that our best
model (BERT finetuned model with frozen parameters plus BiLSTM layers) achieves
state-of-the-art results towards COVID-19 fake news detection task. We also
explore keywords evaluation methods using our best model and evaluate the model
performance after removing keywords.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prose2Poem: The Blessing of Transformers in Translating Prose to Persian Poetry. (arXiv:2109.14934v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14934">
<div class="article-summary-box-inner">
<span><p>Persian Poetry has consistently expressed its philosophy, wisdom, speech, and
rationale on the basis of its couplets, making it an enigmatic language on its
own to both native and non-native speakers. Nevertheless, the notice able gap
between Persian prose and poem has left the two pieces of literature
medium-less. Having curated a parallel corpus of prose and their equivalent
poems, we introduce a novel Neural Machine Translation (NMT) approach to
translate prose to ancient Persian poetry using transformer-based Language
Models in an extremely low-resource setting. More specifically, we trained a
Transformer model from scratch to obtain initial translations and pretrained
different variations of BERT to obtain final translations. To address the
challenge of using masked language modelling under poeticness criteria, we
heuristically joined the two models and generated valid poems in terms of
automatic and human assessments. Final results demonstrate the eligibility and
creativity of our novel heuristically aided approach among Literature
professionals and non-professionals in generating novel Persian poems.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Mining for strong gravitational lenses with self-supervised learning. (arXiv:2110.00023v1 [astro-ph.IM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00023">
<div class="article-summary-box-inner">
<span><p>We employ self-supervised representation learning to distill information from
76 million galaxy images from the Dark Energy Spectroscopic Instrument (DESI)
Legacy Imaging Surveys' Data Release 9. Targeting the identification of new
strong gravitational lens candidates, we first create a rapid similarity search
tool to discover new strong lenses given only a single labelled example. We
then show how training a simple linear classifier on the self-supervised
representations, requiring only a few minutes on a CPU, can automatically
classify strong lenses with great efficiency. We present 1192 new strong lens
candidates that we identified through a brief visual identification campaign,
and release an interactive web-based similarity search tool and the top network
predictions to facilitate crowd-sourcing rapid discovery of additional strong
gravitational lenses and other rare objects:
github.com/georgestein/ssl-legacysurvey
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Multi-Site Harmonization of Magnetic Resonance Images Without Traveling Human Phantoms. (arXiv:2110.00041v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00041">
<div class="article-summary-box-inner">
<span><p>Harmonization improves data consistency and is central to effective
integration of diverse imaging data acquired across multiple sites. Recent deep
learning techniques for harmonization are predominantly supervised in nature
and hence require imaging data of the same human subjects to be acquired at
multiple sites. Data collection as such requires the human subjects to travel
across sites and is hence challenging, costly, and impractical, more so when
sufficient sample size is needed for reliable network training. Here we show
how harmonization can be achieved with a deep neural network that does not rely
on traveling human phantom data. Our method disentangles site-specific
appearance information and site-invariant anatomical information from images
acquired at multiple sites and then employs the disentangled information to
generate the image of each subject for any target site. We demonstrate with
more than 6,000 multi-site T1- and T2-weighted images that our method is
remarkably effective in generating images with realistic site-specific
appearances without altering anatomical details. Our method allows
retrospective harmonization of data in a wide range of existing modern
large-scale imaging studies, conducted via different scanners and protocols,
without additional data collection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Quadratic Optimisation over the Stiefel Manifold with Application to Permutation Synchronisation. (arXiv:2110.00053v1 [math.OC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00053">
<div class="article-summary-box-inner">
<span><p>We address the non-convex optimisation problem of finding a sparse matrix on
the Stiefel manifold (matrices with mutually orthogonal columns of unit length)
that maximises (or minimises) a quadratic objective function. Optimisation
problems on the Stiefel manifold occur for example in spectral relaxations of
various combinatorial problems, such as graph matching, clustering, or
permutation synchronisation. Although sparsity is a desirable property in such
settings, it is mostly neglected in spectral formulations since existing
solvers, e.g. based on eigenvalue decomposition, are unable to account for
sparsity while at the same time maintaining global optimality guarantees. We
fill this gap and propose a simple yet effective sparsity-promoting
modification of the Orthogonal Iteration algorithm for finding the dominant
eigenspace of a matrix. By doing so, we can guarantee that our method finds a
Stiefel matrix that is globally optimal with respect to the quadratic objective
function, while in addition being sparse. As a motivating application we
consider the task of permutation synchronisation, which can be understood as a
constrained clustering problem that has particular relevance for matching
multiple images or 3D shapes in computer vision, computer graphics, and beyond.
We demonstrate that the proposed approach outperforms previous methods in this
domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Predict Trustworthiness with Steep Slope Loss. (arXiv:2110.00054v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00054">
<div class="article-summary-box-inner">
<span><p>Understanding the trustworthiness of a prediction yielded by a classifier is
critical for the safe and effective use of AI models. Prior efforts have been
proven to be reliable on small-scale datasets. In this work, we study the
problem of predicting trustworthiness on real-world large-scale datasets, where
the task is more challenging due to high-dimensional features, diverse visual
concepts, and large-scale samples. In such a setting, we observe that the
trustworthiness predictors trained with prior-art loss functions, i.e., the
cross entropy loss, focal loss, and true class probability confidence loss, are
prone to view both correct predictions and incorrect predictions to be
trustworthy. The reasons are two-fold. Firstly, correct predictions are
generally dominant over incorrect predictions. Secondly, due to the data
complexity, it is challenging to differentiate the incorrect predictions from
the correct ones on real-world large-scale datasets. To improve the
generalizability of trustworthiness predictors, we propose a novel steep slope
loss to separate the features w.r.t. correct predictions from the ones w.r.t.
incorrect predictions by two slide-like curves that oppose each other. The
proposed loss is evaluated with two representative deep learning models, i.e.,
Vision Transformer and ResNet, as trustworthiness predictors. We conduct
comprehensive experiments and analyses on ImageNet, which show that the
proposed loss effectively improves the generalizability of trustworthiness
predictors. The code and pre-trained trustworthiness predictors for
reproducibility are available at
https://github.com/luoyan407/predict_trustworthiness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scientific evidence extraction. (arXiv:2110.00061v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00061">
<div class="article-summary-box-inner">
<span><p>Recently, interest has grown in applying machine learning to the problem of
table structure inference and extraction from unstructured documents. However,
progress in this area has been challenging both to make and to measure, due to
several issues that arise in training and evaluating models from labeled data.
This includes challenges as fundamental as the lack of a single definitive
ground truth output for each input sample and the lack of an ideal metric for
measuring partial correctness for this task. To address these we propose a new
dataset, PubMed Tables One Million (PubTables-1M), and a new class of metric,
grid table similarity (GriTS). PubTables-1M is nearly twice as large as the
previous largest comparable dataset, can be used for models across multiple
architectures and modalities, and addresses issues such as ambiguity and lack
of consistency in the annotations. We apply DETR to table extraction for the
first time and show that object detection models trained on PubTables-1M
produce excellent results out-of-the-box for all three tasks of detection,
structure recognition, and functional analysis. We describe the dataset in
detail to enable others to build on our work and combine this data with other
datasets for these and related tasks. It is our hope that PubTables-1M and the
proposed metrics can further progress in this area by creating a benchmark
suitable for training and evaluating a wide variety of models for table
extraction. Data and code will be released at
https://github.com/microsoft/table-transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Noise2Recon: A Semi-Supervised Framework for Joint MRI Reconstruction and Denoising. (arXiv:2110.00075v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00075">
<div class="article-summary-box-inner">
<span><p>Deep learning (DL) has shown promise for faster, high quality accelerated MRI
reconstruction. However, standard supervised DL methods depend on extensive
amounts of fully-sampled ground-truth data and are sensitive to
out-of-distribution (OOD) shifts, in particular for low signal-to-noise ratio
(SNR) acquisitions. To alleviate this challenge, we propose a semi-supervised,
consistency-based framework (termed Noise2Recon) for joint MR reconstruction
and denoising. Our method enables the usage of a limited number of
fully-sampled and a large number of undersampled-only scans. We compare our
method to augmentation-based supervised techniques and fine-tuned denoisers.
Results demonstrate that even with minimal ground-truth data, Noise2Recon (1)
achieves high performance on in-distribution (low-noise) scans and (2) improves
generalizability to OOD, noisy scans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerating Inverse Rendering By Using a GPU and Reuse of Light Paths. (arXiv:2110.00085v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00085">
<div class="article-summary-box-inner">
<span><p>Inverse rendering seeks to estimate scene characteristics from a set of data
images. The dominant approach is based on differential rendering using
Monte-Carlo. Algorithms as such usually rely on a forward model and use an
iterative gradient method that requires sampling millions of light paths per
iteration. This paper presents an efficient framework that speeds up existing
inverse rendering algorithms. This is achieved by tailoring the iterative
process of inverse rendering specifically to a GPU architecture. For this
cause, we introduce two interleaved steps - Path Sorting and Path Recycling.
Path Sorting allows the GPU to deal with light paths of the same size. Path
Recycling allows the algorithm to use light paths from previous iterations to
better utilize the information they encode. Together, these steps significantly
speed up gradient optimization. In this paper, we give the theoretical
background for Path Recycling. We demonstrate its efficiency for volumetric
scattering tomography and reflectometry (surface reflections).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seeing Glass: Joint Point Cloud and Depth Completion for Transparent Objects. (arXiv:2110.00087v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00087">
<div class="article-summary-box-inner">
<span><p>The basis of many object manipulation algorithms is RGB-D input. Yet,
commodity RGB-D sensors can only provide distorted depth maps for a wide range
of transparent objects due light refraction and absorption. To tackle the
perception challenges posed by transparent objects, we propose TranspareNet, a
joint point cloud and depth completion method, with the ability to complete the
depth of transparent objects in cluttered and complex scenes, even with
partially filled fluid contents within the vessels. To address the shortcomings
of existing transparent object data collection schemes in literature, we also
propose an automated dataset creation workflow that consists of
robot-controlled image collection and vision-based automatic annotation.
Through this automated workflow, we created Toronto Transparent Objects Depth
Dataset (TODD), which consists of nearly 15000 RGB-D images. Our experimental
evaluation demonstrates that TranspareNet outperforms existing state-of-the-art
depth completion methods on multiple datasets, including ClearGrasp, and that
it also handles cluttered scenes when trained on TODD. Code and dataset will be
released at https://www.pair.toronto.edu/TranspareNet/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepMCAT: Large-Scale Deep Clustering for Medical Image Categorization. (arXiv:2110.00109v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00109">
<div class="article-summary-box-inner">
<span><p>In recent years, the research landscape of machine learning in medical
imaging has changed drastically from supervised to semi-, weakly- or
unsupervised methods. This is mainly due to the fact that ground-truth labels
are time-consuming and expensive to obtain manually. Generating labels from
patient metadata might be feasible but it suffers from user-originated errors
which introduce biases. In this work, we propose an unsupervised approach for
automatically clustering and categorizing large-scale medical image datasets,
with a focus on cardiac MR images, and without using any labels. We
investigated the end-to-end training using both class-balanced and imbalanced
large-scale datasets. Our method was able to create clusters with high purity
and achieved over 0.99 cluster purity on these datasets. The results
demonstrate the potential of the proposed method for categorizing unstructured
large medical databases, such as organizing clinical PACS systems in hospitals.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning-based Action Detection in Untrimmed Videos: A Survey. (arXiv:2110.00111v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00111">
<div class="article-summary-box-inner">
<span><p>Understanding human behavior and activity facilitates advancement of numerous
real-world applications, and is critical for video analysis. Despite the
progress of action recognition algorithms in trimmed videos, the majority of
real-world videos are lengthy and untrimmed with sparse segments of interest.
The task of temporal activity detection in untrimmed videos aims to localize
the temporal boundary of actions and classify the action categories. Temporal
activity detection task has been investigated in full and limited supervision
settings depending on the availability of action annotations. This paper
provides an extensive overview of deep learning-based algorithms to tackle
temporal action detection in untrimmed videos with different supervision levels
including fully-supervised, weakly-supervised, unsupervised, self-supervised,
and semi-supervised. In addition, this paper also reviews advances in
spatio-temporal action detection where actions are localized in both temporal
and spatial dimensions. Moreover, the commonly used action detection benchmark
datasets and evaluation metrics are described, and the performance of the
state-of-the-art methods are compared. Finally, real-world applications of
temporal action detection in untrimmed videos and a set of future directions
are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HUMBI: A Large Multiview Dataset of Human Body Expressions and Benchmark Challenge. (arXiv:2110.00119v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00119">
<div class="article-summary-box-inner">
<span><p>This paper presents a new large multiview dataset called HUMBI for human body
expressions with natural clothing. The goal of HUMBI is to facilitate modeling
view-specific appearance and geometry of five primary body signals including
gaze, face, hand, body, and garment from assorted people. 107 synchronized HD
cameras are used to capture 772 distinctive subjects across gender, ethnicity,
age, and style. With the multiview image streams, we reconstruct high fidelity
body expressions using 3D mesh models, which allows representing view-specific
appearance. We demonstrate that HUMBI is highly effective in learning and
reconstructing a complete human model and is complementary to the existing
datasets of human body expressions with limited views and subjects such as
MPII-Gaze, Multi-PIE, Human3.6M, and Panoptic Studio datasets. Based on HUMBI,
we formulate a new benchmark challenge of a pose-guided appearance rendering
task that aims to substantially extend photorealism in modeling diverse human
expressions in 3D, which is the key enabling factor of authentic social
tele-presence. HUMBI is publicly available at <a href="http://humbi-data.net">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Development of the algorithm for differentiating bone metastases and trauma of the ribs in bone scintigraphy and demonstration of visual evidence of the algorithm -- Using only anterior bone scan view of thorax. (arXiv:2110.00130v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00130">
<div class="article-summary-box-inner">
<span><p>Background: Although there are many studies on the application of artificial
intelligence (AI) models to medical imaging, there is no report of an AI model
that determines the accumulation of ribs in bone metastases and trauma only
using the anterior image of thorax of bone scintigraphy. In recent years, a
method for visualizing diagnostic grounds called Gradient-weighted Class
Activation Mapping (Grad-CAM) has been proposed in the area of diagnostic
images using Deep Convolutional Neural Network (DCNN). As far as we have
investigated, there are no reports of visualization of the diagnostic basis in
bone scintigraphy. Our aim is to visualize the area of interest of DCNN, in
addition to developing an algorithm to classify and diagnose whether RI
accumulation on the ribs is bone metastasis or trauma using only anterior bone
scan view of thorax. Material and Methods: For this retrospective study, we
used 838 patients who underwent bone scintigraphy to search for bone metastases
at our institution. A frontal chest image of bone scintigraphy was used to
create the algorithm. We used 437 cases with bone metastases on the ribs and
401 cases with abnormal RI accumulation due to trauma. Result: AI model was
able to detect bone metastasis lesion with a sensitivity of 90.00% and accuracy
of 86.5%. And it was possible to visualize the part that the AI model focused
on with Grad-CAM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Neighbourhood-Preserving Transformations for Quantization-Based Unsupervised Hashing. (arXiv:2110.00216v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00216">
<div class="article-summary-box-inner">
<span><p>An effective unsupervised hashing algorithm leads to compact binary codes
preserving the neighborhood structure of data as much as possible. One of the
most established schemes for unsupervised hashing is to reduce the
dimensionality of data and then find a rigid (neighbourhood-preserving)
transformation that reduces the quantization error. Although employing rigid
transformations is effective, we may not reduce quantization loss to the
ultimate limits. As well, reducing dimensionality and quantization loss in two
separate steps seems to be sub-optimal. Motivated by these shortcomings, we
propose to employ both rigid and non-rigid transformations to reduce
quantization error and dimensionality simultaneously. We relax the
orthogonality constraint on the projection in a PCA-formulation and regularize
this by a quantization term. We show that both the non-rigid projection matrix
and rotation matrix contribute towards minimizing quantization loss but in
different ways. A scalable nested coordinate descent approach is proposed to
optimize this mixed-integer optimization problem. We evaluate the proposed
method on five public benchmark datasets providing almost half a million
images. Comparative results indicate that the proposed method mostly
outperforms state-of-art linear methods and competes with end-to-end deep
solutions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Object Permanence using Agent Actions and Reasoning. (arXiv:2110.00238v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00238">
<div class="article-summary-box-inner">
<span><p>Object permanence in psychology means knowing that objects still exist even
if they are no longer visible. It is a crucial concept for robots to operate
autonomously in uncontrolled environments. Existing approaches learn object
permanence from low-level perception, but perform poorly on more complex
scenarios, like when objects are contained and carried by others. Knowledge
about manipulation actions performed on an object prior to its disappearance
allows us to reason about its location, e.g., that the object has been placed
in a carrier. In this paper we argue that object permanence can be improved
when the robot uses knowledge about executed actions and describe an approach
to infer hidden object states from agent actions. We show that considering
agent actions not only improves rule-based reasoning models but also purely
neural approaches, showing its general applicability. Then, we conduct
quantitative experiments on a snitch localization task using a dataset of 1,371
synthesized videos, where we compare the performance of different object
permanence models with and without action annotations. We demonstrate that
models with action annotations can significantly increase performance of both
neural and rule-based approaches. Finally, we evaluate the usability of our
approach in real-world applications by conducting qualitative experiments with
two Universal Robots (UR5 and UR16e) in both lab and industrial settings. The
robots complete benchmark tasks for a gearbox assembly and demonstrate the
object permanence capabilities with real sensor data in an industrial
environment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Efficient Instance Segmentation with a Single GPU. (arXiv:2110.00242v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00242">
<div class="article-summary-box-inner">
<span><p>Not everyone is wealthy enough to have hundreds of GPUs or TPUs. Therefore,
we've got to find a way out. In this paper, we introduce a data-efficient
instance segmentation method we used in the 2021 VIPriors Instance Segmentation
Challenge. Our solution is a modified version of Swin Transformer, based on the
mmdetection which is a powerful toolbox. To solve the problem of lack of data,
we utilize data augmentation including random flip and multiscale training to
train our model. During inference, multiscale fusion is used to boost the
performance. We only use a single GPU during the whole training and testing
stages. In the end, our team named THU_IVG_2018 achieved the result of 0.366
for AP@0.50:0.95 on the test set, which is competitive with other top-ranking
methods while only one GPU is used. Besides, our method achieved the
AP@0.50:0.95 (medium) of 0.592, which ranks second among all contestants
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lightweight Transformer in Federated Setting for Human Activity Recognition. (arXiv:2110.00244v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00244">
<div class="article-summary-box-inner">
<span><p>Human Activity Recognition (HAR) has been a challenging problem yet it needs
to be solved. It will mainly be used for eldercare and healthcare as an
assistive technology when ensemble with other technologies like Internet of
Things(IoT). HAR can be achieved with the help of sensors, smartphones or
images. Deep neural network techniques like artificial neural networks,
convolutional neural networks and recurrent neural networks have been used in
HAR, both in centralized and federated setting. However, these techniques have
certain limitations. RNNs have limitation of parallelization, CNNS have the
limitation of sequence length and they are computationally expensive. In this
paper, to address the state of art challenges, we present a inertial
sensors-based novel one patch transformer which gives the best of both RNNs and
CNNs for Human activity recognition. We also design a testbed to collect
real-time human activity data. The data collected is further used to train and
test the proposed transformer. With the help of experiments, we show that the
proposed transformer outperforms the state of art CNN and RNN based
classifiers, both in federated and centralized setting. Moreover, the proposed
transformer is computationally inexpensive as it uses very few parameter
compared to the existing state of art CNN and RNN based classifier. Thus its
more suitable for federated learning as it provides less communication and
computational cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Synergizing between Self-Training and Adversarial Learning for Domain Adaptive Object Detection. (arXiv:2110.00249v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00249">
<div class="article-summary-box-inner">
<span><p>We study adapting trained object detectors to unseen domains manifesting
significant variations of object appearance, viewpoints and backgrounds. Most
current methods align domains by either using image or instance-level feature
alignment in an adversarial fashion. This often suffers due to the presence of
unwanted background and as such lacks class-specific alignment. A common remedy
to promote class-level alignment is to use high confidence predictions on the
unlabelled domain as pseudo labels. These high confidence predictions are often
fallacious since the model is poorly calibrated under domain shift. In this
paper, we propose to leverage model predictive uncertainty to strike the right
balance between adversarial feature alignment and class-level alignment.
Specifically, we measure predictive uncertainty on class assignments and the
bounding box predictions. Model predictions with low uncertainty are used to
generate pseudo-labels for self-supervision, whereas the ones with higher
uncertainty are used to generate tiles for an adversarial feature alignment
stage. This synergy between tiling around the uncertain object regions and
generating pseudo-labels from highly certain object regions allows us to
capture both the image and instance level context during the model adaptation
stage. We perform extensive experiments covering various domain shift
scenarios. Our approach improves upon existing state-of-the-art methods with
visible margins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Memory-Guided Semantic Reasoning Model for Image Inpainting. (arXiv:2110.00261v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00261">
<div class="article-summary-box-inner">
<span><p>Most existing methods for image inpainting focus on learning the intra-image
priors from the known regions of the current input image to infer the content
of the corrupted regions in the same image. While such methods perform well on
images with small corrupted regions, it is challenging for these methods to
deal with images with large corrupted area due to two potential limitations: 1)
such methods tend to overfit each single training pair of images relying solely
on the intra-image prior knowledge learned from the limited known area; 2) the
inter-image prior knowledge about the general distribution patterns of visual
semantics, which can be transferred across images sharing similar semantics, is
not exploited. In this paper, we propose the Generative Memory-Guided Semantic
Reasoning Model (GM-SRM), which not only learns the intra-image priors from the
known regions, but also distills the inter-image reasoning priors to infer the
content of the corrupted regions. In particular, the proposed GM-SRM first
pre-learns a generative memory from the whole training data to capture the
semantic distribution patterns in a global view. Then the learned memory are
leveraged to retrieve the matching inter-image priors for the current corrupted
image to perform semantic reasoning during image inpainting. While the
intra-image priors are used for guaranteeing the pixel-level content
consistency, the inter-image priors are favorable for performing high-level
semantic reasoning, which is particularly effective for inferring semantic
content for large corrupted area. Extensive experiments on Paris Street View,
CelebA-HQ, and Places2 benchmarks demonstrate that our GM-SRM outperforms the
state-of-the-art methods for image inpainting in terms of both the visual
quality and quantitative metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From SLAM to Situational Awareness: Challenges and Survey. (arXiv:2110.00273v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00273">
<div class="article-summary-box-inner">
<span><p>The knowledge that an intelligent and autonomous mobile robot has and is able
to acquire of itself and the environment, namely the situation, limits its
reasoning, decision-making, and execution skills to efficiently and safely
perform complex missions. Situational awareness is a basic capability of humans
that has been deeply studied in fields like Psychology, Military, Aerospace,
Education, etc., but it has barely been considered in robotics, which has
focused on ideas such as sensing, perception, sensor fusion, state estimation,
localization and mapping, spatial AI, etc. In our research, we connected the
broad multidisciplinary existing knowledge on situational awareness with its
counterpart in mobile robotics. In this paper, we survey the state-of-the-art
robotics algorithms, we analyze the situational awareness aspects that have
been covered by them, and we discuss their missing points. We found out that
the existing robotics algorithms are still missing manifold important aspects
of situational awareness. As a consequence, we conclude that these missing
features are limiting the performance of robotic situational awareness, and
further research is needed to overcome this challenge. We see this as an
opportunity, and provide our vision for future research on robotic situational
awareness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stochastic Modeling for Learnable Human Pose Triangulation. (arXiv:2110.00280v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00280">
<div class="article-summary-box-inner">
<span><p>We propose a stochastic modeling framework for 3D human pose triangulation
and evaluate its performance across different datasets and spatial camera
arrangements. The common approach to 3D pose estimation is to first detect 2D
keypoints in images and then apply the triangulation from multiple views.
However, the majority of existing triangulation models are limited to a single
dataset, i.e. camera arrangement and their number. Moreover, they require known
camera parameters. The proposed stochastic pose triangulation model
successfully generalizes to different camera arrangements and between two
public datasets. In each step, we generate a set of 3D pose hypotheses obtained
by triangulation from a random subset of views. The hypotheses are evaluated by
a neural network and the expectation of the triangulation error is minimized.
The key novelty is that the network learns to evaluate the poses without taking
into account the spatial camera arrangement, thus improving generalization.
Additionally, we demonstrate that the proposed stochastic framework can also be
used for fundamental matrix estimation, showing promising results towards
relative camera pose estimation from noisy keypoint correspondences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DCT based Fusion of Variable Exposure Images for HDRI. (arXiv:2110.00312v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00312">
<div class="article-summary-box-inner">
<span><p>Combining images with different exposure settings are of prime importance in
the field of computational photography. Both transform domain approach and
filtering based approaches are possible for fusing multiple exposure images, to
obtain the well-exposed image. We propose a Discrete Cosine Transform
(DCT-based) approach for fusing multiple exposure images. The input image stack
is processed in the transform domain by an averaging operation and the inverse
transform is performed on the averaged image obtained to generate the fusion of
multiple exposure image. The experimental observation leads us to the
conjecture that the obtained DCT coefficients are indicators of parameters to
measure well-exposedness, contrast and saturation as specified in the
traditional exposure fusion based approach and the averaging performed
indicates equal weights assigned to the DCT coefficients in this non-parametric
and non pyramidal approach to fuse the multiple exposure stack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Cluster Separation Using High-Dimensional Sharpened Dimensionality Reduction. (arXiv:2110.00317v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00317">
<div class="article-summary-box-inner">
<span><p>Applying dimensionality reduction (DR) to large, high-dimensional data sets
can be challenging when distinguishing the underlying high-dimensional data
clusters in a 2D projection for exploratory analysis. We address this problem
by first sharpening the clusters in the original high-dimensional data prior to
the DR step using Local Gradient Clustering (LGC). We then project the
sharpened data from the high-dimensional space to 2D by a user-selected DR
method. The sharpening step aids this method to preserve cluster separation in
the resulting 2D projection. With our method, end-users can label each distinct
cluster to further analyze an otherwise unlabeled data set. Our
`High-Dimensional Sharpened DR' (HD-SDR) method, tested on both synthetic and
real-world data sets, is favorable to DR methods with poor cluster separation
and yields a better visual cluster separation than these DR methods with no
sharpening. Our method achieves good quality (measured by quality metrics) and
scales computationally well with large high-dimensional data. To illustrate its
concrete applications, we further apply HD-SDR on a recent astronomical
catalog.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Student Helping Teacher: Teacher Evolution via Self-Knowledge Distillation. (arXiv:2110.00329v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00329">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation usually transfers the knowledge from a pre-trained
cumbersome teacher network to a compact student network, which follows the
classical teacher-teaching-student paradigm. Based on this paradigm, previous
methods mostly focus on how to efficiently train a better student network for
deployment. Different from the existing practices, in this paper, we propose a
novel student-helping-teacher formula, Teacher Evolution via Self-Knowledge
Distillation (TESKD), where the target teacher (for deployment) is learned with
the help of multiple hierarchical students by sharing the structural backbone.
The diverse feedback from multiple students allows the teacher to improve
itself through the shared feature representations. The effectiveness of our
proposed framework is demonstrated by extensive experiments with various
network settings on two standard benchmarks including CIFAR-100 and ImageNet.
Notably, when trained together with our proposed method, ResNet-18 achieves
79.15% and 71.14% accuracy on CIFAR-100 and ImageNet, outperforming the
baseline results by 4.74% and 1.43%, respectively. The code is available at:
https://github.com/zhengli427/TESKD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geometry Attention Transformer with Position-aware LSTMs for Image Captioning. (arXiv:2110.00335v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00335">
<div class="article-summary-box-inner">
<span><p>In recent years, transformer structures have been widely applied in image
captioning with impressive performance. For good captioning results, the
geometry and position relations of different visual objects are often thought
of as crucial information. Aiming to further promote image captioning by
transformers, this paper proposes an improved Geometry Attention Transformer
(GAT) model. In order to further leverage geometric information, two novel
geometry-aware architectures are designed respectively for the encoder and
decoder in our GAT. Besides, this model includes the two work modules: 1) a
geometry gate-controlled self-attention refiner, for explicitly incorporating
relative spatial information into image region representations in encoding
steps, and 2) a group of position-LSTMs, for precisely informing the decoder of
relative word position in generating caption texts. The experiment comparisons
on the datasets MS COCO and Flickr30K show that our GAT is efficient, and it
could often outperform current state-of-the-art image captioning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PhiNets: a scalable backbone for low-power AI at the edge. (arXiv:2110.00337v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00337">
<div class="article-summary-box-inner">
<span><p>In the Internet of Things era, where we see many interconnected and
heterogeneous mobile and fixed smart devices, distributing the intelligence
from the cloud to the edge has become a necessity. Due to limited computational
and communication capabilities, low memory and limited energy budget, bringing
artificial intelligence algorithms to peripheral devices, such as the end-nodes
of a sensor network, is a challenging task and requires the design of
innovative methods. In this work, we present PhiNets, a new scalable backbone
optimized for deep-learning-based image processing on resource-constrained
platforms. PhiNets are based on inverted residual blocks specifically designed
to decouple the computational cost, working memory, and parameter memory, thus
exploiting all the available resources. With a YoloV2 detection head and Simple
Online and Realtime Tracking, the proposed architecture has achieved the
state-of-the-art results in (i) detection on the COCO and VOC2012 benchmarks,
and (ii) tracking on the MOT15 benchmark. PhiNets reduce the parameter count of
87% to 93% with respect to previous state-of-the-art models (EfficientNetv1,
MobileNetv2) and achieve better performance with lower computational cost.
Moreover, we demonstrate our approach on a prototype node based on a STM32H743
microcontroller (MCU) with 2MB of internal Flash and 1MB of RAM and achieve
power requirements in the order of 10 mW. The code for the PhiNets is publicly
available on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summarize and Search: Learning Consensus-aware Dynamic Convolution for Co-Saliency Detection. (arXiv:2110.00338v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00338">
<div class="article-summary-box-inner">
<span><p>Humans perform co-saliency detection by first summarizing the consensus
knowledge in the whole group and then searching corresponding objects in each
image. Previous methods usually lack robustness, scalability, or stability for
the first process and simply fuse consensus features with image features for
the second process. In this paper, we propose a novel consensus-aware dynamic
convolution model to explicitly and effectively perform the "summarize and
search" process. To summarize consensus image features, we first summarize
robust features for every single image using an effective pooling method and
then aggregate cross-image consensus cues via the self-attention mechanism. By
doing this, our model meets the scalability and stability requirements. Next,
we generate dynamic kernels from consensus features to encode the summarized
consensus knowledge. Two kinds of kernels are generated in a supplementary way
to summarize fine-grained image-specific consensus object cues and the coarse
group-wise common knowledge, respectively. Then, we can effectively perform
object searching by employing dynamic convolution at multiple scales. Besides,
a novel and effective data synthesis method is also proposed to train our
network. Experimental results on four benchmark datasets verify the
effectiveness of our proposed method. Our code and saliency maps are available
at \url{https://github.com/nnizhang/CADC}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Spiking Variational Autoencoder. (arXiv:2110.00375v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00375">
<div class="article-summary-box-inner">
<span><p>Spiking neural networks (SNNs) can be run on neuromorphic devices with
ultra-high speed and ultra-low energy consumption because of their binary and
event-driven nature. Therefore, SNNs are expected to have various applications,
including as generative models being running on edge devices to create
high-quality images. In this study, we build a variational autoencoder (VAE)
with SNN to enable image generation. VAE is known for its stability among
generative models; recently, its quality advanced. In vanilla VAE, the latent
space is represented as a normal distribution, and floating-point calculations
are required in sampling. However, this is not possible in SNNs because all
features must be binary time series data. Therefore, we constructed the latent
space with an autoregressive SNN model, and randomly selected samples from its
output to sample the latent variables. This allows the latent variables to
follow the Bernoulli process and allows variational learning. Thus, we build
the Fully Spiking Variational Autoencoder where all modules are constructed
with SNN. To the best of our knowledge, we are the first to build a VAE only
with SNN layers. We experimented with several datasets, and confirmed that it
can generate images with the same or better quality compared to conventional
ANNs. The code will be available soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAN-based Reactive Motion Synthesis with Class-aware Discriminators for Human-human Interaction. (arXiv:2110.00380v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00380">
<div class="article-summary-box-inner">
<span><p>Creating realistic characters that can react to the users' or another
character's movement can benefit computer graphics, games and virtual reality
hugely. However, synthesizing such reactive motions in human-human interactions
is a challenging task due to the many different ways two humans can interact.
While there are a number of successful researches in adapting the generative
adversarial network (GAN) in synthesizing single human actions, there are very
few on modelling human-human interactions. In this paper, we propose a
semi-supervised GAN system that synthesizes the reactive motion of a character
given the active motion from another character. Our key insights are two-fold.
First, to effectively encode the complicated spatial-temporal information of a
human motion, we empower the generator with a part-based long short-term memory
(LSTM) module, such that the temporal movement of different limbs can be
effectively modelled. We further include an attention module such that the
temporal significance of the interaction can be learned, which enhances the
temporal alignment of the active-reactive motion pair. Second, as the reactive
motion of different types of interactions can be significantly different, we
introduce a discriminator that not only tells if the generated movement is
realistic or not, but also tells the class label of the interaction. This
allows the use of such labels in supervising the training of the generator. We
experiment with the SBU and the HHOI datasets. The high quality of the
synthetic motion demonstrates the effective design of our generator, and the
discriminability of the synthesis also demonstrates the strength of our
discriminator.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personalized Retrogress-Resilient Framework for Real-World Medical Federated Learning. (arXiv:2110.00394v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00394">
<div class="article-summary-box-inner">
<span><p>Nowadays, deep learning methods with large-scale datasets can produce
clinically useful models for computer-aided diagnosis. However, the privacy and
ethical concerns are increasingly critical, which make it difficult to collect
large quantities of data from multiple institutions. Federated Learning (FL)
provides a promising decentralized solution to train model collaboratively by
exchanging client models instead of private data. However, the server
aggregation of existing FL methods is observed to degrade the model performance
in real-world medical FL setting, which is termed as retrogress. To address
this problem, we propose a personalized retrogress-resilient framework to
produce a superior personalized model for each client. Specifically, we devise
a Progressive Fourier Aggregation (PFA) at the server to achieve more stable
and effective global knowledge gathering by integrating client models from
low-frequency to high-frequency gradually. Moreover, with an introduced deputy
model to receive the aggregated server model, we design a Deputy-Enhanced
Transfer (DET) strategy at the client and conduct three steps of
Recover-Exchange-Sublimate to ameliorate the personalized local model by
transferring the global knowledge smoothly. Extensive experiments on real-world
dermoscopic FL dataset prove that our personalized retrogress-resilient
framework outperforms state-of-the-art FL methods, as well as the
generalization on an out-of-distribution cohort. The code and dataset are
available at https://github.com/CityU-AIM-Group/PRR-FL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning of Inter-Label Geometric Relationships Using Self-Supervised Learning: Application To Gleason Grade Segmentation. (arXiv:2110.00404v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00404">
<div class="article-summary-box-inner">
<span><p>Segmentation of Prostate Cancer (PCa) tissues from Gleason graded
histopathology images is vital for accurate diagnosis. Although deep learning
(DL) based segmentation methods achieve state-of-the-art accuracy, they rely on
large datasets with manual annotations. We propose a method to synthesize for
PCa histopathology images by learning the geometrical relationship between
different disease labels using self-supervised learning. We use a weakly
supervised segmentation approach that uses Gleason score to segment the
diseased regions and the resulting segmentation map is used to train a Shape
Restoration Network (ShaRe-Net) to predict missing mask segments in a
self-supervised manner. Using DenseUNet as the backbone generator architecture
we incorporate latent variable sampling to inject diversity in the image
generation process and thus improve robustness. Experiments on multiple
histopathology datasets demonstrate the superiority of our method over
competing image synthesis methods for segmentation tasks. Ablation studies show
the benefits of integrating geometry and diversity in generating high-quality
images, and our self-supervised approach with limited class-labeled data
achieves similar performance as fully supervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-shot Natural Language Video Localization. (arXiv:2110.00428v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00428">
<div class="article-summary-box-inner">
<span><p>Understanding videos to localize moments with natural language often requires
large expensive annotated video regions paired with language queries. To
eliminate the annotation costs, we make a first attempt to train a natural
language video localization model in zero-shot manner. Inspired by unsupervised
image captioning setup, we merely require random text corpora, unlabeled video
collections, and an off-the-shelf object detector to train a model. With the
unpaired data, we propose to generate pseudo-supervision of candidate temporal
regions and corresponding query sentences, and develop a simple NLVL model to
train with the pseudo-supervision. Our empirical validations show that the
proposed pseudo-supervised method outperforms several baseline approaches and a
number of methods using stronger supervision on Charades-STA and
ActivityNet-Captions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Protecting Face Embeddings in Mobile Face Verification Scenarios. (arXiv:2110.00434v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00434">
<div class="article-summary-box-inner">
<span><p>This paper proposes PolyProtect, a method for protecting the sensitive face
embeddings that are used to represent people's faces in neural-network-based
face verification systems. PolyProtect transforms a face embedding to a more
secure template, using a mapping based on multivariate polynomials
parameterised by user-specific coefficients and exponents. In this work,
PolyProtect is evaluated on two open-source face verification systems in a
mobile application context, under the toughest threat model that assumes a
fully-informed attacker with complete knowledge of the system and all its
parameters. Results indicate that PolyProtect can be tuned to achieve a
satisfactory trade-off between the recognition accuracy of the PolyProtected
face verification system and the irreversibility of the PolyProtected
templates. Furthermore, PolyProtected templates are shown to be effectively
unlinkable, especially if the user-specific parameters employed in the
PolyProtect mapping are selected in a non-naive manner. The evaluation is
conducted using practical methodologies with tangible results, to present
realistic insight into the method's robustness as a face embedding protection
scheme in practice. The code to fully reproduce this work is available at:
https://gitlab.idiap.ch/bob/bob.paper.polyprotect_2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MonoCInIS: Camera Independent Monocular 3D Object Detection using Instance Segmentation. (arXiv:2110.00464v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00464">
<div class="article-summary-box-inner">
<span><p>Monocular 3D object detection has recently shown promising results, however
there remain challenging problems. One of those is the lack of invariance to
different camera intrinsic parameters, which can be observed across different
3D object datasets. Little effort has been made to exploit the combination of
heterogeneous 3D object datasets. In contrast to general intuition, we show
that more data does not automatically guarantee a better performance, but
rather, methods need to have a degree of 'camera independence' in order to
benefit from large and heterogeneous training data. In this paper we propose a
category-level pose estimation method based on instance segmentation, using
camera independent geometric reasoning to cope with the varying camera
viewpoints and intrinsics of different datasets. Every pixel of an instance
predicts the object dimensions, the 3D object reference points projected in 2D
image space and, optionally, the local viewing angle. Camera intrinsics are
only used outside of the learned network to lift the predicted 2D reference
points to 3D. We surpass camera independent methods on the challenging KITTI3D
benchmark and show the key benefits compared to camera dependent methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Graph-theoretic Algorithm for Small Bowel Path Tracking in CT Scans. (arXiv:2110.00466v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00466">
<div class="article-summary-box-inner">
<span><p>We present a novel graph-theoretic method for small bowel path tracking. It
is formulated as finding the minimum cost path between given start and end
nodes on a graph that is constructed based on the bowel wall detection. We
observed that a trivial solution with many short-cuts is easily made even with
the wall detection, where the tracked path penetrates indistinct walls around
the contact between different parts of the small bowel. Thus, we propose to
include must-pass nodes in finding the path to better cover the entire course
of the small bowel. The proposed method does not entail training with
ground-truth paths while the previous methods do. We acquired ground-truth
paths that are all connected from start to end of the small bowel for 10
abdominal CT scans, which enables the evaluation of the path tracking for the
entire course of the small bowel. The proposed method showed clear improvements
in terms of several metrics compared to the baseline method. The maximum length
of the path that is tracked without an error per scan, by the proposed method,
is above 800mm on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instance Segmentation Challenge Track Technical Report, VIPriors Workshop at ICCV 2021: Task-Specific Copy-Paste Data Augmentation Method for Instance Segmentation. (arXiv:2110.00470v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00470">
<div class="article-summary-box-inner">
<span><p>Copy-Paste has proven to be a very effective data augmentation for instance
segmentation which can improve the generalization of the model. We used a
task-specific Copy-Paste data augmentation method to achieve good performance
on the instance segmentation track of the 2nd VIPriors workshop challenge. We
also applied additional data augmentation techniques including RandAugment and
GridMask. Our segmentation model is the HTC detector on the CBSwin-B with CBFPN
with some tweaks. This model was trained at the multi-scale mode by a random
sampler on the 6x schedule and tested at the single-scale mode. By combining
these techniques, we achieved 0.398 AP@0.50:0.95 with the validation set and
0.433 AP@0.50:0.95 with the test set. Finally, we reached 0.477 AP@0.50:0.95
with the test set by adding the validation set to the training data. Source
code is available at https://github.com/jahongir7174/VIP2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey and synthesis of state of the art in driver monitoring. (arXiv:2110.00472v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00472">
<div class="article-summary-box-inner">
<span><p>Road-vehicle accidents are mostly due to human errors, and many such
accidents could be avoided by continuously monitoring the driver. Driver
monitoring (DM) is a topic of growing interest in the automotive industry, and
it will remain relevant for all vehicles that are not fully autonomous, and
thus for decades for the average vehicle owner. The present paper focuses on
the first step of DM, which consists in characterizing the state of the driver.
Since DM will be increasingly linked to driving automation (DA), this paper
presents a clear view of the role of DM at each of the six SAE levels of DA.
This paper surveys the state of the art of DM, and then synthesizes it,
providing a unique, structured, polychotomous view of the many characterization
techniques of DM. Informed by the survey, the paper characterizes the driver
state along the five main dimensions--called here "(sub)states"--of drowsiness,
mental workload, distraction, emotions, and under the influence. The
polychotomous view of DM is presented through a pair of interlocked tables that
relate these states to their indicators (e.g., the eye-blink rate) and the
sensors that can access each of these indicators (e.g., a camera). The tables
factor in not only the effects linked directly to the driver, but also those
linked to the (driven) vehicle and the (driving) environment. They show, at a
glance, to concerned researchers, equipment providers, and vehicle
manufacturers (1) most of the options they have to implement various forms of
advanced DM systems, and (2) fruitful areas for further research and
innovation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Score-Based Generative Classifiers. (arXiv:2110.00473v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00473">
<div class="article-summary-box-inner">
<span><p>The tremendous success of generative models in recent years raises the
question whether they can also be used to perform classification. Generative
models have been used as adversarially robust classifiers on simple datasets
such as MNIST, but this robustness has not been observed on more complex
datasets like CIFAR-10. Additionally, on natural image datasets, previous
results have suggested a trade-off between the likelihood of the data and
classification accuracy. In this work, we investigate score-based generative
models as classifiers for natural images. We show that these models not only
obtain competitive likelihood values but simultaneously achieve
state-of-the-art classification accuracy for generative classifiers on
CIFAR-10. Nevertheless, we find that these models are only slightly, if at all,
more robust than discriminative baseline models on out-of-distribution tasks
based on common image corruptions. Similarly and contrary to prior results, we
find that score-based are prone to worst-case distribution shifts in the form
of adversarial perturbations. Our work highlights that score-based generative
models are closing the gap in classification accuracy compared to standard
discriminative models. While they do not yet deliver on the promise of
adversarial and out-of-domain robustness, they provide a different approach to
classification that warrants further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ResNet strikes back: An improved training procedure in timm. (arXiv:2110.00476v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00476">
<div class="article-summary-box-inner">
<span><p>The influential Residual Networks designed by He et al. remain the
gold-standard architecture in numerous scientific publications. They typically
serve as the default architecture in studies, or as baselines when new
architectures are proposed. Yet there has been significant progress on best
practices for training neural networks since the inception of the ResNet
architecture in 2015. Novel optimization &amp; data-augmentation have increased the
effectiveness of the training recipes. In this paper, we re-evaluate the
performance of the vanilla ResNet-50 when trained with a procedure that
integrates such advances. We share competitive training settings and
pre-trained models in the timm open-source library, with the hope that they
will serve as better baselines for future work. For instance, with our more
demanding training setting, a vanilla ResNet-50 reaches 80.4% top-1 accuracy at
resolution 224x224 on ImageNet-val without extra data or distillation. We also
report the performance achieved with popular models with our training
procedure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustly Removing Deep Sea Lighting Effects for Visual Mapping of Abyssal Plains. (arXiv:2110.00480v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00480">
<div class="article-summary-box-inner">
<span><p>The majority of Earth's surface lies deep in the oceans, where no surface
light reaches. Robots diving down to great depths must bring light sources that
create moving illumination patterns in the darkness, such that the same 3D
point appears with different color in each image. On top, scattering and
attenuation of light in the water makes images appear foggy and typically
blueish, the degradation depending on each pixel's distance to its observed
seafloor patch, on the local composition of the water and the relative poses
and cones of the light sources. Consequently, visual mapping, including image
matching and surface albedo estimation, severely suffers from the effects that
co-moving light sources produce, and larger mosaic maps from photos are often
dominated by lighting effects that obscure the actual seafloor structure. In
this contribution a practical approach to estimating and compensating these
lighting effects on predominantly homogeneous, flat seafloor regions, as can be
found in the Abyssal plains of our oceans, is presented. The method is
essentially parameter-free and intended as a preprocessing step to facilitate
visual mapping, but already produces convincing lighting artefact compensation
up to a global white balance factor. It does not require to be trained
beforehand on huge sets of annotated images, which are not available for the
deep sea. Rather, we motivate our work by physical models of light propagation,
perform robust statistics-based estimates of additive and multiplicative
nuisances that avoid explicit parameters for light, camera, water or scene,
discuss the breakdown point of the algorithms and show results on imagery
captured by robots in several kilometer water depth.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Preconditioned Plug-and-Play ADMM with Locally Adjustable Denoiser for Image Restoration. (arXiv:2110.00493v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00493">
<div class="article-summary-box-inner">
<span><p>Plug-and-Play optimization recently emerged as a powerful technique for
solving inverse problems by plugging a denoiser into a classical optimization
algorithm. The denoiser accounts for the regularization and therefore
implicitly determines the prior knowledge on the data, hence replacing typical
handcrafted priors. In this paper, we extend the concept of plug-and-play
optimization to use denoisers that can be parameterized for non-constant noise
variance. In that aim, we introduce a preconditioning of the ADMM algorithm,
which mathematically justifies the use of such an adjustable denoiser. We
additionally propose a procedure for training a convolutional neural network
for high quality non-blind image denoising that also allows for pixel-wise
control of the noise standard deviation. We show that our pixel-wise adjustable
denoiser, along with a suitable preconditioning strategy, can further improve
the plug-and-play ADMM approach for several applications, including image
completion, interpolation, demosaicing and Poisson denoising.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASH: A Modern Framework for Parallel Spatial Hashing in 3D Perception. (arXiv:2110.00511v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00511">
<div class="article-summary-box-inner">
<span><p>We present ASH, a modern and high-performance framework for parallel spatial
hashing on GPU. Compared to existing GPU hash map implementations, ASH achieves
higher performance, supports richer functionality, and requires fewer lines of
code (LoC) when used for implementing spatially varying operations from
volumetric geometry reconstruction to differentiable appearance reconstruction.
Unlike existing GPU hash maps, the ASH framework provides a versatile tensor
interface, hiding low-level details from the users. In addition, by decoupling
the internal hashing data structures and key-value data in buffers, we offer
direct access to spatially varying data via indices, enabling seamless
integration to modern libraries such as PyTorch. To achieve this, we 1) detach
stored key-value data from the low-level hash map implementation; 2) bridge the
pointer-first low level data structures to index-first high-level tensor
interfaces via an index heap; 3) adapt both generic and non-generic
integer-only hash map implementations as backends to operate on
multi-dimensional keys. We first profile our hash map against state-of-the-art
hash maps on synthetic data to show the performance gain from this
architecture. We then show that ASH can consistently achieve higher performance
on various large-scale 3D perception tasks with fewer LoC by showcasing several
applications, including 1) point cloud voxelization, 2) dense volumetric SLAM,
3) non-rigid point cloud registration and volumetric deformation, and 4)
spatially varying geometry and appearance refinement. ASH and its example
applications are open sourced in Open3D (<a href="http://www.open3d.org">this http URL</a>).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optic Disc Segmentation using Disk-Centered Patch Augmentation. (arXiv:2110.00512v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00512">
<div class="article-summary-box-inner">
<span><p>The optic disc is a crucial diagnostic feature in the eye since changes to
its physiognomy is correlated with the severity of various ocular and
cardiovascular diseases. While identifying the bulk of the optic disc in a
color fundus image is straightforward, accurately segmenting its boundary at
the pixel level is very challenging. In this work, we propose disc-centered
patch augmentation (DCPA) -- a simple, yet novel training scheme for deep
neural networks -- to address this problem. DCPA achieves state-of-the-art
results on full-size images even when using small neural networks, specifically
a U-Net with only 7 million parameters as opposed to the original 31 million.
In DCPA, we restrict the training data to patches that fully contain the optic
nerve. In addition, we also train the network using dynamic cost functions to
increase its robustness. We tested DCPA-trained networks on five retinal
datasets: DRISTI, DRIONS-DB, DRIVE, AV-WIDE, and CHASE-DB. The first two had
available optic disc ground truth, and we manually estimated the ground truth
for the latter three. Our approach achieved state-of-the-art F1 and IOU results
on four datasets (95 % F1, 91 % IOU on DRISTI; 92 % F1, 84 % IOU on DRIVE; 83 %
F1, 71 % IOU on AV-WIDE; 83 % F1, 71 % IOU on CHASEDB) and competitive results
on the fifth (95 % F1, 91 % IOU on DRIONS-DB), confirming its generality. Our
open-source code and ground-truth annotations are available at:
https://github.com/saeidmotevali/fundusdisk
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrating Concepts and Operations: Towards Symbolic Reasoning on Real Images. (arXiv:2110.00519v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00519">
<div class="article-summary-box-inner">
<span><p>While neural symbolic methods demonstrate impressive performance in visual
question answering on synthetic images, their performance suffers on real
images. We identify that the long-tail distribution of visual concepts and
unequal importance of reasoning steps in real data are the two key obstacles
that limit the models' real-world potentials. To address these challenges, we
propose a new paradigm, Calibrating Concepts and Operations (CCO), which
enables neural symbolic models to capture underlying data characteristics and
to reason with hierarchical importance. Specifically, we introduce an executor
with learnable concept embedding magnitudes for handling distribution
imbalance, and an operation calibrator for highlighting important operations
and suppressing redundant ones. Our experiments show CCO substantially boosts
the performance of neural symbolic methods on real images. By evaluating models
on the real world dataset GQA, CCO helps the neural symbolic method NSCL
outperforms its vanilla counterpart by 9.1% (from 47.0% to 56.1%); this result
also largely reduces the performance gap between symbolic and non-symbolic
methods. Additionally, we create a perturbed test set for better understanding
and analyzing model performance on real images. Code is available at
https://github.com/Lizw14/CaliCO.git .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mask or Non-Mask? Robust Face Mask Detector via Triplet-Consistency Representation Learning. (arXiv:2110.00523v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00523">
<div class="article-summary-box-inner">
<span><p>In the absence of vaccines or medicines to stop COVID-19, one of the
effective methods to slow the spread of the coronavirus and reduce the
overloading of healthcare is to wear a face mask. Nevertheless, to mandate the
use of face masks or coverings in public areas, additional human resources are
required, which is tedious and attention-intensive. To automate the monitoring
process, one of the promising solutions is to leverage existing object
detection models to detect the faces with or without masks. As such, security
officers do not have to stare at the monitoring devices or crowds, and only
have to deal with the alerts triggered by the detection of faces without masks.
Existing object detection models usually focus on designing the CNN-based
network architectures for extracting discriminative features. However, the size
of training datasets of face mask detection is small, while the difference
between faces with and without masks is subtle. Therefore, in this paper, we
propose a face mask detection framework that uses the context attention module
to enable the effective attention of the feed-forward convolution neural
network by adapting their attention maps feature refinement. Moreover, we
further propose an anchor-free detector with Triplet-Consistency Representation
Learning by integrating the consistency loss and the triplet loss to deal with
the small-scale training data and the similarity between masks and occlusions.
Extensive experimental results show that our method outperforms the other
state-of-the-art methods. The source code is released as a public download to
improve public health at https://github.com/wei-1006/MaskFaceDetection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistent Explanations by Contrastive Learning. (arXiv:2110.00527v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00527">
<div class="article-summary-box-inner">
<span><p>Understanding and explaining the decisions of neural networks are critical to
building trust, rather than relying on them as black box algorithms. Post-hoc
evaluation techniques, such as Grad-CAM, enable humans to inspect the spatial
regions responsible for a particular network decision. However, it is shown
that such explanations are not always consistent with human priors, such as
consistency across image transformations. Given an interpretation algorithm,
e.g., Grad-CAM, we introduce a novel training method to train the model to
produce more consistent explanations. Since obtaining the ground truth for a
desired model interpretation is not a well-defined task, we adopt ideas from
contrastive self-supervised learning and apply them to the interpretations of
the model rather than its embeddings. Explicitly training the network to
produce more reasonable interpretations and subsequently evaluating those
interpretations will enhance our ability to trust the network. We show that our
method, Contrastive Grad-CAM Consistency (CGC), results in Grad-CAM
interpretation heatmaps that are consistent with human annotations while still
achieving comparable classification accuracy. Moreover, since our method can be
seen as a form of regularizer, on limited-data fine-grained classification
settings, our method outperforms the baseline classification accuracy on
Caltech-Birds, Stanford Cars, VGG Flowers, and FGVC-Aircraft datasets. In
addition, because our method does not rely on annotations, it allows for the
incorporation of unlabeled data into training, which enables better
generalization of the model. Our code is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Self-Supervised and Supervised Methods Learn Similar Visual Representations?. (arXiv:2110.00528v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00528">
<div class="article-summary-box-inner">
<span><p>Despite the success of a number of recent techniques for visual
self-supervised deep learning, there remains limited investigation into the
representations that are ultimately learned. By using recent advances in
comparing neural representations, we explore in this direction by comparing a
constrastive self-supervised algorithm (SimCLR) to supervision for simple image
data in a common architecture. We find that the methods learn similar
intermediate representations through dissimilar means, and that the
representations diverge rapidly in the final few layers. We investigate this
divergence, finding that it is caused by these layers strongly fitting to the
distinct learning objectives. We also find that SimCLR's objective implicitly
fits the supervised objective in intermediate layers, but that the reverse is
not true. Our work particularly highlights the importance of the learned
intermediate representations, and raises important questions for auxiliary task
design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Motion Representation Learning with Capsule Autoencoders. (arXiv:2110.00529v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00529">
<div class="article-summary-box-inner">
<span><p>We propose the Motion Capsule Autoencoder (MCAE), which addresses a key
challenge in the unsupervised learning of motion representations:
transformation invariance. MCAE models motion in a two-level hierarchy. In the
lower level, a spatio-temporal motion signal is divided into short, local, and
semantic-agnostic snippets. In the higher level, the snippets are aggregated to
form full-length semantic-aware segments. For both levels, we represent motion
with a set of learned transformation invariant templates and the corresponding
geometric transformations by using capsule autoencoders of a novel design. This
leads to a robust and efficient encoding of viewpoint changes. MCAE is
evaluated on a novel Trajectory20 motion dataset and various real-world
skeleton-based human action datasets. Notably, it achieves better results than
baselines on Trajectory20 with considerably fewer parameters and
state-of-the-art performance on the unsupervised skeleton-based action
recognition task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TEACh: Task-driven Embodied Agents that Chat. (arXiv:2110.00534v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00534">
<div class="article-summary-box-inner">
<span><p>Robots operating in human spaces must be able to engage in natural language
interaction with people, both understanding and executing instructions, and
using conversation to resolve ambiguity and recover from mistakes. To study
this, we introduce TEACh, a dataset of over 3,000 human--human, interactive
dialogues to complete household tasks in simulation. A Commander with access to
oracle information about a task communicates in natural language with a
Follower. The Follower navigates through and interacts with the environment to
complete tasks varying in complexity from "Make Coffee" to "Prepare Breakfast",
asking questions and getting additional information from the Commander. We
propose three benchmarks using TEACh to study embodied intelligence challenges,
and we evaluate initial models' abilities in dialogue understanding, language
grounding, and task execution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Secondary Landmark Detection via 3D Representation Learning. (arXiv:2110.00543v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00543">
<div class="article-summary-box-inner">
<span><p>Recent technological developments have spurred great advances in the
computerized tracking of joints and other landmarks in moving animals,
including humans. Such tracking promises important advances in biology and
biomedicine. Modern tracking models depend critically on labor-intensive
annotated datasets of primary landmarks by non-expert humans. However, such
annotation approaches can be costly and impractical for secondary landmarks,
that is, ones that reflect fine-grained geometry of animals, and that are often
specific to customized behavioral tasks. Due to visual and geometric ambiguity,
nonexperts are often not qualified for secondary landmark annotation, which can
require anatomical and zoological knowledge. These barriers significantly
impede downstream behavioral studies because the learned tracking models
exhibit limited generalizability. We hypothesize that there exists a shared
representation between the primary and secondary landmarks because the range of
motion of the secondary landmarks can be approximately spanned by that of the
primary landmarks. We present a method to learn this spatial relationship of
the primary and secondary landmarks in three dimensional space, which can, in
turn, self-supervise the secondary landmark detector. This 3D representation
learning is generic, and can therefore be applied to various multiview settings
across diverse organisms, including macaques, flies, and humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Decomposition, Disentanglement and Prediction of Video Sequences while Interpreting Dynamics: A Koopman Perspective. (arXiv:2110.00547v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00547">
<div class="article-summary-box-inner">
<span><p>Human interpretation of the world encompasses the use of symbols to
categorize sensory inputs and compose them in a hierarchical manner. One of the
long-term objectives of Computer Vision and Artificial Intelligence is to endow
machines with the capacity of structuring and interpreting the world as we do.
Towards this goal, recent methods have successfully been able to decompose and
disentangle video sequences into their composing objects and dynamics, in a
self-supervised fashion. However, there has been a scarce effort in giving
interpretation to the dynamics of the scene. We propose a method to decompose a
video into moving objects and their attributes, and model each object's
dynamics with linear system identification tools, by means of a Koopman
embedding. This allows interpretation, manipulation and extrapolation of the
dynamics of the different objects by employing the Koopman operator K. We test
our method in various synthetic datasets and successfully forecast challenging
trajectories while interpreting them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Temporal Relationship Mining for Data-Efficient Person Re-identification. (arXiv:2110.00549v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00549">
<div class="article-summary-box-inner">
<span><p>This paper is a technical report to our submission to the ICCV 2021 VIPriors
Re-identification Challenge. In order to make full use of the visual inductive
priors of the data, we treat the query and gallery images of the same identity
as continuous frames in a video sequence. And we propose one novel
post-processing strategy for video temporal relationship mining, which not only
calculates the distance matrix between query and gallery images, but also the
matrix between gallery images. The initial query image is used to retrieve the
most similar image from the gallery, then the retrieved image is treated as a
new query to retrieve its most similar image from the gallery. By iteratively
searching for the closest image, we can achieve accurate image retrieval and
finally obtain a robust retrieval sequence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Neurally-Inspired Hierarchical Prediction Network for Spatiotemporal Sequence Learning and Prediction. (arXiv:1901.09002v2 [cs.NE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.09002">
<div class="article-summary-box-inner">
<span><p>In this paper we developed a hierarchical network model, called Hierarchical
Prediction Network (HPNet), to understand how spatiotemporal memories might be
learned and encoded in the recurrent circuits in the visual cortical hierarchy
for predicting future video frames. This neurally inspired model operates in
the analysis-by-synthesis framework. It contains a feed-forward path that
computes and encodes spatiotemporal features of successive complexity and a
feedback path for the successive levels to project their interpretations to the
level below. Within each level, the feed-forward path and the feedback path
intersect in a recurrent gated circuit, instantiated in a LSTM module, to
generate a prediction or explanation of the incoming signals. The network
learns its internal model of the world by minimizing the errors of its
prediction of the incoming signals at each level of the hierarchy. We found
that hierarchical interaction in the network increases semantic clustering of
global movement patterns in the population codes of the units along the
hierarchy, even in the earliest module. This facilitates the learning of
relationships among movement patterns, yielding state-of-the-art performance in
long range video sequence predictions in the benchmark datasets. The network
model automatically reproduces a variety of prediction suppression and
familiarity suppression neurophysiological phenomena observed in the visual
cortex, suggesting that hierarchical prediction might indeed be an important
principle for representational learning in the visual cortex.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distance Metric Learned Collaborative Representation Classifier. (arXiv:1905.01168v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.01168">
<div class="article-summary-box-inner">
<span><p>Any generic deep machine learning algorithm is essentially a function fitting
exercise, where the network tunes its weights and parameters to learn
discriminatory features by minimizing some cost function. Though the network
tries to learn the optimal feature space, it seldom tries to learn an optimal
distance metric in the cost function, and hence misses out on an additional
layer of abstraction. We present a simple effective way of achieving this by
learning a generic Mahalanabis distance in a collaborative loss function in an
end-to-end fashion with any standard convolutional network as the feature
learner. The proposed method DML-CRC gives state-of-the-art performance on
benchmark fine-grained classification datasets CUB Birds, Oxford Flowers and
Oxford-IIIT Pets using the VGG-19 deep network. The method is network agnostic
and can be used for any similar classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Compositional Augmentations for Scene Graph Prediction. (arXiv:2007.05756v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.05756">
<div class="article-summary-box-inner">
<span><p>Inferring objects and their relationships from an image in the form of a
scene graph is useful in many applications at the intersection of vision and
language. We consider a challenging problem of compositional generalization
that emerges in this task due to a long tail data distribution. Current scene
graph generation models are trained on a tiny fraction of the distribution
corresponding to the most frequent compositions, e.g. &lt;cup, on, table&gt;.
However, test images might contain zero- and few-shot compositions of objects
and relationships, e.g. &lt;cup, on, surfboard&gt;. Despite each of the object
categories and the predicate (e.g. 'on') being frequent in the training data,
the models often fail to properly understand such unseen or rare compositions.
To improve generalization, it is natural to attempt increasing the diversity of
the training distribution. However, in the graph domain this is non-trivial. To
that end, we propose a method to synthesize rare yet plausible scene graphs by
perturbing real ones. We then propose and empirically study a model based on
conditional generative adversarial networks (GANs) that allows us to generate
visual features of perturbed scene graphs and learn from them in a joint
fashion. When evaluated on the Visual Genome dataset, our approach yields
marginal, but consistent improvements in zero- and few-shot metrics. We analyze
the limitations of our approach indicating promising directions for future
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layered Neural Rendering for Retiming People in Video. (arXiv:2009.07833v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07833">
<div class="article-summary-box-inner">
<span><p>We present a method for retiming people in an ordinary, natural video --
manipulating and editing the time in which different motions of individuals in
the video occur. We can temporally align different motions, change the speed of
certain actions (speeding up/slowing down, or entirely "freezing" people), or
"erase" selected people from the video altogether. We achieve these effects
computationally via a dedicated learning-based layered video representation,
where each frame in the video is decomposed into separate RGBA layers,
representing the appearance of different people in the video. A key property of
our model is that it not only disentangles the direct motions of each person in
the input video, but also correlates each person automatically with the scene
changes they generate -- e.g., shadows, reflections, and motion of loose
clothing. The layers can be individually retimed and recombined into a new
video, allowing us to achieve realistic, high-quality renderings of retiming
effects for real-world videos depicting complex actions and involving multiple
individuals, including dancing, trampoline jumping, or group running.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building 3D Morphable Models from a Single Scan. (arXiv:2011.12440v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12440">
<div class="article-summary-box-inner">
<span><p>We propose a method for constructing generative models of 3D objects from a
single 3D mesh. Our method produces a 3D morphable model that represents shape
and albedo in terms of Gaussian processes. We define the shape deformations in
physical (3D) space and the albedo deformations as a combination of
physical-space and color-space deformations. Whereas previous approaches have
typically built 3D morphable models from multiple high-quality 3D scans through
principal component analysis, we build 3D morphable models from a single scan
or template. As we demonstrate in the face domain, these models can be used to
infer 3D reconstructions from 2D data (inverse graphics) or 3D data
(registration). Specifically, we show that our approach can be used to perform
face recognition using only a single 3D scan (one scan total, not one per
person), and further demonstrate how multiple scans can be incorporated to
improve performance without requiring dense correspondence. Our approach
enables the synthesis of 3D morphable models for 3D object categories where
dense correspondence between multiple scans is unavailable. We demonstrate this
by constructing additional 3D morphable models for fish and birds and use them
to perform simple inverse rendering tasks. We share the code used to generate
these models and to perform our inverse rendering and registration experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Content-Preserving Unpaired Translation from Simulated to Realistic Ultrasound Images. (arXiv:2103.05745v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05745">
<div class="article-summary-box-inner">
<span><p>Interactive simulation of ultrasound imaging greatly facilitates sonography
training. Although ray-tracing based methods have shown promising results,
obtaining realistic images requires substantial modeling effort and manual
parameter tuning. In addition, current techniques still result in a significant
appearance gap between simulated images and real clinical scans. Herein we
introduce a novel content-preserving image translation framework (ConPres) to
bridge this appearance gap, while maintaining the simulated anatomical layout.
We achieve this goal by leveraging both simulated images with semantic
segmentations and unpaired in-vivo ultrasound scans. Our framework is based on
recent contrastive unpaired translation techniques and we propose a
regularization approach by learning an auxiliary segmentation-to-real image
translation task, which encourages the disentanglement of content and style. In
addition, we extend the generator to be class-conditional, which enables the
incorporation of additional losses, in particular a cyclic consistency loss, to
further improve the translation quality. Qualitative and quantitative
comparisons against state-of-the-art unpaired translation methods demonstrate
the superiority of our proposed framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collapsible Linear Blocks for Super-Efficient Super Resolution. (arXiv:2103.09404v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09404">
<div class="article-summary-box-inner">
<span><p>With the advent of smart devices that support 4K and 8K resolution, Single
Image Super Resolution (SISR) has become an important computer vision problem.
However, most super resolution deep networks are computationally very
expensive. In this paper, we propose SESR, a new class of Super-Efficient Super
Resolution networks that significantly improve image quality and reduce
computational complexity. Detailed experiments across six benchmark datasets
demonstrate that SESR achieves similar or better image quality than
state-of-the-art models while requiring 2x to 330x fewer Multiply-Accumulate
(MAC) operations. As a result, SESR can be used on constrained hardware to
perform x2 (1080p to 4K) and x4 SISR (1080p to 8K). Towards this, we simulate
hardware performance numbers for a commercial mobile Neural Processing Unit
(NPU) for 1080p to 4K (x2) and 1080p to 8K (x4) SISR. Our results highlight the
challenges faced by super resolution on AI accelerators and demonstrate that
SESR is significantly faster than existing models. Overall, SESR establishes a
new Pareto frontier on the quality (PSNR)-computation relationship for the
super resolution task. The code for this work is available at
https://github.com/ARM-software/sesr.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Track with Object Permanence. (arXiv:2103.14258v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14258">
<div class="article-summary-box-inner">
<span><p>Tracking by detection, the dominant approach for online multi-object
tracking, alternates between localization and association steps. As a result,
it strongly depends on the quality of instantaneous observations, often failing
when objects are not fully visible. In contrast, tracking in humans is
underlined by the notion of object permanence: once an object is recognized, we
are aware of its physical existence and can approximately localize it even
under full occlusions. In this work, we introduce an end-to-end trainable
approach for joint object detection and tracking that is capable of such
reasoning. We build on top of the recent CenterTrack architecture, which takes
pairs of frames as input, and extend it to videos of arbitrary length. To this
end, we augment the model with a spatio-temporal, recurrent memory module,
allowing it to reason about object locations and identities in the current
frame using all the previous history. It is, however, not obvious how to train
such an approach. We study this question on a new, large-scale, synthetic
dataset for multi-object tracking, which provides ground truth annotations for
invisible objects, and propose several approaches for supervising tracking
behind occlusions. Our model, trained jointly on synthetic and real data,
outperforms the state of the art on KITTI and MOT17 datasets thanks to its
robustness to occlusions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Vibration Tomography: Estimating Interior Material Properties from Monocular Video. (arXiv:2104.02735v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02735">
<div class="article-summary-box-inner">
<span><p>An object's interior material properties, while invisible to the human eye,
determine motion observed on its surface. We propose an approach that estimates
heterogeneous material properties of an object directly from a monocular video
of its surface vibrations. Specifically, we estimate Young's modulus and
density throughout a 3D object with known geometry. Knowledge of how these
values change across the object is useful for characterizing defects and
simulating how the object will interact with different environments.
Traditional non-destructive testing approaches, which generally estimate
homogenized material properties or the presence of defects, are expensive and
use specialized instruments. We propose an approach that leverages monocular
video to (1) measure and object's sub-pixel motion and decompose this motion
into image-space modes, and (2) directly infer spatially-varying Young's
modulus and density values from the observed image-space modes. On both
simulated and real videos, we demonstrate that our approach is able to image
material properties simply by analyzing surface motion. In particular, our
method allows us to identify unseen defects on a 2D drum head from real,
high-speed video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">X2CT-FLOW: Maximum a posteriori reconstruction using a progressive flow-based deep generative model for ultra sparse-view computed tomography in ultra low-dose protocols. (arXiv:2104.04179v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04179">
<div class="article-summary-box-inner">
<span><p>Ultra sparse-view computed tomography (CT) algorithms can reduce radiation
exposure of patients, but those algorithms lack an explicit cycle consistency
loss minimization and an explicit log-likelihood maximization in testing. Here,
we propose X2CT-FLOW for the maximum a posteriori (MAP) reconstruction of a
three-dimensional (3D) chest CT image from a single or a few two-dimensional
(2D) projection images using a progressive flow-based deep generative model,
especially for ultra low-dose protocols. The MAP reconstruction can
simultaneously optimize the cycle consistency loss and the log-likelihood. The
proposed algorithm is built upon a newly developed progressive flow-based deep
generative model, which is featured with exact log-likelihood estimation,
efficient sampling, and progressive learning. We applied X2CT-FLOW to
reconstruction of 3D chest CT images from biplanar projection images without
noise contamination (assuming a standard-dose protocol) and with strong noise
contamination (assuming an ultra low-dose protocol). With the standard-dose
protocol, our images reconstructed from 2D projected images and 3D ground-truth
CT images showed good agreement in terms of structural similarity (SSIM, 0.7675
on average), peak signal-to-noise ratio (PSNR, 25.89 dB on average), mean
absolute error (MAE, 0.02364 on average), and normalized root mean square error
(NRMSE, 0.05731 on average). Moreover, with the ultra low-dose protocol, our
images reconstructed from 2D projected images and the 3D ground-truth CT images
also showed good agreement in terms of SSIM (0.7008 on average), PSNR (23.58 dB
on average), MAE (0.02991 on average), and NRMSE (0.07349 on average).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iterative Human and Automated Identification of Wildlife Images. (arXiv:2105.02320v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02320">
<div class="article-summary-box-inner">
<span><p>Camera trapping is increasingly used to monitor wildlife, but this technology
typically requires extensive data annotation. Recently, deep learning has
significantly advanced automatic wildlife recognition. However, current methods
are hampered by a dependence on large static data sets when wildlife data is
intrinsically dynamic and involves long-tailed distributions. These two
drawbacks can be overcome through a hybrid combination of machine learning and
humans in the loop. Our proposed iterative human and automated identification
approach is capable of learning from wildlife imagery data with a long-tailed
distribution. Additionally, it includes self-updating learning that facilitates
capturing the community dynamics of rapidly changing natural systems. Extensive
experiments show that our approach can achieve a ~90% accuracy employing only
~20% of the human annotations of existing approaches. Our synergistic
collaboration of humans and machines transforms deep learning from a relatively
inefficient post-annotation tool to a collaborative on-going annotation tool
that vastly relieves the burden of human annotation and enables efficient and
constant model updates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation of Anatomical Layers and Artifacts in Intravascular Polarization Sensitive Optical Coherence Tomography Using Attending Physician and Boundary Cardinality Losses. (arXiv:2105.05137v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05137">
<div class="article-summary-box-inner">
<span><p>Intravascular ultrasound and optical coherence tomography are widely
available for characterizing coronary stenoses and provide critical vessel
parameters to optimize percutaneous intervention. Intravascular
polarization-sensitive optical coherence tomography (PS-OCT) simultaneously
provides high-resolution cross-sectional images of vascular structures while
also revealing preponderant tissue components such as collagen and smooth
muscle and thereby enhances plaque characterization. Automated interpretation
of these features promises to facilitate the objective clinical investigation
of the natural history and significance of coronary atheromas. Here, we propose
a convolutional neural network model, optimized using a new multi-term loss
function, to classify the lumen, intima, and media layers in addition to the
guidewire and plaque shadows. We demonstrate that our multi-class
classification model outperforms state-of-the-art methods in detecting the
coronary anatomical layers. Furthermore, the proposed model segments two
classes of common imaging artifacts and detects the anatomical layers within
the thickened vessel wall regions that were excluded from analysis by other
studies. The source code and the trained model are publicly available at
https://github.com/mhaft/OCTseg
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Omnimatte: Associating Objects and Their Effects in Video. (arXiv:2105.06993v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06993">
<div class="article-summary-box-inner">
<span><p>Computer vision is increasingly effective at segmenting objects in images and
videos; however, scene effects related to the objects -- shadows, reflections,
generated smoke, etc -- are typically overlooked. Identifying such scene
effects and associating them with the objects producing them is important for
improving our fundamental understanding of visual scenes, and can also assist a
variety of applications such as removing, duplicating, or enhancing objects in
video. In this work, we take a step towards solving this novel problem of
automatically associating objects with their effects in video. Given an
ordinary video and a rough segmentation mask over time of one or more subjects
of interest, we estimate an omnimatte for each subject -- an alpha matte and
color image that includes the subject along with all its related time-varying
scene elements. Our model is trained only on the input video in a
self-supervised manner, without any manual labels, and is generic -- it
produces omnimattes automatically for arbitrary objects and a variety of
effects. We show results on real-world videos containing interactions between
different types of subjects (cars, animals, people) and complex effects,
ranging from semi-transparent elements such as smoke and reflections, to fully
opaque effects such as objects attached to the subject.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding. (arXiv:2105.09996v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09996">
<div class="article-summary-box-inner">
<span><p>We present a simplified, task-agnostic multi-modal pre-training approach that
can accept either video or text input, or both for a variety of end tasks.
Existing pre-training are task-specific by adopting either a single cross-modal
encoder that requires both modalities, limiting their use for retrieval-style
end tasks or more complex multitask learning with two unimodal encoders,
limiting early cross-modal fusion. We instead introduce new pretraining masking
schemes that better mix across modalities (e.g. by forcing masks for text to
predict the closest video embeddings) while also maintaining separability (e.g.
unimodal predictions are sometimes required, without using all the input).
Experimental results show strong performance across a wider range of tasks than
any previous methods, often outperforming task-specific pre-training. Code is
made available at https://github.com/pytorch/fairseq/tree/main/examples/MMPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Deep Neural Network Calibration by Regularization and its Impact on Refinement. (arXiv:2106.09385v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09385">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have been shown to be highly miscalibrated. often they
tend to be overconfident in their predictions. It poses a significant challenge
for safety-critical systems to utilise deep neural networks (DNNs), reliably.
Many recently proposed approaches to mitigate this have demonstrated
substantial progress in improving DNN calibration. However, they hardly touch
upon refinement, which historically has been an essential aspect of
calibration. Refinement indicates separability of a network's correct and
incorrect predictions. This paper presents a theoretically and empirically
supported exposition reviewing refinement of a calibrated model. Firstly, we
show the breakdown of expected calibration error (ECE), into predicted
confidence and refinement under the assumption of over-confident predictions.
Secondly, linking with this result, we highlight that regularization based
calibration only focuses on naively reducing a model's confidence. This
logically has a severe downside to a model's refinement as correct and
incorrect predictions become tightly coupled. Lastly, connecting refinement
with ECE also provides support to existing refinement based approaches which
improve calibration but do not explain the reasoning behind it. We support our
claims through rigorous empirical evaluations of many state of the art
calibration approaches on widely used datasets and neural networks. We find
that many calibration approaches with the likes of label smoothing, mixup etc.
lower the usefulness of a DNN by degrading its refinement. Even under natural
data shift, this calibration-refinement trade-off holds for the majority of
calibration methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual-Stream Reciprocal Disentanglement Learning for Domain Adaptation Person Re-Identification. (arXiv:2106.13929v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13929">
<div class="article-summary-box-inner">
<span><p>Since human-labeled samples are free for the target set, unsupervised person
re-identification (Re-ID) has attracted much attention in recent years, by
additionally exploiting the source set. However, due to the differences on
camera styles, illumination and backgrounds, there exists a large gap between
source domain and target domain, introducing a great challenge on cross-domain
matching. To tackle this problem, in this paper we propose a novel method named
Dual-stream Reciprocal Disentanglement Learning (DRDL), which is quite
efficient in learning domain-invariant features. In DRDL, two encoders are
first constructed for id-related and id-unrelated feature extractions, which
are respectively measured by their associated classifiers. Furthermore,
followed by an adversarial learning strategy, both streams reciprocally and
positively effect each other, so that the id-related features and id-unrelated
features are completely disentangled from a given image, allowing the encoder
to be powerful enough to obtain the discriminative but domain-invariant
features. In contrast to existing approaches, our proposed method is free from
image generation, which not only reduces the computational complexity
remarkably, but also removes redundant information from id-related features.
Extensive experiments substantiate the superiority of our proposed method
compared with the state-of-the-arts. The source code has been released in
https://github.com/lhf12278/DRDL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Xformers: Efficient Attention for Image Classification. (arXiv:2107.02239v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02239">
<div class="article-summary-box-inner">
<span><p>Although transformers have become the neural architectures of choice for
natural language processing, they require orders of magnitude more training
data, GPU memory, and computations in order to compete with convolutional
neural networks for computer vision. The attention mechanism of transformers
scales quadratically with the length of the input sequence, and unrolled images
have long sequence lengths. Plus, transformers lack an inductive bias that is
appropriate for images. We tested three modifications to vision transformer
(ViT) architectures that address these shortcomings. Firstly, we alleviate the
quadratic bottleneck by using linear attention mechanisms, called X-formers
(such that, X in {Performer, Linformer, Nystr\"omformer}), thereby creating
Vision X-formers (ViXs). This resulted in up to a seven times reduction in the
GPU memory requirement. We also compared their performance with FNet and
multi-layer perceptron mixers, which further reduced the GPU memory
requirement. Secondly, we introduced an inductive bias for images by replacing
the initial linear embedding layer by convolutional layers in ViX, which
significantly increased classification accuracy without increasing the model
size. Thirdly, we replaced the learnable 1D position embeddings in ViT with
Rotary Position Embedding (RoPE), which increases the classification accuracy
for the same model size. We believe that incorporating such changes can
democratize transformers by making them accessible to those with limited data
and computing resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Image Synthesis from Intuitive User Input: A Review and Perspectives. (arXiv:2107.04240v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04240">
<div class="article-summary-box-inner">
<span><p>In many applications of computer graphics, art and design, it is desirable
for a user to provide intuitive non-image input, such as text, sketch, stroke,
graph or layout, and have a computer system automatically generate
photo-realistic images that adhere to the input content. While classic works
that allow such automatic image content generation have followed a framework of
image retrieval and composition, recent advances in deep generative models such
as generative adversarial networks (GANs), variational autoencoders (VAEs), and
flow-based methods have enabled more powerful and versatile image generation
tasks. This paper reviews recent works for image synthesis given intuitive user
input, covering advances in input versatility, image generation methodology,
benchmark datasets, and evaluation metrics. This motivates new perspectives on
input representation and interactivity, cross pollination between major image
generation paradigms, and evaluation and comparison of generation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable, Axiomatic Explanations of Deep Alzheimer's Diagnosis from Heterogeneous Data. (arXiv:2107.05997v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05997">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks (DNNs) have an enormous potential to learn from complex
biomedical data. In particular, DNNs have been used to seamlessly fuse
heterogeneous information from neuroanatomy, genetics, biomarkers, and
neuropsychological tests for highly accurate Alzheimer's disease diagnosis. On
the other hand, their black-box nature is still a barrier for the adoption of
such a system in the clinic, where interpretability is absolutely essential. We
propose Shapley Value Explanation of Heterogeneous Neural Networks (SVEHNN) for
explaining the Alzheimer's diagnosis made by a DNN from the 3D point cloud of
the neuroanatomy and tabular biomarkers. Our explanations are based on the
Shapley value, which is the unique method that satisfies all fundamental axioms
for local explanations previously established in the literature. Thus, SVEHNN
has many desirable characteristics that previous work on interpretability for
medical decision making is lacking. To avoid the exponential time complexity of
the Shapley value, we propose to transform a given DNN into a Lightweight
Probabilistic Deep Network without re-training, thus achieving a complexity
only quadratic in the number of features. In our experiments on synthetic and
real data, we show that we can closely approximate the exact Shapley value with
a dramatically reduced runtime and can reveal the hidden knowledge the network
has learned from the data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Neural Human Performance Rendering from Sparse RGBD Videos. (arXiv:2107.06505v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06505">
<div class="article-summary-box-inner">
<span><p>Recent neural rendering approaches for human activities achieve remarkable
view synthesis results, but still rely on dense input views or dense training
with all the capture frames, leading to deployment difficulty and inefficient
training overload. However, existing advances will be ill-posed if the input is
both spatially and temporally sparse. To fill this gap, in this paper we
propose a few-shot neural human rendering approach (FNHR) from only sparse RGBD
inputs, which exploits the temporal and spatial redundancy to generate
photo-realistic free-view output of human activities. Our FNHR is trained only
on the key-frames which expand the motion manifold in the input sequences. We
introduce a two-branch neural blending to combine the neural point render and
classical graphics texturing pipeline, which integrates reliable observations
over sparse key-frames. Furthermore, we adopt a patch-based adversarial
training process to make use of the local redundancy and avoids over-fitting to
the key-frames, which generates fine-detailed rendering results. Extensive
experiments demonstrate the effectiveness of our approach to generate
high-quality free view-point results for challenging human performances under
the sparse setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep graph matching meets mixed-integer linear programming: Relax at your own risk ?. (arXiv:2108.00394v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00394">
<div class="article-summary-box-inner">
<span><p>Graph matching is an important problem that has received widespread
attention, especially in the field of computer vision. Recently,
state-of-the-art methods seek to incorporate graph matching with deep learning.
However, there is no research to explain what role the graph matching algorithm
plays in the model. Therefore, we propose an approach integrating a MILP
formulation of the graph matching problem. This formulation is solved to
optimal and it provides inherent baseline. Meanwhile, similar approaches are
derived by releasing the optimal guarantee of the graph matching solver and by
introducing a quality level. This quality level controls the quality of the
solutions provided by the graph matching solver. In addition, several
relaxations of the graph matching problem are put to the test. Our experimental
evaluation gives several theoretical insights and guides the direction of deep
graph matching methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Free Lunch for Co-Saliency Detection: Context Adjustment. (arXiv:2108.02093v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02093">
<div class="article-summary-box-inner">
<span><p>We unveil a long-standing problem in the prevailing co-saliency detection
systems: there is indeed inconsistency between training and testing.
Constructing a high-quality co-saliency detection dataset involves
time-consuming and labor-intensive pixel-level labeling, which has forced most
recent works to rely instead on semantic segmentation or saliency detection
datasets for training. However, the lack of proper co-saliency and the absence
of multiple foreground objects in these datasets can lead to spurious
variations and inherent biases learned by models. To tackle this, we introduce
the idea of counterfactual training through context adjustment and propose a
"cost-free" group-cut-paste (GCP) procedure to leverage off-the-shelf images
and synthesize new samples. Following GCP, we collect a novel dataset called
Context Adjustment Training (CAT). CAT consists of 33,500 images, which is four
times larger than the current co-saliency detection datasets. All samples are
automatically annotated with high-quality mask annotations, object categories,
and edge maps. Extensive experiments on recent benchmarks are conducted, show
that CAT can improve various state-of-the-art models by a large margin (5% ~
25%). We hope that the scale, diversity, and quality of our dataset can benefit
researchers in this area and beyond. Our dataset will be publicly accessible
through our project page.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MEDIC: A Multi-Task Learning Dataset for Disaster Image Classification. (arXiv:2108.12828v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12828">
<div class="article-summary-box-inner">
<span><p>Recent research in disaster informatics demonstrates a practical and
important use case of artificial intelligence to save human lives and
sufferings during post-natural disasters based on social media contents (text
and images). While notable progress has been made using texts, research on
exploiting the images remains relatively under-explored. To advance the
image-based approach, we propose MEDIC (available at:
https://crisisnlp.qcri.org/medic/index.html), which is the largest social media
image classification dataset for humanitarian response consisting of 71,198
images to address four different tasks in a multi-task learning setup. This is
the first dataset of its kind: social media image, disaster response, and
multi-task learning research. An important property of this dataset is its high
potential to contribute research on multi-task learning, which recently
receives much interest from the machine learning community and has shown
remarkable results in terms of memory, inference speed, performance, and
generalization capability. Therefore, the proposed dataset is an important
resource for advancing image-based disaster management and multi-task machine
learning research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Human Deformation Transfer. (arXiv:2109.01588v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01588">
<div class="article-summary-box-inner">
<span><p>We consider the problem of human deformation transfer, where the goal is to
retarget poses between different characters. Traditional methods that tackle
this problem require a clear definition of the pose, and use this definition to
transfer poses between characters. In this work, we take a different approach
and transform the identity of a character into a new identity without modifying
the character's pose. This offers the advantage of not having to define
equivalences between 3D human poses, which is not straightforward as poses tend
to change depending on the identity of the character performing them, and as
their meaning is highly contextual. To achieve the deformation transfer, we
propose a neural encoder-decoder architecture where only identity information
is encoded and where the decoder is conditioned on the pose. We use pose
independent representations, such as isometry-invariant shape characteristics,
to represent identity features. Our model uses these features to supervise the
prediction of offsets from the deformed pose to the result of the transfer. We
show experimentally that our method outperforms state-of-the-art methods both
quantitatively and qualitatively, and generalises better to poses not seen
during training. We also introduce a fine-tuning step that allows to obtain
competitive results for extreme identities, and allows to transfer simple
clothing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Moving Object Detection for Event-based Vision using k-means Clustering. (arXiv:2109.01879v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01879">
<div class="article-summary-box-inner">
<span><p>Moving object detection is important in computer vision. Event-based cameras
are bio-inspired cameras that work by mimicking the working of the human eye.
These cameras have multiple advantages over conventional frame-based cameras,
like reduced latency, HDR, reduced motion blur during high motion, low power
consumption, etc. In spite of these advantages, event-based cameras are
noise-sensitive and have low resolution. Moreover, the task of moving object
detection in these cameras is difficult, as event-based sensors lack useful
visual features like texture and color. In this paper, we investigate the
application of the k-means clustering technique in detecting moving objects in
event-based data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Event Detection based on Spatio-Temporal Latent Action Unit using Skeletal Information. (arXiv:2109.02376v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02376">
<div class="article-summary-box-inner">
<span><p>This paper propose a novel dictionary learning approach to detect event
action using skeletal information extracted from RGBD video. The event action
is represented as several latent atoms and composed of latent spatial and
temporal attributes. We perform the method at the example of fall event
detection. The skeleton frames are clustered by an initial K-means method. Each
skeleton frame is assigned with a varying weight parameter and fed into our
Gradual Online Dictionary Learning (GODL) algorithm. During the training
process, outlier frames will be gradually filtered by reducing the weight that
is inversely proportional to a cost. In order to strictly distinguish the event
action from similar actions and robustly acquire its action unit, we build a
latent unit temporal structure for each sub-action. We evaluate the proposed
method on parts of the NTURGB+D dataset, which includes 209 fall videos, 405
ground-lift videos, 420 sit-down videos, and 280 videos of 46 otheractions. We
present the experimental validation of the achieved accuracy, recall and
precision. Our approach achieves the bestperformance on precision and accuracy
of human fall event detection, compared with other existing dictionary learning
methods. With increasing noise ratio, our method remains the highest accuracy
and the lowest variance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">nnFormer: Interleaved Transformer for Volumetric Segmentation. (arXiv:2109.03201v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03201">
<div class="article-summary-box-inner">
<span><p>Transformers, the default model of choices in natural language processing,
have drawn scant attention from the medical imaging community. Given the
ability to exploit long-term dependencies, transformers are promising to help
atypical convolutional neural networks (convnets) to overcome its inherent
shortcomings of spatial inductive bias. However, most of recently proposed
transformer-based segmentation approaches simply treated transformers as
assisted modules to help encode global context into convolutional
representations without investigating how to optimally combine self-attention
(i.e., the core of transformers) with convolution. To address this issue, in
this paper, we introduce nnFormer (i.e., Not-aNother transFormer), a powerful
segmentation model with an interleaved architecture based on empirical
combination of self-attention and convolution. In practice, nnFormer learns
volumetric representations from 3D local volumes. Compared to the naive
voxel-level self-attention implementation, such volume-based operations help to
reduce the computational complexity by approximate 98% and 99.5% on Synapse and
ACDC datasets, respectively. In comparison to prior-art network configurations,
nnFormer achieves tremendous improvements over previous transformer-based
methods on two commonly used datasets Synapse and ACDC. For instance, nnFormer
outperforms Swin-UNet by over 7 percents on Synapse. Even when compared to
nnUNet, currently the best performing fully-convolutional medical segmentation
network, nnFormer still provides slightly better performance on Synapse and
ACDC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Rotation Invariance in Object Detection. (arXiv:2109.13488v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13488">
<div class="article-summary-box-inner">
<span><p>Rotation augmentations generally improve a model's invariance/equivariance to
rotation - except in object detection. In object detection the shape is not
known, therefore rotation creates a label ambiguity. We show that the de-facto
method for bounding box label rotation, the Largest Box Method, creates very
large labels, leading to poor performance and in many cases worse performance
than using no rotation at all. We propose a new method of rotation augmentation
that can be implemented in a few lines of code. First, we create a
differentiable approximation of label accuracy and show that axis-aligning the
bounding box around an ellipse is optimal. We then introduce Rotation
Uncertainty (RU) Loss, allowing the model to adapt to the uncertainty of the
labels. On five different datasets (including COCO, PascalVOC, and Transparent
Object Bin Picking), this approach improves the rotational invariance of both
one-stage and two-stage architectures when measured with AP, AP50, and AP75.
The code is available at https://github.com/akasha-imaging/ICCV2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding. (arXiv:2109.14084v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14084">
<div class="article-summary-box-inner">
<span><p>We present VideoCLIP, a contrastive approach to pre-train a unified model for
zero-shot video and text understanding, without using any labels on downstream
tasks. VideoCLIP trains a transformer for video and text by contrasting
temporally overlapping positive video-text pairs with hard negatives from
nearest neighbor retrieval. Our experiments on a diverse series of downstream
tasks, including sequence-level text-video retrieval, VideoQA, token-level
action localization, and action segmentation reveal state-of-the-art
performance, surpassing prior work, and in some cases even outperforming
supervised approaches. Code is made available at
https://github.com/pytorch/fairseq/tree/main/examples/MMPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning for 3D Medical Image Analysis using 3D SimCLR and Monte Carlo Dropout. (arXiv:2109.14288v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14288">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning methods can be used to learn meaningful
representations from unlabeled data that can be transferred to supervised
downstream tasks to reduce the need for labeled data. In this paper, we propose
a 3D self-supervised method that is based on the contrastive (SimCLR) method.
Additionally, we show that employing Bayesian neural networks (with Monte-Carlo
Dropout) during the inference phase can further enhance the results on the
downstream tasks. We showcase our models on two medical imaging segmentation
tasks: i) Brain Tumor Segmentation from 3D MRI, ii) Pancreas Tumor Segmentation
from 3D CT. Our experimental results demonstrate the benefits of our proposed
methods in both downstream data-efficiency and performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross Modal Focal Loss for RGBD Face Anti-Spoofing. (arXiv:2103.00948v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00948">
<div class="article-summary-box-inner">
<span><p>Automatic methods for detecting presentation attacks are essential to ensure
the reliable use of facial recognition technology. Most of the methods
available in the literature for presentation attack detection (PAD) fails in
generalizing to unseen attacks. In recent years, multi-channel methods have
been proposed to improve the robustness of PAD systems. Often, only a limited
amount of data is available for additional channels, which limits the
effectiveness of these methods. In this work, we present a new framework for
PAD that uses RGB and depth channels together with a novel loss function. The
new architecture uses complementary information from the two modalities while
reducing the impact of overfitting. Essentially, a cross-modal focal loss
function is proposed to modulate the loss contribution of each channel as a
function of the confidence of individual channels. Extensive evaluations in two
publicly available datasets demonstrate the effectiveness of the proposed
approach.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-04 23:01:54.895913749 UTC">2021-10-04 23:01:54 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>