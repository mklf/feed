<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-02-08T01:30:00Z">02-08</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity Detection using Zero and One Shot Learning. (arXiv:2202.02394v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02394">
<div class="article-summary-box-inner">
<span><p>Large Language Models have been successful in a wide variety of Natural
Language Processing tasks by capturing the compositionality of the text
representations. In spite of their great success, these vector representations
fail to capture meaning of idiomatic multi-word expressions (MWEs). In this
paper, we focus on the detection of idiomatic expressions by using binary
classification. We use a dataset consisting of the literal and idiomatic usage
of MWEs in English and Portuguese. Thereafter, we perform the classification in
two different settings: zero shot and one shot, to determine if a given
sentence contains an idiom or not. N shot classification for this task is
defined by N number of common idioms between the training and testing sets. In
this paper, we train multiple Large Language Models in both the settings and
achieve an F1 score (macro) of 0.73 for the zero shot setting and an F1 score
(macro) of 0.85 for the one shot setting. An implementation of our work can be
found at
https://github.com/ashwinpathak20/Idiomaticity_Detection_Using_Few_Shot_Learning .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pir\'a: A Bilingual Portuguese-English Dataset for Question-Answering about the Ocean. (arXiv:2202.02398v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02398">
<div class="article-summary-box-inner">
<span><p>Current research in natural language processing is highly dependent on
carefully produced corpora. Most existing resources focus on English; some
resources focus on languages such as Chinese and French; few resources deal
with more than one language. This paper presents the Pir\'a dataset, a large
set of questions and answers about the ocean and the Brazilian coast both in
Portuguese and English. Pir\'a is, to the best of our knowledge, the first QA
dataset with supporting texts in Portuguese, and, perhaps more importantly, the
first bilingual QA dataset that includes this language. The Pir\'a dataset
consists of 2261 properly curated question/answer (QA) sets in both languages.
The QA sets were manually created based on two corpora: abstracts related to
the Brazilian coast and excerpts of United Nation reports about the ocean. The
QA sets were validated in a peer-review process with the dataset contributors.
We discuss some of the advantages as well as limitations of Pir\'a, as this new
resource can support a set of tasks in NLP such as question-answering,
information retrieval, and machine translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers and the representation of biomedical background knowledge. (arXiv:2202.02432v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02432">
<div class="article-summary-box-inner">
<span><p>BioBERT and BioMegatron are Transformers models adapted for the biomedical
domain based on publicly available biomedical corpora. As such, they have the
potential to encode large-scale biological knowledge. We investigate the
encoding and representation of biological knowledge in these models, and its
potential utility to support inference in cancer precision medicine - namely,
the interpretation of the clinical significance of genomic alterations. We
compare the performance of different transformer baselines; we use probing to
determine the consistency of encodings for distinct entities; and we use
clustering methods to compare and contrast the internal properties of the
embeddings for genes, variants, drugs and diseases. We show that these models
do indeed encode biological knowledge, although some of this is lost in
fine-tuning for specific tasks. Finally, we analyse how the models behave with
regard to biases and imbalances in the dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Logic Analogy Learning. (arXiv:2202.02436v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02436">
<div class="article-summary-box-inner">
<span><p>Letter-string analogy is an important analogy learning task which seems to be
easy for humans but very challenging for machines. The main idea behind current
approaches to solving letter-string analogies is to design heuristic rules for
extracting analogy structures and constructing analogy mappings. However, one
key problem is that it is difficult to build a comprehensive and exhaustive set
of analogy structures which can fully describe the subtlety of analogies. This
problem makes current approaches unable to handle complicated letter-string
analogy problems. In this paper, we propose Neural logic analogy learning
(Noan), which is a dynamic neural architecture driven by differentiable logic
reasoning to solve analogy problems. Each analogy problem is converted into
logical expressions consisting of logical variables and basic logical
operations (AND, OR, and NOT). More specifically, Noan learns the logical
variables as vector embeddings and learns each logical operation as a neural
module. In this way, the model builds computational graph integrating neural
network with logical reasoning to capture the internal logical structure of the
input letter strings. The analogy learning problem then becomes a True/False
evaluation problem of the logical expressions. Experiments show that our
machine learning-based Noan approach outperforms state-of-the-art approaches on
standard letter-string analogy benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Similarity Computing Model Based on Multi Model Fine-Grained Nonlinear Fusion. (arXiv:2202.02476v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02476">
<div class="article-summary-box-inner">
<span><p>Natural language processing (NLP) task has achieved excellent performance in
many fields, including semantic understanding, automatic summarization, image
recognition and so on. However, most of the neural network models for NLP
extract the text in a fine-grained way, which is not conducive to grasp the
meaning of the text from a global perspective. To alleviate the problem, the
combination of the traditional statistical method and deep learning model as
well as a novel model based on multi model nonlinear fusion are proposed in
this paper. The model uses the Jaccard coefficient based on part of speech,
Term Frequency-Inverse Document Frequency (TF-IDF) and word2vec-CNN algorithm
to measure the similarity of sentences respectively. According to the
calculation accuracy of each model, the normalized weight coefficient is
obtained and the calculation results are compared. The weighted vector is input
into the fully connected neural network to give the final classification
results. As a result, the statistical sentence similarity evaluation algorithm
reduces the granularity of feature extraction, so it can grasp the sentence
features globally. Experimental results show that the matching of sentence
similarity calculation method based on multi model nonlinear fusion is 84%, and
the F1 value of the model is 75%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A simple language-agnostic yet very strong baseline system for hate speech and offensive content identification. (arXiv:2202.02511v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02511">
<div class="article-summary-box-inner">
<span><p>For automatically identifying hate speech and offensive content in tweets, a
system based on a classical supervised algorithm only fed with character
n-grams, and thus completely language-agnostic, is proposed by the SATLab team.
After its optimization in terms of the feature weighting and the classifier
parameters, it reached, in the multilingual HASOC 2021 challenge, a medium
performance level in English, the language for which it is easy to develop deep
learning approaches relying on many external linguistic resources, but a far
better level for the two less resourced language, Hindi and Marathi. It ends
even first when performances are averaged over the three tasks in these
languages, outperforming many deep learning approaches. These performances
suggest that it is an interesting reference level to evaluate the benefits of
using more complex approaches such as deep learning or taking into account
complementary resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Automated Sarcasm Detection on Twitter. (arXiv:2202.02516v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02516">
<div class="article-summary-box-inner">
<span><p>Automatic sarcasm detection is a growing field in computer science. Short
text messages are increasingly used for communication, especially over social
media platforms such as Twitter. Due to insufficient or missing context,
unidentified sarcasm in these messages can invert the meaning of a statement,
leading to confusion and communication failures. This paper covers a variety of
current methods used for sarcasm detection, including detection by context,
posting history and machine learning models. Additionally, a shift towards deep
learning methods is observable, likely due to the benefit of using a model with
induced instead of discrete features combined with the innovation of
transformers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEAPMood: Light and Efficient Architecture to Predict Mood with Genetic Algorithm driven Hyperparameter Tuning. (arXiv:2202.02522v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02522">
<div class="article-summary-box-inner">
<span><p>Accurate and automatic detection of mood serves as a building block for use
cases like user profiling which in turn power applications such as advertising,
recommendation systems, and many more. One primary source indicative of an
individual's mood is textual data. While there has been extensive research on
emotion recognition, the field of mood prediction has been barely explored. In
addition, very little work is done in the area of on-device inferencing, which
is highly important from the user privacy point of view. In this paper, we
propose for the first time, an on-device deep learning approach for mood
prediction from textual data, LEAPMood. We use a novel on-device
deployment-focused objective function for hyperparameter tuning based on the
Genetic Algorithm (GA) and optimize the parameters concerning both performance
and size. LEAPMood consists of Emotion Recognition in Conversion (ERC) as the
first building block followed by mood prediction using K-means clustering. We
show that using a combination of character embedding, phonetic hashing, and
attention along with Conditional Random Fields (CRF), results in a performance
closely comparable to that of the current State-Of-the-Art with a significant
reduction in model size (&gt; 90%) for the task of ERC. We achieve a Micro F1
score of 62.05% with a memory footprint of a mere 1.67MB on the DailyDialog
dataset. Furthermore, we curate a dataset for the task of mood prediction
achieving a Macro F1-score of 72.12% with LEAPMood.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aspect-based Sentiment Analysis through EDU-level Attentions. (arXiv:2202.02535v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02535">
<div class="article-summary-box-inner">
<span><p>A sentence may express sentiments on multiple aspects. When these aspects are
associated with different sentiment polarities, a model's accuracy is often
adversely affected. We observe that multiple aspects in such hard sentences are
mostly expressed through multiple clauses, or formally known as elementary
discourse units (EDUs), and one EDU tends to express a single aspect with
unitary sentiment towards that aspect. In this paper, we propose to consider
EDU boundaries in sentence modeling, with attentions at both word and EDU
levels. Specifically, we highlight sentiment-bearing words in EDU through
word-level sparse attention. Then at EDU level, we force the model to attend to
the right EDU for the right aspect, by using EDU-level sparse attention and
orthogonal regularization. Experiments on three benchmark datasets show that
our simple EDU-Attention model outperforms state-of-the-art baselines. Because
EDU can be automatically segmented with high accuracy, our model can be applied
to sentences directly without the need of manual EDU boundary annotation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimization of a Real-Time Wavelet-Based Algorithm for Improving Speech Intelligibility. (arXiv:2202.02545v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02545">
<div class="article-summary-box-inner">
<span><p>The optimization of a wavelet-based algorithm to improve speech
intelligibility is reported. The discrete-time speech signal is split into
frequency sub-bands via a multi-level discrete wavelet transform. Various gains
are applied to the sub-band signals before they are recombined to form a
modified version of the speech. The sub-band gains are adjusted while keeping
the overall signal energy unchanged, and the speech intelligibility under
various background interference and simulated hearing loss conditions is
enhanced and evaluated objectively and quantitatively using Google
Speech-to-Text transcription. For English and Chinese noise-free speech,
overall intelligibility is improved, and the transcription accuracy can be
increased by as much as 80 percentage points by reallocating the spectral
energy toward the mid-frequency sub-bands, effectively increasing the
consonant-vowel intensity ratio. This is reasonable since the consonants are
relatively weak and of short duration, which are therefore the most likely to
become indistinguishable in the presence of background noise or high-frequency
hearing impairment. For speech already corrupted by noise, improving
intelligibility is challenging but still realizable. The proposed algorithm is
implementable for real-time signal processing and comparatively simpler than
previous algorithms. Potential applications include speech enhancement, hearing
aids, machine listening, and a better understanding of speech intelligibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LST: Lexicon-Guided Self-Training for Few-Shot Text Classification. (arXiv:2202.02566v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02566">
<div class="article-summary-box-inner">
<span><p>Self-training provides an effective means of using an extremely small amount
of labeled data to create pseudo-labels for unlabeled data. Many
state-of-the-art self-training approaches hinge on different regularization
methods to prevent overfitting and improve generalization. Yet they still rely
heavily on predictions initially trained with the limited labeled data as
pseudo-labels and are likely to put overconfident label belief on erroneous
classes depending on the first prediction. To tackle this issue in text
classification, we introduce LST, a simple self-training method that uses a
lexicon to guide the pseudo-labeling mechanism in a linguistically-enriched
manner. We consistently refine the lexicon by predicting confidence of the
unseen data to teach pseudo-labels better in the training iterations. We
demonstrate that this simple yet well-crafted lexical knowledge achieves
1.0-2.0% better performance on 30 labeled samples per class for five benchmark
datasets than the current state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Fine-Tuning of Transformer-Based Language Models for Named Entity Recognition. (arXiv:2202.02617v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02617">
<div class="article-summary-box-inner">
<span><p>The current standard approach for fine-tuning transformer-based language
models includes a fixed number of training epochs and a linear learning rate
schedule. In order to obtain a near-optimal model for the given downstream
task, a search in optimization hyperparameter space is usually required. In
particular, the number of training epochs needs to be adjusted to the dataset
size. In this paper, we introduce adaptive fine-tuning, which is an alternative
approach that uses early stopping and a custom learning rate schedule to
dynamically adjust the number of training epochs to the dataset size. For the
example use case of named entity recognition, we show that our approach not
only makes hyperparameter search with respect to the number of training epochs
redundant, but also leads to improved results in terms of performance,
stability and efficiency. This holds true especially for small datasets, where
we outperform the state-of-the-art fine-tuning method by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Probabilistic Models in Text Classification via Active Learning. (arXiv:2202.02629v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02629">
<div class="article-summary-box-inner">
<span><p>When using text data, social scientists often classify documents in order to
use the resulting document labels as an outcome or predictor. Since it is
prohibitively costly to label a large number of documents manually, automated
text classification has become a standard tool. However, current approaches for
text classification do not take advantage of all the data at one's disposal. We
propose a fast new model for text classification that combines information from
both labeled and unlabeled data with an active learning component, where a
human iteratively labels documents that the algorithm is least certain about.
Using text data from Wikipedia discussion pages, BBC News articles, historical
US Supreme Court opinions, and human rights abuse allegations, we show that by
introducing information about the structure of unlabeled data and iteratively
labeling uncertain documents, our model improves performance relative to
classifiers that (a) only use information from labeled data and (b) randomly
decide which documents to label at the cost of manually labelling a small
number of documents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Hate Speech and Offensive Content Detection using Modified Cross-entropy Loss. (arXiv:2202.02635v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02635">
<div class="article-summary-box-inner">
<span><p>The number of increased social media users has led to a lot of people
misusing these platforms to spread offensive content and use hate speech.
Manual tracking the vast amount of posts is impractical so it is necessary to
devise automated methods to identify them quickly. Large language models are
trained on a lot of data and they also make use of contextual embeddings. We
fine-tune the large language models to help in our task. The data is also quite
unbalanced; so we used a modified cross-entropy loss to tackle the issue. We
observed that using a model which is fine-tuned in hindi corpora performs
better. Our team (HNLP) achieved the macro F1-scores of 0.808, 0.639 in English
Subtask A and English Subtask B respectively. For Hindi Subtask A, Hindi
Subtask B our team achieved macro F1-scores of 0.737, 0.443 respectively in
HASOC 2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification on Sentence Embeddings for Legal Assistance. (arXiv:2202.02639v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02639">
<div class="article-summary-box-inner">
<span><p>Legal proceedings take plenty of time and also cost a lot. The lawyers have
to do a lot of work in order to identify the different sections of prior cases
and statutes. The paper tries to solve the first tasks in AILA2021 (Artificial
Intelligence for Legal Assistance) that will be held in FIRE2021 (Forum for
Information Retrieval Evaluation). The task is to semantically segment the
document into different assigned one of the 7 predefined labels or "rhetorical
roles." The paper uses BERT to obtain the sentence embeddings from a sentence,
and then a linear classifier is used to output the final prediction. The
experiments show that when more weightage is assigned to the class with the
highest frequency, the results are better than those when more weightage is
given to the class with a lower frequency. In task 1, the team legalNLP
obtained a F1 score of 0.22.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RerrFact: Reduced Evidence Retrieval Representations for Scientific Claim Verification. (arXiv:2202.02646v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02646">
<div class="article-summary-box-inner">
<span><p>Exponential growth in digital information outlets and the race to publish has
made scientific misinformation more prevalent than ever. However, the task to
fact-verify a given scientific claim is not straightforward even for
researchers. Scientific claim verification requires in-depth knowledge and
great labor from domain experts to substantiate supporting and refuting
evidence from credible scientific sources. The SciFact dataset and
corresponding task provide a benchmarking leaderboard to the community to
develop automatic scientific claim verification systems via extracting and
assimilating relevant evidence rationales from source abstracts. In this work,
we propose a modular approach that sequentially carries out binary
classification for every prediction subtask as in the SciFact leaderboard. Our
simple classifier-based approach uses reduced abstract representations to
retrieve relevant abstracts. These are further used to train the relevant
rationale-selection model. Finally, we carry out two-step stance predictions
that first differentiate non-relevant rationales and then identify supporting
or refuting rationales for a given claim. Experimentally, our system RerrFact
with no fine-tuning, simple design, and a fraction of model parameters fairs
competitively on the leaderboard against large-scale, modular, and joint
modeling approaches. We make our codebase available at
https://github.com/ashishrana160796/RerrFact.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ethics, Rules of Engagement, and AI: Neural Narrative Mapping Using Large Transformer Language Models. (arXiv:2202.02647v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02647">
<div class="article-summary-box-inner">
<span><p>The problem of determining if a military unit has correctly understood an
order and is properly executing on it is one that has bedeviled military
planners throughout history. The advent of advanced language models such as
OpenAI's GPT-series offers new possibilities for addressing this problem. This
paper presents a mechanism to harness the narrative output of large language
models and produce diagrams or "maps" of the relationships that are latent in
the weights of such models as the GPT-3. The resulting "Neural Narrative Maps"
(NNMs), are intended to provide insight into the organization of information,
opinion, and belief in the model, which in turn provide means to understand
intent and response in the context of physical distance. This paper discusses
the problem of mapping information spaces in general, and then presents a
concrete implementation of this concept in the context of OpenAI's GPT-3
language model for determining if a subordinate is following a commander's
intent in a high-risk situation. The subordinate's locations within the NNM
allow a novel capability to evaluate the intent of the subordinate with respect
to the commander. We show that is is possible not only to determine if they are
nearby in narrative space, but also how they are oriented, and what
"trajectory" they are on. Our results show that our method is able to produce
high-quality maps, and demonstrate new ways of evaluating intent more
generally.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models. (arXiv:2202.02664v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02664">
<div class="article-summary-box-inner">
<span><p>Recent research has shown the existence of significant redundancy in large
Transformer models. One can prune the redundant parameters without
significantly sacrificing the generalization performance. However, we question
whether the redundant parameters could have contributed more if they were
properly trained. To answer this question, we propose a novel training strategy
that encourages all parameters to be trained sufficiently. Specifically, we
adaptively adjust the learning rate for each parameter according to its
sensitivity, a robust gradient-based measure reflecting this parameter's
contribution to the model performance. A parameter with low sensitivity is
redundant, and we improve its fitting by increasing its learning rate. In
contrast, a parameter with high sensitivity is well-trained, and we regularize
it by decreasing its learning rate to prevent further overfitting. We conduct
extensive experiments on natural language understanding, neural machine
translation, and image classification to demonstrate the effectiveness of the
proposed schedule. Analysis shows that the proposed schedule indeed reduces the
redundancy and improves generalization performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Effective is Incongruity? Implications for Code-mix Sarcasm Detection. (arXiv:2202.02702v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02702">
<div class="article-summary-box-inner">
<span><p>The presence of sarcasm in conversational systems and social media like
chatbots, Facebook, Twitter, etc. poses several challenges for downstream NLP
tasks. This is attributed to the fact that the intended meaning of a sarcastic
text is contrary to what is expressed. Further, the use of code-mix language to
express sarcasm is increasing day by day. Current NLP techniques for code-mix
data have limited success due to the use of different lexicon, syntax, and
scarcity of labeled corpora. To solve the joint problem of code-mixing and
sarcasm detection, we propose the idea of capturing incongruity through
sub-word level embeddings learned via fastText. Empirical results shows that
our proposed model achieves F1-score on code-mix Hinglish dataset comparable to
pretrained multilingual models while training 10x faster and using a lower
memory footprint
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating natural language processing models with generalization metrics that do not need access to any training or testing data. (arXiv:2202.02842v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02842">
<div class="article-summary-box-inner">
<span><p>The search for effective and robust generalization metrics has been the focus
of recent theoretical and empirical work.
</p>
<p>In this paper, we discuss the performance of natural language processing
(NLP) models, and we evaluate various existing and novel generalization
metrics.
</p>
<p>Compared to prior studies, we
</p>
<p>(i) focus on NLP instead of computer vision (CV),
</p>
<p>(ii) focus on generalization metrics that predict test error instead of the
generalization gap,
</p>
<p>(iii) focus on generalization metrics that do not need the access to data,
and
</p>
<p>(iv) focus on the heavy-tail (HT) phenomenon that has received comparatively
less attention in the study of deep neural networks (NNs).
</p>
<p>We extend recent HT-based work which focuses on power law (PL) distributions,
and we study exponential (EXP) and exponentially truncated power law (E-TPL)
fitting to the empirical spectral densities (ESDs) of weight matrices.
</p>
<p>Our detailed empirical studies show that
</p>
<p>(i) \emph{shape metrics}, or the metrics obtained from fitting the shape of
the ESDs, perform uniformly better at predicting generalization performance
than \emph{scale metrics} commonly studied in the literature, as measured by
the \emph{average} rank correlations with the generalization performance for
all of our experiments;
</p>
<p>(ii) among forty generalization metrics studied in our paper, the
\RANDDISTANCE metric, a new shape metric invented in this paper that measures
the distance between empirical eigenvalues of weight matrices and those of
randomly initialized weight matrices, achieves the highest worst-case rank
correlation with generalization performance under a variety of training
settings; and
</p>
<p>(iii) among the three HT distributions considered in our paper, the E-TPL
fitting of ESDs performs the most robustly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Design as Information Renormalization. (arXiv:1708.01525v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1708.01525">
<div class="article-summary-box-inner">
<span><p>Here we consider some well-known facts in syntax from a physics perspective,
allowing us to establish equivalences between both fields with many
consequences. Mainly, we observe that the operation MERGE, put forward by N.
Chomsky in 1995, can be interpreted as a physical information coarse-graining.
Thus, MERGE in linguistics entails information renormalization in physics,
according to different time scales. We make this point mathematically formal in
terms of language models. In this setting, MERGE amounts to a probability
tensor implementing a coarse-graining, akin to a probabilistic context-free
grammar. The probability vectors of meaningful sentences are given by
stochastic tensor networks (TN) built from diagonal tensors and which are
mostly loop-free, such as Tree Tensor Networks and Matrix Product States, thus
being computationally very efficient to manipulate. We show that this implies
the polynomially-decaying (long-range) correlations experimentally observed in
language, and also provides arguments in favour of certain types of neural
networks for language processing. Moreover, we show how to obtain such language
models from quantum states that can be efficiently prepared on a quantum
computer, and use this to find bounds on the perplexity of the probability
distribution of words in a sentence. Implications of our results are discussed
across several ambits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UNISON: Unpaired Cross-lingual Image Captioning. (arXiv:2010.01288v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01288">
<div class="article-summary-box-inner">
<span><p>Image captioning has emerged as an interesting research field in recent years
due to its broad application scenarios. The traditional paradigm of image
captioning relies on paired image-caption datasets to train the model in a
supervised manner. However, creating such paired datasets for every target
language is prohibitively expensive, which hinders the extensibility of
captioning technology and deprives a large part of the world population of its
benefit. In this work, we present a novel unpaired cross-lingual method to
generate image captions without relying on any caption corpus in the source or
the target language. Specifically, our method consists of two phases: (i) a
cross-lingual auto-encoding process, which utilizing a sentence parallel
(bitext) corpus to learn the mapping from the source to the target language in
the scene graph encoding space and decode sentences in the target language, and
(ii) a cross-modal unsupervised feature mapping, which seeks to map the encoded
scene graph features from image modality to language modality. We verify the
effectiveness of our proposed method on the Chinese image caption generation
task. The comparisons against several existing methods demonstrate the
effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlled Analyses of Social Biases in Wikipedia Bios. (arXiv:2101.00078v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00078">
<div class="article-summary-box-inner">
<span><p>Social biases on Wikipedia, a widely-read global platform, could greatly
influence public opinion. While prior research has examined man/woman gender
bias in biography articles, possible influences of other demographic attributes
limit conclusions. In this work, we present a methodology for analyzing
Wikipedia pages about people that isolates dimensions of interest (e.g.,
gender), from other attributes (e.g., occupation). Given a target corpus for
analysis (e.g.~biographies about women), we present a method for constructing a
comparison corpus that matches the target corpus in as many attributes as
possible, except the target one. We develop evaluation metrics to measure how
well the comparison corpus aligns with the target corpus and then examine how
articles about gender and racial minorities (cis. women, non-binary people,
transgender women, and transgender men; African American, Asian American, and
Hispanic/Latinx American people) differ from other articles. In addition to
identifying suspect social biases, our results show that failing to control for
covariates can result in different conclusions and veil biases. Our
contributions include methodology that facilitates further analyses of bias in
Wikipedia articles, findings that can aid Wikipedia editors in reducing biases,
and a framework and evaluation metrics to guide future work in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence Alignment with Parallel Documents Facilitates Biomedical Machine Translation. (arXiv:2104.08588v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08588">
<div class="article-summary-box-inner">
<span><p>Objective: Today's neural machine translation (NMT) can achieve near
human-level translation quality and greatly facilitates international
communications, but the lack of parallel corpora poses a key problem to the
development of translation systems for highly specialized domains, such as
biomedicine. This work presents an unsupervised algorithm for deriving parallel
corpora from document-level translations by using sentence alignment and
explores how training materials affect the performance of biomedical NMT
systems. Materials and Methods: Document-level translations are mixed to train
bilingual word embeddings (BWEs) for the evaluation of cross-lingual word
similarity, and sentence distance is defined by combining semantic and
positional similarities of the sentences. The alignment of sentences is
formulated as an extended earth mover's distance problem. A Chinese-English
biomedical parallel corpus is derived with the proposed algorithm using
bilingual articles from UpToDate and translations of PubMed abstracts, which is
then used for the training and evaluation of NMT. Results: On two manually
aligned translation datasets, the proposed algorithm achieved accurate sentence
alignment in the 1-to-1 cases and outperformed competing algorithms in the
many-to-many cases. The NMT model fine-tuned on biomedical data significantly
improved the in-domain translation quality (zh-en: +17.72 BLEU; en-zh: +17.02
BLEU). Both the size of the training data and the combination of different
corpora can significantly affect the model's performance. Conclusion: The
proposed algorithm relaxes the assumption for sentence alignment and
effectively generates accurate translation pairs that facilitate training high
quality biomedical NMT models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-performance symbolic-numerics via multiple dispatch. (arXiv:2105.03949v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03949">
<div class="article-summary-box-inner">
<span><p>As mathematical computing becomes more democratized in high-level languages,
high-performance symbolic-numeric systems are necessary for domain scientists
and engineers to get the best performance out of their machine without deep
knowledge of code optimization. Naturally, users need different term types
either to have different algebraic properties for them, or to use efficient
data structures. To this end, we developed Symbolics.jl, an extendable symbolic
system which uses dynamic multiple dispatch to change behavior depending on the
domain needs. In this work we detail an underlying abstract term interface
which allows for speed without sacrificing generality. We show that by
formalizing a generic API on actions independent of implementation, we can
retroactively add optimized data structures to our system without changing the
pre-existing term rewriters. We showcase how this can be used to optimize term
construction and give a 113x acceleration on general symbolic transformations.
Further, we show that such a generic API allows for complementary
term-rewriting implementations. We demonstrate the ability to swap between
classical term-rewriting simplifiers and e-graph-based term-rewriting
simplifiers. We showcase an e-graph ruleset which minimizes the number of CPU
cycles during expression evaluation, and demonstrate how it simplifies a
real-world reaction-network simulation to halve the runtime. Additionally, we
show a reaction-diffusion partial differential equation solver which is able to
be automatically converted into symbolic expressions via multiple dispatch
tracing, which is subsequently accelerated and parallelized to give a 157x
simulation speedup. Together, this presents Symbolics.jl as a next-generation
symbolic-numeric computing environment geared towards modeling and simulation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Local Explanation of Dialogue Response Generation. (arXiv:2106.06528v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06528">
<div class="article-summary-box-inner">
<span><p>In comparison to the interpretation of classification models, the explanation
of sequence generation models is also an important problem, however it has seen
little attention. In this work, we study model-agnostic explanations of a
representative text generation task -- dialogue response generation. Dialog
response generation is challenging with its open-ended sentences and multiple
acceptable responses. To gain insights into the reasoning process of a
generation model, we propose a new method, local explanation of response
generation (LERG) that regards the explanations as the mutual interaction of
segments in input and output sentences. LERG views the sequence prediction as
uncertainty estimation of a human response and then creates explanations by
perturbing the input and calculating the certainty change over the human
response. We show that LERG adheres to desired properties of explanations for
text generation including unbiased approximation, consistency and cause
identification. Empirically, our results show that our method consistently
improves other widely used methods on proposed automatic- and human- evaluation
metrics for this new task by 4.4-12.8%. Our analysis demonstrates that LERG can
extract both explicit and implicit relations between input and output segments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classifying Textual Data with Pre-trained Vision Models through Transfer Learning and Data Transformations. (arXiv:2106.12479v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12479">
<div class="article-summary-box-inner">
<span><p>Knowledge is acquired by humans through experience, and no boundary is set
between the kinds of knowledge or skill levels we can achieve on different
tasks at the same time. When it comes to Neural Networks, that is not the case.
The breakthroughs in the field are extremely task and domain-specific. Vision
and language are dealt with in separate manners, using separate methods and
different datasets. Current text classification methods, mostly rely on
obtaining contextual embeddings for input text samples, then training a
classifier on the embedded dataset. Transfer learning in Language-related tasks
in general, is heavily used in obtaining the contextual text embeddings for the
input samples. In this work, we propose to use the knowledge acquired by
benchmark Vision Models which are trained on ImageNet to help a much smaller
architecture learn to classify text. A data transformation technique is used to
create a new image dataset, where each image represents a sentence embedding
from the last six layers of BERT, projected on a 2D plane using a t-SNE based
method. We trained five models containing early layers sliced from vision
models which are pretrained on ImageNet, on the created image dataset for the
IMDB dataset embedded with the last six layers of BERT. Despite the challenges
posed by the very different datasets, experimental results achieved by this
approach which links large pretrained models on both language and vision, are
very promising, without employing compute resources. Specifically, Sentiment
Analysis is achieved by five different models on the same image dataset
obtained after BERT embeddings are transformed into gray scale images.
</p>
<p>Index Terms: BERT, Convolutional Neural Networks, Domain Adaptation, image
classification, Natural Language Processing, t-SNE, text classification,
Transfer Learning
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoBERT-Zero: Evolving BERT Backbone from Scratch. (arXiv:2107.07445v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07445">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-trained language models like BERT and its variants have
recently achieved promising performance in various natural language processing
(NLP) tasks. However, the conventional paradigm constructs the backbone by
purely stacking the manually designed global self-attention layers, introducing
inductive bias and thus leads to sub-optimal. In this work, we make the first
attempt to automatically discover novel pre-trained language model (PLM)
backbone on a flexible search space containing the most fundamental operations
from scratch. Specifically, we propose a well-designed search space which (i)
contains primitive math operations in the intra-layer level to explore novel
attention structures, and (ii) leverages convolution blocks to be the
supplementary for attentions in the inter-layer level to better learn local
dependency. To enhance the efficiency for finding promising architectures, we
propose an Operation-Priority Neural Architecture Search (OP-NAS) algorithm,
which optimizes both the search algorithm and evaluation of candidate models.
Specifically, we propose Operation-Priority (OP) evolution strategy to
facilitate model search via balancing exploration and exploitation.
Furthermore, we design a Bi-branch Weight-Sharing (BIWS) training strategy for
fast model evaluation. Extensive experiments show that the searched
architecture (named AutoBERT-Zero) significantly outperforms BERT and its
variants of different model capacities in various downstream tasks, proving the
architecture's transfer and scaling abilities. Remarkably, AutoBERT-Zero-base
outperforms RoBERTa-base (using much more data) and BERT-large (with much
larger model size) by 2.4 and 1.4 higher score on GLUE test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Adapter Based Pre-Training for Efficient and Scalable Self-Supervised Speech Representation Learning. (arXiv:2107.13530v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13530">
<div class="article-summary-box-inner">
<span><p>We present a method for transferring pre-trained self-supervised (SSL) speech
representations to multiple languages. There is an abundance of unannotated
speech, so creating self-supervised representations from raw audio and
fine-tuning on small annotated datasets is a promising direction to build
speech recognition systems. SSL models generally perform SSL on raw audio in a
pre-training phase and then fine-tune on a small fraction of annotated data.
Such models have produced state of the art results for ASR. However, these
models are very expensive to pre-train. We use an existing wav2vec 2.0 model
and tackle the problem of learning new language representations while utilizing
existing model knowledge. Crucially we do so without catastrophic forgetting of
the existing language representation. We use adapter modules to speed up
pre-training a new language task. Our model can decrease pre-training times by
32% when learning a new language task, and learn this new audio-language
representation without forgetting previous language representation. We evaluate
by applying these language representations to automatic speech recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey of Low-Resource Machine Translation. (arXiv:2109.00486v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00486">
<div class="article-summary-box-inner">
<span><p>We present a survey covering the state of the art in low-resource machine
translation research. There are currently around 7000 languages spoken in the
world and almost all language pairs lack significant resources for training
machine translation models. There has been increasing interest in research
addressing the challenge of producing useful translation models when very
little translated training data is available. We present a summary of this
topical research field and provide a description of the techniques evaluated by
researchers in several recent shared tasks in low-resource MT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative. (arXiv:2109.07437v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07437">
<div class="article-summary-box-inner">
<span><p>In most settings of practical concern, machine learning practitioners know in
advance what end-task they wish to boost with auxiliary tasks. However, widely
used methods for leveraging auxiliary data like pre-training and its
continued-pretraining variant are end-task agnostic: they rarely, if ever,
exploit knowledge of the target task. We study replacing end-task agnostic
continued training of pre-trained language models with end-task aware training
of said models. We argue that for sufficiently important end-tasks, the
benefits of leveraging auxiliary data in a task-aware fashion can justify
forgoing the traditional approach of obtaining generic, end-task agnostic
representations as with (continued) pre-training. On three different
low-resource NLP tasks from two domains, we demonstrate that multi-tasking the
end-task and auxiliary objectives results in significantly better downstream
task performance than the widely-used task-agnostic continued pre-training
paradigm of Gururangan et al. (2020). We next introduce an online meta-learning
algorithm that learns a set of multi-task weights to better balance among our
multiple auxiliary objectives, achieving further improvements on end-task
performance and data efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Case for Claim Difficulty Assessment in Automatic Fact Checking. (arXiv:2109.09689v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09689">
<div class="article-summary-box-inner">
<span><p>Fact-checking is the process of evaluating the veracity of claims (i.e.,
purported facts). In this opinion piece, we raise an issue that has received
little attention in prior work -- that some claims are far more difficult to
fact-check than others. We discuss the implications this has for both practical
fact-checking and research on automated fact-checking, including task
formulation and dataset design. We report a manual analysis undertaken to
explore factors underlying varying claim difficulty and identify several
distinct types of difficulty. We motivate this new claim difficulty prediction
task as beneficial to both automated fact-checking and practical fact-checking
organizations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FLAVA: A Foundational Language And Vision Alignment Model. (arXiv:2112.04482v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04482">
<div class="article-summary-box-inner">
<span><p>State-of-the-art vision and vision-and-language models rely on large-scale
visio-linguistic pretraining for obtaining good performance on a variety of
downstream tasks. Generally, such models are often either cross-modal
(contrastive) or multi-modal (with earlier fusion) but not both; and they often
only target specific modalities or tasks. A promising direction would be to use
a single holistic universal model, as a "foundation", that targets all
modalities at once -- a true vision and language foundation model should be
good at vision tasks, language tasks, and cross- and multi-modal vision and
language tasks. We introduce FLAVA as such a model and demonstrate impressive
performance on a wide range of 35 tasks spanning these target modalities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Selecting Parallel In-domain Sentences for Neural Machine Translation Using Monolingual Texts. (arXiv:2112.06096v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06096">
<div class="article-summary-box-inner">
<span><p>Continuously-growing data volumes lead to larger generic models. Specific
use-cases are usually left out, since generic models tend to perform poorly in
domain-specific cases. Our work addresses this gap with a method for selecting
in-domain data from generic-domain (parallel text) corpora, for the task of
machine translation. The proposed method ranks sentences in parallel
general-domain data according to their cosine similarity with a monolingual
domain-specific data set. We then select the top K sentences with the highest
similarity score to train a new machine translation system tuned to the
specific in-domain data. Our experimental results show that models trained on
this in-domain data outperform models trained on generic or a mixture of
generic and domain data. That is, our method selects high-quality
domain-specific training instances at low computational cost and data size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual-Key Multimodal Backdoors for Visual Question Answering. (arXiv:2112.07668v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07668">
<div class="article-summary-box-inner">
<span><p>The success of deep learning has enabled advances in multimodal tasks that
require non-trivial fusion of multiple input domains. Although multimodal
models have shown potential in many problems, their increased complexity makes
them more vulnerable to attacks. A Backdoor (or Trojan) attack is a class of
security vulnerability wherein an attacker embeds a malicious secret behavior
into a network (e.g. targeted misclassification) that is activated when an
attacker-specified trigger is added to an input. In this work, we show that
multimodal networks are vulnerable to a novel type of attack that we refer to
as Dual-Key Multimodal Backdoors. This attack exploits the complex fusion
mechanisms used by state-of-the-art networks to embed backdoors that are both
effective and stealthy. Instead of using a single trigger, the proposed attack
embeds a trigger in each of the input modalities and activates the malicious
behavior only when both the triggers are present. We present an extensive study
of multimodal backdoors on the Visual Question Answering (VQA) task with
multiple architectures and visual feature backbones. A major challenge in
embedding backdoors in VQA models is that most models use visual features
extracted from a fixed pretrained object detector. This is challenging for the
attacker as the detector can distort or ignore the visual trigger entirely,
which leads to models where backdoors are over-reliant on the language trigger.
We tackle this problem by proposing a visual trigger optimization strategy
designed for pretrained object detectors. Through this method, we create
Dual-Key Backdoors with over a 98% attack success rate while only poisoning 1%
of the training data. Finally, we release TrojVQA, a large collection of clean
and trojan VQA models to enable research in defending against multimodal
backdoors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ADBCMM : Acronym Disambiguation by Building Counterfactuals and Multilingual Mixing. (arXiv:2112.08991v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08991">
<div class="article-summary-box-inner">
<span><p>Scientific documents often contain a large number of acronyms. Disambiguation
of these acronyms will help researchers better understand the meaning of
vocabulary in the documents. In the past, thanks to large amounts of data from
English literature, acronym task was mainly applied in English literature.
However, for other low-resource languages, this task is difficult to obtain
good performance and receives less attention due to the lack of large amount of
annotation data. To address the above issue, this paper proposes an new method
for acronym disambiguation, named as ADBCMM, which can significantly improve
the performance of low-resource languages by building counterfactuals and
multilingual mixing. Specifically, by balancing data bias in low-resource
langauge, ADBCMM will able to improve the test performance outside the data
set. In SDU@AAAI-22 - Shared Task 2: Acronym Disambiguation, the proposed
method won first place in French and Spanish. You can repeat our results here
https://github.com/WENGSYX/ADBCMM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">This Must Be the Place: Predicting Engagement of Online Communities in a Large-scale Distributed Campaign. (arXiv:2201.05334v2 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05334">
<div class="article-summary-box-inner">
<span><p>Understanding collective decision making at a large-scale, and elucidating
how community organization and community dynamics shape collective behavior are
at the heart of social science research. In this work we study the behavior of
thousands of communities with millions of active members. We define a novel
task: predicting which community will undertake an unexpected, large-scale,
distributed campaign.
</p>
<p>To this end, we develop a hybrid model, combining textual cues, community
meta-data, and structural properties. We show how this multi-faceted model can
accurately predict large-scale collective decision-making in a distributed
environment. We demonstrate the applicability of our model through Reddit's
r/place - a large-scale online experiment in which millions of users,
self-organized in thousands of communities, clashed and collaborated in an
effort to realize their agenda.
</p>
<p>Our hybrid model achieves a high F1 prediction score of 0.826. We find that
coarse meta-features are as important for prediction accuracy as fine-grained
textual cues, while explicit structural features play a smaller role.
Interpreting our model, we provide and support various social insights about
the unique characteristics of the communities that participated in the \r/place
experiment.
</p>
<p>Our results and analysis shed light on the complex social dynamics that drive
collective behavior, and on the factors that propel user coordination. The
scale and the unique conditions of the \rp~experiment suggest that our findings
may apply in broader contexts, such as online activism, (countering) the spread
of hate speech and reducing political polarization. The broader applicability
of the model is demonstrated through an extensive analysis of the
WallStreetBets community, their role in r/place and four years later, in the
GameStop short squeeze campaign of 2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive Continual Learning for Spoken Keyword Spotting. (arXiv:2201.12546v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12546">
<div class="article-summary-box-inner">
<span><p>Catastrophic forgetting is a thorny challenge when updating keyword spotting
(KWS) models after deployment. To tackle such challenges, we propose a
progressive continual learning strategy for small-footprint spoken keyword
spotting (PCL-KWS). Specifically, the proposed PCL-KWS framework introduces a
network instantiator to generate the task-specific sub-networks for remembering
previously learned keywords. As a result, the PCL-KWS approach incrementally
learns new keywords without forgetting prior knowledge. Besides, the
keyword-aware network scaling mechanism of PCL-KWS constrains the growth of
model parameters while achieving high performance. Experimental results show
that after learning five new tasks sequentially, our proposed PCL-KWS approach
archives the new state-of-the-art performance of 92.8% average accuracy for all
the tasks on Google Speech Command dataset compared with other baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VC-GPT: Visual Conditioned GPT for End-to-End Generative Vision-and-Language Pre-training. (arXiv:2201.12723v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12723">
<div class="article-summary-box-inner">
<span><p>Vision-and-language pre-trained models (VLMs) have achieved tremendous
success in the cross-modal area, but most of them require a large amount of
parallel image-caption data for pre-training. Collating such data is expensive
and labor-intensive. In this work, we focus on reducing such need for
generative vision-and-language pre-training (G-VLP) by taking advantage of the
visual pre-trained model (CLIP-ViT) as encoder and language pre-trained model
(GPT2) as decoder. Unfortunately, GPT2 lacks a necessary cross-attention
module, which hinders the direct connection of CLIP-ViT and GPT2. To remedy
such defects, we conduct extensive experiments to empirically investigate how
to design and pre-train our model. Based on our experimental results, we
propose a novel G-VLP framework, Visual Conditioned GPT (VC-GPT), and pre-train
it with a small-scale image-caption corpus (Visual Genome, only 110k distinct
images). Evaluating on the image captioning downstream tasks (MSCOCO and
Flickr30k Captioning), VC-GPT achieves either the best or the second-best
performance across all evaluation metrics over the previous works which consume
around 30 times more distinct images during cross-modal pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia and Wikidata Translated by Native Speakers. (arXiv:2202.00120v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00120">
<div class="article-summary-box-inner">
<span><p>The ability to have the same experience for different user groups (i.e.,
accessibility) is one of the most important characteristics of Web-based
systems. The same is true for Knowledge Graph Question Answering (KGQA) systems
that provide the access to Semantic Web data via natural language interface.
While following our research agenda on the multilingual aspect of accessibility
of KGQA systems, we identified several ongoing challenges. One of them is the
lack of multilingual KGQA benchmarks. In this work, we extend one of the most
popular KGQA benchmarks - QALD-9 by introducing high-quality questions'
translations to 8 languages provided by native speakers, and transferring the
SPARQL queries of QALD-9 from DBpedia to Wikidata, s.t., the usability and
relevance of the dataset is strongly increased. Five of the languages -
Armenian, Ukrainian, Lithuanian, Bashkir and Belarusian - to our best knowledge
were never considered in KGQA research community before. The latter two of the
languages are considered as "endangered" by UNESCO. We call the extended
dataset QALD-9-plus and made it available online
https://github.com/Perevalov/qald_9_plus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Streaming Multi-Talker ASR with Token-Level Serialized Output Training. (arXiv:2202.00842v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00842">
<div class="article-summary-box-inner">
<span><p>This paper proposes a token-level serialized output training (t-SOT), a novel
framework for streaming multi-talker automatic speech recognition (ASR). Unlike
existing streaming multi-talker ASR models using multiple output layers, the
t-SOT model has only a single output layer that generates recognition tokens
(e.g., words, subwords) of multiple speakers in chronological order based on
their emission times. A special token that indicates the change of "virtual"
output channels is introduced to keep track of the overlapping utterances.
Compared to the prior streaming multi-talker ASR models, the t-SOT model has
the advantages of less inference cost and a simpler model architecture.
Moreover, in our experiments with LibriSpeechMix and LibriCSS datasets, the
t-SOT-based transformer transducer model achieves the state-of-the-art word
error rates by a significant margin to the prior results. For non-overlapping
speech, the t-SOT model is on par with a single-talker ASR model in terms of
both accuracy and computational cost, opening the door for deploying one model
for both single- and multi-talker scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Knowledge Integration in Language Models with Graph Convolutions. (arXiv:2202.00964v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00964">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (LMs) do not capture factual knowledge very well.
This has led to the development of a number of knowledge integration (KI)
methods which aim to incorporate external knowledge into pretrained LMs. Even
though KI methods show some performance gains over vanilla LMs, the
inner-workings of these methods are not well-understood. For instance, it is
unclear how and what kind of knowledge is effectively integrated into these
models and if such integration may lead to catastrophic forgetting of already
learned knowledge. This paper revisits the KI process in these models with an
information-theoretic view and shows that KI can be interpreted using a graph
convolution operation. We propose a probe model called \textit{Graph
Convolution Simulator} (GCS) for interpreting knowledge-enhanced LMs and
exposing what kind of knowledge is integrated into these models. We conduct
experiments to verify that our GCS can indeed be used to correctly interpret
the KI process, and we use it to analyze two well-known knowledge-enhanced LMs:
ERNIE and K-Adapter, and find that only a small amount of factual knowledge is
integrated in them. We stratify knowledge in terms of various relation types
and find that ERNIE and K-Adapter integrate different kinds of knowledge to
different extent. Our analysis also shows that simply increasing the size of
the KI corpus may not lead to better KI; fundamental advances may be needed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RescoreBERT: Discriminative Speech Recognition Rescoring with BERT. (arXiv:2202.01094v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01094">
<div class="article-summary-box-inner">
<span><p>Second-pass rescoring is an important component in automatic speech
recognition (ASR) systems that is used to improve the outputs from a first-pass
decoder by implementing a lattice rescoring or $n$-best re-ranking. While
pretraining with a masked language model (MLM) objective has received great
success in various natural language understanding (NLU) tasks, it has not
gained traction as a rescoring model for ASR. Specifically, training a
bidirectional model like BERT on a discriminative objective such as minimum WER
(MWER) has not been explored. Here we show how to train a BERT-based rescoring
model with MWER loss, to incorporate the improvements of a discriminative loss
into fine-tuning of deep bidirectional pretrained models for ASR. Specifically,
we propose a fusion strategy that incorporates the MLM into the discriminative
training process to effectively distill knowledge from a pretrained model. We
further propose an alternative discriminative loss. We name this approach
RescoreBERT. On the LibriSpeech corpus, it reduces WER by 6.6%/3.4% relative on
clean/other test sets over a BERT baseline without discriminative objective. We
also evaluate our method on an internal dataset from a conversational agent and
find that it reduces both latency and WER (by 3 to 8% relative) over an LSTM
rescoring model.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Boundary-aware Information Maximization for Self-supervised Medical Image Segmentation. (arXiv:2202.02371v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02371">
<div class="article-summary-box-inner">
<span><p>Unsupervised pre-training has been proven as an effective approach to boost
various downstream tasks given limited labeled data. Among various methods,
contrastive learning learns a discriminative representation by constructing
positive and negative pairs. However, it is not trivial to build reasonable
pairs for a segmentation task in an unsupervised way. In this work, we propose
a novel unsupervised pre-training framework that avoids the drawback of
contrastive learning. Our framework consists of two principles: unsupervised
over-segmentation as a pre-train task using mutual information maximization and
boundary-aware preserving learning. Experimental results on two benchmark
medical segmentation datasets reveal our method's effectiveness in improving
segmentation performance when few annotated images are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Automated Tree Topology Estimation and Artery-Vein Classification. (arXiv:2202.02382v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02382">
<div class="article-summary-box-inner">
<span><p>We present a fully automatic technique for extracting the retinal vascular
topology, i.e., how the different vessels are connected to each other, given a
single color fundus image. Determining this connectivity is very challenging
because vessels cross each other in a 2D image, obscuring their true paths. We
validated the usefulness of our extraction method by using it to achieve
state-of-the-art results in retinal artery-vein classification.
</p>
<p>Our proposed approach works as follows. We first segment the retinal vessels
using our previously developed state-of-the-art segmentation method. Then, we
estimate an initial graph from the extracted vessels and assign the most likely
blood flow to each edge. We then use a handful of high-level operations (HLOs)
to fix errors in the graph. These HLOs include detaching neighboring nodes,
shifting the endpoints of an edge, and reversing the estimated blood flow
direction for a branch. We use a novel cost function to find the optimal set of
HLO operations for a given graph. Finally, we show that our extracted vascular
structure is correct by propagating artery/vein labels along the branches. As
our experiments show, our topology-based artery-vein labeling achieved
state-of-the-art results on multiple datasets. We also performed several
ablation studies to verify the importance of the different components of our
proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StandardSim: A Synthetic Dataset For Retail Environments. (arXiv:2202.02418v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02418">
<div class="article-summary-box-inner">
<span><p>Autonomous checkout systems rely on visual and sensory inputs to carry out
fine-grained scene understanding in retail environments. Retail environments
present unique challenges compared to typical indoor scenes owing to the vast
number of densely packed, unique yet similar objects. The problem becomes even
more difficult when only RGB input is available, especially for data-hungry
tasks such as instance segmentation. To address the lack of datasets for
retail, we present StandardSim, a large-scale photorealistic synthetic dataset
featuring annotations for semantic segmentation, instance segmentation, depth
estimation, and object detection. Our dataset provides multiple views per
scene, enabling multi-view representation learning. Further, we introduce a
novel task central to autonomous checkout called change detection, requiring
pixel-level classification of takes, puts and shifts in objects over time. We
benchmark widely-used models for segmentation and depth estimation on our
dataset, show that our test set constitutes a difficult benchmark compared to
current smaller-scale datasets and that our training set provides models with
crucial information for autonomous checkout tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The influence of labeling techniques in classifying human manipulation movement of different speed. (arXiv:2202.02426v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02426">
<div class="article-summary-box-inner">
<span><p>In this work, we investigate the influence of labeling methods on the
classification of human movements on data recorded using a marker-based motion
capture system. The dataset is labeled using two different approaches, one
based on video data of the movements, the other based on the movement
trajectories recorded using the motion capture system. The dataset is labeled
using two different approaches, one based on video data of the movements, the
other based on the movement trajectories recorded using the motion capture
system. The data was recorded from one participant performing a stacking
scenario comprising simple arm movements at three different speeds (slow,
normal, fast). Machine learning algorithms that include k-Nearest Neighbor,
Random Forest, Extreme Gradient Boosting classifier, Convolutional Neural
networks (CNN), Long Short-Term Memory networks (LSTM), and a combination of
CNN-LSTM networks are compared on their performance in recognition of these arm
movements. The models were trained on actions performed on slow and normal
speed movements segments and generalized on actions consisting of fast-paced
human movement. It was observed that all the models trained on normal-paced
data labeled using trajectories have almost 20% improvement in accuracy on test
data in comparison to the models trained on data labeled using videos of the
performed experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stratification of carotid atheromatous plaque using interpretable deep learning methods on B-mode ultrasound images. (arXiv:2202.02428v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02428">
<div class="article-summary-box-inner">
<span><p>Carotid atherosclerosis is the major cause of ischemic stroke resulting in
significant rates of mortality and disability annually. Early diagnosis of such
cases is of great importance, since it enables clinicians to apply a more
effective treatment strategy. This paper introduces an interpretable
classification approach of carotid ultrasound images for the risk assessment
and stratification of patients with carotid atheromatous plaque. To address the
highly imbalanced distribution of patients between the symptomatic and
asymptomatic classes (16 vs 58, respectively), an ensemble learning scheme
based on a sub-sampling approach was applied along with a two-phase,
cost-sensitive strategy of learning, that uses the original and a resampled
data set. Convolutional Neural Networks (CNNs) were utilized for building the
primary models of the ensemble. A six-layer deep CNN was used to automatically
extract features from the images, followed by a classification stage of two
fully connected layers. The obtained results (Area Under the ROC Curve (AUC):
73%, sensitivity: 75%, specificity: 70%) indicate that the proposed approach
achieved acceptable discrimination performance. Finally, interpretability
methods were applied on the model's predictions in order to reveal insights on
the model's decision process as well as to enable the identification of novel
image biomarkers for the stratification of patients with carotid atheromatous
plaque.Clinical Relevance-The integration of interpretability methods with deep
learning strategies can facilitate the identification of novel ultrasound image
biomarkers for the stratification of patients with carotid atheromatous plaque.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation. (arXiv:2202.02440v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02440">
<div class="article-summary-box-inner">
<span><p>In reinforcement learning for visual navigation, it is common to develop a
model for each new task, and train that model from scratch with task-specific
interactions in 3D environments. However, this process is expensive; massive
amounts of interactions are needed for the model to generalize well. Moreover,
this process is repeated whenever there is a change in the task type or the
goal modality. We present a unified approach to visual navigation using a novel
modular transfer learning model. Our model can effectively leverage its
experience from one source task and apply it to multiple target tasks (e.g.,
ObjectNav, RoomNav, ViewNav) with various goal modalities (e.g., image, sketch,
audio, label). Furthermore, our model enables zero-shot experience learning,
whereby it can solve the target tasks without receiving any task-specific
interactive training. Our experiments on multiple photorealistic datasets and
challenging tasks show that our approach learns faster, generalizes better, and
outperforms SoTA models by a significant margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning Method for Functional Assessment of Retinal Models. (arXiv:2202.02443v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02443">
<div class="article-summary-box-inner">
<span><p>Challenges in the field of retinal prostheses motivate the development of
retinal models to accurately simulate Retinal Ganglion Cells (RGCs) responses.
The goal of retinal prostheses is to enable blind individuals to solve complex,
reallife visual tasks. In this paper, we introduce the functional assessment
(FA) of retinal models, which describes the concept of evaluating the
performance of retinal models on visual understanding tasks. We present a
machine learning method for FA: we feed traditional machine learning
classifiers with RGC responses generated by retinal models, to solve object and
digit recognition tasks (CIFAR-10, MNIST, Fashion MNIST, Imagenette). We
examined critical FA aspects, including how the performance of FA depends on
the task, how to optimally feed RGC responses to the classifiers and how the
number of output neurons correlates with the model's accuracy. To increase the
number of output neurons, we manipulated input images - by splitting and then
feeding them to the retinal model and we found that image splitting does not
significantly improve the model's accuracy. We also show that differences in
the structure of datasets result in largely divergent performance of the
retinal model (MNIST and Fashion MNIST exceeded 80% accuracy, while CIFAR-10
and Imagenette achieved ~40%). Furthermore, retinal models which perform better
in standard evaluation, i.e. more accurately predict RGC response, perform
better in FA as well. However, unlike standard evaluation, FA results can be
straightforwardly interpreted in the context of comparing the quality of visual
perception.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spelunking the Deep: Guaranteed Queries for General Neural Implicit Surfaces. (arXiv:2202.02444v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02444">
<div class="article-summary-box-inner">
<span><p>Neural implicit representations, which encode a surface as the level set of a
neural network applied to spatial coordinates, have proven to be remarkably
effective for optimizing, compressing, and generating 3D geometry. Although
these representations are easy to fit, it is not clear how to best evaluate
geometric queries on the shape, such as intersecting against a ray or finding a
closest point. The predominant approach is to encourage the network to have a
signed distance property. However, this property typically holds only
approximately, leading to robustness issues, and holds only at the conclusion
of training, inhibiting the use of queries in loss functions. Instead, this
work presents a new approach to perform queries directly on general neural
implicit functions for a wide range of existing architectures. Our key tool is
the application of range analysis to neural networks, using automatic
arithmetic rules to bound the output of a network over a region; we conduct a
study of range analysis on neural networks, and identify variants of affine
arithmetic which are highly effective. We use the resulting bounds to develop
geometric queries including ray casting, intersection testing, constructing
spatial hierarchies, fast mesh extraction, closest-point evaluation, evaluating
bulk properties, and more. Our queries can be efficiently evaluated on GPUs,
and offer concrete accuracy guarantees even on randomly-initialized networks,
enabling their use in training objectives and beyond. We also show a
preliminary application to inverse rendering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Learning as Cluster-induced Voronoi Diagrams: A Geometric Approach. (arXiv:2202.02471v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02471">
<div class="article-summary-box-inner">
<span><p>Few-shot learning (FSL) is the process of rapid generalization from abundant
base samples to inadequate novel samples. Despite extensive research in recent
years, FSL is still not yet able to generate satisfactory solutions for a wide
range of real-world applications. To confront this challenge, we study the FSL
problem from a geometric point of view in this paper. One observation is that
the widely embraced ProtoNet model is essentially a Voronoi Diagram (VD) in the
feature space. We retrofit it by making use of a recent advance in
computational geometry called Cluster-induced Voronoi Diagram (CIVD). Starting
from the simplest nearest neighbor model, CIVD gradually incorporates
cluster-to-point and then cluster-to-cluster relationships for space
subdivision, which is used to improve the accuracy and robustness at multiple
stages of FSL. Specifically, we use CIVD (1) to integrate parametric and
nonparametric few-shot classifiers; (2) to combine feature representation and
surrogate representation; (3) and to leverage feature-level,
transformation-level, and geometry-level heterogeneities for a better ensemble.
Our CIVD-based workflow enables us to achieve new state-of-the-art results on
mini-ImageNet, CUB, and tiered-ImagenNet datasets, with ${\sim}2\%{-}5\%$
improvements upon the next best. To summarize, CIVD provides a mathematically
elegant and geometrically interpretable framework that compensates for extreme
data insufficiency, prevents overfitting, and allows for fast geometric
ensemble for thousands of individual VD. These together make FSL stronger.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor Imagery Classification. (arXiv:2202.02472v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02472">
<div class="article-summary-box-inner">
<span><p>Deep learning (DL) has been widely investigated in a vast majority of
applications in electroencephalography (EEG)-based brain-computer interfaces
(BCIs), especially for motor imagery (MI) classification in the past five
years. The mainstream DL methodology for the MI-EEG classification exploits the
temporospatial patterns of EEG signals using convolutional neural networks
(CNNs), which have been particularly successful in visual images. However,
since the statistical characteristics of visual images may not benefit EEG
signals, a natural question that arises is whether there exists an alternative
network architecture despite CNNs to extract features for the MI-EEG
classification. To address this question, we propose a novel geometric deep
learning (GDL) framework called Tensor-CSPNet to characterize EEG signals on
symmetric positive definite (SPD) manifolds and exploit the
temporo-spatio-frequential patterns using deep neural networks on SPD
manifolds. Meanwhile, many experiences of successful MI-EEG classifiers have
been integrated into the Tensor-CSPNet framework to make it more efficient. In
the experiments, Tensor-CSPNet attains or slightly outperforms the current
state-of-the-art performance on the cross-validation and holdout scenarios of
two MI-EEG datasets. The visualization and interpretability analyses also
exhibit its validity for the MI-EEG classification. To conclude, we provide a
feasible answer to the question by generalizing the previous DL methodologies
on SPD manifolds, which indicates the start of a specific class from the GDL
methodology for the MI-EEG classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Challenges of Class Imbalance and Scale Variation in Object Detection in Aerial Images. (arXiv:2202.02489v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02489">
<div class="article-summary-box-inner">
<span><p>While object detection is a common problem in computer vision, it is even
more challenging when dealing with aerial satellite images. The variety in
object scales and orientations can make them difficult to identify. In
addition, there can be large amounts of densely packed small objects such as
cars. In this project, we propose a few changes to the Faster-RCNN
architecture. First, we experiment with different backbones to extract better
features. We also modify the data augmentations and generated anchor sizes for
region proposals in order to better handle small objects. Finally, we
investigate the effects of different loss functions. Our proposed design
achieves an improvement of 4.7 mAP over the baseline which used a vanilla
Faster R-CNN with a ResNet-101 FPN backbone.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Detector with Robust Classifier. (arXiv:2202.02503v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02503">
<div class="article-summary-box-inner">
<span><p>Deep neural network (DNN) models are wellknown to easily misclassify
prediction results by using input images with small perturbations, called
adversarial examples. In this paper, we propose a novel adversarial detector,
which consists of a robust classifier and a plain one, to highly detect
adversarial examples. The proposed adversarial detector is carried out in
accordance with the logits of plain and robust classifiers. In an experiment,
the proposed detector is demonstrated to outperform a state-of-the-art detector
without any robust classifier.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Less is More: Reversible Steganography with Uncertainty-Aware Predictive Analytics. (arXiv:2202.02518v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02518">
<div class="article-summary-box-inner">
<span><p>Artificial neural networks have advanced the frontiers of reversible
steganography. The core strength of neural networks is the ability to render
accurate predictions for a bewildering variety of data. Residual modulation is
recognised as the most advanced reversible steganographic algorithm for digital
images and the pivot of which is the predictive module. The function of this
module is to predict pixel intensity given some pixel-wise contextual
information. This task can be perceived as a low-level vision problem and hence
neural networks for addressing a similar class of problems can be deployed. On
top of the prior art, this paper analyses the predictive uncertainty and endows
the predictive module with the option to abstain when encountering a high level
of uncertainty. Uncertainty analysis can be formulated as a pixel-level binary
classification problem and tackled by both supervised and unsupervised
learning. In contrast to handcrafted statistical analytics, learning-based
analytics can learn to follow some general statistical principles and
simultaneously adapt to a specific predictor. Experimental results show that
steganographic performance can be remarkably improved by adaptively filtering
out the unpredictable regions with the learning-based uncertainty analysers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparative study of 3D object detection frameworks based on LiDAR data and sensor fusion techniques. (arXiv:2202.02521v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02521">
<div class="article-summary-box-inner">
<span><p>Estimating and understanding the surroundings of the vehicle precisely forms
the basic and crucial step for the autonomous vehicle. The perception system
plays a significant role in providing an accurate interpretation of a vehicle's
environment in real-time. Generally, the perception system involves various
subsystems such as localization, obstacle (static and dynamic) detection, and
avoidance, mapping systems, and others. For perceiving the environment, these
vehicles will be equipped with various exteroceptive (both passive and active)
sensors in particular cameras, Radars, LiDARs, and others. These systems are
equipped with deep learning techniques that transform the huge amount of data
from the sensors into semantic information on which the object detection and
localization tasks are performed. For numerous driving tasks, to provide
accurate results, the location and depth information of a particular object is
necessary. 3D object detection methods, by utilizing the additional pose data
from the sensors such as LiDARs, stereo cameras, provides information on the
size and location of the object. Based on recent research, 3D object detection
frameworks performing object detection and localization on LiDAR data and
sensor fusion techniques show significant improvement in their performance. In
this work, a comparative study of the effect of using LiDAR data for object
detection frameworks and the performance improvement seen by using sensor
fusion techniques are performed. Along with discussing various state-of-the-art
methods in both the cases, performing experimental analysis, and providing
future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PrivPAS: A real time Privacy-Preserving AI System and applied ethics. (arXiv:2202.02524v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02524">
<div class="article-summary-box-inner">
<span><p>With 3.78 billion social media users worldwide in 2021 (48% of the human
population), almost 3 billion images are shared daily. At the same time, a
consistent evolution of smartphone cameras has led to a photography explosion
with 85% of all new pictures being captured using smartphones. However, lately,
there has been an increased discussion of privacy concerns when a person being
photographed is unaware of the picture being taken or has reservations about
the same being shared. These privacy violations are amplified for people with
disabilities, who may find it challenging to raise dissent even if they are
aware. Such unauthorized image captures may also be misused to gain sympathy by
third-party organizations, leading to a privacy breach. Privacy for people with
disabilities has so far received comparatively less attention from the AI
community. This motivates us to work towards a solution to generate
privacy-conscious cues for raising awareness in smartphone users of any
sensitivity in their viewfinder content. To this end, we introduce PrivPAS (A
real time Privacy-Preserving AI System) a novel framework to identify sensitive
content. Additionally, we curate and annotate a dataset to identify and
localize accessibility markers and classify whether an image is sensitive to a
featured subject with a disability. We demonstrate that the proposed
lightweight architecture, with a memory footprint of a mere 8.49MB, achieves a
high mAP of 89.52% on resource-constrained devices. Furthermore, our pipeline,
trained on face anonymized data, achieves an F1-score of 73.1%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting. (arXiv:2202.02543v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02543">
<div class="article-summary-box-inner">
<span><p>Learning from unlabeled or partially labeled data to alleviate human labeling
remains a challenging research topic in 3D modeling. Along this line,
unsupervised representation learning is a promising direction to auto-extract
features without human intervention. This paper proposes a general unsupervised
approach, named \textbf{ConClu}, to perform the learning of point-wise and
global features by jointly leveraging point-level clustering and instance-level
contrasting. Specifically, for one thing, we design an Expectation-Maximization
(EM) like soft clustering algorithm that provides local supervision to extract
discriminating local features based on optimal transport. We show that this
criterion extends standard cross-entropy minimization to an optimal transport
problem, which we solve efficiently using a fast variant of the Sinkhorn-Knopp
algorithm. For another, we provide an instance-level contrasting method to
learn the global geometry, which is formulated by maximizing the similarity
between two augmentations of one point cloud. Experimental evaluations on
downstream applications such as 3D object classification and semantic
segmentation demonstrate the effectiveness of our framework and show that it
can outperform state-of-the-art techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DEVO: Depth-Event Camera Visual Odometry in Challenging Conditions. (arXiv:2202.02556v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02556">
<div class="article-summary-box-inner">
<span><p>We present a novel real-time visual odometry framework for a stereo setup of
a depth and high-resolution event camera. Our framework balances accuracy and
robustness against computational efficiency towards strong performance in
challenging scenarios. We extend conventional edge-based semi-dense visual
odometry towards time-surface maps obtained from event streams. Semi-dense
depth maps are generated by warping the corresponding depth values of the
extrinsically calibrated depth camera. The tracking module updates the camera
pose through efficient, geometric semi-dense 3D-2D edge alignment. Our approach
is validated on both public and self-collected datasets captured under various
conditions. We show that the proposed method performs comparable to
state-of-the-art RGB-D camera-based alternatives in regular conditions, and
eventually outperforms in challenging conditions such as high dynamics or low
illumination.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Catch Me if You Can: A Novel Task for Detection of Covert Geo-Locations (CGL). (arXiv:2202.02567v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02567">
<div class="article-summary-box-inner">
<span><p>Most visual scene understanding tasks in the field of computer vision involve
identification of the objects present in the scene. Image regions like
hideouts, turns, &amp; other obscured regions of the scene also contain crucial
information, for specific surveillance tasks. Task proposed in this paper
involves the design of an intelligent visual aid for identification of such
locations in an image, which has either the potential to create an imminent
threat from an adversary or appear as the target zones needing further
investigation. Covert places (CGL) for hiding behind an occluding object are
concealed 3D locations, not detectable from the viewpoint (camera). Hence this
involves delineating specific image regions around the projections of outer
boundary of the occluding objects, as places to be accessed around the
potential hideouts. CGL detection finds applications in military
counter-insurgency operations, surveillance with path planning for an
exploratory robot. Given an RGB image, the goal is to identify all CGLs in the
2D scene. Identification of such regions would require knowledge about the 3D
boundaries of obscuring items (pillars, furniture), their spatial location with
respect to the neighboring regions of the scene. We propose this as a novel
task, termed Covert Geo-Location (CGL) Detection. Classification of any region
of an image as a CGL (as boundary sub-segments of an occluding object that
conceals the hideout) requires examining the 3D relation between boundaries of
occluding objects and their neighborhoods &amp; surroundings. Our method
successfully extracts relevant depth features from a single RGB image and
quantitatively yields significant improvement over existing object detection
and segmentation models adapted and trained for CGL detection. We also
introduce a novel hand-annotated CGL detection dataset containing 1.5K
real-world images for experimentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VIS-iTrack: Visual Intention through Gaze Tracking using Low-Cost Webcam. (arXiv:2202.02587v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02587">
<div class="article-summary-box-inner">
<span><p>Human intention is an internal, mental characterization for acquiring desired
information. From interactive interfaces containing either textual or graphical
information, intention to perceive desired information is subjective and
strongly connected with eye gaze. In this work, we determine such intention by
analyzing real-time eye gaze data with a low-cost regular webcam. We extracted
unique features (e.g., Fixation Count, Eye Movement Ratio) from the eye gaze
data of 31 participants to generate a dataset containing 124 samples of visual
intention for perceiving textual or graphical information, labeled as either
TEXT or IMAGE, having 48.39% and 51.61% distribution, respectively. Using this
dataset, we analyzed 5 classifiers, including Support Vector Machine (SVM)
(Accuracy: 92.19%). Using the trained SVM, we investigated the variation of
visual intention among 30 participants, distributed in 3 age groups, and found
out that young users were more leaned towards graphical contents whereas older
adults felt more interested in textual ones. This finding suggests that
real-time eye gaze data can be a potential source of identifying visual
intention, analyzing which intention aware interactive interfaces can be
designed and developed to facilitate human cognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Memory Defense: More Robust Classification via a Memory-Masking Autoencoder. (arXiv:2202.02595v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02595">
<div class="article-summary-box-inner">
<span><p>Many deep neural networks are susceptible to minute perturbations of images
that have been carefully crafted to cause misclassification. Ideally, a robust
classifier would be immune to small variations in input images, and a number of
defensive approaches have been created as a result. One method would be to
discern a latent representation which could ignore small changes to the input.
However, typical autoencoders easily mingle inter-class latent representations
when there are strong similarities between classes, making it harder for a
decoder to accurately project the image back to the original high-dimensional
space. We propose a novel framework, Memory Defense, an augmented classifier
with a memory-masking autoencoder to counter this challenge. By masking other
classes, the autoencoder learns class-specific independent latent
representations. We test the model's robustness against four widely used
attacks. Experiments on the Fashion-MNIST &amp; CIFAR-10 datasets demonstrate the
superiority of our model. We make available our source code at GitHub
repository: https://github.com/eashanadhikarla/MemDefense
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ROMNet: Renovate the Old Memories. (arXiv:2202.02606v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02606">
<div class="article-summary-box-inner">
<span><p>Renovating the memories in old photos is an intriguing research topic in
computer vision fields. These legacy images often suffer from severe and
commingled degradations such as cracks, noise, and color-fading, while lack of
large-scale paired old photo datasets makes this restoration task very
challenging. In this work, we present a novel reference-based end-to-end
learning framework that can jointly repair and colorize the degraded legacy
pictures. Specifically, the proposed framework consists of three modules: a
restoration sub-network for degradation restoration, a similarity sub-network
for color histogram matching and transfer, and a colorization subnet that
learns to predict the chroma elements of the images conditioned on chromatic
reference signals. The whole system takes advantage of the color histogram
priors in a given reference image, which vastly reduces the dependency on
large-scale training data. Apart from the proposed method, we also create, to
our knowledge, the first public and real-world old photo dataset with paired
ground truth for evaluating old photo restoration models, wherein each old
photo is paired with a manually restored pristine image by PhotoShop experts.
Our extensive experiments conducted on both synthetic and real-world datasets
demonstrate that our method significantly outperforms state-of-the-arts both
quantitatively and qualitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DSSIM: a structural similarity index for floating-point data. (arXiv:2202.02616v1 [stat.CO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02616">
<div class="article-summary-box-inner">
<span><p>Data visualization is a critical component in terms of interacting with
floating-point output data from large model simulation codes. Indeed,
postprocessing analysis workflows on simulation data often generate a large
number of images from the raw data, many of which are then compared to each
other or to specified reference images. In this image-comparison scenario,
image quality assessment (IQA) measures are quite useful, and the Structural
Similarity Index (SSIM) continues to be a popular choice. However, generating
large numbers of images can be costly, and plot-specific (but data independent)
choices can affect the SSIM value. A natural question is whether we can apply
the SSIM directly to the floating-point simulation data and obtain an
indication of whether differences in the data are likely to impact a visual
assessment, effectively bypassing the creation of a specific set of images from
the data. To this end, we propose an alternative to the popular SSIM that can
be applied directly to the floating point data, which we refer to as the Data
SSIM (DSSIM). While we demonstrate the usefulness of the DSSIM in the context
of evaluating differences due to lossy compression on large volumes of
simulation data from a popular climate model, the DSSIM may prove useful for
many other applications involving simulation or image data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layer-wise Regularized Adversarial Training using Layers Sustainability Analysis (LSA) framework. (arXiv:2202.02626v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02626">
<div class="article-summary-box-inner">
<span><p>Deep neural network models are used today in various applications of
artificial intelligence, the strengthening of which, in the face of adversarial
attacks is of particular importance. An appropriate solution to adversarial
attacks is adversarial training, which reaches a trade-off between robustness
and generalization. This paper introduces a novel framework (Layer
Sustainability Analysis (LSA)) for the analysis of layer vulnerability in a
given neural network in the scenario of adversarial attacks. LSA can be a
helpful toolkit to assess deep neural networks and to extend the adversarial
training approaches towards improving the sustainability of model layers via
layer monitoring and analysis. The LSA framework identifies a list of Most
Vulnerable Layers (MVL list) of a given network. The relative error, as a
comparison measure, is used to evaluate representation sustainability of each
layer against adversarial attack inputs. The proposed approach for obtaining
robust neural networks to fend off adversarial attacks is based on a layer-wise
regularization (LR) over LSA proposal(s) for adversarial training (AT); i.e.
the AT-LR procedure. AT-LR could be used with any benchmark adversarial attack
to reduce the vulnerability of network layers and to improve conventional
adversarial training approaches. The proposed idea performs well theoretically
and experimentally for state-of-the-art multilayer perceptron and convolutional
neural network architectures. Compared with the AT-LR and its corresponding
base adversarial training, the classification accuracy of more significant
perturbations increased by 16.35%, 21.79%, and 10.730% on Moon, MNIST, and
CIFAR-10 benchmark datasets in comparison with the AT-LR and its corresponding
base adversarial training, respectively. The LSA framework is available and
published at https://github.com/khalooei/LSA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training. (arXiv:2202.02643v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02643">
<div class="article-summary-box-inner">
<span><p>Random pruning is arguably the most naive way to attain sparsity in neural
networks, but has been deemed uncompetitive by either post-training pruning or
sparse training. In this paper, we focus on sparse training and highlight a
perhaps counter-intuitive finding, that random pruning at initialization can be
quite powerful for the sparse training of modern neural networks. Without any
delicate pruning criteria or carefully pursued sparsity structures, we
empirically demonstrate that sparsely training a randomly pruned network from
scratch can match the performance of its dense equivalent. There are two key
factors that contribute to this revival: (i) the network sizes matter: as the
original dense networks grow wider and deeper, the performance of training a
randomly pruned sparse network will quickly grow to matching that of its dense
equivalent, even at high sparsity ratios; (ii) appropriate layer-wise sparsity
ratios can be pre-chosen for sparse training, which shows to be another
important performance booster. Simple as it looks, a randomly pruned subnetwork
of Wide ResNet-50 can be sparsely trained to outperforming a dense Wide
ResNet-50, on ImageNet. We also observed such randomly pruned networks
outperform dense counterparts in other favorable aspects, such as
out-of-distribution detection, uncertainty estimation, and adversarial
robustness. Overall, our results strongly suggest there is larger-than-expected
room for sparse training at scale, and the benefits of sparsity might be more
universal beyond carefully designed pruning. Our source code can be found at
https://github.com/VITA-Group/Random_Pruning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A survey of top-down approaches for human pose estimation. (arXiv:2202.02656v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02656">
<div class="article-summary-box-inner">
<span><p>Human pose estimation in two-dimensional images videos has been a hot topic
in the computer vision problem recently due to its vast benefits and potential
applications for improving human life, such as behaviors recognition, motion
capture and augmented reality, training robots, and movement tracking. Many
state-of-the-art methods implemented with Deep Learning have addressed several
challenges and brought tremendous remarkable results in the field of human pose
estimation. Approaches are classified into two kinds: the two-step framework
(top-down approach) and the part-based framework (bottom-up approach). While
the two-step framework first incorporates a person detector and then estimates
the pose within each box independently, detecting all body parts in the image
and associating parts belonging to distinct persons is conducted in the
part-based framework. This paper aims to provide newcomers with an extensive
review of deep learning methods-based 2D images for recognizing the pose of
people, which only focuses on top-down approaches since 2016. The discussion
through this paper presents significant detectors and estimators depending on
mathematical background, the challenges and limitations, benchmark datasets,
evaluation metrics, and comparison between methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LiDAR dataset distillation within bayesian active learning framework: Understanding the effect of data augmentation. (arXiv:2202.02661v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02661">
<div class="article-summary-box-inner">
<span><p>Autonomous driving (AD) datasets have progressively grown in size in the past
few years to enable better deep representation learning. Active learning (AL)
has re-gained attention recently to address reduction of annotation costs and
dataset size. AL has remained relatively unexplored for AD datasets, especially
on point cloud data from LiDARs. This paper performs a principled evaluation of
AL based dataset distillation on (1/4th) of the large Semantic-KITTI dataset.
Further on, the gains in model performance due to data augmentation (DA) are
demonstrated across different subsets of the AL loop. We also demonstrate how
DA improves the selection of informative samples to annotate. We observe that
data augmentation achieves full dataset accuracy using only 60\% of samples
from the selected dataset configuration. This provides faster training time and
subsequent gains in annotation costs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simulation-to-Reality domain adaptation for offline 3D object annotation on pointclouds with correlation alignment. (arXiv:2202.02666v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02666">
<div class="article-summary-box-inner">
<span><p>Annotating objects with 3D bounding boxes in LiDAR pointclouds is a costly
human driven process in an autonomous driving perception system. In this paper,
we present a method to semi-automatically annotate real-world pointclouds
collected by deployment vehicles using simulated data. We train a 3D object
detector model on labeled simulated data from CARLA jointly with real world
pointclouds from our target vehicle. The supervised object detection loss is
augmented with a CORAL loss term to reduce the distance between labeled
simulated and unlabeled real pointcloud feature representations. The goal here
is to learn representations that are invariant to simulated (labeled) and
real-world (unlabeled) target domains. We also provide an updated survey on
domain adaptation methods for pointclouds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SRPCN: Structure Retrieval based Point Completion Network. (arXiv:2202.02669v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02669">
<div class="article-summary-box-inner">
<span><p>Given partial objects and some complete ones as references, point cloud
completion aims to recover authentic shapes. However, existing methods pay
little attention to general shapes, which leads to the poor authenticity of
completion results. Besides, the missing patterns are diverse in reality, but
existing methods can only handle fixed ones, which means a poor generalization
ability. Considering that a partial point cloud is a subset of the
corresponding complete one, we regard them as different samples of the same
distribution and propose Structure Retrieval based Point Completion Network
(SRPCN). It first uses k-means clustering to extract structure points and
disperses them into distributions, and then KL Divergence is used as a metric
to find the complete structure point cloud that best matches the input in a
database. Finally, a PCN-like decoder network is adopted to generate the final
results based on the retrieved structure point clouds. As structure plays an
important role in describing the general shape of an object and the proposed
structure retrieval method is robust to missing patterns, experiments show that
our method can generate more authentic results and has a stronger
generalization ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyper-Convolutions via Implicit Kernels for Medical Imaging. (arXiv:2202.02701v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02701">
<div class="article-summary-box-inner">
<span><p>The convolutional neural network (CNN) is one of the most commonly used
architectures for computer vision tasks. The key building block of a CNN is the
convolutional kernel that aggregates information from the pixel neighborhood
and shares weights across all pixels. A standard CNN's capacity, and thus its
performance, is directly related to the number of learnable kernel weights,
which is determined by the number of channels and the kernel size (support). In
this paper, we present the \textit{hyper-convolution}, a novel building block
that implicitly encodes the convolutional kernel using spatial coordinates.
Hyper-convolutions decouple kernel size from the total number of learnable
parameters, enabling a more flexible architecture design. We demonstrate in our
experiments that replacing regular convolutions with hyper-convolutions can
improve performance with less parameters, and increase robustness against
noise. We provide our code here:
\emph{https://github.com/tym002/Hyper-Convolution}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal Sensor Fusion for Auto Driving Perception: A Survey. (arXiv:2202.02703v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02703">
<div class="article-summary-box-inner">
<span><p>Multi-modal fusion is a fundamental task for the perception of an autonomous
driving system, which has recently intrigued many researchers. However,
achieving a rather good performance is not an easy task due to the noisy raw
data, underutilized information, and the misalignment of multi-modal sensors.
In this paper, we provide a literature review of the existing multi-modal-based
methods for perception tasks in autonomous driving. Generally, we make a
detailed analysis including over 50 papers leveraging perception sensors
including LiDAR and camera trying to solve object detection and semantic
segmentation tasks. Different from traditional fusion methodology for
categorizing fusion models, we propose an innovative way that divides them into
two major classes, four minor classes by a more reasonable taxonomy in the view
of the fusion stage. Moreover, we dive deep into the current fusion methods,
focusing on the remaining problems and open-up discussions on the potential
research opportunities. In conclusion, what we expect to do in this paper is to
present a new taxonomy of multi-modal fusion methods for the autonomous driving
perception tasks and provoke thoughts of the fusion-based techniques in the
future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Portrait Segmentation Using Deep Learning. (arXiv:2202.02705v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02705">
<div class="article-summary-box-inner">
<span><p>A portrait is a painting, drawing, photograph, or engraving of a person,
especially one depicting only the face or head and shoulders. In the digital
world the portrait of a person is captured by having the person as a subject in
the image and capturing the image of the person such that the background is
blurred. DSLRs generally do it by reducing the aperture to focus on very close
regions of interest and automatically blur the background. In this paper I have
come up with a novel approach to replicate the portrait mode from DSLR using
any smartphone to generate high quality portrait images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FEAT: Face Editing with Attention. (arXiv:2202.02713v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02713">
<div class="article-summary-box-inner">
<span><p>Employing the latent space of pretrained generators has recently been shown
to be an effective means for GAN-based face manipulation. The success of this
approach heavily relies on the innate disentanglement of the latent space axes
of the generator. However, face manipulation often intends to affect local
regions only, while common generators do not tend to have the necessary spatial
disentanglement. In this paper, we build on the StyleGAN generator, and present
a method that explicitly encourages face manipulation to focus on the intended
regions by incorporating learned attention maps. During the generation of the
edited image, the attention map serves as a mask that guides a blending between
the original features and the modified ones. The guidance for the latent space
edits is achieved by employing CLIP, which has recently been shown to be
effective for text-driven edits. We perform extensive experiments and show that
our method can perform disentangled and controllable face manipulations based
on text descriptions by attending to the relevant regions only. Both
qualitative and quantitative experimental results demonstrate the superiority
of our method for facial region editing over alternative methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing variational generation through self-decomposition. (arXiv:2202.02738v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02738">
<div class="article-summary-box-inner">
<span><p>In this article we introduce the notion of Split Variational Autoencoder
(SVAE), whose output $\hat{x}$ is obtained as a weighted sum $\sigma \odot
\hat{x_1} + (1-\sigma) \odot \hat{x_2}$ of two generated images
$\hat{x_1},\hat{x_2}$, and $\sigma$ is a learned compositional map. The network
is trained as a usual Variational Autoencoder with a negative loglikelihood
loss between training and reconstructed images. The decomposition is
nondeterministic, but follows two main schemes, that we may roughly categorize
as either "syntactic" or "semantic". In the first case, the map tends to
exploit the strong correlation between adjacent pixels, splitting the image in
two complementary high frequency sub-images. In the second case, the map
typically focuses on the contours of objects, splitting the image in
interesting variations of its content, with more marked and distinctive
features. In this case, the Fr\'echet Inception Distance (FID) of $\hat{x_1}$
and $\hat{x_2}$ is usually lower (hence better) than that of $\hat{x}$, that
clearly suffers from being the average of the formers. In a sense, a SVAE
forces the Variational Autoencoder to {\em make choices}, in contrast with its
intrinsic tendency to average between alternatives with the aim to minimize the
reconstruction loss towards a specific sample. According to the FID metric, our
technique, tested on typical datasets such as Mnist, Cifar10 and Celeba, allows
us to outperform all previous purely variational architectures (not relying on
normalization flows).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Smart Gaze based Annotation of Histopathology Images for Training of Deep Convolutional Neural Networks. (arXiv:2202.02764v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02764">
<div class="article-summary-box-inner">
<span><p>Unavailability of large training datasets is a bottleneck that needs to be
overcome to realize the true potential of deep learning in histopathology
applications. Although slide digitization via whole slide imaging scanners has
increased the speed of data acquisition, labeling of virtual slides requires a
substantial time investment from pathologists. Eye gaze annotations have the
potential to speed up the slide labeling process. This work explores the
viability and timing comparisons of eye gaze labeling compared to conventional
manual labeling for training object detectors. Challenges associated with gaze
based labeling and methods to refine the coarse data annotations for subsequent
object detection are also discussed. Results demonstrate that gaze tracking
based labeling can save valuable pathologist time and delivers good performance
when employed for training a deep object detector. Using the task of
localization of Keratin Pearls in cases of oral squamous cell carcinoma as a
test case, we compare the performance gap between deep object detectors trained
using hand-labelled and gaze-labelled data. On average, compared to
`Bounding-box' based hand-labeling, gaze-labeling required $57.6\%$ less time
per label and compared to `Freehand' labeling, gaze-labeling required on
average $85\%$ less time per label.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Features with Parameter-Free Layers. (arXiv:2202.02777v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02777">
<div class="article-summary-box-inner">
<span><p>Trainable layers such as convolutional building blocks are the standard
network design choices by learning parameters to capture the global context
through successive spatial operations. When designing an efficient network,
trainable layers such as the depthwise convolution is the source of efficiency
in the number of parameters and FLOPs, but there was little improvement to the
model speed in practice. This paper argues that simple built-in parameter-free
operations can be a favorable alternative to the efficient trainable layers
replacing spatial operations in a network architecture. We aim to break the
stereotype of organizing the spatial operations of building blocks into
trainable layers. Extensive experimental analyses based on layer-level studies
with fully-trained models and neural architecture searches are provided to
investigate whether parameter-free operations such as the max-pool are
functional. The studies eventually give us a simple yet effective idea for
redesigning network architectures, where the parameter-free operations are
heavily used as the main building block without sacrificing the model accuracy
as much. Experimental results on the ImageNet dataset demonstrate that the
network architectures with parameter-free operations could enjoy the advantages
of further efficiency in terms of model speed, the number of the parameters,
and FLOPs. Code and ImageNet pretrained models are available at
https://github.com/naver-ai/PfLayer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-domain Unsupervised Image-to-Image Translation with Appearance Adaptive Convolution. (arXiv:2202.02779v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02779">
<div class="article-summary-box-inner">
<span><p>Over the past few years, image-to-image (I2I) translation methods have been
proposed to translate a given image into diverse outputs. Despite the
impressive results, they mainly focus on the I2I translation between two
domains, so the multi-domain I2I translation still remains a challenge. To
address this problem, we propose a novel multi-domain unsupervised
image-to-image translation (MDUIT) framework that leverages the decomposed
content feature and appearance adaptive convolution to translate an image into
a target appearance while preserving the given geometric content. We also
exploit a contrast learning objective, which improves the disentanglement
ability and effectively utilizes multi-domain image data in the training
process by pairing the semantically similar images. This allows our method to
learn the diverse mappings between multiple visual domains with only a single
framework. We show that the proposed method produces visually diverse and
plausible results in multiple domains compared to the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Energy awareness in low precision neural networks. (arXiv:2202.02783v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02783">
<div class="article-summary-box-inner">
<span><p>Power consumption is a major obstacle in the deployment of deep neural
networks (DNNs) on end devices. Existing approaches for reducing power
consumption rely on quite general principles, including avoidance of
multiplication operations and aggressive quantization of weights and
activations. However, these methods do not take into account the precise power
consumed by each module in the network, and are therefore not optimal. In this
paper we develop accurate power consumption models for all arithmetic
operations in the DNN, under various working conditions. We reveal several
important factors that have been overlooked to date. Based on our analysis, we
present PANN (power-aware neural network), a simple approach for approximating
any full-precision network by a low-power fixed-precision variant. Our method
can be applied to a pre-trained network, and can also be used during training
to achieve improved performance. In contrast to previous methods, PANN incurs
only a minor degradation in accuracy w.r.t. the full-precision version of the
network, even when working at the power-budget of a 2-bit quantized variant. In
addition, our scheme enables to seamlessly traverse the power-accuracy
trade-off at deployment time, which is a major advantage over existing
quantization methods that are constrained to specific bit widths.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLPanoDepth: Global-to-Local Panoramic Depth Estimation. (arXiv:2202.02796v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02796">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a learning-based method for predicting dense depth
values of a scene from a monocular omnidirectional image. An omnidirectional
image has a full field-of-view, providing much more complete descriptions of
the scene than perspective images. However, fully-convolutional networks that
most current solutions rely on fail to capture rich global contexts from the
panorama. To address this issue and also the distortion of equirectangular
projection in the panorama, we propose Cubemap Vision Transformers (CViT), a
new transformer-based architecture that can model long-range dependencies and
extract distortion-free global features from the panorama. We show that cubemap
vision transformers have a global receptive field at every stage and can
provide globally coherent predictions for spherical signals. To preserve
important local features, we further design a convolution-based branch in our
pipeline (dubbed GLPanoDepth) and fuse global features from cubemap vision
transformers at multiple scales. This global-to-local strategy allows us to
fully exploit useful global and local features in the panorama, achieving
state-of-the-art performance in panoramic depth estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-confidence Samples Matter for Domain Adaptation. (arXiv:2202.02802v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02802">
<div class="article-summary-box-inner">
<span><p>Domain adaptation (DA) aims to transfer knowledge from a label-rich source
domain to a related but label-scarce target domain. The conventional DA
strategy is to align the feature distributions of the two domains. Recently,
increasing researches have focused on self-training or other semi-supervised
algorithms to explore the data structure of the target domain. However, the
bulk of them depend largely on confident samples in order to build reliable
pseudo labels, prototypes or cluster centers. Representing the target data
structure in such a way would overlook the huge low-confidence samples,
resulting in sub-optimal transferability that is biased towards the samples
similar to the source domain. To overcome this issue, we propose a novel
contrastive learning method by processing low-confidence samples, which
encourages the model to make use of the target data structure through the
instance discrimination process. To be specific, we create positive and
negative pairs only using low-confidence samples, and then re-represent the
original features with the classifier weights rather than directly utilizing
them, which can better encode the task-specific semantic information.
Furthermore, we combine cross-domain mixup to augment the proposed contrastive
loss. Consequently, the domain gap can be well bridged through contrastive
learning of intermediate representations across domains. We evaluate the
proposed method in both unsupervised and semi-supervised DA settings, and
extensive experimental results on benchmarks reveal that our method is
effective and achieves state-of-the-art performance. The code can be found in
https://github.com/zhyx12/MixLRCo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perceptual Coding for Compressed Video Understanding: A New Framework and Benchmark. (arXiv:2202.02813v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02813">
<div class="article-summary-box-inner">
<span><p>Most video understanding methods are learned on high-quality videos. However,
in most real-world scenarios, the videos are first compressed before the
transportation and then decompressed for understanding. The decompressed videos
are degraded in terms of perceptual quality, which may degenerate the
downstream tasks. To address this issue, we propose the first coding framework
for compressed video understanding, where another learnable perceptual
bitstream is introduced and simultaneously transported with the video
bitstream. With the sophisticatedly designed optimization target and network
architectures, this new stream largely boosts the perceptual quality of the
decoded videos yet with a small bit cost. Our framework can enjoy the best of
both two worlds, (1) highly efficient content-coding of industrial video codec
and (2) flexible perceptual-coding of neural networks (NNs). Finally, we build
a rigorous benchmark for compressed video understanding over four different
compression levels, six large-scale datasets, and two popular tasks. The
proposed Dual-bitstream Perceptual Video Coding framework Dual-PVC consistently
demonstrates significantly stronger performances than the baseline codec under
the same bitrate level.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Block shuffling learning for Deepfake Detection. (arXiv:2202.02819v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02819">
<div class="article-summary-box-inner">
<span><p>Although the deepfake detection based on convolutional neural network has
achieved good results, the detection results show that these detectors show
obvious performance degradation when the input images undergo some common
transformations (like resizing, blurring), which indicates that the
generalization ability of the detector is insufficient. In this paper, we
propose a novel block shuffling learning method to solve this problem.
Specifically, we divide the images into blocks and then introduce the random
shuffling to intra-block and inter-block. Intra-block shuffling increases the
robustness of the detector and we also propose an adversarial loss algorithm to
overcome the over-fitting problem brought by the noise introduced by shuffling.
Moreover, we encourage the detector to focus on finding differences among the
local features through inter-block shuffling, and reconstruct the spatial
layout of the blocks to model the semantic associations between them.
Especially, our method can be easily integrated with various CNN models.
Extensive experiments show that our proposed method achieves state-of-the-art
performance in forgery face detection, including good generalization ability in
the face of common image transformations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification. (arXiv:2202.02832v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02832">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks have demonstrated human-level performance in
the classification of melanoma and other skin lesions, but evident performance
disparities between differing skin tones should be addressed before widespread
deployment. In this work, we utilise a modified variational autoencoder to
uncover skin tone bias in datasets commonly used as benchmarks. We propose an
efficient yet effective algorithm for automatically labelling the skin tone of
lesion images, and use this to annotate the benchmark ISIC dataset. We
subsequently use two leading bias unlearning techniques to mitigate skin tone
bias. Our experimental results provide evidence that our skin tone detection
algorithm outperforms existing solutions and that unlearning skin tone improves
generalisation and can reduce the performance disparity between melanoma
detection in lighter and darker skin tones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CheXstray: Real-time Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02833">
<div class="article-summary-box-inner">
<span><p>Rapidly expanding Clinical AI applications worldwide have the potential to
impact to all areas of medical practice. Medical imaging applications
constitute a vast majority of approved clinical AI applications. Though
healthcare systems are eager to adopt AI solutions a fundamental question
remains: \textit{what happens after the AI model goes into production?} We use
the CheXpert and PadChest public datasets to build and test a medical imaging
AI drift monitoring workflow that tracks data and model drift without
contemporaneous ground truth. We simulate drift in multiple experiments to
compare model performance with our novel multi-modal drift metric, which uses
DICOM metadata, image appearance representation from a variational autoencoder
(VAE), and model output probabilities as input. Through experimentation, we
demonstrate a strong proxy for ground truth performance using unsupervised
distributional shifts in relevant metadata, predicted probabilities, and VAE
latent representation. Our key contributions include (1) proof-of-concept for
medical imaging drift detection including use of VAE and domain specific
statistical methods (2) a multi-modal methodology for measuring and unifying
drift metrics (3) new insights into the challenges and solutions for observing
deployed medical imaging AI (4) creation of open-source tools enabling others
to easily run their own workflows or scenarios. This work has important
implications for addressing the translation gap related to continuous medical
imaging AI model monitoring in dynamic healthcare environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Motion Deblurring with an Adaptive Network. (arXiv:1903.11394v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.11394">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the problem of dynamic scene deblurring in the
presence of motion blur. Restoration of images affected by severe blur
necessitates a network design with a large receptive field, which existing
networks attempt to achieve through simple increment in the number of generic
convolution layers, kernel-size, or the scales at which the image is processed.
However, increasing the network capacity in this manner comes at the expense of
increase in model size and inference speed, and ignoring the non-uniform nature
of blur. We present a new architecture composed of spatially adaptive residual
learning modules that implicitly discover the spatially varying shifts
responsible for non-uniform blur in the input image and learn to modulate the
filters. This capability is complemented by a self-attentive module which
captures non-local relationships among the intermediate features and enhances
the receptive field. We then incorporate a spatiotemporal recurrent module in
the design to also facilitate efficient video deblurring. Our networks can
implicitly model the spatially-varying deblurring process, while dispensing
with multi-scale processing and large filters entirely. Extensive qualitative
and quantitative comparisons with prior art on benchmark dynamic scene
deblurring datasets clearly demonstrate the superiority of the proposed
networks via reduction in model-size and significant improvements in accuracy
and speed, enabling almost real-time deblurring.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Planar Geometry and Image Recovery from Motion-Blur. (arXiv:1904.03710v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.03710">
<div class="article-summary-box-inner">
<span><p>Existing works on motion deblurring either ignore the effects of
depth-dependent blur or work with the assumption of a multi-layered scene
wherein each layer is modeled in the form of fronto-parallel plane. In this
work, we consider the case of 3D scenes with piecewise planar structure i.e., a
scene that can be modeled as a combination of multiple planes with arbitrary
orientations. We first propose an approach for estimation of normal of a planar
scene from a single motion blurred observation. We then develop an algorithm
for automatic recovery of number of planes, the parameters corresponding to
each plane, and camera motion from a single motion blurred image of a
multiplanar 3D scene. Finally, we propose a first-of-its-kind approach to
recover the planar geometry and latent image of the scene by adopting an
alternating minimization framework built on our findings. Experiments on
synthetic and real data reveal that our proposed method achieves
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Deepfakes Creation and Detection: A Survey. (arXiv:1909.11573v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11573">
<div class="article-summary-box-inner">
<span><p>Deep learning has been successfully applied to solve various complex problems
ranging from big data analytics to computer vision and human-level control.
Deep learning advances however have also been employed to create software that
can cause threats to privacy, democracy and national security. One of those
deep learning-powered applications recently emerged is deepfake. Deepfake
algorithms can create fake images and videos that humans cannot distinguish
them from authentic ones. The proposal of technologies that can automatically
detect and assess the integrity of digital visual media is therefore
indispensable. This paper presents a survey of algorithms used to create
deepfakes and, more importantly, methods proposed to detect deepfakes in the
literature to date. We present extensive discussions on challenges, research
trends and directions related to deepfake technologies. By reviewing the
background of deepfakes and state-of-the-art deepfake detection methods, this
study provides a comprehensive overview of deepfake techniques and facilitates
the development of new and more robust methods to deal with the increasingly
challenging deepfakes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FISR: Deep Joint Frame Interpolation and Super-Resolution with a Multi-scale Temporal Loss. (arXiv:1912.07213v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.07213">
<div class="article-summary-box-inner">
<span><p>Super-resolution (SR) has been widely used to convert low-resolution legacy
videos to high-resolution (HR) ones, to suit the increasing resolution of
displays (e.g. UHD TVs). However, it becomes easier for humans to notice motion
artifacts (e.g. motion judder) in HR videos being rendered on larger-sized
display devices. Thus, broadcasting standards support higher frame rates for
UHD (Ultra High Definition) videos (4K@60 fps, 8K@120 fps), meaning that
applying SR only is insufficient to produce genuine high quality videos. Hence,
to up-convert legacy videos for realistic applications, not only SR but also
video frame interpolation (VFI) is necessitated. In this paper, we first
propose a joint VFI-SR framework for up-scaling the spatio-temporal resolution
of videos from 2K 30 fps to 4K 60 fps. For this, we propose a novel training
scheme with a multi-scale temporal loss that imposes temporal regularization on
the input video sequence, which can be applied to any general video-related
task. The proposed structure is analyzed in depth with extensive experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FedOCR: Communication-Efficient Federated Learning for Scene Text Recognition. (arXiv:2007.11462v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.11462">
<div class="article-summary-box-inner">
<span><p>While scene text recognition techniques have been widely used in commercial
applications, data privacy has rarely been taken into account by this research
community. Most existing algorithms have assumed a set of shared or centralized
training data. However, in practice, data may be distributed on different local
devices that can not be centralized to share due to the privacy restrictions.
In this paper, we study how to make use of decentralized datasets for training
a robust scene text recognizer while keeping them stay on local devices. To the
best of our knowledge, we propose the first framework leveraging federated
learning for scene text recognition, which is trained with decentralized
datasets collaboratively. Hence we name it FedOCR. To make FedCOR fairly
suitable to be deployed on end devices, we make two improvements including
using lightweight models and hashing techniques. We argue that both are crucial
for FedOCR in terms of the communication efficiency of federated learning. The
simulations on decentralized datasets show that the proposed FedOCR achieves
competitive results to the models that are trained with centralized data, with
fewer communication costs and higher-level privacy-preserving.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compensation Tracker: Reprocessing Lost Object for Multi-Object Tracking. (arXiv:2008.12052v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.12052">
<div class="article-summary-box-inner">
<span><p>Tracking by detection paradigm is one of the most popular object tracking
methods. However, it is very dependent on the performance of the detector. When
the detector has a behavior of missing detection, the tracking result will be
directly affected. In this paper, we analyze the phenomenon of the lost
tracking object in real-time tracking model on MOT2020 dataset. Based on simple
and traditional methods, we propose a compensation tracker to further alleviate
the lost tracking problem caused by missing detection. It consists of a motion
compensation module and an object selection module. The proposed method not
only can re-track missing tracking objects from lost objects, but also does not
require additional networks so as to maintain speed-accuracy trade-off of the
real-time model. Our method only needs to be embedded into the tracker to work
without re-training the network. Experiments show that the compensation tracker
can efficaciously improve the performance of the model and reduce identity
switches. With limited costs, the compensation tracker successfully enhances
the baseline tracking performance by a large margin and reaches 66% of MOTA and
67% of IDF1 on MOT2020 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness. (arXiv:2009.09612v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.09612">
<div class="article-summary-box-inner">
<span><p>Ensemble-based adversarial training is a principled approach to achieve
robustness against adversarial attacks. An important technique of this approach
is to control the transferability of adversarial examples among ensemble
members. We propose in this work a simple yet effective strategy to collaborate
among committee models of an ensemble model. This is achieved via the secure
and insecure sets defined for each model member on a given sample, hence help
us to quantify and regularize the transferability. Consequently, our proposed
framework provides the flexibility to reduce the adversarial transferability as
well as to promote the diversity of ensemble members, which are two crucial
factors for better robustness in our ensemble approach. We conduct extensive
and comprehensive experiments to demonstrate that our proposed method
outperforms the state-of-the-art ensemble baselines, at the same time can
detect a wide range of adversarial examples with a nearly perfect accuracy. Our
code is available at:
https://github.com/tuananhbui89/Crossing-Collaborative-Ensemble.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Real-Time Predictive Pedestrian Collision Warning Service for Cooperative Intelligent Transportation Systems Using 3D Pose Estimation. (arXiv:2009.10868v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10868">
<div class="article-summary-box-inner">
<span><p>Minimizing traffic accidents between vehicles and pedestrians is one of the
primary research goals in intelligent transportation systems. To achieve the
goal, pedestrian orientation recognition and prediction of pedestrian's
crossing or not-crossing intention play a central role. Contemporary approaches
do not guarantee satisfactory performance due to limited field-of-view, lack of
generalization, and high computational complexity. To overcome these
limitations, we propose a real-time predictive pedestrian collision warning
service (P2CWS) for two tasks: pedestrian orientation recognition (100.53 FPS)
and intention prediction (35.76 FPS). Our framework obtains satisfying
generalization over multiple sites because of the proposed site-independent
features. At the center of the feature extraction lies 3D pose estimation. The
3D pose analysis enables robust and accurate recognition of pedestrian
orientations and prediction of intentions over multiple sites. The proposed
vision framework realizes 89.3% accuracy in the behavior recognition task on
the TUD dataset without any training process and 91.28% accuracy in intention
prediction on our dataset achieving new state-of-the-art performance. To
contribute to the corresponding research community, we make our source codes
public which are available at https://github.com/Uehwan/VisionForPedestrian
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging 2D and 3D Segmentation Networks for Computation Efficient Volumetric Medical Image Segmentation: An Empirical Study of 2.5D Solutions. (arXiv:2010.06163v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06163">
<div class="article-summary-box-inner">
<span><p>Recently, deep convolutional neural networks have achieved great success for
medical image segmentation. However, unlike segmentation of natural images,
most medical images such as MRI and CT are volumetric data. In order to make
full use of volumetric information, 3D CNNs are widely used. However, 3D CNNs
suffer from higher inference time and computation cost, which hinders their
further clinical applications. Additionally, with the increased number of
parameters, the risk of overfitting is higher, especially for medical images
where data and annotations are expensive to acquire. To issue this problem,
many 2.5D segmentation methods have been proposed to make use of volumetric
spatial information with less computation cost. Despite these works lead to
improvements on a variety of segmentation tasks, to the best of our knowledge,
there has not previously been a large-scale empirical comparison of these
methods. In this paper, we aim to present a review of the latest developments
of 2.5D methods for volumetric medical image segmentation. Additionally, to
compare the performance and effectiveness of these methods, we provide an
empirical study of these methods on three representative segmentation tasks
involving different modalities and targets. Our experimental results highlight
that 3D CNNs may not always be the best choice. Despite all these 2.5D methods
can bring performance gains to 2D baseline, not all the methods hold the
benefits on different datasets. We hope the results and conclusions of our
study will prove useful for the community on exploring and developing efficient
volumetric medical image segmentation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Regularization Prediction in Diffeomorphic Image Registration. (arXiv:2011.14229v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14229">
<div class="article-summary-box-inner">
<span><p>This paper presents a predictive model for estimating regularization
parameters of diffeomorphic image registration. We introduce a novel framework
that automatically determines the parameters controlling the smoothness of
diffeomorphic transformations. Our method significantly reduces the effort of
parameter tuning, which is time and labor-consuming. To achieve the goal, we
develop a predictive model based on deep convolutional neural networks (CNN)
that learns the mapping between pairwise images and the regularization
parameter of image registration. In contrast to previous methods that estimate
such parameters in a high-dimensional image space, our model is built in an
efficient bandlimited space with much lower dimensions. We demonstrate the
effectiveness of our model on both 2D synthetic data and 3D real brain images.
Experimental results show that our model not only predicts appropriate
regularization parameters for image registration, but also improving the
network training in terms of time and memory efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dense outlier detection and open-set recognition based on training with noisy negative images. (arXiv:2101.09193v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09193">
<div class="article-summary-box-inner">
<span><p>Deep convolutional models often produce inadequate predictions for inputs
foreign to the training distribution. Consequently, the problem of detecting
outlier images has recently been receiving a lot of attention. Unlike most
previous work, we address this problem in the dense prediction context in order
to be able to locate outlier objects in front of in-distribution background.
Our approach is based on two reasonable assumptions. First, we assume that the
inlier dataset is related to some narrow application field (e.g.~road driving).
Second, we assume that there exists a general-purpose dataset which is much
more diverse than the inlier dataset (e.g.~ImageNet-1k). We consider pixels
from the general-purpose dataset as noisy negative training samples since most
(but not all) of them are outliers. We encourage the model to recognize borders
between known and unknown by pasting jittered negative patches over inlier
training images. Our experiments target two dense open-set recognition
benchmarks (WildDash 1 and Fishyscapes) and one dense open-set recognition
dataset (StreetHazard). Extensive performance evaluation indicates competitive
potential of the proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Kanerva++: extending The Kanerva Machine with differentiable, locally block allocated latent memory. (arXiv:2103.03905v3 [cs.NE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03905">
<div class="article-summary-box-inner">
<span><p>Episodic and semantic memory are critical components of the human memory
model. The theory of complementary learning systems (McClelland et al., 1995)
suggests that the compressed representation produced by a serial event
(episodic memory) is later restructured to build a more generalized form of
reusable knowledge (semantic memory). In this work we develop a new principled
Bayesian memory allocation scheme that bridges the gap between episodic and
semantic memory via a hierarchical latent variable model. We take inspiration
from traditional heap allocation and extend the idea of locally contiguous
memory to the Kanerva Machine, enabling a novel differentiable block allocated
latent memory. In contrast to the Kanerva Machine, we simplify the process of
memory writing by treating it as a fully feed forward deterministic process,
relying on the stochasticity of the read key distribution to disperse
information within the memory. We demonstrate that this allocation scheme
improves performance in memory conditional image generation, resulting in new
state-of-the-art conditional likelihood values on binarized MNIST (&lt;=41.58
nats/image) , binarized Omniglot (&lt;=66.24 nats/image), as well as presenting
competitive performance on CIFAR10, DMLab Mazes, Celeb-A and ImageNet32x32.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised and self-adaptative techniques for cross-domain person re-identification. (arXiv:2103.11520v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11520">
<div class="article-summary-box-inner">
<span><p>Person Re-Identification (ReID) across non-overlapping cameras is a
challenging task and, for this reason, most works in the prior art rely on
supervised feature learning from a labeled dataset to match the same person in
different views. However, it demands the time-consuming task of labeling the
acquired data, prohibiting its fast deployment, specially in forensic
scenarios. Unsupervised Domain Adaptation (UDA) emerges as a promising
alternative, as it performs feature-learning adaptation from a model trained on
a source to a target domain without identity-label annotation. However, most
UDA-based algorithms rely upon a complex loss function with several
hyper-parameters, which hinders the generalization to different scenarios.
Moreover, as UDA depends on the translation between domains, it is important to
select the most reliable data from the unseen domain, thus avoiding error
propagation caused by noisy examples on the target data -- an often overlooked
problem. In this sense, we propose a novel UDA-based ReID method that optimizes
a simple loss function with only one hyper-parameter and that takes advantage
of triplets of samples created by a new offline strategy based on the diversity
of cameras within a cluster. This new strategy adapts the model and also
regularizes it, avoiding overfitting on the target domain. We also introduce a
new self-ensembling strategy, in which weights from different iterations are
aggregated to create a final model combining knowledge from distinct moments of
the adaptation. For evaluation, we consider three well-known deep learning
architectures and combine them for final decision-making. The proposed method
does not use person re-ranking nor any label on the target domain, and
outperforms the state of the art, with a much simpler setup, on the Market to
Duke, the challenging Market1501 to MSMT17, and Duke to MSMT17 adaptation
scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Image Aesthetic Assessment. (arXiv:2103.11616v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11616">
<div class="article-summary-box-inner">
<span><p>Automatic image aesthetics assessment is a computer vision problem dealing
with categorizing images into different aesthetic levels. The categorization is
usually done by analyzing an input image and computing some measure of the
degree to which the image adheres to the fundamental principles of photography
such as balance, rhythm, harmony, contrast, unity, look, feel, tone and
texture. Due to its diverse applications in many areas, automatic image
aesthetic assessment has gained significant research attention in recent years.
This article presents a review of the contemporary automatic image aesthetics
assessment techniques. Many traditional hand-crafted and deep learning-based
approaches are reviewed, and critical problem aspects are discussed, including
why some features or models perform better than others and the limitations. A
comparison of the quantitative results of different methods is also provided.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eigenbackground Revisited: Can We Model the Background with Eigenvectors?. (arXiv:2104.11379v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11379">
<div class="article-summary-box-inner">
<span><p>Using dominant eigenvectors for background modeling (usually known as
Eigenbackground) is a common technique in the literature. However, its results
suffer from noticeable artifacts. Thus have been many attempts to reduce the
artifacts by making some improvements/enhancement in the Eigenbackground
algorithm.
</p>
<p>In this paper, we show the main problem of the Eigenbackground is in its own
core and in fact, it is not a good idea to use strongest eigenvectors for
modeling the background. Instead, we propose an alternative solution by
exploiting the weakest eigenvectors (which are usually thrown away and treated
as garbage data) for background modeling. MATLAB codes are available at
\url{https://github.com/mamintoosi/Eigenbackground-Revisited}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary Monocular Cameras. (arXiv:2106.04477v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04477">
<div class="article-summary-box-inner">
<span><p>Synthesizing novel views of dynamic humans from stationary monocular cameras
is a specialized but desirable setup. This is particularly attractive as it
does not require static scenes, controlled environments, or specialized capture
hardware. In contrast to techniques that exploit multi-view observations, the
problem of modeling a dynamic scene from a single view is significantly more
under-constrained and ill-posed. In this paper, we introduce Neural Motion
Consensus Flow (MoCo-Flow), a representation that models dynamic humans in
stationary monocular cameras using a 4D continuous time-variant function. We
learn the proposed representation by optimizing for a dynamic scene that
minimizes the total rendering error, over all the observed images. At the heart
of our work lies a carefully designed optimization scheme, which includes a
dedicated initialization step and is constrained by a motion consensus
regularization on the estimated motion flow. We extensively evaluate MoCo-Flow
on several datasets that contain human motions of varying complexity, and
compare, both qualitatively and quantitatively, to several baselines and
ablated variations of our methods, showing the efficacy and merits of the
proposed approach. Pretrained model, code, and data will be released for
research purposes upon paper acceptance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Training via Boosting Pruning Plasticity with Neuroregeneration. (arXiv:2106.10404v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10404">
<div class="article-summary-box-inner">
<span><p>Works on lottery ticket hypothesis (LTH) and single-shot network pruning
(SNIP) have raised a lot of attention currently on post-training pruning
(iterative magnitude pruning), and before-training pruning (pruning at
initialization). The former method suffers from an extremely large computation
cost and the latter usually struggles with insufficient performance. In
comparison, during-training pruning, a class of pruning methods that
simultaneously enjoys the training/inference efficiency and the comparable
performance, temporarily, has been less explored. To better understand
during-training pruning, we quantitatively study the effect of pruning
throughout training from the perspective of pruning plasticity (the ability of
the pruned networks to recover the original performance). Pruning plasticity
can help explain several other empirical observations about neural network
pruning in literature. We further find that pruning plasticity can be
substantially improved by injecting a brain-inspired mechanism called
neuroregeneration, i.e., to regenerate the same number of connections as
pruned. We design a novel gradual magnitude pruning (GMP) method, named gradual
pruning with zero-cost neuroregeneration (\textbf{GraNet}), that advances state
of the art. Perhaps most impressively, its sparse-to-sparse version for the
first time boosts the sparse-to-sparse training performance over various
dense-to-sparse methods with ResNet-50 on ImageNet without extending the
training time. We release all codes in
https://github.com/Shiweiliuiiiiiii/GraNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity. (arXiv:2106.14568v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14568">
<div class="article-summary-box-inner">
<span><p>The success of deep ensembles on improving predictive performance,
uncertainty estimation, and out-of-distribution robustness has been extensively
studied in the machine learning literature. Albeit the promising results,
naively training multiple deep neural networks and combining their predictions
at inference leads to prohibitive computational costs and memory requirements.
Recently proposed efficient ensemble approaches reach the performance of the
traditional deep ensembles with significantly lower costs. However, the
training resources required by these approaches are still at least the same as
training a single dense model. In this work, we draw a unique connection
between sparse neural network training and deep ensembles, yielding a novel
efficient ensemble learning framework called FreeTickets. Instead of training
multiple dense networks and averaging them, we directly train sparse
subnetworks from scratch and extract diverse yet accurate subnetworks during
this efficient, sparse-to-sparse training. Our framework, FreeTickets, is
defined as the ensemble of these relatively cheap sparse subnetworks. Despite
being an ensemble method, FreeTickets has even fewer parameters and training
FLOPs than a single dense model. This seemingly counter-intuitive outcome is
due to the ultra training/inference efficiency of dynamic sparse training.
FreeTickets surpasses the dense baseline in all the following criteria:
prediction accuracy, uncertainty estimation, out-of-distribution (OoD)
robustness, as well as efficiency for both training and inference.
Impressively, FreeTickets outperforms the naive deep ensemble with ResNet50 on
ImageNet using around only 1/5 of the training FLOPs required by the latter. We
have released our source code at https://github.com/VITA-Group/FreeTickets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional GANs with Auxiliary Discriminative Classifier. (arXiv:2107.10060v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10060">
<div class="article-summary-box-inner">
<span><p>Conditional generative models aim to learn the underlying joint distribution
of data and labels, and thus realize conditional generation. Among them,
auxiliary classifier generative adversarial networks (AC-GAN) have been widely
used, but suffer from the problem of low intra-class diversity on generated
samples. The fundamental reason pointed out in this paper is that the
classifier of AC-GAN is generator-agnostic, which therefore cannot provide
informative guidance to the generator to approximate the target distribution,
resulting in minimization of conditional entropy that decreases the intra-class
diversity. Motivated by this, we propose a novel conditional GAN with auxiliary
\textit{discriminative} classifier (ADC-GAN) to resolve the above problem.
Specifically, the proposed auxiliary \textit{discriminative} classifier becomes
generator-aware by recognizing the labels of the real data and the generated
data \textit{discriminatively}. Our theoretical analysis reveals that the
generator can faithfully replicate the target distribution even without the
original discriminator, making the proposed ADC-GAN robust to the value of
coefficient hyper-parameter and the selection of GAN loss, and being stable
during the training process. Extensive experimental results on synthetic and
real-world datasets demonstrate the superiority of ADC-GAN on conditional
generative modeling compared with state-of-the-art classifier-based and
projection-based cGANs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medical Image Segmentation using 3D Convolutional Neural Networks: A Review. (arXiv:2108.08467v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08467">
<div class="article-summary-box-inner">
<span><p>Computer-aided medical image analysis plays a significant role in assisting
medical practitioners for expert clinical diagnosis and deciding the optimal
treatment plan. At present, convolutional neural networks (CNN) are the
preferred choice for medical image analysis. In addition, with the rapid
advancements in three-dimensional (3D) imaging systems and the availability of
excellent hardware and software support to process large volumes of data, 3D
deep learning methods are gaining popularity in medical image analysis. Here,
we present an extensive review of the recently evolved 3D deep learning methods
in medical image segmentation. Furthermore, the research gaps and future
directions in 3D medical image segmentation are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01134">
<div class="article-summary-box-inner">
<span><p>Large pre-trained vision-language models like CLIP have shown great potential
in learning representations that are transferable across a wide range of
downstream tasks. Different from the traditional representation learning that
is based mostly on discretized labels, vision-language pre-training aligns
images and texts in a common feature space, which allows zero-shot transfer to
any downstream task via \emph{prompting}, i.e., classification weights are
synthesized from natural language describing classes of interest. In this work,
we show that a major challenge for deploying such models in practice is prompt
engineering, which requires domain expertise and is extremely time-consuming --
one needs to spend a significant amount of time on words tuning since a slight
change in wording could have a huge impact on performance. Inspired by recent
advances in prompt learning research in natural language processing (NLP), we
propose \emph{Context Optimization (CoOp)}, a simple approach specifically for
adapting CLIP-like vision-language models for downstream image recognition.
Concretely, CoOp models a prompt's context words with learnable vectors while
the entire pre-trained parameters are kept fixed. To handle different image
recognition tasks, we provide two implementations of CoOp: unified context and
class-specific context. Through extensive experiments on 11 datasets, we
demonstrate that CoOp requires as few as one or two shots to beat hand-crafted
prompts with a decent margin and is able to gain significant improvements when
using more shots, e.g., with 16 shots the average gain is around 15\% (with the
highest reaching over 45\%). Despite being a learning-based approach, CoOp
achieves superb domain generalization performance compared with the zero-shot
model using hand-crafted prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UMPNet: Universal Manipulation Policy Network for Articulated Objects. (arXiv:2109.05668v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05668">
<div class="article-summary-box-inner">
<span><p>We introduce the Universal Manipulation Policy Network (UMPNet) -- a single
image-based policy network that infers closed-loop action sequences for
manipulating arbitrary articulated objects. To infer a wide range of action
trajectories, the policy supports 6DoF action representation and varying
trajectory length. To handle a diverse set of objects, the policy learns from
objects with different articulation structures and generalizes to unseen
objects or categories. The policy is trained with self-guided exploration
without any human demonstrations, scripted policy, or pre-defined goal
conditions. To support effective multi-step interaction, we introduce a novel
Arrow-of-Time action attribute that indicates whether an action will change the
object state back to the past or forward into the future. With the
Arrow-of-Time inference at each interaction step, the learned policy is able to
select actions that consistently lead towards or away from a given state,
thereby, enabling both effective state exploration and goal-conditioned
manipulation. Video is available at https://youtu.be/KqlvcL9RqKM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Single-stream CNN with Learnable Architecture for Multi-source Remote Sensing Data. (arXiv:2109.06094v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06094">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose an efficient and generalizable framework based on
deep convolutional neural network (CNN) for multi-source remote sensing data
joint classification. While recent methods are mostly based on multi-stream
architectures, we use group convolution to construct equivalent network
architectures efficiently within a single-stream network. We further adopt and
improve dynamic grouping convolution (DGConv) to make group convolution
hyperparameters, and thus the overall network architecture, learnable during
network training. The proposed method therefore can theoretically adjust any
modern CNN models to any multi-source remote sensing data set, and can
potentially avoid sub-optimal solutions caused by manually decided architecture
hyperparameters. In the experiments, the proposed method is applied to ResNet
and UNet, and the adjusted networks are verified on three very diverse
benchmark data sets (i.e., Houston2018 data, Berlin data, and MUUFL data).
Experimental results demonstrate the effectiveness of the proposed
single-stream CNNs, and in particular ResNet18-DGConv improves the
state-of-the-art classification overall accuracy (OA) on HS-SAR Berlin data set
from $62.23\%$ to $68.21\%$. In the experiments we have two interesting
findings. First, using DGConv generally reduces test OA variance. Second,
multi-stream is harmful to model performance if imposed to the first few
layers, but becomes beneficial if applied to deeper layers. Altogether, the
findings imply that multi-stream architecture, instead of being a strictly
necessary component in deep learning models for multi-source remote sensing
data, essentially plays the role of model regularizer. Our code is publicly
available at https://github.com/yyyyangyi/Multi-source-RS-DGConv. We hope our
work can inspire novel research in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting the Timing of Camera Movements From the Kinematics of Instruments in Robotic-Assisted Surgery Using Artificial Neural Networks. (arXiv:2109.11192v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11192">
<div class="article-summary-box-inner">
<span><p>Robotic-assisted surgeries benefit both surgeons and patients, however,
surgeons frequently need to adjust the endoscopic camera to achieve good
viewpoints. Simultaneously controlling the camera and the surgical instruments
is impossible, and consequentially, these camera adjustments repeatedly
interrupt the surgery. Autonomous camera control could help overcome this
challenge, but most existing systems are reactive, e.g., by having the camera
follow the surgical instruments. We propose a predictive approach for
anticipating when camera movements will occur using artificial neural networks.
We used the kinematic data of the surgical instruments, which were recorded
during robotic-assisted surgical training on porcine models. We split the data
into segments, and labeled each either as a segment that immediately precedes a
camera movement, or one that does not. Due to the large class imbalance, we
trained an ensemble of networks, each on a balanced sub-set of the training
data. We found that the instruments' kinematic data can be used to predict when
camera movements will occur, and evaluated the performance on different segment
durations and ensemble sizes. We also studied how much in advance an upcoming
camera movement can be predicted, and found that predicting a camera movement
0.25, 0.5, and 1 second before they occurred achieved 98%, 94%, and 84%
accuracy relative to the prediction of an imminent camera movement. This
indicates that camera movement events can be predicted early enough to leave
time for computing and executing an autonomous camera movement and suggests
that an autonomous camera controller for RAMIS may one day be feasible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HarrisZ$^+$: Harris Corner Selection for Next-Gen Image Matching Pipelines. (arXiv:2109.12925v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12925">
<div class="article-summary-box-inner">
<span><p>Due to its role in many computer vision tasks, image matching has been
subjected to an active investigation by researchers, which has lead to better
and more discriminant feature descriptors and to more robust matching
strategies, also thanks to the advent of the deep learning and the increased
computational power of the modern hardware. Despite of these achievements, the
keypoint extraction process at the base of the image matching pipeline has not
seen equivalent progresses. This paper presents HarrisZ$^+$, an upgrade to the
HarrisZ corner detector, optimized to synergically take advance of the recent
improvements of the other steps of the image matching pipeline. HarrisZ$^+$
does not only consists of a tuning of the setup parameters, but introduces
further refinements to the selection criteria delineated by HarrisZ, so
providing more, yet discriminative, keypoints, which are better distributed on
the image and with higher localization accuracy. The image matching pipeline
including HarrisZ$^+$, together with the other modern components, obtained in
different recent matching benchmarks state-of-the-art results among the classic
image matching pipelines. These results are quite close to those obtained by
the more recent fully deep end-to-end trainable approaches and show that there
is still a proper margin of improvement that can be granted by the research in
classic image matching methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for Group-Aware Dense Crowd Trajectory Forecasting. (arXiv:2109.14128v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14128">
<div class="article-summary-box-inner">
<span><p>Accurate, long-term forecasting of human pedestrian trajectories in highly
dynamic and interactive scenes is a long-standing challenge. Recent advances in
using data-driven approaches have achieved significant improvements in terms of
prediction accuracy. However, the lack of group-aware analysis has limited the
performance of forecasting models. This is especially apparent in highly
populated scenes, where pedestrians are moving in groups and the interactions
between groups are extremely complex and dynamic. In this paper, we present
Grouptron, a multi-scale dynamic forecasting framework that leverages
pedestrian group detection and utilizes individual-level, group-level, and
scene-level information for better understanding and representation of the
scenes. Our approach employs spatio-temporal clustering algorithms to identify
pedestrian groups, creates spatio-temporal graphs at the individual, group, and
scene levels. It then uses graph neural networks to encode dynamics at
different scales and incorporates encoding across different scales for
trajectory prediction. We carried out extensive comparisons and ablation
experiments to demonstrate the effectiveness of our approach. Our method
achieves a 9.3% decrease in final displacement error (FDE) compared with
state-of-the-art methods on ETH/UCY benchmark datasets, and a 16.1% decrease in
FDE in more crowded scenes where extensive human group interactions are more
frequently present.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Unlearning of Backdoors via Implicit Hypergradient. (arXiv:2110.03735v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03735">
<div class="article-summary-box-inner">
<span><p>We propose a minimax formulation for removing backdoors from a given poisoned
model based on a small set of clean data. This formulation encompasses much of
prior work on backdoor removal. We propose the Implicit Bacdoor Adversarial
Unlearning (I-BAU) algorithm to solve the minimax. Unlike previous work, which
breaks down the minimax into separate inner and outer problems, our algorithm
utilizes the implicit hypergradient to account for the interdependence between
inner and outer optimization. We theoretically analyze its convergence and the
generalizability of the robustness gained by solving minimax on clean data to
unseen test data. In our evaluation, we compare I-BAU with six state-of-art
backdoor defenses on seven backdoor attacks over two datasets and various
attack settings, including the common setting where the attacker targets one
class as well as important but underexplored settings where multiple classes
are targeted. I-BAU's performance is comparable to and most often significantly
better than the best baseline. Particularly, its performance is more robust to
the variation on triggers, attack settings, poison ratio, and clean data size.
Moreover, I-BAU requires less computation to take effect; particularly, it is
more than $13\times$ faster than the most efficient baseline in the
single-target attack setting. Furthermore, it can remain effective in the
extreme case where the defender can only access 100 clean samples -- a setting
where all the baselines fail to produce acceptable results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Demystifying the Transferability of Adversarial Attacks in Computer Networks. (arXiv:2110.04488v2 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04488">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks (CNNs) models are one of the most frequently
used deep learning networks and are extensively used in both academia and
industry. Recent studies demonstrated that adversarial attacks against such
models can maintain their effectiveness even when used on models other than the
one targeted by the attacker. This major property is known as transferability
and makes CNNs ill-suited for security applications. In this paper, we provide
the first comprehensive study which assesses the robustness of CNN-based models
for computer networks against adversarial transferability. Furthermore, we
investigate whether the transferability property issue holds in computer
networks applications. In our experiments, we first consider five different
attacks: the Iterative Fast Gradient Method (I-FGSM), the Jacobian-based
Saliency Map (JSMA), the Limited-memory Broyden letcher Goldfarb Shanno BFGS
(L-BFGS), the Projected Gradient Descent (PGD), and the DeepFool attack. Then,
we perform these attacks against three well-known datasets: the Network-based
Detection of IoT (N-BaIoT) dataset and the Domain Generating Algorithms (DGA)
dataset, and RIPE Atlas dataset. Our experimental results show clearly that the
transferability happens in specific use cases for the I-FGSM, the JSMA, and the
LBFGS attack. In such scenarios, the attack success rate on the target network
range from 63.00\% to 100\%. Finally, we suggest two shielding strategies to
hinder the attack transferability, by considering the Most Powerful Attacks
(MPAs), and the mismatch LSTM architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ADMM-DAD net: a deep unfolding network for analysis compressed sensing. (arXiv:2110.06986v2 [cs.IT] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06986">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a new deep unfolding neural network based on the
ADMM algorithm for analysis Compressed Sensing. The proposed network jointly
learns a redundant analysis operator for sparsification and reconstructs the
signal of interest. We compare our proposed network with a state-of-the-art
unfolded ISTA decoder, that also learns an orthogonal sparsifier. Moreover, we
consider not only image, but also speech datasets as test examples.
Computational experiments demonstrate that our proposed network outperforms the
state-of-the-art deep unfolding network, consistently for both real-world image
and speech datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?. (arXiv:2110.07472v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07472">
<div class="article-summary-box-inner">
<span><p>Equivariance has emerged as a desirable property of representations of
objects subject to identity-preserving transformations that constitute a group,
such as translations and rotations. However, the expressivity of a
representation constrained by group equivariance is still not fully understood.
We address this gap by providing a generalization of Cover's Function Counting
Theorem that quantifies the number of linearly separable and group-invariant
binary dichotomies that can be assigned to equivariant representations of
objects. We find that the fraction of separable dichotomies is determined by
the dimension of the space that is fixed by the group action. We show how this
relation extends to operations such as convolutions, element-wise
nonlinearities, and global and local pooling. While other operations do not
change the fraction of separable dichotomies, local pooling decreases the
fraction, despite being a highly nonlinear operation. Finally, we test our
theory on intermediate representations of randomly initialized and fully
trained convolutional neural networks and find perfect agreement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TorchEsegeta: Framework for Interpretability and Explainability of Image-based Deep Learning Models. (arXiv:2110.08429v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08429">
<div class="article-summary-box-inner">
<span><p>Clinicians are often very sceptical about applying automatic image processing
approaches, especially deep learning based methods, in practice. One main
reason for this is the black-box nature of these approaches and the inherent
problem of missing insights of the automatically derived decisions. In order to
increase trust in these methods, this paper presents approaches that help to
interpret and explain the results of deep learning algorithms by depicting the
anatomical areas which influence the decision of the algorithm most. Moreover,
this research presents a unified framework, TorchEsegeta, for applying various
interpretability and explainability techniques for deep learning models and
generate visual interpretations and explanations for clinicians to corroborate
their clinical findings. In addition, this will aid in gaining confidence in
such methods. The framework builds on existing interpretability and
explainability techniques that are currently focusing on classification models,
extending them to segmentation tasks. In addition, these methods have been
adapted to 3D models for volumetric analysis. The proposed framework provides
methods to quantitatively compare visual explanations using infidelity and
sensitivity metrics. This framework can be used by data scientists to perform
post-hoc interpretations and explanations of their models, develop more
explainable tools and present the findings to clinicians to increase their
faith in such models. The proposed framework was evaluated based on a use case
scenario of vessel segmentation models trained on Time-of-fight (TOF) Magnetic
Resonance Angiogram (MRA) images of the human brain. Quantitative and
qualitative results of a comparative study of different models and
interpretability methods are presented. Furthermore, this paper provides an
extensive overview of several existing interpretability and explainability
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Demystifying How Self-Supervised Features Improve Training from Noisy Labels. (arXiv:2110.09022v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09022">
<div class="article-summary-box-inner">
<span><p>The advancement of self-supervised learning (SSL) motivates researchers to
apply SSL on other tasks such as learning with noisy labels. Recent literature
indicates that methods built on SSL features can substantially improve the
performance of learning with noisy labels. Nonetheless, the deeper reasons why
(and how) SSL features benefit the training from noisy labels are less
understood. In this paper, we study why and how self-supervised features help
networks resist label noise using both theoretical analyses and numerical
experiments. Our results explain when and why fixing the SSL encoder helps
converge to a better optimum, and why an unfixed encoder is unstable but tends
to achieve a better best-epoch accuracy in more challenging noise settings.
Further, we provide insights for how knowledge distilled from SSL features can
compromise between a fixed encoder and an unfixed encoder. We hope our work
provides a better understanding for learning with noisy labels from the
perspective of self-supervised learning and can potentially serve as a
guideline for further research. Code is available at
github.com/UCSC-REAL/SelfSup_NoisyLabel.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v7 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09113">
<div class="article-summary-box-inner">
<span><p>Salt and pepper noise removal is a common inverse problem in image
processing. Traditional denoising methods have two limitations. First, noise
characteristics are often not described accurately. For example, the noise
location information is often ignored and the sparsity of the salt and pepper
noise is often described by L1 norm, which cannot illustrate the sparse
variables clearly. Second, conventional methods separate the contaminated image
into a recovered image and a noise part, thus resulting in recovering an image
with unsatisfied smooth parts and detail parts. In this study, we introduce a
noise detection strategy to determine the position of the noise, and a
non-convex sparsity regularization depicted by Lp quasi-norm is employed to
describe the sparsity of the noise, thereby addressing the first limitation.
The morphological component analysis framework with stationary Framelet
transform is adopted to decompose the processed image into cartoon, texture,
and noise parts to resolve the second limitation. Then, the alternating
direction method of multipliers (ADMM) is employed to solve the proposed model.
Finally, experiments are conducted to verify the proposed method and compare it
with some current state-of-the-art denoising methods. The experimental results
show that the proposed method can remove salt and pepper noise while preserving
the details of the processed image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">csBoundary: City-scale Road-boundary Detection in Aerial Images for High-definition Maps. (arXiv:2111.06020v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.06020">
<div class="article-summary-box-inner">
<span><p>High-Definition (HD) maps can provide precise geometric and semantic
information of static traffic environments for autonomous driving.
Road-boundary is one of the most important information contained in HD maps
since it distinguishes between road areas and off-road areas, which can guide
vehicles to drive within road areas. But it is labor-intensive to annotate road
boundaries for HD maps at the city scale. To enable automatic HD map
annotation, current work uses semantic segmentation or iterative graph growing
for road-boundary detection. However, the former could not ensure topological
correctness since it works at the pixel level, while the latter suffers from
inefficiency and drifting issues. To provide a solution to the aforementioned
problems, in this letter, we propose a novel system termed csBoundary to
automatically detect road boundaries at the city scale for HD map annotation.
Our network takes as input an aerial image patch, and directly infers the
continuous road-boundary graph (i.e., vertices and edges) from this image. To
generate the city-scale road-boundary graph, we stitch the obtained graphs from
all the image patches. Our csBoundary is evaluated and compared on a public
benchmark dataset. The results demonstrate our superiority. The accompanied
demonstration video is available at our project page
\url{https://sites.google.com/view/csboundary/}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MPF6D: Masked Pyramid Fusion 6D Pose Estimation. (arXiv:2111.09378v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09378">
<div class="article-summary-box-inner">
<span><p>Object pose estimation has multiple important applications, such as robotic
grasping and augmented reality. We present a new method to estimate the 6D pose
of objects that improves upon the accuracy of current proposals and can still
be used in real-time. Our method uses RGB-D data as input to segment objects
and estimate their pose. It uses a neural network with multiple heads to
identify the objects in the scene, generate the appropriate masks and estimate
the values of the translation vectors and the quaternion that represents the
objects' rotation. These heads leverage a pyramid architecture used during
feature extraction and feature fusion. We conduct an empirical evaluation using
the two most common datasets in the area, and compare against state-of-the-art
approaches, illustrating the capabilities of MPF6D. Our method can be used in
real-time with its low inference time and high accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ALIKE: Accurate and Lightweight Keypoint Detection and Descriptor Extraction. (arXiv:2112.02906v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.02906">
<div class="article-summary-box-inner">
<span><p>Existing methods detect the keypoints in a non-differentiable way, therefore
they can not directly optimize the position of keypoints through
back-propagation. To address this issue, we present a partially differentiable
keypoint detection module, which outputs accurate sub-pixel keypoints. The
reprojection loss is then proposed to directly optimize these sub-pixel
keypoints, and the dispersity peak loss is presented for accurate keypoints
regularization. We also extract the descriptors in a sub-pixel way, and they
are trained with the stable neural reprojection error loss. Moreover, a
lightweight network is designed for keypoint detection and descriptor
extraction, which can run at 95 frames per second for 640x480 images on a
commercial GPU. On homography estimation, camera pose estimation, and visual
(re-)localization tasks, the proposed method achieves equivalent performance
with the state-of-the-art approaches, while greatly reduces the inference time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FLAVA: A Foundational Language And Vision Alignment Model. (arXiv:2112.04482v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04482">
<div class="article-summary-box-inner">
<span><p>State-of-the-art vision and vision-and-language models rely on large-scale
visio-linguistic pretraining for obtaining good performance on a variety of
downstream tasks. Generally, such models are often either cross-modal
(contrastive) or multi-modal (with earlier fusion) but not both; and they often
only target specific modalities or tasks. A promising direction would be to use
a single holistic universal model, as a "foundation", that targets all
modalities at once -- a true vision and language foundation model should be
good at vision tasks, language tasks, and cross- and multi-modal vision and
language tasks. We introduce FLAVA as such a model and demonstrate impressive
performance on a wide range of 35 tasks spanning these target modalities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hybrid Atlas Building with Deep Registration Priors. (arXiv:2112.06406v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06406">
<div class="article-summary-box-inner">
<span><p>Registration-based atlas building often poses computational challenges in
high-dimensional image spaces. In this paper, we introduce a novel hybrid atlas
building algorithm that fast estimates atlas from large-scale image datasets
with much reduced computational cost. In contrast to previous approaches that
iteratively perform registration tasks between an estimated atlas and
individual images, we propose to use learned priors of registration from
pre-trained neural networks. This newly developed hybrid framework features
several advantages of (i) providing an efficient way of atlas building without
losing the quality of results, and (ii) offering flexibility in utilizing a
wide variety of deep learning based registration methods. We demonstrate the
effectiveness of this proposed model on 3D brain magnetic resonance imaging
(MRI) scans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual-Key Multimodal Backdoors for Visual Question Answering. (arXiv:2112.07668v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07668">
<div class="article-summary-box-inner">
<span><p>The success of deep learning has enabled advances in multimodal tasks that
require non-trivial fusion of multiple input domains. Although multimodal
models have shown potential in many problems, their increased complexity makes
them more vulnerable to attacks. A Backdoor (or Trojan) attack is a class of
security vulnerability wherein an attacker embeds a malicious secret behavior
into a network (e.g. targeted misclassification) that is activated when an
attacker-specified trigger is added to an input. In this work, we show that
multimodal networks are vulnerable to a novel type of attack that we refer to
as Dual-Key Multimodal Backdoors. This attack exploits the complex fusion
mechanisms used by state-of-the-art networks to embed backdoors that are both
effective and stealthy. Instead of using a single trigger, the proposed attack
embeds a trigger in each of the input modalities and activates the malicious
behavior only when both the triggers are present. We present an extensive study
of multimodal backdoors on the Visual Question Answering (VQA) task with
multiple architectures and visual feature backbones. A major challenge in
embedding backdoors in VQA models is that most models use visual features
extracted from a fixed pretrained object detector. This is challenging for the
attacker as the detector can distort or ignore the visual trigger entirely,
which leads to models where backdoors are over-reliant on the language trigger.
We tackle this problem by proposing a visual trigger optimization strategy
designed for pretrained object detectors. Through this method, we create
Dual-Key Backdoors with over a 98% attack success rate while only poisoning 1%
of the training data. Finally, we release TrojVQA, a large collection of clean
and trojan VQA models to enable research in defending against multimodal
backdoors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Image Visual Question Answering. (arXiv:2112.13706v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13706">
<div class="article-summary-box-inner">
<span><p>While a lot of work has been done on developing models to tackle the problem
of Visual Question Answering, the ability of these models to relate the
question to the image features still remain less explored. We present an
empirical study of different feature extraction methods with different loss
functions. We propose New dataset for the task of Visual Question Answering
with multiple image inputs having only one ground truth, and benchmark our
results on them. Our final model utilising Resnet + RCNN image features and
Bert embeddings, inspired from stacked attention network gives 39% word
accuracy and 99% image accuracy on CLEVER+TinyImagenet dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Band Wi-Fi Sensing with Matched Feature Granularity. (arXiv:2112.14006v2 [cs.NI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.14006">
<div class="article-summary-box-inner">
<span><p>Complementary to the fine-grained channel state information (CSI) from the
physical layer and coarse-grained received signal strength indicator (RSSI)
measurements, the mid-grained spatial beam attributes (e.g., beam SNR) that are
available at millimeter-wave (mmWave) bands during the mandatory beam training
phase can be repurposed for Wi-Fi sensing applications. In this paper, we
propose a multi-band Wi-Fi fusion method for Wi-Fi sensing that hierarchically
fuses the features from both the fine-grained CSI at sub-6 GHz and the
mid-grained beam SNR at 60 GHz in a granularity matching framework. The
granularity matching is realized by pairing two feature maps from the CSI and
beam SNR at different granularity levels and linearly combining all paired
feature maps into a fused feature map with learnable weights. To further
address the issue of limited labeled training data, we propose an
autoencoder-based multi-band Wi-Fi fusion network that can be pre-trained in an
unsupervised fashion. Once the autoencoder-based fusion network is pre-trained,
we detach the decoders and append multi-task sensing heads to the fused feature
map by fine-tuning the fusion block and re-training the multi-task heads from
the scratch. The multi-band Wi-Fi fusion framework is thoroughly validated by
in-house experimental Wi-Fi sensing datasets spanning three tasks: 1) pose
recognition; 2) occupancy sensing; and 3) indoor localization. Comparison to
four baseline methods (i.e., CSI-only, beam SNR-only, input fusion, and feature
fusion) demonstrates the granularity matching improves the multi-task sensing
performance. Quantitative performance is evaluated as a function of the number
of labeled training data, latent space dimension, and fine-tuning learning
rates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RePaint: Inpainting using Denoising Diffusion Probabilistic Models. (arXiv:2201.09865v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09865">
<div class="article-summary-box-inner">
<span><p>Free-form inpainting is the task of adding new content to an image in the
regions specified by an arbitrary binary mask. Most existing approaches train
for a certain distribution of masks, which limits their generalization
capabilities to unseen mask types. Furthermore, training with pixel-wise and
perceptual losses often leads to simple textural extensions towards the missing
areas instead of semantically meaningful generation. In this work, we propose
RePaint: A Denoising Diffusion Probabilistic Model (DDPM) based inpainting
approach that is applicable to even extreme masks. We employ a pretrained
unconditional DDPM as the generative prior. To condition the generation
process, we only alter the reverse diffusion iterations by sampling the
unmasked regions using the given image information. Since this technique does
not modify or condition the original DDPM network itself, the model produces
high-quality and diverse output images for any inpainting form. We validate our
method for both faces and general-purpose image inpainting using standard and
extreme masks.
</p>
<p>RePaint outperforms state-of-the-art Autoregressive, and GAN approaches for
at least five out of six mask distributions.
</p>
<p>Github Repository: git.io/RePaint
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Projective Urban Texturing. (arXiv:2201.10938v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10938">
<div class="article-summary-box-inner">
<span><p>This paper proposes a method for automatic generation of textures for 3D city
meshes in immersive urban environments. Many recent pipelines capture or
synthesize large quantities of city geometry using scanners or procedural
modeling pipelines. Such geometry is intricate and realistic, however the
generation of photo-realistic textures for such large scenes remains a problem.
We propose to generate textures for input target 3D meshes driven by the
textural style present in readily available datasets of panoramic photos
capturing urban environments. Re-targeting such 2D datasets to 3D geometry is
challenging because the underlying shape, size, and layout of the urban
structures in the photos do not correspond to the ones in the target meshes.
Photos also often have objects (e.g., trees, vehicles) that may not even be
present in the target geometry. To address these issues we present a method,
called Projective Urban Texturing (PUT), which re-targets textural style from
real-world panoramic images to unseen urban meshes. PUT relies on contrastive
and adversarial training of a neural architecture designed for unpaired
image-to-texture translation. The generated textures are stored in a texture
atlas applied to the target 3D mesh geometry. To promote texture consistency,
PUT employs an iterative procedure in which texture synthesis is conditioned on
previously generated, adjacent textures. We demonstrate both quantitative and
qualitative evaluation of the generated textures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Denoising Diffusion Restoration Models. (arXiv:2201.11793v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11793">
<div class="article-summary-box-inner">
<span><p>Many interesting tasks in image restoration can be cast as linear inverse
problems. A recent family of approaches for solving these problems uses
stochastic algorithms that sample from the posterior distribution of natural
images given the measurements. However, efficient solutions often require
problem-specific supervised training to model the posterior, whereas
unsupervised methods that are not problem-specific typically rely on
inefficient iterative methods. This work addresses these issues by introducing
Denoising Diffusion Restoration Models (DDRM), an efficient, unsupervised
posterior sampling method. Motivated by variational inference, DDRM takes
advantage of a pre-trained denoising diffusion generative model for solving any
linear inverse problem. We demonstrate DDRM's versatility on several image
datasets for super-resolution, deblurring, inpainting, and colorization under
various amounts of measurement noise. DDRM outperforms the current leading
unsupervised methods on the diverse ImageNet dataset in reconstruction quality,
perceptual quality, and runtime, being 5x faster than the nearest competitor.
DDRM also generalizes well for natural images out of the distribution of the
observed ImageNet training set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite Time Neural ODEs (Continuous DEQs). (arXiv:2201.12240v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12240">
<div class="article-summary-box-inner">
<span><p>Implicit deep learning architectures, like Neural ODEs and Deep Equilibrium
Models (DEQs), separate the definition of a layer from the description of its
solution process. While implicit layers allow features such as depth to adapt
to new scenarios and inputs automatically, this adaptivity makes its
computational expense challenging to predict. Numerous authors have noted that
implicit layer techniques can be more computationally intensive than explicit
layer methods. In this manuscript, we address the question: is there a way to
simultaneously achieve the robustness of implicit layers while allowing the
reduced computational expense of an explicit layer? To solve this we develop
Skip DEQ, an implicit-explicit (IMEX) layer that simultaneously trains an
explicit prediction followed by an implicit correction. We show that training
this explicit layer is free and even decreases the training time by 2.5x and
prediction time by 3.4x. We then further increase the "implicitness" of the DEQ
by redefining the method in terms of an infinite time neural ODE which
paradoxically decreases the training cost over a standard neural ODE by not
requiring backpropagation through time. We demonstrate how the resulting
Continuous Skip DEQ architecture trains more robustly than the original DEQ
while achieving faster training and prediction times. Together, this manuscript
shows how bridging the dichotomy of implicit and explicit deep learning can
combine the advantages of both techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VC-GPT: Visual Conditioned GPT for End-to-End Generative Vision-and-Language Pre-training. (arXiv:2201.12723v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12723">
<div class="article-summary-box-inner">
<span><p>Vision-and-language pre-trained models (VLMs) have achieved tremendous
success in the cross-modal area, but most of them require a large amount of
parallel image-caption data for pre-training. Collating such data is expensive
and labor-intensive. In this work, we focus on reducing such need for
generative vision-and-language pre-training (G-VLP) by taking advantage of the
visual pre-trained model (CLIP-ViT) as encoder and language pre-trained model
(GPT2) as decoder. Unfortunately, GPT2 lacks a necessary cross-attention
module, which hinders the direct connection of CLIP-ViT and GPT2. To remedy
such defects, we conduct extensive experiments to empirically investigate how
to design and pre-train our model. Based on our experimental results, we
propose a novel G-VLP framework, Visual Conditioned GPT (VC-GPT), and pre-train
it with a small-scale image-caption corpus (Visual Genome, only 110k distinct
images). Evaluating on the image captioning downstream tasks (MSCOCO and
Flickr30k Captioning), VC-GPT achieves either the best or the second-best
performance across all evaluation metrics over the previous works which consume
around 30 times more distinct images during cross-modal pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmenting Novelty Search with a Surrogate Model to Engineer Meta-Diversity in Ensembles of Classifiers. (arXiv:2201.12896v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12896">
<div class="article-summary-box-inner">
<span><p>Using Neuroevolution combined with Novelty Search to promote behavioural
diversity is capable of constructing high-performing ensembles for
classification. However, using gradient descent to train evolved architectures
during the search can be computationally prohibitive. Here we propose a method
to overcome this limitation by using a surrogate model which estimates the
behavioural distance between two neural network architectures required to
calculate the sparseness term in Novelty Search. We demonstrate a speedup of 10
times over previous work and significantly improve on previous reported results
on three benchmark datasets from Computer Vision -- CIFAR-10, CIFAR-100, and
SVHN. This results from the expanded architecture search space facilitated by
using a surrogate. Our method represents an improved paradigm for implementing
horizontal scaling of learning algorithms by making an explicit search for
diversity considerably more tractable for the same bounded resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Filtering In Neural Implicit Functions. (arXiv:2201.13013v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.13013">
<div class="article-summary-box-inner">
<span><p>Neural implicit functions are highly effective for representing many kinds of
data, including images and 3D shapes. However, the implicit functions learned
by neural networks usually include over-smoothed patches or noisy artifacts
into the results if the data has many scales of details or a wide range of
frequencies. Adapting the result containing both noise and over-smoothed
regions usually suffers from either over smoothing or noisy issues. To overcome
this challenge, we propose a new framework, coined FINN, that integrates a
filtering module into the neural network to perform data generation while
filtering artifacts. The filtering module has a smoothing operator that acts on
the intermediate results of the network and a recovering operator that brings
distinct details from the input back to the regions overly smoothed. The
proposed method significantly alleviates over smoothing or noisy issues. We
demonstrate the advantage of the FINN on the image regression task, considering
both real-world and synthetic images, and showcases significant improvement on
both quantitative and qualitative results compared to state-of-the-art methods.
Moreover, FINN yields better performance in both convergence speed and network
stability. Source code is available at https://github.com/yixin26/FINN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MHSnet: Multi-head and Spatial Attention Network with False-Positive Reduction for Pulmonary Nodules Detection. (arXiv:2201.13392v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.13392">
<div class="article-summary-box-inner">
<span><p>The mortality of lung cancer has ranked high among cancers for many years.
Early detection of lung cancer is critical for disease prevention, cure, and
mortality rate reduction. However, existing detection methods on pulmonary
nodules introduce an excessive number of false positive proposals in order to
achieve high sensitivity, which is not practical in clinical situations. In
this paper, we propose the multi-head detection and spatial
squeeze-and-attention network, MHSnet, to detect pulmonary nodules, in order to
aid doctors in the early diagnosis of lung cancers. Specifically, we first
introduce multi-head detectors and skip connections to customize for the
variety of nodules in sizes, shapes and types and capture multi-scale features.
Then, we implement a spatial attention module to enable the network to focus on
different regions differently inspired by how experienced clinicians screen CT
images, which results in fewer false positive proposals. Lastly, we present a
lightweight but effective false positive reduction module with the Linear
Regression model to cut down the number of false positive proposals, without
any constraints on the front network. Extensive experimental results compared
with the state-of-the-art models have shown the superiority of the MHSnet in
terms of the average FROC, sensitivity and especially false discovery rate
(2.98% and 2.18% improvement in terms of average FROC and sensitivity, 5.62%
and 28.33% decrease in terms of false discovery rate and average candidates per
scan). The false positive reduction module significantly decreases the average
number of candidates generated per scan by 68.11% and the false discovery rate
by 13.48%, which is promising to reduce distracted proposals for the downstream
tasks based on the detection results.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-02-08 23:06:47.644724618 UTC">2022-02-08 23:06:47 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>