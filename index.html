<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-08T01:30:00Z">10-08</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">NUS-IDS at FinCausal 2021: Dependency Tree in Graph Neural Network for Better Cause-Effect Span Detection. (arXiv:2110.02991v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02991">
<div class="article-summary-box-inner">
<span><p>Automatic identification of cause-effect spans in financial documents is
important for causality modelling and understanding reasons that lead to
financial events. To exploit the observation that words are more connected to
other words with the same cause-effect type in a dependency tree, we construct
useful graph embeddings by incorporating dependency relation features through a
graph neural network. Our model builds on a baseline BERT token classifier with
Viterbi decoding, and outperforms this baseline in cross-validation and during
the competition. In the official run of FinCausal 2021, we obtained Precision,
Recall, and F1 scores of 95.56%, 95.56% and 95.57% that all ranked 1st place,
and an Exact Match score of 86.05% which ranked 3rd place.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Multimodal Language Representations using Convolutional Autoencoders. (arXiv:2110.03007v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03007">
<div class="article-summary-box-inner">
<span><p>Multimodal Language Analysis is a demanding area of research, since it is
associated with two requirements: combining different modalities and capturing
temporal information. During the last years, several works have been proposed
in the area, mostly centered around supervised learning in downstream tasks. In
this paper we propose extracting unsupervised Multimodal Language
representations that are universal and can be applied to different tasks.
Towards this end, we map the word-level aligned multimodal sequences to 2-D
matrices and then use Convolutional Autoencoders to learn embeddings by
combining multiple datasets. Extensive experimentation on Sentiment Analysis
(MOSEI) and Emotion Recognition (IEMOCAP) indicate that the learned
representations can achieve near-state-of-the-art performance with just the use
of a Logistic Regression algorithm for downstream classification. It is also
shown that our method is extremely lightweight and can be easily generalized to
other tasks and unseen data with small performance drop and almost the same
number of parameters. The proposed multimodal representation models are
open-sourced and will help grow the applicability of Multimodal Language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emphasis control for parallel neural TTS. (arXiv:2110.03012v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03012">
<div class="article-summary-box-inner">
<span><p>The semantic information conveyed by a speech signal is strongly influenced
by local variations in prosody. Recent parallel neural text-to-speech (TTS)
synthesis methods are able to generate speech with high fidelity while
maintaining high performance. However, these systems often lack simple control
over the output prosody, thus restricting the semantic information conveyable
for a given text. This paper proposes a hierarchical parallel neural TTS system
for prosodic emphasis control by learning a latent space that directly
corresponds to a change in emphasis. Three candidate features for the latent
space are compared: 1) Variance of pitch and duration within words in a
sentence, 2) a wavelet based feature computed from pitch, energy, and duration
and 3) a learned combination of the above features. Objective measures reveal
that the proposed methods are able to achieve a wide range of emphasis
modification, and subjective evaluations on the degree of emphasis and the
overall quality indicate that they show promise for real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Low-Resource Double Bind: An Empirical Study of Pruning for Low-Resource Machine Translation. (arXiv:2110.03036v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03036">
<div class="article-summary-box-inner">
<span><p>A "bigger is better" explosion in the number of parameters in deep neural
networks has made it increasingly challenging to make state-of-the-art networks
accessible in compute-restricted environments. Compression techniques have
taken on renewed importance as a way to bridge the gap. However, evaluation of
the trade-offs incurred by popular compression techniques has been centered on
high-resource datasets. In this work, we instead consider the impact of
compression in a data-limited regime. We introduce the term low-resource double
bind to refer to the co-occurrence of data limitations and compute resource
constraints. This is a common setting for NLP for low-resource languages, yet
the trade-offs in performance are poorly studied. Our work offers surprising
insights into the relationship between capacity and generalization in
data-limited regimes for the task of machine translation. Our experiments on
magnitude pruning for translations from English into Yoruba, Hausa, Igbo and
German show that in low-resource regimes, sparsity preserves performance on
frequent sentences but has a disparate impact on infrequent ones. However, it
improves robustness to out-of-distribution shifts, especially for datasets that
are very distinct from the training distribution. Our findings suggest that
sparsity can play a beneficial role at curbing memorization of low frequency
attributes, and therefore offers a promising solution to the low-resource
double bind.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating Categorical Features in End-to-End ASR. (arXiv:2110.03047v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03047">
<div class="article-summary-box-inner">
<span><p>All-neural, end-to-end ASR systems gained rapid interest from the speech
recognition community. Such systems convert speech input to text units using a
single trainable neural network model. E2E models require large amounts of
paired speech text data that is expensive to obtain. The amount of data
available varies across different languages and dialects. It is critical to
make use of all these data so that both low resource languages and high
resource languages can be improved. When we want to deploy an ASR system for a
new application domain, the amount of domain specific training data is very
limited. To be able to leverage data from existing domains is important for ASR
accuracy in the new domain. In this paper, we treat all these aspects as
categorical information in an ASR system, and propose a simple yet effective
way to integrate categorical features into E2E model. We perform detailed
analysis on various training strategies, and find that building a joint model
that includes categorical features can be more accurate than multiple
independently trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Neurons Invariant to Sentence Structural Changes in Neural Machine Translation. (arXiv:2110.03067v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03067">
<div class="article-summary-box-inner">
<span><p>To gain insight into the role neurons play, we study the activation patterns
corresponding to meaning-preserving paraphrases (e.g., active-passive). We
compile a dataset of controlled syntactic paraphrases in English with their
reference German translations and demonstrate our model-agnostic approach with
the Transformer translation model. First, we identify neurons that correlate
across paraphrases and dissect the observed correlation into possible
confounds. Although lower-level components are found as the cause of similar
activations, no sentence-level semantics or syntax are detected locally. Later,
we manipulate neuron activations to influence translation towards a particular
syntactic form. We find that a simple value shift is effective, and more so
when many neurons are modified. These suggest that complex syntactic
constructions are indeed encoded in the model. We conclude by discussing how to
better manipulate it using the correlations we first obtained.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DRAFT-What you always wanted to know but could not find about block-based environments. (arXiv:2110.03073v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03073">
<div class="article-summary-box-inner">
<span><p>Block-based environments are visual programming environments, which are
becoming more and more popular because of their ease of use. The ease of use
comes thanks to their intuitive graphical representation and structural
metaphors (jigsaw-like puzzles) to display valid combinations of language
constructs to the users. Part of the current popularity of block-based
environments is thanks to Scratch. As a result they are often associated with
tools for children or young learners. However, it is unclear how these types of
programming environments are developed and used in general. So we conducted a
systematic literature review on block-based environments by studying 152 papers
published between 2014 and 2020, and a non-systematic tool review of 32
block-based environments. In particular, we provide a helpful inventory of
block-based editors for end-users on different topics and domains. Likewise, we
focused on identifying the main components of block-based environments, how
they are engineered, and how they are used. This survey should be equally
helpful for language engineering researchers and language engineers alike.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CTC Variations Through New WFST Topologies. (arXiv:2110.03098v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03098">
<div class="article-summary-box-inner">
<span><p>This paper presents novel Weighted Finite-State Transducer (WFST) topologies
to implement Connectionist Temporal Classification (CTC)-like algorithms for
automatic speech recognition. Three new CTC variants are proposed: (1) the
"compact-CTC", in which direct transitions between units are replaced with
&lt;epsilon&gt; back-off transitions; (2) the "minimal-CTC", that only adds &lt;blank&gt;
self-loops when used in WFST-composition; and (3) "selfless-CTC", that
disallows self-loop for non-blank units. The new CTC variants have several
benefits, such as reducing decoding graph size and GPU memory required for
training while keeping model accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cut the CARP: Fishing for zero-shot story evaluation. (arXiv:2110.03111v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03111">
<div class="article-summary-box-inner">
<span><p>Recent advances in large-scale language models (Raffel et al., 2019; Brown et
al., 2020) have brought significant qualitative and quantitative improvements
in machine-driven text generation. Despite this, generation and evaluation of
machine-generated narrative text remains a challenging problem. Objective
evaluation of computationally-generated stories may be prohibitively expensive,
require meticulously annotated datasets, or may not adequately measure the
logical coherence of a generated story's narratological structure.
</p>
<p>Informed by recent advances in contrastive learning (Radford et al., 2021),
we present Contrastive Authoring and Reviewing Pairing (CARP): a scalable,
efficient method for performing qualitatively superior, zero-shot evaluation of
stories. We show a strong correlation between human evaluation of stories and
those of CARP. Model outputs more significantly correlate with corresponding
human input than those language-model based methods which utilize finetuning or
prompt engineering approaches. We also present and analyze the Story-Critique
Dataset, a new corpora composed of 1.3 million aligned story-critique pairs
derived from over 80,000 stories. We expect this corpus to be of interest to
NLP researchers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Study of Transformer-Based Language Models on Extractive Question Answering. (arXiv:2110.03142v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03142">
<div class="article-summary-box-inner">
<span><p>Question Answering (QA) is a task in natural language processing that has
seen considerable growth after the advent of transformers. There has been a
surge in QA datasets that have been proposed to challenge natural language
processing models to improve human and existing model performance. Many
pre-trained language models have proven to be incredibly effective at the task
of extractive question answering. However, generalizability remains as a
challenge for the majority of these models. That is, some datasets require
models to reason more than others. In this paper, we train various pre-trained
language models and fine-tune them on multiple question answering datasets of
varying levels of difficulty to determine which of the models are capable of
generalizing the most comprehensively across different datasets. Further, we
propose a new architecture, BERT-BiLSTM, and compare it with other language
models to determine if adding more bidirectionality can improve model
performance. Using the F1-score as our metric, we find that the RoBERTa and
BART pre-trained models perform the best across all datasets and that our
BERT-BiLSTM model outperforms the baseline BERT model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transcribe-to-Diarize: Neural Speaker Diarization for Unlimited Number of Speakers using End-to-End Speaker-Attributed ASR. (arXiv:2110.03151v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03151">
<div class="article-summary-box-inner">
<span><p>This paper presents Transcribe-to-Diarize, a new approach for neural speaker
diarization that uses an end-to-end (E2E) speaker-attributed automatic speech
recognition (SA-ASR). The E2E SA-ASR is a joint model that was recently
proposed for speaker counting, multi-talker speech recognition, and speaker
identification from monaural audio that contains overlapping speech. Although
the E2E SA-ASR model originally does not estimate any time-related information,
we show that the start and end times of each word can be estimated with
sufficient accuracy from the internal state of the E2E SA-ASR by adding a small
number of learnable parameters. Similar to the target-speaker voice activity
detection (TS-VAD)-based diarization method, the E2E SA-ASR model is applied to
estimate speech activity of each speaker while it has the advantages of (i)
handling unlimited number of speakers, (ii) leveraging linguistic information
for speaker diarization, and (iii) simultaneously generating speaker-attributed
transcriptions. Experimental results on the LibriCSS and AMI corpora show that
the proposed method achieves significantly better diarization error rate than
various existing speaker diarization methods when the number of speakers is
unknown, and achieves a comparable performance to TS-VAD when the number of
speakers is given in advance. The proposed method simultaneously generates
speaker-attributed transcription with state-of-the-art accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transliteration of Foreign Words in Burmese. (arXiv:2110.03163v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03163">
<div class="article-summary-box-inner">
<span><p>This manuscript provides general descriptions on transliteration of foreign
words in the Burmese language. Phenomena caused by phonetic and orthographic
issues are discussed. Based on this work, we expect to gradually establish
prescriptive guidelines to normalize the transliteration in Burmese in future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HowSumm: A Multi-Document Summarization Dataset Derived from WikiHow Articles. (arXiv:2110.03179v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03179">
<div class="article-summary-box-inner">
<span><p>We present \textsc{HowSumm}, a novel large-scale dataset for the task of
query-focused multi-document summarization (qMDS), which targets the use-case
of generating actionable instructions from a set of sources. This use-case is
different from the use-cases covered in existing multi-document summarization
(MDS) datasets and is applicable to educational and industrial scenarios. We
employed automatic methods, and leveraged statistics from existing
human-crafted qMDS datasets, to create \textsc{HowSumm} from wikiHow website
articles and the sources they cite. We describe the creation of the dataset and
discuss the unique features that distinguish it from other summarization
corpora. Automatic and human evaluations of both extractive and abstractive
summarization models on the dataset reveal that there is room for improvement.
% in existing summarization models We propose that \textsc{HowSumm} can be
leveraged to advance summarization research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GNN is a Counter? Revisiting GNN for Question Answering. (arXiv:2110.03192v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03192">
<div class="article-summary-box-inner">
<span><p>Question Answering (QA) has been a long-standing research topic in AI and NLP
fields, and a wealth of studies have been conducted to attempt to equip QA
systems with human-level reasoning capability. To approximate the complicated
human reasoning process, state-of-the-art QA systems commonly use pre-trained
language models (LMs) to access knowledge encoded in LMs together with
elaborately designed modules based on Graph Neural Networks (GNNs) to perform
reasoning over knowledge graphs (KGs). However, many problems remain open
regarding the reasoning functionality of these GNN-based modules. Can these
GNN-based modules really perform a complex reasoning process? Are they under-
or over-complicated for QA? To open the black box of GNN and investigate these
problems, we dissect state-of-the-art GNN modules for QA and analyze their
reasoning capability. We discover that even a very simple graph neural counter
can outperform all the existing GNN modules on CommonsenseQA and OpenBookQA,
two popular QA benchmark datasets which heavily rely on knowledge-aware
reasoning. Our work reveals that existing knowledge-aware GNN modules may only
carry out some simple reasoning such as counting. It remains a challenging open
problem to build comprehensive reasoning modules for knowledge-powered QA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Influence Tuning: Demoting Spurious Correlations via Instance Attribution and Instance-Driven Updates. (arXiv:2110.03212v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03212">
<div class="article-summary-box-inner">
<span><p>Among the most critical limitations of deep learning NLP models are their
lack of interpretability, and their reliance on spurious correlations. Prior
work proposed various approaches to interpreting the black-box models to unveil
the spurious correlations, but the research was primarily used in
human-computer interaction scenarios. It still remains underexplored whether or
how such model interpretations can be used to automatically "unlearn"
confounding features. In this work, we propose influence tuning--a procedure
that leverages model interpretations to update the model parameters towards a
plausible interpretation (rather than an interpretation that relies on spurious
patterns in the data) in addition to learning to predict the task labels. We
show that in a controlled setup, influence tuning can help deconfounding the
model from spurious patterns in data, significantly outperforming baseline
methods that use adversarial training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Continual Knowledge Learning of Language Models. (arXiv:2110.03215v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03215">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LMs) are known to encode world knowledge in their
parameters as they pretrain on a vast amount of web corpus, which is often
utilized for performing knowledge-dependent downstream tasks such as question
answering, fact-checking, and open dialogue. In real-world scenarios, the world
knowledge stored in the LMs can quickly become outdated as the world changes,
but it is non-trivial to avoid catastrophic forgetting and reliably acquire new
knowledge while preserving invariant knowledge. To push the community towards
better maintenance of ever-changing LMs, we formulate a new continual learning
(CL) problem called Continual Knowledge Learning (CKL). We construct a new
benchmark and metric to quantify the retention of time-invariant world
knowledge, the update of outdated knowledge, and the acquisition of new
knowledge. We adopt applicable recent methods from literature to create several
strong baselines. Through extensive experiments, we find that CKL exhibits
unique challenges that are not addressed in previous CL setups, where parameter
expansion is necessary to reliably retain and learn knowledge simultaneously.
By highlighting the critical causes of knowledge forgetting, we show that CKL
is a challenging and important problem that helps us better understand and
train ever-changing LMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layer-wise Pruning of Transformer Attention Heads for Efficient Language Modeling. (arXiv:2110.03252v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03252">
<div class="article-summary-box-inner">
<span><p>While Transformer-based models have shown impressive language modeling
performance, the large computation cost is often prohibitive for practical use.
Attention head pruning, which removes unnecessary attention heads in the
multihead attention, is a promising technique to solve this problem. However,
it does not evenly reduce the overall load because the heavy feedforward module
is not affected by head pruning. In this paper, we apply layer-wise attention
head pruning on All-attention Transformer so that the entire computation and
the number of parameters can be reduced proportionally to the number of pruned
heads. While the architecture has the potential to fully utilize head pruning,
we propose three training methods that are especially helpful to minimize
performance degradation and stabilize the pruning process. Our pruned model
shows consistently lower perplexity within a comparable parameter size than
Transformer-XL on WikiText-103 language modeling benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Situated Dialogue Learning through Procedural Environment Generation. (arXiv:2110.03262v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03262">
<div class="article-summary-box-inner">
<span><p>We teach goal-driven agents to interactively act and speak in situated
environments by training on generated curriculums. Our agents operate in LIGHT
(Urbanek et al. 2019) -- a large-scale crowd-sourced fantasy text adventure
game wherein an agent perceives and interacts with the world through textual
natural language. Goals in this environment take the form of character-based
quests, consisting of personas and motivations. We augment LIGHT by learning to
procedurally generate additional novel textual worlds and quests to create a
curriculum of steadily increasing difficulty for training agents to achieve
such goals. In particular, we measure curriculum difficulty in terms of the
rarity of the quest in the original training distribution -- an easier
environment is one that is more likely to have been found in the unaugmented
dataset. An ablation study shows that this method of learning from the tail of
a distribution results in significantly higher generalization abilities as
measured by zero-shot performance on never-before-seen quests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-tasking Dialogue Comprehension with Discourse Parsing. (arXiv:2110.03269v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03269">
<div class="article-summary-box-inner">
<span><p>Multi-party dialogue machine reading comprehension (MRC) raises an even more
challenging understanding goal on dialogue with more than two involved
speakers, compared with the traditional plain passage style MRC. To accurately
perform the question-answering (QA) task according to such multi-party
dialogue, models have to handle fundamentally different discourse relationships
from common non-dialogue plain text, where discourse relations are supposed to
connect two far apart utterances in a linguistics-motivated way.To further
explore the role of such unusual discourse structure on the correlated QA task
in terms of MRC, we propose the first multi-task model for jointly performing
QA and discourse parsing (DP) on the multi-party dialogue MRC task. Our
proposed model is evaluated on the latest benchmark Molweni, whose results
indicate that training with complementary tasks indeed benefits not only QA
task, but also DP task itself. We further find that the joint model is
distinctly stronger when handling longer dialogues which again verifies the
necessity of DP in the related MRC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Autism Spectrum Disorders with Machine Learning Models Using Speech Transcripts. (arXiv:2110.03281v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03281">
<div class="article-summary-box-inner">
<span><p>Autism spectrum disorder (ASD) can be defined as a neurodevelopmental
disorder that affects how children interact, communicate and socialize with
others. This disorder can occur in a broad spectrum of symptoms, with varying
effects and severity. While there is no permanent cure for ASD, early detection
and proactive treatment can substantially improve the lives of many children.
Current methods to accurately diagnose ASD are invasive, time-consuming, and
tedious. They can also be subjective perspectives of a number of clinicians
involved, including pediatricians, speech pathologists, psychologists, and
psychiatrists. New technologies are rapidly emerging that include machine
learning models using speech, computer vision from facial, retinal, and brain
MRI images of patients to accurately and timely detect this disorder. Our
research focuses on computational linguistics and machine learning using speech
data from TalkBank, the world's largest spoken language database. We used data
of both ASD and Typical Development (TD) in children from TalkBank to develop
machine learning models to accurately predict ASD. More than 50 features were
used from specifically two datasets in TalkBank to run our experiments using
five different classifiers. Logistic Regression and Random Forest models were
found to be the most effective for each of these two main datasets, with an
accuracy of 0.75. These experiments confirm that while significant
opportunities exist for improving the accuracy, machine learning models can
reliably predict ASD status in children for effective diagnosis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Supermask Pruning: Learning to Prune Image Captioning Models. (arXiv:2110.03298v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03298">
<div class="article-summary-box-inner">
<span><p>With the advancement of deep models, research work on image captioning has
led to a remarkable gain in raw performance over the last decade, along with
increasing model complexity and computational cost. However, surprisingly works
on compression of deep networks for image captioning task has received little
to no attention. For the first time in image captioning research, we provide an
extensive comparison of various unstructured weight pruning methods on three
different popular image captioning architectures, namely Soft-Attention,
Up-Down and Object Relation Transformer. Following this, we propose a novel
end-to-end weight pruning method that performs gradual sparsification based on
weight sensitivity to the training loss. The pruning schemes are then extended
with encoder pruning, where we show that conducting both decoder pruning and
training simultaneously prior to the encoder pruning provides good overall
performance. Empirically, we show that an 80% to 95% sparse network (up to 75%
reduction in model size) can either match or outperform its dense counterpart.
The code and pre-trained models for Up-Down and Object Relation Transformer
that are capable of achieving CIDEr scores &gt;120 on the MS-COCO dataset but with
only 8.7 MB and 14.5 MB in model size (size reduction of 96% and 94%
respectively against dense versions) are publicly available at
https://github.com/jiahuei/sparse-image-captioning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Latent Holes of VAEs for Text Generation. (arXiv:2110.03318v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03318">
<div class="article-summary-box-inner">
<span><p>In this paper, we provide the first focused study on the discontinuities
(aka. holes) in the latent space of Variational Auto-Encoders (VAEs), a
phenomenon which has been shown to have a detrimental effect on model capacity.
When investigating latent holes, existing works are exclusively centred around
the encoder network and they merely explore the existence of holes. We tackle
these limitations by proposing a highly efficient Tree-based Decoder-Centric
(TDC) algorithm for latent hole identification, with a focal point on the text
domain. In contrast to past studies, our approach pays attention to the decoder
network, as a decoder has a direct impact on the model's output quality.
Furthermore, we provide, for the first time, in-depth empirical analysis of the
latent hole phenomenon, investigating several important aspects such as how the
holes impact VAE algorithms' performance on text generation, and how the holes
are distributed in the latent space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Logic-Based Framework for Natural Language Inference in Dutch. (arXiv:2110.03323v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03323">
<div class="article-summary-box-inner">
<span><p>At its core, the system is powered by two ${\lambda}$-calculi, used as
syntactic and semantic theories, respectively. Sentences are first converted to
syntactic proofs and terms of the linear ${\lambda}$-calculus using a choice of
two parsers: an Alpino-based pipeline, and Neural Proof Nets. The syntactic
terms are then converted to semantic terms of the simply typed
${\lambda}$-calculus, via a set of hand designed type- and term-level
transformations. Pairs of semantic terms are then fed to an automated theorem
prover for natural logic which reasons with them while using lexical relations
found in the Open Dutch WordNet. We evaluate the reasoning pipeline on the
recently created Dutch natural language inference dataset, and achieve
promising results, remaining only within a $1.1-3.2{\%}$ performance margin to
strong neural baselines. To the best of our knowledge, the reasoning pipeline
is the first logic-based system for Dutch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Back from the future: bidirectional CTC decoding using future information in speech recognition. (arXiv:2110.03326v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03326">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a simple but effective method to decode the output
of Connectionist Temporal Classifier (CTC) model using a bi-directional neural
language model. The bidirectional language model uses the future as well as the
past information in order to predict the next output in the sequence. The
proposed method based on bi-directional beam search takes advantage of the CTC
greedy decoding output to represent the noisy future information. Experiments
on the Librispeechdataset demonstrate the superiority of our proposed method
compared to baselines using unidirectional decoding. In particular, the boost
inaccuracy is most apparent at the start of a sequence which is the most
erroneous part for existing systems based on unidirectional decoding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Language Learning for Entity Matching. (arXiv:2110.03338v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03338">
<div class="article-summary-box-inner">
<span><p>Transformer-based matching methods have significantly moved the
state-of-the-art for less-structured matching tasks involving textual entity
descriptions. In order to excel on these tasks, Transformer-based matching
methods require a decent amount of training pairs. Providing enough training
data can be challenging, especially if a matcher for non-English entity
descriptions should be learned. This paper explores along the use case of
matching product offers from different e-shops to which extent it is possible
to improve the performance of Transformer-based entity matchers by
complementing a small set of training pairs in the target language, German in
our case, with a larger set of English-language training pairs. Our experiments
using different Transformers show that extending the German set with English
pairs is always beneficial. The impact of adding the English pairs is
especially high in low-resource settings in which only a rather small number of
non-English pairs is available. As it is often possible to automatically gather
English training pairs from the Web by using schema.org annotations, our
results could proof relevant for many product matching scenarios targeting
low-resource languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VisualTTS: TTS with Accurate Lip-Speech Synchronization for Automatic Voice Over. (arXiv:2110.03342v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03342">
<div class="article-summary-box-inner">
<span><p>In this paper, we formulate a novel task to synthesize speech in sync with a
silent pre-recorded video, denoted as automatic voice over (AVO). Unlike
traditional speech synthesis, AVO seeks to generate not only human-sounding
speech, but also perfect lip-speech synchronization. A natural solution to AVO
is to condition the speech rendering on the temporal progression of lip
sequence in the video. We propose a novel text-to-speech model that is
conditioned on visual input, named VisualTTS, for accurate lip-speech
synchronization. The proposed VisualTTS adopts two novel mechanisms that are 1)
textual-visual attention, and 2) visual fusion strategy during acoustic
decoding, which both contribute to forming accurate alignment between the input
text content and lip motion in input lip sequence. Experimental results show
that VisualTTS achieves accurate lip-speech synchronization and outperforms all
baseline systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Noisy Text Data: Achilles' Heel of popular transformer based NLP models. (arXiv:2110.03353v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03353">
<div class="article-summary-box-inner">
<span><p>In the last few years, the ML community has created a number of new NLP
models based on transformer architecture. These models have shown great
performance for various NLP tasks on benchmark datasets, often surpassing SOTA
results. Buoyed with this success, one often finds industry practitioners
actively experimenting with fine-tuning these models to build NLP applications
for industry use cases. However, for most datasets that are used by
practitioners to build industrial NLP applications, it is hard to guarantee the
presence of any noise in the data. While most transformer based NLP models have
performed exceedingly well in transferring the learnings from one dataset to
another, it remains unclear how these models perform when fine-tuned on noisy
text. We address the open question by Kumar et al. (2020) to explore the
sensitivity of popular transformer based NLP models to noise in the text data.
We continue working with the noise as defined by them -- spelling mistakes &amp;
typos (which are the most commonly occurring noise). We show (via experimental
results) that these models perform badly on most common NLP tasks namely text
classification, textual similarity, NER, question answering, text summarization
on benchmark datasets. We further show that as the noise in data increases, the
performance degrades. Our findings suggest that one must be vary of the
presence of noise in their datasets while fine-tuning popular transformer based
NLP models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WenetSpeech: A 10000+ Hours Multi-domain Mandarin Corpus for Speech Recognition. (arXiv:2110.03370v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03370">
<div class="article-summary-box-inner">
<span><p>In this paper, we present WenetSpeech, a multi-domain Mandarin corpus
consisting of 10000+ hours high-quality labeled speech, 2400+ hours weakly
labeled speech, and about 10000 hours unlabeled speech, with 22400+ hours in
total. We collect the data from YouTube and Podcast, which covers a variety of
speaking styles, scenarios, domains, topics, and noisy conditions. An optical
character recognition (OCR) based method is introduced to generate the
audio/text segmentation candidates for the YouTube data on its corresponding
video captions, while a high-quality ASR transcription system is used to
generate audio/text pair candidates for the Podcast data. Then we propose a
novel end-to-end label error detection approach to further validate and filter
the candidates. We also provide three manually labelled high-quality test sets
along with WenetSpeech for evaluation -- Dev for cross-validation purpose in
training, Test_Net, collected from Internet for matched test, and
Test\_Meeting, recorded from real meetings for more challenging mismatched
test. Baseline systems trained with WenetSpeech are provided for three popular
speech recognition toolkits, namely Kaldi, ESPnet, and WeNet, and recognition
results on the three test sets are also provided as benchmarks. To the best of
our knowledge, WenetSpeech is the current largest open-sourced Mandarin speech
corpus with transcriptions, which benefits research on production-level speech
recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangled dimensionality reduction for noise-robust speaker diarisation. (arXiv:2110.03380v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03380">
<div class="article-summary-box-inner">
<span><p>The objective of this work is to train noise-robust speaker embeddings for
speaker diarisation. Speaker embeddings play a crucial role in the performance
of diarisation systems, but they often capture spurious information such as
noise and reverberation, adversely affecting performance. Our previous work
have proposed an auto-encoder-based dimensionality reduction module to help
remove the spurious information. However, they do not explicitly separate such
information and have also been found to be sensitive to hyperparameter values.
To this end, we propose two contributions to overcome these issues: (i) a novel
dimensionality reduction framework that can disentangle spurious information
from the speaker embeddings; (ii) the use of a speech/non-speech indicator to
prevent the speaker code from learning from the background noise. Through a
range of experiments conducted on four different datasets, our approach
consistently demonstrates the state-of-the-art performance among models that do
not adopt ensembles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beam Search with Bidirectional Strategies for Neural Response Generation. (arXiv:2110.03389v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03389">
<div class="article-summary-box-inner">
<span><p>Sequence-to-sequence neural networks have been widely used in language-based
applications as they have flexible capabilities to learn various language
models. However, when seeking for the optimal language response through trained
neural networks, current existing approaches such as beam-search decoder
strategies are still not able reaching to promising performances. Instead of
developing various decoder strategies based on a "regular sentence order"
neural network (a trained model by outputting sentences from left-to-right
order), we leveraged "reverse" order as additional language model (a trained
model by outputting sentences from right-to-left order) which can provide
different perspectives for the path finding problems. In this paper, we propose
bidirectional strategies in searching paths by combining two networks
(left-to-right and right-to-left language models) making a bidirectional beam
search possible. Besides, our solution allows us using any similarity measure
in our sentence selection criterion. Our approaches demonstrate better
performance compared to the unidirectional beam search strategy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Attention always needed? A Case Study on Language Identification from Speech. (arXiv:2110.03427v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03427">
<div class="article-summary-box-inner">
<span><p>Language Identification (LID), a recommended initial step to Automatic Speech
Recognition (ASR), is used to detect a spoken language from audio specimens. In
state-of-the-art systems capable of multilingual speech processing, however,
users have to explicitly set one or more languages before using them. LID,
therefore, plays a very important role in situations where ASR based systems
cannot parse the uttered language in multilingual contexts causing failure in
speech recognition. We propose an attention based convolutional recurrent
neural network (CRNN with Attention) that works on Mel-frequency Cepstral
Coefficient (MFCC) features of audio specimens. Additionally, we reproduce some
state-of-the-art approaches, namely Convolutional Neural Network (CNN) and
Convolutional Recurrent Neural Network (CRNN), and compare them to our proposed
method. We performed extensive evaluation on thirteen different Indian
languages and our model achieves classification accuracy over 98%. Our LID
model is robust to noise and provides 91.2% accuracy in a noisy scenario. The
proposed model is easily extensible to new languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pretrained Language Models are Symbolic Mathematics Solvers too!. (arXiv:2110.03501v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03501">
<div class="article-summary-box-inner">
<span><p>Solving symbolic mathematics has always been of in the arena of human
ingenuity that needs compositional reasoning and recurrence. However, recent
studies have shown that large-scale language models such as transformers are
universal and surprisingly can be trained as a sequence-to-sequence task to
solve complex mathematical equations. These large transformer models need
humongous amounts of training data to generalize to unseen symbolic mathematics
problems. In this paper, we present a sample efficient way of solving the
symbolic tasks by first pretraining the transformer model with language
translation and then fine-tuning the pretrained transformer model to solve the
downstream task of symbolic mathematics. We achieve comparable accuracy on the
integration task with our pretrained model while using around $1.5$ orders of
magnitude less number of training samples with respect to the state-of-the-art
deep learning for symbolic mathematics. The test accuracy on differential
equation tasks is considerably lower comparing with integration as they need
higher order recursions that are not present in language translations. We
pretrain our model with different pairs of language translations. Our results
show language bias in solving symbolic mathematics tasks. Finally, we study the
robustness of the fine-tuned model on symbolic math tasks against distribution
shift, and our approach generalizes better in distribution shift scenarios for
the function integration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mandarin-English Code-switching Speech Recognition with Self-supervised Speech Representation Models. (arXiv:2110.03504v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03504">
<div class="article-summary-box-inner">
<span><p>Code-switching (CS) is common in daily conversations where more than one
language is used within a sentence. The difficulties of CS speech recognition
lie in alternating languages and the lack of transcribed data. Therefore, this
paper uses the recently successful self-supervised learning (SSL) methods to
leverage many unlabeled speech data without CS. We show that hidden
representations of SSL models offer frame-level language identity even if the
models are trained with English speech only. Jointly training CTC and language
identification modules with self-supervised speech representations improves CS
speech recognition performance. Furthermore, using multilingual speech data for
pre-training obtains the best CS speech recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Single-Trial Representational Similarity Analysis with EEG to track semantic similarity in emotional word processing. (arXiv:2110.03529v1 [q-bio.NC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03529">
<div class="article-summary-box-inner">
<span><p>Electroencephalography (EEG) is a powerful non-invasive brain imaging
technique with a high temporal resolution that has seen extensive use across
multiple areas of cognitive science research. This thesis adapts
representational similarity analysis (RSA) to single-trial EEG datasets and
introduces its principles to EEG researchers unfamiliar with multivariate
analyses. We have two separate aims: 1. we want to explore the effectiveness of
single-trial RSA on EEG datasets; 2. we want to utilize single-trial RSA and
computational semantic models to investigate the role of semantic meaning in
emotional word processing. We report two primary findings: 1. single-trial RSA
on EEG datasets can produce meaningful and interpretable results given a high
number of trials and subjects; 2. single-trial RSA reveals that emotional
processing in the 500-800ms time window is associated with additional semantic
analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mRAT-SQL+GAP:A Portuguese Text-to-SQL Transformer. (arXiv:2110.03546v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03546">
<div class="article-summary-box-inner">
<span><p>The translation of natural language questions to SQL queries has attracted
growing attention, in particular in connection with transformers and similar
language models. A large number of techniques are geared towards the English
language; in this work, we thus investigated translation to SQL when input
questions are given in the Portuguese language. To do so, we properly adapted
state-of-the-art tools and resources. We changed the RAT-SQL+GAP system by
relying on a multilingual BART model (we report tests with other language
models), and we produced a translated version of the Spider dataset. Our
experiments expose interesting phenomena that arise when non-English languages
are targeted; in particular, it is better to train with original and translated
training datasets together, even if a single target language is desired. This
multilingual BART model fine-tuned with a double-size training dataset (English
and Portuguese) achieved 83% of the baseline, making inferences for the
Portuguese test dataset. This investigation can help other researchers to
produce results in Machine Learning in a language different from English. Our
multilingual ready version of RAT-SQL+GAP and the data are available,
open-sourced as mRAT-SQL+GAP at: https://github.com/C4AI/gap-text2sql
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Magic dust for cross-lingual adaptation of monolingual wav2vec-2.0. (arXiv:2110.03560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03560">
<div class="article-summary-box-inner">
<span><p>We propose a simple and effective cross-lingual transfer learning method to
adapt monolingual wav2vec-2.0 models for Automatic Speech Recognition (ASR) in
resource-scarce languages. We show that a monolingual wav2vec-2.0 is a good
few-shot ASR learner in several languages. We improve its performance further
via several iterations of Dropout Uncertainty-Driven Self-Training (DUST) by
using a moderate-sized unlabeled speech dataset in the target language. A key
finding of this work is that the adapted monolingual wav2vec-2.0 achieves
similar performance as the topline multilingual XLSR model, which is trained on
fifty-three languages, on the target language ASR task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GeSERA: General-domain Summary Evaluation by Relevance Analysis. (arXiv:2110.03567v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03567">
<div class="article-summary-box-inner">
<span><p>We present GeSERA, an open-source improved version of SERA for evaluating
automatic extractive and abstractive summaries from the general domain. SERA is
based on a search engine that compares candidate and reference summaries
(called queries) against an information retrieval document base (called index).
SERA was originally designed for the biomedical domain only, where it showed a
better correlation with manual methods than the widely used lexical-based ROUGE
method. In this paper, we take out SERA from the biomedical domain to the
general one by adapting its content-based method to successfully evaluate
summaries from the general domain. First, we improve the query reformulation
strategy with POS Tags analysis of general-domain corpora. Second, we replace
the biomedical index used in SERA with two article collections from AQUAINT-2
and Wikipedia. We conduct experiments with TAC2008, TAC2009, and CNNDM
datasets. Results show that, in most cases, GeSERA achieves higher correlations
with manual evaluation methods than SERA, while it reduces its gap with ROUGE
for general-domain summary evaluation. GeSERA even surpasses ROUGE in two cases
of TAC2009. Finally, we conduct extensive experiments and provide a
comprehensive study of the impact of human annotators and the index size on
summary evaluation with SERA and GeSERA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridge to Target Domain by Prototypical Contrastive Learning and Label Confusion: Re-explore Zero-Shot Learning for Slot Filling. (arXiv:2110.03572v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03572">
<div class="article-summary-box-inner">
<span><p>Zero-shot cross-domain slot filling alleviates the data dependence in the
case of data scarcity in the target domain, which has aroused extensive
research. However, as most of the existing methods do not achieve effective
knowledge transfer to the target domain, they just fit the distribution of the
seen slot and show poor performance on unseen slot in the target domain. To
solve this, we propose a novel approach based on prototypical contrastive
learning with a dynamic label confusion strategy for zero-shot slot filling.
The prototypical contrastive learning aims to reconstruct the semantic
constraints of labels, and we introduce the label confusion strategy to
establish the label dependence between the source domains and the target domain
on-the-fly. Experimental results show that our model achieves significant
improvement on the unseen slots, while also set new state-of-the-arts on slot
filling task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Applying Phonological Features in Multilingual Text-To-Speech. (arXiv:2110.03609v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03609">
<div class="article-summary-box-inner">
<span><p>This study investigates whether phonological features can be applied in
text-to-speech systems to generate native and non-native speech. We present a
mapping between ARPABET/pinyin-&gt;SAMPA/SAMPA-SC-&gt;phonological features in this
paper, and tested whether native, non-native, and code-switched speech could be
successfully generated using this mapping. We ran two experiments, one with a
small dataset and one with a larger dataset. The results proved that
phonological features can be a feasible input system, although it needs further
investigation to improve model performance. The accented output generated by
the TTS models also helps with understanding human second language acquisition
processes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Retriever-Ranker for dense text retrieval. (arXiv:2110.03611v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03611">
<div class="article-summary-box-inner">
<span><p>Current dense text retrieval models face two typical challenges. First, it
adopts a siamese dual-encoder architecture to encode query and document
independently for fast indexing and searching, whereas neglecting the
finer-grained term-wise interactions. This results in a sub-optimal recall
performance. Second, it highly relies on a negative sampling technique to build
up the negative documents in its contrastive loss. To address these challenges,
we present Adversarial Retriever-Ranker (AR2), which consists of a dual-encoder
retriever plus a cross-encoder ranker. The two models are jointly optimized
according to a minimax adversarial objective: the retriever learns to retrieve
negative documents to cheat the ranker, while the ranker learns to rank a
collection of candidates including both the ground-truth and the retrieved
ones, as well as providing progressive direct feedback to the dual-encoder
retriever. Through this adversarial game, the retriever gradually produces
harder negative documents to train a better ranker, whereas the cross-encoder
ranker provides progressive feedback to improve retriever. We evaluate AR2 on
three benchmarks. Experimental results show that AR2 consistently and
significantly outperforms existing dense retriever methods and achieves new
state-of-the-art results on all of them. This includes the improvements on
Natural Questions R@5 to 77.9%(+2.1%), TriviaQA R@5 to 78.2%(+1.4), and
MS-MARCO MRR@10 to 39.5%(+1.3%). We will make our code, models, and data
publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Direction of Data Collection Matters: Implications of Causal and Anticausal Learning in NLP. (arXiv:2110.03618v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03618">
<div class="article-summary-box-inner">
<span><p>The principle of independent causal mechanisms (ICM) states that generative
processes of real world data consist of independent modules which do not
influence or inform each other. While this idea has led to fruitful
developments in the field of causal inference, it is not widely-known in the
NLP community. In this work, we argue that the causal direction of the data
collection process bears nontrivial implications that can explain a number of
published NLP findings, such as differences in semi-supervised learning (SSL)
and domain adaptation (DA) performance across different settings. We categorize
common NLP tasks according to their causal direction and empirically assay the
validity of the ICM principle for text data using minimum description length.
We conduct an extensive meta-analysis of over 100 published SSL and 30 DA
studies, and find that the results are consistent with our expectations based
on causal insights. This work presents the first attempt to analyze the ICM
principle in NLP, and provides constructive suggestions for future modeling
choices. Code available at https://github.com/zhijing-jin/icm4nlp.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantifying the Suicidal Tendency on Social Media: A Survey. (arXiv:2110.03663v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03663">
<div class="article-summary-box-inner">
<span><p>Amid lockdown period more people express their feelings over social media
platforms due to closed third-place and academic researchers have witnessed
strong associations between the mental healthcare and social media posts. The
stress for a brief period may lead to clinical depressions and the long-lasting
traits of prevailing depressions can be life threatening with suicidal ideation
as the possible outcome. The increasing concern towards the rise in number of
suicide cases is because it is one of the leading cause of premature but
preventable death. Recent studies have shown that mining social media data has
helped in quantifying the suicidal tendency of users at risk. This potential
manuscript elucidates the taxonomy of mental healthcare and highlights some
recent attempts in examining the potential of quantifying suicidal tendency on
social media data. This manuscript presents the classification of heterogeneous
features from social media data and handling feature vector representation.
Aiming to identify the new research directions and advances in the development
of Machine Learning (ML) and Deep Learning (DL) based models, a quantitative
synthesis and a qualitative review was carried out with corpus of over 77
potential research articles related to stress, depression and suicide risk from
2013 to 2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TBCOV: Two Billion Multilingual COVID-19 Tweets with Sentiment, Entity, Geo, and Gender Labels. (arXiv:2110.03664v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03664">
<div class="article-summary-box-inner">
<span><p>The widespread usage of social networks during mass convergence events, such
as health emergencies and disease outbreaks, provides instant access to
citizen-generated data that carry rich information about public opinions,
sentiments, urgent needs, and situational reports. Such information can help
authorities understand the emergent situation and react accordingly. Moreover,
social media plays a vital role in tackling misinformation and disinformation.
This work presents TBCOV, a large-scale Twitter dataset comprising more than
two billion multilingual tweets related to the COVID-19 pandemic collected
worldwide over a continuous period of more than one year. More importantly,
several state-of-the-art deep learning models are used to enrich the data with
important attributes, including sentiment labels, named-entities (e.g.,
mentions of persons, organizations, locations), user types, and gender
information. Last but not least, a geotagging method is proposed to assign
country, state, county, and city information to tweets, enabling a myriad of
data analysis tasks to understand real-world issues. Our sentiment and trend
analyses reveal interesting insights and confirm TBCOV's broad coverage of
important topics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeBERTa: Decoding-enhanced BERT with Disentangled Attention. (arXiv:2006.03654v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03654">
<div class="article-summary-box-inner">
<span><p>Recent progress in pre-trained neural language models has significantly
improved the performance of many natural language processing (NLP) tasks. In
this paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT
with disentangled attention) that improves the BERT and RoBERTa models using
two novel techniques. The first is the disentangled attention mechanism, where
each word is represented using two vectors that encode its content and
position, respectively, and the attention weights among words are computed
using disentangled matrices on their contents and relative positions,
respectively. Second, an enhanced mask decoder is used to incorporate absolute
positions in the decoding layer to predict the masked tokens in model
pre-training. In addition, a new virtual adversarial training method is used
for fine-tuning to improve models' generalization. We show that these
techniques significantly improve the efficiency of model pre-training and the
performance of both natural language understanding (NLU) and natural langauge
generation (NLG) downstream tasks. Compared to RoBERTa-Large, a DeBERTa model
trained on half of the training data performs consistently better on a wide
range of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%),
on SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%).
Notably, we scale up DeBERTa by training a larger version that consists of 48
Transform layers with 1.5 billion parameters. The significant performance boost
makes the single DeBERTa model surpass the human performance on the SuperGLUE
benchmark (Wang et al., 2019a) for the first time in terms of macro-average
score (89.9 versus 89.8), and the ensemble DeBERTa model sits atop the
SuperGLUE leaderboard as of January 6, 2021, out performing the human baseline
by a decent margin (90.3 versus 89.8).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Arabic aspect based sentiment analysis using bidirectional GRU based models. (arXiv:2101.10539v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10539">
<div class="article-summary-box-inner">
<span><p>Aspect-based Sentiment analysis (ABSA) accomplishes a fine-grained analysis
that defines the aspects of a given document or sentence and the sentiments
conveyed regarding each aspect. This level of analysis is the most detailed
version that is capable of exploring the nuanced viewpoints of the reviews. The
bulk of study in ABSA focuses on English with very little work available in
Arabic. Most previous work in Arabic has been based on regular methods of
machine learning that mainly depends on a group of rare resources and tools for
analyzing and processing Arabic content such as lexicons, but the lack of those
resources presents another challenge. In order to address these challenges,
Deep Learning (DL)-based methods are proposed using two models based on Gated
Recurrent Units (GRU) neural networks for ABSA. The first is a DL model that
takes advantage of word and character representations by combining
bidirectional GRU, Convolutional Neural Network (CNN), and Conditional Random
Field (CRF) making up the (BGRU-CNN-CRF) model to extract the main opinionated
aspects (OTE). The second is an interactive attention network based on
bidirectional GRU (IAN-BGRU) to identify sentiment polarity toward extracted
aspects. We evaluated our models using the benchmarked Arabic hotel reviews
dataset. The results indicate that the proposed methods are better than
baseline research on both tasks having 39.7% enhancement in F1-score for
opinion target extraction (T2) and 7.58% in accuracy for aspect-based sentiment
polarity classification (T3). Achieving F1 score of 70.67% for T2, and accuracy
of 83.98% for T3.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XTREME-R: Towards More Challenging and Nuanced Multilingual Evaluation. (arXiv:2104.07412v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07412">
<div class="article-summary-box-inner">
<span><p>Machine learning has brought striking advances in multilingual natural
language processing capabilities over the past year. For example, the latest
techniques have improved the state-of-the-art performance on the XTREME
multilingual benchmark by more than 13 points. While a sizeable gap to
human-level performance remains, improvements have been easier to achieve in
some tasks than in others. This paper analyzes the current state of
cross-lingual transfer learning and summarizes some lessons learned. In order
to catalyze meaningful progress, we extend XTREME to XTREME-R, which consists
of an improved set of ten natural language understanding tasks, including
challenging language-agnostic retrieval tasks, and covers 50 typologically
diverse languages. In addition, we provide a massively multilingual diagnostic
suite (MultiCheckList) and fine-grained multi-dataset evaluation capabilities
through an interactive public leaderboard to gain a better understanding of
such models. The leaderboard and code for XTREME-R will be made available at
https://sites.research.google/xtreme and
https://github.com/google-research/xtreme respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context-Adaptive Document-Level Neural Machine Translation. (arXiv:2104.08259v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08259">
<div class="article-summary-box-inner">
<span><p>Most existing document-level neural machine translation (NMT) models leverage
a fixed number of the previous or all global source sentences to handle the
context-independent problem in standard NMT. However, the translating of each
source sentence benefits from various sizes of context, and inappropriate
context may harm the translation performance. In this work, we introduce a
data-adaptive method that enables the model to adopt the necessary and useful
context. Specifically, we introduce a light predictor into two document-level
translation models to select the explicit context. Experiments demonstrate the
proposed approach can significantly improve the performance over the previous
methods with a gain up to 1.99 BLEU points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enriching a Model's Notion of Belief using a Persistent Memory. (arXiv:2104.08401v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08401">
<div class="article-summary-box-inner">
<span><p>Although pretrained language models (PTLMs) have been shown to contain
significant amounts of world knowledge, they can still produce inconsistent
answers to questions when probed, even after using specialized training
techniques to reduce inconsistency. As a result, it can be hard to identify
what the model actually "believes" about the world. Our goal is to reduce this
problem, so systems are more globally consistent and accurate in their answers.
Our approach is to add a memory component -- a BeliefBank -- that records a
model's answers, and two mechanisms that use it to improve consistency among
beliefs. First, a reasoning component -- a weighted SAT solver -- improves
consistency by flipping answers that significantly clash with others. Second, a
feedback component re-queries the model but using known beliefs as context. We
show that, in a controlled experimental setting, these two mechanisms improve
both accuracy and consistency. This is significant as it is a first step
towards endowing models with an evolving memory, allowing them to construct a
more coherent picture of the world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Speech Recognition. (arXiv:2105.11084v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11084">
<div class="article-summary-box-inner">
<span><p>Despite rapid progress in the recent past, current speech recognition systems
still require labeled training data which limits this technology to a small
fraction of the languages spoken around the globe. This paper describes
wav2vec-U, short for wav2vec Unsupervised, a method to train speech recognition
models without any labeled data. We leverage self-supervised speech
representations to segment unlabeled audio and learn a mapping from these
representations to phonemes via adversarial training. The right representations
are key to the success of our method. Compared to the best previous
unsupervised work, wav2vec-U reduces the phoneme error rate on the TIMIT
benchmark from 26.1 to 11.3. On the larger English Librispeech benchmark,
wav2vec-U achieves a word error rate of 5.9 on test-other, rivaling some of the
best published systems trained on 960 hours of labeled data from only two years
ago. We also experiment on nine other languages, including low-resource
languages such as Kyrgyz, Swahili and Tatar.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Language Model for Efficient Linguistic Steganalysis. (arXiv:2107.12168v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12168">
<div class="article-summary-box-inner">
<span><p>Recent advances in linguistic steganalysis have successively applied CNN,
RNN, GNN and other efficient deep models for detecting secret information in
generative texts. These methods tend to seek stronger feature extractors to
achieve higher steganalysis effects. However, we have found through experiments
that there actually exists significant difference between automatically
generated stego texts and carrier texts in terms of the conditional probability
distribution of individual words. Such kind of difference can be naturally
captured by the language model used for generating stego texts. Through further
experiments, we conclude that this ability can be transplanted to a text
classifier by pre-training and fine-tuning to improve the detection
performance. Motivated by this insight, we propose two methods for efficient
linguistic steganalysis. One is to pre-train a language model based on RNN, and
the other is to pre-train a sequence autoencoder. The results indicate that the
two methods have different degrees of performance gain compared to the randomly
initialized RNN, and the convergence speed is significantly accelerated.
Moreover, our methods have achieved the state-of-the-art detection results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Similar Language Translation With Transfer Learning. (arXiv:2108.03533v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03533">
<div class="article-summary-box-inner">
<span><p>We investigate transfer learning based on pre-trained neural machine
translation models to translate between (low-resource) similar languages. This
work is part of our contribution to the WMT 2021 Similar Languages Translation
Shared Task where we submitted models for different language pairs, including
French-Bambara, Spanish-Catalan, and Spanish-Portuguese in both directions. Our
models for Catalan-Spanish ($82.79$ BLEU) and Portuguese-Spanish ($87.11$ BLEU)
rank top 1 in the official shared task evaluation, and we are the only team to
submit models for the French-Bambara pairs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Exploration in Quality Filtering of Text Data. (arXiv:2109.00698v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00698">
<div class="article-summary-box-inner">
<span><p>While conventional wisdom suggests that more aggressively filtering data from
low-quality sources like Common Crawl always monotonically improves the quality
of training data, we find that aggressive filtering can in fact lead to a
decrease in model quality on a wide array of downstream tasks for a GPT-like
language model. We speculate that this is because optimizing sufficiently
strongly for a proxy metric harms performance on the true objective, suggesting
a need for more robust filtering objectives when attempting to filter more
aggressively. We hope this work leads to detailed analysis of the effects of
dataset filtering design choices on downstream model performance in future
work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factorized Neural Transducer for Efficient Language Model Adaptation. (arXiv:2110.01500v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01500">
<div class="article-summary-box-inner">
<span><p>In recent years, end-to-end (E2E) based automatic speech recognition (ASR)
systems have achieved great success due to their simplicity and promising
performance. Neural Transducer based models are increasingly popular in
streaming E2E based ASR systems and have been reported to outperform the
traditional hybrid system in some scenarios. However, the joint optimization of
acoustic model, lexicon and language model in neural Transducer also brings
about challenges to utilize pure text for language model adaptation. This
drawback might prevent their potential applications in practice. In order to
address this issue, in this paper, we propose a novel model, factorized neural
Transducer, by factorizing the blank and vocabulary prediction, and adopting a
standalone language model for the vocabulary prediction. It is expected that
this factorization can transfer the improvement of the standalone language
model to the Transducer for speech recognition, which allows various language
model adaptation techniques to be applied. We demonstrate that the proposed
factorized neural Transducer yields 15% to 20% WER improvements when
out-of-domain text data is used for language model adaptation, at the cost of a
minor degradation in WER on a general test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rerunning OCR: A Machine Learning Approach to Quality Assessment and Enhancement Prediction. (arXiv:2110.01661v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01661">
<div class="article-summary-box-inner">
<span><p>Iterating with new and improved OCR solutions enforces decisions to be taken
when it comes to targeting the right reprocessing candidates. This especially
applies when the underlying data collection is of considerable size and rather
diverse in terms of fonts, languages, periods of publication and consequently
OCR quality. This article captures the efforts of the National Library of
Luxembourg to support those exact decisions. They are crucial in order to
guarantee low computational overhead and reduced quality degradation risks,
combined with a more quantifiable OCR improvement. In particular, this work
explains the methodology of the library with respect to text block level
quality assessment. As an extension of this technique, another contribution
comes in the form of a regression model that takes the enhancement potential of
a new OCR engine into account. They both mark promising approaches, especially
for cultural institutions dealing with historic data of lower quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactively Generating Explanations for Transformer Language Models. (arXiv:2110.02058v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02058">
<div class="article-summary-box-inner">
<span><p>Transformer language models are state-of-the-art in a multitude of NLP tasks.
Despite these successes, their opaqueness remains problematic. Recent methods
aiming to provide interpretability and explainability to black-box models
primarily focus on post-hoc explanations of (sometimes spurious) input-output
correlations. Instead, we emphasize using prototype networks directly
incorporated into the model architecture and hence explain the reasoning
process behind the network's decisions. Moreover, while our architecture
performs on par with several language models, it enables one to learn from user
interactions. This not only offers a better understanding of language models
but uses human capabilities to incorporate knowledge outside of the rigid range
of purely data-driven approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OPAD: An Optimized Policy-based Active Learning Framework for Document Content Analysis. (arXiv:2110.02069v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02069">
<div class="article-summary-box-inner">
<span><p>Documents are central to many business systems, and include forms, reports,
contracts, invoices or purchase orders. The information in documents is
typically in natural language, but can be organized in various layouts and
formats. There have been recent spurt of interest in understanding document
content with novel deep learning architectures. However, document understanding
tasks need dense information annotations, which are costly to scale and
generalize. Several active learning techniques have been proposed to reduce the
overall budget of annotation while maintaining the performance of the
underlying deep learning model. However, most of these techniques work only for
classification problems. But content detection is a more complex task, and has
been scarcely explored in active learning literature. In this paper, we propose
\textit{OPAD}, a novel framework using reinforcement policy for active learning
in content detection tasks for documents. The proposed framework learns the
acquisition function to decide the samples to be selected while optimizing
performance metrics that the tasks typically have. Furthermore, we extend to
weak labelling scenarios to further reduce the cost of annotation
significantly. We propose novel rewards to account for class imbalance and user
feedback in the annotation interface, to improve the active learning method. We
show superior performance of the proposed \textit{OPAD} framework for active
learning for various tasks related to document understanding like layout
parsing, object detection and named entity recognition. Ablation studies for
human feedback and class imbalance rewards are presented, along with a
comparison of annotation times for different approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Contextual Adaptation with Neural Associative Memory for On-Device Personalized Speech Recognition. (arXiv:2110.02220v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02220">
<div class="article-summary-box-inner">
<span><p>Fast contextual adaptation has shown to be effective in improving Automatic
Speech Recognition (ASR) of rare words and when combined with an on-device
personalized training, it can yield an even better recognition result. However,
the traditional re-scoring approaches based on an external language model is
prone to diverge during the personalized training. In this work, we introduce a
model-based end-to-end contextual adaptation approach that is decoder-agnostic
and amenable to on-device personalization. Our on-device simulation experiments
demonstrate that the proposed approach outperforms the traditional re-scoring
technique by 12% relative WER and 15.7% entity mention specific F1-score in a
continues personalization scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PoNet: Pooling Network for Efficient Token Mixing in Long Sequences. (arXiv:2110.02442v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02442">
<div class="article-summary-box-inner">
<span><p>Transformer-based models have achieved great success in various NLP, vision,
and speech tasks. However, the core of Transformer, the self-attention
mechanism, has a quadratic time and memory complexity with respect to the
sequence length, which hinders applications of Transformer-based models to long
sequences. Many approaches have been proposed to mitigate this problem, such as
sparse attention mechanisms, low-rank matrix approximations and scalable
kernels, and token mixing alternatives to self-attention. We propose a novel
Pooling Network (PoNet) for token mixing in long sequences with linear
complexity. We design multi-granularity pooling and pooling fusion to capture
different levels of contextual information and combine their interactions with
tokens. On the Long Range Arena benchmark, PoNet significantly outperforms
Transformer and achieves competitive accuracy, while being only slightly slower
than the fastest model, FNet, across all sequence lengths measured on GPUs. We
also conduct systematic studies on the transfer learning capability of PoNet
and observe that PoNet achieves 96.0% of the accuracy of BERT on the GLUE
benchmark, outperforming FNet by 4.5% relative. Comprehensive ablation analysis
demonstrates effectiveness of the designed multi-granularity pooling and
pooling fusion for token mixing in long sequences and efficacy of the designed
pre-training tasks for PoNet to learn transferable contextualized language
representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PSG@HASOC-Dravidian CodeMixFIRE2021: Pretrained Transformers for Offensive Language Identification in Tanglish. (arXiv:2110.02852v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02852">
<div class="article-summary-box-inner">
<span><p>This paper describes the system submitted to Dravidian-Codemix-HASOC2021:
Hate Speech and Offensive Language Identification in Dravidian Languages
(Tamil-English and Malayalam-English). This task aims to identify offensive
content in code-mixed comments/posts in Dravidian Languages collected from
social media. Our approach utilizes pooling the last layers of pretrained
transformer multilingual BERT for this task which helped us achieve rank nine
on the leaderboard with a weighted average score of 0.61 for the Tamil-English
dataset in subtask B. After the task deadline, we sampled the dataset uniformly
and used the MuRIL pretrained model, which helped us achieve a weighted average
score of 0.67, the top score in the leaderboard. Furthermore, our approach to
utilizing the pretrained models helps reuse our models for the same task with a
different dataset. Our code and models are available in
https://github.com/seanbenhur/tanglish-offensive-language-identification
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence-to-Sequence Lexical Normalization with Multilingual Transformers. (arXiv:2110.02869v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02869">
<div class="article-summary-box-inner">
<span><p>Current benchmark tasks for natural language processing contain text that is
qualitatively different from the text used in informal day to day digital
communication. This discrepancy has led to severe performance degradation of
state-of-the-art NLP models when fine-tuned on real-world data. One way to
resolve this issue is through lexical normalization, which is the process of
transforming non-standard text, usually from social media, into a more
standardized form. In this work, we propose a sentence-level
sequence-to-sequence model based on mBART, which frames the problem as a
machine translation problem. As the noisy text is a pervasive problem across
languages, not just English, we leverage the multi-lingual pre-training of
mBART to fine-tune it to our data. While current approaches mainly operate at
the word or subword level, we argue that this approach is straightforward from
a technical standpoint and builds upon existing pre-trained transformer
networks. Our results show that while word-level, intrinsic, performance
evaluation is behind other methods, our model improves performance on
extrinsic, downstream tasks through normalization compared to models operating
on raw, unprocessed, social media text.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Canonical Embedding for Non-rigid Shape Matching. (arXiv:2110.02994v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02994">
<div class="article-summary-box-inner">
<span><p>This paper provides a novel framework that learns canonical embeddings for
non-rigid shape matching. In contrast to prior work in this direction, our
framework is trained end-to-end and thus avoids instabilities and constraints
associated with the commonly-used Laplace-Beltrami basis or sequential
optimization schemes. On multiple datasets, we demonstrate that learning self
symmetry maps with a deep functional map projects 3D shapes into a low
dimensional canonical embedding that facilitates non-rigid shape correspondence
via a simple nearest neighbor search. Our framework outperforms multiple recent
learning based methods on FAUST and SHREC benchmarks while being
computationally cheaper, data-efficient, and robust.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Scale Convolutional Neural Network for Automated AMD Classification using Retinal OCT Images. (arXiv:2110.03002v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03002">
<div class="article-summary-box-inner">
<span><p>Age-related macular degeneration (AMD) is the most common cause of blindness
in developed countries, especially in people over 60 years of age. The workload
of specialists and the healthcare system in this field has increased in recent
years mainly dues to three reasons: 1) increased use of retinal optical
coherence tomography (OCT) imaging technique, 2) prevalence of population aging
worldwide, and 3) chronic nature of AMD. Recent developments in deep learning
have provided a unique opportunity for the development of fully automated
diagnosis frameworks. Considering the presence of AMD-related retinal
pathologies in varying sizes in OCT images, our objective was to propose a
multi-scale convolutional neural network (CNN) capable of distinguishing
pathologies using receptive fields with various sizes. The multi-scale CNN was
designed based on the feature pyramid network (FPN) structure and was used to
diagnose normal and two common clinical characteristics of dry and wet AMD,
namely drusen and choroidal neovascularization (CNV). The proposed method was
evaluated on a national dataset gathered at Noor Eye Hospital (NEH), consisting
of 12649 retinal OCT images from 441 patients, and a UCSD public dataset,
consisting of 108312 OCT images. The results show that the multi-scale
FPN-based structure was able to improve the base model's overall accuracy by
0.4% to 3.3% for different backbone models. In addition, gradual learning
improved the performance in two phases from 87.2%+-2.5% to 93.4%+-1.4% by
pre-training the base model on ImageNet weights in the first phase and
fine-tuning the resulting model on a dataset of OCT images in the second phase.
The promising quantitative and qualitative results of the proposed architecture
prove the suitability of the proposed method to be used as a screening tool in
healthcare centers assisting ophthalmologists in making better diagnostic
decisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Centric Semi-Supervised Learning. (arXiv:2110.03006v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03006">
<div class="article-summary-box-inner">
<span><p>We study unsupervised data selection for semi-supervised learning (SSL),
where a large-scale unlabeled data is available and a small subset of data is
budgeted for label acquisition. Existing SSL methods focus on learning a model
that effectively integrates information from given small labeled data and large
unlabeled data, whereas we focus on selecting the right data for SSL without
any label or task information, in an also stark contrast to supervised data
selection for active learning. Intuitively, instances to be labeled shall
collectively have maximum diversity and coverage for downstream tasks, and
individually have maximum information propagation utility for SSL. We formalize
these concepts in a three-step data-centric SSL method that improves FixMatch
in stability and accuracy by 8% on CIFAR-10 (0.08% labeled) and 14% on
ImageNet-1K (0.2% labeled). Our work demonstrates that a small compute spent on
careful labeled data selection brings big annotation efficiency and model
performance gain without changing the learning pipeline. Our completely
unsupervised data selection can be easily extended to other weakly supervised
learning settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepBBS: Deep Best Buddies for Point Cloud Registration. (arXiv:2110.03016v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03016">
<div class="article-summary-box-inner">
<span><p>Recently, several deep learning approaches have been proposed for point cloud
registration. These methods train a network to generate a representation that
helps finding matching points in two 3D point clouds. Finding good matches
allows them to calculate the transformation between the point clouds
accurately. Two challenges of these techniques are dealing with occlusions and
generalizing to objects of classes unseen during training. This work proposes
DeepBBS, a novel method for learning a representation that takes into account
the best buddy distance between points during training. Best Buddies (i.e.,
mutual nearest neighbors) are pairs of points nearest to each other. The Best
Buddies criterion is a strong indication for correct matches that, in turn,
leads to accurate registration. Our experiments show improved performance
compared to previous methods. In particular, our learned representation leads
to an accurate registration for partial shapes and in unseen categories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamically Decoding Source Domain Knowledge For Unseen Domain Generalization. (arXiv:2110.03027v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03027">
<div class="article-summary-box-inner">
<span><p>Domain generalization is an important problem which has gain much attention
recently. While most existing studies focus on learning domain-invariant
feature representations, some researchers try ensemble learning of multi
experts and demonstrate promising performance. However, in existing
multi-expert learning frameworks, the source domain knowledge has not yet been
much explored, resulting in sub-optimal performance. In this paper, we propose
to adapt Transformers for the purpose of dynamically decoding source domain
knowledge for domain generalization. Specifically, we build one domain-specific
local expert per source domain, and one domain-agnostic feature branch as
query. Then, all local-domain features will be encoded by Transformer encoders,
as source domain knowledge in memory. While in the Transformer decoders, the
domain-agnostic query will interact with the memory in the cross-attention
module, where similar domains with the input will contribute more in the
attention output. This way, the source domain knowledge will be dynamically
decoded for the inference of the current input from unseen domain. Therefore,
this mechanism makes the proposed method well generalizable to unseen domains.
The proposed method is evaluated on three benchmarks in the domain
generalization field. The comparison with the state-of-the-art methods shows
that the proposed method achieves the best performance, outperforming the
others with a clear gap.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FOD-A: A Dataset for Foreign Object Debris in Airports. (arXiv:2110.03072v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03072">
<div class="article-summary-box-inner">
<span><p>Foreign Object Debris (FOD) detection has attracted increased attention in
the area of machine learning and computer vision. However, a robust and
publicly available image dataset for FOD has not been initialized. To this end,
this paper introduces an image dataset of FOD, named FOD in Airports (FOD-A).
FOD-A object categories have been selected based on guidance from prior
documentation and related research by the Federal Aviation Administration
(FAA). In addition to the primary annotations of bounding boxes for object
detection, FOD-A provides labeled environmental conditions. As such, each
annotation instance is further categorized into three light level categories
(bright, dim, and dark) and two weather categories (dry and wet). Currently,
FOD-A has released 31 object categories and over 30,000 annotation instances.
This paper presents the creation methodology, discusses the publicly available
dataset extension process, and demonstrates the practicality of FOD-A with
widely used machine learning models for object detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large-Scale Topological Radar Localization Using Learned Descriptors. (arXiv:2110.03081v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03081">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a method for large-scale topological localization
based on radar scan images using learned descriptors. We present a simple yet
efficient deep network architecture to compute a rotationally invariant
discriminative global descriptor from a radar scan image. The performance and
generalization ability of the proposed method is experimentally evaluated on
two large scale driving datasets: MulRan and Oxford Radar RobotCar.
Additionally, we present a comparative evaluation of radar-based and
LiDAR-based localization using learned global descriptors. Our code and trained
models are publicly available on the project website.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision-based Excavator Activity Analysis and Safety Monitoring System. (arXiv:2110.03083v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03083">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose an excavator activity analysis and safety
monitoring system, leveraging recent advancements in deep learning and computer
vision. Our proposed system detects the surrounding environment and the
excavators while estimating the poses and actions of the excavators. Compared
to previous systems, our method achieves higher accuracy in object detection,
pose estimation, and action recognition tasks. In addition, we build an
excavator dataset using the Autonomous Excavator System (AES) on the waste
disposal recycle scene to demonstrate the effectiveness of our system. We also
evaluate our method on a benchmark construction dataset. The experimental
results show that the proposed action recognition approach outperforms the
state-of-the-art approaches on top-1 accuracy by about 5.18%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Player Tracking and Identification in Ice Hockey. (arXiv:2110.03090v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03090">
<div class="article-summary-box-inner">
<span><p>Tracking and identifying players is a fundamental step in computer
vision-based ice hockey analytics. The data generated by tracking is used in
many other downstream tasks, such as game event detection and game strategy
analysis. Player tracking and identification is a challenging problem since the
motion of players in hockey is fast-paced and non-linear when compared to
pedestrians. There is also significant camera panning and zooming in hockey
broadcast video. Identifying players in ice hockey is challenging since the
players of the same team look almost identical, with the jersey number the only
discriminating factor between players. In this paper, an automated system to
track and identify players in broadcast NHL hockey videos is introduced. The
system is composed of three components (1) Player tracking, (2) Team
identification and (3) Player identification. Due to the absence of publicly
available datasets, the datasets used to train the three components are
annotated manually. Player tracking is performed with the help of a state of
the art tracking algorithm obtaining a Multi-Object Tracking Accuracy (MOTA)
score of 94.5%. For team identification, the away-team jerseys are grouped into
a single class and home-team jerseys are grouped in classes according to their
jersey color. A convolutional neural network is then trained on the team
identification dataset. The team identification network gets an accuracy of 97%
on the test set. A novel player identification model is introduced that
utilizes a temporal one-dimensional convolutional network to identify players
from player bounding box sequences. The player identification model further
takes advantage of the available NHL game roster data to obtain a player
identification accuracy of 83%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Fractal Pre-training. (arXiv:2110.03091v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03091">
<div class="article-summary-box-inner">
<span><p>The deep neural networks used in modern computer vision systems require
enormous image datasets to train them. These carefully-curated datasets
typically have a million or more images, across a thousand or more distinct
categories. The process of creating and curating such a dataset is a monumental
undertaking, demanding extensive effort and labelling expense and necessitating
careful navigation of technical and social issues such as label accuracy,
copyright ownership, and content bias.
</p>
<p>What if we had a way to harness the power of large image datasets but with
few or none of the major issues and concerns currently faced? This paper
extends the recent work of Kataoka et. al. (2020), proposing an improved
pre-training dataset based on dynamically-generated fractal images. Challenging
issues with large-scale image datasets become points of elegance for fractal
pre-training: perfect label accuracy at zero cost; no need to store/transmit
large image archives; no privacy/demographic bias/concerns of inappropriate
content, as no humans are pictured; limitless supply and diversity of images;
and the images are free/open-source. Perhaps surprisingly, avoiding these
difficulties imposes only a small penalty in performance. Leveraging a
newly-proposed pre-training task -- multi-instance prediction -- our
experiments demonstrate that fine-tuning a network pre-trained using fractals
attains 92.7-98.1\% of the accuracy of an ImageNet pre-trained network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Pneumonia Localization via Cross-Attention on Medical Images and Reports. (arXiv:2110.03094v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03094">
<div class="article-summary-box-inner">
<span><p>Localization and characterization of diseases like pneumonia are primary
steps in a clinical pipeline, facilitating detailed clinical diagnosis and
subsequent treatment planning. Additionally, such location annotated datasets
can provide a pathway for deep learning models to be used for downstream tasks.
However, acquiring quality annotations is expensive on human resources and
usually requires domain expertise. On the other hand, medical reports contain a
plethora of information both about pneumonia characteristics and its location.
In this paper, we propose a novel weakly-supervised attention-driven deep
learning model that leverages encoded information in medical reports during
training to facilitate better localization. Our model also performs
classification of attributes that are associated to pneumonia and extracted
from medical reports for supervision. Both the classification and localization
are trained in conjunction and once trained, the model can be utilized for both
the localization and characterization of pneumonia using only the input image.
In this paper, we explore and analyze the model using chest X-ray datasets and
demonstrate qualitatively and quantitatively that the introduction of textual
information improves pneumonia localization. We showcase quantitative results
on two datasets, MIMIC-CXR and Chest X-ray-8, and we also showcase severity
characterization on the COVID-19 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective. (arXiv:2110.03095v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03095">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) often rely on easy-to-learn discriminatory
features, or cues, that are not necessarily essential to the problem at hand.
For example, ducks in an image may be recognized based on their typical
background scenery, such as lakes or streams. This phenomenon, also known as
shortcut learning, is emerging as a key limitation of the current generation of
machine learning models. In this work, we introduce a set of experiments to
deepen our understanding of shortcut learning and its implications. We design a
training setup with several shortcut cues, named WCST-ML, where each cue is
equally conducive to the visual recognition problem at hand. Even under equal
opportunities, we observe that (1) certain cues are preferred to others, (2)
solutions biased to the easy-to-learn cues tend to converge to relatively flat
minima on the loss surface, and (3) the solutions focusing on those preferred
cues are far more abundant in the parameter space. We explain the abundance of
certain cues via their Kolmogorov (descriptional) complexity: solutions
corresponding to Kolmogorov-simple cues are abundant in the parameter space and
are thus preferred by DNNs. Our studies are based on the synthetic dataset
DSprites and the face dataset UTKFace. In our WCST-ML, we observe that the
inborn bias of models leans toward simple cues, such as color and ethnicity.
Our findings emphasize the importance of active human intervention to remove
the inborn model biases that may cause negative societal impacts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPEED+: Next Generation Dataset for Spacecraft Pose Estimation across Domain Gap. (arXiv:2110.03101v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03101">
<div class="article-summary-box-inner">
<span><p>Autonomous vision-based spaceborne navigation is an enabling technology for
future on-orbit servicing and space logistics missions. While computer vision
in general has benefited from Machine Learning (ML), training and validating
spaceborne ML models are extremely challenging due to the impracticality of
acquiring a large-scale labeled dataset of images of the intended target in the
space environment. Existing datasets, such as Spacecraft PosE Estimation
Dataset (SPEED), have so far mostly relied on synthetic images for both
training and validation, which are easy to mass-produce but fail to resemble
the visual features and illumination variability inherent to the target
spaceborne images. In order to bridge the gap between the current practices and
the intended applications in future space missions, this paper introduces
SPEED+: the next generation spacecraft pose estimation dataset with specific
emphasis on domain gap. In addition to 60,000 synthetic images for training,
SPEED+ includes 9,531 simulated images of a spacecraft mockup model captured
from the Testbed for Rendezvous and Optical Navigation (TRON) facility. TRON is
a first-of-a-kind robotic testbed capable of capturing an arbitrary number of
target images with accurate and maximally diverse pose labels and high-fidelity
spaceborne illumination conditions. SPEED+ will be used in the upcoming
international Satellite Pose Estimation Challenge co-hosted with the Advanced
Concepts Team of the European Space Agency to evaluate and compare the
robustness of spaceborne ML models trained on synthetic images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning a Metacognition for Object Detection. (arXiv:2110.03105v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03105">
<div class="article-summary-box-inner">
<span><p>In contrast to object recognition models, humans do not blindly trust their
perception when building representations of the world, instead recruiting
metacognition to detect percepts that are unreliable or false, such as when we
realize that we mistook one object for another. We propose METAGEN, an
unsupervised model that enhances object recognition models through a
metacognition. Given noisy output from an object-detection model, METAGEN
learns a meta-representation of how its perceptual system works and uses it to
infer the objects in the world responsible for the detections. METAGEN achieves
this by conditioning its inference on basic principles of objects that even
human infants understand (known as Spelke principles: object permanence,
cohesion, and spatiotemporal continuity). We test METAGEN on a variety of
state-of-the-art object detection neural networks. We find that METAGEN quickly
learns an accurate metacognitive representation of the neural network, and that
this improves detection accuracy by filling in objects that the detection model
missed and removing hallucinated objects. This approach enables generalization
to out-of-sample data and outperforms comparison models that lack a
metacognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generic tool for numerical simulation of transformation-diffusion processes in complex volume geometric shapes: application to microbial decomposition of organic matter. (arXiv:2110.03130v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03130">
<div class="article-summary-box-inner">
<span><p>This paper presents a generic framework for the numerical simulation of
transformation-diffusion processes in complex volume geometric shapes. This
work follows a previous one devoted to the simulation of microbial degradation
of organic matter in porous system at microscopic scale. We generalized and
improved the MOSAIC method significantly and thus yielding a much more generic
and efficient numerical simulation scheme. In particular, regarding the
simulation of diffusion processes from the graph, in this study we proposed a
completely explicit and semi-implicit numerical scheme that can significantly
reduce the computational complexity. We validated our method by comparing the
results to the one provided by classical Lattice Boltzmann Method (LBM) within
the context of microbial decomposition simulation. For the same datasets, we
obtained similar results in a significantly shorter computing time (i.e., 10-15
minutes) than the prior work (several hours). Besides the classical LBM method
takes around 3 weeks computing time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Sharpness-aware Minimization for Improved Training of Neural Networks. (arXiv:2110.03141v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03141">
<div class="article-summary-box-inner">
<span><p>Overparametrized Deep Neural Networks (DNNs) often achieve astounding
performances, but may potentially result in severe generalization error.
Recently, the relation between the sharpness of the loss landscape and the
generalization error has been established by Foret et al. (2020), in which the
Sharpness Aware Minimizer (SAM) was proposed to mitigate the degradation of the
generalization. Unfortunately, SAM s computational cost is roughly double that
of base optimizers, such as Stochastic Gradient Descent (SGD). This paper thus
proposes Efficient Sharpness Aware Minimizer (ESAM), which boosts SAM s
efficiency at no cost to its generalization performance. ESAM includes two
novel and efficient training strategies-StochasticWeight Perturbation and
Sharpness-Sensitive Data Selection. In the former, the sharpness measure is
approximated by perturbing a stochastically chosen set of weights in each
iteration; in the latter, the SAM loss is optimized using only a judiciously
selected subset of data that is sensitive to the sharpness. We provide
theoretical explanations as to why these strategies perform well. We also show,
via extensive experiments on the CIFAR and ImageNet datasets, that ESAM
enhances the efficiency over SAM from requiring 100% extra computations to 40%
vis-a-vis base optimizers, while test accuracies are preserved or even
improved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-UDA: Unsupervised Domain Adaptive Thermal Object Detection using Meta-Learning. (arXiv:2110.03143v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03143">
<div class="article-summary-box-inner">
<span><p>Object detectors trained on large-scale RGB datasets are being extensively
employed in real-world applications. However, these RGB-trained models suffer a
performance drop under adverse illumination and lighting conditions. Infrared
(IR) cameras are robust under such conditions and can be helpful in real-world
applications. Though thermal cameras are widely used for military applications
and increasingly for commercial applications, there is a lack of robust
algorithms to robustly exploit the thermal imagery due to the limited
availability of labeled thermal data. In this work, we aim to enhance the
object detection performance in the thermal domain by leveraging the labeled
visible domain data in an Unsupervised Domain Adaptation (UDA) setting. We
propose an algorithm agnostic meta-learning framework to improve existing UDA
methods instead of proposing a new UDA strategy. We achieve this by
meta-learning the initial condition of the detector, which facilitates the
adaptation process with fine updates without overfitting or getting stuck at
local optima. However, meta-learning the initial condition for the detection
scenario is computationally heavy due to long and intractable computation
graphs. Therefore, we propose an online meta-learning paradigm which performs
online updates resulting in a short and tractable computation graph. To this
end, we demonstrate the superiority of our method over many baselines in the
UDA setting, producing a state-of-the-art thermal detector for the KAIST and
DSIAC datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DoubleStar: Long-Range Attack Towards Depth Estimation based Obstacle Avoidance in Autonomous Systems. (arXiv:2110.03154v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03154">
<div class="article-summary-box-inner">
<span><p>Depth estimation-based obstacle avoidance has been widely adopted by
autonomous systems (drones and vehicles) for safety purpose. It normally relies
on a stereo camera to automatically detect obstacles and make flying/driving
decisions, e.g., stopping several meters ahead of the obstacle in the path or
moving away from the detected obstacle. In this paper, we explore new security
risks associated with the stereo vision-based depth estimation algorithms used
for obstacle avoidance. By exploiting the weaknesses of the stereo matching in
depth estimation algorithms and the lens flare effect in optical imaging, we
propose DoubleStar, a long-range attack that injects fake obstacle depth by
projecting pure light from two complementary light sources.
</p>
<p>DoubleStar includes two distinctive attack formats: beams attack and orbs
attack, which leverage projected light beams and lens flare orbs respectively
to cause false depth perception. We successfully attack two commercial stereo
cameras designed for autonomous systems (ZED and Intel RealSense). The
visualization of fake depth perceived by the stereo cameras illustrates the
false stereo matching induced by DoubleStar. We further use Ardupilot to
simulate the attack and demonstrate its impact on drones. To validate the
attack on real systems, we perform a real-world attack towards a commercial
drone equipped with state-of-the-art obstacle avoidance algorithms. Our attack
can continuously bring a flying drone to a sudden stop or drift it away across
a long distance under various lighting conditions, even bypassing sensor fusion
mechanisms. Specifically, our experimental results show that DoubleStar creates
fake depth up to 15 meters in distance at night and up to 8 meters during the
daytime. To mitigate this newly discovered threat, we provide discussions on
potential countermeasures to defend against DoubleStar.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TreeGCN-ED: Encoding Point Cloud using a Tree-Structured Graph Network. (arXiv:2110.03170v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03170">
<div class="article-summary-box-inner">
<span><p>Point cloud is an efficient way of representing and storing 3D geometric
data. Deep learning algorithms on point clouds are time and memory efficient.
Several methods such as PointNet and FoldingNet have been proposed for
processing point clouds. This work proposes an autoencoder based framework to
generate robust embeddings for point clouds by utilizing hierarchical
information using graph convolution. We perform multiple experiments to assess
the quality of embeddings generated by the proposed encoder architecture and
visualize the t-SNE map to highlight its ability to distinguish between
different object classes. We further demonstrate the applicability of the
proposed framework in applications like: 3D point cloud completion and Single
image based 3D reconstruction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tile Embedding: A General Representation for Procedural Level Generation via Machine Learning. (arXiv:2110.03181v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03181">
<div class="article-summary-box-inner">
<span><p>In recent years, Procedural Level Generation via Machine Learning (PLGML)
techniques have been applied to generate game levels with machine learning.
These approaches rely on human-annotated representations of game levels.
Creating annotated datasets for games requires domain knowledge and is
time-consuming. Hence, though a large number of video games exist, annotated
datasets are curated only for a small handful. Thus current PLGML techniques
have been explored in limited domains, with Super Mario Bros. as the most
common example. To address this problem, we present tile embeddings, a unified,
affordance-rich representation for tile-based 2D games. To learn this
embedding, we employ autoencoders trained on the visual and semantic
information of tiles from a set of existing, human-annotated games. We evaluate
this representation on its ability to predict affordances for unseen tiles, and
to serve as a PLGML representation for annotated and unannotated games.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint optimization of system design and reconstruction in MIMO radar imaging. (arXiv:2110.03218v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03218">
<div class="article-summary-box-inner">
<span><p>Multiple-input multiple-output (MIMO) radar is one of the leading depth
sensing modalities. However, the usage of multiple receive channels lead to
relative high costs and prevent the penetration of MIMOs in many areas such as
the automotive industry. Over the last years, few studies concentrated on
designing reduced measurement schemes and image reconstruction schemes for MIMO
radars, however these problems have been so far addressed separately. On the
other hand, recent works in optical computational imaging have demonstrated
growing success of simultaneous learning-based design of the acquisition and
reconstruction schemes, manifesting significant improvement in the
reconstruction quality. Inspired by these successes, in this work, we propose
to learn MIMO acquisition parameters in the form of receive (Rx) antenna
elements locations jointly with an image neural-network based reconstruction.
To this end, we propose an algorithm for training the combined
acquisition-reconstruction pipeline end-to-end in a differentiable way. We
demonstrate the significance of using our learned acquisition parameters with
and without the neural-network reconstruction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient Step Denoiser for convergent Plug-and-Play. (arXiv:2110.03220v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03220">
<div class="article-summary-box-inner">
<span><p>Plug-and-Play methods constitute a class of iterative algorithms for imaging
problems where regularization is performed by an off-the-shelf denoiser.
Although Plug-and-Play methods can lead to tremendous visual performance for
various image problems, the few existing convergence guarantees are based on
unrealistic (or suboptimal) hypotheses on the denoiser, or limited to strongly
convex data terms. In this work, we propose a new type of Plug-and-Play
methods, based on half-quadratic splitting, for which the denoiser is realized
as a gradient descent step on a functional parameterized by a deep neural
network. Exploiting convergence results for proximal gradient descent
algorithms in the non-convex setting, we show that the proposed Plug-and-Play
algorithm is a convergent iterative scheme that targets stationary points of an
explicit global functional. Besides, experiments show that it is possible to
learn such a deep denoiser while not compromising the performance in comparison
to other state-of-the-art deep denoisers used in Plug-and-Play schemes. We
apply our proximal gradient algorithm to various ill-posed inverse problems,
e.g. deblurring, super-resolution and inpainting. For all these applications,
numerical results empirically confirm the convergence results. Experiments also
show that this new algorithm reaches state-of-the-art performance, both
quantitatively and qualitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Design of an Intelligent Vision Algorithm for Recognition and Classification of Apples in an Orchard Scene. (arXiv:2110.03232v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03232">
<div class="article-summary-box-inner">
<span><p>Apple is one of the remarkable fresh fruit that contains a high degree of
nutritious and medicinal value. Hand harvesting of apples by seasonal
farmworkers increases physical damages on the surface of these fruits, which
causes a great loss in marketing quality. The main objective of this study is
focused on designing a robust vision algorithm for robotic apple harvesters.
The proposed algorithm is able to recognize and classify 4-classes of objects
found in an orchard scene including apples, leaves, trunk and branches, and sky
into two apples and non-apples classes. 100 digital images of Red Delicious
apples and 100 digital images of Golden Delicious apples were selected among
1000 captured images of apples from 18 apple gardens in West Azerbaijan, Iran.
An image processing algorithm is proposed for segmentation and extraction of
the image classes based on the color characteristics of mentioned classes.
Invariant-Momentums were chosen as the extracted features from the segmented
classes, e.g. apples. Multilayer Feedforward Neural Networks, MFNNs, were used
as an artificial intelligence tool for the recognition and classification of
image classes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Depth Completion for Active Stereo. (arXiv:2110.03234v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03234">
<div class="article-summary-box-inner">
<span><p>Active stereo systems are widely used in the robotics industry due to their
low cost and high quality depth maps. These depth sensors, however, suffer from
stereo artefacts and do not provide dense depth estimates. In this work, we
present the first self-supervised depth completion method for active stereo
systems that predicts accurate dense depth maps. Our system leverages a
feature-based visual inertial SLAM system to produce motion estimates and
accurate (but sparse) 3D landmarks. The 3D landmarks are used both as model
input and as supervision during training. The motion estimates are used in our
novel reconstruction loss that relies on a combination of passive and active
stereo frames, resulting in significant improvements in textureless areas that
are common in indoor environments. Due to the non-existence of publicly
available active stereo datasets, we release a real dataset together with
additional information for a publicly available synthetic dataset needed for
active depth completion and prediction. Through rigorous evaluations we show
that our method outperforms state of the art on both datasets. Additionally we
show how our method obtains more complete, and therefore safer, 3D maps when
used in a robotic platform
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Colored Point Cloud to Image Alignment. (arXiv:2110.03249v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03249">
<div class="article-summary-box-inner">
<span><p>Recognition and segmentation of objects in images enjoy the wealth of large
volume of well annotated data. At the other end, when dealing with the
reconstruction of geometric structures of objects from images, there is a
limited amount of accurate data available for supervised learning. One type of
such geometric data with insufficient amount required for deep learning is real
world accurate RGB-D images. The lack of accurate RGB-D datasets is one of the
obstacles in the evolution of geometric scene reconstructions from images. One
solution to creating such a dataset is to capture RGB images while
simultaneously using an accurate depth scanning device that assigns a depth
value to each pixel. A major challenge in acquiring such ground truth data is
the accurate alignment between the RGB images and the measured depth and color
profiles. We introduce a differential optimization method that aligns a colored
point cloud to a given color image via iterative geometric and color matching.
The proposed method enables the construction of RGB-D datasets for specific
camera systems. In the suggested framework, the optimization minimizes the
difference between the colors of the image pixels and the corresponding colors
of the projected points to the camera plane. We assume that the colors produced
by the geometric scanner camera and the color camera sensor are different and
thus are characterized by different chromatic acquisition properties. We align
the different color spaces while compensating for their corresponding color
appearance. Under this setup, we find the transformation between the camera
image and the point cloud colors by iterating between matching the relative
location of the point cloud and matching colors. The successful alignments
produced by the proposed method are demonstrated on both synthetic data with
quantitative evaluation and real world scenes with qualitative results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving MC-Dropout Uncertainty Estimates with Calibration Error-based Optimization. (arXiv:2110.03260v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03260">
<div class="article-summary-box-inner">
<span><p>Uncertainty quantification of machine learning and deep learning methods
plays an important role in enhancing trust to the obtained result. In recent
years, a numerous number of uncertainty quantification methods have been
introduced. Monte Carlo dropout (MC-Dropout) is one of the most well-known
techniques to quantify uncertainty in deep learning methods. In this study, we
propose two new loss functions by combining cross entropy with Expected
Calibration Error (ECE) and Predictive Entropy (PE). The obtained results
clearly show that the new proposed loss functions lead to having a calibrated
MC-Dropout method. Our results confirmed the great impact of the new hybrid
loss functions for minimising the overlap between the distributions of
uncertainty estimates for correct and incorrect predictions without sacrificing
the model's overall performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Propagating State Uncertainty Through Trajectory Forecasting. (arXiv:2110.03267v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03267">
<div class="article-summary-box-inner">
<span><p>Uncertainty pervades through the modern robotic autonomy stack, with nearly
every component (e.g., sensors, detection, classification, tracking, behavior
prediction) producing continuous or discrete probabilistic distributions.
Trajectory forecasting, in particular, is surrounded by uncertainty as its
inputs are produced by (noisy) upstream perception and its outputs are
predictions that are often probabilistic for use in downstream planning.
However, most trajectory forecasting methods do not account for upstream
uncertainty, instead taking only the most-likely values. As a result,
perceptual uncertainties are not propagated through forecasting and predictions
are frequently overconfident. To address this, we present a novel method for
incorporating perceptual state uncertainty in trajectory forecasting, a key
component of which is a new statistical distance-based loss function which
encourages predicting uncertainties that better match upstream perception. We
evaluate our approach both in illustrative simulations and on large-scale,
real-world data, demonstrating its efficacy in propagating perceptual state
uncertainty through prediction and producing more calibrated predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Injecting Planning-Awareness into Prediction and Detection Evaluation. (arXiv:2110.03270v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03270">
<div class="article-summary-box-inner">
<span><p>Detecting other agents and forecasting their behavior is an integral part of
the modern robotic autonomy stack, especially in safety-critical scenarios
entailing human-robot interaction such as autonomous driving. Due to the
importance of these components, there has been a significant amount of interest
and research in perception and trajectory forecasting, resulting in a wide
variety of approaches. Common to most works, however, is the use of the same
few accuracy-based evaluation metrics, e.g., intersection-over-union,
displacement error, log-likelihood, etc. While these metrics are informative,
they are task-agnostic and outputs that are evaluated as equal can lead to
vastly different outcomes in downstream planning and decision making. In this
work, we take a step back and critically assess current evaluation metrics,
proposing task-aware metrics as a better measure of performance in systems
where they are deployed. Experiments on an illustrative simulation as well as
real-world autonomous driving data validate that our proposed task-aware
metrics are able to account for outcome asymmetry and provide a better estimate
of a model's closed-loop performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Virtual Multi-Modality Self-Supervised Foreground Matting for Human-Object Interaction. (arXiv:2110.03278v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03278">
<div class="article-summary-box-inner">
<span><p>Most existing human matting algorithms tried to separate pure human-only
foreground from the background. In this paper, we propose a Virtual
Multi-modality Foreground Matting (VMFM) method to learn human-object
interactive foreground (human and objects interacted with him or her) from a
raw RGB image. The VMFM method requires no additional inputs, e.g. trimap or
known background. We reformulate foreground matting as a self-supervised
multi-modality problem: factor each input image into estimated depth map,
segmentation mask, and interaction heatmap using three auto-encoders. In order
to fully utilize the characteristics of each modality, we first train a dual
encoder-to-decoder network to estimate the same alpha matte. Then we introduce
a self-supervised method: Complementary Learning(CL) to predict deviation
probability map and exchange reliable gradients across modalities without
label. We conducted extensive experiments to analyze the effectiveness of each
modality and the significance of different components in complementary
learning. We demonstrate that our model outperforms the state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MC-LCR: Multi-modal contrastive classification by locally correlated representations for effective face forgery detection. (arXiv:2110.03290v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03290">
<div class="article-summary-box-inner">
<span><p>As the remarkable development of facial manipulation technologies is
accompanied by severe security concerns, face forgery detection has become a
recent research hotspot. Most existing detection methods train a binary
classifier under global supervision to judge real or fake. However, advanced
manipulations only perform small-scale tampering, posing challenges to
comprehensively capture subtle and local forgery artifacts, especially in high
compression settings and cross-dataset scenarios. To address such limitations,
we propose a novel framework named Multi-modal Contrastive Classification by
Locally Correlated Representations(MC-LCR), for effective face forgery
detection. Instead of specific appearance features, our MC-LCR aims to amplify
implicit local discrepancies between authentic and forged faces from both
spatial and frequency domains. Specifically, we design the shallow style
representation block that measures the pairwise correlation of shallow feature
maps, which encodes local style information to extract more discriminative
features in the spatial domain. Moreover, we make a key observation that subtle
forgery artifacts can be further exposed in the patch-wise phase and amplitude
spectrum and exhibit different clues. According to the complementarity of
amplitude and phase information, we develop a patch-wise amplitude and phase
dual attention module to capture locally correlated inconsistencies with each
other in the frequency domain. Besides the above two modules, we further
introduce the collaboration of supervised contrastive loss with cross-entropy
loss. It helps the network learn more discriminative and generalized
representations. Through extensive experiments and comprehensive studies, we
achieve state-of-the-art performance and demonstrate the robustness and
generalization of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Supermask Pruning: Learning to Prune Image Captioning Models. (arXiv:2110.03298v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03298">
<div class="article-summary-box-inner">
<span><p>With the advancement of deep models, research work on image captioning has
led to a remarkable gain in raw performance over the last decade, along with
increasing model complexity and computational cost. However, surprisingly works
on compression of deep networks for image captioning task has received little
to no attention. For the first time in image captioning research, we provide an
extensive comparison of various unstructured weight pruning methods on three
different popular image captioning architectures, namely Soft-Attention,
Up-Down and Object Relation Transformer. Following this, we propose a novel
end-to-end weight pruning method that performs gradual sparsification based on
weight sensitivity to the training loss. The pruning schemes are then extended
with encoder pruning, where we show that conducting both decoder pruning and
training simultaneously prior to the encoder pruning provides good overall
performance. Empirically, we show that an 80% to 95% sparse network (up to 75%
reduction in model size) can either match or outperform its dense counterpart.
The code and pre-trained models for Up-Down and Object Relation Transformer
that are capable of achieving CIDEr scores &gt;120 on the MS-COCO dataset but with
only 8.7 MB and 14.5 MB in model size (size reduction of 96% and 94%
respectively against dense versions) are publicly available at
https://github.com/jiahuei/sparse-image-captioning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MGPSN: Motion-Guided Pseudo Siamese Network for Indoor Video Head Detection. (arXiv:2110.03302v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03302">
<div class="article-summary-box-inner">
<span><p>Head detection in real-world videos is an important research topic in
computer vision. However, existing studies face some challenges in complex
scenes. The performance of head detectors deteriorates when objects which have
similar head appearance exist for indoor videos. Moreover, heads have small
scales and diverse poses, which increases the difficulty in detection. To
handle these issues, we propose Motion-Guided Pseudo Siamese Network for Indoor
Video Head Detection (MGPSN), an end-to-end model to learn the robust head
motion features. MGPSN integrates spatial-temporal information on pixel level,
guiding the model to extract effective head features. Experiments show that
MGPSN is able to suppress static objects and enhance motion instances. Compared
with previous methods, it achieves state-of-the-art performance on the crowd
Brainwash dataset. Different backbone networks and detectors are evaluated to
verify the flexibility and generality of MGPSN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Moment evolution equations and moment matching for stochastic image EPDiff. (arXiv:2110.03337v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03337">
<div class="article-summary-box-inner">
<span><p>Models of stochastic image deformation allow study of time-continuous
stochastic effects transforming images by deforming the image domain.
Applications include longitudinal medical image analysis with both population
trends and random subject specific variation. Focusing on a stochastic
extension of the LDDMM models with evolutions governed by a stochastic EPDiff
equation, we use moment approximations of the corresponding Ito diffusion to
construct estimators for statistical inference in the full stochastic model. We
show that this approach, when efficiently implemented with automatic
differentiation tools, can successfully estimate parameters encoding the
spatial correlation of the noise fields on the image
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-aware GAN with Adaptive Loss for Robust MRI Image Enhancement. (arXiv:2110.03343v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03343">
<div class="article-summary-box-inner">
<span><p>Image-to-image translation is an ill-posed problem as unique one-to-one
mapping may not exist between the source and target images. Learning-based
methods proposed in this context often evaluate the performance on test data
that is similar to the training data, which may be impractical. This demands
robust methods that can quantify uncertainty in the prediction for making
informed decisions, especially for critical areas such as medical imaging.
Recent works that employ conditional generative adversarial networks (GANs)
have shown improved performance in learning photo-realistic image-to-image
mappings between the source and the target images. However, these methods do
not focus on (i)~robustness of the models to out-of-distribution (OOD)-noisy
data and (ii)~uncertainty quantification. This paper proposes a GAN-based
framework that (i)~models an adaptive loss function for robustness to OOD-noisy
data that automatically tunes the spatially varying norm for penalizing the
residuals and (ii)~estimates the per-voxel uncertainty in the predictions. We
demonstrate our method on two key applications in medical imaging:
(i)~undersampled magnetic resonance imaging (MRI) reconstruction (ii)~MRI
modality propagation. Our experiments with two different real-world datasets
show that the proposed method (i)~is robust to OOD-noisy test data and provides
improved accuracy and (ii)~quantifies voxel-level uncertainty in the
predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MSHCNet: Multi-Stream Hybridized Convolutional Networks with Mixed Statistics in Euclidean/Non-Euclidean Spaces and Its Application to Hyperspectral Image Classification. (arXiv:2110.03346v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03346">
<div class="article-summary-box-inner">
<span><p>It is well known that hyperspectral images (HSI) contain rich
spatial-spectral contextual information, and how to effectively combine both
spectral and spatial information using DNN for HSI classification has become a
new research hotspot. Compared with CNN with square kernels, GCN have exhibited
exciting potential to model spatial contextual structure and conduct flexible
convolution on arbitrarily irregular image regions. However, current GCN only
using first-order spectral-spatial signatures can result in boundary blurring
and isolated misclassification. To address these, we first designed the
graph-based second-order pooling (GSOP) operation to obtain contextual nodes
information in non-Euclidean space for GCN. Further, we proposed a novel
multi-stream hybridized convolutional network (MSHCNet) with combination of
first and second order statistics in Euclidean/non-Euclidean spaces to learn
and fuse multi-view complementary information to segment HSIs. Specifically,
our MSHCNet adopted four parallel streams, which contained G-stream, utilizing
the irregular correlation between adjacent land covers in terms of first-order
graph in non-Euclidean space; C-stream, adopting convolution operator to learn
regular spatial-spectral features in Euclidean space; N-stream, combining first
and second order features to learn representative and discriminative regular
spatial-spectral features of Euclidean space; S-stream, using GSOP to capture
boundary correlations and obtain graph representations from all nodes in graphs
of non-Euclidean space. Besides, these feature representations learned from
four different streams were fused to integrate the multi-view complementary
information for HSI classification. Finally, we evaluated our proposed MSHCNet
on three hyperspectral datasets, and experimental results demonstrated that our
method significantly outperformed state-of-the-art eight methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimized U-Net for Brain Tumor Segmentation. (arXiv:2110.03352v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03352">
<div class="article-summary-box-inner">
<span><p>We propose an optimized U-Net architecture for a brain \mbox{tumor}
segmentation task in the BraTS21 Challenge. To find the \mbox{optimal} model
architecture and learning schedule we ran an extensive ablation study to test:
deep supervision loss, Focal loss, decoder attention, drop block, and residual
connections. Additionally, we have searched for the optimal depth of the U-Net
and number of convolutional channels. Our solution was the winner of the
challenge validation phase, with the normalized statistical ranking score of
0.267 and mean Dice score of 0.8855
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse MoEs meet Efficient Ensembles. (arXiv:2110.03360v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03360">
<div class="article-summary-box-inner">
<span><p>Machine learning models based on the aggregated outputs of submodels, either
at the activation or prediction levels, lead to strong performance. We study
the interplay of two popular classes of such models: ensembles of neural
networks and sparse mixture of experts (sparse MoEs). First, we show that these
two approaches have complementary features whose combination is beneficial.
Then, we present partitioned batch ensembles, an efficient ensemble of sparse
MoEs that takes the best of both classes of models. Extensive experiments on
fine-tuned vision transformers demonstrate the accuracy, log-likelihood,
few-shot learning, robustness, and uncertainty calibration improvements of our
approach over several challenging baselines. Partitioned batch ensembles not
only scale to models with up to 2.7B parameters, but also provide larger
performance gains for larger models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Baseline Framework for Part-level Action Parsing and Action Recognition. (arXiv:2110.03368v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03368">
<div class="article-summary-box-inner">
<span><p>This technical report introduces our 2nd place solution to Kinetics-TPS Track
on Part-level Action Parsing in ICCV DeeperAction Workshop 2021. Our entry is
mainly based on YOLOF for instance and part detection, HRNet for human pose
estimation, and CSN for video-level action recognition and frame-level part
state parsing. We describe technical details for the Kinetics-TPS dataset,
together with some experimental results. In the competition, we achieved 61.37%
mAP on the test set of Kinetics-TPS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data. (arXiv:2110.03374v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03374">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation aims to align a labeled source domain and an
unlabeled target domain, but it requires to access the source data which often
raises concerns in data privacy, data portability and data transmission
efficiency. We study unsupervised model adaptation (UMA), or called
Unsupervised Domain Adaptation without Source Data, an alternative setting that
aims to adapt source-trained models towards target distributions without
accessing source data. To this end, we design an innovative historical
contrastive learning (HCL) technique that exploits historical source hypothesis
to make up for the absence of source data in UMA. HCL addresses the UMA
challenge from two perspectives. First, it introduces historical contrastive
instance discrimination (HCID) that learns from target samples by contrasting
their embeddings which are generated by the currently adapted model and the
historical models. With the source-trained and earlier-epoch models as the
historical models, HCID encourages UMA to learn instance-discriminative target
representations while preserving the source hypothesis. Second, it introduces
historical contrastive category discrimination (HCCD) that pseudo-labels target
samples to learn category-discriminative target representations. Instead of
globally thresholding pseudo labels, HCCD re-weights pseudo labels according to
their prediction consistency across the current and historical models.
Extensive experiments show that HCL outperforms and complements
state-of-the-art methods consistently across a variety of visual tasks (e.g.,
segmentation, classification and detection) and setups (e.g., close-set,
open-set and partial adaptation).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Model Explainability for Inspection Accuracy Improvement in the Automotive Industry. (arXiv:2110.03384v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03384">
<div class="article-summary-box-inner">
<span><p>The welding seams visual inspection is still manually operated by humans in
different companies, so the result of the test is still highly subjective and
expensive. At present, the integration of deep learning methods for welds
classification is a research focus in engineering applications. This work
intends to apprehend and emphasize the contribution of deep learning model
explainability to the improvement of welding seams classification accuracy and
reliability, two of the various metrics affecting the production lines and cost
in the automotive industry. For this purpose, we implement a novel hybrid
method that relies on combining the model prediction scores and visual
explanation heatmap of the model in order to make a more accurate
classification of welding seam defects and improve both its performance and its
reliability. The results show that the hybrid model performance is relatively
above our target performance and helps to increase the accuracy by at least
18%, which presents new perspectives to the developments of deep Learning
explainability and interpretability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AnoSeg: Anomaly Segmentation Network Using Self-Supervised Learning. (arXiv:2110.03396v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03396">
<div class="article-summary-box-inner">
<span><p>Anomaly segmentation, which localizes defective areas, is an important
component in large-scale industrial manufacturing. However, most recent
researches have focused on anomaly detection. This paper proposes a novel
anomaly segmentation network (AnoSeg) that can directly generate an accurate
anomaly map using self-supervised learning. For highly accurate anomaly
segmentation, the proposed AnoSeg considers three novel techniques: Anomaly
data generation based on hard augmentation, self-supervised learning with
pixel-wise and adversarial losses, and coordinate channel concatenation. First,
to generate synthetic anomaly images and reference masks for normal data, the
proposed method uses hard augmentation to change the normal sample
distribution. Then, the proposed AnoSeg is trained in a self-supervised
learning manner from the synthetic anomaly data and normal data. Finally, the
coordinate channel, which represents the pixel location information, is
concatenated to an input of AnoSeg to consider the positional relationship of
each pixel in the image. The estimated anomaly map can also be utilized to
improve the performance of anomaly detection. Our experiments show that the
proposed method outperforms the state-of-the-art anomaly detection and anomaly
segmentation methods for the MVTec AD dataset. In addition, we compared the
proposed method with the existing methods through the intersection over union
(IoU) metric commonly used in segmentation tasks and demonstrated the
superiority of our method for anomaly segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Hierarchical Variational Neural Uncertainty Model for Stochastic Video Prediction. (arXiv:2110.03446v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03446">
<div class="article-summary-box-inner">
<span><p>Predicting the future frames of a video is a challenging task, in part due to
the underlying stochastic real-world phenomena. Prior approaches to solve this
task typically estimate a latent prior characterizing this stochasticity,
however do not account for the predictive uncertainty of the (deep learning)
model. Such approaches often derive the training signal from the mean-squared
error (MSE) between the generated frame and the ground truth, which can lead to
sub-optimal training, especially when the predictive uncertainty is high.
Towards this end, we introduce Neural Uncertainty Quantifier (NUQ) - a
stochastic quantification of the model's predictive uncertainty, and use it to
weigh the MSE loss. We propose a hierarchical, variational framework to derive
NUQ in a principled manner using a deep, Bayesian graphical model. Our
experiments on four benchmark stochastic video prediction datasets show that
our proposed framework trains more effectively compared to the state-of-the-art
models (especially when the training sets are small), while demonstrating
better video generation quality and diversity against several evaluation
metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inter-Domain Alignment for Predicting High-Resolution Brain Networks Using Teacher-Student Learning. (arXiv:2110.03452v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03452">
<div class="article-summary-box-inner">
<span><p>Accurate and automated super-resolution image synthesis is highly desired
since it has the great potential to circumvent the need for acquiring high-cost
medical scans and a time-consuming preprocessing pipeline of neuroimaging data.
However, existing deep learning frameworks are solely designed to predict
high-resolution (HR) image from a low-resolution (LR) one, which limits their
generalization ability to brain graphs (i.e., connectomes). A small body of
works has focused on superresolving brain graphs where the goal is to predict a
HR graph from a single LR graph. Although promising, existing works mainly
focus on superresolving graphs belonging to the same domain (e.g., functional),
overlooking the domain fracture existing between multimodal brain data
distributions (e.g., morphological and structural). To this aim, we propose a
novel inter-domain adaptation framework namely, Learn to SuperResolve Brain
Graphs with Knowledge Distillation Network (L2S-KDnet), which adopts a
teacher-student paradigm to superresolve brain graphs. Our teacher network is a
graph encoder-decoder that firstly learns the LR brain graph embeddings, and
secondly learns how to align the resulting latent representations to the HR
ground truth data distribution using an adversarial regularization. Ultimately,
it decodes the HR graphs from the aligned embeddings. Next, our student network
learns the knowledge of the aligned brain graphs as well as the topological
structure of the predicted HR graphs transferred from the teacher. We further
leverage the decoder of the teacher to optimize the student network. L2S-KDnet
presents the first TS architecture tailored for brain graph super-resolution
synthesis that is based on inter-domain alignment. Our experimental results
demonstrate substantial performance gains over benchmark methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recurrent Multigraph Integrator Network for Predicting the Evolution of Population-Driven Brain Connectivity Templates. (arXiv:2110.03453v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03453">
<div class="article-summary-box-inner">
<span><p>Learning how to estimate a connectional brain template(CBT) from a population
of brain multigraphs, where each graph (e.g., functional) quantifies a
particular relationship between pairs of brain regions of interest (ROIs),
allows to pin down the unique connectivity patterns shared across individuals.
Specifically, a CBT is viewed as an integral representation of a set of highly
heterogeneous graphs and ideally meeting the centeredness (i.e., minimum
distance to all graphs in the population) and discriminativeness (i.e.,
distinguishes the healthy from the disordered population) criteria. So far,
existing works have been limited to only integrating and fusing a population of
brain multigraphs acquired at a single timepoint. In this paper, we
unprecedentedly tackle the question: Given a baseline multigraph population,
can we learn how to integrate and forecast its CBT representations at follow-up
timepoints? Addressing such question is of paramount in predicting common
alternations across healthy and disordered populations. To fill this gap, we
propose Recurrent Multigraph Integrator Network (ReMI-Net), the first graph
recurrent neural network which infers the baseline CBT of an input population
t1 and predicts its longitudinal evolution over time (ti &gt; t1). Our ReMI-Net is
composed of recurrent neural blocks with graph convolutional layers using a
cross-node message passing to first learn hidden-states embeddings of each CBT
node (i.e., brain region of interest) and then predict its evolution at the
consecutive timepoint. Moreover, we design a novel time-dependent loss to
regularize the CBT evolution trajectory over time and further introduce a
cyclic recursion and learnable normalization layer to generate well-centered
CBTs from time-dependent hidden-state embeddings. Finally, we derive the CBT
adjacency matrix from the learned hidden state graph representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differential Anomaly Detection for Facial Images. (arXiv:2110.03464v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03464">
<div class="article-summary-box-inner">
<span><p>Due to their convenience and high accuracy, face recognition systems are
widely employed in governmental and personal security applications to
automatically recognise individuals. Despite recent advances, face recognition
systems have shown to be particularly vulnerable to identity attacks (i.e.,
digital manipulations and attack presentations). Identity attacks pose a big
security threat as they can be used to gain unauthorised access and spread
misinformation. In this context, most algorithms for detecting identity attacks
generalise poorly to attack types that are unknown at training time. To tackle
this problem, we introduce a differential anomaly detection framework in which
deep face embeddings are first extracted from pairs of images (i.e., reference
and probe) and then combined for identity attack detection. The experimental
evaluation conducted over several databases shows a high generalisation
capability of the proposed method for detecting unknown attacks in both the
digital and physical domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Image Decomposition with Phase-Correlation Networks. (arXiv:2110.03473v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03473">
<div class="article-summary-box-inner">
<span><p>The ability to decompose scenes into their object components is a desired
property for autonomous agents, allowing them to reason and act in their
surroundings. Recently, different methods have been proposed to learn
object-centric representations from data in an unsupervised manner. These
methods often rely on latent representations learned by deep neural networks,
hence requiring high computational costs and large amounts of curated data.
Such models are also difficult to interpret. To address these challenges, we
propose the Phase-Correlation Decomposition Network (PCDNet), a novel model
that decomposes a scene into its object components, which are represented as
transformed versions of a set of learned object prototypes. The core building
block in PCDNet is the Phase-Correlation Cell (PC Cell), which exploits the
frequency-domain representation of the images in order to estimate the
transformation between an object prototype and its transformed version in the
image. In our experiments, we show how PCDNet outperforms state-of-the-art
methods for unsupervised object discovery and segmentation on simple benchmark
datasets and on more challenging data, while using a small number of learnable
parameters and being fully interpretable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InfoSeg: Unsupervised Semantic Image Segmentation with Mutual Information Maximization. (arXiv:2110.03477v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03477">
<div class="article-summary-box-inner">
<span><p>We propose a novel method for unsupervised semantic image segmentation based
on mutual information maximization between local and global high-level image
features. The core idea of our work is to leverage recent progress in
self-supervised image representation learning. Representation learning methods
compute a single high-level feature capturing an entire image. In contrast, we
compute multiple high-level features, each capturing image segments of one
particular semantic class. To this end, we propose a novel two-step learning
procedure comprising a segmentation and a mutual information maximization step.
In the first step, we segment images based on local and global features. In the
second step, we maximize the mutual information between local features and
high-level features of their respective class. For training, we provide solely
unlabeled images and start from random network initialization. For quantitative
and qualitative evaluation, we use established benchmarks, and COCO-Persons,
whereby we introduce the latter in this paper as a challenging novel benchmark.
InfoSeg significantly outperforms the current state-of-the-art, e.g., we
achieve a relative increase of 26% in the Pixel Accuracy metric on the
COCO-Stuff dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Camera Calibration through Camera Projection Loss. (arXiv:2110.03479v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03479">
<div class="article-summary-box-inner">
<span><p>Camera calibration is a necessity in various tasks including 3D
reconstruction, hand-eye coordination for a robotic interaction, autonomous
driving, etc. In this work we propose a novel method to predict extrinsic
(baseline, pitch, and translation), intrinsic (focal length and principal point
offset) parameters using an image pair. Unlike existing methods, instead of
designing an end-to-end solution, we proposed a new representation that
incorporates camera model equations as a neural network in multi-task learning
framework. We estimate the desired parameters via novel \emph{camera projection
loss} (CPL) that uses the camera model neural network to reconstruct the 3D
points and uses the reconstruction loss to estimate the camera parameters. To
the best of our knowledge, ours is the first method to jointly estimate both
the intrinsic and extrinsic parameters via a multi-task learning methodology
that combines analytical equations in learning framework for the estimation of
camera parameters. We also proposed a novel dataset using CARLA Simulator.
Empirically, we demonstrate that our proposed approach achieves better
performance with respect to both deep learning-based and traditional methods on
7 out of 10 parameters evaluated using both synthetic and real data. Our code
and generated dataset will be made publicly available to facilitate future
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Regress Bodies from Images using Differentiable Semantic Rendering. (arXiv:2110.03480v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03480">
<div class="article-summary-box-inner">
<span><p>Learning to regress 3D human body shape and pose (e.g.~SMPL parameters) from
monocular images typically exploits losses on 2D keypoints, silhouettes, and/or
part-segmentation when 3D training data is not available. Such losses, however,
are limited because 2D keypoints do not supervise body shape and segmentations
of people in clothing do not match projected minimally-clothed SMPL shapes. To
exploit richer image information about clothed people, we introduce
higher-level semantic information about clothing to penalize clothed and
non-clothed regions of the image differently. To do so, we train a body
regressor using a novel Differentiable Semantic Rendering - DSR loss. For
Minimally-Clothed regions, we define the DSR-MC loss, which encourages a tight
match between a rendered SMPL body and the minimally-clothed regions of the
image. For clothed regions, we define the DSR-C loss to encourage the rendered
SMPL body to be inside the clothing mask. To ensure end-to-end differentiable
training, we learn a semantic clothing prior for SMPL vertices from thousands
of clothed human scans. We perform extensive qualitative and quantitative
experiments to evaluate the role of clothing semantics on the accuracy of 3D
human pose and shape estimation. We outperform all previous state-of-the-art
methods on 3DPW and Human3.6M and obtain on par results on MPI-INF-3DHP. Code
and trained models are available for research at https://dsr.is.tue.mpg.de/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cartoon Explanations of Image Classifiers. (arXiv:2110.03485v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03485">
<div class="article-summary-box-inner">
<span><p>We present CartoonX (Cartoon Explanation), a novel model-agnostic explanation
method tailored towards image classifiers and based on the rate-distortion
explanation (RDE) framework. Natural images are roughly piece-wise smooth
signals -- also called cartoon images -- and tend to be sparse in the wavelet
domain. CartoonX is the first explanation method to exploit this by requiring
its explanations to be sparse in the wavelet domain, thus extracting the
\emph{relevant piece-wise smooth} part of an image instead of relevant
pixel-sparse regions. We demonstrate experimentally that CartoonX is not only
highly interpretable due to its piece-wise smooth nature but also particularly
apt at explaining misclassifications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scale Invariant Domain Generalization Image Recapture Detection. (arXiv:2110.03496v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03496">
<div class="article-summary-box-inner">
<span><p>Recapturing and rebroadcasting of images are common attack methods in
insurance frauds and face identification spoofing, and an increasing number of
detection techniques were introduced to handle this problem. However, most of
them ignored the domain generalization scenario and scale variances, with an
inferior performance on domain shift situations, and normally were exacerbated
by intra-domain and inter-domain scale variances. In this paper, we propose a
scale alignment domain generalization framework (SADG) to address these
challenges. First, an adversarial domain discriminator is exploited to minimize
the discrepancies of image representation distributions among different
domains. Meanwhile, we exploit triplet loss as a local constraint to achieve a
clearer decision boundary. Moreover, a scale alignment loss is introduced as a
global relationship regularization to force the image representations of the
same class across different scales to be undistinguishable. Experimental
results on four databases and comparison with state-of-the-art approaches show
that better performance can be achieved using our framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Few-shot Learning Graph Multi-Trajectory Evolution Network for Forecasting Multimodal Baby Connectivity Development from a Baseline Timepoint. (arXiv:2110.03535v1 [q-bio.NC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03535">
<div class="article-summary-box-inner">
<span><p>Charting the baby connectome evolution trajectory during the first year after
birth plays a vital role in understanding dynamic connectivity development of
baby brains. Such analysis requires acquisition of longitudinal connectomic
datasets. However, both neonatal and postnatal scans are rarely acquired due to
various difficulties. A small body of works has focused on predicting baby
brain evolution trajectory from a neonatal brain connectome derived from a
single modality. Although promising, large training datasets are essential to
boost model learning and to generalize to a multi-trajectory prediction from
different modalities (i.e., functional and morphological connectomes). Here, we
unprecedentedly explore the question: Can we design a few-shot learning-based
framework for predicting brain graph trajectories across different modalities?
To this aim, we propose a Graph Multi-Trajectory Evolution Network (GmTE-Net),
which adopts a teacher-student paradigm where the teacher network learns on
pure neonatal brain graphs and the student network learns on simulated brain
graphs given a set of different timepoints. To the best of our knowledge, this
is the first teacher-student architecture tailored for brain graph
multi-trajectory growth prediction that is based on few-shot learning and
generalized to graph neural networks (GNNs). To boost the performance of the
student network, we introduce a local topology-aware distillation loss that
forces the predicted graph topology of the student network to be consistent
with the teacher network. Experimental results demonstrate substantial
performance gains over benchmark methods. Hence, our GmTE-Net can be leveraged
to predict atypical brain connectivity trajectory evolution across various
modalities. Our code is available at https: //github.com/basiralab/GmTE-Net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAR: Region-Aware Point Cloud Registration. (arXiv:2110.03544v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03544">
<div class="article-summary-box-inner">
<span><p>This paper concerns the research problem of point cloud registration to find
the rigid transformation to optimally align the source point set with the
target one. Learning robust point cloud registration models with deep neural
networks has emerged as a powerful paradigm, offering promising performance in
predicting the global geometric transformation for a pair of point sets.
Existing methods firstly leverage an encoder to regress a latent shape
embedding, which is then decoded into a shape-conditioned transformation via
concatenation-based conditioning. However, different regions of a 3D shape vary
in their geometric structures which makes it more sense that we have a
region-conditioned transformation instead of the shape-conditioned one. In this
paper we present a \underline{R}egion-\underline{A}ware point cloud
\underline{R}egistration, denoted as RAR, to predict transformation for
pairwise point sets in the self-supervised learning fashion. More specifically,
we develop a novel region-aware decoder (RAD) module that is formed with an
implicit neural region representation parameterized by neural networks. The
implicit neural region representation is learned with a self-supervised 3D
shape reconstruction loss without the need for region labels. Consequently, the
region-aware decoder (RAD) module guides the training of the region-aware
transformation (RAT) module and region-aware weight (RAW) module, which predict
the transforms and weights for different regions respectively. The global
geometric transformation from source point set to target one is then formed by
the weighted fusion of region-aware transforms. Compared to the
state-of-the-art approaches, our experiments show that our RAR achieves
superior registration performance over various benchmark datasets (e.g.
ModelNet40).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Human-Object Interaction Detection in Video via Contrastive Spatiotemporal Regions. (arXiv:2110.03562v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03562">
<div class="article-summary-box-inner">
<span><p>We introduce the task of weakly supervised learning for detecting human and
object interactions in videos. Our task poses unique challenges as a system
does not know what types of human-object interactions are present in a video or
the actual spatiotemporal location of the human and the object. To address
these challenges, we introduce a contrastive weakly supervised training loss
that aims to jointly associate spatiotemporal regions in a video with an action
and object vocabulary and encourage temporal continuity of the visual
appearance of moving objects as a form of self-supervision. To train our model,
we introduce a dataset comprising over 6.5k videos with human-object
interaction annotations that have been semi-automatically curated from sentence
captions associated with the videos. We demonstrate improved performance over
weakly supervised baselines adapted to our task on our video dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Simple Vision Algorithm for Detecting the Enzymic Browning Defects in Golden Delicious Apples. (arXiv:2110.03574v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03574">
<div class="article-summary-box-inner">
<span><p>In this work, a simple vision algorithm is designed and implemented to
extract and identify the surface defects on the Golden Delicious apples caused
by the enzymic browning process. 34 Golden Delicious apples were selected for
the experiments, of which 17 had enzymic browning defects and the other 17 were
sound. The image processing part of the proposed vision algorithm extracted the
defective surface area of the apples with high accuracy of 97.15%. The area and
mean of the segmented images were selected as the 2x1 feature vectors to feed
into a designed artificial neural network. The analysis based on the above
features indicated that the images with a mean less than 0.0065 did not belong
to the defective apples; rather, they were extracted as part of the calyx and
stem of the healthy apples. The classification accuracy of the neural network
applied in this study was 99.19%
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating Image Depth in the Comics Domain. (arXiv:2110.03575v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03575">
<div class="article-summary-box-inner">
<span><p>Estimating the depth of comics images is challenging as such images a) are
monocular; b) lack ground-truth depth annotations; c) differ across different
artistic styles; d) are sparse and noisy. We thus, use an off-the-shelf
unsupervised image to image translation method to translate the comics images
to natural ones and then use an attention-guided monocular depth estimator to
predict their depth. This lets us leverage the depth annotations of existing
natural images to train the depth estimator. Furthermore, our model learns to
distinguish between text and images in the comics panels to reduce text-based
artefacts in the depth estimates. Our method consistently outperforms the
existing state-ofthe-art approaches across all metrics on both the DCM and
eBDtheque images. Finally, we introduce a dataset to evaluate depth prediction
on comics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Accurate Cross-Domain In-Bed Human Pose Estimation. (arXiv:2110.03578v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03578">
<div class="article-summary-box-inner">
<span><p>Human behavioral monitoring during sleep is essential for various medical
applications. Majority of the contactless human pose estimation algorithms are
based on RGB modality, causing ineffectiveness in in-bed pose estimation due to
occlusions by blankets and varying illumination conditions. Long-wavelength
infrared (LWIR) modality based pose estimation algorithms overcome the
aforementioned challenges; however, ground truth pose generations by a human
annotator under such conditions are not feasible. A feasible solution to
address this issue is to transfer the knowledge learned from images with pose
labels and no occlusions, and adapt it towards real world conditions
(occlusions due to blankets). In this paper, we propose a novel learning
strategy comprises of two-fold data augmentation to reduce the cross-domain
discrepancy and knowledge distillation to learn the distribution of unlabeled
images in real world conditions. Our experiments and analysis show the
effectiveness of our approach over multiple standard human pose estimation
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A transformer-based deep learning approach for classifying brain metastases into primary organ sites using clinical whole brain MRI images. (arXiv:2110.03588v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03588">
<div class="article-summary-box-inner">
<span><p>The treatment decisions for brain metastatic disease are driven by knowledge
of the primary organ site cancer histology, often requiring invasive biopsy.
This study aims to develop a novel deep learning approach for accurate and
rapid non-invasive identification of brain metastatic tumor histology with
conventional whole-brain MRI. The use of clinical whole-brain data and the
end-to-end pipeline obviate external human intervention. This IRB-approved
single-site retrospective study was comprised of patients (n=1,293) referred
for MRI treatment-planning and gamma knife radiosurgery from July 2000 to May
2019. Contrast-enhanced T1-weighted contrast enhanced and
T2-weighted-Fluid-Attenuated Inversion Recovery brain MRI exams (n=1,428) were
minimally preprocessed (voxel resolution unification and signal-intensity
rescaling/normalization), requiring only seconds per an MRI scan, and input
into the proposed deep learning workflow for tumor segmentation, modality
transfer, and primary site classification associated with brain metastatic
disease in one of four classes (lung, melanoma, renal, and other). Ten-fold
cross-validation generated the overall AUC of 0.941, lung class AUC of 0.899,
melanoma class AUC of 0.882, renal class AUC of 0.870, and other class AUC of
0.885. It is convincingly established that whole-brain imaging features would
be sufficiently discriminative to allow accurate diagnosis of the primary organ
site of malignancy. Our end-to-end deep learning-based radiomic method has a
great translational potential for classifying metastatic tumor types using
whole-brain MRI images, without additional human intervention. Further
refinement may offer invaluable tools to expedite primary organ site cancer
identification for treatment of brain metastatic disease and improvement of
patient outcomes and survival.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TranSalNet: Visual saliency prediction using transformers. (arXiv:2110.03593v1 [cs.MM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03593">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) have significantly advanced
computational modeling for saliency prediction. However, the inherent inductive
biases of convolutional architectures cause insufficient long-range contextual
encoding capacity, which potentially makes a saliency model less humanlike.
Transformers have shown great potential in encoding long-range information by
leveraging the self-attention mechanism. In this paper, we propose a novel
saliency model integrating transformer components to CNNs to capture the
long-range contextual information. Experimental results show that the new
components make improvements, and the proposed model achieves promising results
in predicting saliency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Thing to Fool them All: Generating Interpretable, Universal, and Physically-Realizable Adversarial Features. (arXiv:2110.03605v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03605">
<div class="article-summary-box-inner">
<span><p>It is well understood that modern deep networks are vulnerable to adversarial
attacks. However, conventional methods fail to produce adversarial
perturbations that are intelligible to humans, and they pose limited threats in
the physical world. To study feature-class associations in networks and better
understand the real-world threats they face, we develop feature-level
adversarial perturbations using deep image generators and a novel optimization
objective. We term these feature-fool attacks. We show that they are versatile
and use them to generate targeted feature-level attacks at the ImageNet scale
that are simultaneously interpretable, universal to any source image, and
physically-realizable. These attacks can also reveal spurious,
semantically-describable feature/class associations, and we use them to guide
the design of "copy/paste" adversaries in which one natural image is pasted
into another to cause a targeted misclassification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boxhead: A Dataset for Learning Hierarchical Representations. (arXiv:2110.03628v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03628">
<div class="article-summary-box-inner">
<span><p>Disentanglement is hypothesized to be beneficial towards a number of
downstream tasks. However, a common assumption in learning disentangled
representations is that the data generative factors are statistically
independent. As current methods are almost solely evaluated on toy datasets
where this ideal assumption holds, we investigate their performance in
hierarchical settings, a relevant feature of real-world data. In this work, we
introduce Boxhead, a dataset with hierarchically structured ground-truth
generative factors. We use this novel dataset to evaluate the performance of
state-of-the-art autoencoder-based disentanglement models and observe that
hierarchical models generally outperform single-layer VAEs in terms of
disentanglement of hierarchically arranged factors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Contrastive Learning and Pseudolabels to learn representations for Retail Product Image Classification. (arXiv:2110.03639v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03639">
<div class="article-summary-box-inner">
<span><p>Retail product Image classification problems are often few shot
classification problems, given retail product classes cannot have the type of
variations across images like a cat or dog or tree could have. Previous works
have shown different methods to finetune Convolutional Neural Networks to
achieve better classification accuracy on such datasets. In this work, we try
to address the problem statement : Can we pretrain a Convolutional Neural
Network backbone which yields good enough representations for retail product
images, so that training a simple logistic regression on these representations
gives us good classifiers ? We use contrastive learning and pseudolabel based
noisy student training to learn representations that get accuracy in order of
finetuning the entire Convnet backbone for retail product image classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Keypoint Matching and Interactive Self Attention Network to verify Retail POSMs. (arXiv:2110.03646v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03646">
<div class="article-summary-box-inner">
<span><p>Point of Sale Materials(POSM) are the merchandising and decoration items that
are used by companies to communicate product information and offers in retail
stores. POSMs are part of companies' retail marketing strategy and are often
applied as stylized window displays around retail shelves. In this work, we
apply computer vision techniques to the task of verification of POSMs in
supermarkets by telling if all desired components of window display are present
in a shelf image. We use Convolutional Neural Network based unsupervised
keypoint matching as a baseline to verify POSM components and propose a
supervised Neural Network based method to enhance the accuracy of baseline by a
large margin. We also show that the supervised pipeline is not restricted to
the POSM material it is trained on and can generalize. We train and evaluate
our model on a private dataset composed of retail shelf images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design. (arXiv:2110.03659v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03659">
<div class="article-summary-box-inner">
<span><p>An agent's functionality is largely determined by its design, i.e., skeletal
structure and joint attributes (e.g., length, size, strength). However, finding
the optimal agent design for a given function is extremely challenging since
the problem is inherently combinatorial and the design space is prohibitively
large. Additionally, it can be costly to evaluate each candidate design which
requires solving for its optimal controller. To tackle these problems, our key
idea is to incorporate the design procedure of an agent into its
decision-making process. Specifically, we learn a conditional policy that, in
an episode, first applies a sequence of transform actions to modify an agent's
skeletal structure and joint attributes, and then applies control actions under
the new design. To handle a variable number of joints across designs, we use a
graph-based policy where each graph node represents a joint and uses message
passing with its neighbors to output joint-specific actions. Using policy
gradient methods, our approach enables first-order optimization of agent design
and control as well as experience sharing across different designs, which
improves sample efficiency tremendously. Experiments show that our approach,
Transform2Act, outperforms prior methods significantly in terms of convergence
speed and final performance. Notably, Transform2Act can automatically discover
plausible designs similar to giraffes, squids, and spiders. Our project website
is at https://sites.google.com/view/transform2act.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dense Gaussian Processes for Few-Shot Segmentation. (arXiv:2110.03674v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03674">
<div class="article-summary-box-inner">
<span><p>Few-shot segmentation is a challenging dense prediction task, which entails
segmenting a novel query image given only a small annotated support set. The
key problem is thus to design a method that aggregates detailed information
from the support set, while being robust to large variations in appearance and
context. To this end, we propose a few-shot segmentation method based on dense
Gaussian process (GP) regression. Given the support set, our dense GP learns
the mapping from local deep image features to mask values, capable of capturing
complex appearance distributions. Furthermore, it provides a principled means
of capturing uncertainty, which serves as another powerful cue for the final
segmentation, obtained by a CNN decoder. Instead of a one-dimensional mask
output, we further exploit the end-to-end learning capabilities of our approach
to learn a high-dimensional output space for the GP. Our approach sets a new
state-of-the-art for both 1-shot and 5-shot FSS on the PASCAL-5$^i$ and
COCO-20$^i$ benchmarks, achieving an absolute gain of $+14.9$ mIoU in the
COCO-20$^i$ 5-shot setting. Furthermore, the segmentation quality of our
approach scales gracefully when increasing the support set size, while
achieving robust cross-dataset transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ATISS: Autoregressive Transformers for Indoor Scene Synthesis. (arXiv:2110.03675v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03675">
<div class="article-summary-box-inner">
<span><p>The ability to synthesize realistic and diverse indoor furniture layouts
automatically or based on partial input, unlocks many applications, from better
interactive 3D tools to data synthesis for training and simulation. In this
paper, we present ATISS, a novel autoregressive transformer architecture for
creating diverse and plausible synthetic indoor environments, given only the
room type and its floor plan. In contrast to prior work, which poses scene
synthesis as sequence generation, our model generates rooms as unordered sets
of objects. We argue that this formulation is more natural, as it makes ATISS
generally useful beyond fully automatic room layout synthesis. For example, the
same trained model can be used in interactive applications for general scene
completion, partial room re-arrangement with any objects specified by the user,
as well as object suggestions for any partial room. To enable this, our model
leverages the permutation equivariance of the transformer when conditioning on
the partial scene, and is trained to be permutation-invariant across object
orderings. Our model is trained end-to-end as an autoregressive generative
model using only labeled 3D bounding boxes as supervision. Evaluations on four
room types in the 3D-FRONT dataset demonstrate that our model consistently
generates plausible room layouts that are more realistic than existing methods.
In addition, it has fewer parameters, is simpler to implement and train and
runs up to 8 times faster than existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Burst Image Restoration and Enhancement. (arXiv:2110.03680v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03680">
<div class="article-summary-box-inner">
<span><p>Modern handheld devices can acquire burst image sequence in a quick
succession. However, the individual acquired frames suffer from multiple
degradations and are misaligned due to camera shake and object motions. The
goal of Burst Image Restoration is to effectively combine complimentary cues
across multiple burst frames to generate high-quality outputs. Towards this
goal, we develop a novel approach by solely focusing on the effective
information exchange between burst frames, such that the degradations get
filtered out while the actual scene details are preserved and enhanced. Our
central idea is to create a set of \emph{pseudo-burst} features that combine
complimentary information from all the input burst frames to seamlessly
exchange information. The pseudo-burst representations encode channel-wise
features from the original burst images, thus making it easier for the model to
learn distinctive information offered by multiple burst frames. However, the
pseudo-burst cannot be successfully created unless the individual burst frames
are properly aligned to discount inter-frame movements. Therefore, our approach
initially extracts preprocessed features from each burst frame and matches them
using an edge-boosting burst alignment module. The pseudo-burst features are
then created and enriched using multi-scale contextual information. Our final
step is to adaptively aggregate information from the pseudo-burst features to
progressively increase resolution in multiple stages while merging the
pseudo-burst features. In comparison to existing works that usually follow a
late fusion scheme with single-stage upsampling, our approach performs
favorably, delivering state of the art performance on burst super-resolution
and low-light image enhancement tasks. Our codes and models will be released
publicly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vehicle Image Generation Going Well with The Surroundings. (arXiv:1807.02925v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1807.02925">
<div class="article-summary-box-inner">
<span><p>Since the generative neural networks have made a breakthrough in the image
generation problem, lots of researches on their applications have been studied
such as image restoration, style transfer and image completion. However, there
has been few research generating objects in uncontrolled real-world
environments. In this paper, we propose a novel approach for vehicle image
generation in real-world scenes. Using a subnetwork based on a precedent work
of image completion, our model makes the shape of an object. Details of objects
are trained by an additional colorization and refinement subnetwork, resulting
in a better quality of generated objects. Unlike many other works, our method
does not require any segmentation layout but still makes a plausible vehicle in
the image. We evaluate our method by using images from Berkeley Deep Drive
(BDD) and Cityscape datasets, which are widely used for object detection and
image segmentation problems. The adequacy of the generated images by the
proposed method has also been evaluated using a widely utilized object
detection algorithm and the FID score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal Graph Transformer Self-Attention Networks. (arXiv:1909.11855v12 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11855">
<div class="article-summary-box-inner">
<span><p>The transformer has been extensively used in research domains such as
computer vision, image processing, and natural language processing. The
transformer, however, has not been actively used in graph neural networks. To
this end, we introduce a transformer-based advanced GNN model, named UGformer,
to learn graph representations. In particular, given an input graph, we present
two UGformer variants. The first variant is to leverage the transformer on a
set of sampled neighbors for each node, while the second is to leverage the
transformer directly on the input graph. Experimental results demonstrate that
these two UGformer variants achieve state-of-the-art accuracies on well-known
benchmark datasets for graph classification and inductive text classification,
respectively. The code is available on Github:
\url{https://github.com/daiquocnguyen/Graph-Transformer}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hypernetwork-Based Augmentation. (arXiv:2006.06320v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06320">
<div class="article-summary-box-inner">
<span><p>Data augmentation is an effective technique to improve the generalization of
deep neural networks. Recently, AutoAugment proposed a well-designed search
space and a search algorithm that automatically finds augmentation policies in
a data-driven manner. However, AutoAugment is computationally intensive. In
this paper, we propose an efficient gradient-based search algorithm, called
Hypernetwork-Based Augmentation (HBA), which simultaneously learns model
parameters and augmentation hyperparameters in a single training. Our HBA uses
a hypernetwork to approximate a population-based training algorithm, which
enables us to tune augmentation hyperparameters by gradient descent. Besides,
we introduce a weight sharing strategy that simplifies our hypernetwork
architecture and speeds up our search algorithm. We conduct experiments on
CIFAR-10, CIFAR-100, SVHN, and ImageNet. Our results show that HBA is
competitive to the state-of-the-art methods in terms of both search speed and
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reintroducing Straight-Through Estimators as Principled Methods for Stochastic Binary Networks. (arXiv:2006.06880v3 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06880">
<div class="article-summary-box-inner">
<span><p>Training neural networks with binary weights and activations is a challenging
problem due to the lack of gradients and difficulty of optimization over
discrete weights. Many successful experimental results have been achieved with
empirical straight-through (ST) approaches, proposing a variety of ad-hoc rules
for propagating gradients through non-differentiable activations and updating
discrete weights. At the same time, ST methods can be truly derived as
estimators in the stochastic binary network (SBN) model with Bernoulli weights.
We advance these derivations to a more complete and systematic study. We
analyze properties, estimation accuracy, obtain different forms of correct ST
estimators for activations and weights, explain existing empirical approaches
and their shortcomings, explain how latent weights arise from the mirror
descent method when optimizing over probabilities. This allows to reintroduce
ST methods, long known empirically, as sound approximations, apply them with
clarity and develop further improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data. (arXiv:2007.08457v6 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08457">
<div class="article-summary-box-inner">
<span><p>Photorealistic image generation has reached a new level of quality due to the
breakthroughs of generative adversarial networks (GANs). Yet, the dark side of
such deepfakes, the malicious use of generated media, raises concerns about
visual misinformation. While existing research work on deepfake detection
demonstrates high accuracy, it is subject to advances in generation techniques
and adversarial iterations on detection countermeasure techniques. Thus, we
seek a proactive and sustainable solution on deepfake detection, that is
agnostic to the evolution of generative models, by introducing artificial
fingerprints into the models.
</p>
<p>Our approach is simple and effective. We first embed artificial fingerprints
into training data, then validate a surprising discovery on the transferability
of such fingerprints from training data to generative models, which in turn
appears in the generated deepfakes. Experiments show that our fingerprinting
solution (1) holds for a variety of cutting-edge generative models, (2) leads
to a negligible side effect on generation quality, (3) stays robust against
image-level and model-level perturbations, (4) stays hard to be detected by
adversaries, and (5) converts deepfake detection and attribution into trivial
tasks and outperforms the recent state-of-the-art baselines. Our solution
closes the responsibility loop between publishing pre-trained generative model
inventions and their possible misuses, which makes it independent of the
current arms race.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-domain semantic segmentation with pyramidal fusion. (arXiv:2009.01636v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.01636">
<div class="article-summary-box-inner">
<span><p>We present our submission to the semantic segmentation contest of the Robust
Vision Challenge held at ECCV 2020. The contest requires submitting the same
model to seven benchmarks from three different domains. Our approach is based
on the SwiftNet architecture with pyramidal fusion. We address inconsistent
taxonomies with a single-level 193-dimensional softmax output. We strive to
train with large batches in order to stabilize optimization of a hard
recognition problem, and to favour smooth evolution of batchnorm statistics. We
achieve this by implementing a custom backward step through log-sum-prob loss,
and by using small crops before freezing the population statistics. Our model
ranks first on the RVC semantic segmentation challenge as well as on the
WildDash 2 leaderboard. This suggests that pyramidal fusion is competitive not
only for efficient inference with lightweight backbones, but also in
large-scale setups for multi-domain application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Batch Normalization Increases Adversarial Vulnerability and Decreases Adversarial Transferability: A Non-Robust Feature Perspective. (arXiv:2010.03316v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03316">
<div class="article-summary-box-inner">
<span><p>Batch normalization (BN) has been widely used in modern deep neural networks
(DNNs) due to improved convergence. BN is observed to increase the model
accuracy while at the cost of adversarial robustness. There is an increasing
interest in the ML community to understand the impact of BN on DNNs, especially
related to the model robustness. This work attempts to understand the impact of
BN on DNNs from a non-robust feature perspective. Straightforwardly, the
improved accuracy can be attributed to the better utilization of useful
features. It remains unclear whether BN mainly favors learning robust features
(RFs) or non-robust features (NRFs). Our work presents empirical evidence that
supports that BN shifts a model towards being more dependent on NRFs. To
facilitate the analysis of such a feature robustness shift, we propose a
framework for disentangling robust usefulness into robustness and usefulness.
Extensive analysis under the proposed framework yields valuable insight on the
DNN behavior regarding robustness, e.g. DNNs first mainly learn RFs and then
NRFs. The insight that RFs transfer better than NRFs, further inspires simple
techniques to strengthen transfer-based black-box attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Full-Glow: Fully conditional Glow for more realistic image generation. (arXiv:2012.05846v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05846">
<div class="article-summary-box-inner">
<span><p>Autonomous agents, such as driverless cars, require large amounts of labeled
visual data for their training. A viable approach for acquiring such data is
training a generative model with collected real data, and then augmenting the
collected real dataset with synthetic images from the model, generated with
control of the scene layout and ground truth labeling. In this paper we propose
Full-Glow, a fully conditional Glow-based architecture for generating plausible
and realistic images of novel street scenes given a semantic segmentation map
indicating the scene layout. Benchmark comparisons show our model to outperform
recent works in terms of the semantic segmentation performance of a pretrained
PSPNet. This indicates that images from our model are, to a higher degree than
from other models, similar to real images of the same kinds of scenes and
objects, making them suitable as training data for a visual semantic
segmentation or object recognition system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Two-stage Framework for Compound Figure Separation. (arXiv:2101.09903v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09903">
<div class="article-summary-box-inner">
<span><p>Scientific literature contains large volumes of complex, unstructured figures
that are compound in nature (i.e. composed of multiple images, graphs, and
drawings). Separation of these compound figures is critical for information
retrieval from these figures. In this paper, we propose a new strategy for
compound figure separation, which decomposes the compound figures into
constituent subfigures while preserving the association between the subfigures
and their respective caption components. We propose a two-stage framework to
address the proposed compound figure separation problem. In particular, the
subfigure label detection module detects all subfigure labels in the first
stage. Then, in the subfigure detection module, the detected subfigure labels
help to detect the subfigures by optimizing the feature selection process and
providing the global layout information as extra features. Extensive
experiments are conducted to validate the effectiveness and superiority of the
proposed framework, which improves the detection precision by 9%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Achieving Explainability for Plant Disease Classification with Disentangled Variational Autoencoders. (arXiv:2102.03082v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03082">
<div class="article-summary-box-inner">
<span><p>Agricultural image recognition tasks are becoming increasingly dependent on
deep learning (DL); however, despite the excellent performance of DL, it is
difficult to comprehend the type of logic or features of the input image it
uses during decision making. Knowing the logic or features is highly crucial
for result verification, algorithm improvement, training data improvement, and
knowledge extraction. However, the explanations from the current heatmap-based
algorithms are insufficient for the abovementioned requirements. To address
this, this paper details the development of a classification and explanation
method based on a variational autoencoder (VAE) architecture, which can
visualize the variations of the most important features by visualizing the
generated images that correspond to the variations of those features. Using the
PlantVillage dataset, an acceptable level of explainability was achieved
without sacrificing the classification accuracy. The proposed method can also
be extended to other crops as well as other image classification tasks.
Further, application systems using this method for disease identification
tasks, such as the identification of potato blackleg disease, potato virus Y,
and other image classification tasks, are currently being developed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VAE Approximation Error: ELBO and Conditional Independence. (arXiv:2102.09310v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09310">
<div class="article-summary-box-inner">
<span><p>The importance of Variational Autoencoders reaches far beyond standalone
generative models -- the approach is also used for learning latent
representations and can be generalized to semi-supervised learning. This
requires a thorough analysis of their commonly known shortcomings: posterior
collapse and approximation errors. This paper analyzes VAE approximation errors
caused by the combination of the ELBO objective with the choice of the encoder
probability family, in particular under conditional independence assumptions.
We identify the subclass of generative models consistent with the encoder
family. We show that the ELBO optimizer is pulled from the likelihood optimizer
towards this consistent subset. Furthermore, this subset can not be enlarged,
and the respective error cannot be decreased, by only considering deeper
encoder networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Deep Learning to Automate the Detection of Flaws in Nuclear Fuel Channel UT Scans. (arXiv:2102.13635v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13635">
<div class="article-summary-box-inner">
<span><p>Nuclear reactor inspections are critical to ensure the safety and reliability
of a nuclear facility's operation. In Canada, Ultrasonic Testing (UT) is used
to inspect the health of pressure tubes which are part of Canada's Deuterium
Uranium (CANDU) reactor's fuel channels. Currently, analysis of UT scans is
performed by manual visualization and measurement to locate, characterize, and
disposition flaws. Therefore, there is motivation to develop an automated
method that is fast and accurate. In this paper, a proof of concept (PoC) that
automates the detection of flaws in nuclear fuel channel UT scans using a
convolutional neural network (CNN) is presented. The CNN model was trained
after constructing a dataset using historical UT scans and the corresponding
inspection results. The requirement for this prototype was to identify the
location of at least a portion of each flaw in UT scans while minimizing false
positives (FPs). The proposed CNN model achieves this target by automatically
identifying at least a portion of each flaw where further manual analysis is
performed to identify the width, the length, and the type of the flaw.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Architecture Search From Task Similarity Measure. (arXiv:2103.00241v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00241">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a neural architecture search framework based on a
similarity measure between some baseline tasks and a target task. We first
define the notion of the task similarity based on the log-determinant of the
Fisher Information matrix. Next, we compute the task similarity from each of
the baseline tasks to the target task. By utilizing the relation between a
target and a set of learned baseline tasks, the search space of architectures
for the target task can be significantly reduced, making the discovery of the
best candidates in the set of possible architectures tractable and efficient,
in terms of GPU days. This method eliminates the requirement for training the
networks from scratch for a given target task as well as introducing the bias
in the initialization of the search space from the human domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain and View-point Agnostic Hand Action Recognition. (arXiv:2103.02303v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02303">
<div class="article-summary-box-inner">
<span><p>Hand action recognition is a special case of action recognition with
applications in human-robot interaction, virtual reality or life-logging
systems. Building action classifiers able to work for such heterogeneous action
domains is very challenging. There are very subtle changes across different
actions from a given application but also large variations across domains (e.g.
virtual reality vs life-logging). This work introduces a novel skeleton-based
hand motion representation model that tackles this problem. The framework we
propose is agnostic to the application domain or camera recording view-point.
When working on a single domain (intra-domain action classification) our
approach performs better or similar to current state-of-the-art methods on
well-known hand action recognition benchmarks. And, more importantly, when
performing hand action recognition for action domains and camera perspectives
which our approach has not been trained for (cross-domain action
classification), our proposed framework achieves comparable performance to
intra-domain state-of-the-art methods. These experiments show the robustness
and generalization capabilities of our framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What's in My LiDAR Odometry Toolbox?. (arXiv:2103.09708v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09708">
<div class="article-summary-box-inner">
<span><p>With the democratization of 3D LiDAR sensors, precise LiDAR odometries and
SLAM are in high demand. New methods regularly appear, proposing solutions
ranging from small variations in classical algorithms to radically new
paradigms based on deep learning. Yet it is often difficult to compare these
methods, notably due to the few datasets on which the methods can be evaluated
and compared. Furthermore, their weaknesses are rarely examined, often letting
the user discover the hard way whether a method would be appropriate for a use
case. In this paper, we review and organize the main 3D LiDAR odometries into
distinct categories. We implemented several approaches (geometric based, deep
learning based, and hybrid methods) to conduct an in-depth analysis of their
strengths and weaknesses on multiple datasets, guiding the reader through the
different LiDAR odometries available. Implementation of the methods has been
made publicly available at https://github.com/Kitware/pyLiDAR-SLAM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoordiNet: uncertainty-aware pose regressor for reliable vehicle localization. (arXiv:2103.10796v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10796">
<div class="article-summary-box-inner">
<span><p>In this paper, we investigate visual-based camera re-localization with neural
networks for robotics and autonomous vehicles applications. Our solution is a
CNN-based algorithm which predicts camera pose (3D translation and 3D rotation)
directly from a single image. It also provides an uncertainty estimate of the
pose. Pose and uncertainty are learned together with a single loss function and
are fused at test time with an EKF. Furthermore, we propose a new fully
convolutional architecture, named CoordiNet, designed to embed some of the
scene geometry. Our framework outperforms comparable methods on the largest
available benchmark, the Oxford RobotCar dataset, with an average error of 8
meters where previous best was 19 meters. We have also investigated the
performance of our method on large scenes for real time (18 fps) vehicle
localization. In this setup, structure-based methods require a large database,
and we show that our proposal is a reliable alternative, achieving 29cm median
error in a 1.9km loop in a busy urban area
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AgentFormer: Agent-Aware Transformers for Socio-Temporal Multi-Agent Forecasting. (arXiv:2103.14023v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14023">
<div class="article-summary-box-inner">
<span><p>Predicting accurate future trajectories of multiple agents is essential for
autonomous systems, but is challenging due to the complex agent interaction and
the uncertainty in each agent's future behavior. Forecasting multi-agent
trajectories requires modeling two key dimensions: (1) time dimension, where we
model the influence of past agent states over future states; (2) social
dimension, where we model how the state of each agent affects others. Most
prior methods model these two dimensions separately, e.g., first using a
temporal model to summarize features over time for each agent independently and
then modeling the interaction of the summarized features with a social model.
This approach is suboptimal since independent feature encoding over either the
time or social dimension can result in a loss of information. Instead, we would
prefer a method that allows an agent's state at one time to directly affect
another agent's state at a future time. To this end, we propose a new
Transformer, AgentFormer, that jointly models the time and social dimensions.
The model leverages a sequence representation of multi-agent trajectories by
flattening trajectory features across time and agents. Since standard attention
operations disregard the agent identity of each element in the sequence,
AgentFormer uses a novel agent-aware attention mechanism that preserves agent
identities by attending to elements of the same agent differently than elements
of other agents. Based on AgentFormer, we propose a stochastic multi-agent
trajectory prediction model that can attend to features of any agent at any
previous timestep when inferring an agent's future position. The latent intent
of all agents is also jointly modeled, allowing the stochasticity in one
agent's behavior to affect other agents. Our method substantially improves the
state of the art on well-established pedestrian and autonomous driving
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LatentKeypointGAN: Controlling GANs via Latent Keypoints. (arXiv:2103.15812v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15812">
<div class="article-summary-box-inner">
<span><p>Generative adversarial networks (GANs) have attained photo-realistic quality
in image generation. However, how to best control the image content remains an
open challenge. We introduce LatentKeypointGAN, a two-stage GAN which is
trained end-to-end on the classical GAN objective with internal conditioning on
a set of space keypoints. These keypoints have associated appearance embeddings
that respectively control the position and style of the generated objects and
their parts. A major difficulty that we address with suitable network
architectures and training schemes is disentangling the image into spatial and
appearance factors without domain knowledge and supervision signals. We
demonstrate that LatentKeypointGAN provides an interpretable latent space that
can be used to re-arrange the generated images by re-positioning and exchanging
keypoint embeddings, such as generating portraits by combining the eyes, nose,
and mouth from different images. In addition, the explicit generation of
keypoints and matching images enables a new, GAN-based method for unsupervised
keypoint detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Contrastive Loss and Attention for GANs. (arXiv:2103.16748v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16748">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GANs) produce impressive results on
unconditional image generation when powered with large-scale image datasets.
Yet generated images are still easy to spot especially on datasets with high
variance (e.g. bedroom, church). In this paper, we propose various improvements
to further push the boundaries in image generation. Specifically, we propose a
novel dual contrastive loss and show that, with this loss, discriminator learns
more generalized and distinguishable representations to incentivize generation.
In addition, we revisit attention and extensively experiment with different
attention blocks in the generator. We find attention to be still an important
module for successful image generation even though it was not used in the
recent state-of-the-art models. Lastly, we study different attention
architectures in the discriminator, and propose a reference attention
mechanism. By combining the strengths of these remedies, we improve the
compelling state-of-the-art Fr\'{e}chet Inception Distance (FID) by at least
17.5% on several benchmark datasets. We obtain even more significant
improvements on compositional synthetic scenes (up to 47.5% in FID).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Invariant Adversarial Learning. (arXiv:2104.00322v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00322">
<div class="article-summary-box-inner">
<span><p>The phenomenon of adversarial examples illustrates one of the most basic
vulnerabilities of deep neural networks. Among the variety of techniques
introduced to surmount this inherent weakness, adversarial training has emerged
as the most effective strategy to achieve robustness. Typically, this is
achieved by balancing robust and natural objectives. In this work, we aim to
further optimize the trade-off between robust and standard accuracy by
enforcing a domain-invariant feature representation. We present a new
adversarial training method, Domain Invariant Adversarial Learning (DIAL),
which learns a feature representation that is both robust and domain invariant.
DIAL uses a variant of Domain Adversarial Neural Network (DANN) on the natural
domain and its corresponding adversarial domain. In the case where the source
domain consists of natural examples and the target domain is the adversarially
perturbed examples, our method learns a feature representation constrained not
to discriminate between the natural and adversarial examples, and can therefore
achieve a more robust representation. Our experiments indicate that our method
improves both robustness and standard accuracy, when compared to other
state-of-the-art adversarial training methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InfinityGAN: Towards Infinite-Pixel Image Synthesis. (arXiv:2104.03963v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03963">
<div class="article-summary-box-inner">
<span><p>We present a novel framework, InfinityGAN, for arbitrary-sized image
generation. The task is associated with several key challenges. First, scaling
existing models to an arbitrarily large image size is resource-constrained, in
terms of both computation and availability of large-field-of-view training
data. InfinityGAN trains and infers in a seamless patch-by-patch manner with
low computational resources. Second, large images should be locally and
globally consistent, avoid repetitive patterns, and look realistic. To address
these, InfinityGAN disentangles global appearances, local structures, and
textures. With this formulation, we can generate images with spatial size and
level of details not attainable before. Experimental evaluation validates that
InfinityGAN generates images with superior realism compared to baselines and
features parallelizable inference. Finally, we show several applications
unlocked by our approach, such as spatial style fusion, multi-modal
outpainting, and image inbetweening. All applications can be operated with
arbitrary input and output sizes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point-Based Modeling of Human Clothing. (arXiv:2104.08230v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08230">
<div class="article-summary-box-inner">
<span><p>We propose a new approach to human clothing modeling based on point clouds.
Within this approach, we learn a deep model that can predict point clouds of
various outfits, for various human poses, and for various human body shapes.
Notably, outfits of various types and topologies can be handled by the same
model. Using the learned model, we can infer the geometry of new outfits from
as little as a single image, and perform outfit retargeting to new bodies in
new poses. We complement our geometric model with appearance modeling that uses
the point cloud geometry as a geometric scaffolding and employs neural
point-based graphics to capture outfit appearance from videos and to re-render
the captured outfits. We validate both geometric modeling and appearance
modeling aspects of the proposed approach against recently proposed methods and
establish the viability of point-based clothing modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations. (arXiv:2104.14548v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14548">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning algorithms based on instance discrimination train
encoders to be invariant to pre-defined transformations of the same instance.
While most methods treat different views of the same image as positives for a
contrastive loss, we are interested in using positives from other instances in
the dataset. Our method, Nearest-Neighbor Contrastive Learning of visual
Representations (NNCLR), samples the nearest neighbors from the dataset in the
latent space, and treats them as positives. This provides more semantic
variations than pre-defined transformations.
</p>
<p>We find that using the nearest-neighbor as positive in contrastive losses
improves performance significantly on ImageNet classification, from 71.7% to
75.6%, outperforming previous state-of-the-art methods. On semi-supervised
learning benchmarks we improve performance significantly when only 1% ImageNet
labels are available, from 53.8% to 56.5%. On transfer learning benchmarks our
method outperforms state-of-the-art methods (including supervised learning with
ImageNet) on 8 out of 12 downstream datasets. Furthermore, we demonstrate
empirically that our method is less reliant on complex data augmentations. We
see a relative reduction of only 2.1% ImageNet Top-1 accuracy when we train
using only random crops.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Animatable Neural Radiance Fields for Modeling Dynamic Human Bodies. (arXiv:2105.02872v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02872">
<div class="article-summary-box-inner">
<span><p>This paper addresses the challenge of reconstructing an animatable human
model from a multi-view video. Some recent works have proposed to decompose a
non-rigidly deforming scene into a canonical neural radiance field and a set of
deformation fields that map observation-space points to the canonical space,
thereby enabling them to learn the dynamic scene from images. However, they
represent the deformation field as translational vector field or SE(3) field,
which makes the optimization highly under-constrained. Moreover, these
representations cannot be explicitly controlled by input motions. Instead, we
introduce neural blend weight fields to produce the deformation fields. Based
on the skeleton-driven deformation, blend weight fields are used with 3D human
skeletons to generate observation-to-canonical and canonical-to-observation
correspondences. Since 3D human skeletons are more observable, they can
regularize the learning of deformation fields. Moreover, the learned blend
weight fields can be combined with input skeletal motions to generate new
deformation fields to animate the human model. Experiments show that our
approach significantly outperforms recent human synthesis methods. The code and
supplementary materials are available at
https://zju3dv.github.io/animatable_nerf/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes. (arXiv:2106.01487v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01487">
<div class="article-summary-box-inner">
<span><p>Learning binary representations of instances and classes is a classical
problem with several high potential applications. In modern settings, the
compression of high-dimensional neural representations to low-dimensional
binary codes is a challenging task and often require large bit-codes to be
accurate. In this work, we propose a novel method for Learning Low-dimensional
binary Codes (LLC) for instances as well as classes. Our method does not
require any side-information, like annotated attributes or label meta-data, and
learns extremely low-dimensional binary codes (~20 bits for ImageNet-1K). The
learnt codes are super-efficient while still ensuring nearly optimal
classification accuracy for ResNet50 on ImageNet-1K. We demonstrate that the
learnt codes capture intrinsically important features in the data, by
discovering an intuitive taxonomy over classes. We further quantitatively
measure the quality of our codes by applying it to the efficient image
retrieval as well as out-of-distribution (OOD) detection problems. For
ImageNet-100 retrieval problem, our learnt binary codes outperform 16 bit
HashNet using only 10 bits and also are as accurate as 10 dimensional real
representations. Finally, our learnt binary codes can perform OOD detection,
out-of-the-box, as accurately as a baseline that needs ~3000 samples to tune
its threshold, while we require none. Code is open-sourced at
https://github.com/RAIVNLab/LLC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature Flow Regularization: Improving Structured Sparsity in Deep Neural Networks. (arXiv:2106.02914v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02914">
<div class="article-summary-box-inner">
<span><p>Pruning is a model compression method that removes redundant parameters in
deep neural networks (DNNs) while maintaining accuracy. Most available filter
pruning methods require complex treatments such as iterative pruning, features
statistics/ranking, or additional optimization designs in the training process.
In this paper, we propose a simple and effective regularization strategy from a
new perspective of evolution of features, which we call feature flow
regularization (FFR), for improving structured sparsity and filter pruning in
DNNs. Specifically, FFR imposes controls on the gradient and curvature of
feature flow along the neural network, which implicitly increases the sparsity
of the parameters. The principle behind FFR is that coherent and smooth
evolution of features will lead to an efficient network that avoids redundant
parameters. The high structured sparsity obtained from FFR enables us to prune
filters effectively. Experiments with VGGNets, ResNets on CIFAR-10/100, and
Tiny ImageNet datasets demonstrate that FFR can significantly improve both
unstructured and structured sparsity. Our pruning results in terms of reduction
of parameters and FLOPs are comparable to or even better than those of
state-of-the-art pruning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scene Transformer: A unified architecture for predicting multiple agent trajectories. (arXiv:2106.08417v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08417">
<div class="article-summary-box-inner">
<span><p>Predicting the motion of multiple agents is necessary for planning in dynamic
environments. This task is challenging for autonomous driving since agents
(e.g. vehicles and pedestrians) and their associated behaviors may be diverse
and influence one another. Most prior work have focused on predicting
independent futures for each agent based on all past motion, and planning
against these independent predictions. However, planning against independent
predictions can make it challenging to represent the future interaction
possibilities between different agents, leading to sub-optimal planning. In
this work, we formulate a model for predicting the behavior of all agents
jointly, producing consistent futures that account for interactions between
agents. Inspired by recent language modeling approaches, we use a masking
strategy as the query to our model, enabling one to invoke a single model to
predict agent behavior in many ways, such as potentially conditioned on the
goal or full future trajectory of the autonomous vehicle or the behavior of
other agents in the environment. Our model architecture employs attention to
combine features across road elements, agent interactions, and time steps. We
evaluate our approach on autonomous driving datasets for both marginal and
joint motion prediction, and achieve state of the art performance across two
popular datasets. Through combining a scene-centric approach, agent permutation
equivariant model, and a sequence masking strategy, we show that our model can
unify a variety of motion prediction tasks from joint motion predictions to
conditioned prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding the Security of Deepfake Detection. (arXiv:2107.02045v3 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02045">
<div class="article-summary-box-inner">
<span><p>Deepfakes pose growing challenges to the trust of information on the
Internet. Thus, detecting deepfakes has attracted increasing attentions from
both academia and industry. State-of-the-art deepfake detection methods consist
of two key components, i.e., face extractor and face classifier, which extract
the face region in an image and classify it to be real/fake, respectively.
Existing studies mainly focused on improving the detection performance in
non-adversarial settings, leaving security of deepfake detection in adversarial
settings largely unexplored. In this work, we aim to bridge the gap. In
particular, we perform a systematic measurement study to understand the
security of the state-of-the-art deepfake detection methods in adversarial
settings. We use two large-scale public deepfakes data sources including
FaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes
are fake face images; and we train state-of-the-art deepfake detection methods.
These detection methods can achieve 0.94--0.99 accuracies in non-adversarial
settings on these datasets. However, our measurement results uncover multiple
security limitations of the deepfake detection methods in adversarial settings.
First, we find that an attacker can evade a face extractor, i.e., the face
extractor fails to extract the correct face regions, via adding small Gaussian
noise to its deepfake images. Second, we find that a face classifier trained
using deepfakes generated by one method cannot detect deepfakes generated by
another method, i.e., an attacker can evade detection via generating deepfakes
using a new method. Third, we find that an attacker can leverage backdoor
attacks developed by the adversarial machine learning community to evade a face
classifier. Our results highlight that deepfake detection should consider the
adversarial nature of the problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Align before Fuse: Vision and Language Representation Learning with Momentum Distillation. (arXiv:2107.07651v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07651">
<div class="article-summary-box-inner">
<span><p>Large-scale vision and language representation learning has shown promising
improvements on various vision-language tasks. Most existing methods employ a
transformer-based multimodal encoder to jointly model visual tokens
(region-based image features) and word tokens. Because the visual tokens and
word tokens are unaligned, it is challenging for the multimodal encoder to
learn image-text interactions. In this paper, we introduce a contrastive loss
to ALign the image and text representations BEfore Fusing (ALBEF) them through
cross-modal attention, which enables more grounded vision and language
representation learning. Unlike most existing methods, our method does not
require bounding box annotations nor high-resolution images. In order to
improve learning from noisy web data, we propose momentum distillation, a
self-training method which learns from pseudo-targets produced by a momentum
model. We provide a theoretical analysis of ALBEF from a mutual information
maximization perspective, showing that different training tasks can be
interpreted as different ways to generate views for an image-text pair. ALBEF
achieves state-of-the-art performance on multiple downstream vision-language
tasks. On image-text retrieval, ALBEF outperforms methods that are pre-trained
on orders of magnitude larger datasets. On VQA and NLVR$^2$, ALBEF achieves
absolute improvements of 2.37% and 3.84% compared to the state-of-the-art,
while enjoying faster inference speed. Code and pre-trained models are
available at https://github.com/salesforce/ALBEF/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds. (arXiv:2108.06455v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06455">
<div class="article-summary-box-inner">
<span><p>3D single object tracking is a key issue for robotics. In this paper, we
propose a transformer module called Point-Track-Transformer (PTT) for point
cloud-based 3D single object tracking. PTT module contains three blocks for
feature embedding, position encoding, and self-attention feature computation.
Feature embedding aims to place features closer in the embedding space if they
have similar semantic information. Position encoding is used to encode
coordinates of point clouds into high dimension distinguishable features.
Self-attention generates refined attention features by computing attention
weights. Besides, we embed the PTT module into the open-source state-of-the-art
method P2B to construct PTT-Net. Experiments on the KITTI dataset reveal that
our PTT-Net surpasses the state-of-the-art by a noticeable margin (~10%).
Additionally, PTT-Net could achieve real-time performance (~40FPS) on NVIDIA
1080Ti GPU. Our code is open-sourced for the robotics community at
https://github.com/shanjiayao/PTT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Adversarially-Enhanced k-Nearest Neighbors. (arXiv:2108.06797v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06797">
<div class="article-summary-box-inner">
<span><p>Recent works have theoretically and empirically shown that deep neural
networks (DNNs) have an inherent vulnerability to small perturbations. Applying
the Deep k-Nearest Neighbors (DkNN) classifier, we observe a dramatically
increasing robustness-accuracy trade-off as the layer goes deeper. In this
work, we propose a Deep Adversarially-Enhanced k-Nearest Neighbors (DAEkNN)
method which achieves higher robustness than DkNN and mitigates the
robustness-accuracy trade-off in deep layers through two key elements. First,
DAEkNN is based on an adversarially trained model. Second, DAEkNN makes
predictions by leveraging a weighted combination of benign and adversarial
training data. Empirically, we find that DAEkNN improves both the robustness
and the robustness-accuracy trade-off on MNIST and CIFAR-10 datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Scaling Law for Synthetic-to-Real Transfer: How Much Is Your Pre-training Effective?. (arXiv:2108.11018v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11018">
<div class="article-summary-box-inner">
<span><p>Synthetic-to-real transfer learning is a framework in which a synthetically
generated dataset is used to pre-train a model to improve its performance on
real vision tasks. The most significant advantage of using synthetic images is
that the ground-truth labels are automatically available, enabling unlimited
expansion of the data size without human cost. However, synthetic data may have
a huge domain gap, in which case increasing the data size does not improve the
performance. How can we know that? In this study, we derive a simple scaling
law that predicts the performance from the amount of pre-training data. By
estimating the parameters of the law, we can judge whether we should increase
the data or change the setting of image synthesis. Further, we analyze the
theory of transfer learning by considering learning dynamics and confirm that
the derived generalization bound is consistent with our empirical findings. We
empirically validated our scaling law on various experimental settings of
benchmark tasks, model sizes, and complexities of synthetic images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eyes Tell All: Irregular Pupil Shapes Reveal GAN-generated Faces. (arXiv:2109.00162v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00162">
<div class="article-summary-box-inner">
<span><p>Generative adversary network (GAN) generated high-realistic human faces have
been used as profile images for fake social media accounts and are visually
challenging to discern from real ones. In this work, we show that GAN-generated
faces can be exposed via irregular pupil shapes. This phenomenon is caused by
the lack of physiological constraints in the GAN models. We demonstrate that
such artifacts exist widely in high-quality GAN-generated faces and further
describe an automatic method to extract the pupils from two eyes and analysis
their shapes for exposing the GAN-generated faces. Qualitative and quantitative
evaluations of our method suggest its simplicity and effectiveness in
distinguishing GAN-generated faces.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Brand Label Albedo Extraction of eCommerce Products using Generative Adversarial Network. (arXiv:2109.02929v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02929">
<div class="article-summary-box-inner">
<span><p>In this paper we present our solution to extract albedo of branded labels for
e-commerce products. To this end, we generate a large-scale photo-realistic
synthetic data set for albedo extraction followed by training a generative
model to translate images with diverse lighting conditions to albedo. We
performed an extensive evaluation to test the generalisation of our method to
in-the-wild images. From the experimental results, we observe that our solution
generalises well compared to the existing method both in the unseen rendered
images as well as in the wild image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Compositional Feature Embedding and Similarity Metric for Ultra-Fine-Grained Visual Categorization. (arXiv:2109.12380v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12380">
<div class="article-summary-box-inner">
<span><p>Fine-grained visual categorization (FGVC), which aims at classifying objects
with small inter-class variances, has been significantly advanced in recent
years. However, ultra-fine-grained visual categorization (ultra-FGVC), which
targets at identifying subclasses with extremely similar patterns, has not
received much attention. In ultra-FGVC datasets, the samples per category are
always scarce as the granularity moves down, which will lead to overfitting
problems. Moreover, the difference among different categories is too subtle to
distinguish even for professional experts. Motivated by these issues, this
paper proposes a novel compositional feature embedding and similarity metric
(CECS). Specifically, in the compositional feature embedding module, we
randomly select patches in the original input image, and these patches are then
replaced by patches from the images of different categories or masked out. Then
the replaced and masked images are used to augment the original input images,
which can provide more diverse samples and thus largely alleviate overfitting
problem resulted from limited training samples. Besides, learning with diverse
samples forces the model to learn not only the most discriminative features but
also other informative features in remaining regions, enhancing the
generalization and robustness of the model. In the compositional similarity
metric module, a new similarity metric is developed to improve the
classification performance by narrowing the intra-category distance and
enlarging the inter-category distance. Experimental results on two ultra-FGVC
datasets and one FGVC dataset with recent benchmark methods consistently
demonstrate that the proposed CECS method achieves the state of-the-art
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Student Helping Teacher: Teacher Evolution via Self-Knowledge Distillation. (arXiv:2110.00329v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00329">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation usually transfers the knowledge from a pre-trained
cumbersome teacher network to a compact student network, which follows the
classical teacher-teaching-student paradigm. Based on this paradigm, previous
methods mostly focus on how to efficiently train a better student network for
deployment. Different from the existing practices, in this paper, we propose a
novel student-helping-teacher formula, Teacher Evolution via Self-Knowledge
Distillation (TESKD), where the target teacher (for deployment) is learned with
the help of multiple hierarchical students by sharing the structural backbone.
The diverse feedback from multiple students allows the teacher to improve
itself through the shared feature representations. The effectiveness of our
proposed framework is demonstrated by extensive experiments with various
network settings on two standard benchmarks including CIFAR-100 and ImageNet.
Notably, when trained together with our proposed method, ResNet-18 achieves
79.15% and 71.14% accuracy on CIFAR-100 and ImageNet, outperforming the
baseline results by 4.74% and 1.43%, respectively. The code is available at:
https://github.com/zhengli427/TESKD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Unfolding Total Variation Network for Low-Light Image Enhancement. (arXiv:2110.00984v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00984">
<div class="article-summary-box-inner">
<span><p>Real-world low-light images suffer from two main degradations, namely,
inevitable noise and poor visibility. Since the noise exhibits different
levels, its estimation has been implemented in recent works when enhancing
low-light images from raw Bayer space. When it comes to sRGB color space, the
noise estimation becomes more complicated due to the effect of the image
processing pipeline. Nevertheless, most existing enhancing algorithms in sRGB
space only focus on the low visibility problem or suppress the noise under a
hypothetical noise level, leading them impractical due to the lack of
robustness. To address this issue,we propose an adaptive unfolding total
variation network (UTVNet), which approximates the noise level from the real
sRGB low-light image by learning the balancing parameter in the model-based
denoising method with total variation regularization. Meanwhile, we learn the
noise level map by unrolling the corresponding minimization process for
providing the inferences of smoothness and fidelity constraints. Guided by the
noise level map, our UTVNet can recover finer details and is more capable to
suppress noise in real captured low-light scenes. Extensive experiments on
real-world low-light images clearly demonstrate the superior performance of
UTVNet over state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Online Visual Invariances for Novel Objects via Supervised and Self-Supervised Training. (arXiv:2110.01476v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01476">
<div class="article-summary-box-inner">
<span><p>Humans can identify objects following various spatial transformations such as
scale and viewpoint. This extends to novel objects, after a single presentation
at a single pose, sometimes referred to as online invariance. CNNs have been
proposed as a compelling model of human vision, but their ability to identify
objects across transformations is typically tested on held-out samples of
trained categories after extensive data augmentation. This paper assesses
whether standard CNNs can support human-like online invariance by training
models to recognize images of synthetic 3D objects that undergo several
transformations: rotation, scaling, translation, brightness, contrast, and
viewpoint. Through the analysis of models' internal representations, we show
that standard supervised CNNs trained on transformed objects can acquire strong
invariances on novel classes even when trained with as few as 50 objects taken
from 10 classes. This extended to a different dataset of photographs of real
objects. We also show that these invariances can be acquired in a
self-supervised way, through solving the same/different task. We suggest that
this latter approach may be similar to how humans acquire invariances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantified Facial Expressiveness for Affective Behavior Analytics. (arXiv:2110.01758v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01758">
<div class="article-summary-box-inner">
<span><p>The quantified measurement of facial expressiveness is crucial to analyze
human affective behavior at scale. Unfortunately, methods for expressiveness
quantification at the video frame-level are largely unexplored, unlike the
study of discrete expression. In this work, we propose an algorithm that
quantifies facial expressiveness using a bounded, continuous expressiveness
score using multimodal facial features, such as action units (AUs), landmarks,
head pose, and gaze. The proposed algorithm more heavily weights AUs with high
intensities and large temporal changes. The proposed algorithm can compute the
expressiveness in terms of discrete expression, and can be used to perform
tasks including facial behavior tracking and subjectivity quantification in
context. Our results on benchmark datasets show the proposed algorithm is
effective in terms of capturing temporal changes and expressiveness, measuring
subjective differences in context, and extracting useful insight.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">2nd Place Solution to Google Landmark Recognition Competition 2021. (arXiv:2110.02638v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02638">
<div class="article-summary-box-inner">
<span><p>As Transformer-based architectures have recently shown encouraging progresses
in computer vision. In this work, we present the solution to the Google
Landmark Recognition 2021 Challenge held on Kaggle, which is an improvement on
our last year's solution by changing three designs, including (1) Using Swin
and CSWin as backbone for feature extraction, (2) Train on full GLDv2, and (3)
Using full GLDv2 images as index image set for kNN search.
</p>
<p>With these modifications, our solution significantly improves last year
solution on this year competition. Our full pipeline, after ensembling Swin,
CSWin, EfficientNet B7 models, scores 0.4907 on the private leaderboard which
help us to get the 2nd place in the competition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3rd Place Solution to Google Landmark Recognition Competition 2021. (arXiv:2110.02794v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02794">
<div class="article-summary-box-inner">
<span><p>In this paper, we show our solution to the Google Landmark Recognition 2021
Competition. Firstly, embeddings of images are extracted via various
architectures (i.e. CNN-, Transformer- and hybrid-based), which are optimized
by ArcFace loss. Then we apply an efficient pipeline to re-rank predictions by
adjusting the retrieval score with classification logits and non-landmark
distractors. Finally, the ensembled model scores 0.489 on the private
leaderboard, achieving the 3rd place in the 2021 edition of the Google Landmark
Recognition Competition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Cropped versus Uncropped Training Sets in Tabular Structure Detection. (arXiv:2110.02933v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02933">
<div class="article-summary-box-inner">
<span><p>Automated document processing for tabular information extraction is highly
desired in many organizations, from industry to government. Prior works have
addressed this problem under table detection and table structure detection
tasks. Proposed solutions leveraging deep learning approaches have been giving
promising results in these tasks. However, the impact of dataset structures on
table structure detection has not been investigated. In this study, we provide
a comparison of table structure detection performance with cropped and
uncropped datasets. The cropped set consists of only table images that are
cropped from documents assuming tables are detected perfectly. The uncropped
set consists of regular document images. Experiments show that deep learning
models can improve the detection performance by up to 9% in average precision
and average recall on the cropped versions. Furthermore, the impact of cropped
images is negligible under the Intersection over Union (IoU) values of 50%-70%
when compared to the uncropped versions. However, beyond 70% IoU thresholds,
cropped datasets provide significantly higher detection performance.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-09 23:02:24.084071165 UTC">2021-10-09 23:02:24 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>