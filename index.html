<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-03-17T01:30:00Z">03-17</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepTrust: A Reliable Financial Knowledge Retrieval Framework For Explaining Extreme Pricing Anomalies. (arXiv:2203.08144v1 [q-fin.ST])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08144">
<div class="article-summary-box-inner">
<span><p>Extreme pricing anomalies may occur unexpectedly without a trivial cause, and
equity traders typically experience a meticulous process to source disparate
information and analyze its reliability before integrating it into the trusted
knowledge base. We introduce DeepTrust, a reliable financial knowledge
retrieval framework on Twitter to explain extreme price moves at speed, while
ensuring data veracity using state-of-the-art NLP techniques. Our proposed
framework consists of three modules, specialized for anomaly detection,
information retrieval and reliability assessment. The workflow starts with
identifying anomalous asset price changes using machine learning models trained
with historical pricing data, and retrieving correlated unstructured data from
Twitter using enhanced queries with dynamic search conditions. DeepTrust
extrapolates information reliability from tweet features, traces of generative
language model, argumentation structure, subjectivity and sentiment signals,
and refine a concise collection of credible tweets for market insights. The
framework is evaluated on two self-annotated financial anomalies, i.e., Twitter
and Facebook stock price on 29 and 30 April 2021. The optimal setup outperforms
the baseline classifier by 7.75% and 15.77% on F0.5-scores, and 10.55% and
18.88% on precision, respectively, proving its capability in screening
unreliable information precisely. At the same time, information retrieval and
reliability assessment modules are analyzed individually on their effectiveness
and causes of limitations, with identified subjective and objective factors
that influence the performance. As a collaborative project with Refinitiv, this
framework paves a promising path towards building a scalable commercial
solution that assists traders to reach investment decisions on pricing
anomalies with authenticated knowledge from social media platforms in
real-time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Contamination: From Memorization to Exploitation. (arXiv:2203.08242v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08242">
<div class="article-summary-box-inner">
<span><p>Pretrained language models are typically trained on massive web-based
datasets, which are often "contaminated" with downstream test sets. It is not
clear to what extent models exploit the contaminated data for downstream tasks.
We present a principled method to study this question. We pretrain BERT models
on joint corpora of Wikipedia and labeled downstream datasets, and fine-tune
them on the relevant task. Comparing performance between samples seen and
unseen during pretraining enables us to define and quantify levels of
memorization and exploitation. Experiments with two models and three downstream
tasks show that exploitation exists in some cases, but in others the models
memorize the contaminated data, but do not exploit it. We show that these two
measures are affected by different factors such as the number of duplications
of the contaminated data and the model size. Our results highlight the
importance of analyzing massive web-scale datasets to verify that progress in
NLP is obtained by better language understanding and not better data
exploitation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Improving Attentive Neural Networks in Legal Text Processing. (arXiv:2203.08244v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08244">
<div class="article-summary-box-inner">
<span><p>In recent years, thanks to breakthroughs in neural network techniques
especially attentive deep learning models, natural language processing has made
many impressive achievements. However, automated legal word processing is still
a difficult branch of natural language processing. Legal sentences are often
long and contain complicated legal terminologies. Hence, models that work well
on general documents still face challenges in dealing with legal documents. We
have verified the existence of this problem with our experiments in this work.
In this dissertation, we selectively present the main achievements in improving
attentive neural networks in automatic legal document processing. Language
models tend to grow larger and larger, though, without expert knowledge, these
models can still fail in domain adaptation, especially for specialized fields
like law.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Multi-Agent Actor-Critic for Multi-Step Radiology Report Summarization. (arXiv:2203.08257v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08257">
<div class="article-summary-box-inner">
<span><p>The IMPRESSIONS section of a radiology report about an imaging study is a
summary of the radiologist's reasoning and conclusions, and it also aids the
referring physician in confirming or excluding certain diagnoses. A cascade of
tasks are required to automatically generate an abstractive summary of the
typical information-rich radiology report. These tasks include acquisition of
salient content from the report and generation of a concise, easily consumable
IMPRESSIONS section. Prior research on radiology report summarization has
focused on single-step end-to-end models -- which subsume the task of salient
content acquisition. To fully explore the cascade structure and explainability
of radiology report summarization, we introduce two innovations. First, we
design a two-step approach: extractive summarization followed by abstractive
summarization. Second, we additionally break down the extractive part into two
independent tasks: extraction of salient (1) sentences and (2) keywords.
Experiments on a publicly available radiology report dataset show our novel
approach leads to a more precise summary compared to single-step and to
two-step-with-single-extractive-process baselines with an overall improvement
in F1 score Of 3-4%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Better Quality Estimation for Low Resource Corpus Mining. (arXiv:2203.08259v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08259">
<div class="article-summary-box-inner">
<span><p>Quality Estimation (QE) models have the potential to change how we evaluate
and maybe even train machine translation models. However, these models still
lack the robustness to achieve general adoption. We show that State-of-the-art
QE models, when tested in a Parallel Corpus Mining (PCM) setting, perform
unexpectedly bad due to a lack of robustness to out-of-domain examples. We
propose a combination of multitask training, data augmentation and contrastive
learning to achieve better and more robust QE performance. We show that our
method improves QE performance significantly in the MLQE challenge and the
robustness of QE models when tested in the Parallel Corpus Mining setup. We
increase the accuracy in PCM by more than 0.80, making it on par with
state-of-the-art PCM methods that use millions of sentence pairs to train their
models. In comparison, we use a thousand times less data, 7K parallel sentences
in total, and propose a novel low resource PCM method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-neural Models Matter: A Re-evaluation of Neural Referring Expression Generation Systems. (arXiv:2203.08274v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08274">
<div class="article-summary-box-inner">
<span><p>In recent years, neural models have often outperformed rule-based and classic
Machine Learning approaches in NLG. These classic approaches are now often
disregarded, for example when new neural models are evaluated. We argue that
they should not be overlooked, since, for some tasks, well-designed non-neural
approaches achieve better performance than neural ones. In this paper, the task
of generating referring expressions in linguistic context is used as an
example. We examined two very different English datasets (WEBNLG and WSJ), and
evaluated each algorithm using both automatic and human evaluations. Overall,
the results of these evaluations suggest that rule-based systems with simple
rule sets achieve on-par or better performance on both datasets compared to
state-of-the-art neural REG systems. In the case of the more realistic dataset,
WSJ, a machine learning-based system with well-designed linguistic features
performed best. We hope that our work can encourage researchers to consider
non-neural models in future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FastKASSIM: A Fast Tree Kernel-Based Syntactic Similarity Metric. (arXiv:2203.08299v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08299">
<div class="article-summary-box-inner">
<span><p>Syntax is a fundamental component of language, yet few metrics have been
employed to capture syntactic similarity or coherence at the utterance- and
document-level. The existing standard document-level syntactic similarity
metric is computationally expensive and performs inconsistently when faced with
syntactically dissimilar documents. To address these challenges, we present
FastKASSIM, a metric for utterance- and document-level syntactic similarity
which pairs and averages the most similar dependency parse trees between a pair
of documents based on tree kernels. FastKASSIM is more robust to syntactic
dissimilarities and differences in length, and runs up to to 5.2 times faster
than our baseline method over the documents in the r/ChangeMyView corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyperdecoders: Instance-specific decoders for multi-task NLP. (arXiv:2203.08304v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08304">
<div class="article-summary-box-inner">
<span><p>We investigate input-conditioned hypernetworks for multi-tasking in NLP,
generating parameter-efficient adaptations for a decoder using a hypernetwork
conditioned on the output of an encoder. This approach produces a unique
decoder for every input instance, allowing the network a larger degree of
flexibility than prior work that specializes the decoder for each task. We
apply our method to sequence classification tasks, extractive QA, and
summarisation and find that it often outperforms fully finetuning the
underlying model and surpasses previous parameter efficient fine-tuning
methods. Gains are particularly large when evaluated out-of-domain on the MRQA
benchmark. In addition, as the pretrained model is frozen, our method
eliminates negative interference among unrelated tasks, a common failure mode
in fully fine-tuned approaches. An analysis of the embeddings produced by our
model suggests that a large benefit of our approach is allowing the encoder
more effective control over the decoder, allowing mapping from hidden
representations to a final text-based label without interference from other
tasks' output formats or labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Word Translation via Two-Stage Contrastive Learning. (arXiv:2203.08307v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08307">
<div class="article-summary-box-inner">
<span><p>Word translation or bilingual lexicon induction (BLI) is a key cross-lingual
task, aiming to bridge the lexical gap between different languages. In this
work, we propose a robust and effective two-stage contrastive learning
framework for the BLI task. At Stage C1, we propose to refine standard
cross-lingual linear maps between static word embeddings (WEs) via a
contrastive learning objective; we also show how to integrate it into the
self-learning procedure for even more refined cross-lingual maps. In Stage C2,
we conduct BLI-oriented contrastive fine-tuning of mBERT, unlocking its word
translation capability. We also show that static WEs induced from the
`C2-tuned' mBERT complement static WEs from Stage C1. Comprehensive experiments
on standard BLI datasets for diverse languages and different experimental
setups demonstrate substantial gains achieved by our framework. While the BLI
method from Stage C1 already yields substantial gains over all state-of-the-art
BLI methods in our comparison, even stronger improvements are met with the full
two-stage framework: e.g., we report gains for 112/112 BLI setups, spanning 28
language pairs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Generative Language Models for Zero-Shot Cross-Lingual Event Argument Extraction. (arXiv:2203.08308v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08308">
<div class="article-summary-box-inner">
<span><p>We present a study on leveraging multilingual pre-trained generative language
models for zero-shot cross-lingual event argument extraction (EAE). By
formulating EAE as a language generation task, our method effectively encodes
event structures and captures the dependencies between arguments. We design
language-agnostic templates to represent the event argument structures, which
are compatible with any language, hence facilitating the cross-lingual
transfer. Our proposed model finetunes multilingual pre-trained generative
language models to generate sentences that fill in the language-agnostic
template with arguments extracted from the input passage. The model is trained
on source languages and is then directly applied to target languages for event
argument extraction. Experiments demonstrate that the proposed model
outperforms the current state-of-the-art models on zero-shot cross-lingual EAE.
Comprehensive studies and error analyses are presented to better understand the
advantages and the current limitations of using generative language models for
zero-shot cross-lingual transfer EAE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Afrocentric NLP for African Languages: Where We Are and Where We Can Go. (arXiv:2203.08351v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08351">
<div class="article-summary-box-inner">
<span><p>Aligning with ACL 2022 special Theme on "Language Diversity: from Low
Resource to Endangered Languages", we discuss the major linguistic and
sociopolitical challenges facing development of NLP technologies for African
languages. Situating African languages in a typological framework, we discuss
how the particulars of these languages can be harnessed. To facilitate future
research, we also highlight current efforts, communities, venues, datasets, and
tools. Our main objective is to motivate and advocate for an Afrocentric
approach to technology development. With this in mind, we recommend
\textit{what} technologies to build and \textit{how} to build, evaluate, and
deploy them based on the needs of local African communities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spot the Difference: A Cooperative Object-Referring Game in Non-Perfectly Co-Observable Scene. (arXiv:2203.08362v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08362">
<div class="article-summary-box-inner">
<span><p>Visual dialog has witnessed great progress after introducing various
vision-oriented goals into the conversation, especially such as GuessWhich and
GuessWhat, where the only image is visible by either and both of the questioner
and the answerer, respectively. Researchers explore more on visual dialog tasks
in such kind of single- or perfectly co-observable visual scene, while somewhat
neglect the exploration on tasks of non perfectly co-observable visual scene,
where the images accessed by two agents may not be exactly the same, often
occurred in practice. Although building common ground in non-perfectly
co-observable visual scene through conversation is significant for advanced
dialog agents, the lack of such dialog task and corresponding large-scale
dataset makes it impossible to carry out in-depth research. To break this
limitation, we propose an object-referring game in non-perfectly co-observable
visual scene, where the goal is to spot the difference between the similar
visual scenes through conversing in natural language. The task addresses
challenges of the dialog strategy in non-perfectly co-observable visual scene
and the ability of categorizing objects. Correspondingly, we construct a
large-scale multimodal dataset, named SpotDiff, which contains 87k Virtual
Reality images and 97k dialogs generated by self-play. Finally, we give
benchmark models for this task, and conduct extensive experiments to evaluate
its performance as well as analyze its main challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-View Document Representation Learning for Open-Domain Dense Retrieval. (arXiv:2203.08372v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08372">
<div class="article-summary-box-inner">
<span><p>Dense retrieval has achieved impressive advances in first-stage retrieval
from a large-scale document collection, which is built on bi-encoder
architecture to produce single vector representation of query and document.
However, a document can usually answer multiple potential queries from
different views. So the single vector representation of a document is hard to
match with multi-view queries, and faces a semantic mismatch problem. This
paper proposes a multi-view document representation learning framework, aiming
to produce multi-view embeddings to represent documents and enforce them to
align with different queries. First, we propose a simple yet effective method
of generating multiple embeddings through viewers. Second, to prevent
multi-view embeddings from collapsing to the same one, we further propose a
global-local loss with annealed temperature to encourage the multiple viewers
to better align with different potential queries. Experiments show our method
outperforms recent works and achieves state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transforming Sequence Tagging Into A Seq2Seq Task. (arXiv:2203.08378v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08378">
<div class="article-summary-box-inner">
<span><p>Pretrained, large, generative language models (LMs) have had great success in
a wide range of sequence tagging and structured prediction tasks. Casting a
sequence tagging task as a Seq2Seq one requires deciding the formats of the
input and output sequences. However, we lack a principled understanding of the
trade-offs associated with these formats (such as the effect on model accuracy,
sequence length, multilingual generalization, hallucination). In this paper, we
rigorously study different formats one could use for casting input text
sentences and their output labels into the input and target (i.e., output) of a
Seq2Seq model. Along the way, we introduce a new format, which we show to not
only be simpler but also more effective. Additionally the new format
demonstrates significant gains in the multilingual settings -- both zero-shot
transfer learning and joint training. Lastly, we find that the new format is
more robust and almost completely devoid of hallucination -- an issue we find
common in existing formats. With well over a 1000 experiments studying 14
different formats, over 7 diverse public benchmarks -- including 3 multilingual
datasets spanning 7 languages -- we believe our findings provide a strong
empirical basis in understanding how we should tackle sequence tagging tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shepherd Pre-trained Language Models to Develop a Train of Thought: An Iterative Prompting Approach. (arXiv:2203.08383v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08383">
<div class="article-summary-box-inner">
<span><p>While Pre-trained Language Models (PLMs) internalize a great amount of world
knowledge, they have been shown incapable of recalling these knowledge to solve
tasks requiring complex &amp; multi-step inference procedures. Similar to how
humans develop a "train of thought" for these tasks, how can we equip PLMs with
such abilities? In this work, we explore an iterative prompting framework, a
new prompting paradigm which progressively elicits relevant knowledge from PLMs
for multi-step inference tasks. We identify key limitations of existing
prompting methods, namely they are either restricted to queries with a single
identifiable relation/predicate, or being agnostic to input contexts, which
makes it difficult to capture variabilities across different inference steps.
We propose an iterative context-aware prompter, which addresses these
limitations by learning to dynamically synthesize prompts conditioned on the
current step's contexts. Experiments on three datasets involving multi-step
inference show the effectiveness of the iterative scheme and our proposed
prompter design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages. (arXiv:2203.08388v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08388">
<div class="article-summary-box-inner">
<span><p>While there has been a recent burgeoning of applications at the intersection
of natural and programming languages, such as code generation and code
summarization, these applications are usually English-centric. This creates a
barrier for program developers who are not proficient in English. To mitigate
this gap in technology development across languages, we propose a multilingual
dataset, MCoNaLa, to benchmark code generation from natural language commands
extending beyond English. Modeled off of the methodology from the English
Code/Natural Language Challenge (CoNaLa) dataset, we annotated a total of 896
NL-code pairs in three languages: Spanish, Japanese, and Russian. We present a
quantitative evaluation of performance on the MCoNaLa dataset by testing with
state-of-the-art code generation systems. While the difficulties vary across
these three languages, all systems lag significantly behind their English
counterparts, revealing the challenges in adapting code generation to new
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging the Data Gap between Training and Inference for Unsupervised Neural Machine Translation. (arXiv:2203.08394v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08394">
<div class="article-summary-box-inner">
<span><p>Back-translation is a critical component of Unsupervised Neural Machine
Translation (UNMT), which generates pseudo parallel data from target
monolingual data. A UNMT model is trained on the pseudo parallel data with
translated source, and translates natural source sentences in inference. The
source discrepancy between training and inference hinders the translation
performance of UNMT models. By carefully designing experiments, we identify two
representative characteristics of the data gap in source: (1) style gap (i.e.,
translated vs. natural text style) that leads to poor generalization
capability; (2) content gap that induces the model to produce hallucination
content biased towards the target language. To narrow the data gap, we propose
an online self-training approach, which simultaneously uses the pseudo parallel
data {natural source, translated target} to mimic the inference scenario.
Experimental results on several widely-used language pairs show that our
approach outperforms two strong baselines (XLM and MASS) by remedying the style
and content gaps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again. (arXiv:2203.08410v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08410">
<div class="article-summary-box-inner">
<span><p>The strong few-shot in-context learning capability of large pre-trained
language models (PLMs) such as GPT-3 is highly appealing for biomedical
applications where data annotation is particularly costly. In this paper, we
present the first systematic and comprehensive study to compare the few-shot
performance of GPT-3 in-context learning with fine-tuning smaller (i.e.,
BERT-sized) PLMs on two highly representative biomedical information extraction
tasks, named entity recognition and relation extraction. We follow the true
few-shot setting to avoid overestimating models' few-shot performance by model
selection over a large validation set. We also optimize GPT-3's performance
with known techniques such as contextual calibration and dynamic in-context
example retrieval. However, our results show that GPT-3 still significantly
underperforms compared with simply fine-tuning a smaller PLM using the same
small training set. Moreover, what is equally important for practical
applications is that adding more labeled data would reliably yield an
improvement in model performance. While that is the case when fine-tuning small
PLMs, GPT-3's performance barely improves when adding more data. In-depth
analyses further reveal issues of the in-context learning setting that may be
detrimental to information extraction tasks in general. Given the high cost of
experimenting with GPT-3, we hope our study provides guidance for biomedical
researchers and practitioners towards more promising directions such as
fine-tuning GPT-3 or small PLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FormNet: Structural Encoding beyond Sequential Modeling in Form Document Information Extraction. (arXiv:2203.08411v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08411">
<div class="article-summary-box-inner">
<span><p>Sequence modeling has demonstrated state-of-the-art performance on natural
language and document understanding tasks. However, it is challenging to
correctly serialize tokens in form-like documents in practice due to their
variety of layout patterns. We propose FormNet, a structure-aware sequence
model to mitigate the suboptimal serialization of forms. First, we design Rich
Attention that leverages the spatial relationship between tokens in a form for
more precise attention score calculation. Second, we construct Super-Tokens for
each word by embedding representations from their neighboring tokens through
graph convolutions. FormNet therefore explicitly recovers local syntactic
information that may have been lost during serialization. In experiments,
FormNet outperforms existing methods with a more compact model size and less
pre-training data, establishing new state-of-the-art performance on CORD, FUNSD
and Payment benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Lingual Ability of Multilingual Masked Language Models: A Study of Language Structure. (arXiv:2203.08430v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08430">
<div class="article-summary-box-inner">
<span><p>Multilingual pre-trained language models, such as mBERT and XLM-R, have shown
impressive cross-lingual ability. Surprisingly, both of them use multilingual
masked language model (MLM) without any cross-lingual supervision or aligned
data. Despite the encouraging results, we still lack a clear understanding of
why cross-lingual ability could emerge from multilingual MLM. In our work, we
argue that cross-language ability comes from the commonality between languages.
Specifically, we study three language properties: constituent order,
composition and word co-occurrence. First, we create an artificial language by
modifying property in source language. Then we study the contribution of
modified property through the change of cross-language transfer results on
target language. We conduct experiments on six languages and two cross-lingual
NLP tasks (textual entailment, sentence retrieval). Our main conclusion is that
the contribution of constituent order and word co-occurrence is limited, while
the composition is more crucial to the success of cross-linguistic transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't Say What You Don't Know: Improving the Consistency of Abstractive Summarization by Constraining Beam Search. (arXiv:2203.08436v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08436">
<div class="article-summary-box-inner">
<span><p>Abstractive summarization systems today produce fluent and relevant output,
but often "hallucinate" statements not supported by the source text. We analyze
the connection between hallucinations and training data, and find evidence that
models hallucinate because they train on target summaries that are unsupported
by the source. Based on our findings, we present PINOCCHIO, a new decoding
method that improves the consistency of a transformer-based abstractive
summarizer by constraining beam search to avoid hallucinations. Given the model
states and outputs at a given step, PINOCCHIO detects likely model
hallucinations based on various measures of attribution to the source text.
PINOCCHIO backtracks to find more consistent output, and can opt to produce no
summary at all when no consistent generation can be found. In experiments, we
find that PINOCCHIO improves the consistency of generation (in terms of F1) by
an average of~67% on two abstractive summarization datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding and Improving Sequence-to-Sequence Pretraining for Neural Machine Translation. (arXiv:2203.08442v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08442">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a substantial step in better understanding the SOTA
sequence-to-sequence (Seq2Seq) pretraining for neural machine
translation~(NMT). We focus on studying the impact of the jointly pretrained
decoder, which is the main difference between Seq2Seq pretraining and previous
encoder-based pretraining approaches for NMT. By carefully designing
experiments on three language pairs, we find that Seq2Seq pretraining is a
double-edged sword: On one hand, it helps NMT models to produce more diverse
translations and reduce adequacy-related translation errors. On the other hand,
the discrepancies between Seq2Seq pretraining and NMT finetuning limit the
translation quality (i.e., domain discrepancy) and induce the over-estimation
issue (i.e., objective discrepancy). Based on these observations, we further
propose simple and effective strategies, named in-domain pretraining and input
adaptation to remedy the domain and objective discrepancies, respectively.
Experimental results on several language pairs show that our approach can
consistently improve both translation performance and model robustness upon
Seq2Seq pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structurally Diverse Sampling Reduces Spurious Correlations in Semantic Parsing Datasets. (arXiv:2203.08445v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08445">
<div class="article-summary-box-inner">
<span><p>A rapidly growing body of research has demonstrated the inability of NLP
models to generalize compositionally and has tried to alleviate it through
specialized architectures, training schemes, and data augmentation, among other
approaches. In this work, we study a different relatively under-explored
approach: sampling diverse train sets that encourage compositional
generalization. We propose a novel algorithm for sampling a structurally
diverse set of instances from a labeled instance pool with structured outputs.
Evaluating on 5 semantic parsing datasets of varying complexity, we show that
our algorithm performs competitively with or better than prior algorithms in
not only compositional template splits but also traditional IID splits of all
but the least structurally diverse datasets. In general, we find that diverse
train sets lead to better generalization than random training sets of the same
size in 9 out of 10 dataset-split pairs, with over 10% absolute improvement in
5, providing further evidence to their sample efficiency. Moreover, we show
that structural diversity also makes for more comprehensive test sets that
require diverse training to succeed on. Finally, we use information theory to
show that reduction in spurious correlations between substructures may be one
reason why diverse training sets improve generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Pre-trained Language Models Interpret Similes as Smart as Human?. (arXiv:2203.08452v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08452">
<div class="article-summary-box-inner">
<span><p>Simile interpretation is a crucial task in natural language processing.
Nowadays, pre-trained language models (PLMs) have achieved state-of-the-art
performance on many tasks. However, it remains under-explored whether PLMs can
interpret similes or not. In this paper, we investigate the ability of PLMs in
simile interpretation by designing a novel task named Simile Property Probing,
i.e., to let the PLMs infer the shared properties of similes. We construct our
simile property probing datasets from both general textual corpora and
human-designed questions, containing 1,633 examples covering seven main
categories. Our empirical study based on the constructed datasets shows that
PLMs can infer similes' shared properties while still underperforming humans.
To bridge the gap with human performance, we additionally design a
knowledge-enhanced training objective by incorporating the simile knowledge
into PLMs via knowledge embedding methods. Our method results in a gain of
8.58% in the probing task and 1.37% in the downstream task of sentiment
classification. The datasets and code are publicly available at
https://github.com/Abbey4799/PLMs-Interpret-Simile.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KinyaBERT: a Morphology-aware Kinyarwanda Language Model. (arXiv:2203.08459v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08459">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models such as BERT have been successful at tackling
many natural language processing tasks. However, the unsupervised sub-word
tokenization methods commonly used in these models (e.g., byte-pair encoding -
BPE) are sub-optimal at handling morphologically rich languages. Even given a
morphological analyzer, naive sequencing of morphemes into a standard BERT
architecture is inefficient at capturing morphological compositionality and
expressing word-relative syntactic regularities. We address these challenges by
proposing a simple yet effective two-tier BERT architecture that leverages a
morphological analyzer and explicitly represents morphological
compositionality. Despite the success of BERT, most of its evaluations have
been conducted on high-resource languages, obscuring its applicability on
low-resource languages. We evaluate our proposed method on the low-resource
morphologically rich Kinyarwanda language, naming the proposed model
architecture KinyaBERT. A robust set of experimental results reveal that
KinyaBERT outperforms solid baselines by 2% F1 score on a named entity
recognition task and by 4.3% average score of a machine-translated GLUE
benchmark. KinyaBERT fine-tuning has better convergence and achieves more
robust results on multiple tasks even in the presence of translation noise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">E-KAR: A Benchmark for Rationalizing Natural Language Analogical Reasoning. (arXiv:2203.08480v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08480">
<div class="article-summary-box-inner">
<span><p>The ability to recognize analogies is fundamental to human cognition.
Existing benchmarks to test word analogy do not reveal the underneath process
of analogical reasoning of neural models. Holding the belief that models
capable of reasoning should be right for the right reasons, we propose a
first-of-its-kind Explainable Knowledge-intensive Analogical Reasoning
benchmark (E-KAR). Our benchmark consists of 1,655 (in Chinese) and 1,251 (in
English) problems sourced from the Civil Service Exams, which require intensive
background knowledge to solve. More importantly, we design a free-text
explanation scheme to explain whether an analogy should be drawn, and manually
annotate them for each and every question and candidate answer. Empirical
results suggest that this benchmark is very challenging for some
state-of-the-art models for both explanation generation and analogical question
answering tasks, which invites further research in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HeterMPC: A Heterogeneous Graph Neural Network for Response Generation in Multi-Party Conversations. (arXiv:2203.08500v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08500">
<div class="article-summary-box-inner">
<span><p>Recently, various response generation models for two-party conversations have
achieved impressive improvements, but less effort has been paid to multi-party
conversations (MPCs) which are more practical and complicated. Compared with a
two-party conversation where a dialogue context is a sequence of utterances,
building a response generation model for MPCs is more challenging, since there
exist complicated context structures and the generated responses heavily rely
on both interlocutors (i.e., speaker and addressee) and history utterances. To
address these challenges, we present HeterMPC, a heterogeneous graph-based
neural network for response generation in MPCs which models the semantics of
utterances and interlocutors simultaneously with two types of nodes in a graph.
Besides, we also design six types of meta relations with
node-edge-type-dependent parameters to characterize the heterogeneous
interactions within the graph. Through multi-hop updating, HeterMPC can
adequately utilize the structural knowledge of conversations for response
generation. Experimental results on the Ubuntu Internet Relay Chat (IRC)
channel benchmark show that HeterMPC outperforms various baseline models for
response generation in MPCs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConTinTin: Continual Learning from Task Instructions. (arXiv:2203.08512v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08512">
<div class="article-summary-box-inner">
<span><p>The mainstream machine learning paradigms for NLP often work with two
underlying presumptions. First, the target task is predefined and static, a
system just needs to learn to solve it exclusively. Second, the supervision of
a task mainly comes from a set of labeled examples. A question arises: how to
build a system that can keep learning new tasks from their instructions? This
work defines a new learning paradigm ConTinTin (Continual Learning from Task
Instructions), in which a system should learn a sequence of new tasks one by
one, each task is explained by a piece of textual instruction. The system is
required to (i) generate the expected outputs of a new task by learning from
its instruction, (ii) transfer the knowledge acquired from upstream tasks to
help solve downstream tasks (i.e, forward-transfer), and (iii) retain or even
improve the performance on earlier tasks after learning new tasks (i.e.,
backward-transfer). This new problem is studied on a stream of more than 60
tasks, each equipped with an instruction. Technically, our method
InstructionSpeak contains two strategies that make full use of task
instructions to improve forward-transfer and backward-transfer: one is to learn
from the negative output, the other is to re-visit instructions of prior tasks.
To our knowledge, this is the first time to study ConTinTin in NLP. In addition
to the problem formulation and our promising approach, this work also
contributes to providing rich analyses for the community to better understand
this novel learning problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TegTok: Augmenting Text Generation via Task-specific and Open-world Knowledge. (arXiv:2203.08517v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08517">
<div class="article-summary-box-inner">
<span><p>Generating natural and informative texts has been a long-standing problem in
NLP. Much effort has been dedicated into incorporating pre-trained language
models (PLMs) with various open-world knowledge, such as knowledge graphs or
wiki pages. However, their ability to access and manipulate the task-specific
knowledge is still limited on downstream tasks, as this type of knowledge is
usually not well covered in PLMs and is hard to acquire. To address the
problem, we propose augmenting TExt Generation via Task-specific and Open-world
Knowledge (TegTok) in a unified framework. Our model selects knowledge entries
from two types of knowledge sources through dense retrieval and then injects
them into the input encoding and output decoding stages respectively on the
basis of PLMs. With the help of these two types of knowledge, our model can
learn what and how to generate. Experiments on two text generation tasks of
dialogue generation and question generation, and on two datasets show that our
method achieves better performance than various baseline models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Morphological Reinflection with Multiple Arguments: An Extended Annotation schema and a Georgian Case Study. (arXiv:2203.08527v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08527">
<div class="article-summary-box-inner">
<span><p>In recent years, a flurry of morphological datasets had emerged, most notably
UniMorph, a multi-lingual repository of inflection tables. However, the flat
structure of the current morphological annotation schemas makes the treatment
of some languages quirky, if not impossible, specifically in cases of
polypersonal agreement. In this paper we propose a general solution for such
cases and expand the UniMorph annotation schema to naturally address this
phenomenon, in which verbs agree with multiple arguments using true affixes. We
apply this extended schema to one such language, Georgian, and provide a
human-verified, accurate and balanced morphological dataset for Georgian verbs.
The dataset has 4 times more tables and 6 times more verb forms compared to the
existing UniMorph dataset, covering all possible variants of argument marking,
demonstrating the adequacy of our proposed scheme. Experiments with a standard
reinflection model show that generalization is easy when the data is split at
the form level, but extremely hard when splitting along lemma lines. Expanding
the other languages in UniMorph to this schema is expected to improve both the
coverage, consistency and interpretability of this benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Pre-training with Language and Task Adaptation for Multilingual Text Style Transfer. (arXiv:2203.08552v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08552">
<div class="article-summary-box-inner">
<span><p>We exploit the pre-trained seq2seq model mBART for multilingual text style
transfer. Using machine translated data as well as gold aligned English
sentences yields state-of-the-art results in the three target languages we
consider. Besides, in view of the general scarcity of parallel data, we propose
a modular approach for multilingual formality transfer, which consists of two
training strategies that target adaptation to both language and task. Our
approach achieves competitive performance without monolingual task-specific
parallel data and can be applied to other style transfer tasks as well as to
other languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Dependency Parsing with Worst-Case Aware Automated Curriculum Learning. (arXiv:2203.08555v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08555">
<div class="article-summary-box-inner">
<span><p>Large multilingual pretrained language models such as mBERT and XLM-RoBERTa
have been found to be surprisingly effective for cross-lingual transfer of
syntactic parsing models (Wu and Dredze 2019), but only between related
languages. However, source and training languages are rarely related, when
parsing truly low-resource languages. To close this gap, we adopt a method from
multi-task learning, which relies on automated curriculum learning, to
dynamically optimize for parsing performance on outlier languages. We show that
this approach is significantly better than uniform and size-proportional
sampling in the zero-shot setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEVEN: A Large-Scale Chinese Legal Event Detection Dataset. (arXiv:2203.08556v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08556">
<div class="article-summary-box-inner">
<span><p>Recognizing facts is the most fundamental step in making judgments, hence
detecting events in the legal documents is important to legal case analysis
tasks. However, existing Legal Event Detection (LED) datasets only concern
incomprehensive event types and have limited annotated data, which restricts
the development of LED methods and their downstream applications. To alleviate
these issues, we present LEVEN a large-scale Chinese LEgal eVENt detection
dataset, with 8,116 legal documents and 150,977 human-annotated event mentions
in 108 event types. Not only charge-related events, LEVEN also covers general
events, which are critical for legal case understanding but neglected in
existing LED datasets. To our knowledge, LEVEN is the largest LED dataset and
has dozens of times the data scale of others, which shall significantly promote
the training and evaluation of LED methods. The results of extensive
experiments indicate that LED is challenging and needs further effort.
Moreover, we simply utilize legal events as side information to promote
downstream applications. The method achieves improvements of average 2.2 points
precision in low-resource judgment prediction, and 1.5 points mean average
precision in unsupervised case retrieval, which suggests the fundamentality of
LED. The source code and dataset can be obtained from
https://github.com/thunlp/LEVEN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geographic Adaptation of Pretrained Language Models. (arXiv:2203.08565v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08565">
<div class="article-summary-box-inner">
<span><p>Geographic linguistic features are commonly used to improve the performance
of pretrained language models (PLMs) on NLP tasks where geographic knowledge is
intuitively beneficial (e.g., geolocation prediction and dialect feature
prediction). Existing work, however, leverages such geographic information in
task-specific fine-tuning, failing to incorporate it into PLMs' geo-linguistic
knowledge, which would make it transferable across different tasks. In this
work, we introduce an approach to task-agnostic geoadaptation of PLMs that
forces the PLM to learn associations between linguistic phenomena and
geographic locations. More specifically, geoadaptation is an intermediate
training step that couples masked language modeling and geolocation prediction
in a dynamic multitask learning setup. In our experiments, we geoadapt BERTi\'c
-- a PLM for Bosnian, Croatian, Montenegrin, and Serbian (BCMS) -- using a
corpus of geotagged BCMS tweets. Evaluation on three different tasks, namely
unsupervised (zero-shot) and supervised geolocation prediction and
(unsupervised) prediction of dialect features, shows that our geoadaptation
approach is very effective: e.g., we obtain new state-of-the-art performance in
supervised geolocation prediction and report massive gains over geographically
uninformed PLMs on zero-shot geolocation prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In-Context Learning for Few-Shot Dialogue State Tracking. (arXiv:2203.08568v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08568">
<div class="article-summary-box-inner">
<span><p>Collecting and annotating task-oriented dialogues is time-consuming and
costly. Thus, few-shot learning for dialogue tasks presents an exciting
opportunity. In this work, we propose an in-context (IC) learning framework for
few-shot dialogue state tracking (DST), where a large pre-trained language
model (LM) takes a test instance and a few annotated examples as input, and
directly decodes the dialogue states without any parameter updates. This makes
the LM more flexible and scalable compared to prior few-shot DST work when
adapting to new domains and scenarios. We study ways to formulate dialogue
context into prompts for LMs and propose an efficient approach to retrieve
dialogues as exemplars given a test instance and a selection pool of few-shot
examples. To better leverage the pre-trained LMs, we also reformulate DST into
a text-to-SQL problem. Empirical results on MultiWOZ 2.1 and 2.4 show that our
method IC-DST outperforms previous fine-tuned state-of-the-art models in
few-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Whither the Priors for (Vocal) Interactivity?. (arXiv:2203.08578v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08578">
<div class="article-summary-box-inner">
<span><p>Voice-based communication is often cited as one of the most `natural' ways in
which humans and robots might interact, and the recent availability of accurate
automatic speech recognition and intelligible speech synthesis has enabled
researchers to integrate advanced off-the-shelf spoken language technology
components into their robot platforms. Despite this, the resulting interactions
are anything but `natural'. It transpires that simply giving a robot a voice
doesn't mean that a user will know how (or when) to talk to it, and the
resulting `conversations' tend to be stilted, one-sided and short. On the
surface, these difficulties might appear to be fairly trivial consequences of
users' unfamiliarity with robots (and \emph{vice versa}), and that any problems
would be mitigated by long-term use by the human, coupled with `deep learning'
by the robot. However, it is argued here that such communication failures are
indicative of a deeper malaise: a fundamental lack of basic principles --
\emph{priors} -- underpinning not only speech-based interaction in particular,
but (vocal) interactivity in general. This is evidenced not only by the fact
that contemporary spoken language systems already require training data sets
that are orders-of-magnitude greater than that experienced by a young child,
but also by the lack of design principles for creating effective communicative
human-robot interaction. This short position paper identifies some of the key
areas where theoretical insights might help overcome these shortfalls.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Less is More: Summary of Long Instructions is Better for Program Synthesis. (arXiv:2203.08597v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08597">
<div class="article-summary-box-inner">
<span><p>Despite the success of large pre-trained language models (LMs) such as Codex,
they show below-par performance on the larger and more complicated programming
related questions. We show that LMs benefit from the summarized version of
complicated questions. Our findings show that superfluous information often
present in problem description such as human characters, background stories,
names (which are included to help humans in understanding a task) does not help
models in understanding a task. To this extent, we create a meta-dataset from
the frequently used APPS dataset for the program synthesis task. Our
meta-dataset consists of human and synthesized summary of the long and
complicated programming questions. Experimental results on Codex show that our
proposed approach outperforms baseline by 8.13% on an average in terms of
strict accuracy. Our analysis shows that summary significantly improve
performance for introductory (9.86%) and interview (11.48%) related programming
questions. However, it shows improvement by a small margin (~2%) for
competitive programming questions, implying the scope for future research
direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Neural Networks for Multiparallel Word Alignment. (arXiv:2203.08654v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08654">
<div class="article-summary-box-inner">
<span><p>After a period of decrease, interest in word alignments is increasing again
for their usefulness in domains such as typological research, cross-lingual
annotation projection, and machine translation. Generally, alignment algorithms
only use bitext and do not make use of the fact that many parallel corpora are
multiparallel. Here, we compute high-quality word alignments between multiple
language pairs by considering all language pairs together. First, we create a
multiparallel word alignment graph, joining all bilingual word alignment pairs
in one graph. Next, we use graph neural networks (GNNs) to exploit the graph
structure. Our GNN approach (i) utilizes information about the meaning,
position, and language of the input words, (ii) incorporates information from
multiple parallel sentences, (iii) adds and removes edges from the initial
alignments, and (iv) yields a prediction model that can generalize beyond the
training sentences. We show that community detection provides valuable
information for multiparallel word alignment. Our method outperforms previous
work on three word-alignment datasets and on a downstream task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Feasibility Study of Answer-Unaware Question Generation for Education. (arXiv:2203.08685v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08685">
<div class="article-summary-box-inner">
<span><p>We conduct a feasibility study into the applicability of answer-unaware
question generation models to textbook passages. We show that a significant
portion of errors in such systems arise from asking irrelevant or
uninterpretable questions and that such errors can be ameliorated by providing
summarized input. We find that giving these models human-written summaries
instead of the original text results in a significant increase in acceptability
of generated questions (33% $\rightarrow$ 83%) as determined by expert
annotators. We also find that, in the absence of human-written summaries,
automatic summarization can serve as a good middle ground.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Turning Stocks into Memes: A Dataset for Understanding How Social Communities Can Drive Wall Street. (arXiv:2203.08694v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08694">
<div class="article-summary-box-inner">
<span><p>Who actually expresses an intent to buy GameStop shares on Reddit? What
convinces people to buy stocks? Are people convinced to support a coordinated
plan to adversely impact Wall Street investors? Existing literature on
understanding intent has mainly relied on surveys and self reporting; however
there are limitations to these methodologies. Hence, in this paper, we develop
an annotated dataset of communications centered on the GameStop phenomenon to
analyze the subscriber intentions behaviors within the r/WallStreetBets
community to buy (or not buy) stocks. Likewise, we curate a dataset to better
understand how intent interacts with a user's general support towards the
coordinated actions of the community for GameStop. Overall, our dataset can
provide insight to social scientists on the persuasive power to buy into social
movements online by adopting common language and narrative. WARNING: This paper
contains offensive language that commonly appears on Reddit's r/WallStreetBets
subreddit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Stage Prompting for Knowledgeable Dialogue Generation. (arXiv:2203.08745v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08745">
<div class="article-summary-box-inner">
<span><p>Existing knowledge-grounded dialogue systems typically use finetuned versions
of a pretrained language model (LM) and large-scale knowledge bases. These
models typically fail to generalize on topics outside of the knowledge base,
and require maintaining separate potentially large checkpoints each time
finetuning is needed. In this paper, we aim to address these limitations by
leveraging the inherent knowledge stored in the pretrained LM as well as its
powerful generation ability. We propose a multi-stage prompting approach to
generate knowledgeable responses from a single pretrained LM. We first prompt
the LM to generate knowledge based on the dialogue context. Then, we further
prompt it to generate responses based on the dialogue context and the
previously generated knowledge. Results show that our knowledge generator
outperforms the state-of-the-art retrieval-based model by 5.8% when combining
knowledge relevance and correctness. In addition, our multi-stage prompting
outperforms the finetuning-based dialogue model in terms of response
knowledgeability and engagement by up to 10% and 5%, respectively. Furthermore,
we scale our model up to 530 billion parameters and show that larger LMs
improve the generation correctness score by up to 10%, and response relevance,
knowledgeability and engagement by up to 10%. Our code is available at:
https://github.com/NVIDIA/Megatron-LM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sample, Translate, Recombine: Leveraging Audio Alignments for Data Augmentation in End-to-end Speech Translation. (arXiv:2203.08757v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08757">
<div class="article-summary-box-inner">
<span><p>End-to-end speech translation relies on data that pair source-language speech
inputs with corresponding translations into a target language. Such data are
notoriously scarce, making synthetic data augmentation by back-translation or
knowledge distillation a necessary ingredient of end-to-end training. In this
paper, we present a novel approach to data augmentation that leverages audio
alignments, linguistic properties, and translation. First, we augment a
transcription by sampling from a suffix memory that stores text and audio data.
Second, we translate the augmented transcript. Finally, we recombine
concatenated audio segments and the generated translation. Besides training an
MT-system, we only use basic off-the-shelf components without fine-tuning.
While having similar resource demands as knowledge distillation, adding our
method delivers consistent improvements of up to 0.9 and 1.1 BLEU points on
five language pairs on CoVoST 2 and on two language pairs on Europarl-ST,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data. (arXiv:2203.08773v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08773">
<div class="article-summary-box-inner">
<span><p>Retrieval-based methods have been shown to be effective in NLP tasks via
introducing external knowledge. However, the indexing and retrieving of
large-scale corpora bring considerable computational cost. Surprisingly, we
found that REtrieving from the traINing datA (REINA) only can lead to
significant gains on multiple NLG and NLU tasks. We retrieve the labeled
training instances most similar to the input text and then concatenate them
with the input to feed into the model to generate the output. Experimental
results show that this simple method can achieve significantly better
performance on a variety of NLU and NLG tasks, including summarization, machine
translation, language modeling, and question answering tasks. For instance, our
proposed method achieved state-of-the-art results on XSum, BigPatent, and
CommonsenseQA. Our code is released, https://github.com/microsoft/REINA .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CUE Vectors: Modular Training of Language Models Conditioned on Diverse Contextual Signals. (arXiv:2203.08774v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08774">
<div class="article-summary-box-inner">
<span><p>We propose a framework to modularize the training of neural language models
that use diverse forms of sentence-external context (including metadata) by
eliminating the need to jointly train sentence-external and within-sentence
encoders. Our approach, contextual universal embeddings (CUE), trains LMs on
one set of context, such as date and author, and adapts to novel metadata
types, such as article title, or previous sentence. The model consists of a
pretrained neural sentence LM, a BERT-based context encoder, and a masked
transformer decoder that estimates LM probabilities using sentence-internal and
sentence-external information. When context or metadata are unavailable, our
model learns to combine contextual and sentence-internal information using
noisy oracle unigram embeddings as a proxy. Real contextual information can be
introduced later and used to adapt a small number of parameters that map
contextual data into the decoder's embedding space. We validate the CUE
framework on a NYTimes text corpus with multiple metadata types, for which the
LM perplexity can be lowered from 36.6 to 27.4 by conditioning on context.
Bootstrapping a contextual LM with only a subset of the context/metadata during
training retains 85\% of the achievable gain. Training the model initially with
proxy context retains 67% of the perplexity gain after adapting to real
context. Furthermore, we can swap one type of pretrained sentence LM for
another without retraining the context encoders, by only adapting the decoder
model. Overall, we obtain a modular framework that allows incremental, scalable
training of context-enhanced LMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Shortest Rationales the Best Explanations for Human Understanding?. (arXiv:2203.08788v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08788">
<div class="article-summary-box-inner">
<span><p>Existing self-explaining models typically favor extracting the shortest
possible rationales - snippets of an input text "responsible for" corresponding
output - to explain the model prediction, with the assumption that shorter
rationales are more intuitive to humans. However, this assumption has yet to be
validated. Is the shortest rationale indeed the most human-understandable? To
answer this question, we design a self-explaining model, LimitedInk, which
allows users to extract rationales at any target length. Compared to existing
baselines, LimitedInk achieves compatible end-task performance and
human-annotated rationale agreement, making it a suitable representation of the
recent class of self-explaining models. We use LimitedInk to conduct a user
study on the impact of rationale length, where we ask human judges to predict
the sentiment label of documents based only on LimitedInk-generated rationales
with different lengths. We show rationales that are too short do not help
humans predict labels better than randomly masked text, suggesting the need for
more careful design of the best human rationales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Parameter Allocation Search. (arXiv:2006.10598v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10598">
<div class="article-summary-box-inner">
<span><p>Training neural networks requires increasing amounts of memory. Parameter
sharing can reduce memory and communication costs, but existing methods assume
networks have many identical layers and utilize hand-crafted sharing strategies
that fail to generalize. We introduce Neural Parameter Allocation Search
(NPAS), a novel task where the goal is to train a neural network given an
arbitrary, fixed parameter budget. NPAS covers both low-budget regimes, which
produce compact networks, as well as a novel high-budget regime, where
additional capacity can be added to boost performance without increasing
inference FLOPs. To address NPAS, we introduce Shapeshifter Networks (SSNs),
which automatically learn where and how to share parameters in a network to
support any parameter budget without requiring any changes to the architecture
or loss function. NPAS and SSNs provide a complete framework for addressing
generalized parameter sharing, and can also be combined with prior work for
additional performance gains. We demonstrate the effectiveness of our approach
using nine network architectures across four diverse tasks, including ImageNet
classification and transformers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SHIELD: Defending Textual Neural Networks against Multiple Black-Box Adversarial Attacks with Stochastic Multi-Expert Patcher. (arXiv:2011.08908v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08908">
<div class="article-summary-box-inner">
<span><p>Even though several methods have proposed to defend textual neural network
(NN) models against black-box adversarial attacks, they often defend against a
specific text perturbation strategy and/or require re-training the models from
scratch. This leads to a lack of generalization in practice and redundant
computation. In particular, the state-of-the-art transformer models (e.g.,
BERT, RoBERTa) require great time and computation resources. By borrowing an
idea from software engineering, in order to address these limitations, we
propose a novel algorithm, SHIELD, which modifies and re-trains only the last
layer of a textual NN, and thus it "patches" and "transforms" the NN into a
stochastic weighted ensemble of multi-expert prediction heads. Considering that
most of current black-box attacks rely on iterative search mechanisms to
optimize their adversarial perturbations, SHIELD confuses the attackers by
automatically utilizing different weighted ensembles of predictors depending on
the input. In other words, SHIELD breaks a fundamental assumption of the
attack, which is a victim NN model remains constant during an attack. By
conducting comprehensive experiments, we demonstrate that all of CNN, RNN,
BERT, and RoBERTa-based textual NNs, once patched by SHIELD, exhibit a relative
enhancement of 15%--70% in accuracy on average against 14 different black-box
attacks, outperforming 6 defensive baselines across 3 public datasets. All
codes are to be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Hate Speech with GPT-3. (arXiv:2103.12407v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12407">
<div class="article-summary-box-inner">
<span><p>Sophisticated language models such as OpenAI's GPT-3 can generate hateful
text that targets marginalized groups. Given this capacity, we are interested
in whether large language models can be used to identify hate speech and
classify text as sexist or racist. We use GPT-3 to identify sexist and racist
text passages with zero-, one-, and few-shot learning. We find that with zero-
and one-shot learning, GPT-3 can identify sexist or racist text with an
accuracy between 57 per cent and 68 per cent depending on the category of text
and type of learning. With few-shot learning, the model's accuracy can be as
high as 88 per cent. Large language models have a role to play in hate speech
detection, and with further development could eventually be used to counter
hate speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey on reinforcement learning for language processing. (arXiv:2104.05565v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05565">
<div class="article-summary-box-inner">
<span><p>In recent years some researchers have explored the use of reinforcement
learning (RL) algorithms as key components in the solution of various natural
language processing tasks. For instance, some of these algorithms leveraging
deep neural learning have found their way into conversational systems. This
paper reviews the state of the art of RL methods for their possible use for
different problems of natural language processing, focusing primarily on
conversational systems, mainly due to their growing relevance. We provide
detailed descriptions of the problems as well as discussions of why RL is
well-suited to solve them. Also, we analyze the advantages and limitations of
these methods. Finally, we elaborate on promising research directions in
natural language processing that might benefit from reinforcement learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bilingual alignment transfers to multilingual alignment for unsupervised parallel text mining. (arXiv:2104.07642v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07642">
<div class="article-summary-box-inner">
<span><p>This work presents methods for learning cross-lingual sentence
representations using paired or unpaired bilingual texts. We hypothesize that
the cross-lingual alignment strategy is transferable, and therefore a model
trained to align only two languages can encode multilingually more aligned
representations. We thus introduce dual-pivot transfer: training on one
language pair and evaluating on other pairs. To study this theory, we design
unsupervised models trained on unpaired sentences and single-pair supervised
models trained on bitexts, both based on the unsupervised language model XLM-R
with its parameters frozen. The experiments evaluate the models as universal
sentence encoders on the task of unsupervised bitext mining on two datasets,
where the unsupervised model reaches the state of the art of unsupervised
retrieval, and the alternative single-pair supervised model approaches the
performance of multilingually supervised models. The results suggest that
bilingual training techniques as proposed can be applied to get sentence
representations with multilingual alignment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Premise-based Multimodal Reasoning: A Human-like Cognitive Process. (arXiv:2105.07122v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07122">
<div class="article-summary-box-inner">
<span><p>It is a common practice for recent works in vision language cross-modal
reasoning to adopt a binary or multi-choice classification formulation taking
as input a set of source image(s) and textual query. In this work, we take a
sober look at such an unconditional formulation in the sense that no prior
knowledge is specified with respect to the source image(s). Inspired by the
designs of both visual commonsense reasoning and natural language inference
tasks, we propose a new task termed Premise-based Multi-modal Reasoning(PMR)
where a textual premise is the background presumption on each source image. The
PMR dataset contains 15,360 manually annotated samples which are created by a
multi-phase crowd-sourcing process. With selected high-quality movie
screenshots and human-curated premise templates from 6 pre-defined categories,
we ask crowd-source workers to write one true hypothesis and three distractors
(4 choices) given the premise and image through a cross-check procedure.
Besides, we generate adversarial samples to alleviate the annotation artifacts
and double the size of PMR. We benchmark various state-of-the-art (pretrained)
multi-modal inference models on PMR and conduct comprehensive experimental
analyses to showcase the utility of our dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VISITRON: Visual Semantics-Aligned Interactively Trained Object-Navigator. (arXiv:2105.11589v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11589">
<div class="article-summary-box-inner">
<span><p>Interactive robots navigating photo-realistic environments need to be trained
to effectively leverage and handle the dynamic nature of dialogue in addition
to the challenges underlying vision-and-language navigation (VLN). In this
paper, we present VISITRON, a multi-modal Transformer-based navigator better
suited to the interactive regime inherent to Cooperative Vision-and-Dialog
Navigation (CVDN). VISITRON is trained to: i) identify and associate
object-level concepts and semantics between the environment and dialogue
history, ii) identify when to interact vs. navigate via imitation learning of a
binary classification head. We perform extensive pre-training and fine-tuning
ablations with VISITRON to gain empirical insights and improve performance on
CVDN. VISITRON's ability to identify when to interact leads to a natural
generalization of the game-play mode introduced by Roman et al.
(<a href="/abs/2005.00728">arXiv:2005.00728</a>) for enabling the use of such models in different
environments. VISITRON is competitive with models on the static CVDN
leaderboard and attains state-of-the-art performance on the Success weighted by
Path Length (SPL) metric.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">REAM$\sharp$: An Enhancement Approach to Reference-based Evaluation Metrics for Open-domain Dialog Generation. (arXiv:2105.14488v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14488">
<div class="article-summary-box-inner">
<span><p>The lack of reliable automatic evaluation metrics is a major impediment to
the development of open-domain dialogue systems. Various reference-based
metrics have been proposed to calculate a score between a predicted response
and a small set of references. However, these metrics show unsatisfactory
correlations with human judgments. For a reference-based metric, its
reliability mainly depends on two factors: its ability to measure the
similarity between the predicted response and the reference response, as well
as the reliability of the given reference set. Yet, there are few discussions
on the latter. Our work attempts to fill this vacancy. We first clarify an
assumption on reference-based metrics that, if more high-quality references are
added into the reference set, the reliability of the metric will increase.
Next, we present REAM$\sharp$: an enhancement approach to Reference-based
EvAluation Metrics for open-domain dialogue systems. A prediction model is
designed to estimate the reliability of the given reference set. We show how
its predicted results can be helpful to augment the reference set, and thus
improve the reliability of the metric. Experiments validate both the
effectiveness of our prediction model and that the reliability of
reference-based metrics improves with the augmented reference sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Hyperbolic Neural Networks. (arXiv:2105.14686v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14686">
<div class="article-summary-box-inner">
<span><p>Hyperbolic neural networks have shown great potential for modeling complex
data. However, existing hyperbolic networks are not completely hyperbolic, as
they encode features in a hyperbolic space yet formalize most of their
operations in the tangent space (a Euclidean subspace) at the origin of the
hyperbolic space. This hybrid method greatly limits the modeling ability of
networks. In this paper, we propose a fully hyperbolic framework to build
hyperbolic networks based on the Lorentz model by adapting the Lorentz
transformations (including boost and rotation) to formalize essential
operations of neural networks. Moreover, we also prove that linear
transformation in tangent spaces used by existing hyperbolic networks is a
relaxation of the Lorentz rotation and does not include the boost, implicitly
limiting the capabilities of existing hyperbolic networks. The experimental
results on four NLP tasks show that our method has better performance for
building both shallow and deep networks. Our code will be released to
facilitate follow-up research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues. (arXiv:2106.01006v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01006">
<div class="article-summary-box-inner">
<span><p>Inferring social relations from dialogues is vital for building emotionally
intelligent robots to interpret human language better and act accordingly. We
model the social network as an And-or Graph, named SocAoG, for the consistency
of relations among a group and leveraging attributes as inference cues.
Moreover, we formulate a sequential structure prediction task, and propose an
$\alpha$-$\beta$-$\gamma$ strategy to incrementally parse SocAoG for the
dynamic inference upon any incoming utterance: (i) an $\alpha$ process
predicting attributes and relations conditioned on the semantics of dialogues,
(ii) a $\beta$ process updating the social relations based on related
attributes, and (iii) a $\gamma$ process updating individual's attributes based
on interpersonal social relations. Empirical results on DialogRE and MovieGraph
show that our model infers social relations more accurately than the
state-of-the-art methods. Moreover, the ablation study shows the three
processes complement each other, and the case study demonstrates the dynamic
relational inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Expressivity of Emergent Language is a Trade-off between Contextual Complexity and Unpredictability. (arXiv:2106.03982v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03982">
<div class="article-summary-box-inner">
<span><p>Researchers are using deep learning models to explore the emergence of
language in various language games, where agents interact and develop an
emergent language to solve tasks. We focus on the factors that determine the
expressivity of emergent languages, which reflects the amount of information
about input spaces those languages are capable of encoding. We measure the
expressivity of emergent languages based on the generalisation performance
across different games, and demonstrate that the expressivity of emergent
languages is a trade-off between the complexity and unpredictability of the
context those languages emerged from. Another contribution of this work is the
discovery of message type collapse, i.e. the number of unique messages is lower
than that of inputs. We also show that using the contrastive loss proposed by
Chen et al. (2020) can alleviate this problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Interpretation of Softmax Cross-Entropy and Negative Sampling: With Case Study for Knowledge Graph Embedding. (arXiv:2106.07250v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07250">
<div class="article-summary-box-inner">
<span><p>In knowledge graph embedding, the theoretical relationship between the
softmax cross-entropy and negative sampling loss functions has not been
investigated. This makes it difficult to fairly compare the results of the two
different loss functions. We attempted to solve this problem by using the
Bregman divergence to provide a unified interpretation of the softmax
cross-entropy and negative sampling loss functions. Under this interpretation,
we can derive theoretical findings for fair comparison. Experimental results on
the FB15k-237 and WN18RR datasets show that the theoretical findings are valid
in practical settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Question Answering Infused Pre-training of General-Purpose Contextualized Representations. (arXiv:2106.08190v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08190">
<div class="article-summary-box-inner">
<span><p>We propose a pre-training objective based on question answering (QA) for
learning general-purpose contextual representations, motivated by the intuition
that the representation of a phrase in a passage should encode all questions
that the phrase can answer in context. To this end, we train a bi-encoder QA
model, which independently encodes passages and questions, to match the
predictions of a more accurate cross-encoder model on 80 million synthesized QA
pairs. By encoding QA-relevant information, the bi-encoder's token-level
representations are useful for non-QA downstream tasks without extensive (or in
some cases, any) fine-tuning. We show large improvements over both
RoBERTa-large and previous state-of-the-art results on zero-shot and few-shot
paraphrase detection on four datasets, few-shot named entity recognition on two
datasets, and zero-shot sentiment analysis on three datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Closer Look at How Fine-tuning Changes BERT. (arXiv:2106.14282v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14282">
<div class="article-summary-box-inner">
<span><p>Given the prevalence of pre-trained contextualized representations in today's
NLP, there have been many efforts to understand what information they contain,
and why they seem to be universally successful. The most common approach to use
these representations involves fine-tuning them for an end task. Yet, how
fine-tuning changes the underlying embedding space is less studied. In this
work, we study the English BERT family and use two probing techniques to
analyze how fine-tuning changes the space. We hypothesize that fine-tuning
affects classification performance by increasing the distances between examples
associated with different labels. We confirm this hypothesis with carefully
designed experiments on five different NLP tasks. Via these experiments, we
also discover an exception to the prevailing wisdom that "fine-tuning always
improves performance". Finally, by comparing the representations before and
after fine-tuning, we discover that fine-tuning does not introduce arbitrary
changes to representations; instead, it adjusts the representations to
downstream tasks while largely preserving the original spatial structure of the
data points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Investigation of the (In)effectiveness of Counterfactually Augmented Data. (arXiv:2107.00753v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00753">
<div class="article-summary-box-inner">
<span><p>While pretrained language models achieve excellent performance on natural
language understanding benchmarks, they tend to rely on spurious correlations
and generalize poorly to out-of-distribution (OOD) data. Recent work has
explored using counterfactually-augmented data (CAD) -- data generated by
minimally perturbing examples to flip the ground-truth label -- to identify
robust features that are invariant under distribution shift. However, empirical
results using CAD for OOD generalization have been mixed. To explain this
discrepancy, we draw insights from a linear Gaussian model and demonstrate the
pitfalls of CAD. Specifically, we show that (a) while CAD is effective at
identifying robust features, it may prevent the model from learning unperturbed
robust features; and (b) CAD may exacerbate existing spurious correlations in
the data. On two crowdsourced CAD datasets, our results show that the lack of
perturbation diversity limits their effectiveness on OOD generalization,
calling for innovative crowdsourcing procedures to elicit diverse perturbation
of examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MemSum: Extractive Summarization of Long Documents Using Multi-Step Episodic Markov Decision Processes. (arXiv:2107.08929v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08929">
<div class="article-summary-box-inner">
<span><p>We introduce MemSum (Multi-step Episodic Markov decision process extractive
SUMmarizer), a reinforcement-learning-based extractive summarizer enriched at
each step with information on the current extraction history. When MemSum
iteratively selects sentences into the summary, it considers a broad
information set that would intuitively also be used by humans in this task: 1)
the text content of the sentence, 2) the global text context of the rest of the
document, and 3) the extraction history consisting of the set of sentences that
have already been extracted. With a lightweight architecture, MemSum obtains
state-of-the-art test-set performance (ROUGE) in summarizing long documents
taken from PubMed, arXiv, and GovReport. Ablation studies demonstrate the
importance of local, global, and history information. A human evaluation
confirms the high quality and low redundancy of the generated summaries,
stemming from MemSum's awareness of extraction history.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perceiver IO: A General Architecture for Structured Inputs & Outputs. (arXiv:2107.14795v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14795">
<div class="article-summary-box-inner">
<span><p>A central goal of machine learning is the development of systems that can
solve many problems in as many data domains as possible. Current architectures,
however, cannot be applied beyond a small set of stereotyped settings, as they
bake in domain &amp; task assumptions or scale poorly to large inputs or outputs.
In this work, we propose Perceiver IO, a general-purpose architecture that
handles data from arbitrary settings while scaling linearly with the size of
inputs and outputs. Our model augments the Perceiver with a flexible querying
mechanism that enables outputs of various sizes and semantics, doing away with
the need for task-specific architecture engineering. The same architecture
achieves strong results on tasks spanning natural language and visual
understanding, multi-task and multi-modal reasoning, and StarCraft II. As
highlights, Perceiver IO outperforms a Transformer-based BERT baseline on the
GLUE language benchmark despite removing input tokenization and achieves
state-of-the-art performance on Sintel optical flow estimation with no explicit
mechanisms for multiscale correspondence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASR-GLUE: A New Multi-task Benchmark for ASR-Robust Natural Language Understanding. (arXiv:2108.13048v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13048">
<div class="article-summary-box-inner">
<span><p>Language understanding in speech-based systems have attracted much attention
in recent years with the growing demand for voice interface applications.
However, the robustness of natural language understanding (NLU) systems to
errors introduced by automatic speech recognition (ASR) is under-examined. %To
facilitate the research on ASR-robust general language understanding, In this
paper, we propose ASR-GLUE benchmark, a new collection of 6 different NLU tasks
for evaluating the performance of models under ASR error across 3 different
levels of background noise and 6 speakers with various voice characteristics.
Based on the proposed benchmark, we systematically investigate the effect of
ASR error on NLU tasks in terms of noise intensity, error type and speaker
variants. We further purpose two ways, correction-based method and data
augmentation-based method to improve robustness of the NLU systems. Extensive
experimental results and analysises show that the proposed methods are
effective to some extent, but still far from human performance, demonstrating
that NLU under ASR error is still very challenging and requires further
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-to-Table: A New Way of Information Extraction. (arXiv:2109.02707v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02707">
<div class="article-summary-box-inner">
<span><p>We study a new problem setting of information extraction (IE), referred to as
text-to-table. In text-to-table, given a text, one creates a table or several
tables expressing the main content of the text, while the model is learned from
text-table pair data. The problem setting differs from those of the existing
methods for IE. First, the extraction can be carried out from long texts to
large tables with complex structures. Second, the extraction is entirely
data-driven, and there is no need to explicitly define the schemas. As far as
we know, there has been no previous work that studies the problem. In this
work, we formalize text-to-table as a sequence-to-sequence (seq2seq) problem.
We first employ a seq2seq model fine-tuned from a pre-trained language model to
perform the task. We also develop a new method within the seq2seq approach,
exploiting two additional techniques in table generation: table constraint and
table relation embeddings. We consider text-to-table as an inverse problem of
the well-studied table-to-text, and make use of four existing table-to-text
datasets in our experiments on text-to-table. Experimental results show that
the vanilla seq2seq model can outperform the baseline methods of using relation
extraction and named entity extraction. The results also show that our method
can further boost the performances of the vanilla seq2seq model. We further
discuss the main challenges of the proposed task. The code and data are
available at https://github.com/shirley-wu/text_to_table.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rare Tokens Degenerate All Tokens: Improving Neural Text Generation via Adaptive Gradient Gating for Rare Token Embeddings. (arXiv:2109.03127v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03127">
<div class="article-summary-box-inner">
<span><p>Recent studies have determined that the learned token embeddings of
large-scale neural language models are degenerated to be anisotropic with a
narrow-cone shape. This phenomenon, called the representation degeneration
problem, facilitates an increase in the overall similarity between token
embeddings that negatively affect the performance of the models. Although the
existing methods that address the degeneration problem based on observations of
the phenomenon triggered by the problem improves the performance of the text
generation, the training dynamics of token embeddings behind the degeneration
problem are still not explored. In this study, we analyze the training dynamics
of the token embeddings focusing on rare token embedding. We demonstrate that
the specific part of the gradient for rare token embeddings is the key cause of
the degeneration problem for all tokens during training stage. Based on the
analysis, we propose a novel method called, adaptive gradient gating (AGG). AGG
addresses the degeneration problem by gating the specific part of the gradient
for rare token embeddings. Experimental results from language modeling, word
similarity, and machine translation tasks quantitatively and qualitatively
verify the effectiveness of AGG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variational Latent-State GPT for Semi-supervised Task-Oriented Dialog Systems. (arXiv:2109.04314v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04314">
<div class="article-summary-box-inner">
<span><p>Recently, two approaches, fine-tuning large pre-trained language models and
variational training, have attracted significant interests, separately, for
semi-supervised end-to-end task-oriented dialog (TOD) systems. In this paper,
we propose Variational Latent-State GPT model (VLS-GPT), which is the first to
combine the strengths of the two approaches. Among many options of models, we
propose the generative model and the inference model for variational learning
of the end-to-end TOD system, both as auto-regressive language models based on
GPT-2, which can be further trained over a mix of labeled and unlabeled dialog
data in a semi-supervised manner. Variational training of VLS-GPT is both
statistically and computationally more challenging than previous variational
learning works for sequential latent variable models, which use turn-level
first-order Markovian. The inference model in VLS-GPT is non-Markovian due to
the use of the Transformer architecture. In this work, we establish Recursive
Monte Carlo Approximation (RMCA) to the variational objective with
non-Markovian inference model and prove its unbiasedness. Further, we develop
the computational strategy of sampling-then-forward-computation to realize
RMCA, which successfully overcomes the memory explosion issue of using GPT in
variational learning and speeds up training. Semi-supervised TOD experiments
are conducted on two benchmark multi-domain datasets of different languages -
MultiWOZ2.1 and CrossWOZ. VLS-GPT is shown to significantly outperform both
supervised-only and semi-supervised self-training baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reframing Instructional Prompts to GPTk's Language. (arXiv:2109.07830v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07830">
<div class="article-summary-box-inner">
<span><p>What kinds of instructional prompts are easier to follow for Language Models
(LMs)? We study this question by conducting extensive empirical analysis that
shed light on important features of successful instructional prompts.
Specifically, we study several classes of reframing techniques for manual
reformulation of prompts into more effective ones. Some examples include
decomposing a complex task instruction into multiple simpler tasks or itemizing
instructions into sequential steps. Our experiments compare the zero-shot and
few-shot performance of LMs prompted with reframed instructions on 12 NLP tasks
across 6 categories. Compared with original instructions, our reframed
instructions lead to significant improvements across LMs with different sizes.
For example, the same reframed prompts boost few-shot performance of
GPT3-series and GPT2-series by 12.5% and 6.7% respectively averaged over all
tasks. Furthermore, reframed instructions reduce the number of examples
required to prompt LMs in the few-shot setting. We hope these
empirically-driven techniques will pave the way towards more effective future
prompting algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PoNet: Pooling Network for Efficient Token Mixing in Long Sequences. (arXiv:2110.02442v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02442">
<div class="article-summary-box-inner">
<span><p>Transformer-based models have achieved great success in various NLP, vision,
and speech tasks. However, the core of Transformer, the self-attention
mechanism, has a quadratic time and memory complexity with respect to the
sequence length, which hinders applications of Transformer-based models to long
sequences. Many approaches have been proposed to mitigate this problem, such as
sparse attention mechanisms, low-rank matrix approximations and scalable
kernels, and token mixing alternatives to self-attention. We propose a novel
Pooling Network (PoNet) for token mixing in long sequences with linear
complexity. We design multi-granularity pooling and pooling fusion to capture
different levels of contextual information and combine their interactions with
tokens. On the Long Range Arena benchmark, PoNet significantly outperforms
Transformer and achieves competitive accuracy, while being only slightly slower
than the fastest model, FNet, across all sequence lengths measured on GPUs. We
also conduct systematic studies on the transfer learning capability of PoNet
and observe that PoNet achieves 95.7% of the accuracy of BERT on the GLUE
benchmark, outperforming FNet by 4.5% relative. Comprehensive ablation analysis
demonstrates effectiveness of the designed multi-granularity pooling and
pooling fusion for token mixing in long sequences and efficacy of the designed
pre-training tasks for PoNet to learn transferable contextualized language
representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compositional Generalization in Dependency Parsing. (arXiv:2110.06843v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06843">
<div class="article-summary-box-inner">
<span><p>Compositionality -- the ability to combine familiar units like words into
novel phrases and sentences -- has been the focus of intense interest in
artificial intelligence in recent years. To test compositional generalization
in semantic parsing, Keysers et al. (2020) introduced Compositional Freebase
Queries (CFQ). This dataset maximizes the similarity between the test and train
distributions over primitive units, like words, while maximizing the compound
divergence: the dissimilarity between test and train distributions over larger
structures, like phrases. Dependency parsing, however, lacks a compositional
generalization benchmark. In this work, we introduce a gold-standard set of
dependency parses for CFQ, and use this to analyze the behavior of a
state-of-the art dependency parser (Qi et al., 2020) on the CFQ dataset. We
find that increasing compound divergence degrades dependency parsing
performance, although not as dramatically as semantic parsing performance.
Additionally, we find the performance of the dependency parser does not
uniformly degrade relative to compound divergence, and the parser performs
differently on different splits with the same compound divergence. We explore a
number of hypotheses for what causes the non-uniform degradation in dependency
parsing performance, and identify a number of syntactic structures that drive
the dependency parser's lower performance on the most challenging splits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tracing Origins: Coreference-aware Machine Reading Comprehension. (arXiv:2110.07961v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07961">
<div class="article-summary-box-inner">
<span><p>Machine reading comprehension is a heavily-studied research and test field
for evaluating new pre-trained language models (PrLMs) and fine-tuning
strategies, and recent studies have enriched the pre-trained language models
with syntactic, semantic and other linguistic information to improve the
performance of the models. In this paper, we imitate the human reading process
in connecting the anaphoric expressions and explicitly leverage the coreference
information of the entities to enhance the word embeddings from the pre-trained
language model, in order to highlight the coreference mentions of the entities
that must be identified for coreference-intensive question answering in QUOREF,
a relatively new dataset that is specifically designed to evaluate the
coreference-related performance of a model. We use two strategies to fine-tune
a pre-trained language model, namely, placing an additional encoder layer after
a pre-trained language model to focus on the coreference mentions or
constructing a relational graph convolutional network to model the coreference
relations. We demonstrate that the explicit incorporation of coreference
information in the fine-tuning stage performs better than the incorporation of
the coreference information in pre-training a language model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BBQ: A Hand-Built Bias Benchmark for Question Answering. (arXiv:2110.08193v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08193">
<div class="article-summary-box-inner">
<span><p>It is well documented that NLP models learn social biases, but little work
has been done on how these biases manifest in model outputs for applied tasks
like question answering (QA). We introduce the Bias Benchmark for QA (BBQ), a
dataset of question sets constructed by the authors that highlight attested
social biases against people belonging to protected classes along nine social
dimensions relevant for U.S. English-speaking contexts. Our task evaluates
model responses at two levels: (i) given an under-informative context, we test
how strongly responses reflect social biases, and (ii) given an adequately
informative context, we test whether the model's biases override a correct
answer choice. We find that models often rely on stereotypes when the context
is under-informative, meaning the model's outputs consistently reproduce
harmful biases in this setting. Though models are more accurate when the
context provides an informative answer, they still rely on stereotypes and
average up to 3.4 percentage points higher accuracy when the correct answer
aligns with a social bias than when it conflicts, with this difference widening
to over 5 points on examples targeting gender for most models tested.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coherence boosting: When your pretrained language model is not paying enough attention. (arXiv:2110.08294v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08294">
<div class="article-summary-box-inner">
<span><p>Long-range semantic coherence remains a challenge in automatic language
generation and understanding. We demonstrate that large language models have
insufficiently learned the effect of distant words on next-token prediction. We
present coherence boosting, an inference procedure that increases a LM's focus
on a long context. We show the benefits of coherence boosting with pretrained
models by distributional analyses of generated ordinary text and dialog
responses. It is also found that coherence boosting with state-of-the-art
models for various zero-shot NLP tasks yields performance gains with no
additional training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Procedural Knowledge by Sequencing Multimodal Instructional Manuals. (arXiv:2110.08486v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08486">
<div class="article-summary-box-inner">
<span><p>The ability to sequence unordered events is an essential skill to comprehend
and reason about real world task procedures, which often requires thorough
understanding of temporal common sense and multimodal information, as these
procedures are often communicated through a combination of texts and images.
Such capability is essential for applications such as sequential task planning
and multi-source instruction summarization. While humans are capable of
reasoning about and sequencing unordered multimodal procedural instructions,
whether current machine learning models have such essential capability is still
an open question. In this work, we benchmark models' capability of reasoning
over and sequencing unordered multimodal instructions by curating datasets from
popular online instructional manuals and collecting comprehensive human
annotations. We find models not only perform significantly worse than humans
but also seem incapable of efficiently utilizing the multimodal information. To
improve machines' performance on multimodal event sequencing, we propose
sequentiality-aware pretraining techniques that exploit the sequential
alignment properties of both texts and images, resulting in &gt; 5% significant
improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sharpness-Aware Minimization Improves Language Model Generalization. (arXiv:2110.08529v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08529">
<div class="article-summary-box-inner">
<span><p>The allure of superhuman-level capabilities has led to considerable interest
in language models like GPT-3 and T5, wherein the research has, by and large,
revolved around new model architectures, training tasks, and loss objectives,
along with substantial engineering efforts to scale up model capacity and
dataset size. Comparatively little work has been done to improve the
generalization of these models through better optimization. In this work, we
show that Sharpness-Aware Minimization (SAM), a recently proposed optimization
procedure that encourages convergence to flatter minima, can substantially
improve the generalization of language models without much computational
overhead. We show that SAM is able to boost performance on SuperGLUE, GLUE, Web
Questions, Natural Questions, Trivia QA, and TyDiQA, with particularly large
gains when training data for these tasks is limited.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Efficiency Misnomer. (arXiv:2110.12894v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12894">
<div class="article-summary-box-inner">
<span><p>Model efficiency is a critical aspect of developing and deploying machine
learning models. Inference time and latency directly affect the user
experience, and some applications have hard requirements. In addition to
inference costs, model training also have direct financial and environmental
impacts. Although there are numerous well-established metrics (cost indicators)
for measuring model efficiency, researchers and practitioners often assume that
these metrics are correlated with each other and report only few of them. In
this paper, we thoroughly discuss common cost indicators, their advantages and
disadvantages, and how they can contradict each other. We demonstrate how
incomplete reporting of cost indicators can lead to partial conclusions and a
blurred or incomplete picture of the practical considerations of different
models. We further present suggestions to improve reporting of efficiency
metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Cross-Lingual Machine Reading Comprehension via Inter-sentence Dependency Graph. (arXiv:2112.00503v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00503">
<div class="article-summary-box-inner">
<span><p>We target the task of cross-lingual Machine Reading Comprehension (MRC) in
the direct zero-shot setting, by incorporating syntactic features from
Universal Dependencies (UD), and the key features we use are the syntactic
relations within each sentence. While previous work has demonstrated effective
syntax-guided MRC models, we propose to adopt the inter-sentence syntactic
relations, in addition to the rudimentary intra-sentence relations, to further
utilize the syntactic dependencies in the multi-sentence input of the MRC task.
In our approach, we build the Inter-Sentence Dependency Graph (ISDG) connecting
dependency trees to form global syntactic relations across sentences. We then
propose the ISDG encoder that encodes the global dependency graph, addressing
the inter-sentence relations via both one-hop and multi-hop dependency paths
explicitly. Experiments on three multilingual MRC datasets (XQuAD, MLQA,
TyDiQA-GoldP) show that our encoder that is only trained on English is able to
improve the zero-shot performance on all 14 test sets covering 8 languages,
with up to 3.8 F1 / 5.2 EM improvement on-average, and 5.2 F1 / 11.2 EM on
certain languages. Further analysis shows the improvement can be attributed to
the attention on the cross-linguistically consistent syntactic path.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sharpness-Aware Minimization with Dynamic Reweighting. (arXiv:2112.08772v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08772">
<div class="article-summary-box-inner">
<span><p>Deep neural networks are often overparameterized and may not easily achieve
model generalization. Adversarial training has shown effectiveness in improving
generalization by regularizing the change of loss on top of adversarially
chosen perturbations. The recently proposed sharpness-aware minimization (SAM)
algorithm conducts adversarial weight perturbation, encouraging the model to
converge to a flat minima. Unfortunately, due to increased computational cost,
adversarial weight perturbation can only be efficiently estimated per-batch
instead of per-instance by SAM, leading to degraded performance. In this paper,
we tackle this efficiency bottleneck and propose the first instance-based
weight perturbation method: sharpness-aware minimization with dynamic
reweighting ({\delta}-SAM). {\delta}-SAM dynamically reweights perturbation
within each batch by estimated guardedness (i.e. unguarded instances are
up-weighted), serving as a better approximation to per-instance perturbation.
Experiments on various tasks demonstrate the effectiveness of {\delta}-SAM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation Leakage in Elicited Natural Language Inference Datasets. (arXiv:2112.09237v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.09237">
<div class="article-summary-box-inner">
<span><p>Natural language inference (NLI) is an important task for producing useful
models of human language. Unfortunately large-scale NLI dataset production
relies on crowdworkers who are prone to introduce biases in the sentences they
write, enabling models to predict sentence pair relations from a single
sentence in the pair, better than chance. This elicited sentence relation
leakage property is undesirable as it enables models to cheat rather than learn
the desired reasoning capabilities, and hasn't gone away since its 2018
discovery. We analyze this problem in 8 modern NLI datasets, using a
combination of previously established and novel model-based techniques, so as
to enable ameliorating this leakage in future NLI datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Stage Episodic Control for Strategic Exploration in Text Games. (arXiv:2201.01251v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01251">
<div class="article-summary-box-inner">
<span><p>Text adventure games present unique challenges to reinforcement learning
methods due to their combinatorially large action spaces and sparse rewards.
The interplay of these two factors is particularly demanding because large
action spaces require extensive exploration, while sparse rewards provide
limited feedback. This work proposes to tackle the explore-vs-exploit dilemma
using a multi-stage approach that explicitly disentangles these two strategies
within each episode. Our algorithm, called eXploit-Then-eXplore (XTX), begins
each episode using an exploitation policy that imitates a set of promising
trajectories from the past, and then switches over to an exploration policy
aimed at discovering novel actions that lead to unseen state spaces. This
policy decomposition allows us to combine global decisions about which parts of
the game space to return to with curiosity-based local exploration in that
space, motivated by how a human may approach these games. Our method
significantly outperforms prior approaches by 27% and 11% average normalized
score over 12 games from the Jericho benchmark (Hausknecht et al., 2020) in
both deterministic and stochastic settings, respectively. On the game of Zork1,
in particular, XTX obtains a score of 103, more than a 2x improvement over
prior methods, and pushes past several known bottlenecks in the game that have
plagued previous state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02639">
<div class="article-summary-box-inner">
<span><p>As humans, we navigate a multimodal world, building a holistic understanding
from all our senses. We introduce MERLOT Reserve, a model that represents
videos jointly over time -- through a new training objective that learns from
audio, subtitles, and video frames. Given a video, we replace snippets of text
and audio with a MASK token; the model learns by choosing the correct
masked-out snippet. Our objective learns faster than alternatives, and performs
well at scale: we pretrain on 20 million YouTube videos.
</p>
<p>Empirical results show that MERLOT Reserve learns strong multimodal
representations. When finetuned, it sets state-of-the-art on Visual Commonsense
Reasoning (VCR), TVQA, and Kinetics-600; outperforming prior work by 5%, 7%,
and 1.5% respectively. Ablations show that these tasks benefit from audio
pretraining -- even VCR, a QA task centered around images (without sound).
Moreover, our objective enables out-of-the-box prediction, revealing strong
multimodal commonsense understanding. In a fully zero-shot setting, our model
obtains competitive results on four video tasks, even outperforming supervised
approaches on the recently proposed Situated Reasoning (STAR) benchmark.
</p>
<p>We analyze why audio enables better vision-language representations,
suggesting significant opportunities for future research. We conclude by
discussing ethical and societal implications of multimodal pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Memory-assisted prompt editing to improve GPT-3 after deployment. (arXiv:2201.06009v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.06009">
<div class="article-summary-box-inner">
<span><p>Large LMs such as GPT-3 are powerful, but can commit mistakes that are
obvious to humans. For example, GPT-3 would mistakenly interpret "What word is
similar to good?" to mean a homonym, while the user intended a synonym. Our
goal is to effectively correct such errors via user interactions with the
system but without retraining, which will be prohibitively costly. We pair
GPT-3 with a growing memory of recorded cases where the model misunderstood the
user's intents, along with user feedback for clarification. Such a memory
allows our system to produce enhanced prompts for any new query based on the
user feedback for error correction on similar cases in the past. On four tasks
(two lexical tasks, two advanced ethical reasoning tasks), we show how a
(simulated) user can interactively teach a deployed GPT-3, substantially
increasing its accuracy over the queries with different kinds of
misunderstandings by the GPT-3. Our approach is a step towards the low-cost
utility enhancement for very large pre-trained LMs. All the code and data is
available at https://github.com/madaan/memprompt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pair-Level Supervised Contrastive Learning for Natural Language Inference. (arXiv:2201.10927v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10927">
<div class="article-summary-box-inner">
<span><p>Natural language inference (NLI) is an increasingly important task for
natural language understanding, which requires one to infer the relationship
between the sentence pair (premise and hypothesis). Many recent works have used
contrastive learning by incorporating the relationship of the sentence pair
from NLI datasets to learn sentence representation. However, these methods only
focus on comparisons with sentence-level representations. In this paper, we
propose a Pair-level Supervised Contrastive Learning approach (PairSCL). We
adopt a cross attention module to learn the joint representations of the
sentence pairs. A contrastive learning objective is designed to distinguish the
varied classes of sentence pairs by pulling those in one class together and
pushing apart the pairs in other classes. We evaluate PairSCL on two public
datasets of NLI where the accuracy of PairSCL outperforms other methods by 2.1%
on average. Furthermore, our method outperforms the previous state-of-the-art
method on seven transfer tasks of text classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SGPT: GPT Sentence Embeddings for Semantic Search. (arXiv:2202.08904v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08904">
<div class="article-summary-box-inner">
<span><p>GPT transformers are the largest language models available, yet semantic
search is dominated by BERT transformers. We present SGPT-BE and SGPT-CE for
applying GPT models as Bi-Encoders or Cross-Encoders to symmetric or asymmetric
search.
</p>
<p>SGPT-BE produces semantically meaningful sentence embeddings by contrastive
fine-tuning of only bias tensors and a novel pooling method. A 5.8 billion
parameter SGPT-BE outperforms the best available sentence embeddings by 6%
setting a new state-of-the-art on BEIR. It outperforms the concurrently
proposed OpenAI Embeddings of the 175B Davinci endpoint, which fine-tunes
250,000 times more parameters.
</p>
<p>SGPT-CE uses log probabilities from GPT models without any fine-tuning. A 6.1
billion parameter SGPT-CE sets an unsupervised state-of-the-art on BEIR. It
beats the supervised state-of-the-art on 7 datasets, but significantly loses on
other datasets. We show how this can be alleviated by adapting the prompt.
</p>
<p>SGPT-BE and SGPT-CE performance scales with model size. Yet, increased
latency, storage and compute costs should be considered. Code, models and
result files are freely available at https://github.com/Muennighoff/sgpt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Impact of Negative Samples of Contrastive Learning: A Case Study of Sentence Embedding. (arXiv:2202.13093v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.13093">
<div class="article-summary-box-inner">
<span><p>Contrastive learning is emerging as a powerful technique for extracting
knowledge from unlabeled data. This technique requires a balanced mixture of
two ingredients: positive (similar) and negative (dissimilar) samples. This is
typically achieved by maintaining a queue of negative samples during training.
Prior works in the area typically uses a fixed-length negative sample queue,
but how the negative sample size affects the model performance remains unclear.
The opaque impact of the number of negative samples on performance when
employing contrastive learning aroused our in-depth exploration. This paper
presents a momentum contrastive learning model with negative sample queue for
sentence embedding, namely MoCoSE. We add the prediction layer to the online
branch to make the model asymmetric and together with EMA update mechanism of
the target branch to prevent the model from collapsing. We define a maximum
traceable distance metric, through which we learn to what extent the text
contrastive learning benefits from the historical information of negative
samples. Our experiments find that the best results are obtained when the
maximum traceable distance is at a certain range, demonstrating that there is
an optimal range of historical information for a negative sample queue. We
evaluate the proposed unsupervised MoCoSE on the semantic text similarity (STS)
task and obtain an average Spearman's correlation of $77.27\%$. Source code is
available at https://github.com/xbdxwyh/mocose.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The impact of lexical and grammatical processing on generating code from natural language. (arXiv:2202.13972v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.13972">
<div class="article-summary-box-inner">
<span><p>Considering the seq2seq architecture of TranX for natural language to code
translation, we identify four key components of importance: grammatical
constraints, lexical preprocessing, input representations, and copy mechanisms.
To study the impact of these components, we use a state-of-the-art architecture
that relies on BERT encoder and a grammar-based decoder for which a
formalization is provided. The paper highlights the importance of the lexical
substitution component in the current natural language to code systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structure Extraction in Task-Oriented Dialogues with Slot Clustering. (arXiv:2203.00073v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.00073">
<div class="article-summary-box-inner">
<span><p>Extracting structure information from dialogue data can help us better
understand user and system behaviors. In task-oriented dialogues, dialogue
structure has often been considered as transition graphs among dialogue states.
However, annotating dialogue states manually is expensive and time-consuming.
In this paper, we propose a simple yet effective approach for structure
extraction in task-oriented dialogues. We first detect and cluster possible
slot tokens with a pre-trained model to approximate dialogue ontology for a
target domain. Then we track the status of each identified token group and
derive a state transition structure. Empirical results show that our approach
outperforms unsupervised baseline models by far in dialogue structure
extraction. In addition, we show that data augmentation based on extracted
structures enriches the surface formats of training data and can achieve a
significant performance boost in dialogue response generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mukayese: Turkish NLP Strikes Back. (arXiv:2203.01215v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01215">
<div class="article-summary-box-inner">
<span><p>Having sufficient resources for language X lifts it from the under-resourced
languages class, but not necessarily from the under-researched class. In this
paper, we address the problem of the absence of organized benchmarks in the
Turkish language. We demonstrate that languages such as Turkish are left behind
the state-of-the-art in NLP applications. As a solution, we present Mukayese, a
set of NLP benchmarks for the Turkish language that contains several NLP tasks.
We work on one or more datasets for each benchmark and present two or more
baselines. Moreover, we present four new benchmarking datasets in Turkish for
language modeling, sentence segmentation, and spell checking. All datasets and
baselines are available under: https://github.com/alisafaya/mukayese
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Iterative Revision from Human-Written Text. (arXiv:2203.03802v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03802">
<div class="article-summary-box-inner">
<span><p>Writing is, by nature, a strategic, adaptive, and more importantly, an
iterative process. A crucial part of writing is editing and revising the text.
Previous works on text revision have focused on defining edit intention
taxonomies within a single domain or developing computational models with a
single level of edit granularity, such as sentence-level edits, which differ
from human's revision cycles. This work describes IteraTeR: the first
large-scale, multi-domain, edit-intention annotated corpus of iteratively
revised text. In particular, IteraTeR is collected based on a new framework to
comprehensively model the iterative text revisions that generalize to various
domains of formal writing, edit intentions, revision depths, and granularities.
When we incorporate our annotated edit intentions, both generative and
edit-based text revision models significantly improve automatic evaluations.
Through our work, we better understand the text revision process, making vital
connections between edit intentions and writing quality, enabling the creation
of diverse corpora to support computational modeling of iterative text
revisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sense Embeddings are also Biased--Evaluating Social Biases in Static and Contextualised Sense Embeddings. (arXiv:2203.07523v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07523">
<div class="article-summary-box-inner">
<span><p>Sense embedding learning methods learn different embeddings for the different
senses of an ambiguous word. One sense of an ambiguous word might be socially
biased while its other senses remain unbiased. In comparison to the numerous
prior work evaluating the social biases in pretrained word embeddings, the
biases in sense embeddings have been relatively understudied. We create a
benchmark dataset for evaluating the social biases in sense embeddings and
propose novel sense-specific bias evaluation measures. We conduct an extensive
evaluation of multiple static and contextualised sense embeddings for various
types of social biases using the proposed measures. Our experimental results
show that even in cases where no biases are found at word-level, there still
exist worrying levels of social biases at sense-level, which are often ignored
by the word-level bias evaluation measures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seamlessly Integrating Factual Information and Social Content with Persuasive Dialogue. (arXiv:2203.07657v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07657">
<div class="article-summary-box-inner">
<span><p>Effective human-chatbot conversations need to achieve both coherence and
efficiency. Complex conversation settings such as persuasion involve
communicating changes in attitude or behavior, so users' perspectives need to
be carefully considered and addressed, even when not directly related to the
topic. In this work, we contribute a novel modular dialogue system framework
that seamlessly integrates factual information and social content into
persuasive dialogue. Our framework is generalizable to any dialogue tasks that
have mixed social and task contents. We conducted a study that compared user
evaluations of our framework versus a baseline end-to-end generation model. We
found our model was evaluated to be more favorable in all dimensions including
competence and friendliness compared to the baseline model which does not
explicitly handle social content or factual questions.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Energy-Latency Attacks via Sponge Poisoning. (arXiv:2203.08147v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08147">
<div class="article-summary-box-inner">
<span><p>Sponge examples are test-time inputs carefully-optimized to increase energy
consumption and latency of neural networks when deployed on hardware
accelerators. In this work, we demonstrate that sponge attacks can also be
implanted at training time, when model training is outsourced to a third party,
via an attack that we call sponge poisoning. This attack allows one to increase
the energy consumption and latency of machine-learning models indiscriminately
on each test-time input. We present a novel formalization for sponge poisoning,
overcoming the limitations related to the optimization of test-time sponge
examples, and show that this attack is possible even if the attacker only
controls a few poisoning samples and model updates. Our extensive experimental
analysis, involving two deep learning architectures and three datasets, shows
that sponge poisoning can almost completely vanish the effect of such hardware
accelerators. Finally, we analyze activations of the resulting sponge models,
identifying the module components that are more sensitive to this
vulnerability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UNet Architectures in Multiplanar Volumetric Segmentation -- Validated on Three Knee MRI Cohorts. (arXiv:2203.08194v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08194">
<div class="article-summary-box-inner">
<span><p>UNet has become the gold standard method for segmenting 2D medical images
that any new method must be validated against. However, in recent years,
several variations of the seminal UNet have been proposed with promising
results. However, there is no clear consensus on the generalisability of these
architectures, and UNet currently remains the methodological gold standard. The
purpose of this study was to evaluate some of the most promising UNet-inspired
architectures for 3D segmentation. For the segmentation of 3D scans,
UNet-inspired methods are also dominant, but there is a larger variety across
applications. By evaluating the architectures in a different dimensionality,
embedded in a different method, and for a different task, we aimed to evaluate
if any of these UNet-alternatives are promising as a new gold standard that
generalizes even better than UNet. Specifically, we investigated the
architectures as the central 2D segmentation core in the Multi-Planar Unet 3D
segmentation method that previously demonstrated excellent generalization in
the MICCAI Segmentation Decathlon. Generalisability can be demonstrated if a
promising UNet-variant consistently outperforms UNet in this setting. For this
purpose, we evaluated four architectures for cartilage segmentation from three
different cohorts with knee MRIs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection. (arXiv:2203.08195v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08195">
<div class="article-summary-box-inner">
<span><p>Lidars and cameras are critical sensors that provide complementary
information for 3D detection in autonomous driving. While prevalent multi-modal
methods simply decorate raw lidar point clouds with camera features and feed
them directly to existing 3D detection models, our study shows that fusing
camera features with deep lidar features instead of raw points, can lead to
better performance. However, as those features are often augmented and
aggregated, a key challenge in fusion is how to effectively align the
transformed features from two modalities. In this paper, we propose two novel
techniques: InverseAug that inverses geometric-related augmentations, e.g.,
rotation, to enable accurate geometric alignment between lidar points and image
pixels, and LearnableAlign that leverages cross-attention to dynamically
capture the correlations between image and lidar features during fusion. Based
on InverseAug and LearnableAlign, we develop a family of generic multi-modal 3D
detection models named DeepFusion, which is more accurate than previous
methods. For example, DeepFusion improves PointPillars, CenterPoint, and 3D-MAN
baselines on Pedestrian detection for 6.7, 8.9, and 6.2 LEVEL_2 APH,
respectively. Notably, our models achieve state-of-the-art performance on Waymo
Open Dataset, and show strong model robustness against input corruptions and
out-of-distribution data. Code will be publicly available at
https://github.com/tensorflow/lingvo/tree/master/lingvo/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SocialVAE: Human Trajectory Prediction using Timewise Latents. (arXiv:2203.08207v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08207">
<div class="article-summary-box-inner">
<span><p>Predicting pedestrian movement is critical for human behavior analysis and
also for safe and efficient human-agent interactions. However, despite
significant advancements, it is still challenging for existing approaches to
capture the uncertainty and multimodality of human navigation decision making.
In this paper, we propose SocialVAE, a novel approach for human trajectory
prediction. The core of SocialVAE is a timewise variational autoencoder
architecture that exploits stochastic recurrent neural networks to perform
prediction, combined with a social attention mechanism and backward posterior
approximation to allow for better extraction of pedestrian navigation
strategies. We show that SocialVAE improves current state-of-the-art
performance on several pedestrian trajectory prediction benchmarks, including
the ETH/UCY benchmark, the Stanford Drone Dataset and SportVU NBA movement
dataset. Code is available at: {\tt https://github.com/xupei0610/SocialVAE}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HUMUS-Net: Hybrid unrolled multi-scale network architecture for accelerated MRI reconstruction. (arXiv:2203.08213v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08213">
<div class="article-summary-box-inner">
<span><p>In accelerated MRI reconstruction, the anatomy of a patient is recovered from
a set of under-sampled and noisy measurements. Deep learning approaches have
been proven to be successful in solving this ill-posed inverse problem and are
capable of producing very high quality reconstructions. However, current
architectures heavily rely on convolutions, that are content-independent and
have difficulties modeling long-range dependencies in images. Recently,
Transformers, the workhorse of contemporary natural language processing, have
emerged as powerful building blocks for a multitude of vision tasks. These
models split input images into non-overlapping patches, embed the patches into
lower-dimensional tokens and utilize a self-attention mechanism that does not
suffer from the aforementioned weaknesses of convolutional architectures.
However, Transformers incur extremely high compute and memory cost when 1) the
input image resolution is high and 2) when the image needs to be split into a
large number of patches to preserve fine detail information, both of which are
typical in low-level vision problems such as MRI reconstruction, having a
compounding effect. To tackle these challenges, we propose HUMUS-Net, a hybrid
architecture that combines the beneficial implicit bias and efficiency of
convolutions with the power of Transformer blocks in an unrolled and
multi-scale network. HUMUS-Net extracts high-resolution features via
convolutional blocks and refines low-resolution features via a novel
Transformer-based multi-scale feature extractor. Features from both levels are
then synthesized into a high-resolution output reconstruction. Our network
establishes new state of the art on the largest publicly available MRI dataset,
the fastMRI dataset. We further demonstrate the performance of HUMUS-Net on two
other popular MRI datasets and perform fine-grained ablation studies to
validate our design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auto-Gait: Automatic Ataxia Risk Assessment with Computer Vision on Gait Task Videos. (arXiv:2203.08215v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08215">
<div class="article-summary-box-inner">
<span><p>In this paper, we investigated whether we can 1) detect participants with
ataxia-specific gait characteristics (risk-prediction), and 2) assess severity
of ataxia from gait (severity-assessment). We collected 155 videos from 89
participants, 24 controls and 65 diagnosed with (or are pre-manifest)
spinocerebellar ataxias (SCAs), performing the gait task of the Scale for the
Assessment and Rating of Ataxia (SARA) from 11 medical sites located in 8
different states in the United States. We developed a method to separate the
participants from their surroundings and constructed several features to
capture gait characteristics like step width, step length, swing, stability,
speed, etc. Our risk-prediction model achieves 83.06% accuracy and an 80.23% F1
score. Similarly, our severity-assessment model achieves a mean absolute error
(MAE) score of 0.6225 and a Pearson's correlation coefficient score of 0.7268.
Our models still performed competitively when evaluated on data from sites not
used during training. Furthermore, through feature importance analysis, we
found that our models associate wider steps, decreased walking speed, and
increased instability with greater ataxia severity, which is consistent with
previously established clinical knowledge. Our models create possibilities for
remote ataxia assessment in non-clinical settings in the future, which could
significantly improve accessibility of ataxia care. Furthermore, our underlying
dataset was assembled from a geographically diverse cohort, highlighting its
potential to further increase equity. The code used in this study is open to
the public, and the anonymized body pose landmark dataset could be released
upon approval from our Institutional Review Board (IRB).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Portrait Harmonization. (arXiv:2203.08216v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08216">
<div class="article-summary-box-inner">
<span><p>Current image harmonization methods consider the entire background as the
guidance for harmonization. However, this may limit the capability for user to
choose any specific object/person in the background to guide the harmonization.
To enable flexible interaction between user and harmonization, we introduce
interactive harmonization, a new setting where the harmonization is performed
with respect to a selected \emph{region} in the reference image instead of the
entire background. A new flexible framework that allows users to pick certain
regions of the background image and use it to guide the harmonization is
proposed. Inspired by professional portrait harmonization users, we also
introduce a new luminance matching loss to optimally match the color/luminance
conditions between the composite foreground and select reference region. This
framework provides more control to the image harmonization pipeline achieving
visually pleasing portrait edits. Furthermore, we also introduce a new dataset
carefully curated for validating portrait harmonization. Extensive experiments
on both synthetic and real-world datasets show that the proposed approach is
efficient and robust compared to previous harmonization baselines, especially
for portraits. Project Webpage at
\href{https://jeya-maria-jose.github.io/IPH-web/}{https://jeya-maria-jose.github.io/IPH-web/}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CrowdMLP: Weakly-Supervised Crowd Counting via Multi-Granularity MLP. (arXiv:2203.08219v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08219">
<div class="article-summary-box-inner">
<span><p>Existing state-of-the-art crowd counting algorithms rely excessively on
location-level annotations, which are burdensome to acquire. When only
count-level (weak) supervisory signals are available, it is arduous and
error-prone to regress total counts due to the lack of explicit spatial
constraints. To address this issue, a novel and efficient counter (referred to
as CrowdMLP) is presented, which probes into modelling global dependencies of
embeddings and regressing total counts by devising a multi-granularity MLP
regressor. In specific, a locally-focused pre-trained frontend is cascaded to
extract crude feature maps with intrinsic spatial cues, which prevent the model
from collapsing into trivial outcomes. The crude embeddings, along with raw
crowd scenes, are tokenized at different granularity levels. The
multi-granularity MLP then proceeds to mix tokens at the dimensions of
cardinality, channel, and spatial for mining global information. An effective
proxy task, namely Split-Counting, is also proposed to evade the barrier of
limited samples and the shortage of spatial hints in a self-supervised manner.
Extensive experiments demonstrate that CrowdMLP significantly outperforms
existing weakly-supervised counting algorithms and performs on par with
state-of-the-art location-level supervised approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Deep Dive into Dataset Imbalance and Bias in Face Identification. (arXiv:2203.08235v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08235">
<div class="article-summary-box-inner">
<span><p>As the deployment of automated face recognition (FR) systems proliferates,
bias in these systems is not just an academic question, but a matter of public
concern. Media portrayals often center imbalance as the main source of bias,
i.e., that FR models perform worse on images of non-white people or women
because these demographic groups are underrepresented in training data. Recent
academic research paints a more nuanced picture of this relationship. However,
previous studies of data imbalance in FR have focused exclusively on the face
verification setting, while the face identification setting has been largely
ignored, despite being deployed in sensitive applications such as law
enforcement. This is an unfortunate omission, as 'imbalance' is a more complex
matter in identification; imbalance may arise in not only the training data,
but also the testing data, and furthermore may affect the proportion of
identities belonging to each demographic group or the number of images
belonging to each identity. In this work, we address this gap in the research
by thoroughly exploring the effects of each kind of imbalance possible in face
identification, and discuss other factors which may impact bias in this
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Visual Transformer Compression. (arXiv:2203.08243v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08243">
<div class="article-summary-box-inner">
<span><p>Vision transformers (ViTs) have gained popularity recently. Even without
customized image operators such as convolutions, ViTs can yield competitive
performance when properly trained on massive data. However, the computational
overhead of ViTs remains prohibitive, due to stacking multi-head self-attention
modules and else. Compared to the vast literature and prevailing success in
compressing convolutional neural networks, the study of Vision Transformer
compression has also just emerged, and existing works focused on one or two
aspects of compression. This paper proposes a unified ViT compression framework
that seamlessly assembles three effective techniques: pruning, layer skipping,
and knowledge distillation. We formulate a budget-constrained, end-to-end
optimization framework, targeting jointly learning model weights, layer-wise
pruning ratios/masks, and skip configurations, under a distillation loss. The
optimization problem is then solved using the primal-dual algorithm.
Experiments are conducted with several ViT variants, e.g. DeiT and T2T-ViT
backbones on the ImageNet dataset, and our approach consistently outperforms
recent competitors. For example, DeiT-Tiny can be trimmed down to 50\% of the
original FLOPs almost without losing accuracy. Codes are available
online:~\url{https://github.com/VITA-Group/UVC}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">2-speed network ensemble for efficient classification of incremental land-use/land-cover satellite image chips. (arXiv:2203.08267v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08267">
<div class="article-summary-box-inner">
<span><p>The ever-growing volume of satellite imagery data presents a challenge for
industry and governments making data-driven decisions based on the timely
analysis of very large data sets. Commonly used deep learning algorithms for
automatic classification of satellite images are time and resource-intensive to
train. The cost of retraining in the context of Big Data presents a practical
challenge when new image data and/or classes are added to a training corpus.
Recognizing the need for an adaptable, accurate, and scalable satellite image
chip classification scheme, in this research we present an ensemble of: i) a
slow to train but high accuracy vision transformer; and ii) a fast to train,
low-parameter convolutional neural network. The vision transformer model
provides a scalable and accurate foundation model. The high-speed CNN provides
an efficient means of incorporating newly labelled data into analysis, at the
expense of lower accuracy. To simulate incremental data, the very large
(~400,000 images) So2Sat LCZ42 satellite image chip dataset is divided into
four intervals, with the high-speed CNN retrained every interval and the vision
transformer trained every half interval. This experimental setup mimics an
increase in data volume and diversity over time. For the task of automated
land-cover/land-use classification, the ensemble models for each data increment
outperform each of the component models, with best accuracy of 65% against a
holdout test partition of the So2Sat dataset. The proposed ensemble and
staggered training schedule provide a scalable and cost-effective satellite
image classification scheme that is optimized to process very large volumes of
satellite data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Driving Anomaly Detection Using Conditional Generative Adversarial Network. (arXiv:2203.08289v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08289">
<div class="article-summary-box-inner">
<span><p>Anomaly driving detection is an important problem in advanced driver
assistance systems (ADAS). It is important to identify potential hazard
scenarios as early as possible to avoid potential accidents. This study
proposes an unsupervised method to quantify driving anomalies using a
conditional generative adversarial network (GAN). The approach predicts
upcoming driving scenarios by conditioning the models on the previously
observed signals. The system uses the difference of the output from the
discriminator between the predicted and actual signals as a metric to quantify
the anomaly degree of a driving segment. We take a driver-centric approach,
considering physiological signals from the driver and controller area
network-Bus (CAN-Bus) signals from the vehicle. The approach is implemented
with convolutional neural networks (CNNs) to extract discriminative feature
representations, and with long short-term memory (LSTM) cells to capture
temporal information. The study is implemented and evaluated with the driving
anomaly dataset (DAD), which includes 250 hours of naturalistic recordings
manually annotated with driving events. The experimental results reveal that
recordings annotated with events that are likely to be anomalous, such as
avoiding on-road pedestrians and traffic rule violations, have higher anomaly
scores than recordings without any event annotation. The results are validated
with perceptual evaluations, where annotators are asked to assess the risk and
familiarity of the videos detected with high anomaly scores. The results
indicate that the driving segments with higher anomaly scores are more risky
and less regularly seen on the road than other driving segments, validating the
proposed unsupervised approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An explainability framework for cortical surface-based deep learning. (arXiv:2203.08312v1 [q-bio.NC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08312">
<div class="article-summary-box-inner">
<span><p>The emergence of explainability methods has enabled a better comprehension of
how deep neural networks operate through concepts that are easily understood
and implemented by the end user. While most explainability methods have been
designed for traditional deep learning, some have been further developed for
geometric deep learning, in which data are predominantly represented as graphs.
These representations are regularly derived from medical imaging data,
particularly in the field of neuroimaging, in which graphs are used to
represent brain structural and functional wiring patterns (brain connectomes)
and cortical surface models are used to represent the anatomical structure of
the brain. Although explainability techniques have been developed for
identifying important vertices (brain areas) and features for graph
classification, these methods are still lacking for more complex tasks, such as
surface-based modality transfer (or vertex-wise regression). Here, we address
the need for surface-based explainability approaches by developing a framework
for cortical surface-based deep learning, providing a transparent system for
modality transfer tasks. First, we adapted a perturbation-based approach for
use with surface data. Then, we applied our perturbation-based method to
investigate the key features and vertices used by a geometric deep learning
model developed to predict brain function from anatomy directly on a cortical
surface model. We show that our explainability framework is not only able to
identify important features and their spatial location but that it is also
reliable and valid.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Motif Mining: Finding and Summarizing Remixed Image Content. (arXiv:2203.08327v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08327">
<div class="article-summary-box-inner">
<span><p>On the internet, images are no longer static; they have become dynamic
content. Thanks to the availability of smartphones with cameras and easy-to-use
editing software, images can be remixed (i.e., redacted, edited, and recombined
with other content) on-the-fly and with a world-wide audience that can repeat
the process. From digital art to memes, the evolution of images through time is
now an important topic of study for digital humanists, social scientists, and
media forensics specialists. However, because typical data sets in computer
vision are composed of static content, the development of automated algorithms
to analyze remixed content has been limited. In this paper, we introduce the
idea of Motif Mining - the process of finding and summarizing remixed image
content in large collections of unlabeled and unsorted data. In this paper,
this idea is formalized and a reference implementation is introduced.
Experiments are conducted on three meme-style data sets, including a newly
collected set associated with the information war in the Russo-Ukrainian
conflict. The proposed motif mining approach is able to identify related
remixed content that, when compared to similar approaches, more closely aligns
with the preferences and expectations of human observers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection. (arXiv:2203.08332v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08332">
<div class="article-summary-box-inner">
<span><p>Monocular 3D object detection is one of the most challenging tasks in 3D
scene understanding. Due to the ill-posed nature of monocular imagery, existing
monocular 3D detection methods highly rely on training with the manually
annotated 3D box labels on the LiDAR point clouds. This annotation process is
very laborious and expensive. To dispense with the reliance on 3D box labels,
in this paper we explore the weakly supervised monocular 3D detection.
Specifically, we first detect 2D boxes on the image. Then, we adopt the
generated 2D boxes to select corresponding RoI LiDAR points as the weak
supervision. Eventually, we adopt a network to predict 3D boxes which can
tightly align with associated RoI LiDAR points. This network is learned by
minimizing our newly-proposed 3D alignment loss between the 3D box estimates
and the corresponding RoI LiDAR points. We will illustrate the potential
challenges of the above learning problem and resolve these challenges by
introducing several effective designs into our method. Codes will be available
at https://github.com/SPengLiang/WeakM3D.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptive Hand Keypoint and Pixel Localization in the Wild. (arXiv:2203.08344v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08344">
<div class="article-summary-box-inner">
<span><p>We aim to improve the performance of regressing hand keypoints and segmenting
pixel-level hand masks under new imaging conditions (e.g., outdoors) when we
only have labeled images taken under very different conditions (e.g., indoors).
In the real world, it is important that the model trained for both tasks works
under various imaging conditions. However, their variation covered by existing
labeled hand datasets is limited. Thus, it is necessary to adapt the model
trained on the labeled images (source) to unlabeled images (target) with unseen
imaging conditions. While self-training domain adaptation methods (i.e.,
learning from the unlabeled target images in a self-supervised manner) have
been developed for both tasks, their training may degrade performance when the
predictions on the target images are noisy. To avoid this, it is crucial to
assign a low importance (confidence) weight to the noisy predictions during
self-training. In this paper, we propose to utilize the divergence of two
predictions to estimate the confidence of the target image for both tasks.
These predictions are given from two separate networks, and their divergence
helps identify the noisy predictions. To integrate our proposed confidence
estimation into self-training, we propose a teacher-student framework where the
two networks (teachers) provide supervision to a network (student) for
self-training, and the teachers are learned from the student by knowledge
distillation. Our experiments show its superiority over state-of-the-art
methods in adaptation settings with different lighting, grasping objects,
backgrounds, and camera viewpoints. Our method improves by 4% the multi-task
score on HO3D compared to the latest adversarial adaptation method. We also
validate our method on Ego4D, egocentric videos with rapid changes in imaging
conditions outdoors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient Correction beyond Gradient Descent. (arXiv:2203.08345v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08345">
<div class="article-summary-box-inner">
<span><p>The great success neural networks have achieved is inseparable from the
application of gradient-descent (GD) algorithms. Based on GD, many variant
algorithms have emerged to improve the GD optimization process. The gradient
for back-propagation is apparently the most crucial aspect for the training of
a neural network. The quality of the calculated gradient can be affected by
multiple aspects, e.g., noisy data, calculation error, algorithm limitation,
and so on. To reveal gradient information beyond gradient descent, we introduce
a framework (\textbf{GCGD}) to perform gradient correction. GCGD consists of
two plug-in modules: 1) inspired by the idea of gradient prediction, we propose
a \textbf{GC-W} module for weight gradient correction; 2) based on Neural ODE,
we propose a \textbf{GC-ODE} module for hidden states gradient correction.
Experiment results show that our gradient correction framework can effectively
improve the gradient quality to reduce training epochs by $\sim$ 20\% and also
improve the network performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Represent, Compare, and Learn: A Similarity-Aware Framework for Class-Agnostic Counting. (arXiv:2203.08354v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08354">
<div class="article-summary-box-inner">
<span><p>Class-agnostic counting (CAC) aims to count all instances in a query image
given few exemplars. A standard pipeline is to extract visual features from
exemplars and match them with query images to infer object counts. Two
essential components in this pipeline are feature representation and similarity
metric. Existing methods either adopt a pretrained network to represent
features or learn a new one, while applying a naive similarity metric with
fixed inner product. We find this paradigm leads to noisy similarity matching
and hence harms counting performance. In this work, we propose a
similarity-aware CAC framework that jointly learns representation and
similarity metric. We first instantiate our framework with a naive baseline
called Bilinear Matching Network (BMNet), whose key component is a learnable
bilinear similarity metric. To further embody the core of our framework, we
extend BMNet to BMNet+ that models similarity from three aspects: 1)
representing the instances via their self-similarity to enhance feature
robustness against intra-class variations; 2) comparing the similarity
dynamically to focus on the key patterns of each exemplar; 3) learning from a
supervision signal to impose explicit constraints on matching results.
Extensive experiments on a recent CAC dataset FSC147 show that our models
significantly outperform state-of-the-art CAC approaches. In addition, we also
validate the cross-dataset generality of BMNet and BMNet+ on a car counting
dataset CARPK. Code is at tiny.one/BMNet
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spot the Difference: A Cooperative Object-Referring Game in Non-Perfectly Co-Observable Scene. (arXiv:2203.08362v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08362">
<div class="article-summary-box-inner">
<span><p>Visual dialog has witnessed great progress after introducing various
vision-oriented goals into the conversation, especially such as GuessWhich and
GuessWhat, where the only image is visible by either and both of the questioner
and the answerer, respectively. Researchers explore more on visual dialog tasks
in such kind of single- or perfectly co-observable visual scene, while somewhat
neglect the exploration on tasks of non perfectly co-observable visual scene,
where the images accessed by two agents may not be exactly the same, often
occurred in practice. Although building common ground in non-perfectly
co-observable visual scene through conversation is significant for advanced
dialog agents, the lack of such dialog task and corresponding large-scale
dataset makes it impossible to carry out in-depth research. To break this
limitation, we propose an object-referring game in non-perfectly co-observable
visual scene, where the goal is to spot the difference between the similar
visual scenes through conversing in natural language. The task addresses
challenges of the dialog strategy in non-perfectly co-observable visual scene
and the ability of categorizing objects. Correspondingly, we construct a
large-scale multimodal dataset, named SpotDiff, which contains 87k Virtual
Reality images and 97k dialogs generated by self-play. Finally, we give
benchmark models for this task, and conduct extensive experiments to evaluate
its performance as well as analyze its main challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixed-Precision Neural Network Quantization via Learned Layer-wise Importance. (arXiv:2203.08368v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08368">
<div class="article-summary-box-inner">
<span><p>The exponentially large discrete search space in mixed-precision quantization
(MPQ) makes it hard to determine the optimal bit-width for each layer. Previous
works usually resort to iterative search methods on the training set, which
consume hundreds or even thousands of GPU-hours. In this study, we reveal that
some unique learnable parameters in quantization, namely the scale factors in
the quantizer, can serve as importance indicators of a layer, reflecting the
contribution of that layer to the final accuracy at certain bit-widths. These
importance indicators naturally perceive the numerical transformation during
quantization-aware training, which can precisely and correctly provide
quantization sensitivity metrics of layers. However, a deep network always
contains hundreds of such indicators, and training them one by one would lead
to an excessive time cost. To overcome this issue, we propose a joint training
scheme that can obtain all indicators at once. It considerably speeds up the
indicators training process by parallelizing the original sequential training
processes. With these learned importance indicators, we formulate the MPQ
search problem as a one-time integer linear programming (ILP) problem. That
avoids the iterative search and significantly reduces search time without
limiting the bit-width search space. For example, MPQ search on ResNet18 with
our indicators takes only 0.06 seconds. Also, extensive experiments show our
approach can achieve SOTA accuracy on ImageNet for far-ranging models with
various constraints (e.g., BitOps, compress rate).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Diffusion Implicit Bridges for Image-to-Image Translation. (arXiv:2203.08382v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08382">
<div class="article-summary-box-inner">
<span><p>Common image-to-image translation methods rely on joint training over data
from both source and target domains. This excludes cases where domain data is
private (e.g., in a federated setting), and often means that a new model has to
be trained for a new pair of domains. We present Dual Diffusion Implicit
Bridges (DDIBs), an image translation method based on diffusion models, that
circumvents training on domain pairs. DDIBs allow translations between
arbitrary pairs of source-target domains, given independently trained diffusion
models on the respective domains. Image translation with DDIBs is a two-step
process: DDIBs first obtain latent encodings for source images with the source
diffusion model, and next decode such encodings using the target model to
construct target images. Moreover, DDIBs enable cycle-consistency by default
and is theoretically connected to optimal transport. Experimentally, we apply
DDIBs on a variety of synthetic and high-resolution image datasets,
demonstrating their utility in example-guided color transfer, image-to-image
translation as well as their connections to optimal transport methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?. (arXiv:2203.08392v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08392">
<div class="article-summary-box-inner">
<span><p>Vision transformers (ViTs) have recently set off a new wave in neural
architecture design thanks to their record-breaking performance in various
vision tasks. In parallel, to fulfill the goal of deploying ViTs into
real-world vision applications, their robustness against potential malicious
attacks has gained increasing attention. In particular, recent works show that
ViTs are more robust against adversarial attacks as compared with convolutional
neural networks (CNNs), and conjecture that this is because ViTs focus more on
capturing global interactions among different input/feature patches, leading to
their improved robustness to local perturbations imposed by adversarial
attacks. In this work, we ask an intriguing question: "Under what kinds of
perturbations do ViTs become more vulnerable learners compared to CNNs?" Driven
by this question, we first conduct a comprehensive experiment regarding the
robustness of both ViTs and CNNs under various existing adversarial attacks to
understand the underlying reason favoring their robustness. Based on the drawn
insights, we then propose a dedicated attack framework, dubbed Patch-Fool, that
fools the self-attention mechanism by attacking its basic component (i.e., a
single patch) with a series of attention-aware optimization techniques.
Interestingly, our Patch-Fool framework shows for the first time that ViTs are
not necessarily more robust than CNNs against adversarial perturbations. In
particular, we find that ViTs are more vulnerable learners compared with CNNs
against our Patch-Fool attack which is consistent across extensive experiments,
and the observations from Sparse/Mild Patch-Fool, two variants of Patch-Fool,
indicate an intriguing insight that the perturbation density and strength on
each patch seem to be the key factors that influence the robustness ranking
between ViTs and CNNs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Privacy-preserving Online AutoML for Domain-Specific Face Detection. (arXiv:2203.08399v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08399">
<div class="article-summary-box-inner">
<span><p>Despite the impressive progress of general face detection, the tuning of
hyper-parameters and architectures is still critical for the performance of a
domain-specific face detector. Though existing AutoML works can speedup such
process, they either require tuning from scratch for a new scenario or do not
consider data privacy. To scale up, we derive a new AutoML setting from a
platform perspective. In such setting, new datasets sequentially arrive at the
platform, where an architecture and hyper-parameter configuration is
recommended to train the optimal face detector for each dataset. This, however,
brings two major challenges: (1) how to predict the best configuration for any
given dataset without touching their raw images due to the privacy concern? and
(2) how to continuously improve the AutoML algorithm from previous tasks and
offer a better warm-up for future ones? We introduce "HyperFD", a new
privacy-preserving online AutoML framework for face detection. At its core
part, a novel meta-feature representation of a dataset as well as its learning
paradigm is proposed. Thanks to HyperFD, each local task (client) is able to
effectively leverage the learning "experience" of previous tasks without
uploading raw images to the platform; meanwhile, the meta-feature extractor is
continuously learned to better trade off the bias and variance. Extensive
experiments demonstrate the effectiveness and efficiency of our design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RBC: Rectifying the Biased Context in Continual Semantic Segmentation. (arXiv:2203.08404v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08404">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed a great development of Convolutional Neural
Networks in semantic segmentation, where all classes of training images are
simultaneously available. In practice, new images are usually made available in
a consecutive manner, leading to a problem called Continual Semantic
Segmentation (CSS). Typically, CSS faces the forgetting problem since previous
training images are unavailable, and the semantic shift problem of the
background class. Considering the semantic segmentation as a context-dependent
pixel-level classification task, we explore CSS from a new perspective of
context analysis in this paper. We observe that the context of old-class pixels
in the new images is much more biased on new classes than that in the old
images, which can sharply aggravate the old-class forgetting and new-class
overfitting. To tackle the obstacle, we propose a biased-context-rectified CSS
framework with a context-rectified image-duplet learning scheme and a
biased-context-insensitive consistency loss. Furthermore, we propose an
adaptive re-weighting class-balanced learning strategy for the biased class
distribution. Our approach outperforms state-of-the-art methods by a large
margin in existing CSS scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Scale Context-Guided Lumbar Spine Disease Identification with Coarse-to-fine Localization and Classification. (arXiv:2203.08408v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08408">
<div class="article-summary-box-inner">
<span><p>Accurate and efficient lumbar spine disease identification is crucial for
clinical diagnosis. However, existing deep learning models with millions of
parameters often fail to learn with only hundreds or dozens of medical images.
These models also ignore the contextual relationship between adjacent objects,
such as between vertebras and intervertebral discs. This work introduces a
multi-scale context-guided network with coarse-to-fine localization and
classification, named CCF-Net, for lumbar spine disease identification.
Specifically, in learning, we divide the localization objective into two
parallel tasks, coarse and fine, which are more straightforward and effectively
reduce the number of parameters and computational cost. The experimental
results show that the coarse-to-fine design presents the potential to achieve
high performance with fewer parameters and data requirements. Moreover, the
multi-scale context-guided module can significantly improve the performance by
6.45% and 5.51% with ResNet18 and ResNet50, respectively. Our code is available
at https://github.com/czifan/CCFNet.pytorch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FormNet: Structural Encoding beyond Sequential Modeling in Form Document Information Extraction. (arXiv:2203.08411v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08411">
<div class="article-summary-box-inner">
<span><p>Sequence modeling has demonstrated state-of-the-art performance on natural
language and document understanding tasks. However, it is challenging to
correctly serialize tokens in form-like documents in practice due to their
variety of layout patterns. We propose FormNet, a structure-aware sequence
model to mitigate the suboptimal serialization of forms. First, we design Rich
Attention that leverages the spatial relationship between tokens in a form for
more precise attention score calculation. Second, we construct Super-Tokens for
each word by embedding representations from their neighboring tokens through
graph convolutions. FormNet therefore explicitly recovers local syntactic
information that may have been lost during serialization. In experiments,
FormNet outperforms existing methods with a more compact model size and less
pre-training data, establishing new state-of-the-art performance on CORD, FUNSD
and Payment benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Semantic Segmentation by Distilling Feature Correspondences. (arXiv:2203.08414v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08414">
<div class="article-summary-box-inner">
<span><p>Unsupervised semantic segmentation aims to discover and localize semantically
meaningful categories within image corpora without any form of annotation. To
solve this task, algorithms must produce features for every pixel that are both
semantically meaningful and compact enough to form distinct clusters. Unlike
previous works which achieve this with a single end-to-end framework, we
propose to separate feature learning from cluster compactification.
Empirically, we show that current unsupervised feature learning frameworks
already generate dense features whose correlations are semantically consistent.
This observation motivates us to design STEGO ($\textbf{S}$elf-supervised
$\textbf{T}$ransformer with $\textbf{E}$nergy-based $\textbf{G}$raph
$\textbf{O}$ptimization), a novel framework that distills unsupervised features
into high-quality discrete semantic labels. At the core of STEGO is a novel
contrastive loss function that encourages features to form compact clusters
while preserving their relationships across the corpora. STEGO yields a
significant improvement over the prior state of the art, on both the CocoStuff
($\textbf{+14 mIoU}$) and Cityscapes ($\textbf{+9 mIoU}$) semantic segmentation
challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WegFormer: Transformers for Weakly Supervised Semantic Segmentation. (arXiv:2203.08421v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08421">
<div class="article-summary-box-inner">
<span><p>Although convolutional neural networks (CNNs) have achieved remarkable
progress in weakly supervised semantic segmentation (WSSS), the effective
receptive field of CNN is insufficient to capture global context information,
leading to sub-optimal results. Inspired by the great success of Transformers
in fundamental vision areas, this work for the first time introduces
Transformer to build a simple and effective WSSS framework, termed WegFormer.
Unlike existing CNN-based methods, WegFormer uses Vision Transformer (ViT) as a
classifier to produce high-quality pseudo segmentation masks. To this end, we
introduce three tailored components in our Transformer-based framework, which
are (1) a Deep Taylor Decomposition (DTD) to generate attention maps, (2) a
soft erasing module to smooth the attention maps, and (3) an efficient
potential object mining (EPOM) to filter noisy activation in the background.
Without any bells and whistles, WegFormer achieves state-of-the-art 70.5% mIoU
on the PASCAL VOC dataset, significantly outperforming the previous best
method. We hope WegFormer provides a new perspective to tap the potential of
Transformer in weakly supervised semantic segmentation. Code will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attribute Group Editing for Reliable Few-shot Image Generation. (arXiv:2203.08422v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08422">
<div class="article-summary-box-inner">
<span><p>Few-shot image generation is a challenging task even using the
state-of-the-art Generative Adversarial Networks (GANs). Due to the unstable
GAN training process and the limited training data, the generated images are
often of low quality and low diversity. In this work, we propose a new
editing-based method, i.e., Attribute Group Editing (AGE), for few-shot image
generation. The basic assumption is that any image is a collection of
attributes and the editing direction for a specific attribute is shared across
all categories. AGE examines the internal representation learned in GANs and
identifies semantically meaningful directions. Specifically, the class
embedding, i.e., the mean vector of the latent codes from a specific category,
is used to represent the category-relevant attributes, and the
category-irrelevant attributes are learned globally by Sparse Dictionary
Learning on the difference between the sample embedding and the class
embedding. Given a GAN well trained on seen categories, diverse images of
unseen categories can be synthesized through editing category-irrelevant
attributes while keeping category-relevant attributes unchanged. Without
re-training the GAN, AGE is capable of not only producing more realistic and
diverse images for downstream visual applications with limited data but
achieving controllable image editing with interpretable category-irrelevant
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiFT: Differentiable Differential Feature Transform for Multi-View Stereo. (arXiv:2203.08435v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08435">
<div class="article-summary-box-inner">
<span><p>We present a novel framework to automatically learn to transform the
differential cues from a stack of images densely captured with a rotational
motion into spatially discriminative and view-invariant per-pixel features at
each view. These low-level features can be directly fed to any existing
multi-view stereo technique for enhanced 3D reconstruction. The lighting
condition during acquisition can also be jointly optimized in a differentiable
fashion. We sample from a dozen of pre-scanned objects with a wide variety of
geometry and reflectance to synthesize a large amount of high-quality training
data. The effectiveness of our features is demonstrated on a number of
challenging objects acquired with a lightstage, comparing favorably with
state-of-the-art techniques. Finally, we explore additional applications of
geometric detail visualization and computational stylization of complex
appearance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open Set Recognition using Vision Transformer with an Additional Detection Head. (arXiv:2203.08441v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08441">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have demonstrated prominent capacities for image
classification tasks in a closed set setting, where the test data come from the
same distribution as the training data. However, in a more realistic open set
scenario, traditional classifiers with incomplete knowledge cannot tackle test
data that are not from the training classes. Open set recognition (OSR) aims to
address this problem by both identifying unknown classes and distinguishing
known classes simultaneously. In this paper, we propose a novel approach to OSR
that is based on the vision transformer (ViT) technique. Specifically, our
approach employs two separate training stages. First, a ViT model is trained to
perform closed set classification. Then, an additional detection head is
attached to the embedded features extracted by the ViT, trained to force the
representations of known data to class-specific clusters compactly. Test
examples are identified as known or unknown based on their distance to the
cluster centers. To the best of our knowledge, this is the first time to
leverage ViT for the purpose of OSR, and our extensive evaluation against
several OSR benchmark datasets reveals that our approach significantly
outperforms other baseline methods and obtains new state-of-the-art
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Panini-Net: GAN Prior Based Degradation-Aware Feature Interpolation for Face Restoration. (arXiv:2203.08444v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08444">
<div class="article-summary-box-inner">
<span><p>Emerging high-quality face restoration (FR) methods often utilize pre-trained
GAN models (\textit{i.e.}, StyleGAN2) as GAN Prior. However, these methods
usually struggle to balance realness and fidelity when facing various
degradation levels. Besides, there is still a noticeable visual quality gap
compared with pre-trained GAN models. In this paper, we propose a novel GAN
Prior based degradation-aware feature interpolation network, dubbed Panini-Net,
for FR tasks by explicitly learning the abstract representations to distinguish
various degradations. Specifically, an unsupervised degradation representation
learning (UDRL) strategy is first developed to extract degradation
representations (DR) of the input degraded images. Then, a degradation-aware
feature interpolation (DAFI) module is proposed to dynamically fuse the two
types of informative features (\textit{i.e.}, features from input images and
features from GAN Prior) with flexible adaption to various degradations based
on DR. Ablation studies reveal the working mechanism of DAFI and its potential
for editable FR. Extensive experiments demonstrate that our Panini-Net achieves
state-of-the-art performance for multi-degradation face restoration and face
super-resolution. The source code is available at
https://github.com/jianzhangcs/panini.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Devil Is in the Details: Window-based Attention for Image Compression. (arXiv:2203.08450v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08450">
<div class="article-summary-box-inner">
<span><p>Learned image compression methods have exhibited superior rate-distortion
performance than classical image compression standards. Most existing learned
image compression models are based on Convolutional Neural Networks (CNNs).
Despite great contributions, a main drawback of CNN based model is that its
structure is not designed for capturing local redundancy, especially the
non-repetitive textures, which severely affects the reconstruction quality.
Therefore, how to make full use of both global structure and local texture
becomes the core problem for learning-based image compression. Inspired by
recent progresses of Vision Transformer (ViT) and Swin Transformer, we found
that combining the local-aware attention mechanism with the global-related
feature learning could meet the expectation in image compression. In this
paper, we first extensively study the effects of multiple kinds of attention
mechanisms for local features learning, then introduce a more straightforward
yet effective window-based local attention block. The proposed window-based
attention is very flexible which could work as a plug-and-play component to
enhance CNN and Transformer models. Moreover, we propose a novel Symmetrical
TransFormer (STF) framework with absolute transformer blocks in the
down-sampling encoder and up-sampling decoder. Extensive experimental
evaluations have shown that the proposed method is effective and outperforms
the state-of-the-art methods. The code is publicly available at
https://github.com/Googolxx/STF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PPCD-GAN: Progressive Pruning and Class-Aware Distillation for Large-Scale Conditional GANs Compression. (arXiv:2203.08456v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08456">
<div class="article-summary-box-inner">
<span><p>We push forward neural network compression research by exploiting a novel
challenging task of large-scale conditional generative adversarial networks
(GANs) compression. To this end, we propose a gradually shrinking GAN
(PPCD-GAN) by introducing progressive pruning residual block (PP-Res) and
class-aware distillation. The PP-Res is an extension of the conventional
residual block where each convolutional layer is followed by a learnable mask
layer to progressively prune network parameters as training proceeds. The
class-aware distillation, on the other hand, enhances the stability of training
by transferring immense knowledge from a well-trained teacher model through
instructive attention maps. We train the pruning and distillation processes
simultaneously on a well-known GAN architecture in an end-to-end manner. After
training, all redundant parameters as well as the mask layers are discarded,
yielding a lighter network while retaining the performance. We comprehensively
illustrate, on ImageNet 128x128 dataset, PPCD-GAN reduces up to 5.2x (81%)
parameters against state-of-the-arts while keeping better performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fusing Local Similarities for Retrieval-based 3D Orientation Estimation of Unseen Objects. (arXiv:2203.08472v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08472">
<div class="article-summary-box-inner">
<span><p>In this paper, we tackle the task of estimating the 3D orientation of
previously-unseen objects from monocular images. This task contrasts with the
one considered by most existing deep learning methods which typically assume
that the testing objects have been observed during training. To handle the
unseen objects, we follow a retrieval-based strategy and prevent the network
from learning object-specific features by computing multi-scale local
similarities between the query image and synthetically-generated reference
images. We then introduce an adaptive fusion module that robustly aggregates
the local similarities into a global similarity score of pairwise images.
Furthermore, we speed up the retrieval process by developing a fast
clustering-based retrieval strategy. Our experiments on the LineMOD,
LineMOD-Occluded, and T-LESS datasets show that our method yields a
significantly better generalization to unseen objects than previous works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Efficient 3D Learner via Knowledge Transferred from 2D Model. (arXiv:2203.08479v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08479">
<div class="article-summary-box-inner">
<span><p>Collecting and labeling the registered 3D point cloud is costly. As a result,
3D resources for training are typically limited in quantity compared to the 2D
images counterpart. In this work, we deal with the data scarcity challenge of
3D tasks by transferring knowledge from strong 2D models via RGB-D images.
Specifically, we utilize a strong and well-trained semantic segmentation model
for 2D images to augment RGB-D images with pseudo-label. The augmented dataset
can then be used to pre-train 3D models. Finally, by simply fine-tuning on a
few labeled 3D instances, our method already outperforms existing
state-of-the-art that is tailored for 3D label efficiency. We also show that
the results of mean-teacher and entropy minimization can be improved by our
pre-training, suggesting that the transferred knowledge is helpful in
semi-supervised setting. We verify the effectiveness of our approach on two
popular 3D models and three different tasks. On ScanNet official evaluation, we
establish new state-of-the-art semantic segmentation results on the
data-efficient track.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding. (arXiv:2203.08481v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08481">
<div class="article-summary-box-inner">
<span><p>Visual grounding, i.e., localizing objects in images according to natural
language queries, is an important topic in visual language understanding. The
most effective approaches for this task are based on deep learning, which
generally require expensive manually labeled image-query or patch-query pairs.
To eliminate the heavy dependence on human annotations, we present a novel
method, named Pseudo-Q, to automatically generate pseudo language queries for
supervised training. Our method leverages an off-the-shelf object detector to
identify visual objects from unlabeled images, and then language queries for
these objects are obtained in an unsupervised fashion with a pseudo-query
generation module. Then, we design a task-related query prompt module to
specifically tailor generated pseudo language queries for visual grounding
tasks. Further, in order to fully capture the contextual relationships between
images and language queries, we develop a visual-language model equipped with
multi-level cross-modality attention mechanism. Extensive experimental results
demonstrate that our method has two notable benefits: (1) it can reduce human
annotation costs significantly, e.g., 31% on RefCOCO without degrading original
model's performance under the fully supervised setting, and (2) without bells
and whistles, it achieves superior or comparable performance compared to
state-of-the-art weakly-supervised visual grounding methods on all the five
datasets we have experimented. Code is available at
https://github.com/LeapLabTHU/Pseudo-Q.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QS-Attn: Query-Selected Attention for Contrastive Learning in I2I Translation. (arXiv:2203.08483v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08483">
<div class="article-summary-box-inner">
<span><p>Unpaired image-to-image (I2I) translation often requires to maximize the
mutual information between the source and the translated images across
different domains, which is critical for the generator to keep the source
content and prevent it from unnecessary modifications. The self-supervised
contrastive learning has already been successfully applied in the I2I. By
constraining features from the same location to be closer than those from
different ones, it implicitly ensures the result to take content from the
source. However, previous work uses the features from random locations to
impose the constraint, which may not be appropriate since some locations
contain less information of source domain. Moreover, the feature itself does
not reflect the relation with others. This paper deals with these problems by
intentionally selecting significant anchor points for contrastive learning. We
design a query-selected attention (QS-Attn) module, which compares feature
distances in the source domain, giving an attention matrix with a probability
distribution in each row. Then we select queries according to their measurement
of significance, computed from the distribution. The selected ones are regarded
as anchors for contrastive loss. At the same time, the reduced attention matrix
is employed to route features in both domains, so that source relations
maintain in the synthesis. We validate our proposed method in three different
I2I datasets, showing that it increases the image quality without adding
learnable parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PointAttN: You Only Need Attention for Point Cloud Completion. (arXiv:2203.08485v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08485">
<div class="article-summary-box-inner">
<span><p>Point cloud completion referring to completing 3D shapes from partial 3D
point clouds is a fundamental problem for 3D point cloud analysis tasks.
Benefiting from the development of deep neural networks, researches on point
cloud completion have made great progress in recent years. However, the
explicit local region partition like kNNs involved in existing methods makes
them sensitive to the density distribution of point clouds. Moreover, it serves
limited receptive fields that prevent capturing features from long-range
context information. To solve the problems, we leverage the cross-attention and
self-attention mechanisms to design novel neural network for processing point
cloud in a per-point manner to eliminate kNNs. Two essential blocks Geometric
Details Perception (GDP) and Self-Feature Augment (SFA) are proposed to
establish the short-range and long-range structural relationships directly
among points in a simple yet effective way via attention mechanism. Then based
on GDP and SFA, we construct a new framework with popular encoder-decoder
architecture for point cloud completion. The proposed framework, namely
PointAttN, is simple, neat and effective, which can precisely capture the
structural information of 3D shapes and predict complete point clouds with
highly detailed geometries. Experimental results demonstrate that our PointAttN
outperforms state-of-the-art methods by a large margin on popular benchmarks
like Completion3D and PCN. Code is available at:
https://github.com/ohhhyeahhh/PointAttN
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Historical Document Image Datasets. (arXiv:2203.08504v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08504">
<div class="article-summary-box-inner">
<span><p>This paper presents a systematic literature review of image datasets for
document image analysis, focusing on historical documents, such as handwritten
manuscripts and early prints. Finding appropriate datasets for historical
document analysis is a crucial prerequisite to facilitate research using
different machine learning algorithms. However, because of the very large
variety of the actual data (e.g., scripts, tasks, dates, support systems, and
amount of deterioration), the different formats for data and label
representation, and the different evaluation processes and benchmarks, finding
appropriate datasets is a difficult task. This work fills this gap, presenting
a meta-study on existing datasets. After a systematic selection process
(according to PRISMA guidelines), we select 56 studies that are chosen based on
different factors, such as the year of publication, number of methods
implemented in the article, reliability of the chosen algorithms, dataset size,
and journal outlet. We summarize each study by assigning it to one of three
pre-defined tasks: document classification, layout structure, or semantic
analysis. We present the statistics, document type, language, tasks, input
visual aspects, and ground truth information for every dataset. In addition, we
provide the benchmark tasks and results from these papers or recent
competitions. We further discuss gaps and challenges in this domain. We
advocate for providing conversion tools to common formats (e.g., COCO format
for computer vision tasks) and always providing a set of evaluation metrics,
instead of just one, to make results comparable across studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-focus thermal image fusion. (arXiv:2203.08513v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08513">
<div class="article-summary-box-inner">
<span><p>This paper proposes a novel algorithm for multi-focus thermal image fusion.
The algorithm is based on local activity analysis and advanced pre-selection of
images into fusion process. The algorithm improves the object temperature
measurement error up to 5 Celsius degrees. The proposed algorithm is evaluated
by half total error rate, root mean squared error, cross correlation and visual
inspection. To the best of our knowledge, this is the first work devoted to
multi-focus thermal image fusion. For testing of proposed algorithm we acquire
six thermal image set with objects at different focal depth.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fantastic Style Channels and Where to Find Them: A Submodular Framework for Discovering Diverse Directions in GANs. (arXiv:2203.08516v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08516">
<div class="article-summary-box-inner">
<span><p>The discovery of interpretable directions in the latent spaces of pre-trained
GAN models has recently become a popular topic. In particular, StyleGAN2 has
enabled various image generation and manipulation tasks due to its rich and
disentangled latent spaces. The discovery of such directions is typically done
either in a supervised manner, which requires annotated data for each desired
manipulation or in an unsupervised manner, which requires a manual effort to
identify the directions. As a result, existing work typically finds only a
handful of directions in which controllable edits can be made. In this study,
we design a novel submodular framework that finds the most representative and
diverse subset of directions in the latent space of StyleGAN2. Our approach
takes advantage of the latent space of channel-wise style parameters, so-called
stylespace, in which we cluster channels that perform similar manipulations
into groups. Our framework promotes diversity by using the notion of clusters
and can be efficiently solved with a greedy optimization scheme. We evaluate
our framework with qualitative and quantitative experiments and show that our
method finds more diverse and disentangled directions. Our project page can be
found at <a href="http://catlab-team.github.io/fantasticstyles.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Practical Certifiable Patch Defense with Vision Transformer. (arXiv:2203.08519v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08519">
<div class="article-summary-box-inner">
<span><p>Patch attacks, one of the most threatening forms of physical attack in
adversarial examples, can lead networks to induce misclassification by
modifying pixels arbitrarily in a continuous region. Certifiable patch defense
can guarantee robustness that the classifier is not affected by patch attacks.
Existing certifiable patch defenses sacrifice the clean accuracy of classifiers
and only obtain a low certified accuracy on toy datasets. Furthermore, the
clean and certified accuracy of these methods is still significantly lower than
the accuracy of normal classification networks, which limits their application
in practice. To move towards a practical certifiable patch defense, we
introduce Vision Transformer (ViT) into the framework of Derandomized Smoothing
(DS). Specifically, we propose a progressive smoothed image modeling task to
train Vision Transformer, which can capture the more discriminable local
context of an image while preserving the global semantic information. For
efficient inference and deployment in the real world, we innovatively
reconstruct the global self-attention structure of the original ViT into
isolated band unit self-attention. On ImageNet, under 2% area patch attacks our
method achieves 41.70% certified accuracy, a nearly 1-fold increase over the
previous best method (26.00%). Simultaneously, our method achieves 78.58% clean
accuracy, which is quite close to the normal ResNet-101 accuracy. Extensive
experiments show that our method obtains state-of-the-art clean and certified
accuracy with inferring efficiently on CIFAR-10 and ImageNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation from Monocular Video. (arXiv:2203.08534v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08534">
<div class="article-summary-box-inner">
<span><p>Learning to capture human motion is essential to 3D human pose and shape
estimation from monocular video. However, the existing methods mainly rely on
recurrent or convolutional operation to model such temporal information, which
limits the ability to capture non-local context relations of human motion. To
address this problem, we propose a motion pose and shape network (MPS-Net) to
effectively capture humans in motion to estimate accurate and temporally
coherent 3D human pose and shape from a video. Specifically, we first propose a
motion continuity attention (MoCA) module that leverages visual cues observed
from human motion to adaptively recalibrate the range that needs attention in
the sequence to better capture the motion continuity dependencies. Then, we
develop a hierarchical attentive feature integration (HAFI) module to
effectively combine adjacent past and future feature representations to
strengthen temporal correlation and refine the feature representation of the
current frame. By coupling the MoCA and HAFI modules, the proposed MPS-Net
excels in estimating 3D human pose and shape in the video. Though conceptually
simple, our MPS-Net not only outperforms the state-of-the-art methods on the
3DPW, MPI-INF-3DHP, and Human3.6M benchmark datasets, but also uses fewer
network parameters. The video demos can be found at
https://mps-net.github.io/MPS-Net/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scribble-Supervised LiDAR Semantic Segmentation. (arXiv:2203.08537v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08537">
<div class="article-summary-box-inner">
<span><p>Densely annotating LiDAR point clouds remains too expensive and
time-consuming to keep up with the ever growing volume of data. While current
literature focuses on fully-supervised performance, developing efficient
methods that take advantage of realistic weak supervision have yet to be
explored. In this paper, we propose using scribbles to annotate LiDAR point
clouds and release ScribbleKITTI, the first scribble-annotated dataset for
LiDAR semantic segmentation. Furthermore, we present a pipeline to reduce the
performance gap that arises when using such weak annotations. Our pipeline
comprises of three stand-alone contributions that can be combined with any
LiDAR semantic segmentation model to achieve up to 95.7% of the
fully-supervised performance while using only 8% labeled points. Our scribble
annotations and code are available at github.com/ouenal/scribblekitti.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating Language Guidance into Vision-based Deep Metric Learning. (arXiv:2203.08543v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08543">
<div class="article-summary-box-inner">
<span><p>Deep Metric Learning (DML) proposes to learn metric spaces which encode
semantic similarities as embedding space distances. These spaces should be
transferable to classes beyond those seen during training. Commonly, DML
methods task networks to solve contrastive ranking tasks defined over binary
class assignments. However, such approaches ignore higher-level semantic
relations between the actual classes. This causes learned embedding spaces to
encode incomplete semantic context and misrepresent the semantic relation
between classes, impacting the generalizability of the learned metric space. To
tackle this issue, we propose a language guidance objective for visual
similarity learning. Leveraging language embeddings of expert- and
pseudo-classnames, we contextualize and realign visual representation spaces
corresponding to meaningful language semantics for better semantic consistency.
Extensive experiments and ablations provide a strong motivation for our
proposed approach and show language guidance offering significant,
model-agnostic improvements for DML, achieving competitive and state-of-the-art
results on all benchmarks. Code available at
https://github.com/ExplainableML/LanguageGuidance_for_DML.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-isotropy Regularization for Proxy-based Deep Metric Learning. (arXiv:2203.08547v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08547">
<div class="article-summary-box-inner">
<span><p>Deep Metric Learning (DML) aims to learn representation spaces on which
semantic relations can simply be expressed through predefined distance metrics.
Best performing approaches commonly leverage class proxies as sample stand-ins
for better convergence and generalization. However, these proxy-methods solely
optimize for sample-proxy distances. Given the inherent non-bijectiveness of
used distance functions, this can induce locally isotropic sample
distributions, leading to crucial semantic context being missed due to
difficulties resolving local structures and intraclass relations between
samples. To alleviate this problem, we propose non-isotropy regularization
($\mathbb{NIR}$) for proxy-based Deep Metric Learning. By leveraging
Normalizing Flows, we enforce unique translatability of samples from their
respective class proxies. This allows us to explicitly induce a non-isotropic
distribution of samples around a proxy to optimize for. In doing so, we equip
proxy-based objectives to better learn local structures. Extensive experiments
highlight consistent generalization benefits of $\mathbb{NIR}$ while achieving
competitive and state-of-the-art performance on the standard benchmarks
CUB200-2011, Cars196 and Stanford Online Products. In addition, we find the
superior convergence properties of proxy-based methods to still be retained or
even improved, making $\mathbb{NIR}$ very attractive for practical usage. Code
available at https://github.com/ExplainableML/NonIsotropicProxyDML.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is it all a cluster game? -- Exploring Out-of-Distribution Detection based on Clustering in the Embedding Space. (arXiv:2203.08549v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08549">
<div class="article-summary-box-inner">
<span><p>It is essential for safety-critical applications of deep neural networks to
determine when new inputs are significantly different from the training
distribution. In this paper, we explore this out-of-distribution (OOD)
detection problem for image classification using clusters of semantically
similar embeddings of the training data and exploit the differences in distance
relationships to these clusters between in- and out-of-distribution data. We
study the structure and separation of clusters in the embedding space and find
that supervised contrastive learning leads to well-separated clusters while its
self-supervised counterpart fails to do so. In our extensive analysis of
different training methods, clustering strategies, distance metrics, and
thresholding approaches, we observe that there is no clear winner. The optimal
approach depends on the model architecture and selected datasets for in- and
out-of-distribution. While we could reproduce the outstanding results for
contrastive training on CIFAR-10 as in-distribution data, we find standard
cross-entropy paired with cosine similarity outperforms all contrastive
training methods when training on CIFAR-100 instead. Cross-entropy provides
competitive results as compared to expensive contrastive training methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MonoJSG: Joint Semantic and Geometric Cost Volume for Monocular 3D Object Detection. (arXiv:2203.08563v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08563">
<div class="article-summary-box-inner">
<span><p>Due to the inherent ill-posed nature of 2D-3D projection, monocular 3D object
detection lacks accurate depth recovery ability. Although the deep neural
network (DNN) enables monocular depth-sensing from high-level learned features,
the pixel-level cues are usually omitted due to the deep convolution mechanism.
To benefit from both the powerful feature representation in DNN and pixel-level
geometric constraints, we reformulate the monocular object depth estimation as
a progressive refinement problem and propose a joint semantic and geometric
cost volume to model the depth error. Specifically, we first leverage neural
networks to learn the object position, dimension, and dense normalized 3D
object coordinates. Based on the object depth, the dense coordinates patch
together with the corresponding object features is reprojected to the image
space to build a cost volume in a joint semantic and geometric error manner.
The final depth is obtained by feeding the cost volume to a refinement network,
where the distribution of semantic and geometric error is regularized by direct
depth supervision. Through effectively mitigating depth error by the refinement
framework, we achieve state-of-the-art results on both the KITTI and Waymo
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EDTER: Edge Detection with Transformer. (arXiv:2203.08566v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08566">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks have made significant progresses in edge
detection by progressively exploring the context and semantic features.
However, local details are gradually suppressed with the enlarging of receptive
fields. Recently, vision transformer has shown excellent capability in
capturing long-range dependencies. Inspired by this, we propose a novel
transformer-based edge detector, \emph{Edge Detection TransformER (EDTER)}, to
extract clear and crisp object boundaries and meaningful edges by exploiting
the full image context information and detailed local cues simultaneously.
EDTER works in two stages. In Stage I, a global transformer encoder is used to
capture long-range global context on coarse-grained image patches. Then in
Stage II, a local transformer encoder works on fine-grained patches to excavate
the short-range local cues. Each transformer encoder is followed by an
elaborately designed Bi-directional Multi-Level Aggregation decoder to achieve
high-resolution features. Finally, the global context and local cues are
combined by a Feature Fusion Module and fed into a decision head for edge
prediction. Extensive experiments on BSDS500, NYUDv2, and Multicue demonstrate
the superiority of EDTER in comparison with state-of-the-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PMAL: Open Set Recognition via Robust Prototype Mining. (arXiv:2203.08569v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08569">
<div class="article-summary-box-inner">
<span><p>Open Set Recognition (OSR) has been an emerging topic. Besides recognizing
predefined classes, the system needs to reject the unknowns. Prototype learning
is a potential manner to handle the problem, as its ability to improve
intra-class compactness of representations is much needed in discrimination
between the known and the unknowns. In this work, we propose a novel Prototype
Mining And Learning (PMAL) framework. It has a prototype mining mechanism
before the phase of optimizing embedding space, explicitly considering two
crucial properties, namely high-quality and diversity of the prototype set.
Concretely, a set of high-quality candidates are firstly extracted from
training samples based on data uncertainty learning, avoiding the interference
from unexpected noise. Considering the multifarious appearance of objects even
in a single category, a diversity-based strategy for prototype set filtering is
proposed. Accordingly, the embedding space can be better optimized to
discriminate therein the predefined classes and between known and unknowns.
Extensive experiments verify the two good characteristics (i.e., high-quality
and diversity) embraced in prototype mining, and show the remarkable
performance of the proposed framework compared to state-of-the-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Infrared Image and Video Sets. (arXiv:2203.08581v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08581">
<div class="article-summary-box-inner">
<span><p>In this survey, we compile a list of publicly available infrared image and
video sets for artificial intelligence and computer vision researchers. We
mainly focus on IR image and video sets which are collected and labelled for
computer vision applications such as object detection, object segmentation,
classification, and motion detection. We categorize 92 different publicly
available or private sets according to their sensor types, image resolution,
and scale. We describe each and every set in detail regarding their collection
purpose, operation environment, optical system properties, and area of
application. We also cover a general overview of fundamental concepts that
relate to IR imagery, such as IR radiation, IR detectors, IR optics and
application fields. We analyse the statistical significance of the entire
corpus from different perspectives. We believe that this survey will be a
guideline for computer vision and artificial intelligence researchers that are
interested in working with the spectra beyond the visible domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep vanishing point detection: Geometric priors make dataset variations vanish. (arXiv:2203.08586v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08586">
<div class="article-summary-box-inner">
<span><p>Deep learning has improved vanishing point detection in images. Yet, deep
networks require expensive annotated datasets trained on costly hardware and do
not generalize to even slightly different domains, and minor problem variants.
Here, we address these issues by injecting deep vanishing point detection
networks with prior knowledge. This prior knowledge no longer needs to be
learned from data, saving valuable annotation efforts and compute, unlocking
realistic few-sample scenarios, and reducing the impact of domain changes.
Moreover, the interpretability of the priors allows to adapt deep networks to
minor problem variations such as switching between Manhattan and non-Manhattan
worlds. We seamlessly incorporate two geometric priors: (i) Hough Transform --
mapping image pixels to straight lines, and (ii) Gaussian sphere -- mapping
lines to great circles whose intersections denote vanishing points.
Experimentally, we ablate our choices and show comparable accuracy to existing
models in the large-data setting. We validate our model's improved data
efficiency, robustness to domain changes, adaptability to non-Manhattan
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CtlGAN: Few-shot Artistic Portraits Generation with Contrastive Transfer Learning. (arXiv:2203.08612v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08612">
<div class="article-summary-box-inner">
<span><p>Generating artistic portraits is a challenging problem in computer vision.
Existing portrait stylization models that generate good quality results are
based on Image-to-Image Translation and require abundant data from both source
and target domains. However, without enough data, these methods would result in
overfitting. In this work, we propose CtlGAN, a new few-shot artistic portraits
generation model with a novel contrastive transfer learning strategy. We adapt
a pretrained StyleGAN in the source domain to a target artistic domain with no
more than 10 artistic faces. To reduce overfitting to the few training
examples, we introduce a novel Cross-Domain Triplet loss which explicitly
encourages the target instances generated from different latent codes to be
distinguishable. We propose a new encoder which embeds real faces into Z+ space
and proposes a dual-path training strategy to better cope with the adapted
decoder and eliminate the artifacts. Extensive qualitative, quantitative
comparisons and a user study show our method significantly outperforms
state-of-the-arts under 10-shot and 1-shot settings and generates high quality
artistic portraits. The code will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional Measurement Density Estimation in Sequential Monte Carlo via Normalizing Flow. (arXiv:2203.08617v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08617">
<div class="article-summary-box-inner">
<span><p>Tuning of measurement models is challenging in real-world applications of
sequential Monte Carlo methods. Recent advances in differentiable particle
filters have led to various efforts to learn measurement models through neural
networks. But existing approaches in the differentiable particle filter
framework do not admit valid probability densities in constructing measurement
models, leading to incorrect quantification of the measurement uncertainty
given state information. We propose to learn expressive and valid probability
densities in measurement models through conditional normalizing flows, to
capture the complex likelihood of measurements given states. We show that the
proposed approach leads to improved estimation performance and faster training
convergence in a visual tracking experiment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coverage Optimization of Camera Network for Continuous Deformable Object. (arXiv:2203.08632v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08632">
<div class="article-summary-box-inner">
<span><p>In this paper, a deformable object is considered for cameras deployment with
the aim of visual coverage. The object contour is discretized into sampled
points as meshes, and the deformation is represented as continuous trajectories
for the sampled points. To reduce the computational complexity, some feature
points are carefully selected representing the continuous deformation process,
and the visual coverage for the deformable object is transferred to cover the
specific feature points. In particular, the vertexes of a rectangle that can
contain the entire deformation trajectory of every sampled point on the object
contour are chosen as the feature points. An improved wolf pack algorithm is
then proposed to solve the optimization problem. Finally, simulation results
are given to demonstrate the effectiveness of the proposed deployment method of
camera network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Complexity Reduction of Learned In-Loop Filtering in Video Coding. (arXiv:2203.08650v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08650">
<div class="article-summary-box-inner">
<span><p>In video coding, in-loop filters are applied on reconstructed video frames to
enhance their perceptual quality, before storing the frames for output.
Conventional in? loop filters are obtained by hand-crafted methods. Recently,
learned filters based on convolutional neural networks that utilize attention
mechanisms have been shown to improve upon traditional techniques. However,
these solutions are typically significantly more computationally expensive,
limiting their potential for practical applications. The proposed method uses a
novel combination of sparsity and structured pruning for complexity reduction
of learned in-loop filters. This is done through a three-step training process
of magnitude-guidedweight pruning, insignificant neuron identification and
removal, and fine-tuning. Through initial tests we find that network parameters
can be significantly reduced with a minimal impact on network performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topology-Preserving Shape Reconstruction and Registration via Neural Diffeomorphic Flow. (arXiv:2203.08652v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08652">
<div class="article-summary-box-inner">
<span><p>Deep Implicit Functions (DIFs) represent 3D geometry with continuous signed
distance functions learned through deep neural nets. Recently DIFs-based
methods have been proposed to handle shape reconstruction and dense point
correspondences simultaneously, capturing semantic relationships across shapes
of the same class by learning a DIFs-modeled shape template. These methods
provide great flexibility and accuracy in reconstructing 3D shapes and
inferring correspondences. However, the point correspondences built from these
methods do not intrinsically preserve the topology of the shapes, unlike
mesh-based template matching methods. This limits their applications on 3D
geometries where underlying topological structures exist and matter, such as
anatomical structures in medical images. In this paper, we propose a new model
called Neural Diffeomorphic Flow (NDF) to learn deep implicit shape templates,
representing shapes as conditional diffeomorphic deformations of templates,
intrinsically preserving shape topologies. The diffeomorphic deformation is
realized by an auto-decoder consisting of Neural Ordinary Differential Equation
(NODE) blocks that progressively map shapes to implicit templates. We conduct
extensive experiments on several medical image organ segmentation datasets to
evaluate the effectiveness of NDF on reconstructing and aligning shapes. NDF
achieves consistently state-of-the-art organ shape reconstruction and
registration results in both accuracy and quality. The source code is publicly
available at https://github.com/Siwensun/Neural_Diffeomorphic_Flow--NDF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Occlusion Fields: An Implicit Representation for Non-Line-of-Sight Surface Reconstruction. (arXiv:2203.08657v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08657">
<div class="article-summary-box-inner">
<span><p>Non-line-of-sight reconstruction (NLoS) is a novel indirect imaging modality
that aims to recover objects or scene parts outside the field of view from
measurements of light that is indirectly scattered off a directly visible,
diffuse wall. Despite recent advances in acquisition and reconstruction
techniques, the well-posedness of the problem at large, and the recoverability
of objects and their shapes in particular, remains an open question. The
commonly employed Fermat path criterion is rather conservative with this
regard, as it classifies some surfaces as unrecoverable, although they
contribute to the signal.
</p>
<p>In this paper, we use a simpler necessary criterion for an opaque surface
patch to be recoverable. Such piece of surface must be directly visible from
some point on the wall, and it must occlude the space behind itself. Inspired
by recent advances in neural implicit representations, we devise a new
representation and reconstruction technique for NLoS scenes that unifies the
treatment of recoverability with the reconstruction itself. Our approach, which
we validate on various synthetic and experimental datasets, exhibits
interesting properties. Unlike memory-inefficient volumetric representations,
ours allows to infer adaptively tessellated surfaces from time-of-flight
measurements of moderate resolution. It can further recover features beyond the
Fermat path criterion, and it is robust to significant amounts of
self-occlusion. We believe that this is the first time that these properties
have been achieved in one system that, as an additional benefit, is trainable
and hence suited for data-driven approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Flow: Cross-layer Graph Flow Distillation for Dual-Efficient Medical Image Segmentation. (arXiv:2203.08667v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08667">
<div class="article-summary-box-inner">
<span><p>With the development of deep convolutional neural networks, medical image
segmentation has achieved a series of breakthroughs in recent years. However,
the higher-performance convolutional neural networks always mean numerous
parameters and expensive computation costs, which will hinder the applications
in clinical scenario. Meanwhile, the scarceness of large-scale annotated
medical image datasets further impedes the application of high-performance
networks. To tackle these problems, we propose Graph Flow, a novel
comprehensive knowledge distillation method, to exploit the cross-layer graph
flow knowledge for both network-efficient and annotation-efficient medical
image segmentation.Specifically, our Graph Flow Distillation constructs a
variation graph which is employed to measure the flow of channel-wise salience
features between different layers. Next, the knowledge included in the
variation graph is transferred from a well-trained cumbersome teacher network
to a non-trained compact student network.In addition, an unsupervised
Paraphraser Module is designed to refine the knowledge of the teacher network,
which is also beneficial for the stabilization of training
procedure.Furthermore, we build a unified distillation framework by integrating
the adversarial distillation and the vanilla logits distillation, which can
further promote the final performance respectively. As a result, extensive
experiments conducted on Gastric Cancer Segmentation Dataset and Synapse
Multi-organ Segmentation Dataset demonstrate the prominent ability of our
method which achieves state-of-the-art performance on these different-modality
and multi-category medical image data. Moreover, we demonstrates the
effectiveness of our Graph Flow through a new semi-supervised paradigm for
dual-efficient medical image segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Know your sensORs $\unicode{x2013}$ A Modality Study For Surgical Action Classification. (arXiv:2203.08674v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08674">
<div class="article-summary-box-inner">
<span><p>The surgical operating room (OR) presents many opportunities for automation
and optimization. Videos from various sources in the OR are becoming
increasingly available. The medical community seeks to leverage this wealth of
data to develop automated methods to advance interventional care, lower costs,
and improve overall patient outcomes. Existing datasets from OR room cameras
are thus far limited in size or modalities acquired, leaving it unclear which
sensor modalities are best suited for tasks such as recognizing surgical action
from videos. This study demonstrates that surgical action recognition
performance can vary depending on the image modalities used. We perform a
methodical analysis on several commonly available sensor modalities, presenting
two fusion approaches that improve classification performance. The analyses are
carried out on a set of multi-view RGB-D video recordings of 18 laparoscopic
procedures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoupled Knowledge Distillation. (arXiv:2203.08679v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08679">
<div class="article-summary-box-inner">
<span><p>State-of-the-art distillation methods are mainly based on distilling deep
features from intermediate layers, while the significance of logit distillation
is greatly overlooked. To provide a novel viewpoint to study logit
distillation, we reformulate the classical KD loss into two parts, i.e., target
class knowledge distillation (TCKD) and non-target class knowledge distillation
(NCKD). We empirically investigate and prove the effects of the two parts: TCKD
transfers knowledge concerning the "difficulty" of training samples, while NCKD
is the prominent reason why logit distillation works. More importantly, we
reveal that the classical KD loss is a coupled formulation, which (1)
suppresses the effectiveness of NCKD and (2) limits the flexibility to balance
these two parts. To address these issues, we present Decoupled Knowledge
Distillation (DKD), enabling TCKD and NCKD to play their roles more efficiently
and flexibly. Compared with complex feature-based methods, our DKD achieves
comparable or even better results and has better training efficiency on
CIFAR-100, ImageNet, and MS-COCO datasets for image classification and object
detection tasks. This paper proves the great potential of logit distillation,
and we hope it will be helpful for future research. The code is available at
https://github.com/megvii-research/mdistiller.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning video retrieval models with relevance-aware online mining. (arXiv:2203.08688v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08688">
<div class="article-summary-box-inner">
<span><p>Due to the amount of videos and related captions uploaded every hour, deep
learning-based solutions for cross-modal video retrieval are attracting more
and more attention. A typical approach consists in learning a joint text-video
embedding space, where the similarity of a video and its associated caption is
maximized, whereas a lower similarity is enforced with all the other captions,
called negatives. This approach assumes that only the video and caption pairs
in the dataset are valid, but different captions - positives - may also
describe its visual contents, hence some of them may be wrongly penalized. To
address this shortcoming, we propose the Relevance-Aware Negatives and
Positives mining (RANP) which, based on the semantics of the negatives,
improves their selection while also increasing the similarity of other valid
positives. We explore the influence of these techniques on two video-text
datasets: EPIC-Kitchens-100 and MSR-VTT. By using the proposed techniques, we
achieve considerable improvements in terms of nDCG and mAP, leading to
state-of-the-art results, e.g. +5.3% nDCG and +3.0% mAP on EPIC-Kitchens-100.
We share code and pretrained models at
\url{https://github.com/aranciokov/ranp}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeciWatch: A Simple Baseline for 10x Efficient 2D and 3D Pose Estimation. (arXiv:2203.08713v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08713">
<div class="article-summary-box-inner">
<span><p>This paper proposes a simple baseline framework for video-based 2D/3D human
pose estimation that can achieve 10 times efficiency improvement over existing
works without any performance degradation, named DeciWatch. Unlike current
solutions that estimate each frame in a video, DeciWatch introduces a simple
yet effective sample-denoise-recover framework that only watches sparsely
sampled frames, taking advantage of the continuity of human motions and the
lightweight pose representation. Specifically, DeciWatch uniformly samples less
than 10% video frames for detailed estimation, denoises the estimated 2D/3D
poses with an efficient Transformer architecture, and then accurately recovers
the rest of the frames using another Transformer-based network. Comprehensive
experimental results on three video-based human pose estimation and body mesh
recovery tasks with four datasets validate the efficiency and effectiveness of
DeciWatch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relational Self-Supervised Learning. (arXiv:2203.08717v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08717">
<div class="article-summary-box-inner">
<span><p>Self-supervised Learning (SSL) including the mainstream contrastive learning
has achieved great success in learning visual representations without data
annotations. However, most methods mainly focus on the instance level
information (\ie, the different augmented images of the same instance should
have the same feature or cluster into the same class), but there is a lack of
attention on the relationships between different instances. In this paper, we
introduce a novel SSL paradigm, which we term as relational self-supervised
learning (ReSSL) framework that learns representations by modeling the
relationship between different instances. Specifically, our proposed method
employs sharpened distribution of pairwise similarities among different
instances as \textit{relation} metric, which is thus utilized to match the
feature embeddings of different augmentations. To boost the performance, we
argue that weak augmentations matter to represent a more reliable relation, and
leverage momentum strategy for practical efficiency. The designed asymmetric
predictor head and an InfoNCE warm-up strategy enhance the robustness to
hyper-parameters and benefit the resulting performance. Experimental results
show that our proposed ReSSL substantially outperforms the state-of-the-art
methods across different network architectures, including various lightweight
networks (\eg, EfficientNet and MobileNet).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attacking deep networks with surrogate-based adversarial black-box methods is easy. (arXiv:2203.08725v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08725">
<div class="article-summary-box-inner">
<span><p>A recent line of work on black-box adversarial attacks has revived the use of
transfer from surrogate models by integrating it into query-based search.
However, we find that existing approaches of this type underperform their
potential, and can be overly complicated besides. Here, we provide a short and
simple algorithm which achieves state-of-the-art results through a search which
uses the surrogate network's class-score gradients, with no need for other
priors or heuristics. The guiding assumption of the algorithm is that the
studied networks are in a fundamental sense learning similar functions, and
that a transfer attack from one to the other should thus be fairly "easy". This
assumption is validated by the extremely low query counts and failure rates
achieved: e.g. an untargeted attack on a VGG-16 ImageNet network using a
ResNet-152 as the surrogate yields a median query count of 6 at a success rate
of 99.9%. Code is available at https://github.com/fiveai/GFCS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tangles and Hierarchical Clustering. (arXiv:2203.08731v1 [cs.DM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08731">
<div class="article-summary-box-inner">
<span><p>We establish a connection between tangles, a concept from structural graph
theory that plays a central role in Robertson and Seymour's graph minor
project, and hierarchical clustering. Tangles cannot only be defined for
graphs, but in fact for arbitrary connectivity functions, which are functions
defined on the subsets of some finite universe. In typical clustering
applications these universes consist of points in some metric space.
Connectivity functions are usually required to be submodular. It is our first
contribution to show that the central duality theorem connecting tangles with
hierarchical decompositions (so-called branch decompositions) also holds if
submodularity is replaced by a different property that we call
maximum-submodular. We then define a connectivity function on finite data sets
in an arbitrary metric space and prove that its tangles are in one-to-one
correspondence with the clusters obtained by applying the well-known single
linkage clustering algorithms to the same data set. Lastly we generalize this
correspondence for any hierarchical clustering. We show that the data structure
that represents hierarchical clustering results, called dendograms, are
equivalent to maximum-submodular connectivity functions and their tangles. The
idea of viewing tangles as clusters has first been proposed by Diestel and
Whittle in 2016 as an approach to image segmentation. To the best of our
knowledge, our result is the first that establishes a precise technical
connection between tangles and clusters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Where To Look -- Generative NAS is Surprisingly Efficient. (arXiv:2203.08734v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08734">
<div class="article-summary-box-inner">
<span><p>The efficient, automated search for well-performing neural architectures
(NAS) has drawn increasing attention in the recent past. Thereby, the
predominant research objective is to reduce the necessity of costly evaluations
of neural architectures while efficiently exploring large search spaces. To
this aim, surrogate models embed architectures in a latent space and predict
their performance, while generative models for neural architectures enable
optimization-based search within the latent space the generator draws from.
Both, surrogate and generative models, have the aim of facilitating
query-efficient search in a well-structured latent space. In this paper, we
further improve the trade-off between query-efficiency and promising
architecture generation by leveraging advantages from both, efficient surrogate
models and generative design. To this end, we propose a generative model,
paired with a surrogate predictor, that iteratively learns to generate samples
from increasingly promising latent subspaces. This approach leads to very
effective and efficient architecture search, while keeping the query amount
low. In addition, our approach allows in a straightforward manner to jointly
optimize for multiple objectives such as accuracy and hardware latency. We show
the benefit of this approach not only w.r.t. the optimization of architectures
for highest classification accuracy but also in the context of hardware
constraints and outperform state-of-the art methods on several NAS benchmarks
for single and multiple objectives. We also achieve state-of-the-art
performance on ImageNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Do Adversarially trained Neural Networks Focus: A Fourier Domain-based Study. (arXiv:2203.08739v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08739">
<div class="article-summary-box-inner">
<span><p>Although many fields have witnessed the superior performance brought about by
deep learning, the robustness of neural networks remains an open issue.
Specifically, a small adversarial perturbation on the input may cause the model
to produce a completely different output. Such poor robustness implies many
potential hazards, especially in security-critical applications, e.g.,
autonomous driving and mobile robotics. This work studies what information the
adversarially trained model focuses on. Empirically, we notice that the
differences between the clean and adversarial data are mainly distributed in
the low-frequency region. We then find that an adversarially-trained model is
more robust than its naturally-trained counterpart due to the reason that the
former pays more attention to learning the dominant information in
low-frequency components. In addition, we consider two common ways to improve
model robustness, namely, by data augmentation and by using stronger network
architectures, and understand these techniques from a frequency-domain
perspective. We are hopeful this work can shed light on the design of more
robust neural networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UnseenNet: Fast Training Detector for Any Unseen Concept. (arXiv:2203.08759v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08759">
<div class="article-summary-box-inner">
<span><p>Training of object detection models using less data is currently the focus of
existing N-shot learning models in computer vision. Such methods use
object-level labels and takes hours to train on unseen classes. There are many
cases where we have large amount of image-level labels available for training
but cannot be utilized by few shot object detection models for training. There
is a need for a machine learning framework that can be used for training any
unseen class and can become useful in real-time situations. In this paper, we
proposed an "Unseen Class Detector" that can be trained within a very short
time for any possible unseen class without bounding boxes with competitive
accuracy. We build our approach on "Strong" and "Weak" baseline detectors,
which we trained on existing object detection and image classification
datasets, respectively. Unseen concepts are fine-tuned on the strong baseline
detector using only image-level labels and further adapted by transferring the
classifier-detector knowledge between baselines. We use semantic as well as
visual similarities to identify the source class (i.e. Sheep) for the
fine-tuning and adaptation of unseen class (i.e. Goat). Our model (UnseenNet)
is trained on the ImageNet classification dataset for unseen classes and tested
on an object detection dataset (OpenImages). UnseenNet improves the mean
average precision (mAP) by 10% to 30% over existing baselines (semi-supervised
and few-shot) of object detection on different unseen class splits. Moreover,
training time of our model is &lt;10 min for each unseen class. Qualitative
results demonstrate that UnseenNet is suitable not only for few classes of
Pascal VOC but for unseen classes of any dataset or web. Code is available at
https://github.com/Asra-Aslam/UnseenNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">X-Learner: Learning Cross Sources and Tasks for Universal Visual Representation. (arXiv:2203.08764v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08764">
<div class="article-summary-box-inner">
<span><p>In computer vision, pre-training models based on largescale supervised
learning have been proven effective over the past few years. However, existing
works mostly focus on learning from individual task with single data source
(e.g., ImageNet for classification or COCO for detection). This restricted form
limits their generalizability and usability due to the lack of vast semantic
information from various tasks and data sources. Here, we demonstrate that
jointly learning from heterogeneous tasks and multiple data sources contributes
to universal visual representation, leading to better transferring results of
various downstream tasks. Thus, learning how to bridge the gaps among different
tasks and data sources is the key, but it still remains an open question. In
this work, we propose a representation learning framework called X-Learner,
which learns the universal feature of multiple vision tasks supervised by
various sources, with expansion and squeeze stage: 1) Expansion Stage:
X-Learner learns the task-specific feature to alleviate task interference and
enrich the representation by reconciliation layer. 2) Squeeze Stage: X-Learner
condenses the model to a reasonable size and learns the universal and
generalizable representation for various tasks transferring. Extensive
experiments demonstrate that X-Learner achieves strong performance on different
tasks without extra annotations, modalities and computational costs compared to
existing representation learning methods. Notably, a single X-Learner model
shows remarkable gains of 3.0%, 3.3% and 1.8% over current pretrained models on
12 downstream datasets for classification, object detection and semantic
segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient conditioned face animation using frontally-viewed embedding. (arXiv:2203.08765v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08765">
<div class="article-summary-box-inner">
<span><p>As the quality of few shot facial animation from landmarks increases, new
applications become possible, such as ultra low bandwidth video chat
compression with a high degree of realism. However, there are some important
challenges to tackle in order to improve the experience in real world
conditions. In particular, the current approaches fail to represent profile
views without distortions, while running in a low compute regime. We focus on
this key problem by introducing a multi-frames embedding dubbed Frontalizer to
improve profile views rendering. In addition to this core improvement, we
explore the learning of a latent code conditioning generations along with
landmarks to better convey facial expressions. Our dense models achieves 22% of
improvement in perceptual quality and 73% reduction of landmark error over the
first order model baseline on a subset of DFDC videos containing head
movements. Declined with mobile architectures, our models outperform the
previous state-of-the-art (improving perceptual quality by more than 16% and
reducing landmark error by more than 47% on two datasets) while running on real
time on iPhone 8 with very low bandwidth requirements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object discovery and representation networks. (arXiv:2203.08777v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08777">
<div class="article-summary-box-inner">
<span><p>The promise of self-supervised learning (SSL) is to leverage large amounts of
unlabeled data to solve complex tasks. While there has been excellent progress
with simple, image-level learning, recent methods have shown the advantage of
including knowledge of image structure. However, by introducing hand-crafted
image segmentations to define regions of interest, or specialized augmentation
strategies, these methods sacrifice the simplicity and generality that makes
SSL so powerful. Instead, we propose a self-supervised learning paradigm that
discovers the structure encoded in these priors by itself. Our method, Odin,
couples object discovery and representation networks to discover meaningful
image segmentations without any supervision. The resulting learning paradigm is
simpler, less brittle, and more general, and achieves state-of-the-art transfer
learning results for object detection and instance segmentation on COCO, and
semantic segmentation on PASCAL and Cityscapes, while strongly surpassing
supervised pre-training for video segmentation on DAVIS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PosePipe: Open-Source Human Pose Estimation Pipeline for Clinical Research. (arXiv:2203.08792v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08792">
<div class="article-summary-box-inner">
<span><p>There has been significant progress in machine learning algorithms for human
pose estimation that may provide immense value in rehabilitation and movement
sciences. However, there remain several challenges to routine use of these
tools for clinical practice and translational research, including: 1) high
technical barrier to entry, 2) rapidly evolving space of algorithms, 3)
challenging algorithmic interdependencies, and 4) complex data management
requirements between these components. To mitigate these barriers, we developed
a human pose estimation pipeline that facilitates running state-of-the-art
algorithms on data acquired in clinical context. Our system allows for running
different implementations of several classes of algorithms and handles their
interdependencies easily. These algorithm classes include subject
identification and tracking, 2D keypoint detection, 3D joint location
estimation, and estimating the pose of body models. The system uses a database
to manage videos, intermediate analyses, and data for computations at each
stage. It also provides tools for data visualization, including generating
video overlays that also obscure faces to enhance privacy. Our goal in this
work is not to train new algorithms, but to advance the use of cutting-edge
human pose estimation algorithms for clinical and translation research. We show
that this tool facilitates analyzing large numbers of videos of human movement
ranging from gait laboratories analyses, to clinic and therapy visits, to
people in the community. We also highlight limitations of these algorithms when
applied to clinical populations in a rehabilitation setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero Pixel Directional Boundary by Vector Transform. (arXiv:2203.08795v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08795">
<div class="article-summary-box-inner">
<span><p>Boundaries are among the primary visual cues used by human and computer
vision systems. One of the key problems in boundary detection is the label
representation, which typically leads to class imbalance and, as a consequence,
to thick boundaries that require non-differential post-processing steps to be
thinned. In this paper, we re-interpret boundaries as 1-D surfaces and
formulate a one-to-one vector transform function that allows for training of
boundary prediction completely avoiding the class imbalance issue.
Specifically, we define the boundary representation at any point as the unit
vector pointing to the closest boundary surface. Our problem formulation leads
to the estimation of direction as well as richer contextual information of the
boundary, and, if desired, the availability of zero-pixel thin boundaries also
at training time. Our method uses no hyper-parameter in the training loss and a
fixed stable hyper-parameter at inference. We provide theoretical
justification/discussions of the vector transform representation. We evaluate
the proposed loss method using a standard architecture and show the excellent
performance over other losses and representations on several datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Continual Learning Framework for Adaptive Defect Classification and Inspection. (arXiv:2203.08796v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08796">
<div class="article-summary-box-inner">
<span><p>Machine-vision-based defect classification techniques have been widely
adopted for automatic quality inspection in manufacturing processes. This
article describes a general framework for classifying defects from high volume
data batches with efficient inspection of unlabelled samples. The concept is to
construct a detector to identify new defect types, send them to the inspection
station for labelling, and dynamically update the classifier in an efficient
manner that reduces both storage and computational needs imposed by data
samples of previously observed batches. Both a simulation study on image
classification and a case study on surface defect detection via 3D point clouds
are performed to demonstrate the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Theme-Aware Aesthetic Distribution Prediction With Full-Resolution Photographs. (arXiv:1908.01308v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.01308">
<div class="article-summary-box-inner">
<span><p>Aesthetic quality assessment (AQA) is a challenging task due to complex
aesthetic factors. Currently, it is common to conduct AQA using deep neural
networks that require fixed-size inputs. Existing methods mainly transform
images by resizing, cropping, and padding or employ adaptive pooling to
alternately capture the aesthetic features from fixed-size inputs. However,
these transformations potentially damage aesthetic features. To address this
issue, we propose a simple but effective method to accomplish full-resolution
image AQA by combining image padding with region of image (RoM) pooling.
Padding turns inputs into the same size. RoM pooling pools image features and
discards extra padded features to eliminate the side effects of padding. In
addition, the image aspect ratios are encoded and fused with visual features to
remedy the shape information loss of RoM pooling. Furthermore, we observe that
the same image may receive different aesthetic evaluations under different
themes, which we call theme criterion bias. Hence, a theme-aware model that
uses theme information to guide model predictions is proposed. Finally, we
design an attention-based feature fusion module to effectively utilize both the
shape and theme information. Extensive experiments prove the effectiveness of
the proposed method over state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Deep Learning-based Architectures for Semantic Segmentation on 2D images. (arXiv:1912.10230v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.10230">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation is the pixel-wise labelling of an image. Since the
problem is defined at the pixel level, determining image class labels only is
not acceptable, but localising them at the original image pixel resolution is
necessary. Boosted by the extraordinary ability of convolutional neural
networks (CNN) in creating semantic, high level and hierarchical image
features; several deep learning-based 2D semantic segmentation approaches have
been proposed within the last decade. In this survey, we mainly focus on the
recent scientific developments in semantic segmentation, specifically on deep
learning-based methods using 2D images. We started with an analysis of the
public image sets and leaderboards for 2D semantic segmentation, with an
overview of the techniques employed in performance evaluation. In examining the
evolution of the field, we chronologically categorised the approaches into
three main periods, namely pre-and early deep learning era, the fully
convolutional era, and the post-FCN era. We technically analysed the solutions
put forward in terms of solving the fundamental problems of the field, such as
fine-grained localisation and scale invariance. Before drawing our conclusions,
we present a table of methods from all mentioned eras, with a summary of each
approach that explains their contribution to the field. We conclude the survey
by discussing the current challenges of the field and to what extent they have
been solved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Parameter Allocation Search. (arXiv:2006.10598v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10598">
<div class="article-summary-box-inner">
<span><p>Training neural networks requires increasing amounts of memory. Parameter
sharing can reduce memory and communication costs, but existing methods assume
networks have many identical layers and utilize hand-crafted sharing strategies
that fail to generalize. We introduce Neural Parameter Allocation Search
(NPAS), a novel task where the goal is to train a neural network given an
arbitrary, fixed parameter budget. NPAS covers both low-budget regimes, which
produce compact networks, as well as a novel high-budget regime, where
additional capacity can be added to boost performance without increasing
inference FLOPs. To address NPAS, we introduce Shapeshifter Networks (SSNs),
which automatically learn where and how to share parameters in a network to
support any parameter budget without requiring any changes to the architecture
or loss function. NPAS and SSNs provide a complete framework for addressing
generalized parameter sharing, and can also be combined with prior work for
additional performance gains. We demonstrate the effectiveness of our approach
using nine network architectures across four diverse tasks, including ImageNet
classification and transformers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Super Resolution Based on Deep Learning: A Comprehensive Survey. (arXiv:2007.12928v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12928">
<div class="article-summary-box-inner">
<span><p>In recent years, deep learning has made great progress in many fields such as
image recognition, natural language processing, speech recognition and video
super-resolution. In this survey, we comprehensively investigate 33
state-of-the-art video super-resolution (VSR) methods based on deep learning.
It is well known that the leverage of information within video frames is
important for video super-resolution. Thus we propose a taxonomy and classify
the methods into six sub-categories according to the ways of utilizing
inter-frame information. Moreover, the architectures and implementation details
of all the methods are depicted in detail. Finally, we summarize and compare
the performance of the representative VSR method on some benchmark datasets. We
also discuss some challenges, which need to be further addressed by researchers
in the community of VSR. To the best of our knowledge, this work is the first
systematic review on VSR tasks, and it is expected to make a contribution to
the development of recent studies in this area and potentially deepen our
understanding to the VSR techniques based on deep learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win. (arXiv:2010.03533v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03533">
<div class="article-summary-box-inner">
<span><p>Sparse Neural Networks (NNs) can match the generalization of dense NNs using
a fraction of the compute/storage for inference, and also have the potential to
enable efficient training. However, naively training unstructured sparse NNs
from random initialization results in significantly worse generalization, with
the notable exceptions of Lottery Tickets (LTs) and Dynamic Sparse Training
(DST). Through our analysis of gradient flow during training we attempt to
answer: (1) why training unstructured sparse networks from random
initialization performs poorly and; (2) what makes LTs and DST the exceptions?
We show that sparse NNs have poor gradient flow at initialization and
demonstrate the importance of using sparsity-aware initialization. Furthermore,
we find that DST methods significantly improve gradient flow during training
over traditional sparse training methods. Finally, we show that LTs do not
improve gradient flow, rather their success lies in re-learning the pruning
solution they are derived from - however, this comes at the cost of learning
novel solutions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Surprising Positive Knowledge Transfer in Continual 3D Object Shape Reconstruction. (arXiv:2101.07295v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07295">
<div class="article-summary-box-inner">
<span><p>Continual learning has been extensively studied for classification tasks with
methods developed to primarily avoid catastrophic forgetting, a phenomenon
where earlier learned concepts are forgotten at the expense of more recent
samples. In this work, we present a set of continual 3D object shape
reconstruction tasks including complete 3D shape reconstruction from different
input modalities and visible surface (2.5D) reconstruction which surprisingly
demonstrates positive knowledge (backward and forward) transfer when training
with solely vanilla SGD and without additional heuristics. We provide evidence
that continuously updated representation learning of single-view 3D shape
reconstruction improves the performance on learned and novel categories over
time. We provide a novel analysis of knowledge transfer ability by looking at
the output distribution shift across sequential learning tasks. Finally, we
show that the robustness of these tasks leads to the potential of having a
proxy representation learning task for continual classification. The codebase,
dataset, and pre-trained models released with this article can be found at
https://github.com/rehg-lab/CLRec.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning. (arXiv:2103.00370v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00370">
<div class="article-summary-box-inner">
<span><p>Visual search, recommendation, and contrastive similarity learning power
technologies that impact billions of users worldwide. Modern model
architectures can be complex and difficult to interpret, and there are several
competing techniques one can use to explain a search engine's behavior. We show
that the theory of fair credit assignment provides a $\textit{unique}$
axiomatic solution that generalizes several existing recommendation- and
metric-explainability techniques in the literature. Using this formalism, we
show when existing approaches violate "fairness" and derive methods that
sidestep these shortcomings and naturally handle counterfactual information.
More specifically, we show existing approaches implicitly approximate
second-order Shapley-Taylor indices and extend CAM, GradCAM, LIME, SHAP, SBSM,
and other methods to search engines. These extensions can extract pairwise
correspondences between images from trained $\textit{opaque-box}$ models. We
also introduce a fast kernel-based method for estimating Shapley-Taylor indices
that require orders of magnitude fewer function evaluations to converge.
Finally, we show that these game-theoretic measures yield more consistent
explanations for image similarity architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Ultra-Resolution Neural Style Transfer via Thumbnail Instance Normalization. (arXiv:2103.11784v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11784">
<div class="article-summary-box-inner">
<span><p>We present an extremely simple Ultra-Resolution Style Transfer framework,
termed URST, to flexibly process arbitrary high-resolution images (e.g.,
10000x10000 pixels) style transfer for the first time. Most of the existing
state-of-the-art methods would fall short due to massive memory cost and small
stroke size when processing ultra-high resolution images. URST completely
avoids the memory problem caused by ultra-high resolution images by (1)
dividing the image into small patches and (2) performing patch-wise style
transfer with a novel Thumbnail Instance Normalization (TIN). Specifically, TIN
can extract thumbnail features' normalization statistics and apply them to
small patches, ensuring the style consistency among different patches.
</p>
<p>Overall, the URST framework has three merits compared to prior arts. (1) We
divide input image into small patches and adopt TIN, successfully transferring
image style with arbitrary high-resolution. (2) Experiments show that our URST
surpasses existing SOTA methods on ultra-high resolution images benefiting from
the effectiveness of the proposed stroke perceptual loss in enlarging the
stroke size. (3) Our URST can be easily plugged into most existing style
transfer methods and directly improve their performance even without training.
Code is available at https://git.io/URST.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text to Image Generation with Semantic-Spatial Aware GAN. (arXiv:2104.00567v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00567">
<div class="article-summary-box-inner">
<span><p>Text-to-image synthesis (T2I) aims to generate photo-realistic images which
are semantically consistent with the text descriptions. Existing methods are
usually built upon conditional generative adversarial networks (GANs) and
initialize an image from noise with sentence embedding, and then refine the
features with fine-grained word embedding iteratively. A close inspection of
their generated images reveals a major limitation: even though the generated
image holistically matches the description, individual image regions or parts
of somethings are often not recognizable or consistent with words in the
sentence, e.g. "a white crown". To address this problem, we propose a novel
framework Semantic-Spatial Aware GAN for synthesizing images from input text.
Concretely, we introduce a simple and effective Semantic-Spatial Aware block,
which (1) learns semantic-adaptive transformation conditioned on text to
effectively fuse text features and image features, and (2) learns a semantic
mask in a weakly-supervised way that depends on the current text-image fusion
process in order to guide the transformation spatially. Experiments on the
challenging COCO and CUB bird datasets demonstrate the advantage of our method
over the recent state-of-the-art approaches, regarding both visual fidelity and
alignment with input text description. Code available at
https://github.com/wtliao/text2image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Deep Neural Networks Forget Facial Action Units? -- Exploring the Effects of Transfer Learning in Health Related Facial Expression Recognition. (arXiv:2104.07389v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07389">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a process to investigate the effects of transfer
learning for automatic facial expression recognition from emotions to pain. To
this end, we first train a VGG16 convolutional neural network to automatically
discern between eight categorical emotions. We then fine-tune successively
larger parts of this network to learn suitable representations for the task of
automatic pain recognition. Subsequently, we apply those fine-tuned
representations again to the original task of emotion recognition to further
investigate the differences in performance between the models. In the second
step, we use Layer-wise Relevance Propagation to analyze predictions of the
model that have been predicted correctly previously but are now wrongly
classified. Based on this analysis, we rely on the visual inspection of a human
observer to generate hypotheses about what has been forgotten by the model.
Finally, we test those hypotheses quantitatively utilizing concept embedding
analysis methods. Our results show that the network, which was fully fine-tuned
for pain recognition, indeed payed less attention to two action units that are
relevant for expression recognition but not for pain recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13450">
<div class="article-summary-box-inner">
<span><p>Digital watermarking is widely used for copyright protection. Traditional 3D
watermarking approaches or commercial software are typically designed to embed
messages into 3D meshes, and later retrieve the messages directly from
distorted/undistorted watermarked 3D meshes. However, in many cases, users only
have access to rendered 2D images instead of 3D meshes. Unfortunately,
retrieving messages from 2D renderings of 3D meshes is still challenging and
underexplored. We introduce a novel end-to-end learning framework to solve this
problem through: 1) an encoder to covertly embed messages in both mesh geometry
and textures; 2) a differentiable renderer to render watermarked 3D objects
from different camera angles and under varied lighting conditions; 3) a decoder
to recover the messages from 2D rendered images. From our experiments, we show
that our model can learn to embed information visually imperceptible to humans,
and to retrieve the embedded information from 2D renderings that undergo 3D
distortions. In addition, we demonstrate that our method can also work with
other renderers, such as ray tracers and real-time renderers with and without
fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VISITRON: Visual Semantics-Aligned Interactively Trained Object-Navigator. (arXiv:2105.11589v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11589">
<div class="article-summary-box-inner">
<span><p>Interactive robots navigating photo-realistic environments need to be trained
to effectively leverage and handle the dynamic nature of dialogue in addition
to the challenges underlying vision-and-language navigation (VLN). In this
paper, we present VISITRON, a multi-modal Transformer-based navigator better
suited to the interactive regime inherent to Cooperative Vision-and-Dialog
Navigation (CVDN). VISITRON is trained to: i) identify and associate
object-level concepts and semantics between the environment and dialogue
history, ii) identify when to interact vs. navigate via imitation learning of a
binary classification head. We perform extensive pre-training and fine-tuning
ablations with VISITRON to gain empirical insights and improve performance on
CVDN. VISITRON's ability to identify when to interact leads to a natural
generalization of the game-play mode introduced by Roman et al.
(<a href="/abs/2005.00728">arXiv:2005.00728</a>) for enabling the use of such models in different
environments. VISITRON is competitive with models on the static CVDN
leaderboard and attains state-of-the-art performance on the Success weighted by
Path Length (SPL) metric.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental False Negative Detection for Contrastive Learning. (arXiv:2106.03719v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03719">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning has recently shown great potential in vision tasks
through contrastive learning, which aims to discriminate each image, or
instance, in the dataset. However, such instance-level learning ignores the
semantic relationship among instances and sometimes undesirably repels the
anchor from the semantically similar samples, termed as "false negatives". In
this work, we show that the unfavorable effect from false negatives is more
significant for the large-scale datasets with more semantic concepts. To
address the issue, we propose a novel self-supervised contrastive learning
framework that incrementally detects and explicitly removes the false negative
samples. Specifically, following the training process, our method dynamically
detects increasing high-quality false negatives considering that the encoder
gradually improves and the embedding space becomes more semantically
structural. Next, we discuss two strategies to explicitly remove the detected
false negatives during contrastive learning. Extensive experiments show that
our framework outperforms other self-supervised contrastive learning methods on
multiple benchmarks in a limited resource setup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the relation between statistical learning and perceptual distances. (arXiv:2106.04427v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04427">
<div class="article-summary-box-inner">
<span><p>It has been demonstrated many times that the behavior of the human visual
system is connected to the statistics of natural images. Since machine learning
relies on the statistics of training data as well, the above connection has
interesting implications when using perceptual distances (which mimic the
behavior of the human visual system) as a loss function. In this paper, we aim
to unravel the non-trivial relationships between the probability distribution
of the data, perceptual distances, and unsupervised machine learning. To this
end, we show that perceptual sensitivity is correlated with the probability of
an image in its close neighborhood. We also explore the relation between
distances induced by autoencoders and the probability distribution of the
training data, as well as how these induced distances are correlated with human
perception. Finally, we find perceptual distances do not always lead to
noticeable gains in performance over Euclidean distance in common image
processing tasks, except when data is scarce and the perceptual distance
provides regularization. We propose this may be due to a \emph{double-counting}
effect of the image statistics, once in the perceptual distance and once in the
training procedure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Models as a Data Source for Multiview Representation Learning. (arXiv:2106.05258v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05258">
<div class="article-summary-box-inner">
<span><p>Generative models are now capable of producing highly realistic images that
look nearly indistinguishable from the data on which they are trained. This
raises the question: if we have good enough generative models, do we still need
datasets? We investigate this question in the setting of learning
general-purpose visual representations from a black-box generative model rather
than directly from data. Given an off-the-shelf image generator without any
access to its training data, we train representations from the samples output
by this generator. We compare several representation learning methods that can
be applied to this setting, using the latent space of the generator to generate
multiple "views" of the same semantic content. We show that for contrastive
methods, this multiview data can naturally be used to identify positive pairs
(nearby in latent space) and negative pairs (far apart in latent space). We
find that the resulting representations rival or even outperform those learned
directly from real data, but that good performance requires care in the
sampling strategy applied and the training method. Generative models can be
viewed as a compressed and organized copy of a dataset, and we envision a
future where more and more "model zoos" proliferate while datasets become
increasingly unwieldy, missing, or private. This paper suggests several
techniques for dealing with visual representation learning in such a future.
Code is available on our project page https://ali-design.github.io/GenRep/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Looking Outside the Window: Wide-Context Transformer for the Semantic Segmentation of High-Resolution Remote Sensing Images. (arXiv:2106.15754v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15754">
<div class="article-summary-box-inner">
<span><p>Long-range contextual information is crucial for the semantic segmentation of
High-Resolution (HR) Remote Sensing Images (RSIs). However, image cropping
operations, commonly used for training neural networks, limit the perception of
long-range contexts in large RSIs. To overcome this limitation, we propose a
Wide-Context Network (WiCoNet) for the semantic segmentation of HR RSIs. Apart
from extracting local features with a conventional CNN, the WiCoNet has an
extra context branch to aggregate information from a larger image area.
Moreover, we introduce a Context Transformer to embed contextual information
from the context branch and selectively project it onto the local features. The
Context Transformer extends the Vision Transformer, an emerging kind of neural
network, to model the dual-branch semantic correlations. It overcomes the
locality limitation of CNNs and enables the WiCoNet to see the bigger picture
before segmenting the land-cover/land-use (LCLU) classes. Ablation studies and
comparative experiments conducted on several benchmark datasets demonstrate the
effectiveness of the proposed method. In addition, we present a new Beijing
Land-Use (BLU) dataset. This is a large-scale HR satellite dataset with
high-quality and fine-grained reference labels, which can facilitate future
studies in this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast whole-slide cartography in colon cancer histology using superpixels and CNN classification. (arXiv:2106.15893v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15893">
<div class="article-summary-box-inner">
<span><p>Automatic outlining of different tissue types in digitized histological
specimen provides a basis for follow-up analyses and can potentially guide
subsequent medical decisions. The immense size of whole-slide-images (WSI),
however, poses a challenge in terms of computation time. In this regard, the
analysis of non-overlapping patches outperforms pixelwise segmentation
approaches, but still leaves room for optimization. Furthermore, the division
into patches, regardless of the biological structures they contain, is a
drawback due to the loss of local dependencies. We propose to subdivide the WSI
into coherent regions prior to classification by grouping visually similar
adjacent pixels into superpixels. Afterwards, only a random subset of patches
per superpixel is classified and patch labels are combined into a superpixel
label. We propose a metric for identifying superpixels with an uncertain
classification and evaluate two medical applications, namely tumor area and
invasive margin estimation and tumor composition analysis. The algorithm has
been developed on 159 hand-annotated WSIs of colon resections and its
performance is compared to an analysis without prior segmentation. The
algorithm shows an average speed-up of 41% and an increase in accuracy from
93.8% to 95.7%. By assigning a rejection label to uncertain superpixels, we
further increase the accuracy by 0.4%. Whilst tumor area estimation shows high
concordance to the annotated area, the analysis of tumor composition highlights
limitations of our approach. By combining superpixel segmentation and patch
classification, we designed a fast and accurate framework for whole-slide
cartography that is AI-model agnostic and provides the basis for various
medical endpoints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Blind Image Super-resolution with Elaborate Degradation Modeling on Noise and Kernel. (arXiv:2107.00986v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00986">
<div class="article-summary-box-inner">
<span><p>While researches on model-based blind single image super-resolution (SISR)
have achieved tremendous successes recently, most of them do not consider the
image degradation sufficiently. Firstly, they always assume image noise obeys
an independent and identically distributed (i.i.d.) Gaussian or Laplacian
distribution, which largely underestimates the complexity of real noise.
Secondly, previous commonly-used kernel priors (e.g., normalization, sparsity)
are not effective enough to guarantee a rational kernel solution, and thus
degenerates the performance of subsequent SISR task. To address the above
issues, this paper proposes a model-based blind SISR method under the
probabilistic framework, which elaborately models image degradation from the
perspectives of noise and blur kernel. Specifically, instead of the traditional
i.i.d. noise assumption, a patch-based non-i.i.d. noise model is proposed to
tackle the complicated real noise, expecting to increase the degrees of freedom
of the model for noise representation. As for the blur kernel, we novelly
construct a concise yet effective kernel generator, and plug it into the
proposed blind SISR method as an explicit kernel prior (EKP). To solve the
proposed model, a theoretically grounded Monte Carlo EM algorithm is
specifically designed. Comprehensive experiments demonstrate the superiority of
our method over current state-of-the-arts on synthetic and real datasets. The
source code is available at https://github.com/zsyOAOA/BSRDM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Discovery of Object Radiance Fields. (arXiv:2107.07905v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07905">
<div class="article-summary-box-inner">
<span><p>We study the problem of inferring an object-centric scene representation from
a single image, aiming to derive a representation that explains the image
formation process, captures the scene's 3D nature, and is learned without
supervision. Most existing methods on scene decomposition lack one or more of
these characteristics, due to the fundamental challenge in integrating the
complex 3D-to-2D image formation process into powerful inference schemes like
deep networks. In this paper, we propose unsupervised discovery of Object
Radiance Fields (uORF), integrating recent progresses in neural 3D scene
representations and rendering with deep inference networks for unsupervised 3D
scene decomposition. Trained on multi-view RGB images without annotations, uORF
learns to decompose complex scenes with diverse, textured background from a
single image. We show that uORF enables novel tasks, such as scene segmentation
and editing in 3D, and it performs well on these tasks and on novel view
synthesis on three datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perceiver IO: A General Architecture for Structured Inputs & Outputs. (arXiv:2107.14795v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14795">
<div class="article-summary-box-inner">
<span><p>A central goal of machine learning is the development of systems that can
solve many problems in as many data domains as possible. Current architectures,
however, cannot be applied beyond a small set of stereotyped settings, as they
bake in domain &amp; task assumptions or scale poorly to large inputs or outputs.
In this work, we propose Perceiver IO, a general-purpose architecture that
handles data from arbitrary settings while scaling linearly with the size of
inputs and outputs. Our model augments the Perceiver with a flexible querying
mechanism that enables outputs of various sizes and semantics, doing away with
the need for task-specific architecture engineering. The same architecture
achieves strong results on tasks spanning natural language and visual
understanding, multi-task and multi-modal reasoning, and StarCraft II. As
highlights, Perceiver IO outperforms a Transformer-based BERT baseline on the
GLUE language benchmark despite removing input tokenization and achieves
state-of-the-art performance on Sintel optical flow estimation with no explicit
mechanisms for multiscale correspondence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rapid Elastic Architecture Search under Specialized Classes and Resource Constraints. (arXiv:2108.01224v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01224">
<div class="article-summary-box-inner">
<span><p>In many real-world applications, we often need to handle various deployment
scenarios, where the resource constraint and the superclass of interest
corresponding to a group of classes are dynamically specified. How to
efficiently deploy deep models for diverse deployment scenarios is a new
challenge. Previous NAS approaches seek to design architectures for all classes
simultaneously, which may not be optimal for some individual superclasses. A
straightforward solution is to search an architecture from scratch for each
deployment scenario, which however is computation-intensive and impractical. To
address this, we present a novel and general framework, called Elastic
Architecture Search (EAS), permitting instant specializations at runtime for
diverse superclasses with various resource constraints. To this end, we first
propose to effectively train an over-parameterized network via a superclass
dropout strategy during training. In this way, the resulting model is robust to
the subsequent superclasses dropping at inference time. Based on the
well-trained over-parameterized network, we then propose an efficient
architecture generator to obtain promising architectures within a single
forward pass. Experiments on three image classification datasets show that EAS
is able to find more compact networks with better performance while remarkably
being orders of magnitude faster than state-of-the-art NAS methods, e.g.,
outperforming OFA (once-for-all) by 1.3% on Top-1 accuracy at a budget around
361M #MAdds on ImageNet-10. More critically, EAS is able to find compact
architectures within 0.1 second for 50 deployment scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SphereFace2: Binary Classification is All You Need for Deep Face Recognition. (arXiv:2108.01513v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01513">
<div class="article-summary-box-inner">
<span><p>State-of-the-art deep face recognition methods are mostly trained with a
softmax-based multi-class classification framework. Despite being popular and
effective, these methods still have a few shortcomings that limit empirical
performance. In this paper, we start by identifying the discrepancy between
training and evaluation in the existing multi-class classification framework
and then discuss the potential limitations caused by the "competitive" nature
of softmax normalization. Motivated by these limitations, we propose a novel
binary classification training framework, termed SphereFace2. In contrast to
existing methods, SphereFace2 circumvents the softmax normalization, as well as
the corresponding closed-set assumption. This effectively bridges the gap
between training and evaluation, enabling the representations to be improved
individually by each binary classification task. Besides designing a specific
well-performing loss function, we summarize a few general principles for this
"one-vs-all" binary classification framework so that it can outperform current
competitive methods. Our experiments on popular benchmarks demonstrate that
SphereFace2 can consistently outperform state-of-the-art deep face recognition
methods. The code has been made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The University of California San Francisco Preoperative Diffuse Glioma MRI (UCSF-PDGM) Dataset. (arXiv:2109.00356v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00356">
<div class="article-summary-box-inner">
<span><p>Here we present the University of California San Francisco Preoperative
Diffuse Glioma MRI (UCSF-PDGM) dataset. The UCSF-PDGM dataset includes 500
subjects with histopathologically-proven diffuse gliomas who were imaged with a
standardized 3 Tesla preoperative brain tumor MRI protocol featuring
predominantly 3D imaging, as well as advanced diffusion and perfusion imaging
techniques. The dataset also includes isocitrate dehydrogenase (IDH) mutation
status for all cases and O6-methylguanine-DNA methyltransferase (MGMT) promotor
methylation status for World Health Organization (WHO) grade III and IV
gliomas. The UCSF-PDGM has been made publicly available in the hopes that
researchers around the world will use these data to continue to push the
boundaries of AI applications for diffuse gliomas.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SphereFace Revived: Unifying Hyperspherical Face Recognition. (arXiv:2109.05565v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05565">
<div class="article-summary-box-inner">
<span><p>This paper addresses the deep face recognition problem under an open-set
protocol, where ideal face features are expected to have smaller maximal
intra-class distance than minimal inter-class distance under a suitably chosen
metric space. To this end, hyperspherical face recognition, as a promising line
of research, has attracted increasing attention and gradually become a major
focus in face recognition research. As one of the earliest works in
hyperspherical face recognition, SphereFace explicitly proposed to learn face
embeddings with large inter-class angular margin. However, SphereFace still
suffers from severe training instability which limits its application in
practice. In order to address this problem, we introduce a unified framework to
understand large angular margin in hyperspherical face recognition. Under this
framework, we extend the study of SphereFace and propose an improved variant
with substantially better training stability -- SphereFace-R. Specifically, we
propose two novel ways to implement the multiplicative margin, and study
SphereFace-R under three different feature normalization schemes (no feature
normalization, hard feature normalization and soft feature normalization). We
also propose an implementation strategy -- "characteristic gradient detachment"
-- to stabilize training. Extensive experiments on SphereFace-R show that it is
consistently better than or competitive with state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Downsample for Segmentation of Ultra-High Resolution Images. (arXiv:2109.11071v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11071">
<div class="article-summary-box-inner">
<span><p>Many computer vision systems require low-cost segmentation algorithms based
on deep learning, either because of the enormous size of input images or
limited computational budget. Common solutions uniformly downsample the input
images to meet memory constraints, assuming all pixels are equally informative.
In this work, we demonstrate that this assumption can harm the segmentation
performance because the segmentation difficulty varies spatially. We combat
this problem by introducing a learnable downsampling module, which can be
optimised together with the given segmentation model in an end-to-end fashion.
We formulate the problem of training such downsampling module as optimisation
of sampling density distributions over the input images given their
low-resolution views. To defend against degenerate solutions (e.g.
over-sampling trivial regions like the backgrounds), we propose a
regularisation term that encourages the sampling locations to concentrate
around the object boundaries. We find the downsampling module learns to sample
more densely at difficult locations, thereby improving the segmentation
performance. Our experiments on benchmarks of high-resolution street view,
aerial and medical images demonstrate substantial improvements in terms of
efficiency-and-accuracy trade-off compared to both uniform downsampling and two
recent advanced downsampling techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spike-inspired Rank Coding for Fast and Accurate Recurrent Neural Networks. (arXiv:2110.02865v3 [cs.NE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02865">
<div class="article-summary-box-inner">
<span><p>Biological spiking neural networks (SNNs) can temporally encode information
in their outputs, e.g. in the rank order in which neurons fire, whereas
artificial neural networks (ANNs) conventionally do not. As a result, models of
SNNs for neuromorphic computing are regarded as potentially more rapid and
efficient than ANNs when dealing with temporal input. On the other hand, ANNs
are simpler to train, and usually achieve superior performance. Here we show
that temporal coding such as rank coding (RC) inspired by SNNs can also be
applied to conventional ANNs such as LSTMs, and leads to computational savings
and speedups. In our RC for ANNs, we apply backpropagation through time using
the standard real-valued activations, but only from a strategically early time
step of each sequential input example, decided by a threshold-crossing event.
Learning then incorporates naturally also _when_ to produce an output, without
other changes to the model or the algorithm. Both the forward and the backward
training pass can be significantly shortened by skipping the remaining input
sequence after that first event. RC-training also significantly reduces
time-to-insight during inference, with a minimal decrease in accuracy. The
desired speed-accuracy trade-off is tunable by varying the threshold or a
regularization parameter that rewards output entropy. We demonstrate these in
two toy problems of sequence classification, and in a temporally-encoded MNIST
dataset where our RC model achieves 99.19% accuracy after the first input
time-step, outperforming the state of the art in temporal coding with SNNs, as
well as in spoken-word classification of Google Speech Commands, outperforming
non-RC-trained early inference with LSTMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepSSM: A Blueprint for Image-to-Shape Deep Learning Models. (arXiv:2110.07152v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07152">
<div class="article-summary-box-inner">
<span><p>Statistical shape modeling (SSM) characterizes anatomical variations in a
population of shapes generated from medical images. SSM requires consistent
shape representation across samples in shape cohort. Establishing this
representation entails a processing pipeline that includes anatomy
segmentation, re-sampling, registration, and non-linear optimization. These
shape representations are then used to extract low-dimensional shape
descriptors that facilitate subsequent analyses in different applications.
However, the current process of obtaining these shape descriptors from imaging
data relies on human and computational resources, requiring domain expertise
for segmenting anatomies of interest. Moreover, this same taxing pipeline needs
to be repeated to infer shape descriptors for new image data using a
pre-trained/existing shape model. Here, we propose DeepSSM, a deep
learning-based framework for learning the functional mapping from images to
low-dimensional shape descriptors and their associated shape representations,
thereby inferring statistical representation of anatomy directly from 3D
images. Once trained using an existing shape model, DeepSSM circumvents the
heavy and manual pre-processing and segmentation and significantly improves the
computational time, making it a viable solution for fully end-to-end SSM
applications. In addition, we introduce a model-based data-augmentation
strategy to address data scarcity. Finally, this paper presents and analyzes
two different architectural variants of DeepSSM with different loss functions
using three medical datasets and their downstream clinical application.
Experiments showcase that DeepSSM performs comparably or better to the
state-of-the-art SSM both quantitatively and on application-driven downstream
tasks. Therefore, DeepSSM aims to provide a comprehensive blueprint for deep
learning-based image-to-shape models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Procedural Knowledge by Sequencing Multimodal Instructional Manuals. (arXiv:2110.08486v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08486">
<div class="article-summary-box-inner">
<span><p>The ability to sequence unordered events is an essential skill to comprehend
and reason about real world task procedures, which often requires thorough
understanding of temporal common sense and multimodal information, as these
procedures are often communicated through a combination of texts and images.
Such capability is essential for applications such as sequential task planning
and multi-source instruction summarization. While humans are capable of
reasoning about and sequencing unordered multimodal procedural instructions,
whether current machine learning models have such essential capability is still
an open question. In this work, we benchmark models' capability of reasoning
over and sequencing unordered multimodal instructions by curating datasets from
popular online instructional manuals and collecting comprehensive human
annotations. We find models not only perform significantly worse than humans
but also seem incapable of efficiently utilizing the multimodal information. To
improve machines' performance on multimodal event sequencing, we propose
sequentiality-aware pretraining techniques that exploit the sequential
alignment properties of both texts and images, resulting in &gt; 5% significant
improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Efficiency Misnomer. (arXiv:2110.12894v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12894">
<div class="article-summary-box-inner">
<span><p>Model efficiency is a critical aspect of developing and deploying machine
learning models. Inference time and latency directly affect the user
experience, and some applications have hard requirements. In addition to
inference costs, model training also have direct financial and environmental
impacts. Although there are numerous well-established metrics (cost indicators)
for measuring model efficiency, researchers and practitioners often assume that
these metrics are correlated with each other and report only few of them. In
this paper, we thoroughly discuss common cost indicators, their advantages and
disadvantages, and how they can contradict each other. We demonstrate how
incomplete reporting of cost indicators can lead to partial conclusions and a
blurred or incomplete picture of the practical considerations of different
models. We further present suggestions to improve reporting of efficiency
metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporally Consistent Online Depth Estimation in Dynamic Scenes. (arXiv:2111.09337v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09337">
<div class="article-summary-box-inner">
<span><p>Temporally consistent depth estimation is crucial for real-time applications.
While stereo depth estimation has received substantial attention, there is
relatively little work focused on maintaining temporal stability. Indeed, based
on our analysis, current techniques still suffer from poor temporal
consistency. Stabilizing depth temporally in dynamic scenes is challenging due
to concurrent object and camera motion. In an online setting, this process is
further aggravated because only past frames are available. We present an
approach to produce temporally consistent depth estimates in dynamic scenes in
an online setting. Our network augments per-frame stereo networks with novel
motion and fusion networks. The motion network accounts for object and camera
motion by predicting a per-pixel SE3 transformation. The fusion network
improves temporal consistency in predictions by aggregating the current and
previous estimates. We conduct extensive experiments across varied datasets. We
demonstrate that our proposed approach outperforms competing methods in terms
of temporal consistency and per-frame accuracy, both quantitatively and
qualitatively. Our code will be available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mesa: A Memory-saving Training Framework for Transformers. (arXiv:2111.11124v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11124">
<div class="article-summary-box-inner">
<span><p>There has been an explosion of interest in designing high-performance
Transformers. While Transformers have delivered significant performance
improvements, training such networks is extremely memory intensive owing to
storing all intermediate activations that are needed for gradient computation
during backpropagation, especially for long sequences. To this end, we present
Mesa, a memory-saving training framework for Transformers. Specifically, Mesa
uses exact activations during forward pass while storing a low-precision
version of activations to reduce memory consumption during training. The
low-precision activations are then dequantized during back-propagation to
compute gradients. Besides, to address the heterogeneous activation
distributions in the multi-head self-attention layers, we propose a head-wise
activation quantization strategy, which quantizes activations based on the
statistics of each head to minimize the approximation error. To further boost
training efficiency, we learn quantization parameters by running estimates.
More importantly, by re-investing the saved memory in employing a larger batch
size or scaling up model size, we may further improve the performance under
constrained computational resources. Extensive experiments on ImageNet,
CIFAR-100 and ADE20K demonstrate that Mesa can achieve flexible memory-savings
(up to 50%) during training while achieving comparable or even better
performance. Code is available at https://github.com/zip-group/Mesa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PointMixer: MLP-Mixer for Point Cloud Understanding. (arXiv:2111.11187v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11187">
<div class="article-summary-box-inner">
<span><p>MLP-Mixer has newly appeared as a new challenger against the realm of CNNs
and transformer. Despite its simplicity compared to transformer, the concept of
channel-mixing MLPs and token-mixing MLPs achieves noticeable performance in
visual recognition tasks. Unlike images, point clouds are inherently sparse,
unordered and irregular, which limits the direct use of MLP-Mixer for point
cloud understanding. In this paper, we propose PointMixer, a universal point
set operator that facilitates information sharing among unstructured 3D points.
By simply replacing token-mixing MLPs with a softmax function, PointMixer can
"mix" features within/between point sets. By doing so, PointMixer can be
broadly used in the network as inter-set mixing, intra-set mixing, and pyramid
mixing. Extensive experiments show the competitive or superior performance of
PointMixer in semantic segmentation, classification, and point reconstruction
against transformer-based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pruning Self-attentions into Convolutional Layers in Single Path. (arXiv:2111.11802v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11802">
<div class="article-summary-box-inner">
<span><p>Vision Transformers (ViTs) have achieved impressive performance over various
computer vision tasks. However, modeling global correlations with multi-head
self-attention (MSA) layers leads to two widely recognized issues: the massive
computational resource consumption and the lack of intrinsic inductive bias for
modeling local visual patterns like convolution. To solve both issues
seamlessly, we devise a simple yet effective method named Single-Path Vision
Transformer pruning (SPViT), to efficiently and automatically compress the
pre-trained ViTs into compact models with proper locality added. Specifically,
we first propose a novel weight-sharing scheme between MSA and convolutional
operations, delivering a single-path space to encode all candidate operations.
In this way, we cast the operation search problem as finding which subset of
parameters to use in each MSA layer, which significantly reduces the
computational cost and optimization difficulty, and the convolution kernels can
be well initialized using pre-trained MSA parameters. Relying on the
single-path space, we further introduce learnable binary gates to encode the
operation choices, which are jointly optimized with network parameters to
automatically determine the configuration of each layer. We conduct extensive
experiments on two representative ViT models showing our method achieves a
favorable accuracy-efficiency trade-off. For example, our SPViT achieves SOTA
pruning performance by trimming 52.6% FLOPs for DeiT-B with only 0.3% top-1
accuracy loss. Code is available at https://github.com/zip-group/SPViT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Source-free unsupervised domain adaptation for cross-modality abdominal multi-organ segmentation. (arXiv:2111.12221v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12221">
<div class="article-summary-box-inner">
<span><p>It is valuable to achieve domain adaptation to transfer the learned knowledge
from the source labeled CT dataset to the target unlabeled MR dataset for
abdominal multi-organ segmentation. Meanwhile, it is highly desirable to avoid
high annotation cost of target dataset and protect privacy of source dataset.
Therefore, we propose an effective source-free unsupervised domain adaptation
method for cross-modality abdominal multi-organ segmentation without accessing
the source dataset. The process of the proposed framework includes two stages.
At the first stage, the feature map statistics-guided model adaptation
combining with entropy minimization is developed to help the top segmentation
network to achieve reliable segmentations on the target images. The
pseudo-labels outputted from the top segmentation network is used to guide the
style compensation network to generate source-like images. The pseudo-labels
outputted from the middle segmentation network is used to supervise the
learning of the desired model (the bottom segmentation network). At the second
stage, the circular learning and the pixel-adaptive mask refinement are used to
further improve the performance of the desired model. With this approach, we
achieve satisfactory performance on the abdominal multi-organ segmentation,
outperforming recent state-of-the-art domain adaptation methods. The proposed
approach can also be easily extended to the situation when there exists target
annotation data. With only one labeled MR volume, the performance is improved
to close to supervised learning. Furthermore, the proposed approach is proved
to be effective in source-free unsupervised domain adaptation in reverse
direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sharpness-aware Quantization for Deep Neural Networks. (arXiv:2111.12273v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12273">
<div class="article-summary-box-inner">
<span><p>Network quantization is an effective compression method to reduce the model
size and computational cost. Despite the high compression ratio, training a
low-precision model is difficult due to the discrete and non-differentiable
nature of quantization, resulting in considerable performance degradation.
Recently, Sharpness-Aware Minimization (SAM) has been proposed to improve the
generalization performance of the models by simultaneously minimizing the loss
value and the loss curvature. However, SAM can not be directly applied to
quantized models due to the discretization process in network quantization. In
this paper, we devise a Sharpness-Aware Quantization (SAQ) method to train
quantized models, leading to better generalization performance. Moreover, since
each layer contributes differently to the loss value and the loss sharpness of
a network, we further devise an effective method that learns a configuration
generator to automatically determine the bitwidth configurations of each layer,
encouraging lower bits for flat regions and vice versa for sharp landscapes,
while simultaneously promoting the flatness of minima to enable more aggressive
quantization. Extensive experiments on CIFAR-100 and ImageNet show the superior
performance of the proposed methods. For example, our quantized ResNet-18 with
53.7x Bit-Operation (BOP) reduction even outperforms the full-precision one by
0.7% in terms of the Top-1 accuracy. Code is available at
https://github.com/zip-group/SAQ.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Equivariant Imaging: a fully unsupervised framework for learning to image from noisy and partial measurements. (arXiv:2111.12855v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12855">
<div class="article-summary-box-inner">
<span><p>Deep networks provide state-of-the-art performance in multiple imaging
inverse problems ranging from medical imaging to computational photography.
However, most existing networks are trained with clean signals which are often
hard or impossible to obtain. Equivariant imaging (EI) is a recent
self-supervised learning framework that exploits the group invariance present
in signal distributions to learn a reconstruction function from partial
measurement data alone. While EI results are impressive, its performance
degrades with increasing noise. In this paper, we propose a Robust Equivariant
Imaging (REI) framework which can learn to image from noisy partial
measurements alone. The proposed method uses Stein's Unbiased Risk Estimator
(SURE) to obtain a fully unsupervised training loss that is robust to noise. We
show that REI leads to considerable performance gains on linear and nonlinear
inverse problems, thereby paving the way for robust unsupervised imaging with
deep networks. Code is available at: https://github.com/edongdongchen/REI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label-Efficient Semantic Segmentation with Diffusion Models. (arXiv:2112.03126v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03126">
<div class="article-summary-box-inner">
<span><p>Denoising diffusion probabilistic models have recently received much research
attention since they outperform alternative approaches, such as GANs, and
currently provide state-of-the-art generative performance. The superior
performance of diffusion models has made them an appealing tool in several
applications, including inpainting, super-resolution, and semantic editing. In
this paper, we demonstrate that diffusion models can also serve as an
instrument for semantic segmentation, especially in the setup when labeled data
is scarce. In particular, for several pretrained diffusion models, we
investigate the intermediate activations from the networks that perform the
Markov step of the reverse diffusion process. We show that these activations
effectively capture the semantic information from an input image and appear to
be excellent pixel-level representations for the segmentation problem. Based on
these observations, we describe a simple segmentation method, which can work
even if only a few training images are provided. Our approach significantly
outperforms the existing alternatives on several datasets for the same amount
of human supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaptPose: Cross-Dataset Adaptation for 3D Human Pose Estimation by Learnable Motion Generation. (arXiv:2112.11593v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11593">
<div class="article-summary-box-inner">
<span><p>This paper addresses the problem of cross-dataset generalization of 3D human
pose estimation models. Testing a pre-trained 3D pose estimator on a new
dataset results in a major performance drop. Previous methods have mainly
addressed this problem by improving the diversity of the training data. We
argue that diversity alone is not sufficient and that the characteristics of
the training data need to be adapted to those of the new dataset such as camera
viewpoint, position, human actions, and body size. To this end, we propose
AdaptPose, an end-to-end framework that generates synthetic 3D human motions
from a source dataset and uses them to fine-tune a 3D pose estimator. AdaptPose
follows an adversarial training scheme. From a source 3D pose the generator
generates a sequence of 3D poses and a camera orientation that is used to
project the generated poses to a novel view. Without any 3D labels or camera
information AdaptPose successfully learns to create synthetic 3D poses from the
target dataset while only being trained on 2D poses. In experiments on the
Human3.6M, MPI-INF-3DHP, 3DPW, and Ski-Pose datasets our method outperforms
previous work in cross-dataset evaluations by 14% and previous semi-supervised
learning methods that use partial 3D annotations by 16%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02639">
<div class="article-summary-box-inner">
<span><p>As humans, we navigate a multimodal world, building a holistic understanding
from all our senses. We introduce MERLOT Reserve, a model that represents
videos jointly over time -- through a new training objective that learns from
audio, subtitles, and video frames. Given a video, we replace snippets of text
and audio with a MASK token; the model learns by choosing the correct
masked-out snippet. Our objective learns faster than alternatives, and performs
well at scale: we pretrain on 20 million YouTube videos.
</p>
<p>Empirical results show that MERLOT Reserve learns strong multimodal
representations. When finetuned, it sets state-of-the-art on Visual Commonsense
Reasoning (VCR), TVQA, and Kinetics-600; outperforming prior work by 5%, 7%,
and 1.5% respectively. Ablations show that these tasks benefit from audio
pretraining -- even VCR, a QA task centered around images (without sound).
Moreover, our objective enables out-of-the-box prediction, revealing strong
multimodal commonsense understanding. In a fully zero-shot setting, our model
obtains competitive results on four video tasks, even outperforming supervised
approaches on the recently proposed Situated Reasoning (STAR) benchmark.
</p>
<p>We analyze why audio enables better vision-language representations,
suggesting significant opportunities for future research. We conclude by
discussing ethical and societal implications of multimodal pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collapse by Conditioning: Training Class-conditional GANs with Limited Data. (arXiv:2201.06578v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.06578">
<div class="article-summary-box-inner">
<span><p>Class-conditioning offers a direct means to control a Generative Adversarial
Network (GAN) based on a discrete input variable. While necessary in many
applications, the additional information provided by the class labels could
even be expected to benefit the training of the GAN itself. On the contrary, we
observe that class-conditioning causes mode collapse in limited data settings,
where unconditional learning leads to satisfactory generative ability.
Motivated by this observation, we propose a training strategy for
class-conditional GANs (cGANs) that effectively prevents the observed
mode-collapse by leveraging unconditional learning. Our training strategy
starts with an unconditional GAN and gradually injects the class conditioning
into the generator and the objective function. The proposed method for training
cGANs with limited data results not only in stable training but also in
generating high-quality images, thanks to the early-stage exploitation of the
shared information across classes. We analyze the observed mode collapse
problem in comprehensive experiments on four datasets. Our approach
demonstrates outstanding results compared with state-of-the-art methods and
established baselines. The code is available at
https://github.com/mshahbazi72/transitional-cGAN
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepMix: Mobility-aware, Lightweight, and Hybrid 3D Object Detection for Headsets. (arXiv:2201.08812v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08812">
<div class="article-summary-box-inner">
<span><p>Mobile headsets should be capable of understanding 3D physical environments
to offer a truly immersive experience for augmented/mixed reality (AR/MR).
However, their small form-factor and limited computation resources make it
extremely challenging to execute in real-time 3D vision algorithms, which are
known to be more compute-intensive than their 2D counterparts. In this paper,
we propose DeepMix, a mobility-aware, lightweight, and hybrid 3D object
detection framework for improving the user experience of AR/MR on mobile
headsets. Motivated by our analysis and evaluation of state-of-the-art 3D
object detection models, DeepMix intelligently combines edge-assisted 2D object
detection and novel, on-device 3D bounding box estimations that leverage depth
data captured by headsets. This leads to low end-to-end latency and
significantly boosts detection accuracy in mobile scenarios. A unique feature
of DeepMix is that it fully exploits the mobility of headsets to fine-tune
detection results and boost detection accuracy. To the best of our knowledge,
DeepMix is the first 3D object detection that achieves 30 FPS (an end-to-end
latency much lower than the 100 ms stringent requirement of interactive AR/MR).
We implement a prototype of DeepMix on Microsoft HoloLens and evaluate its
performance via both extensive controlled experiments and a user study with 30+
participants. DeepMix not only improves detection accuracy by 9.1--37.3% but
also reduces end-to-end latency by 2.68--9.15x, compared to the baseline that
uses existing 3D object detection models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point-NeRF: Point-based Neural Radiance Fields. (arXiv:2201.08845v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08845">
<div class="article-summary-box-inner">
<span><p>Volumetric neural rendering methods like NeRF generate high-quality view
synthesis results but are optimized per-scene leading to prohibitive
reconstruction time. On the other hand, deep multi-view stereo methods can
quickly reconstruct scene geometry via direct network inference. Point-NeRF
combines the advantages of these two approaches by using neural 3D point
clouds, with associated neural features, to model a radiance field. Point-NeRF
can be rendered efficiently by aggregating neural point features near scene
surfaces, in a ray marching-based rendering pipeline. Moreover, Point-NeRF can
be initialized via direct inference of a pre-trained deep network to produce a
neural point cloud; this point cloud can be finetuned to surpass the visual
quality of NeRF with 30X faster training time. Point-NeRF can be combined with
other 3D reconstruction methods and handles the errors and outliers in such
methods via a novel pruning and growing mechanism. The experiments on the DTU,
the NeRF Synthetics , the ScanNet and the Tanks and Temples datasets
demonstrate Point-NeRF can surpass the existing methods and achieve the
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Indicative Image Retrieval: Turning Blackbox Learning into Grey. (arXiv:2201.11898v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11898">
<div class="article-summary-box-inner">
<span><p>Deep learning became the game changer for image retrieval soon after it was
introduced. It promotes the feature extraction (by representation learning) as
the core of image retrieval, with the relevance/matching evaluation being
degenerated into simple similarity metrics. In many applications, we need the
matching evidence to be indicated rather than just have the ranked list (e.g.,
the locations of the target proteins/cells/lesions in medical images). It is
like the matched words need to be highlighted in search engines. However, this
is not easy to implement without explicit relevance/matching modeling. The deep
representation learning models are not feasible because of their blackbox
nature. In this paper, we revisit the importance of relevance/matching modeling
in deep learning era with an indicative retrieval setting. The study shows that
it is possible to skip the representation learning and model the matching
evidence directly. By removing the dependency on the pre-trained models, it has
avoided a lot of related issues (e.g., the domain gap between classification
and retrieval, the detail-diffusion caused by convolution, and so on). More
importantly, the study demonstrates that the matching can be explicitly modeled
and backtracked later for generating the matching evidence indications. It can
improve the explainability of deep inference. Our method obtains a best
performance in literature on both Oxford-5k and Paris-6k, and sets a new record
of 97.77% on Oxford-5k (97.81% on Paris-6k) without extracting any deep
features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auto-Transfer: Learning to Route Transferrable Representations. (arXiv:2202.01011v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01011">
<div class="article-summary-box-inner">
<span><p>Knowledge transfer between heterogeneous source and target networks and tasks
has received a lot of attention in recent times as large amounts of quality
labeled data can be difficult to obtain in many applications. Existing
approaches typically constrain the target deep neural network (DNN) feature
representations to be close to the source DNNs feature representations, which
can be limiting. We, in this paper, propose a novel adversarial multi-armed
bandit approach that automatically learns to route source representations to
appropriate target representations following which they are combined in
meaningful ways to produce accurate target models. We see upwards of 5\%
accuracy improvements compared with the state-of-the-art knowledge transfer
methods on four benchmark (target) image datasets CUB200, Stanford Dogs, MIT67,
and Stanford40 where the source dataset is ImageNet. We qualitatively analyze
the goodness of our transfer scheme by showing individual examples of the
important features focused on by our target network at different layers
compared with the (closest) competitors. We also observe that our improvement
over other methods is higher for smaller target datasets making it an effective
tool for small data applications that may benefit from transfer learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAN-generated Faces Detection: A Survey and New Perspectives (2022). (arXiv:2202.07145v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07145">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GAN) have led to the generation of very
realistic face images, which have been used in fake social media accounts and
other disinformation matters that can generate profound impacts. Therefore, the
corresponding GAN-face detection techniques are under active development that
can examine and expose such fake faces. In this work, we aim to provide a
comprehensive review of recent progress in GAN-face detection. We focus on
methods that can detect face images that are generated or synthesized from GAN
models. We classify the existing detection works into four categories: (1) deep
learning-based, (2) physical-based, (3) physiological-based methods, and (4)
evaluation and comparison against human visual performance. For each category,
we summarize the key ideas and connect them with method implementations. We
also discuss open problems and suggest future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding. (arXiv:2203.00867v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.00867">
<div class="article-summary-box-inner">
<span><p>Image inpainting has made significant advances in recent years. However, it
is still challenging to recover corrupted images with both vivid textures and
reasonable structures. Some specific methods only tackle regular textures while
losing holistic structures due to the limited receptive fields of convolutional
neural networks (CNNs). On the other hand, attention-based models can learn
better long-range dependency for the structure recovery, but they are limited
by the heavy computation for inference with large image sizes. To address these
issues, we propose to leverage an additional structure restorer to facilitate
the image inpainting incrementally. The proposed model restores holistic image
structures with a powerful attention-based transformer model in a fixed
low-resolution sketch space. Such a grayscale space is easy to be upsampled to
larger scales to convey correct structural information. Our structure restorer
can be integrated with other pretrained inpainting models efficiently with the
zero-initialized residual addition. Furthermore, a masking positional encoding
strategy is utilized to improve the performance with large irregular masks.
Extensive experiments on various datasets validate the efficacy of our model
compared with other competitors. Our codes are released in
https://github.com/DQiaole/ZITS_inpainting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Debiased Batch Normalization via Gaussian Process for Generalizable Person Re-Identification. (arXiv:2203.01723v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01723">
<div class="article-summary-box-inner">
<span><p>Generalizable person re-identification aims to learn a model with only
several labeled source domains that can perform well on unseen domains. Without
access to the unseen domain, the feature statistics of the batch normalization
(BN) layer learned from a limited number of source domains is doubtlessly
biased for unseen domain. This would mislead the feature representation
learning for unseen domain and deteriorate the generalizaiton ability of the
model. In this paper, we propose a novel Debiased Batch Normalization via
Gaussian Process approach (GDNorm) for generalizable person re-identification,
which models the feature statistic estimation from BN layers as a dynamically
self-refining Gaussian process to alleviate the bias to unseen domain for
improving the generalization. Specifically, we establish a lightweight model
with multiple set of domain-specific BN layers to capture the discriminability
of individual source domain, and learn the corresponding parameters of the
domain-specific BN layers. These parameters of different source domains are
employed to deduce a Gaussian process. We randomly sample several paths from
this Gaussian process served as the BN estimations of potential new domains
outside of existing source domains, which can further optimize these learned
parameters from source domains, and estimate more accurate Gaussian process by
them in return, tending to real data distribution. Even without a large number
of source domains, GDNorm can still provide debiased BN estimation by using the
mean path of the Gaussian process, while maintaining low computational cost
during testing. Extensive experiments demonstrate that our GDNorm effectively
improves the generalization ability of the model on unseen domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modality-Adaptive Mixup and Invariant Decomposition for RGB-Infrared Person Re-Identification. (arXiv:2203.01735v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01735">
<div class="article-summary-box-inner">
<span><p>RGB-infrared person re-identification is an emerging cross-modality
re-identification task, which is very challenging due to significant modality
discrepancy between RGB and infrared images. In this work, we propose a novel
modality-adaptive mixup and invariant decomposition (MID) approach for
RGB-infrared person re-identification towards learning modality-invariant and
discriminative representations. MID designs a modality-adaptive mixup scheme to
generate suitable mixed modality images between RGB and infrared images for
mitigating the inherent modality discrepancy at the pixel-level. It formulates
modality mixup procedure as Markov decision process, where an actor-critic
agent learns dynamical and local linear interpolation policy between different
regions of cross-modality images under a deep reinforcement learning framework.
Such policy guarantees modality-invariance in a more continuous latent space
and avoids manifold intrusion by the corrupted mixed modality samples.
Moreover, to further counter modality discrepancy and enforce invariant visual
semantics at the feature-level, MID employs modality-adaptive convolution
decomposition to disassemble a regular convolution layer into modality-specific
basis layers and a modality-shared coefficient layer. Extensive experimental
results on two challenging benchmarks demonstrate superior performance of MID
over state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Playable Environments: Video Manipulation in Space and Time. (arXiv:2203.01914v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01914">
<div class="article-summary-box-inner">
<span><p>We present Playable Environments - a new representation for interactive video
generation and manipulation in space and time. With a single image at inference
time, our novel framework allows the user to move objects in 3D while
generating a video by providing a sequence of desired actions. The actions are
learnt in an unsupervised manner. The camera can be controlled to get the
desired viewpoint. Our method builds an environment state for each frame, which
can be manipulated by our proposed action module and decoded back to the image
space with volumetric rendering. To support diverse appearances of objects, we
extend neural radiance fields with style-based modulation. Our method trains on
a collection of various monocular videos requiring only the estimated camera
parameters and 2D object locations. To set a challenging benchmark, we
introduce two large scale video datasets with significant camera movements. As
evidenced by our experiments, playable environments enable several creative
applications not attainable by prior video synthesis works, including playable
3D video generation, stylization and manipulation. Further details, code and
examples are available at
https://willi-menapace.github.io/playable-environments-website
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FS-COCO: Towards Understanding of Freehand Sketches of Common Objects in Context. (arXiv:2203.02113v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.02113">
<div class="article-summary-box-inner">
<span><p>We advance sketch research to scenes with the first dataset of freehand scene
sketches, FS-COCO. With practical applications in mind, we collect sketches
that convey well scene content but can be sketched within a few minutes by a
person with any sketching skills. Our dataset comprises 10,000 freehand scene
vector sketches with per point space-time information by 100 non-expert
individuals, offering both object- and scene-level abstraction. Each sketch is
augmented with its text description. Using our dataset, we study for the first
time the problem of the fine-grained image retrieval from freehand scene
sketches and sketch captions. We draw insights on (i) Scene salience encoded in
sketches with strokes temporal order; (ii) The retrieval performance accuracy
from scene sketches against image captions; (iii) Complementarity of
information in sketches and image captions, as well as the potential benefit of
combining the two modalities. In addition, we propose new solutions enabled by
our dataset (i) We adopt meta-learning to show how the retrieval model can be
fine-tuned to a new user style given just a small set of sketches, (ii) We
extend a popular vector sketch LSTM-based encoder to handle sketches with
larger complexity than was supported by previous work. Namely, we propose a
hierarchical sketch decoder, which we leverage at a sketch-specific "pretext"
task. Our dataset enables for the first time research on freehand scene sketch
understanding and its practical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatio-temporal Gait Feature with Adaptive Distance Alignment. (arXiv:2203.03376v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03376">
<div class="article-summary-box-inner">
<span><p>Gait recognition is an important recognition technology, because it is not
easy to camouflage and does not need cooperation to recognize subjects.
However, there are still serious challenges in gait recognition, that is,
people with similar walking posture are often recognized incorrectly. In this
paper, We try to increase the discrimination of extraced gait features of
different subjects to increase the recognition efficiency of subjects with
similar walking posture. It includes the optimization of network structure and
the refinement of extracted gait features. So our method is proposed, it
consists of Spatio-temporal Feature Extraction (SFE) and Adaptive Distance
Alignment (ADA), which SFE uses Temporal Feature Fusion (TFF) and Fine-grained
Feature Extraction (FFE) to effectively extract the spatio-temporal features
from raw silhouettes, ADA uses a large number of unlabeled gait data in real
life as a benchmark to refine the extracted spatio-temporal features to make
them have low inter-class similarity and high intra-class similarity. Extensive
experiments on mini-OUMVLP and CASIA-B have proved that we have a good result
than some state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Rectangling for Image Stitching: A Learning Baseline. (arXiv:2203.03831v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03831">
<div class="article-summary-box-inner">
<span><p>Stitched images provide a wide field-of-view (FoV) but suffer from unpleasant
irregular boundaries. To deal with this problem, existing image rectangling
methods devote to searching an initial mesh and optimizing a target mesh to
form the mesh deformation in two stages. Then rectangular images can be
generated by warping stitched images. However, these solutions only work for
images with rich linear structures, leading to noticeable distortions for
portraits and landscapes with non-linear objects. In this paper, we address
these issues by proposing the first deep learning solution to image
rectangling. Concretely, we predefine a rigid target mesh and only estimate an
initial mesh to form the mesh deformation, contributing to a compact one-stage
solution. The initial mesh is predicted using a fully convolutional network
with a residual progressive regression strategy. To obtain results with high
content fidelity, a comprehensive objective function is proposed to
simultaneously encourage the boundary rectangular, mesh shape-preserving, and
content perceptually natural. Besides, we build the first image stitching
rectangling dataset with a large diversity in irregular boundaries and scenes.
Experiments demonstrate our superiority over traditional methods both
quantitatively and qualitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-DIAE: Degradation Invariant Autoencoders for Text Recognition and Document Enhancement. (arXiv:2203.04814v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.04814">
<div class="article-summary-box-inner">
<span><p>In this work, we propose Text-Degradation Invariant Auto Encoder (Text-DIAE)
aimed to solve two tasks, text recognition (handwritten or scene-text) and
document image enhancement. We define three pretext tasks as learning
objectives to be optimized during pre-training without the usage of labelled
data. Each of the pre-text objectives is specifically tailored for the final
downstream tasks. We conduct several ablation experiments that show the
importance of each degradation for a specific domain. Exhaustive
experimentation shows that our method does not have limitations of previous
state-of-the-art based on contrastive losses while at the same time requiring
essentially fewer data samples to converge. Finally, we demonstrate that our
method surpasses the state-of-the-art significantly in existing supervised and
self-supervised settings in handwritten and scene text recognition and document
image enhancement. Our code and trained models will be made publicly available
at~\url{ <a href="http://Upon_Acceptance">this http URL</a>}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning. (arXiv:2203.06359v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.06359">
<div class="article-summary-box-inner">
<span><p>Non-exemplar class-incremental learning is to recognize both the old and new
classes when old class samples cannot be saved. It is a challenging task since
representation optimization and feature retention can only be achieved under
supervision from new classes. To address this problem, we propose a novel
self-sustaining representation expansion scheme. Our scheme consists of a
structure reorganization strategy that fuses main-branch expansion and
side-branch updating to maintain the old features, and a main-branch
distillation scheme to transfer the invariant knowledge. Furthermore, a
prototype selection mechanism is proposed to enhance the discrimination between
the old and new classes by selectively incorporating new samples into the
distillation process. Extensive experiments on three benchmarks demonstrate
significant incremental performance, outperforming the state-of-the-art methods
by a margin of 3%, 3% and 6%, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Privacy-friendly Synthetic Data for the Development of Face Morphing Attack Detectors. (arXiv:2203.06691v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.06691">
<div class="article-summary-box-inner">
<span><p>The main question this work aims at answering is: can morphing attack
detection (MAD) solutions be successfully developed based on synthetic data?.
Towards that, this work introduces the first synthetic-based MAD development
dataset, namely the Synthetic Morphing Attack Detection Development dataset
(SMDD). This dataset is utilized successfully to train three MAD backbones
where it proved to lead to high MAD performance, even on completely unknown
attack types. Additionally, an essential aspect of this work is the detailed
legal analyses of the challenges of using and sharing real biometric data,
rendering our proposed SMDD dataset extremely essential. The SMDD dataset,
consisting of 30,000 attack and 50,000 bona fide samples, is made publicly
available for research purposes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Two-Block RNN-based Trajectory Prediction from Incomplete Trajectory. (arXiv:2203.07098v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07098">
<div class="article-summary-box-inner">
<span><p>Trajectory prediction has gained great attention and significant progress has
been made in recent years. However, most works rely on a key assumption that
each video is successfully preprocessed by detection and tracking algorithms
and the complete observed trajectory is always available. However, in complex
real-world environments, we often encounter miss-detection of target agents
(e.g., pedestrian, vehicles) caused by the bad image conditions, such as the
occlusion by other agents. In this paper, we address the problem of trajectory
prediction from incomplete observed trajectory due to miss-detection, where the
observed trajectory includes several missing data points. We introduce a
two-block RNN model that approximates the inference steps of the Bayesian
filtering framework and seeks the optimal estimation of the hidden state when
miss-detection occurs. The model uses two RNNs depending on the detection
result. One RNN approximates the inference step of the Bayesian filter with the
new measurement when the detection succeeds, while the other does the
approximation when the detection fails. Our experiments show that the proposed
model improves the prediction accuracy compared to the three baseline
imputation methods on publicly available datasets: ETH and UCY ($9\%$ and $7\%$
improvement on the ADE and FDE metrics). We also show that our proposed method
can achieve better prediction compared to the baselines when there is no
miss-detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rich CNN-Transformer Feature Aggregation Networks for Super-Resolution. (arXiv:2203.07682v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07682">
<div class="article-summary-box-inner">
<span><p>Recent vision transformers along with self-attention have achieved promising
results on various computer vision tasks. In particular, a pure
transformer-based image restoration architecture surpasses the existing
CNN-based methods using multi-task pre-training with a large number of
trainable parameters. In this paper, we introduce an effective hybrid
architecture for super-resolution (SR) tasks, which leverages local features
from CNNs and long-range dependencies captured by transformers to further
improve the SR results. Specifically, our architecture comprises of transformer
and convolution branches, and we substantially elevate the performance by
mutually fusing two branches to complement each representation. Furthermore, we
propose a cross-scale token attention module, which allows the transformer to
efficiently exploit the informative relationships among tokens across different
scales. Our proposed method achieves state-of-the-art SR results on numerous
benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Implicit field supervision for robust non-rigid shape matching. (arXiv:2203.07694v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07694">
<div class="article-summary-box-inner">
<span><p>Establishing a correspondence between two non-rigidly deforming shapes is one
of the most fundamental problems in visual computing. Existing methods often
show weak resilience when presented with challenges innate to real-world data
such as noise, outliers, self-occlusion etc. On the other hand, auto-decoders
have demonstrated strong expressive power in learning geometrically meaningful
latent embeddings. However, their use in shape analysis and especially in
non-rigid shape correspondence has been limited. In this paper, we introduce an
approach based on auto-decoder framework, that learns a continuous shape-wise
deformation field over a fixed template. By supervising the deformation field
for points on-surface and regularising for points off-surface through a novel
Signed Distance Regularisation (SDR), we learn an alignment between the
template and shape volumes. Unlike classical correspondence techniques, our
method is remarkably robust in the presence of strong artefacts and can be
generalised to arbitrary shape categories. Trained on clean water-tight meshes,
without any data-augmentation, we demonstrate compelling performance on
compromised data and real-world scans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distribution-Aware Single-Stage Models for Multi-Person 3D Pose Estimation. (arXiv:2203.07697v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07697">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a novel Distribution-Aware Single-stage (DAS) model
for tackling the challenging multi-person 3D pose estimation problem. Different
from existing top-down and bottom-up methods, the proposed DAS model
simultaneously localizes person positions and their corresponding body joints
in the 3D camera space in a one-pass manner. This leads to a simplified
pipeline with enhanced efficiency. In addition, DAS learns the true
distribution of body joints for the regression of their positions, rather than
making a simple Laplacian or Gaussian assumption as previous works. This
provides valuable priors for model prediction and thus boosts the
regression-based scheme to achieve competitive performance with volumetric-base
ones. Moreover, DAS exploits a recursive update strategy for progressively
approaching to regression target, alleviating the optimization difficulty and
further lifting the regression performance. DAS is implemented with a fully
Convolutional Neural Network and end-to-end learnable. Comprehensive
experiments on benchmarks CMU Panoptic and MuPoTS-3D demonstrate the superior
efficiency of the proposed DAS model, specifically 1.5x speedup over previous
best model, and its stat-of-the-art accuracy for multi-person 3D pose
estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object Detection as Probabilistic Set Prediction. (arXiv:2203.07980v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07980">
<div class="article-summary-box-inner">
<span><p>Accurate uncertainty estimates are essential for deploying deep object
detectors in safety-critical systems. The development and evaluation of
probabilistic object detectors have been hindered by shortcomings in existing
performance measures, which tend to involve arbitrary thresholds or limit the
detector's choice of distributions. In this work, we propose to view object
detection as a set prediction task where detectors predict the distribution
over the set of objects. Using the negative log-likelihood for random finite
sets, we present a proper scoring rule for evaluating and training
probabilistic object detectors. The proposed method can be applied to existing
probabilistic detectors, is free from thresholds, and enables fair comparison
between architectures. Three different types of detectors are evaluated on the
COCO dataset. Our results indicate that the training of existing detectors is
optimized toward non-probabilistic metrics. We hope to encourage the
development of new object detectors that can accurately estimate their own
uncertainty. Code will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Hyperbolic Embeddings in 2D Object Detection. (arXiv:2203.08049v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08049">
<div class="article-summary-box-inner">
<span><p>Object detection, for the most part, has been formulated in the euclidean
space, where euclidean or spherical geodesic distances measure the similarity
of an image region to an object class prototype. In this work, we study whether
a hyperbolic geometry better matches the underlying structure of the object
classification space. We incorporate a hyperbolic classifier in two-stage,
keypoint-based, and transformer-based object detection architectures and
evaluate them on large-scale, long-tailed, and zero-shot object detection
benchmarks. In our extensive experimental evaluations, we observe categorical
class hierarchies emerging in the structure of the classification space,
resulting in lower classification errors and boosting the overall object
detection performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D Molecular Volumes from Real Cryo-EM Images. (arXiv:2203.08138v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08138">
<div class="article-summary-box-inner">
<span><p>Cryo-electron microscopy (cryo-EM) has become a tool of fundamental
importance in structural biology, helping us understand the basic building
blocks of life. The algorithmic challenge of cryo-EM is to jointly estimate the
unknown 3D poses and the 3D electron scattering potential of a biomolecule from
millions of extremely noisy 2D images. Existing reconstruction algorithms,
however, cannot easily keep pace with the rapidly growing size of cryo-EM
datasets due to their high computational and memory cost. We introduce cryoAI,
an ab initio reconstruction algorithm for homogeneous conformations that uses
direct gradient-based optimization of particle poses and the electron
scattering potential from single-particle cryo-EM data. CryoAI combines a
learned encoder that predicts the poses of each particle image with a
physics-based decoder to aggregate each particle image into an implicit
representation of the scattering potential volume. This volume is stored in the
Fourier domain for computational efficiency and leverages a modern coordinate
network architecture for memory efficiency. Combined with a symmetrized loss
function, this framework achieves results of a quality on par with
state-of-the-art cryo-EM solvers for both simulated and experimental data, one
order of magnitude faster for large datasets and with significantly lower
memory requirements than existing methods.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-03-17 23:07:45.914096421 UTC">2022-03-17 23:07:45 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>