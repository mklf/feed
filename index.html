<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-02-23T01:30:00Z">02-23</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">CaMEL: Mean Teacher Learning for Image Captioning. (arXiv:2202.10492v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10492">
<div class="article-summary-box-inner">
<span><p>Describing images in natural language is a fundamental step towards the
automatic modeling of connections between the visual and textual modalities. In
this paper we present CaMEL, a novel Transformer-based architecture for image
captioning. Our proposed approach leverages the interaction of two
interconnected language models that learn from each other during the training
phase. The interplay between the two language models follows a mean teacher
learning paradigm with knowledge distillation. Experimentally, we assess the
effectiveness of the proposed solution on the COCO dataset and in conjunction
with different visual feature extractors. When comparing with existing
proposals, we demonstrate that our model provides state-of-the-art caption
quality with a significantly reduced number of parameters. According to the
CIDEr metric, we obtain a new state of the art on COCO when training without
using external data. The source code and trained models are publicly available
at: https://github.com/aimagelab/camel.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Base Question Answering by Case-based Reasoning over Subgraphs. (arXiv:2202.10610v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10610">
<div class="article-summary-box-inner">
<span><p>Question answering (QA) over real-world knowledge bases (KBs) is challenging
because of the diverse (essentially unbounded) types of reasoning patterns
needed. However, we hypothesize in a large KB, reasoning patterns required to
answer a query type reoccur for various entities in their respective subgraph
neighborhoods. Leveraging this structural similarity between local
neighborhoods of different subgraphs, we introduce a semiparametric model with
(i) a nonparametric component that for each query, dynamically retrieves other
similar $k$-nearest neighbor (KNN) training queries along with query-specific
subgraphs and (ii) a parametric component that is trained to identify the
(latent) reasoning patterns from the subgraphs of KNN queries and then apply it
to the subgraph of the target query. We also propose a novel algorithm to
select a query-specific compact subgraph from within the massive knowledge
graph (KG), allowing us to scale to full Freebase KG containing billions of
edges. We show that our model answers queries requiring complex reasoning
patterns more effectively than existing KG completion algorithms. The proposed
model outperforms or performs competitively with state-of-the-art models on
several KBQA benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatically Generating Counterfactuals for Relation Exaction. (arXiv:2202.10668v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10668">
<div class="article-summary-box-inner">
<span><p>The goal of relation extraction (RE) is to extract the semantic relations
between/among entities in the text. As a fundamental task in natural language
processing, it is crucial to ensure the robustness of RE models. Despite the
high accuracy current deep neural models have achieved in RE tasks, they are
easily affected by spurious correlations. One solution to this problem is to
train the model with counterfactually augmented data (CAD) such that it can
learn the causation rather than the confounding. However, no attempt has been
made on generating counterfactuals for RE tasks. In this paper, we formulate
the problem of automatically generating CAD for RE tasks from an entity-centric
viewpoint, and develop a novel approach to derive contextual counterfactuals
for entities. Specifically, we exploit two elementary topological properties,
i.e., the centrality and the shortest path, in syntactic and semantic
dependency graphs, to first identify and then intervene on the contextual
causal features for entities. We conduct a comprehensive evaluation on four RE
datasets by combining our proposed approach with a variety of backbone RE
models. The results demonstrate that our approach not only improves the
performance of the backbones, but also makes them more robust in the
out-of-domain test.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incorporating Constituent Syntax for Coreference Resolution. (arXiv:2202.10710v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10710">
<div class="article-summary-box-inner">
<span><p>Syntax has been shown to benefit Coreference Resolution from incorporating
long-range dependencies and structured information captured by syntax trees,
either in traditional statistical machine learning based systems or recently
proposed neural models. However, most leading systems use only dependency
trees. We argue that constituent trees also encode important information, such
as explicit span-boundary signals captured by nested multi-word phrases, extra
linguistic labels and hierarchical structures useful for detecting anaphora. In
this work, we propose a simple yet effective graph-based method to incorporate
constituent syntactic structures. Moreover, we also explore to utilise
higher-order neighbourhood information to encode rich structures in constituent
trees. A novel message propagation mechanism is therefore proposed to enable
information flow among elements in syntax trees. Experiments on the English and
Chinese portions of OntoNotes 5.0 benchmark show that our proposed model either
beats a strong baseline or achieves new state-of-the-art performance. (Code is
available at https://github.com/Fantabulous-J/Coref-Constituent-Graph)
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Cross-lingual Speech Synthesis with Triplet Training Scheme. (arXiv:2202.10729v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10729">
<div class="article-summary-box-inner">
<span><p>Recent advances in cross-lingual text-to-speech (TTS) made it possible to
synthesize speech in a language foreign to a monolingual speaker. However,
there is still a large gap between the pronunciation of generated cross-lingual
speech and that of native speakers in terms of naturalness and intelligibility.
In this paper, a triplet training scheme is proposed to enhance the
cross-lingual pronunciation by allowing previously unseen content and speaker
combinations to be seen during training. Proposed method introduces an extra
fine-tune stage with triplet loss during training, which efficiently draws the
pronunciation of the synthesized foreign speech closer to those from the native
anchor speaker, while preserving the non-native speaker's timbre. Experiments
are conducted based on a state-of-the-art baseline cross-lingual TTS system and
its enhanced variants. All the objective and subjective evaluations show the
proposed method brings significant improvement in both intelligibility and
naturalness of the synthesized cross-lingual speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JAMES: Job Title Mapping with Multi-Aspect Embeddings and Reasoning. (arXiv:2202.10739v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10739">
<div class="article-summary-box-inner">
<span><p>One of the most essential tasks needed for various downstream tasks in career
analytics (e.g., career trajectory analysis, job mobility prediction, and job
recommendation) is Job Title Mapping (JTM), where the goal is to map
user-created (noisy and non-standard) job titles to predefined and standard job
titles. However, solving JTM is domain-specific and non-trivial due to its
inherent challenges: (1) user-created job titles are messy, (2) different job
titles often overlap their job requirements, (3) job transition trajectories
are inconsistent, and (4) the number of job titles in real world applications
is large-scale. Toward this JTM problem, in this work, we propose a novel
solution, named as JAMES, that constructs three unique embeddings of a target
job title: topological, semantic, and syntactic embeddings, together with
multi-aspect co-attention. In addition, we employ logical reasoning
representations to collaboratively estimate similarities between messy job
titles and standard job titles in the reasoning space. We conduct comprehensive
experiments against ten competing models on the large-scale real-world dataset
with more than 350,000 job titles. Our results show that JAMES significantly
outperforms the best baseline by 10.06% in Precision@10 and by 17.52% in
NDCG@10, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CorefDRE: Document-level Relation Extraction with coreference resolution. (arXiv:2202.10744v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10744">
<div class="article-summary-box-inner">
<span><p>Document-level relation extraction is to extract relation facts from a
document consisting of multiple sentences, in which pronoun crossed sentences
are a ubiquitous phenomenon against a single sentence. However, most of the
previous works focus more on mentions coreference resolution except for
pronouns, and rarely pay attention to mention-pronoun coreference and capturing
the relations. To represent multi-sentence features by pronouns, we imitate the
reading process of humans by leveraging coreference information when
dynamically constructing a heterogeneous graph to enhance semantic information.
Since the pronoun is notoriously ambiguous in the graph, a mention-pronoun
coreference resolution is introduced to calculate the affinity between pronouns
and corresponding mentions, and the noise suppression mechanism is proposed to
reduce the noise caused by pronouns. Experiments on the public dataset, DocRED,
DialogRE and MPDD, show that Coref-aware Doc-level Relation Extraction based on
Graph Inference Network outperforms the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Systematic Generalization Through Modularity and Augmentation. (arXiv:2202.10745v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10745">
<div class="article-summary-box-inner">
<span><p>Systematic generalization is the ability to combine known parts into novel
meaning; an important aspect of efficient human learning, but a weakness of
neural network learning. In this work, we investigate how two well-known
modeling principles -- modularity and data augmentation -- affect systematic
generalization of neural networks in grounded language learning. We analyze how
large the vocabulary needs to be to achieve systematic generalization and how
similar the augmented data needs to be to the problem at hand. Our findings
show that even in the controlled setting of a synthetic benchmark, achieving
systematic generalization remains very difficult. After training on an
augmented dataset with almost forty times more adverbs than the original
problem, a non-modular baseline is not able to systematically generalize to a
novel combination of a known verb and adverb. When separating the task into
cognitive processes like perception and navigation, a modular neural network is
able to utilize the augmented data and generalize more systematically,
achieving 70% and 40% exact match increase over state-of-the-art on two gSCAN
tests that have not previously been improved. We hope that this work gives
insight into the drivers of systematic generalization, and what we still need
to improve for neural networks to learn more like humans do.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VU-BERT: A Unified framework for Visual Dialog. (arXiv:2202.10787v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10787">
<div class="article-summary-box-inner">
<span><p>The visual dialog task attempts to train an agent to answer multi-turn
questions given an image, which requires the deep understanding of interactions
between the image and dialog history. Existing researches tend to employ the
modality-specific modules to model the interactions, which might be troublesome
to use. To fill in this gap, we propose a unified framework for image-text
joint embedding, named VU-BERT, and apply patch projection to obtain vision
embedding firstly in visual dialog tasks to simplify the model. The model is
trained over two tasks: masked language modeling and next utterance retrieval.
These tasks help in learning visual concepts, utterances dependence, and the
relationships between these two modalities. Finally, our VU-BERT achieves
competitive performance (0.7287 NDCG scores) on VisDial v1.0 Datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NU HLT at CMCL 2022 Shared Task: Multilingual and Crosslingual Prediction of Human Reading Behavior in Universal Language Space. (arXiv:2202.10855v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10855">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a unified model that works for both multilingual
and crosslingual prediction of reading times of words in various languages. The
secret behind the success of this model is in the preprocessing step where all
words are transformed to their universal language representation via the
International Phonetic Alphabet (IPA). To the best of our knowledge, this is
the first study to favorable exploit this phonological property of language for
the two tasks. Various feature types were extracted covering basic frequencies,
n-grams, information theoretic, and psycholinguistically-motivated predictors
for model training. A finetuned Random Forest model obtained best performance
for both tasks with 3.8031 and 3.9065 MAE scores for mean first fixation
duration (FFDAve) and mean total reading time (TRTAve) respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Persian Tokenizers. (arXiv:2202.10879v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10879">
<div class="article-summary-box-inner">
<span><p>Tokenization plays a significant role in the process of lexical analysis.
Tokens become the input for other natural language processing tasks, like
semantic parsing and language modeling. Natural Language Processing in Persian
is challenging due to Persian's exceptional cases, such as half-spaces. Thus,
it is crucial to have a precise tokenizer for Persian. This article provides a
novel work by introducing the most widely used tokenizers for Persian and
comparing and evaluating their performance on Persian texts using a simple
algorithm with a pre-tagged Persian dependency dataset. After evaluating
tokenizers with the F1-Score, the hybrid version of the Farsi Verb and Hazm
with bounded morphemes fixing showed the best performance with an F1 score of
98.97%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Vision-Language Pre-Trained Models. (arXiv:2202.10936v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10936">
<div class="article-summary-box-inner">
<span><p>As Transformer evolved, pre-trained models have advanced at a breakneck pace
in recent years. They have dominated the mainstream techniques in natural
language processing (NLP) and computer vision (CV). How to adapt pre-training
to the field of Vision-and-Language (V-L) learning and improve the performance
on downstream tasks becomes a focus of multimodal learning. In this paper, we
review the recent progress in Vision-Language Pre-Trained Models (VL-PTMs). As
the core content, we first briefly introduce several ways to encode raw images
and texts to single-modal embeddings before pre-training. Then, we dive into
the mainstream architectures of VL-PTMs in modeling the interaction between
text and image representations. We further present widely-used pre-training
tasks, after which we introduce some common downstream tasks. We finally
conclude this paper and present some promising research directions. Our survey
aims to provide multimodal researchers a synthesis and pointer to related
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Semi-Supervised Learning Approach with Two Teachers to Improve Breakdown Identification in Dialogues. (arXiv:2202.10948v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10948">
<div class="article-summary-box-inner">
<span><p>Identifying breakdowns in ongoing dialogues helps to improve communication
effectiveness. Most prior work on this topic relies on human annotated data and
data augmentation to learn a classification model. While quality labeled
dialogue data requires human annotation and is usually expensive to obtain,
unlabeled data is easier to collect from various sources. In this paper, we
propose a novel semi-supervised teacher-student learning framework to tackle
this task. We introduce two teachers which are trained on labeled data and
perturbed labeled data respectively. We leverage unlabeled data to improve
classification in student training where we employ two teachers to refine the
labeling of unlabeled data through teacher-student learning in a bootstrapping
manner. Through our proposed training approach, the student can achieve
improvements over single-teacher performance. Experimental results on the
Dialogue Breakdown Detection Challenge dataset DBDC5 and Learning to Identify
Follow-Up Questions dataset LIF show that our approach outperforms all previous
published approaches as well as other supervised and semi-supervised baseline
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Cluster Patterns for Abstractive Summarization. (arXiv:2202.10967v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10967">
<div class="article-summary-box-inner">
<span><p>Nowadays, pre-trained sequence-to-sequence models such as BERTSUM and BART
have shown state-of-the-art results in abstractive summarization. In these
models, during fine-tuning, the encoder transforms sentences to context vectors
in the latent space and the decoder learns the summary generation task based on
the context vectors. In our approach, we consider two clusters of salient and
non-salient context vectors, using which the decoder can attend more to salient
context vectors for summary generation. For this, we propose a novel clustering
transformer layer between the encoder and the decoder, which first generates
two clusters of salient and non-salient vectors, and then normalizes and
shirinks the clusters to make them apart in the latent space. Our experimental
result shows that the proposed model outperforms the existing BART model by
learning these distinct cluster patterns, improving up to 4% in ROUGE and 0.3%
in BERTScore on average in CNN/DailyMail and XSUM data sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Statistical and Spatio-temporal Hand Gesture Features for Sign Language Recognition using the Leap Motion Sensor. (arXiv:2202.11005v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11005">
<div class="article-summary-box-inner">
<span><p>In modern society, people should not be identified based on their disability,
rather, it is environments that can disable people with impairments.
Improvements to automatic Sign Language Recognition (SLR) will lead to more
enabling environments via digital technology. Many state-of-the-art approaches
to SLR focus on the classification of static hand gestures, but communication
is a temporal activity, which is reflected by many of the dynamic gestures
present. Given this, temporal information during the delivery of a gesture is
not often considered within SLR. The experiments in this work consider the
problem of SL gesture recognition regarding how dynamic gestures change during
their delivery, and this study aims to explore how single types of features as
well as mixed features affect the classification ability of a machine learning
model. 18 common gestures recorded via a Leap Motion Controller sensor provide
a complex classification problem. Two sets of features are extracted from a 0.6
second time window, statistical descriptors and spatio-temporal attributes.
Features from each set are compared by their ANOVA F-Scores and p-values,
arranged into bins grown by 10 features per step to a limit of the 250
highest-ranked features. Results show that the best statistical model selected
240 features and scored 85.96% accuracy, the best spatio-temporal model
selected 230 features and scored 80.98%, and the best mixed-feature model
selected 240 features from each set leading to a classification accuracy of
86.75%. When all three sets of results are compared (146 individual machine
learning models), the overall distribution shows that the minimum results are
increased when inputs are any number of mixed features compared to any number
of either of the two single sets of features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Overview on Machine Translation Evaluation. (arXiv:2202.11027v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11027">
<div class="article-summary-box-inner">
<span><p>Since the 1950s, machine translation (MT) has become one of the important
tasks of AI and development, and has experienced several different periods and
stages of development, including rule-based methods, statistical methods, and
recently proposed neural network-based learning methods. Accompanying these
staged leaps is the evaluation research and development of MT, especially the
important role of evaluation methods in statistical translation and neural
translation research. The evaluation task of MT is not only to evaluate the
quality of machine translation, but also to give timely feedback to machine
translation researchers on the problems existing in machine translation itself,
how to improve and how to optimise. In some practical application fields, such
as in the absence of reference translations, the quality estimation of machine
translation plays an important role as an indicator to reveal the credibility
of automatically translated target languages. This report mainly includes the
following contents: a brief history of machine translation evaluation (MTE),
the classification of research methods on MTE, and the the cutting-edge
progress, including human evaluation, automatic evaluation, and evaluation of
evaluation methods (meta-evaluation). Manual evaluation and automatic
evaluation include reference-translation based and reference-translation
independent participation; automatic evaluation methods include traditional
n-gram string matching, models applying syntax and semantics, and deep learning
models; evaluation of evaluation methods includes estimating the credibility of
human evaluations, the reliability of the automatic evaluation, the reliability
of the test set, etc. Advances in cutting-edge evaluation methods include
task-based evaluation, using pre-trained language models based on big data, and
lightweight optimisation models using distillation techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArchivalQA: A Large-scale Benchmark Dataset for Open Domain Question Answering over Historical News Collections. (arXiv:2109.03438v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03438">
<div class="article-summary-box-inner">
<span><p>In the last few years, open-domain question answering (ODQA) has advanced
rapidly due to the development of deep learning techniques and the availability
of large-scale QA datasets. However, the current datasets are essentially
designed for synchronic document collections (e.g., Wikipedia). Temporal news
collections such as long-term news archives spanning several decades, are
rarely used in training the models despite they are quite valuable for our
society. To foster the research in the field of ODQA on such historical
collections, we present ArchivalQA, a large question answering dataset
consisting of 532,444 question-answer pairs which is designed for temporal news
QA. We divide our dataset into four subparts based on the question difficulty
levels and the containment of temporal expressions, which we believe are useful
for training and testing ODQA systems characterized by different strengths and
abilities. The novel QA dataset-constructing framework that we introduce can be
also applied to generate non-ambiguous questions of good quality over other
types of temporal document collections.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eliciting Knowledge from Language Models for Event Extraction. (arXiv:2109.05190v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05190">
<div class="article-summary-box-inner">
<span><p>Eliciting knowledge contained in language models via prompt-based learning
has shown great potential in many natural language processing tasks, such as
text classification and generation. Whereas, the applications for more complex
tasks such as event extraction are less studied, since the design of prompt is
not straightforward due to the complicated types and arguments. In this paper,
we explore to elicit the knowledge from pre-trained language models for event
trigger detection and argument extraction. Specifically, we present various
joint trigger/argument prompt methods, which can elicit more complementary
knowledge by modeling the interactions between different triggers or arguments.
The experimental results on the benchmark dataset, namely ACE2005, show the
great advantages of our proposed approach. In particular, our approach is
superior to the recent advanced methods in the few-shot scenario where only a
few samples are used for training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple Entity-Centric Questions Challenge Dense Retrievers. (arXiv:2109.08535v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08535">
<div class="article-summary-box-inner">
<span><p>Open-domain question answering has exploded in popularity recently due to the
success of dense retrieval models, which have surpassed sparse models using
only a few supervised training examples. However, in this paper, we demonstrate
current dense models are not yet the holy grail of retrieval. We first
construct EntityQuestions, a set of simple, entity-rich questions based on
facts from Wikidata (e.g., "Where was Arve Furset born?"), and observe that
dense retrievers drastically underperform sparse methods. We investigate this
issue and uncover that dense retrievers can only generalize to common entities
unless the question pattern is explicitly observed during training. We discuss
two simple solutions towards addressing this critical problem. First, we
demonstrate that data augmentation is unable to fix the generalization problem.
Second, we argue a more robust passage encoder helps facilitate better question
adaptation using specialized question encoders. We hope our work can shed light
on the challenges in creating a robust, universal dense retriever that works
well across different input distributions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dependency Structure for News Document Summarization. (arXiv:2109.11199v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11199">
<div class="article-summary-box-inner">
<span><p>In this work, we develop a neural network based model which leverages
dependency parsing to capture cross-positional dependencies and grammatical
structures. With the help of linguistic signals, sentence-level relations can
be correctly captured, thus improving news documents summarization performance.
Empirical studies demonstrate that this simple but effective method outperforms
existing works on the benchmark dataset. Extensive analyses examine different
settings and configurations of the proposed model which provide a good
reference to the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Have best of both worlds: two-pass hybrid and E2E cascading framework for speech recognition. (arXiv:2110.04891v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04891">
<div class="article-summary-box-inner">
<span><p>Hybrid and end-to-end (E2E) systems have their individual advantages, with
different error patterns in the speech recognition results. By jointly modeling
audio and text, the E2E model performs better in matched scenarios and scales
well with a large amount of paired audio-text training data. The modularized
hybrid model is easier for customization, and better to make use of a massive
amount of unpaired text data. This paper proposes a two-pass hybrid and E2E
cascading (HEC) framework to combine the hybrid and E2E model in order to take
advantage of both sides, with hybrid in the first pass and E2E in the second
pass. We show that the proposed system achieves 8-10% relative word error rate
reduction with respect to each individual system. More importantly, compared
with the pure E2E system, we show the proposed system has the potential to keep
the advantages of hybrid system, e.g., customization and segmentation
capabilities. We also show the second pass E2E model in HEC is robust with
respect to the change in the first pass hybrid model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Non-Autoregressive End-To-End Neural Modeling For English Mispronunciation Detection And Diagnosis. (arXiv:2111.00844v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00844">
<div class="article-summary-box-inner">
<span><p>End-to-end (E2E) neural modeling has emerged as one predominant school of
thought to develop computer-assisted language training (CAPT) systems, showing
competitive performance to conventional pronunciation-scoring based methods.
However, current E2E neural methods for CAPT are faced with at least two
pivotal challenges. On one hand, most of the E2E methods operate in an
autoregressive manner with left-to-right beam search to dictate the
pronunciations of an L2 learners. This however leads to very slow inference
speed, which inevitably hinders their practical use. On the other hand, E2E
neural methods are normally data greedy and meanwhile an insufficient amount of
nonnative training data would often reduce their efficacy on mispronunciation
detection and diagnosis (MD&amp;D). In response, we put forward a novel MD&amp;D method
that leverages non-autoregressive (NAR) E2E neural modeling to dramatically
speed up the inference time while maintaining performance in line with the
conventional E2E neural methods. In addition, we design and develop a
pronunciation modeling network stacked on top of the NAR E2E models of our
method to further boost the effectiveness of MD&amp;D. Empirical experiments
conducted on the L2-ARCTIC English dataset seems to validate the feasibility of
our method, in comparison to some top-of-the-line E2E models and an iconic
pronunciation-scoring based method built on a DNN-HMM acoustic model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey of Hallucination in Natural Language Generation. (arXiv:2202.03629v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.03629">
<div class="article-summary-box-inner">
<span><p>Natural Language Generation (NLG) has improved exponentially in recent years
thanks to the development of deep learning technologies such as
Transformer-based language models. This advancement has led to more fluent and
coherent natural language generation, naturally leading to development in
downstream tasks such as abstractive summarization, dialogue generation and
data-to-text generation. However, it is also investigated that such generation
includes hallucinated texts, which makes the performances of text generation
fail to meet users' expectations in many real-world scenarios. In order to
address this issue, studies in evaluation and mitigation methods of
hallucinations have been presented in various tasks, but have not been reviewed
in a combined manner. In this survey, we provide a broad overview of the
research progress and challenges in the hallucination problem of NLG. The
survey is organized into two big divisions: (i) a general overview of metrics,
mitigation methods, and future directions; (ii) task-specific research progress
for hallucinations in a large set of downstream tasks: abstractive
summarization, dialogue generation, generative question answering, data-to-text
generation, and machine translation. This survey could facilitate collaborative
efforts among researchers in these tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geodesic Quantum Walks. (arXiv:2202.10235v2 [quant-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10235">
<div class="article-summary-box-inner">
<span><p>We propose a new family of discrete-spacetime quantum walks capable to
propagate on any arbitrary triangulations. Moreover we also extend and
generalize the duality principle introduced by one of the authors, linking
continuous local deformations of a given triangulation and the inhomogeneity of
the local unitaries that guide the quantum walker. We proved that in the formal
continuous limit, in both space and time, this new family of quantum walks
converges to the (1+2)D massless Dirac equation on curved manifolds. We believe
that this result has relevance in both modelling/simulating quantum transport
on discrete curved structures, such as fullerene molecules or dynamical causal
triangulation, and in addressing fast and efficient optimization problems in
the context of the curved space optimization methods.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">A Classical-Quantum Convolutional Neural Network for Detecting Pneumonia from Chest Radiographs. (arXiv:2202.10452v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10452">
<div class="article-summary-box-inner">
<span><p>While many quantum computing techniques for machine learning have been
proposed, their performance on real-world datasets remains to be studied. In
this paper, we explore how a variational quantum circuit could be integrated
into a classical neural network for the problem of detecting pneumonia from
chest radiographs. We substitute one layer of a classical convolutional neural
network with a variational quantum circuit to create a hybrid neural network.
We train both networks on an image dataset containing chest radiographs and
benchmark their performance. To mitigate the influence of different sources of
randomness in network training, we sample the results over multiple rounds. We
show that the hybrid network outperforms the classical network on different
performance measures, and that these improvements are statistically
significant. Our work serves as an experimental demonstration of the potential
of quantum computing to significantly improve neural network performance for
real-world, non-trivial problems relevant to society and industry.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting emotion from music videos: exploring the relative contribution of visual and auditory information to affective responses. (arXiv:2202.10453v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10453">
<div class="article-summary-box-inner">
<span><p>Although media content is increasingly produced, distributed, and consumed in
multiple combinations of modalities, how individual modalities contribute to
the perceived emotion of a media item remains poorly understood. In this paper
we present MusicVideos (MuVi), a novel dataset for affective multimedia content
analysis to study how the auditory and visual modalities contribute to the
perceived emotion of media. The data were collected by presenting music videos
to participants in three conditions: music, visual, and audiovisual.
Participants annotated the music videos for valence and arousal over time, as
well as the overall emotion conveyed. We present detailed descriptive
statistics for key measures in the dataset and the results of feature
importance analyses for each condition. Finally, we propose a novel transfer
learning architecture to train Predictive models Augmented with Isolated
modality Ratings (PAIR) and demonstrate the potential of isolated modality
ratings for enhancing multimodal emotion recognition. Our results suggest that
perceptions of arousal are influenced primarily by auditory information, while
perceptions of valence are more subjective and can be influenced by both visual
and auditory information. The dataset is made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feasibility Study of Multi-Site Split Learning for Privacy-Preserving Medical Systems under Data Imbalance Constraints in COVID-19, X-Ray, and Cholesterol Dataset. (arXiv:2202.10456v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10456">
<div class="article-summary-box-inner">
<span><p>It seems as though progressively more people are in the race to upload
content, data, and information online; and hospitals haven't neglected this
trend either. Hospitals are now at the forefront for multi-site medical data
sharing to provide groundbreaking advancements in the way health records are
shared and patients are diagnosed. Sharing of medical data is essential in
modern medical research. Yet, as with all data sharing technology, the
challenge is to balance improved treatment with protecting patient's personal
information. This paper provides a novel split learning algorithm coined the
term, "multi-site split learning", which enables a secure transfer of medical
data between multiple hospitals without fear of exposing personal data
contained in patient records. It also explores the effects of varying the
number of end-systems and the ratio of data-imbalance on the deep learning
performance. A guideline for the most optimal configuration of split learning
that ensures privacy of patient data whilst achieving performance is
empirically given. We argue the benefits of our multi-site split learning
algorithm, especially regarding the privacy preserving factor, using CT scans
of COVID-19 patients, X-ray bone scans, and cholesterol level medical data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Architecture Slimming Method for Network Pruning and Knowledge Distillation. (arXiv:2202.10461v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10461">
<div class="article-summary-box-inner">
<span><p>Network pruning and knowledge distillation are two widely-known model
compression methods that efficiently reduce computation cost and model size. A
common problem in both pruning and distillation is to determine compressed
architecture, i.e., the exact number of filters per layer and layer
configuration, in order to preserve most of the original model capacity. In
spite of the great advances in existing works, the determination of an
excellent architecture still requires human interference or tremendous
experimentations. In this paper, we propose an architecture slimming method
that automates the layer configuration process. We start from the perspective
that the capacity of the over-parameterized model can be largely preserved by
finding the minimum number of filters preserving the maximum parameter variance
per layer, resulting in a thin architecture. We formulate the determination of
compressed architecture as a one-step orthogonal linear transformation, and
integrate principle component analysis (PCA), where the variances of filters in
the first several projections are maximized. We demonstrate the rationality of
our analysis and the effectiveness of the proposed method through extensive
experiments. In particular, we show that under the same overall compression
rate, the compressed architecture determined by our method shows significant
performance gain over baselines after pruning and distillation. Surprisingly,
we find that the resulting layer-wise compression rates correspond to the layer
sensitivities found by existing works through tremendous experimentations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CaMEL: Mean Teacher Learning for Image Captioning. (arXiv:2202.10492v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10492">
<div class="article-summary-box-inner">
<span><p>Describing images in natural language is a fundamental step towards the
automatic modeling of connections between the visual and textual modalities. In
this paper we present CaMEL, a novel Transformer-based architecture for image
captioning. Our proposed approach leverages the interaction of two
interconnected language models that learn from each other during the training
phase. The interplay between the two language models follows a mean teacher
learning paradigm with knowledge distillation. Experimentally, we assess the
effectiveness of the proposed solution on the COCO dataset and in conjunction
with different visual feature extractors. When comparing with existing
proposals, we demonstrate that our model provides state-of-the-art caption
quality with a significantly reduced number of parameters. According to the
CIDEr metric, we obtain a new state of the art on COCO when training without
using external data. The source code and trained models are publicly available
at: https://github.com/aimagelab/camel.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Evolutionary Clustering. (arXiv:2202.10505v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10505">
<div class="article-summary-box-inner">
<span><p>Deep clustering outperforms conventional clustering by mutually promoting
representation learning and cluster assignment. However, most existing deep
clustering methods suffer from two major drawbacks. First, most cluster
assignment methods are based on simple distance comparison and highly dependent
on the target distribution generated by a handcrafted nonlinear mapping. These
facts largely limit the possible performance that deep clustering methods can
reach. Second, the clustering results can be easily guided towards wrong
direction by the misassigned samples in each cluster. The existing deep
clustering methods are incapable of discriminating such samples. To address
these issues, a novel modular Self-Evolutionary Clustering (Self-EvoC)
framework is constructed, which boosts the clustering performance by
classification in a self-supervised manner. Fuzzy theory is used to score the
sample membership with probability which evaluates the intermediate clustering
result certainty of each sample. Based on which, the most reliable samples can
be selected and augmented. The augmented data are employed to fine-tune an
off-the-shelf deep network classifier with the labels from the clustering,
which results in a model to generate the target distribution. The proposed
framework can efficiently discriminate sample outliers and generate better
target distribution with the assistance of self-supervised classifier.
Extensive experiments indicate that the Self-EvoC remarkably outperforms
state-of-the-art deep clustering methods on three benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-Implicit Hybrid Gradient Methods with Application to Adversarial Robustness. (arXiv:2202.10523v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10523">
<div class="article-summary-box-inner">
<span><p>Adversarial examples, crafted by adding imperceptible perturbations to
natural inputs, can easily fool deep neural networks (DNNs). One of the most
successful methods for training adversarially robust DNNs is solving a
nonconvex-nonconcave minimax problem with an adversarial training (AT)
algorithm. However, among the many AT algorithms, only Dynamic AT (DAT) and You
Only Propagate Once (YOPO) guarantee convergence to a stationary point. In this
work, we generalize the stochastic primal-dual hybrid gradient algorithm to
develop semi-implicit hybrid gradient methods (SI-HGs) for finding stationary
points of nonconvex-nonconcave minimax problems. SI-HGs have the convergence
rate $O(1/K)$, which improves upon the rate $O(1/K^{1/2})$ of DAT and YOPO. We
devise a practical variant of SI-HGs, and show that it outperforms other AT
algorithms in terms of convergence speed and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Sampling Rate: Harnessing Frame Coherence in Graphics Applications for Energy-Efficient GPUs. (arXiv:2202.10533v1 [cs.AR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10533">
<div class="article-summary-box-inner">
<span><p>In real-time rendering, a 3D scene is modelled with meshes of triangles that
the GPU projects to the screen. They are discretized by sampling each triangle
at regular space intervals to generate fragments which are then added texture
and lighting effects by a shader program. Realistic scenes require detailed
geometric models, complex shaders, high-resolution displays and high screen
refreshing rates, which all come at a great compute time and energy cost. This
cost is often dominated by the fragment shader, which runs for each sampled
fragment. Conventional GPUs sample the triangles once per pixel, however, there
are many screen regions containing low variation that produce identical
fragments and could be sampled at lower than pixel-rate with no loss in
quality. Additionally, as temporal frame coherence makes consecutive frames
very similar, such variations are usually maintained from frame to frame. This
work proposes Dynamic Sampling Rate (DSR), a novel hardware mechanism to reduce
redundancy and improve the energy efficiency in graphics applications. DSR
analyzes the spatial frequencies of the scene once it has been rendered. Then,
it leverages the temporal coherence in consecutive frames to decide, for each
region of the screen, the lowest sampling rate to employ in the next frame that
maintains image quality. We evaluate the performance of a state-of-the-art
mobile GPU architecture extended with DSR for a wide variety of applications.
Experimental results show that DSR is able to remove most of the redundancy
inherent in the color computations at fragment granularity, which brings
average speedups of 1.68x and energy savings of 40%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReViVD: Exploration and Filtering of Trajectories in an Immersive Environment using 3D Shapes. (arXiv:2202.10545v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10545">
<div class="article-summary-box-inner">
<span><p>We present ReViVD, a tool for exploring and filtering large trajectory-based
datasets using virtual reality. ReViVD's novelty lies in using simple 3D shapes
-- such as cuboids, spheres and cylinders -- as queries for users to select and
filter groups of trajectories. Building on this simple paradigm, more complex
queries can be created by combining previously made selection groups through a
system of user-created Boolean operations. We demonstrate the use of ReViVD in
different application domains, from GPS position tracking to simulated data
(e.g., turbulent particle flows and traffic simulation). Our results show the
ease of use and expressiveness of the 3D geometric shapes in a broad range of
exploratory tasks. ReViVD was found to be particularly useful for progressively
refining selections to isolate outlying behaviors. It also acts as a powerful
communication tool for conveying the structure of normally abstract datasets to
an audience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Privacy Leakage of Adversarial Training Models in Federated Learning Systems. (arXiv:2202.10546v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10546">
<div class="article-summary-box-inner">
<span><p>Adversarial Training (AT) is crucial for obtaining deep neural networks that
are robust to adversarial attacks, yet recent works found that it could also
make models more vulnerable to privacy attacks. In this work, we further reveal
this unsettling property of AT by designing a novel privacy attack that is
practically applicable to the privacy-sensitive Federated Learning (FL)
systems. Using our method, the attacker can exploit AT models in the FL system
to accurately reconstruct users' private training images even when the training
batch size is large. Code is available at
https://github.com/zjysteven/PrivayAttack_AT_FL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guidelines and evaluation for clinical explainable AI on medical image analysis. (arXiv:2202.10553v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10553">
<div class="article-summary-box-inner">
<span><p>Explainable artificial intelligence (XAI) is essential for enabling clinical
users to get informed decision support from AI and comply with evidence-based
medical practice. Applying XAI in clinical settings requires proper evaluation
criteria to ensure the explanation technique is both technically sound and
clinically useful, but specific support is lacking to achieve this goal. To
bridge the research gap, we propose the Clinical XAI Guidelines that consist of
five criteria a clinical XAI needs to be optimized for. The guidelines
recommend choosing an explanation form based on Guideline 1 (G1)
Understandability and G2 Clinical relevance. For the chosen explanation form,
its specific XAI technique should be optimized for G3 Truthfulness, G4
Informative plausibility, and G5 Computational efficiency.
</p>
<p>Following the guidelines, we conducted a systematic evaluation on a novel
problem of multi-modal medical image explanation with two clinical tasks, and
proposed new evaluation metrics accordingly. The evaluated 16 commonly-used
heatmap XAI techniques were not suitable for clinical use due to their failure
in \textbf{G3} and \textbf{G4}. Our evaluation demonstrated the use of Clinical
XAI Guidelines to support the design and evaluation for clinically viable XAI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ensemble Learning techniques for object detection in high-resolution satellite images. (arXiv:2202.10554v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10554">
<div class="article-summary-box-inner">
<span><p>Ensembling is a method that aims to maximize the detection performance by
fusing individual detectors. While rarely mentioned in deep-learning articles
applied to remote sensing, ensembling methods have been widely used to achieve
high scores in recent data science com-petitions, such as Kaggle. The few
remote sensing articles mentioning ensembling mainly focus on mid resolution
images and earth observation applications such as land use classification, but
never on Very High Resolution (VHR) images for defense-related applications or
object detection.This study aims at reviewing the most relevant ensembling
techniques to be used for object detection on very high resolution imagery and
shows an example of the value of such techniques on a relevant operational
use-case (vehicle detection in desert areas).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effective Training Strategies for Deep-learning-based Precipitation Nowcasting and Estimation. (arXiv:2202.10555v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10555">
<div class="article-summary-box-inner">
<span><p>Deep learning has been successfully applied to precipitation nowcasting. In
this work, we propose a pre-training scheme and a new loss function for
improving deep-learning-based nowcasting. First, we adapt U-Net, a widely-used
deep-learning model, for the two problems of interest here: precipitation
nowcasting and precipitation estimation from radar images. We formulate the
former as a classification problem with three precipitation intervals and the
latter as a regression problem. For these tasks, we propose to pre-train the
model to predict radar images in the near future without requiring ground-truth
precipitation, and we also propose the use of a new loss function for
fine-tuning to mitigate the class imbalance problem. We demonstrate the
effectiveness of our approach using radar images and precipitation datasets
collected from South Korea over seven years. It is highlighted that our
pre-training scheme and new loss function improve the critical success index
(CSI) of nowcasting of heavy rainfall (at least 10 mm/hr) by up to 95.7% and
43.6%, respectively, at a 5-hr lead time. We also demonstrate that our approach
reduces the precipitation estimation error by up to 10.7%, compared to the
conventional approach, for light rainfall (between 1 and 10 mm/hr). Lastly, we
report the sensitivity of our approach to different resolutions and a detailed
analysis of four cases of heavy rainfall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Videos with Dynamics-aware Implicit Generative Adversarial Networks. (arXiv:2202.10571v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10571">
<div class="article-summary-box-inner">
<span><p>In the deep learning era, long video generation of high-quality still remains
challenging due to the spatio-temporal complexity and continuity of videos.
Existing prior works have attempted to model video distribution by representing
videos as 3D grids of RGB values, which impedes the scale of generated videos
and neglects continuous dynamics. In this paper, we found that the recent
emerging paradigm of implicit neural representations (INRs) that encodes a
continuous signal into a parameterized neural network effectively mitigates the
issue. By utilizing INRs of video, we propose dynamics-aware implicit
generative adversarial network (DIGAN), a novel generative adversarial network
for video generation. Specifically, we introduce (a) an INR-based video
generator that improves the motion dynamics by manipulating the space and time
coordinates differently and (b) a motion discriminator that efficiently
identifies the unnatural motions without observing the entire long frame
sequences. We demonstrate the superiority of DIGAN under various datasets,
along with multiple intriguing properties, e.g., long video synthesis, video
extrapolation, and non-autoregressive video generation. For example, DIGAN
improves the previous state-of-the-art FVD score on UCF-101 by 30.7% and can be
trained on 128 frame videos of 128x128 resolution, 80 frames longer than the 48
frames of the previous state-of-the-art method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Semantic-Assisted Outlier Removal for Large-scale Point Cloud Registration. (arXiv:2202.10579v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10579">
<div class="article-summary-box-inner">
<span><p>With current trends in sensors (cheaper, more volume of data) and
applications (increasing affordability for new tasks, new ideas in what 3D data
could be useful for); there is corresponding increasing interest in the ability
to automatically, reliably, and cheaply, register together individual point
clouds. The volume of data to handle, and still elusive need to have the
registration occur fully reliably and fully automatically, mean there is a need
to innovate further. One largely untapped area of innovation is that of
exploiting the {\em semantic information} of the points in question. Points on
a tree should match points on a tree, for example, and not points on car.
Moreover, such a natural restriction is clearly human-like - a human would
generally quickly eliminate candidate regions for matching based on semantics.
Employing semantic information is not only efficient but natural. It is also
timely - due to the recent advances in semantic classification capabilities.
This paper advances this theme by demonstrating that state of the art
registration techniques, in particular ones that rely on "preservation of
length under rigid motion" as an underlying matching consistency constraint,
can be augmented with semantic information. Semantic identity is of course also
preserved under rigid-motion, but also under wider motions present in a scene.
We demonstrate that not only the potential obstacle of cost of semantic
segmentation, and the potential obstacle of the unreliability of semantic
segmentation; are both no impediment to achieving both speed and accuracy in
fully automatic registration of large scale point clouds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling Light Fields for Super-Resolution and Disparity Estimation. (arXiv:2202.10603v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10603">
<div class="article-summary-box-inner">
<span><p>Light field (LF) cameras record both intensity and directions of light rays,
and encode 3D scenes into 4D LF images. Recently, many convolutional neural
networks (CNNs) have been proposed for various LF image processing tasks.
However, it is challenging for CNNs to effectively process LF images since the
spatial and angular information are highly inter-twined with varying
disparities. In this paper, we propose a generic mechanism to disentangle these
coupled information for LF image processing. Specifically, we first design a
class of domain-specific convolutions to disentangle LFs from different
dimensions, and then leverage these disentangled features by designing
task-specific modules. Our disentangling mechanism can well incorporate the LF
structure prior and effectively handle 4D LF data. Based on the proposed
mechanism, we develop three networks (i.e., DistgSSR, DistgASR and DistgDisp)
for spatial super-resolution, angular super-resolution and disparity
estimation. Experimental results show that our networks achieve
state-of-the-art performance on all these three tasks, which demonstrates the
effectiveness, efficiency, and generality of our disentangling mechanism.
Project page: https://yingqianwang.github.io/DistgLF/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Local Sliced-Wasserstein Feature Sets for Illumination-invariant Face Recognition. (arXiv:2202.10642v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10642">
<div class="article-summary-box-inner">
<span><p>We present a new method for face recognition from digital images acquired
under varying illumination conditions. The method is based on mathematical
modeling of local gradient distributions using the Radon Cumulative
Distribution Transform (R-CDT). We demonstrate that lighting variations cause
certain types of deformations of local image gradient distributions which, when
expressed in R-CDT domain, can be modeled as a subspace. Face recognition is
then performed using a nearest subspace in R-CDT domain of local gradient
distributions. Experiment results demonstrate the proposed method outperforms
other alternatives in several face recognition tasks with challenging
illumination conditions. Python code implementing the proposed method is
available, which is integrated as a part of the software package PyTransKit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Two-Branch Neural Network for Gait Recognition. (arXiv:2202.10645v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10645">
<div class="article-summary-box-inner">
<span><p>Gait recognition, a promising long-distance biometric technology, has aroused
intense interest in computer vision. Existing works on gait recognition can be
divided into appearance-based methods and model-based methods, which extract
features from silhouettes and skeleton data, respectively. However, since
appearance-based methods are greatly affected by clothing changing and carrying
condition, and model-based methods are limited by the accuracy of pose
estimation approaches, gait recognition remains challenging in practical
applications. In order to integrate the merits of such two approaches, a
two-branch neural network (NN)-based model is proposed in this paper. The
method contains two branches, namely a CNN-based branch taking silhouettes as
input and a GCN-based branch taking skeletons as input. In addition, two
modifications are introduced into the GCN-based branch to boost the
performance. First, we present a simple fully connected graph convolution
operator to integrate multi-scale graph convolutions and relieve dependence on
natural connections. Second, we deploy an attention module named STC-Att after
each GCN block to learn spatial, temporal and channel-wise attention
simultaneously. We evaluated the proposed two-branch neural network on the
CASIA-B dataset. The experimental results show that our method achieves
state-of-the-art performance in various conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Movies2Scenes: Learning Scene Representations Using Movie Similarities. (arXiv:2202.10650v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10650">
<div class="article-summary-box-inner">
<span><p>Automatic understanding of movie-scenes is an important problem with multiple
downstream applications including video-moderation, search and recommendation.
The long-form nature of movies makes labeling of movie scenes a laborious task,
which makes applying end-to-end supervised approaches for understanding
movie-scenes a challenging problem. Directly applying state-of-the-art visual
representations learned from large-scale image datasets for movie-scene
understanding does not prove to be effective given the large gap between the
two domains. To address these challenges, we propose a novel contrastive
learning approach that uses commonly available sources of movie-information
(e.g., genre, synopsis, more-like-this information) to learn a general-purpose
scene-representation. Using a new dataset (MovieCL30K) with 30,340 movies, we
demonstrate that our learned scene-representation surpasses existing
state-of-the-art results on eleven downstream tasks from multiple datasets. To
further show the effectiveness of our scene-representation, we introduce
another new dataset (MCD) focused on large-scale video-moderation with 44,581
clips containing sex, violence, and drug-use activities covering 18,330 movies
and TV episodes, and show strong gains over existing state-of-the-art
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit Detection & Multi-Task Learning Challenges. (arXiv:2202.10659v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10659">
<div class="article-summary-box-inner">
<span><p>This paper describes the third Affective Behavior Analysis in-the-wild (ABAW)
Competition, held in conjunction with IEEE International Conference on Computer
Vision and Pattern Recognition (CVPR), 2022. The 3rd ABAW Competition is a
continuation of the Competitions held at ICCV 2021, IEEE FG 2020 and IEEE CVPR
2017 Conferences, and aims at automatically analyzing affect. This year the
Competition encompasses four Challenges: i) uni-task Valence-Arousal
Estimation, ii) uni-task Expression Classification, iii) uni-task Action Unit
Detection, and iv) Multi-Task-Learning. All the Challenges are based on a
common benchmark database, Aff-Wild2, which is a large scale in-the-wild
database and the first one to be annotated in terms of valence-arousal,
expressions and action units. In this paper, we present the four Challenges,
with the utilized Competition corpora, we outline the evaluation metrics and
present the baseline systems along with their obtained results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Eye Detector Using Metric Learning for Iris on The Move. (arXiv:2202.10671v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10671">
<div class="article-summary-box-inner">
<span><p>This paper proposes a fast eye detection method based on fully-convolutional
Siamese networks for iris recognition. The iris on the move system requires to
capture high resolution iris images from a moving subject for iris recognition.
Therefore, capturing images contains both eyes at high-frame-rate increases the
chance of iris imaging. In order to output the authentication result in real
time, the system requires a fast eye detector extracting the left and right eye
regions from the image. Our method extracts features of a partial face image
and a reference eye image using Siamese network frameworks. Similarity heat
maps of both eyes are created by calculating the spatial cosine similarity
between extracted features. Besides, we use CosFace as a loss function for
training to discriminate the left and right eyes with high accuracy even with a
shallow network. Experimental results show that our method trained by CosFace
is fast and accurate compared with conventional generic object detection
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seeing is Living? Rethinking the Security of Facial Liveness Verification in the Deepfake Era. (arXiv:2202.10673v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10673">
<div class="article-summary-box-inner">
<span><p>Facial Liveness Verification (FLV) is widely used for identity authentication
in many security-sensitive domains and offered as Platform-as-a-Service (PaaS)
by leading cloud vendors. Yet, with the rapid advances in synthetic media
techniques (e.g., deepfake), the security of FLV is facing unprecedented
challenges, about which little is known thus far.
</p>
<p>To bridge this gap, in this paper, we conduct the first systematic study on
the security of FLV in real-world settings. Specifically, we present
LiveBugger, a new deepfake-powered attack framework that enables customizable,
automated security evaluation of FLV. Leveraging LiveBugger, we perform a
comprehensive empirical assessment of representative FLV platforms, leading to
a set of interesting findings. For instance, most FLV APIs do not use
anti-deepfake detection; even for those with such defenses, their effectiveness
is concerning (e.g., it may detect high-quality synthesized videos but fail to
detect low-quality ones). We then conduct an in-depth analysis of the factors
impacting the attack performance of LiveBugger: a) the bias (e.g., gender or
race) in FLV can be exploited to select victims; b) adversarial training makes
deepfake more effective to bypass FLV; c) the input quality has a varying
influence on different deepfake techniques to bypass FLV. Based on these
findings, we propose a customized, two-stage approach that can boost the attack
success rate by up to 70%. Further, we run proof-of-concept attacks on several
representative applications of FLV (i.e., the clients of FLV APIs) to
illustrate the practical implications: due to the vulnerability of the APIs,
many downstream applications are vulnerable to deepfake. Finally, we discuss
potential countermeasures to improve the security of FLV. Our findings have
been confirmed by the corresponding vendors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reinforcing Local Feature Representation for Weakly-Supervised Dense Crowd Counting. (arXiv:2202.10681v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10681">
<div class="article-summary-box-inner">
<span><p>Fully-supervised crowd counting is a laborious task due to the large amounts
of annotations. Few works focus on weekly-supervised crowd counting, where only
the global crowd numbers are available for training. The main challenge of
weekly-supervised crowd counting is the lack of local supervision information.
To address this problem, we propose a self-adaptive feature similarity learning
(SFSL) network and a global-local consistency (GLC) loss to reinforce local
feature representation. We introduce a feature vector which represents the
unbiased feature estimation of persons. The network updates the feature vector
self-adaptively and utilizes the feature similarity for the regression of crowd
numbers. Besides, the proposed GLC loss leverages the consistency between the
network estimations from global and local areas. The experimental results
demonstrate that our proposed method based on different backbones narrows the
gap between weakly-supervised and fully-supervised dense crowd counting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cut and Continuous Paste towards Real-time Deep Fall Detection. (arXiv:2202.10687v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10687">
<div class="article-summary-box-inner">
<span><p>Deep learning based fall detection is one of the crucial tasks for
intelligent video surveillance systems, which aims to detect unintentional
falls of humans and alarm dangerous situations. In this work, we propose a
simple and efficient framework to detect falls through a single and small-sized
convolutional neural network. To this end, we first introduce a new image
synthesis method that represents human motion in a single frame. This
simplifies the fall detection task as an image classification task. Besides,
the proposed synthetic data generation method enables to generate a sufficient
amount of training dataset, resulting in satisfactory performance even with the
small model. At the inference step, we also represent real human motion in a
single image by estimating mean of input frames. In the experiment, we conduct
both qualitative and quantitative evaluations on URFD and AIHub airport
datasets to show the effectiveness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Object Aware Hybrid U-Net for Breast Tumour Annotation. (arXiv:2202.10691v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10691">
<div class="article-summary-box-inner">
<span><p>In the clinical settings, during digital examination of histopathological
slides, the pathologist annotate the slides by marking the rough boundary
around the suspected tumour region. The marking or annotation is generally
represented as a polygonal boundary that covers the extent of the tumour in the
slide. These polygonal markings are difficult to imitate through CAD techniques
since the tumour regions are heterogeneous and hence segmenting them would
require exhaustive pixel wise ground truth annotation. Therefore, for CAD
analysis, the ground truths are generally annotated by pathologist explicitly
for research purposes. However, this kind of annotation which is generally
required for semantic or instance segmentation is time consuming and tedious.
In this proposed work, therefore, we have tried to imitate pathologist like
annotation by segmenting tumour extents by polygonal boundaries. For polygon
like annotation or segmentation, we have used Active Contours whose vertices or
snake points move towards the boundary of the object of interest to find the
region of minimum energy. To penalize the Active Contour we used modified U-Net
architecture for learning penalization values. The proposed hybrid deep
learning model fuses the modern deep learning segmentation algorithm with
traditional Active Contours segmentation technique. The model is tested against
both state-of-the-art semantic segmentation and hybrid models for performance
evaluation against contemporary work. The results obtained show that the
pathologist like annotation could be achieved by developing such hybrid models
that integrate the domain knowledge through classical segmentation methods like
Active Contours and global knowledge through semantic segmentation deep
learning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal adversarial perturbation for remote sensing images. (arXiv:2202.10693v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10693">
<div class="article-summary-box-inner">
<span><p>Recently, with the application of deep learning in the remote sensing image
(RSI) field, the classification accuracy of the RSI has been greatly improved
compared with traditional technology. However, even state-of-the-art object
recognition convolutional neural networks are fooled by the universal
adversarial perturbation (UAP). To verify that UAP makes the RSI classification
model error classification, this paper proposes a novel method combining an
encoder-decoder network with an attention mechanism. Firstly, the former can
learn the distribution of perturbations better, then the latter is used to find
the main regions concerned by the RSI classification model. Finally, the
generated regions are used to fine-tune the perturbations making the model
misclassified with fewer perturbations. The experimental results show that the
UAP can make the RSI misclassify, and the attack success rate (ASR) of our
proposed method on the RSI data set is as high as 97.35%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ensembling Handcrafted Features with Deep Features: An Analytical Study for Classification of Routine Colon Cancer Histopathological Nuclei Images. (arXiv:2202.10694v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10694">
<div class="article-summary-box-inner">
<span><p>The use of Deep Learning (DL) based methods in medical histopathology images
have been one of the most sought after solutions to classify, segment, and
detect diseased biopsy samples. However, given the complex nature of medical
datasets due to the presence of intra-class variability and heterogeneity, the
use of complex DL models might not give the optimal performance up to the level
which is suitable for assisting pathologists. Therefore, ensemble DL methods
with the scope of including domain agnostic handcrafted Features (HC-F)
inspired this work. We have, through experiments, tried to highlight that a
single DL network (domain-specific or state of the art pre-trained models)
cannot be directly used as the base model without proper analysis with the
relevant dataset. We have used F1-measure, Precision, Recall, AUC, and
Cross-Entropy Loss to analyse the performance of our approaches. We observed
from the results that the DL features ensemble bring a marked improvement in
the overall performance of the model, whereas, domain agnostic HC-F remains
dormant on the performance of the DL models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bag of Visual Words (BoVW) with Deep Features -- Patch Classification Model for Limited Dataset of Breast Tumours. (arXiv:2202.10701v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10701">
<div class="article-summary-box-inner">
<span><p>Currently, the computational complexity limits the training of high
resolution gigapixel images using Convolutional Neural Networks. Therefore,
such images are divided into patches or tiles. Since, these high resolution
patches are encoded with discriminative information therefore; CNNs are trained
on these patches to perform patch-level predictions. However, the problem with
patch-level prediction is that pathologist generally annotates at image-level
and not at patch level. Due to this limitation most of the patches may not
contain enough class-relevant features. Through this work, we tried to
incorporate patch descriptive capability within the deep framework by using Bag
of Visual Words (BoVW) as a kind of regularisation to improve generalizability.
Using this hypothesis, we aim to build a patch based classifier to discriminate
between four classes of breast biopsy image patches (normal, benign, \textit{In
situ} carcinoma, invasive carcinoma). The task is to incorporate quality deep
features using CNN to describe relevant information in the images while
simultaneously discarding irrelevant information using Bag of Visual Words
(BoVW). The proposed method passes patches obtained from WSI and microscopy
images through pre-trained CNN to extract features. BoVW is used as a feature
selector to select most discriminative features among the CNN features.
Finally, the selected feature sets are classified as one of the four classes.
The hybrid model provides flexibility in terms of choice of pre-trained models
for feature extraction. The pipeline is end-to-end since it does not require
post processing of patch predictions to select discriminative patches. We
compared our observations with state-of-the-art methods like ResNet50,
DenseNet169, and InceptionV3 on the BACH-2018 challenge dataset. Our proposed
method shows better performance than all the three methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Privacy-Preserving In-Bed Pose Monitoring: A Fusion and Reconstruction Study. (arXiv:2202.10704v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10704">
<div class="article-summary-box-inner">
<span><p>Recently, in-bed human pose estimation has attracted the interest of
researchers due to its relevance to a wide range of healthcare applications.
Compared to the general problem of human pose estimation, in-bed pose
estimation has several inherent challenges, the most prominent being frequent
and severe occlusions caused by bedding. In this paper we explore the effective
use of images from multiple non-visual and privacy-preserving modalities such
as depth, long-wave infrared (LWIR) and pressure maps for the task of in-bed
pose estimation in two settings. First, we explore the effective fusion of
information from different imaging modalities for better pose estimation.
Secondly, we propose a framework that can estimate in-bed pose estimation when
visible images are unavailable, and demonstrate the applicability of fusion
methods to scenarios where only LWIR images are available. We analyze and
demonstrate the effect of fusing features from multiple modalities. For this
purpose, we consider four different techniques: 1) Addition, 2) Concatenation,
3) Fusion via learned modal weights, and 4) End-to-end fully trainable
approach; with a state-of-the-art pose estimation model. We also evaluate the
effect of reconstructing a data-rich modality (i.e., visible modality) from a
privacy-preserving modality with data scarcity (i.e., long-wavelength infrared)
for in-bed human pose estimation. For reconstruction, we use a conditional
generative adversarial network. We conduct ablative studies across different
design decisions of our framework. This includes selecting features with
different levels of granularity, using different fusion techniques, and varying
model parameters. Through extensive evaluations, we demonstrate that our method
produces on par or better results compared to the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PointMatch: A Consistency Training Framework for Weakly SupervisedSemantic Segmentation of 3D Point Clouds. (arXiv:2202.10705v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10705">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation of point cloud usually relies on dense annotation that
is exhausting and costly, so it attracts wide attention to investigate
solutions for the weakly supervised scheme with only sparse points annotated.
Existing works start from the given labels and propagate them to highly-related
but unlabeled points, with the guidance of data, e.g. intra-point relation.
However, it suffers from (i) the inefficient exploitation of data information,
and (ii) the strong reliance on labels thus is easily suppressed when given
much fewer annotations. Therefore, we propose a novel framework, PointMatch,
that stands on both data and label, by applying consistency regularization to
sufficiently probe information from data itself and leveraging weak labels as
assistance at the same time. By doing so, meaningful information can be learned
from both data and label for better representation learning, which also enables
the model more robust to the extent of label sparsity. Simple yet effective,
the proposed PointMatch achieves the state-of-the-art performance under various
weakly-supervised schemes on both ScanNet-v2 and S3DIS datasets, especially on
the settings with extremely sparse labels, e.g. surpassing SQN by 21.2% and
17.2% on the 0.01% and 0.1% setting of ScanNet-v2, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HRel: Filter Pruning based on High Relevance between Activation Maps and Class Labels. (arXiv:2202.10716v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10716">
<div class="article-summary-box-inner">
<span><p>This paper proposes an Information Bottleneck theory based filter pruning
method that uses a statistical measure called Mutual Information (MI). The MI
between filters and class labels, also called \textit{Relevance}, is computed
using the filter's activation maps and the annotations. The filters having High
Relevance (HRel) are considered to be more important. Consequently, the least
important filters, which have lower Mutual Information with the class labels,
are pruned. Unlike the existing MI based pruning methods, the proposed method
determines the significance of the filters purely based on their corresponding
activation map's relationship with the class labels. Architectures such as
LeNet-5, VGG-16, ResNet-56\textcolor{myblue}{, ResNet-110 and ResNet-50 are
utilized to demonstrate the efficacy of the proposed pruning method over MNIST,
CIFAR-10 and ImageNet datasets. The proposed method shows the state-of-the-art
pruning results for LeNet-5, VGG-16, ResNet-56, ResNet-110 and ResNet-50
architectures. In the experiments, we prune 97.98 \%, 84.85 \%, 76.89\%,
76.95\%, and 63.99\% of Floating Point Operation (FLOP)s from LeNet-5, VGG-16,
ResNet-56, ResNet-110, and ResNet-50 respectively.} The proposed HRel pruning
method outperforms recent state-of-the-art filter pruning methods. Even after
pruning the filters from convolutional layers of LeNet-5 drastically (i.e. from
20, 50 to 2, 3, respectively), only a small accuracy drop of 0.52\% is
observed. Notably, for VGG-16, 94.98\% parameters are reduced, only with a drop
of 0.36\% in top-1 accuracy. \textcolor{myblue}{ResNet-50 has shown a 1.17\%
drop in the top-5 accuracy after pruning 66.42\% of the FLOPs.} In addition to
pruning, the Information Plane dynamics of Information Bottleneck theory is
analyzed for various Convolutional Neural Network architectures with the effect
of pruning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature reconstruction from incomplete tomographic data without detour. (arXiv:2202.10724v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10724">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider the problem of feature reconstruction from
incomplete x-ray CT data. Such problems occurs, e.g., as a result of dose
reduction in the context medical imaging. Since image reconstruction from
incomplete data is a severely ill-posed problem, the reconstructed images may
suffer from characteristic artefacts or missing features, and significantly
complicate subsequent image processing tasks (e.g., edge detection or
segmentation). In this paper, we introduce a novel framework for the robust
reconstruction of convolutional image features directly from CT data, without
the need of computing a reconstruction firs. Within our framework we use
non-linear (variational) regularization methods that can be adapted to a
variety of feature reconstruction tasks and to several limited data situations
. In our numerical experiments, we consider several instances of edge
reconstructions from angularly undersampled data and show that our approach is
able to reliably reconstruct feature maps in this case.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Convolutional Neural Network Modelling for MODIS Land Surface Temperature Super-Resolution. (arXiv:2202.10753v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10753">
<div class="article-summary-box-inner">
<span><p>Nowadays, thermal infrared satellite remote sensors enable to extract very
interesting information at large scale, in particular Land Surface Temperature
(LST). However such data are limited in spatial and/or temporal resolutions
which prevents from an analysis at fine scales. For example, MODIS satellite
provides daily acquisitions with 1Km spatial resolutions which is not
sufficient to deal with highly heterogeneous environments as agricultural
parcels. Therefore, image super-resolution is a crucial task to better exploit
MODIS LSTs. This issue is tackled in this paper. We introduce a deep
learning-based algorithm, named Multi-residual U-Net, for super-resolution of
MODIS LST single-images. Our proposed network is a modified version of U-Net
architecture, which aims at super-resolving the input LST image from 1Km to
250m per pixel. The results show that our Multi-residual U-Net outperforms
other state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thinking the Fusion Strategy of Multi-reference Face Reenactment. (arXiv:2202.10758v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10758">
<div class="article-summary-box-inner">
<span><p>In recent advances of deep generative models, face reenactment -manipulating
and controlling human face, including their head movement-has drawn much
attention for its wide range of applicability. Despite its strong
expressiveness, it is inevitable that the models fail to reconstruct or
accurately generate unseen side of the face of a given single reference image.
Most of existing methods alleviate this problem by learning appearances of
human faces from large amount of data and generate realistic texture at
inference time. Rather than completely relying on what generative models learn,
we show that simple extension by using multiple reference images significantly
improves generation quality. We show this by 1) conducting the reconstruction
task on publicly available dataset, 2) conducting facial motion transfer on our
original dataset which consists of multi-person's head movement video
sequences, and 3) using a newly proposed evaluation metric to validate that our
method achieves better quantitative results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep learning based domain adaptation for mitochondria segmentation on EM volumes. (arXiv:2202.10773v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10773">
<div class="article-summary-box-inner">
<span><p>Accurate segmentation of electron microscopy (EM) volumes of the brain is
essential to characterize neuronal structures at a cell or organelle level.
While supervised deep learning methods have led to major breakthroughs in that
direction during the past years, they usually require large amounts of
annotated data to be trained, and perform poorly on other data acquired under
similar experimental and imaging conditions. This is a problem known as domain
adaptation, since models that learned from a sample distribution (or source
domain) struggle to maintain their performance on samples extracted from a
different distribution or target domain. In this work, we address the complex
case of deep learning based domain adaptation for mitochondria segmentation
across EM datasets from different tissues and species. We present three
unsupervised domain adaptation strategies to improve mitochondria segmentation
in the target domain based on (1) state-of-the-art style transfer between
images of both domains; (2) self-supervised learning to pre-train a model using
unlabeled source and target images, and then fine-tune it only with the source
labels; and (3) multi-task neural network architectures trained end-to-end with
both labeled and unlabeled images. Additionally, we propose a new training
stopping criterion based on morphological priors obtained exclusively in the
source domain. We carried out all possible cross-dataset experiments using
three publicly available EM datasets. We evaluated our proposed strategies on
the mitochondria semantic labels predicted on the target datasets. The methods
introduced here outperform the baseline methods and compare favorably to the
state of the art. In the absence of validation labels, monitoring our proposed
morphology-based metric is an intuitive and effective way to stop the training
process and select in average optimal models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RuCLIP -- new models and experiments: a technical report. (arXiv:2202.10784v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10784">
<div class="article-summary-box-inner">
<span><p>In the report we propose six new implementations of ruCLIP model trained on
our 240M pairs. The accuracy results are compared with original CLIP model with
Ru-En translation (OPUS-MT) on 16 datasets from different domains. Our best
implementations outperform CLIP + OPUS-MT solution on most of the datasets in
few-show and zero-shot tasks. In the report we briefly describe the
implementations and concentrate on the conducted experiments. Inference
execution time comparison is also presented in the report.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VU-BERT: A Unified framework for Visual Dialog. (arXiv:2202.10787v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10787">
<div class="article-summary-box-inner">
<span><p>The visual dialog task attempts to train an agent to answer multi-turn
questions given an image, which requires the deep understanding of interactions
between the image and dialog history. Existing researches tend to employ the
modality-specific modules to model the interactions, which might be troublesome
to use. To fill in this gap, we propose a unified framework for image-text
joint embedding, named VU-BERT, and apply patch projection to obtain vision
embedding firstly in visual dialog tasks to simplify the model. The model is
trained over two tasks: masked language modeling and next utterance retrieval.
These tasks help in learning visual concepts, utterances dependence, and the
relationships between these two modalities. Finally, our VU-BERT achieves
competitive performance (0.7287 NDCG scores) on VisDial v1.0 Datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A-Eye: Driving with the Eyes of AI for Corner Case Generation. (arXiv:2202.10803v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10803">
<div class="article-summary-box-inner">
<span><p>The overall goal of this work is to enrich training data for automated
driving with so called corner cases. In road traffic, corner cases are
critical, rare and unusual situations that challenge the perception by AI
algorithms. For this purpose, we present the design of a test rig to generate
synthetic corner cases using a human-in-the-loop approach. For the test rig, a
real-time semantic segmentation network is trained and integrated into the
driving simulation software CARLA in such a way that a human can drive on the
network's prediction. In addition, a second person gets to see the same scene
from the original CARLA output and is supposed to intervene with the help of a
second control unit as soon as the semantic driver shows dangerous driving
behavior. Interventions potentially indicate poor recognition of a critical
scene by the segmentation network and then represents a corner case. In our
experiments, we show that targeted enrichment of training data with corner
cases leads to improvements in pedestrian detection in safety relevant episodes
in road traffic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One-shot Scene Graph Generation. (arXiv:2202.10824v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10824">
<div class="article-summary-box-inner">
<span><p>As a structured representation of the image content, the visual scene graph
(visual relationship) acts as a bridge between computer vision and natural
language processing. Existing models on the scene graph generation task
notoriously require tens or hundreds of labeled samples. By contrast, human
beings can learn visual relationships from a few or even one example. Inspired
by this, we design a task named One-Shot Scene Graph Generation, where each
relationship triplet (e.g., "dog-has-head") comes from only one labeled
example. The key insight is that rather than learning from scratch, one can
utilize rich prior knowledge. In this paper, we propose Multiple Structured
Knowledge (Relational Knowledge and Commonsense Knowledge) for the one-shot
scene graph generation task. Specifically, the Relational Knowledge represents
the prior knowledge of relationships between entities extracted from the visual
content, e.g., the visual relationships "standing in", "sitting in", and "lying
in" may exist between "dog" and "yard", while the Commonsense Knowledge encodes
"sense-making" knowledge like "dog can guard yard". By organizing these two
kinds of knowledge in a graph structure, Graph Convolution Networks (GCNs) are
used to extract knowledge-embedded semantic features of the entities. Besides,
instead of extracting isolated visual features from each entity generated by
Faster R-CNN, we utilize an Instance Relation Transformer encoder to fully
explore their context information. Based on a constructed one-shot dataset, the
experimental results show that our method significantly outperforms existing
state-of-the-art methods by a large margin. Ablation studies also verify the
effectiveness of the Instance Relation Transformer encoder and the Multiple
Structured Knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation Regularized Scene Graph Generation. (arXiv:2202.10826v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10826">
<div class="article-summary-box-inner">
<span><p>Scene graph generation (SGG) is built on top of detected objects to predict
object pairwise visual relations for describing the image content abstraction.
Existing works have revealed that if the links between objects are given as
prior knowledge, the performance of SGG is significantly improved. Inspired by
this observation, in this article, we propose a relation regularized network
(R2-Net), which can predict whether there is a relationship between two objects
and encode this relation into object feature refinement and better SGG.
Specifically, we first construct an affinity matrix among detected objects to
represent the probability of a relationship between two objects. Graph
convolution networks (GCNs) over this relation affinity matrix are then used as
object encoders, producing relation-regularized representations of objects.
With these relation-regularized features, our R2-Net can effectively refine
object labels and generate scene graphs. Extensive experiments are conducted on
the visual genome dataset for three SGG tasks (i.e., predicate classification,
scene graph classification, and scene graph detection), demonstrating the
effectiveness of our proposed method. Ablation studies also verify the key
roles of our proposed components in performance improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting long-term temporal dynamics for video captioning. (arXiv:2202.10828v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10828">
<div class="article-summary-box-inner">
<span><p>Automatically describing videos with natural language is a fundamental
challenge for computer vision and natural language processing. Recently,
progress in this problem has been achieved through two steps: 1) employing 2-D
and/or 3-D Convolutional Neural Networks (CNNs) (e.g. VGG, ResNet or C3D) to
extract spatial and/or temporal features to encode video contents; and 2)
applying Recurrent Neural Networks (RNNs) to generate sentences to describe
events in videos. Temporal attention-based model has gained much progress by
considering the importance of each video frame. However, for a long video,
especially for a video which consists of a set of sub-events, we should
discover and leverage the importance of each sub-shot instead of each frame. In
this paper, we propose a novel approach, namely temporal and spatial LSTM
(TS-LSTM), which systematically exploits spatial and temporal dynamics within
video sequences. In TS-LSTM, a temporal pooling LSTM (TP-LSTM) is designed to
incorporate both spatial and temporal information to extract long-term temporal
dynamics within video sub-shots; and a stacked LSTM is introduced to generate a
list of words to describe the video. Experimental results obtained in two
public video captioning benchmarks indicate that our TS-LSTM outperforms the
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SADN: Learned Light Field Image Compression with Spatial-Angular Decorrelation. (arXiv:2202.10837v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10837">
<div class="article-summary-box-inner">
<span><p>Light field image becomes one of the most promising media types for immersive
video applications. In this paper, we propose a novel end-to-end
spatial-angular-decorrelated network (SADN) for high-efficiency light field
image compression. Different from the existing methods that exploit either
spatial or angular consistency in the light field image, SADN decouples the
angular and spatial information by dilation convolution and stride convolution
in spatial-angular interaction, and performs feature fusion to compress spatial
and angular information jointly. To train a stable and robust algorithm, a
large-scale dataset consisting of 7549 light field images is proposed and
built. The proposed method provides 2.137 times and 2.849 times higher
compression efficiency relative to H.266/VVC and H.265/HEVC inter coding,
respectively. It also outperforms the end-to-end image compression networks by
an average of 79.6% bitrate saving with much higher subjective quality and
light field consistency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography. (arXiv:2202.10847v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10847">
<div class="article-summary-box-inner">
<span><p>Implicit neural representations (INRs) have achieved impressive results for
scene reconstruction and computer graphics, where their performance has
primarily been assessed on reconstruction accuracy. However, in medical
imaging, where the reconstruction problem is underdetermined and model
predictions inform high-stakes diagnoses, uncertainty quantification of INR
inference is critical. To that end, we study UncertaINR: a Bayesian
reformulation of INR-based image reconstruction, for computed tomography (CT).
We test several Bayesian deep learning implementations of UncertaINR and find
that they achieve well-calibrated uncertainty, while retaining accuracy
competitive with other classical, INR-based, and CNN-based reconstruction
techniques. In contrast to the best-performing prior approaches, UncertaINR
does not require a large training dataset, but only a handful of validation
images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep learning classification of large-scale point clouds: A case study on cuneiform tablets. (arXiv:2202.10851v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10851">
<div class="article-summary-box-inner">
<span><p>This paper introduces a novel network architecture for the classification of
large-scale point clouds. The network is used to classify metadata from
cuneiform tablets. As more than half a million tablets remain unprocessed, this
can help create an overview of the tablets. The network is tested on a
comparison dataset and obtains state-of-the-art performance. We also introduce
new metadata classification tasks on which the network shows promising results.
Finally, we introduce the novel Maximum Attention visualization, demonstrating
that the trained network focuses on the intended features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Consistent Local Superresolution for Medical Imaging. (arXiv:2202.10875v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10875">
<div class="article-summary-box-inner">
<span><p>In this work we propose a new paradigm of iterative model-based
reconstruction algorithms for providing real-time solution for zooming-in and
refining a region of interest in medical and clinical tomographic (such as
CT/MRI/PET, etc) images. This algorithmic framework is tailor for a clinical
need in medical imaging practice, that after a reconstruction of the full
tomographic image, the clinician may believe that some critical parts of the
image are not clear enough, and may wish to see clearer these
regions-of-interest. A naive approach (which is highly not recommended) would
be performing the global reconstruction of a higher resolution image, which has
two major limitations: firstly, it is computationally inefficient, and
secondly, the image regularization is still applied globally which may
over-smooth some local regions. Furthermore if one wish to fine-tune the
regularization parameter for local parts, it would be computationally
infeasible in practice for the case of using global reconstruction. Our new
iterative approaches for such tasks are based on jointly utilizing the
measurement information, efficient upsampling/downsampling across image spaces,
and locally adjusted image prior for efficient and high-quality
post-processing. The numerical results in low-dose X-ray CT image local zoom-in
demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coordinate-Aligned Multi-Camera Collaboration for Active Multi-Object Tracking. (arXiv:2202.10881v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10881">
<div class="article-summary-box-inner">
<span><p>Active Multi-Object Tracking (AMOT) is a task where cameras are controlled by
a centralized system to adjust their poses automatically and collaboratively so
as to maximize the coverage of targets in their shared visual field. In AMOT,
each camera only receives partial information from its observation, which may
mislead cameras to take locally optimal action. Besides, the global goal, i.e.,
maximum coverage of objects, is hard to be directly optimized. To address the
above issues, we propose a coordinate-aligned multi-camera collaboration system
for AMOT. In our approach, we regard each camera as an agent and address AMOT
with a multi-agent reinforcement learning solution. To represent the
observation of each agent, we first identify the targets in the camera view
with an image detector, and then align the coordinates of the targets in 3D
environment. We define the reward of each agent based on both global coverage
as well as four individual reward terms. The action policy of the agents is
derived with a value-based Q-network. To the best of our knowledge, we are the
first to study the AMOT task. To train and evaluate the efficacy of our system,
we build a virtual yet credible 3D environment, named "Soccer Court", to mimic
the real-world AMOT scenario. The experimental results show that our system
achieves a coverage of 71.88%, outperforming the baseline method by 8.9%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Perceiver. (arXiv:2202.10890v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10890">
<div class="article-summary-box-inner">
<span><p>General perception systems such as Perceivers can process arbitrary
modalities in any combination and are able to handle up to a few hundred
thousand inputs. They achieve this generality by exclusively using global
attention operations. This however hinders them from scaling up to the inputs
sizes required to process raw high-resolution images or video. In this paper,
we show that some degree of locality can be introduced back into these models,
greatly improving their efficiency while preserving their generality. To scale
them further, we introduce a self-supervised approach that enables learning
dense low-dimensional positional embeddings for very large signals. We call the
resulting model a Hierarchical Perceiver (HiP). HiP retains the ability to
process arbitrary modalities, but now at higher-resolution and without any
specialized preprocessing, improving over flat Perceivers in both efficiency
and accuracy on the ImageNet, Audioset and PASCAL VOC datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sound Adversarial Audio-Visual Navigation. (arXiv:2202.10910v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10910">
<div class="article-summary-box-inner">
<span><p>Audio-visual navigation task requires an agent to find a sound source in a
realistic, unmapped 3D environment by utilizing egocentric audio-visual
observations. Existing audio-visual navigation works assume a clean environment
that solely contains the target sound, which, however, would not be suitable in
most real-world applications due to the unexpected sound noise or intentional
interference. In this work, we design an acoustically complex environment in
which, besides the target sound, there exists a sound attacker playing a
zero-sum game with the agent. More specifically, the attacker can move and
change the volume and category of the sound to make the agent suffer from
finding the sounding object while the agent tries to dodge the attack and
navigate to the goal under the intervention. Under certain constraints to the
attacker, we can improve the robustness of the agent towards unexpected sound
attacks in audio-visual navigation. For better convergence, we develop a joint
training mechanism by employing the property of a centralized critic with
decentralized actors. Experiments on two real-world 3D scan datasets, Replica,
and Matterport3D, verify the effectiveness and the robustness of the agent
trained under our designed environment when transferred to the clean
environment or the one containing sound attackers with random policy. Project:
\url{https://yyf17.github.io/SAAVN}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Vision-Language Pre-Trained Models. (arXiv:2202.10936v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10936">
<div class="article-summary-box-inner">
<span><p>As Transformer evolved, pre-trained models have advanced at a breakneck pace
in recent years. They have dominated the mainstream techniques in natural
language processing (NLP) and computer vision (CV). How to adapt pre-training
to the field of Vision-and-Language (V-L) learning and improve the performance
on downstream tasks becomes a focus of multimodal learning. In this paper, we
review the recent progress in Vision-Language Pre-Trained Models (VL-PTMs). As
the core content, we first briefly introduce several ways to encode raw images
and texts to single-modal embeddings before pre-training. Then, we dive into
the mainstream architectures of VL-PTMs in modeling the interaction between
text and image representations. We further present widely-used pre-training
tasks, after which we introduce some common downstream tasks. We finally
conclude this paper and present some promising research directions. Our survey
aims to provide multimodal researchers a synthesis and pointer to related
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient Based Activations for Accurate Bias-Free Learning. (arXiv:2202.10943v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10943">
<div class="article-summary-box-inner">
<span><p>Bias mitigation in machine learning models is imperative, yet challenging.
While several approaches have been proposed, one view towards mitigating bias
is through adversarial learning. A discriminator is used to identify the bias
attributes such as gender, age or race in question. This discriminator is used
adversarially to ensure that it cannot distinguish the bias attributes. The
main drawback in such a model is that it directly introduces a trade-off with
accuracy as the features that the discriminator deems to be sensitive for
discrimination of bias could be correlated with classification. In this work we
solve the problem. We show that a biased discriminator can actually be used to
improve this bias-accuracy tradeoff. Specifically, this is achieved by using a
feature masking approach using the discriminator's gradients. We ensure that
the features favoured for the bias discrimination are de-emphasized and the
unbiased features are enhanced during classification. We show that this simple
approach works well to reduce bias as well as improve accuracy significantly.
We evaluate the proposed model on standard benchmarks. We improve the accuracy
of the adversarial methods while maintaining or even improving the unbiasness
and also outperform several other recent methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Subtyping brain diseases from imaging data. (arXiv:2202.10945v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10945">
<div class="article-summary-box-inner">
<span><p>The imaging community has increasingly adopted machine learning (ML) methods
to provide individualized imaging signatures related to disease diagnosis,
prognosis, and response to treatment. Clinical neuroscience and cancer imaging
have been two areas in which ML has offered particular promise. However, many
neurologic and neuropsychiatric diseases, as well as cancer, are often
heterogeneous in terms of their clinical manifestations, neuroanatomical
patterns or genetic underpinnings. Therefore, in such cases, seeking a single
disease signature might be ineffectual in delivering individualized precision
diagnostics. The current chapter focuses on ML methods, especially
semi-supervised clustering, that seek disease subtypes using imaging data. Work
from Alzheimer Disease and its prodromal stages, psychosis, depression, autism,
and brain cancer are discussed. Our goal is to provide the readers with a broad
overview in terms of methodology and clinical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Controller With the Hand Gestures Pinch and Grab for Picking Up and Placing Virtual Objects. (arXiv:2202.10964v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10964">
<div class="article-summary-box-inner">
<span><p>Grabbing virtual objects is one of the essential tasks for Augmented,
Virtual, and Mixed Reality applications. Modern applications usually use a
simple pinch gesture for grabbing and moving objects. However, picking up
objects by pinching has disadvantages. It can be an unnatural gesture to pick
up objects and prevents the implementation of other gestures which would be
performed with thumb and index. Therefore it is not the optimal choice for many
applications. In this work, different implementations for grabbing and placing
virtual objects are proposed and compared. Performance and accuracy of the
proposed techniques are measured and compared.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Classification Model Performance on Chest X-Rays through Lung Segmentation. (arXiv:2202.10971v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10971">
<div class="article-summary-box-inner">
<span><p>Chest radiography is an effective screening tool for diagnosing pulmonary
diseases. In computer-aided diagnosis, extracting the relevant region of
interest, i.e., isolating the lung region of each radiography image, can be an
essential step towards improved performance in diagnosing pulmonary disorders.
Methods: In this work, we propose a deep learning approach to enhance abnormal
chest x-ray (CXR) identification performance through segmentations. Our
approach is designed in a cascaded manner and incorporates two modules: a deep
neural network with criss-cross attention modules (XLSor) for localizing lung
region in CXR images and a CXR classification model with a backbone of a
self-supervised momentum contrast (MoCo) model pre-trained on large-scale CXR
data sets. The proposed pipeline is evaluated on Shenzhen Hospital (SH) data
set for the segmentation module, and COVIDx data set for both segmentation and
classification modules. Novel statistical analysis is conducted in addition to
regular evaluation metrics for the segmentation module. Furthermore, the
results of the optimized approach are analyzed with gradient-weighted class
activation mapping (Grad-CAM) to investigate the rationale behind the
classification decisions and to interpret its choices. Results and Conclusion:
Different data sets, methods, and scenarios for each module of the proposed
pipeline are examined for designing an optimized approach, which has achieved
an accuracy of 0.946 in distinguishing abnormal CXR images (i.e., Pneumonia and
COVID-19) from normal ones. Numerical and visual validations suggest that
applying automated segmentation as a pre-processing step for classification
improves the generalization capability and the performance of the
classification models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimation of Looming from LiDAR. (arXiv:2202.10972v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10972">
<div class="article-summary-box-inner">
<span><p>Looming, traditionally defined as the relative expansion of objects in the
observer's retina, is a fundamental visual cue for perception of threat and can
be used to accomplish collision free navigation. The measurement of the looming
cue is not only limited to vision, and can also be obtained from range sensors
like LiDAR (Light Detection and Ranging). In this article we present two
methods that process raw LiDAR data to estimate the looming cue. Using looming
values we show how to obtain threat zones for collision avoidance tasks. The
methods are general enough to be suitable for any six-degree-of-freedom motion
and can be implemented in real-time without the need for fine matching,
point-cloud registration, object classification or object segmentation.
Quantitative results using the KITTI dataset shows advantages and limitations
of the methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Winning Solution to the iFLYTEK Challenge 2021 Cultivated Land Extraction from High-Resolution Remote Sensing Image. (arXiv:2202.10974v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10974">
<div class="article-summary-box-inner">
<span><p>Extracting cultivated land accurately from high-resolution remote images is a
basic task for precision agriculture. This report introduces our solution to
the iFLYTEK challenge 2021 cultivated land extraction from high-resolution
remote sensing image. The challenge requires segmenting cultivated land objects
in very high-resolution multispectral remote sensing images. We established a
highly effective and efficient pipeline to solve this problem. We first divided
the original images into small tiles and separately performed instance
segmentation on each tile. We explored several instance segmentation algorithms
that work well on natural images and developed a set of effective methods that
are applicable to remote sensing images. Then we merged the prediction results
of all small tiles into seamless, continuous segmentation results through our
proposed overlap-tile fusion strategy. We achieved the first place among 486
teams in the challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tracking perovskite crystallization via deep learning-based feature detection on 2D X-ray scattering data. (arXiv:2202.10983v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10983">
<div class="article-summary-box-inner">
<span><p>Understanding the processes of perovskite crystallization is essential for
improving the properties of organic solar cells. In situ real-time
grazing-incidence X-ray diffraction (GIXD) is a key technique for this task,
but it produces large amounts of data, frequently exceeding the capabilities of
traditional data processing methods. We propose an automated pipeline for the
analysis of GIXD images, based on the Faster R-CNN deep learning architecture
for object detection, modified to conform to the specifics of the scattering
data. The model exhibits high accuracy in detecting diffraction features on
noisy patterns with various experimental artifacts. We demonstrate our method
on real-time tracking of organic-inorganic perovskite structure crystallization
and test it on two applications: 1. the automated phase identification and
unit-cell determination of two coexisting phases of Ruddlesden-Popper 2D
perovskites, and 2. the fast tracking of MAPbI$_3$ perovskite formation. By
design, our approach is equally suitable for other crystalline thin-film
materials.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does prior knowledge in the form of multiple low-dose PET images (at different dose levels) improve standard-dose PET prediction?. (arXiv:2202.10998v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10998">
<div class="article-summary-box-inner">
<span><p>Reducing the injected dose would result in quality degradation and loss of
information in PET imaging. To address this issue, deep learning methods have
been introduced to predict standard PET images (S-PET) from the corresponding
low-dose versions (L-PET). The existing deep learning-based denoising methods
solely rely on a single dose level of PET images to predict the S-PET images.
In this work, we proposed to exploit the prior knowledge in the form of
multiple low-dose levels of PET images (in addition to the target low-dose
level) to estimate the S-PET images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Objective Dual Simplex-Mesh Based Deformable Image Registration for 3D Medical Images -- Proof of Concept. (arXiv:2202.11001v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11001">
<div class="article-summary-box-inner">
<span><p>Reliably and physically accurately transferring information between images
through deformable image registration with large anatomical differences is an
open challenge in medical image analysis. Most existing methods have two key
shortcomings: first, they require extensive up-front parameter tuning to each
specific registration problem, and second, they have difficulty capturing large
deformations and content mismatches between images. There have however been
developments that have laid the foundation for potential solutions to both
shortcomings. Towards the first shortcoming, a multi-objective optimization
approach using the Real-Valued Gene-pool Optimal Mixing Evolutionary Algorithm
(RV-GOMEA) has been shown to be capable of producing a diverse set of
registrations for 2D images in one run of the algorithm, representing different
trade-offs between conflicting objectives in the registration problem. This
allows the user to select a registration afterwards and removes the need for
up-front tuning. Towards the second shortcoming, a dual-dynamic grid
transformation model has proven effective at capturing large differences in 2D
images. These two developments have recently been accelerated through GPU
parallelization, delivering large speed-ups. Based on this accelerated version,
it is now possible to extend the approach to 3D images. Concordantly, this work
introduces the first method for multi-objective 3D deformable image
registration, using a 3D dual-dynamic grid transformation model based on
simplex meshes while still supporting the incorporation of annotated guidance
information and multi-resolution schemes. Our proof-of-concept prototype shows
promising results on synthetic and clinical 3D registration problems, forming
the foundation for a new, insightful method that can include bio-mechanical
properties in the registration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Statistical and Spatio-temporal Hand Gesture Features for Sign Language Recognition using the Leap Motion Sensor. (arXiv:2202.11005v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11005">
<div class="article-summary-box-inner">
<span><p>In modern society, people should not be identified based on their disability,
rather, it is environments that can disable people with impairments.
Improvements to automatic Sign Language Recognition (SLR) will lead to more
enabling environments via digital technology. Many state-of-the-art approaches
to SLR focus on the classification of static hand gestures, but communication
is a temporal activity, which is reflected by many of the dynamic gestures
present. Given this, temporal information during the delivery of a gesture is
not often considered within SLR. The experiments in this work consider the
problem of SL gesture recognition regarding how dynamic gestures change during
their delivery, and this study aims to explore how single types of features as
well as mixed features affect the classification ability of a machine learning
model. 18 common gestures recorded via a Leap Motion Controller sensor provide
a complex classification problem. Two sets of features are extracted from a 0.6
second time window, statistical descriptors and spatio-temporal attributes.
Features from each set are compared by their ANOVA F-Scores and p-values,
arranged into bins grown by 10 features per step to a limit of the 250
highest-ranked features. Results show that the best statistical model selected
240 features and scored 85.96% accuracy, the best spatio-temporal model
selected 230 features and scored 80.98%, and the best mixed-feature model
selected 240 features from each set leading to a classification accuracy of
86.75%. When all three sets of results are compared (146 individual machine
learning models), the overall distribution shows that the minimum results are
increased when inputs are any number of mixed features compared to any number
of either of the two single sets of features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computing Multiple Image Reconstructions with a Single Hypernetwork. (arXiv:2202.11009v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11009">
<div class="article-summary-box-inner">
<span><p>Deep learning based techniques achieve state-of-the-art results in a wide
range of image reconstruction tasks like compressed sensing. These methods
almost always have hyperparameters, such as the weight coefficients that
balance the different terms in the optimized loss function. The typical
approach is to train the model for a hyperparameter setting determined with
some empirical or theoretical justification. Thus, at inference time, the model
can only compute reconstructions corresponding to the pre-determined
hyperparameter values. In this work, we present a hypernetwork based approach,
called HyperRecon, to train reconstruction models that are agnostic to
hyperparameter settings. At inference time, HyperRecon can efficiently produce
diverse reconstructions, which would each correspond to different
hyperparameter values. In this framework, the user is empowered to select the
most useful output(s) based on their own judgement. We demonstrate our method
in compressed sensing, super-resolution and denoising tasks, using two
large-scale and publicly-available MRI datasets. Our code is available at
https://github.com/alanqrwang/hyperrecon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constrained Visual-Inertial Localization With Application And Benchmark in Laparoscopic Surgery. (arXiv:2202.11075v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11075">
<div class="article-summary-box-inner">
<span><p>We propose a novel method to tackle the visual-inertial localization problem
for constrained camera movements. We use residuals from the different
modalities to jointly optimize a global cost function. The residuals emerge
from IMU measurements, stereoscopic feature points, and constraints on possible
solutions in SE(3). In settings where dynamic disturbances are frequent, the
residuals reduce the complexity of the problem and make localization feasible.
We verify the advantages of our method in a suitable medical use case and
produce a dataset capturing a minimally invasive surgery in the abdomen. Our
novel clinical dataset MITI is comparable to state-of-the-art evaluation
datasets, contains calibration and synchronization and is available at
https://mediatum.ub.tum.<a href="/abs/de/1621941">de/1621941</a>.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReorientBot: Learning Object Reorientation for Specific-Posed Placement. (arXiv:2202.11092v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11092">
<div class="article-summary-box-inner">
<span><p>Robots need the capability of placing objects in arbitrary, specific poses to
rearrange the world and achieve various valuable tasks. Object reorientation
plays a crucial role in this as objects may not initially be oriented such that
the robot can grasp and then immediately place them in a specific goal pose. In
this work, we present a vision-based manipulation system, ReorientBot, which
consists of 1) visual scene understanding with pose estimation and volumetric
reconstruction using an onboard RGB-D camera; 2) learned waypoint selection for
successful and efficient motion generation for reorientation; 3) traditional
motion planning to generate a collision-free trajectory from the selected
waypoints. We evaluate our method using the YCB objects in both simulation and
the real world, achieving 93% overall success, 81% improvement in success rate,
and 22% improvement in execution time compared to a heuristic approach. We
demonstrate extended multi-object rearrangement showing the general capability
of the system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GroupViT: Semantic Segmentation Emerges from Text Supervision. (arXiv:2202.11094v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11094">
<div class="article-summary-box-inner">
<span><p>Grouping and recognition are important components of visual scene
understanding, e.g., for object detection and semantic segmentation. With
end-to-end deep learning systems, grouping of image regions usually happens
implicitly via top-down supervision from pixel-level recognition labels.
Instead, in this paper, we propose to bring back the grouping mechanism into
deep networks, which allows semantic segments to emerge automatically with only
text supervision. We propose a hierarchical Grouping Vision Transformer
(GroupViT), which goes beyond the regular grid structure representation and
learns to group image regions into progressively larger arbitrary-shaped
segments. We train GroupViT jointly with a text encoder on a large-scale
image-text dataset via contrastive losses. With only text supervision and
without any pixel-level annotations, GroupViT learns to group together semantic
regions and successfully transfers to the task of semantic segmentation in a
zero-shot manner, i.e., without any further fine-tuning. It achieves a
zero-shot accuracy of 51.2% mIoU on the PASCAL VOC 2012 and 22.3% mIoU on
PASCAL Context datasets, and performs competitively to state-of-the-art
transfer-learning methods requiring greater levels of supervision. Project page
is available at https://jerryxu.net/GroupViT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CaDIS: Cataract Dataset for Image Segmentation. (arXiv:1906.11586v7 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.11586">
<div class="article-summary-box-inner">
<span><p>Video feedback provides a wealth of information about surgical procedures and
is the main sensory cue for surgeons. Scene understanding is crucial to
computer assisted interventions (CAI) and to post-operative analysis of the
surgical procedure. A fundamental building block of such capabilities is the
identification and localization of surgical instruments and anatomical
structures through semantic segmentation. Deep learning has advanced semantic
segmentation techniques in the recent years but is inherently reliant on the
availability of labelled datasets for model training. This paper introduces a
dataset for semantic segmentation of cataract surgery videos complementing the
publicly available CATARACTS challenge dataset. In addition, we benchmark the
performance of several state-of-the-art deep learning models for semantic
segmentation on the presented dataset. The dataset is publicly available at
https://cataracts-semantic-segmentation2020.grand-challenge.org/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pyramid Convolutional RNN for MRI Image Reconstruction. (arXiv:1912.00543v7 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.00543">
<div class="article-summary-box-inner">
<span><p>Fast and accurate MRI image reconstruction from undersampled data is crucial
in clinical practice. Deep learning based reconstruction methods have shown
promising advances in recent years. However, recovering fine details from
undersampled data is still challenging. In this paper, we introduce a novel
deep learning based method, Pyramid Convolutional RNN (PC-RNN), to reconstruct
images from multiple scales. Based on the formulation of MRI reconstruction as
an inverse problem, we design the PC-RNN model with three convolutional RNN
(ConvRNN) modules to iteratively learn the features in multiple scales. Each
ConvRNN module reconstructs images at different scales and the reconstructed
images are combined by a final CNN module in a pyramid fashion. The multi-scale
ConvRNN modules learn a coarse-to-fine image reconstruction. Unlike other
common reconstruction methods for parallel imaging, PC-RNN does not employ coil
sensitive maps for multi-coil data and directly model the multiple coils as
multi-channel inputs. The coil compression technique is applied to standardize
data with various coil numbers, leading to more efficient training. We evaluate
our model on the fastMRI knee and brain datasets and the results show that the
proposed model outperforms other methods and can recover more details. The
proposed method is one of the winner solutions in the 2019 fastMRI competition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SDFDiff: Differentiable Rendering of Signed Distance Fields for 3D Shape Optimization. (arXiv:1912.07109v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.07109">
<div class="article-summary-box-inner">
<span><p>We propose SDFDiff, a novel approach for image-based shape optimization using
differentiable rendering of 3D shapes represented by signed distance functions
(SDFs). Compared to other representations, SDFs have the advantage that they
can represent shapes with arbitrary topology, and that they guarantee
watertight surfaces. We apply our approach to the problem of multi-view 3D
reconstruction, where we achieve high reconstruction quality and can capture
complex topology of 3D objects. In addition, we employ a multi-resolution
strategy to obtain a robust optimization algorithm. We further demonstrate that
our SDF-based differentiable renderer can be integrated with deep learning
models, which opens up options for learning approaches on 3D objects without 3D
supervision. In particular, we apply our method to single-view 3D
reconstruction and achieve state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Defense by Latent Style Transformations. (arXiv:2006.09701v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09701">
<div class="article-summary-box-inner">
<span><p>Machine learning models have demonstrated vulnerability to adversarial
attacks, more specifically misclassification of adversarial examples.
</p>
<p>In this paper, we investigate an attack-agnostic defense against adversarial
attacks on high-resolution images by detecting suspicious inputs.
</p>
<p>The intuition behind our approach is that the essential characteristics of a
normal image are generally consistent with non-essential style transformations,
e.g., slightly changing the facial expression of human portraits.
</p>
<p>In contrast, adversarial examples are generally sensitive to such
transformations.
</p>
<p>In our approach to detect adversarial instances, we propose an
in\underline{V}ertible \underline{A}utoencoder based on the
\underline{S}tyleGAN2 generator via \underline{A}dversarial training (VASA) to
inverse images to disentangled latent codes that reveal hierarchical styles.
</p>
<p>We then build a set of edited copies with non-essential style transformations
by performing latent shifting and reconstruction, based on the correspondences
between latent codes and style transformations.
</p>
<p>The classification-based consistency of these edited copies is used to
distinguish adversarial instances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tracking Passengers and Baggage Items using Multi-camera Systems at Security Checkpoints. (arXiv:2007.07924v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.07924">
<div class="article-summary-box-inner">
<span><p>We introduce a novel tracking-by-detection framework to track multiple
objects in overhead camera videos for airport checkpoint security scenarios
where targets correspond to passengers and their baggage items. Our approach
improves object detection by employing a test-time data augmentation procedure
that provides multiple geometrically transformed images as inputs to a
convolutional neural network. We cluster the multiple detections generated by
the network using the mean-shift algorithm. The multiple hypothesis tracking
algorithm then keeps track of the temporal identifiers of the targets based on
the cluster centroids. Our method also incorporates a trajectory association
mechanism to maintain the consistency of the temporal identifiers as passengers
travel across camera views. Finally, we also introduce a simple distance-based
matching mechanism to associate passengers with their luggage. An evaluation of
detection, tracking, and association performances on videos obtained from
multiple overhead cameras in a realistic airport checkpoint environment
demonstrates the effectiveness of the proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Real-Time Predictive Pedestrian Collision Warning Service for Cooperative Intelligent Transportation Systems Using 3D Pose Estimation. (arXiv:2009.10868v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10868">
<div class="article-summary-box-inner">
<span><p>Minimizing traffic accidents between vehicles and pedestrians is one of the
primary research goals in intelligent transportation systems. To achieve the
goal, pedestrian orientation recognition and prediction of pedestrian's
crossing or not-crossing intention play a central role. Contemporary approaches
do not guarantee satisfactory performance due to limited field-of-view, lack of
generalization, and high computational complexity. To overcome these
limitations, we propose a real-time predictive pedestrian collision warning
service (P2CWS) for two tasks: pedestrian orientation recognition (100.53 FPS)
and intention prediction (35.76 FPS). Our framework obtains satisfying
generalization over multiple sites because of the proposed site-independent
features. At the center of the feature extraction lies 3D pose estimation. The
3D pose analysis enables robust and accurate recognition of pedestrian
orientations and prediction of intentions over multiple sites. The proposed
vision framework realizes 89.3% accuracy in the behavior recognition task on
the TUD dataset without any training process and 91.28% accuracy in intention
prediction on our dataset achieving new state-of-the-art performance. To
contribute to the corresponding research community, we make our source codes
public which are available at https://github.com/Uehwan/VisionForPedestrian
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Child-Computer Interaction with Mobile Devices: Recent Works, New Dataset, and Age Detection. (arXiv:2102.01405v3 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01405">
<div class="article-summary-box-inner">
<span><p>This article provides an overview of recent research in Child-Computer
Interaction with mobile devices and describe our framework ChildCI intended
for: i) overcoming the lack of large-scale publicly available databases in the
area, ii) generating a better understanding of the cognitive and neuromotor
development of children along time, contrary to most previous studies in the
literature focused on a single-session acquisition, and iii) enabling new
applications in e-Learning and e-Health through the acquisition of additional
information such as the school grades and children's disorders, among others.
Our framework includes a new mobile application, specific data acquisition
protocols, and a first release of the ChildCI dataset (ChildCIdb v1), which is
planned to be extended yearly to enable longitudinal studies.
</p>
<p>In our framework children interact with a tablet device, using both a pen
stylus and the finger, performing different tasks that require different levels
of neuromotor and cognitive skills. ChildCIdb is the first database in the
literature that comprises more than 400 children from 18 months to 8 years old,
considering therefore the first three development stages of the Piaget's
theory. In addition, and as a demonstration of the potential of the ChildCI
framework, we include experimental results for one of the many applications
enabled by ChildCIdb: children age detection based on device interaction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GANav: Efficient Terrain Segmentation for Robot Navigation in Unstructured Outdoor Environments. (arXiv:2103.04233v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04233">
<div class="article-summary-box-inner">
<span><p>We propose GANav, a novel group-wise attention mechanism to identify safe and
navigable regions in off-road terrains and unstructured environments from RGB
images. Our approach classifies terrains based on their navigability levels
using coarse-grained semantic segmentation. Our novel group-wise attention loss
enables any backbone network to explicitly focus on the different groups'
features with low spatial resolution. Our design leads to efficient inference
while maintaining a high level of accuracy compared to existing SOTA methods.
Our extensive evaluations on the RUGD and RELLIS-3D datasets shows that GANav
achieves an improvement over the SOTA mIoU by 2.25-39.05% on RUGD and
5.17-19.06% on RELLIS-3D. We interface GANav with a deep reinforcement
learning-based navigation algorithm and highlight its benefits in terms of
navigation in real-world unstructured terrains. We integrate our GANav-based
navigation algorithm with ClearPath Jackal and Husky robots, and observe an
increase of 10% in terms of success rate, 2-47% in terms of selecting the
surface with the best navigability and a decrease of 4.6-13.9% in trajectory
roughness. Further, GANav reduces the false positive rate of forbidden regions
by 37.79%. Code, videos, and a full technical report are available at
https://gamma.umd.edu/offroad/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Illumination based Depth Sensing using Deep Superpixel and Soft Sampling Approximation. (arXiv:2103.12297v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12297">
<div class="article-summary-box-inner">
<span><p>Dense depth map capture is challenging in existing active sparse illumination
based depth acquisition techniques, such as LiDAR. Various techniques have been
proposed to estimate a dense depth map based on fusion of the sparse depth map
measurement with the RGB image. Recent advances in hardware enable adaptive
depth measurements resulting in further improvement of the dense depth map
estimation. In this paper, we study the topic of estimating dense depth from
depth sampling. The adaptive sparse depth sampling network is jointly trained
with a fusion network of an RGB image and sparse depth, to generate optimal
adaptive sampling masks. We show that such adaptive sampling masks can
generalize well to many RGB and sparse depth fusion algorithms under a variety
of sampling rates (as low as $0.0625\%$). The proposed adaptive sampling method
is fully differentiable and flexible to be trained end-to-end with upstream
perception algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Facial Expression Recognition with Visual Transformers and Attentional Selective Fusion. (arXiv:2103.16854v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16854">
<div class="article-summary-box-inner">
<span><p>Facial Expression Recognition (FER) in the wild is extremely challenging due
to occlusions, variant head poses, face deformation and motion blur under
unconstrained conditions. Although substantial progresses have been made in
automatic FER in the past few decades, previous studies were mainly designed
for lab-controlled FER. Real-world occlusions, variant head poses and other
issues definitely increase the difficulty of FER on account of these
information-deficient regions and complex backgrounds. Different from previous
pure CNNs based methods, we argue that it is feasible and practical to
translate facial images into sequences of visual words and perform expression
recognition from a global perspective. Therefore, we propose the Visual
Transformers with Feature Fusion (VTFF) to tackle FER in the wild by two main
steps. First, we propose the attentional selective fusion (ASF) for leveraging
two kinds of feature maps generated by two-branch CNNs. The ASF captures
discriminative information by fusing multiple features with the global-local
attention. The fused feature maps are then flattened and projected into
sequences of visual words. Second, inspired by the success of Transformers in
natural language processing, we propose to model relationships between these
visual words with the global self-attention. The proposed method is evaluated
on three public in-the-wild facial expression datasets (RAF-DB, FERPlus and
AffectNet). Under the same settings, extensive experiments demonstrate that our
method shows superior performance over other methods, setting new state of the
art on RAF-DB with 88.14%, FERPlus with 88.81% and AffectNet with 61.85%. The
cross-dataset evaluation on CK+ shows the promising generalization capability
of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Fine-grained Visual Representations by Combining Contrastive Learning with Image Reconstruction and Attention-weighted Pooling. (arXiv:2104.04323v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04323">
<div class="article-summary-box-inner">
<span><p>This paper presents Contrastive Reconstruction, ConRec - a self-supervised
learning algorithm that obtains image representations by jointly optimizing a
contrastive and a self-reconstruction loss. We showcase that state-of-the-art
contrastive learning methods (e.g. SimCLR) have shortcomings to capture
fine-grained visual features in their representations. ConRec extends the
SimCLR framework by adding (1) a self-reconstruction task and (2) an attention
mechanism within the contrastive learning task. This is accomplished by
applying a simple encoder-decoder architecture with two heads. We show that
both extensions contribute towards an improved vector representation for images
with fine-grained visual features. Combining those concepts, ConRec outperforms
SimCLR and SimCLR with Attention-Pooling on fine-grained classification
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scale-invariant scale-channel networks: Deep networks that generalise to previously unseen scales. (arXiv:2106.06418v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06418">
<div class="article-summary-box-inner">
<span><p>The ability to handle large scale variations is crucial for many real world
visual tasks. A straightforward approach for handling scale in a deep network
is to process an image at several scales simultaneously in a set of scale
channels. Scale invariance can then, in principle, be achieved by using weight
sharing between the scale channels together with max or average pooling over
the outputs from the scale channels. The ability of such scale channel networks
to generalise to scales not present in the training set over significant scale
ranges has, however, not previously been explored.
</p>
<p>In this paper, we present a systematic study of this methodology by
implementing different types of scale channel networks and evaluating their
ability to generalise to previously unseen scales. We develop a formalism for
analysing the covariance and invariance properties of scale channel networks,
and explore how different design choices, unique to scaling transformations,
affect the overall performance of scale channel networks. We first show that
two previously proposed scale channel network designs do not generalise well to
scales not present in the training set. We explain theoretically and
demonstrate experimentally why generalisation fails in these cases.
</p>
<p>We then propose a new type of foveated scale channel architecture}, where the
scale channels process increasingly larger parts of the image with decreasing
resolution. This new type of scale channel network is shown to generalise
extremely well, provided sufficient image resolution and the absence of
boundary effects. Our proposed FovMax and FovAvg networks perform almost
identically over a scale range of 8, also when training on single scale
training data, and do also give improved performance when learning from
datasets with large scale variations in the small sample regime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards to Robust and Generalized Medical Image Segmentation Framework. (arXiv:2108.03823v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03823">
<div class="article-summary-box-inner">
<span><p>Deep learning-based computer-aided diagnosis is gradually deployed to review
and analyze medical images. However, this paradigm is restricted in real-world
clinical applications due to the poor robustness and generalization. The issue
is more sinister with a lack of training data. In this paper, we address the
challenge from the transfer learning point of view. Different from the common
setting that transferring knowledge from the natural image domain to the
medical image domain, we find the knowledge from the same domain further boosts
the model robustness and generalization. Therefore, we propose a novel
two-stage framework for robust generalized medical image segmentation. Firstly,
an unsupervised tile-wise autoencoder pretraining architecture is proposed to
learn local and global knowledge. Secondly, the downstream segmentation model
coupled with an auxiliary reconstruction network is designed. The
reconstruction branch encourages the model to capture more general semantic
features. Experiments of lung segmentation on multi chest X-ray datasets are
conducted. Comprehensive results demonstrate the superior robustness of the
proposed framework to corruption and high generalization performance on unseen
datasets, especially under the scenario of the limited training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SVC-onGoing: Signature Verification Competition. (arXiv:2108.06090v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06090">
<div class="article-summary-box-inner">
<span><p>This article presents SVC-onGoing, an on-going competition for on-line
signature verification where researchers can easily benchmark their systems
against the state of the art in an open common platform using large-scale
public databases, such as DeepSignDB and SVC2021_EvalDB, and standard
experimental protocols. SVC-onGoing is based on the ICDAR 2021 Competition on
On-Line Signature Verification (SVC 2021), which has been extended to allow
participants anytime. The goal of SVC-onGoing is to evaluate the limits of
on-line signature verification systems on popular scenarios (office/mobile) and
writing inputs (stylus/finger) through large-scale public databases. Three
different tasks are considered in the competition, simulating realistic
scenarios as both random and skilled forgeries are simultaneously considered on
each task. The results obtained in SVC-onGoing prove the high potential of deep
learning methods in comparison with traditional methods. In particular, the
best signature verification system has obtained Equal Error Rate (EER) values
of 3.33% (Task 1), 7.41% (Task 2), and 6.04% (Task 3). Future studies in the
field should be oriented to improve the performance of signature verification
systems on the challenging mobile scenarios of SVC-onGoing in which several
mobile devices and the finger are used during the signature acquisition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LOTR: Face Landmark Localization Using Localization Transformer. (arXiv:2109.10057v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10057">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel Transformer-based facial landmark localization
network named Localization Transformer (LOTR). The proposed framework is a
direct coordinate regression approach leveraging a Transformer network to
better utilize the spatial information in the feature map. An LOTR model
consists of three main modules: 1) a visual backbone that converts an input
image into a feature map, 2) a Transformer module that improves the feature
representation from the visual backbone, and 3) a landmark prediction head that
directly predicts the landmark coordinates from the Transformer's
representation. Given cropped-and-aligned face images, the proposed LOTR can be
trained end-to-end without requiring any post-processing steps. This paper also
introduces the smooth-Wing loss function, which addresses the gradient
discontinuity of the Wing loss, leading to better convergence than standard
loss functions such as L1, L2, and Wing loss. Experimental results on the JD
landmark dataset provided by the First Grand Challenge of 106-Point Facial
Landmark Localization indicate the superiority of LOTR over the existing
methods on the leaderboard and two recent heatmap-based approaches. On the WFLW
dataset, the proposed LOTR framework demonstrates promising results compared
with several state-of-the-art methods. Additionally, we report the improvement
in state-of-the-art face recognition performance when using our proposed LOTRs
for face alignment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Image Fusion Using Deep Image Priors. (arXiv:2110.09490v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09490">
<div class="article-summary-box-inner">
<span><p>A significant number of researchers have applied deep learning methods to
image fusion. However, most works require a large amount of training data or
depend on pre-trained models or frameworks to capture features from source
images. This is inevitably hampered by a shortage of training data or a
mismatch between the framework and the actual problem. Deep Image Prior (DIP)
has been introduced to exploit convolutional neural networks' ability to
synthesize the 'prior' in the input image. However, the original design of DIP
is hard to be generalized to multi-image processing problems, particularly for
image fusion. Therefore, we propose a new image fusion technique that extends
DIP to fusion tasks formulated as inverse problems. Additionally, we apply a
multi-channel approach to enhance DIP's effect further. The evaluation is
conducted with several commonly used image fusion assessment metrics. The
results are compared with state-of-the-art image fusion methods. Our method
outperforms these techniques for a range of metrics. In particular, it is shown
to provide the best objective results for most metrics when applied to medical
images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RGB Camera-based Physiological Sensing: Challenges and Future Directions. (arXiv:2110.13362v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13362">
<div class="article-summary-box-inner">
<span><p>Numerous real-world applications have been driven by the recent algorithmic
advancement of artificial intelligence (AI). Healthcare is no exception and AI
technologies have great potential to revolutionize the industry. Non-contact
camera-based physiological sensing, including remote photoplethysmography
(rPPG), is a set of imaging methods that leverages ordinary RGB cameras (e.g.,
webcam or smartphone camera) to capture subtle changes in electromagnetic
radiation (e.g., light) reflected by the body caused by physiological
processes. RGB camera-based systems not only have the ability to measure the
signals without contact with the body but also have the opportunity to capture
multimodal information (e.g., facial expressions, activities and other context)
from the same sensor. However, developing accessible, equitable and useful
camera-based physiological sensing systems comes with various challenges. In
this article, we identify four research challenges for the field of RGB
camera-based physiological sensing and broader AI driven healthcare communities
and suggest future directions to tackle these. We believe solving these
challenges will help deliver accurate, equitable and generalizable AI systems
for healthcare that are practical in real-world and clinical contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Look at Spike-Timing-Dependent Plasticity Networks for Spatio-Temporal Feature Learning. (arXiv:2111.00791v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00791">
<div class="article-summary-box-inner">
<span><p>We present new theoretical foundations for unsupervised
Spike-Timing-Dependent Plasticity (STDP) learning in spiking neural networks
(SNNs). In contrast to empirical parameter search used in most previous works,
we provide novel theoretical grounds for SNN and STDP parameter tuning which
considerably reduces design time. Using our generic framework, we propose a
class of global, action-based and convolutional SNN-STDP architectures for
learning spatio-temporal features from event-based cameras. We assess our
methods on the N-MNIST, the CIFAR10-DVS and the IBM DVS128 Gesture datasets,
all acquired with a real-world event camera. Using our framework, we report
significant improvements in classification accuracy compared to both
conventional state-of-the-art event-based feature descriptors (+8.2% on
CIFAR10-DVS), and compared to state-of-the-art STDP-based systems (+9.3% on
N-MNIST, +7.74% on IBM DVS128 Gesture). Our work contributes to both
ultra-low-power learning in neuromorphic edge devices, and towards a
biologically-plausible, optimization-based theory of cortical vision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structure-Preserving Graph Kernel for Brain Network Classification. (arXiv:2111.10803v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.10803">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel graph-based kernel learning approach for
connectome analysis. Specifically, we demonstrate how to leverage the naturally
available structure within the graph representation to encode prior knowledge
in the kernel. We first proposed a matrix factorization to directly extract
structural features from natural symmetric graph representations of connectome
data. We then used them to derive a structure-persevering graph kernel to be
fed into the support vector machine. The proposed approach has the advantage of
being clinically interpretable. Quantitative evaluations on challenging HIV
disease classification (DTI- and fMRI-derived connectome data) and emotion
recognition (EEG-derived connectome data) tasks demonstrate the superior
performance of our proposed methods against the state-of-the-art. Results
showed that relevant EEG-connectome information is primarily encoded in the
alpha band during the emotion regulation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Texture Recognition using PDV Hashing and Dictionary Learning on Multi-scale Volume Local Binary Pattern. (arXiv:2111.12315v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12315">
<div class="article-summary-box-inner">
<span><p>Spatial-temporal local binary pattern (STLBP) has been widely used in dynamic
texture recognition. STLBP often encounters the high-dimension problem as its
dimension increases exponentially, so that STLBP could only utilize a small
neighborhood. To tackle this problem, we propose a method for dynamic texture
recognition using PDV hashing and dictionary learning on multi-scale volume
local binary pattern (PHD-MVLBP). Instead of forming very high-dimensional LBP
histogram features, it first uses hash functions to map the pixel difference
vectors (PDVs) to binary vectors, then forms a dictionary using the derived
binary vector, and encodes them using the derived dictionary. In such a way,
the PDVs are mapped to feature vectors of the size of dictionary, instead of
LBP histograms of very high dimension. Such an encoding scheme could extract
the discriminant information from videos in a much larger neighborhood
effectively. The experimental results on two widely-used dynamic textures
datasets, DynTex++ and UCLA, show the superiority performance of the proposed
approach over the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Track Boosting and Synthetic Data Aided Drone Detection. (arXiv:2111.12389v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12389">
<div class="article-summary-box-inner">
<span><p>This is the paper for the first place winning solution of the Drone vs. Bird
Challenge, organized by AVSS 2021. As the usage of drones increases with
lowered costs and improved drone technology, drone detection emerges as a vital
object detection task. However, detecting distant drones under unfavorable
conditions, namely weak contrast, long-range, low visibility, requires
effective algorithms. Our method approaches the drone detection problem by
fine-tuning a YOLOv5 model with real and synthetically generated data using a
Kalman-based object tracker to boost detection confidence. Our results indicate
that augmenting the real data with an optimal subset of synthetic data can
increase the performance. Moreover, temporal information gathered by object
tracking methods can increase performance further.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">n-CPS: Generalising Cross Pseudo Supervision to n Networks for Semi-Supervised Semantic Segmentation. (arXiv:2112.07528v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07528">
<div class="article-summary-box-inner">
<span><p>We present n-CPS - a generalisation of the recent state-of-the-art cross
pseudo supervision (CPS) approach for the task of semi-supervised semantic
segmentation. In n-CPS, there are n simultaneously trained subnetworks that
learn from each other through one-hot encoding perturbation and consistency
regularisation. We also show that ensembling techniques applied to subnetworks
outputs can significantly improve the performance. To the best of our
knowledge, n-CPS paired with CutMix outperforms CPS and sets the new
state-of-the-art for Pascal VOC 2012 with (1/16, 1/8, 1/4, and 1/2 supervised
regimes) and Cityscapes (1/16 supervised).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nearest neighbor search with compact codes: A decoder perspective. (arXiv:2112.09568v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.09568">
<div class="article-summary-box-inner">
<span><p>Modern approaches for fast retrieval of similar vectors on billion-scaled
datasets rely on compressed-domain approaches such as binary sketches or
product quantization. These methods minimize a certain loss, typically the mean
squared error or other objective functions tailored to the retrieval problem.
In this paper, we re-interpret popular methods such as binary hashing or
product quantizers as auto-encoders, and point out that they implicitly make
suboptimal assumptions on the form of the decoder. We design
backward-compatible decoders that improve the reconstruction of the vectors
from the same codes, which translates to a better performance in nearest
neighbor search. Our method significantly improves over binary hashing methods
or product quantization on popular benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to scale hyperparameters for quickshift image segmentation. (arXiv:2201.09286v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09286">
<div class="article-summary-box-inner">
<span><p>Quickshift is a popular algorithm for image segmentation, used as a
preprocessing step in many applications. Unfortunately, it is quite challenging
to understand the hyperparameters' influence on the number and shape of
superpixels produced by the method. In this paper, we study theoretically a
slightly modified version of the quickshift algorithm, with a particular
emphasis on homogeneous image patches with i.i.d. pixel noise and sharp
boundaries between such patches. Leveraging this analysis, we derive a simple
heuristic to scale quickshift hyperparameters with respect to the image size,
which we check empirically.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal unsupervised brain image registration using edge maps. (arXiv:2202.04647v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04647">
<div class="article-summary-box-inner">
<span><p>Diffeomorphic deformable multi-modal image registration is a challenging task
which aims to bring images acquired by different modalities to the same
coordinate space and at the same time to preserve the topology and the
invertibility of the transformation. Recent research has focused on leveraging
deep learning approaches for this task as these have been shown to achieve
competitive registration accuracy while being computationally more efficient
than traditional iterative registration methods. In this work, we propose a
simple yet effective unsupervised deep learning-based {\em multi-modal} image
registration approach that benefits from auxiliary information coming from the
gradient magnitude of the image, i.e. the image edges, during the training. The
intuition behind this is that image locations with a strong gradient are
assumed to denote a transition of tissues, which are locations of high
information value able to act as a geometry constraint. The task is similar to
using segmentation maps to drive the training, but the edge maps are easier and
faster to acquire and do not require annotations. We evaluate our approach in
the context of registering multi-modal (T1w to T2w) magnetic resonance (MR)
brain images of different subjects using three different loss functions that
are said to assist multi-modal registration, showing that in all cases the
auxiliary information leads to better results without compromising the runtime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision. (arXiv:2202.08360v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08360">
<div class="article-summary-box-inner">
<span><p>Discriminative self-supervised learning allows training models on any random
group of internet images, and possibly recover salient information that helps
differentiate between the images. Applied to ImageNet, this leads to object
centric features that perform on par with supervised features on most
object-centric downstream tasks. In this work, we question if using this
ability, we can learn any salient and more representative information present
in diverse unbounded set of images from across the globe. To do so, we train
models on billions of random images without any data pre-processing or prior
assumptions about what we want the model to learn. We scale our model size to
dense 10 billion parameters to avoid underfitting on a large data size. We
extensively study and validate our model performance on over 50 benchmarks
including fairness, robustness to distribution shift, geographical diversity,
fine grained recognition, image copy detection and many image classification
datasets. The resulting model, not only captures well semantic information, it
also captures information about artistic style and learns salient information
such as geolocations and multilingual word embeddings based on visual content
only. More importantly, we discover that such model is more robust, more fair,
less harmful and less biased than supervised models or models trained on object
centric datasets such as ImageNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fourier PlenOctrees for Dynamic Radiance Field Rendering in Real-time. (arXiv:2202.08614v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08614">
<div class="article-summary-box-inner">
<span><p>Implicit neural representations such as Neural Radiance Field (NeRF) have
focused mainly on modeling static objects captured under multi-view settings
where real-time rendering can be achieved with smart data structures, e.g.,
PlenOctree. In this paper, we present a novel Fourier PlenOctree (FPO)
technique to tackle efficient neural modeling and real-time rendering of
dynamic scenes captured under the free-view video (FVV) setting. The key idea
in our FPO is a novel combination of generalized NeRF, PlenOctree
representation, volumetric fusion and Fourier transform. To accelerate FPO
construction, we present a novel coarse-to-fine fusion scheme that leverages
the generalizable NeRF technique to generate the tree via spatial blending. To
tackle dynamic scenes, we tailor the implicit network to model the Fourier
coefficients of timevarying density and color attributes. Finally, we construct
the FPO and train the Fourier coefficients directly on the leaves of a union
PlenOctree structure of the dynamic sequence. We show that the resulting FPO
enables compact memory overload to handle dynamic objects and supports
efficient fine-tuning. Extensive experiments show that the proposed method is
3000 times faster than the original NeRF and achieves over an order of
magnitude acceleration over SOTA while preserving high visual quality for the
free-viewpoint rendering of unseen dynamic scenes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OmniSyn: Synthesizing 360 Videos with Wide-baseline Panoramas. (arXiv:2202.08752v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08752">
<div class="article-summary-box-inner">
<span><p>Immersive maps such as Google Street View and Bing Streetside provide
true-to-life views with a massive collection of panoramas. However, these
panoramas are only available at sparse intervals along the path they are taken,
resulting in visual discontinuities during navigation. Prior art in view
synthesis is usually built upon a set of perspective images, a pair of
stereoscopic images, or a monocular image, but barely examines wide-baseline
panoramas, which are widely adopted in commercial platforms to optimize
bandwidth and storage usage. In this paper, we leverage the unique
characteristics of wide-baseline panoramas and present OmniSyn, a novel
pipeline for 360{\deg} view synthesis between wide-baseline panoramas. OmniSyn
predicts omnidirectional depth maps using a spherical cost volume and a
monocular skip connection, renders meshes in 360{\deg} images, and synthesizes
intermediate views with a fusion network. We demonstrate the effectiveness of
OmniSyn via comprehensive experimental results including comparison with the
state-of-the-art methods on CARLA and Matterport datasets, ablation studies,
and generalization studies on street views. We envision our work may inspire
future research for this unheeded real-world task and eventually produce a
smoother experience for navigating immersive maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Snowflake Point Deconvolution for Point Cloud Completion and Generation with Skip-Transformer. (arXiv:2202.09367v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09367">
<div class="article-summary-box-inner">
<span><p>Most existing point cloud completion methods suffered from discrete nature of
point clouds and unstructured prediction of points in local regions, which
makes it hard to reveal fine local geometric details. To resolve this issue, we
propose SnowflakeNet with Snowflake Point Deconvolution (SPD) to generate the
complete point clouds. SPD models the generation of complete point clouds as
the snowflake-like growth of points, where the child points are progressively
generated by splitting their parent points after each SPD. Our insight of
revealing detailed geometry is to introduce skip-transformer in SPD to learn
point splitting patterns which can fit local regions the best. Skip-transformer
leverages attention mechanism to summarize the splitting patterns used in
previous SPD layer to produce the splitting in current SPD layer. The locally
compact and structured point clouds generated by SPD precisely reveal the
structure characteristic of 3D shape in local patches, which enables us to
predict highly detailed geometries. Moreover, since SPD is a general operation,
which is not limited to completion, we further explore the applications of SPD
on other generative tasks, including point cloud auto-encoding, generation,
single image reconstruction and upsampling. Our experimental results outperform
the state-of-the-art methods under widely used benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SAGE: SLAM with Appearance and Geometry Prior for Endoscopy. (arXiv:2202.09487v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09487">
<div class="article-summary-box-inner">
<span><p>In endoscopy, many applications (e.g., surgical navigation) would benefit
from a real-time method that can simultaneously track the endoscope and
reconstruct the dense 3D geometry of the observed anatomy from a monocular
endoscopic video. To this end, we develop a Simultaneous Localization and
Mapping system by combining the learning-based appearance and optimizable
geometry priors and factor graph optimization. The appearance and geometry
priors are explicitly learned in an end-to-end differentiable training pipeline
to master the task of pair-wise image alignment, one of the core components of
the SLAM system. In our experiments, the proposed SLAM system is shown to
robustly handle the challenges of texture scarceness and illumination variation
that are commonly seen in endoscopy. The system generalizes well to unseen
endoscopes and subjects and performs favorably compared with a state-of-the-art
feature-based SLAM system. The code repository is available at
https://github.com/lppllppl920/SAGE-SLAM.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PMP-Net++: Point Cloud Completion by Transformer-Enhanced Multi-step Point Moving Paths. (arXiv:2202.09507v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09507">
<div class="article-summary-box-inner">
<span><p>Point cloud completion concerns to predict missing part for incomplete 3D
shapes. A common strategy is to generate complete shape according to incomplete
input. However, unordered nature of point clouds will degrade generation of
high-quality 3D shapes, as detailed topology and structure of unordered points
are hard to be captured during the generative process using an extracted latent
code. We address this problem by formulating completion as point cloud
deformation process. Specifically, we design a novel neural network, named
PMP-Net++, to mimic behavior of an earth mover. It moves each point of
incomplete input to obtain a complete point cloud, where total distance of
point moving paths (PMPs) should be the shortest. Therefore, PMP-Net++ predicts
unique PMP for each point according to constraint of point moving distances.
The network learns a strict and unique correspondence on point-level, and thus
improves quality of predicted complete shape. Moreover, since moving points
heavily relies on per-point features learned by network, we further introduce a
transformer-enhanced representation learning network, which significantly
improves completion performance of PMP-Net++. We conduct comprehensive
experiments in shape completion, and further explore application on point cloud
up-sampling, which demonstrate non-trivial improvement of PMP-Net++ over
state-of-the-art point cloud completion/up-sampling methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparsity Winning Twice: Better Robust Generalization from More Efficient Training. (arXiv:2202.09844v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09844">
<div class="article-summary-box-inner">
<span><p>Recent studies demonstrate that deep networks, even robustified by the
state-of-the-art adversarial training (AT), still suffer from large robust
generalization gaps, in addition to the much more expensive training costs than
standard training. In this paper, we investigate this intriguing problem from a
new perspective, i.e., injecting appropriate forms of sparsity during
adversarial training. We introduce two alternatives for sparse adversarial
training: (i) static sparsity, by leveraging recent results from the lottery
ticket hypothesis to identify critical sparse subnetworks arising from the
early training; (ii) dynamic sparsity, by allowing the sparse subnetwork to
adaptively adjust its connectivity pattern (while sticking to the same sparsity
ratio) throughout training. We find both static and dynamic sparse methods to
yield win-win: substantially shrinking the robust generalization gap and
alleviating the robust overfitting, meanwhile significantly saving training and
inference FLOPs. Extensive experiments validate our proposals with multiple
network architectures on diverse datasets, including CIFAR-10/100 and
Tiny-ImageNet. For example, our methods reduce robust generalization gap and
overfitting by 34.44% and 4.02%, with comparable robust/standard accuracy
boosts and 87.83%/87.82% training/inference FLOPs savings on CIFAR-100 with
ResNet-18. Besides, our approaches can be organically combined with existing
regularizers, establishing new state-of-the-art results in AT. Codes are
available in https://github.com/VITA-Group/Sparsity-Win-Robust-Generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't Touch What Matters: Task-Aware Lipschitz Data Augmentation for Visual Reinforcement Learning. (arXiv:2202.09982v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09982">
<div class="article-summary-box-inner">
<span><p>One of the key challenges in visual Reinforcement Learning (RL) is to learn
policies that can generalize to unseen environments. Recently, data
augmentation techniques aiming at enhancing data diversity have demonstrated
proven performance in improving the generalization ability of learned policies.
However, due to the sensitivity of RL training, naively applying data
augmentation, which transforms each pixel in a task-agnostic manner, may suffer
from instability and damage the sample efficiency, thus further exacerbating
the generalization performance. At the heart of this phenomenon is the diverged
action distribution and high-variance value estimation in the face of augmented
images. To alleviate this issue, we propose Task-aware Lipschitz Data
Augmentation (TLDA) for visual RL, which explicitly identifies the
task-correlated pixels with large Lipschitz constants, and only augments the
task-irrelevant pixels. To verify the effectiveness of TLDA, we conduct
extensive experiments on DeepMind Control suite, CARLA and DeepMind
Manipulation tasks, showing that TLDA improves both sample efficiency in
training time and generalization in test time. It outperforms previous
state-of-the-art methods across the 3 different visual control benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Synthetic CT Skull Generation for Transcranial MR Imaging-Guided Focused Ultrasound Interventions with Conditional Adversarial Networks. (arXiv:2202.10136v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10136">
<div class="article-summary-box-inner">
<span><p>Transcranial MRI-guided focused ultrasound (TcMRgFUS) is a therapeutic
ultrasound method that focuses sound through the skull to a small region
noninvasively under MRI guidance. It is clinically approved to thermally ablate
regions of the thalamus and is being explored for other therapies, such as
blood brain barrier opening and neuromodulation. To accurately target
ultrasound through the skull, the transmitted waves must constructively
interfere at the target region. However, heterogeneity of the sound speed,
density, and ultrasound attenuation in different individuals' skulls requires
patient-specific estimates of these parameters for optimal treatment planning.
CT imaging is currently the gold standard for estimating acoustic properties of
an individual skull during clinical procedures, but CT imaging exposes patients
to radiation and increases the overall number of imaging procedures required
for therapy. A method to estimate acoustic parameters in the skull without the
need for CT would be desirable. Here, we synthesized CT images from routinely
acquired T1-weighted MRI by using a 3D patch-based conditional generative
adversarial network and evaluated the performance of synthesized CT images for
treatment planning with transcranial focused ultrasound. We compared the
performance of synthetic CT to real CT images using Kranion and k-Wave acoustic
simulation. Our work demonstrates the feasibility of replacing real CT with the
MR-synthesized CT for TcMRgFUS planning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pseudo Numerical Methods for Diffusion Models on Manifolds. (arXiv:2202.09778v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09778">
<div class="article-summary-box-inner">
<span><p>Denoising Diffusion Probabilistic Models (DDPMs) can generate high-quality
samples such as image and audio samples. However, DDPMs require hundreds to
thousands of iterations to produce final samples. Several prior works have
successfully accelerated DDPMs through adjusting the variance schedule (e.g.,
Improved Denoising Diffusion Probabilistic Models) or the denoising equation
(e.g., Denoising Diffusion Implicit Models (DDIMs)). However, these
acceleration methods cannot maintain the quality of samples and even introduce
new noise at a high speedup rate, which limit their practicability. To
accelerate the inference process while keeping the sample quality, we provide a
fresh perspective that DDPMs should be treated as solving differential
equations on manifolds. Under such a perspective, we propose pseudo numerical
methods for diffusion models (PNDMs). Specifically, we figure out how to solve
differential equations on manifolds and show that DDIMs are simple cases of
pseudo numerical methods. We change several classical numerical methods to
corresponding pseudo numerical methods and find that the pseudo linear
multi-step method is the best in most situations. According to our experiments,
by directly using pre-trained models on Cifar10, CelebA and LSUN, PNDMs can
generate higher quality synthetic images with only 50 steps compared with
1000-step DDIMs (20x speedup), significantly outperform DDIMs with 250 steps
(by around 0.4 in FID) and have good generalization on different variance
schedules. Our implementation is available at
https://github.com/luping-liu/PNDM.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-02-23 23:08:03.894374373 UTC">2022-02-23 23:08:03 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>