<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-11T01:30:00Z">10-11</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Sentence Classification: Detecting Sustainability Initiatives in Company Reports. (arXiv:2110.03727v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03727">
<div class="article-summary-box-inner">
<span><p>We introduce the novel task of detecting sustainability initiatives in
company reports. Given a full report, the aim is to automatically identify
mentions of practical activities that a company has performed in order to
tackle specific societal issues. As a single initiative can often be described
over multiples sentences, new methods for identifying continuous sentence spans
needs to be developed. We release a new dataset of company reports in which the
text has been manually annotated with sustainability initiatives. We also
evaluate different models for initiative detection, introducing a novel
aggregation and evaluation methodology. Our proposed architecture uses
sequences of five consecutive sentences to account for contextual information
when making classification decisions at the individual sentence level.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UoB at SemEval-2021 Task 5: Extending Pre-Trained Language Models to Include Task and Domain-Specific Information for Toxic Span Prediction. (arXiv:2110.03730v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03730">
<div class="article-summary-box-inner">
<span><p>Toxicity is pervasive in social media and poses a major threat to the health
of online communities. The recent introduction of pre-trained language models,
which have achieved state-of-the-art results in many NLP tasks, has transformed
the way in which we approach natural language processing. However, the inherent
nature of pre-training means that they are unlikely to capture task-specific
statistical information or learn domain-specific knowledge. Additionally, most
implementations of these models typically do not employ conditional random
fields, a method for simultaneous token classification. We show that these
modifications can improve model performance on the Toxic Spans Detection task
at SemEval-2021 to achieve a score within 4 percentage points of the top
performing team.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Distillation: Task-level Mixture-of-Experts for Efficient Inference. (arXiv:2110.03742v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03742">
<div class="article-summary-box-inner">
<span><p>Sparse Mixture-of-Experts (MoE) has been a successful approach for scaling
multilingual translation models to billions of parameters without a
proportional increase in training computation. However, MoE models are
prohibitively large and practitioners often resort to methods such as
distillation for serving. In this work, we investigate routing strategies at
different granularity (token, sentence, task) in MoE models to bypass
distillation. Experiments on WMT and a web-scale dataset suggest that
task-level routing (task-MoE) enables us to extract smaller, ready-to-deploy
sub-networks from large sparse models. On WMT, our task-MoE with 32 experts
(533M parameters) outperforms the best performing token-level MoE model
(token-MoE) by +1.0 BLEU on average across 30 language pairs. The peak
inference throughput is also improved by a factor of 1.9x when we route by
tasks instead of tokens. While distilling a token-MoE to a smaller dense model
preserves only 32% of the BLEU gains, our sub-network task-MoE, by design,
preserves all the gains with the same inference cost as the distilled student
model. Finally, when scaling up to 200 language pairs, our 128-expert task-MoE
(13B parameters) performs competitively with a token-level counterpart, while
improving the peak inference throughput by a factor of 2.6x.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sonorant spectra and coarticulation distinguish speakers with different dialects. (arXiv:2110.03756v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03756">
<div class="article-summary-box-inner">
<span><p>The aim of this study is to determine the effect of language varieties on the
spectral distribution of stressed and unstressed sonorants (nasals /m, n/,
lateral approximants /l/, and rhotics /r/) and on their coarticulatory effects
on adjacent sounds. To quantify the shape of the spectral distribution, we
calculated the spectral moments from the sonorant spectra of nasals /m, n/,
lateral approximants /l/, and rhotics /r/ produced by Athenian Greek and
Cypriot Greek speakers. To estimate the co-articulatory effects of sonorants on
the adjacent vowels' F1 - F4 formant frequencies, we developed polynomial
models of the adjacent vowel's formant contours. We found significant effects
of language variety (sociolinguistic information) on the spectral moments of
each sonorant /m/, /n/, /l/, /r/ (except between /m/ and /n/) and on the
formant contours of the adjacent vowel. All sonorants (including /m/ and /n/)
had distinct effects on adjacent vowel's formant contours, especially for F3
and F4. The study highlights that the combination of spectral moments and
coarticulatory effects of sonorants determines linguistic (stress and phonemic
category) and sociolinguistic (language variety) characteristics of sonorants.
It also provides the first comparative acoustic analysis of Athenian Greek and
Cypriot Greek sonorants.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Input Length Matters: An Empirical Study Of RNN-T And MWER Training For Long-form Telephony Speech Recognition. (arXiv:2110.03841v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03841">
<div class="article-summary-box-inner">
<span><p>End-to-end models have achieved state-of-the-art results on several automatic
speech recognition tasks. However, they perform poorly when evaluated on
long-form data, e.g., minutes long conversational telephony audio. One reason
the model fails on long-form speech is that it has only seen short utterances
during training. This paper presents an empirical study on the effect of
training utterance length on the word error rate (WER) for RNN-transducer
(RNN-T) model. We compare two widely used training objectives, log loss (or
RNN-T loss) and minimum word error rate (MWER) loss. We conduct experiments on
telephony datasets in four languages. Our experiments show that for both
losses, the WER on long-form speech reduces substantially as the training
utterance length increases. The average relative WER gain is 15.7% for log loss
and 8.8% for MWER loss. When training on short utterances, MWER loss leads to a
lower WER than the log loss. Such difference between the two losses diminishes
when the input length increases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Translation Verbosity Control for Automatic Dubbing. (arXiv:2110.03847v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03847">
<div class="article-summary-box-inner">
<span><p>Automatic dubbing aims at seamlessly replacing the speech in a video document
with synthetic speech in a different language. The task implies many
challenges, one of which is generating translations that not only convey the
original content, but also match the duration of the corresponding utterances.
In this paper, we focus on the problem of controlling the verbosity of machine
translation output, so that subsequent steps of our automatic dubbing pipeline
can generate dubs of better quality. We propose new methods to control the
verbosity of MT output and compare them against the state of the art with both
intrinsic and extrinsic evaluations. For our experiments we use a public data
set to dub English speeches into French, Italian, German and Spanish. Finally,
we report extensive subjective tests that measure the impact of MT verbosity
control on the final quality of dubbed video clips.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speeding up Deep Model Training by Sharing Weights and Then Unsharing. (arXiv:2110.03848v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03848">
<div class="article-summary-box-inner">
<span><p>We propose a simple and efficient approach for training the BERT model. Our
approach exploits the special structure of BERT that contains a stack of
repeated modules (i.e., transformer encoders). Our proposed approach first
trains BERT with the weights shared across all the repeated modules till some
point. This is for learning the commonly shared component of weights across all
repeated layers. We then stop weight sharing and continue training until
convergence. We present theoretic insights for training by sharing weights then
unsharing with analysis for simplified models. Empirical experiments on the
BERT model show that our method yields better performance of trained models,
and significantly reduces the number of training iterations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A study on the efficacy of model pre-training in developing neural text-to-speech system. (arXiv:2110.03857v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03857">
<div class="article-summary-box-inner">
<span><p>In the development of neural text-to-speech systems, model pre-training with
a large amount of non-target speakers' data is a common approach. However, in
terms of ultimately achieved system performance for target speaker(s), the
actual benefits of model pre-training are uncertain and unstable, depending
very much on the quantity and text content of training data. This study aims to
understand better why and how model pre-training can positively contribute to
TTS system performance. It is postulated that the pre-training process plays a
critical role in learning text-related variation in speech, while further
training with the target speaker's data aims to capture the speaker-related
variation. Different test sets are created with varying degrees of similarity
to target speaker data in terms of text content. Experiments show that
leveraging a speaker-independent TTS trained on speech data with diverse text
content can improve the target speaker TTS on domain-mismatched text. We also
attempt to reduce the amount of pre-training data for a new text domain and
improve the data and computational efficiency. It is found that the TTS system
could achieve comparable performance when the pre-training data is reduced to
1/8 of its original size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QTN-VQC: An End-to-End Learning framework for Quantum Neural Networks. (arXiv:2110.03861v1 [quant-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03861">
<div class="article-summary-box-inner">
<span><p>The advent of noisy intermediate-scale quantum (NISQ) computers raises a
crucial challenge to design quantum neural networks for fully quantum learning
tasks. To bridge the gap, this work proposes an end-to-end learning framework
named QTN-VQC, by introducing a trainable quantum tensor network (QTN) for
quantum embedding on a variational quantum circuit (VQC). The architecture of
QTN is composed of a parametric tensor-train network for feature extraction and
a tensor product encoding for quantum encoding. We highlight the QTN for
quantum embedding in terms of two perspectives: (1) we theoretically
characterize QTN by analyzing its representation power of input features; (2)
QTN enables an end-to-end parametric model pipeline, namely QTN-VQC, from the
generation of quantum embedding to the output measurement. Our experiments on
the MNIST dataset demonstrate the advantages of QTN for quantum embedding over
other quantum embedding approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Cross-Lingual Transfer of Structured Predictors without Source Data. (arXiv:2110.03866v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03866">
<div class="article-summary-box-inner">
<span><p>Providing technologies to communities or domains where training data is
scarce or protected e.g., for privacy reasons, is becoming increasingly
important. To that end, we generalise methods for unsupervised transfer from
multiple input models for structured prediction. We show that the means of
aggregating over the input models is critical, and that multiplying marginal
probabilities of substructures to obtain high-probability structures for
distant supervision is substantially better than taking the union of such
structures over the input models, as done in prior work. Testing on 18
languages, we demonstrate that the method works in a cross-lingual setting,
considering both dependency parsing and part-of-speech structured prediction
problems. Our analyses show that the proposed method produces less noisy labels
for the distant supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Representation of professions in entertainment media: Insights into frequency and sentiment trends through computational text analysis. (arXiv:2110.03873v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03873">
<div class="article-summary-box-inner">
<span><p>Societal ideas and trends dictate media narratives and cinematic depictions
which in turn influences people's beliefs and perceptions of the real world.
Media portrayal of culture, education, government, religion, and family affect
their function and evolution over time as people interpret and perceive these
representations and incorporate them into their beliefs and actions. It is
important to study media depictions of these social structures so that they do
not propagate or reinforce negative stereotypes, or discriminate against any
demographic section. In this work, we examine media representation of
professions and provide computational insights into their incidence, and
sentiment expressed, in entertainment media content. We create a searchable
taxonomy of professional groups and titles to facilitate their retrieval from
speaker-agnostic text passages like movie and television (TV) show subtitles.
We leverage this taxonomy and relevant natural language processing (NLP) models
to create a corpus of professional mentions in media content, spanning more
than 136,000 IMDb titles over seven decades (1950-2017). We analyze the
frequency and sentiment trends of different occupations, study the effect of
media attributes like genre, country of production, and title type on these
trends, and investigate if the incidence of professions in media subtitles
correlate with their real-world employment statistics. We observe increased
media mentions of STEM, arts, sports, and entertainment occupations in the
analyzed subtitles, and a decreased frequency of manual labor jobs and military
occupations. The sentiment expressed toward lawyers, police, and doctors is
becoming negative over time, whereas astronauts, musicians, singers, and
engineers are mentioned favorably. Professions that employ more people have
increased media frequency, supporting our hypothesis that media acts as a
mirror to society.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phone-to-audio alignment without text: A Semi-supervised Approach. (arXiv:2110.03876v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03876">
<div class="article-summary-box-inner">
<span><p>The task of phone-to-audio alignment has many applications in speech
research. Here we introduce two Wav2Vec2-based models for both text-dependent
and text-independent phone-to-audio alignment. The proposed Wav2Vec2-FS, a
semi-supervised model, directly learns phone-to-audio alignment through
contrastive learning and a forward sum loss, and can be coupled with a
pretrained phone recognizer to achieve text-independent alignment. The other
model, Wav2Vec2-FC, is a frame classification model trained on forced aligned
labels that can both perform forced alignment and text-independent
segmentation. Evaluation results suggest that both proposed methods, even when
transcriptions are not available, generate highly close results to existing
forced alignment tools. Our work presents a neural pipeline of fully automated
phone-to-audio alignment. Code and pretrained models are available at
https://github.com/lingjzhu/charsiu.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining the Attention Mechanism of End-to-End Speech Recognition Using Decision Trees. (arXiv:2110.03879v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03879">
<div class="article-summary-box-inner">
<span><p>The attention mechanism has largely improved the performance of end-to-end
speech recognition systems. However, the underlying behaviours of attention is
not yet clearer. In this study, we use decision trees to explain how the
attention mechanism impact itself in speech recognition. The results indicate
that attention levels are largely impacted by their previous states rather than
the encoder and decoder patterns. Additionally, the default attention mechanism
seems to put more weights on closer states, but behaves poorly on modelling
long-term dependencies of attention states.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. (arXiv:2110.03888v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03888">
<div class="article-summary-box-inner">
<span><p>Recent expeditious developments in deep learning algorithms, distributed
training, and even hardware design for large models have enabled training
extreme-scale models, say GPT-3 and Switch Transformer possessing hundreds of
billions or even trillions of parameters. However, under limited resources,
extreme-scale model training that requires enormous amounts of computes and
memory footprint suffers from frustratingly low efficiency in model
convergence. In this paper, we propose a simple training strategy called
"Pseudo-to-Real" for high-memory-footprint-required large models.
Pseudo-to-Real is compatible with large models with architecture of sequential
layers. We demonstrate a practice of pretraining unprecedented
10-trillion-parameter model, an order of magnitude larger than the
state-of-the-art, on solely 512 GPUs within 10 days. Besides demonstrating the
application of Pseudo-to-Real, we also provide a technique, Granular CPU
offloading, to manage CPU memory for training large model and maintain high GPU
utilities. Fast training of extreme-scale models on a decent amount of
resources can bring much smaller carbon footprint and contribute to greener AI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ALL-IN-ONE: Multi-Task Learning BERT models for Evaluating Peer Assessments. (arXiv:2110.03895v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03895">
<div class="article-summary-box-inner">
<span><p>Peer assessment has been widely applied across diverse academic fields over
the last few decades and has demonstrated its effectiveness. However, the
advantages of peer assessment can only be achieved with high-quality peer
reviews. Previous studies have found that high-quality review comments usually
comprise several features (e.g., contain suggestions, mention problems, use a
positive tone). Thus, researchers have attempted to evaluate peer-review
comments by detecting different features using various machine learning and
deep learning models. However, there is no single study that investigates using
a multi-task learning (MTL) model to detect multiple features simultaneously.
This paper presents two MTL models for evaluating peer-review comments by
leveraging the state-of-the-art pre-trained language representation models BERT
and DistilBERT. Our results demonstrate that BERT-based models significantly
outperform previous GloVe-based methods by around 6% in F1-score on tasks of
detecting a single feature, and MTL further improves performance while reducing
model size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CheerBots: Chatbots toward Empathy and Emotionusing Reinforcement Learning. (arXiv:2110.03949v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03949">
<div class="article-summary-box-inner">
<span><p>Apart from the coherence and fluency of responses, an empathetic chatbot
emphasizes more on people's feelings. By considering altruistic behaviors
between human interaction, empathetic chatbots enable people to get a better
interactive and supportive experience. This study presents a framework whereby
several empathetic chatbots are based on understanding users' implied feelings
and replying empathetically for multiple dialogue turns. We call these chatbots
CheerBots. CheerBots can be retrieval-based or generative-based and were
finetuned by deep reinforcement learning. To respond in an empathetic way, we
develop a simulating agent, a Conceptual Human Model, as aids for CheerBots in
training with considerations on changes in user's emotional states in the
future to arouse sympathy. Finally, automatic metrics and human rating results
demonstrate that CheerBots outperform other baseline chatbots and achieves
reciprocal altruism. The code and the pre-trained models will be made
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perceived and Intended Sarcasm Detection with Graph Attention Networks. (arXiv:2110.04001v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04001">
<div class="article-summary-box-inner">
<span><p>Existing sarcasm detection systems focus on exploiting linguistic markers,
context, or user-level priors. However, social studies suggest that the
relationship between the author and the audience can be equally relevant for
the sarcasm usage and interpretation. In this work, we propose a framework
jointly leveraging (1) a user context from their historical tweets together
with (2) the social information from a user's conversational neighborhood in an
interaction graph, to contextualize the interpretation of the post. We use
graph attention networks (GAT) over users and tweets in a conversation thread,
combined with dense user history representations. Apart from achieving
state-of-the-art results on the recently published dataset of 19k Twitter users
with 30K labeled tweets, adding 10M unlabeled tweets as context, our results
indicate that the model contributes to interpreting the sarcastic intentions of
an author more than to predicting the sarcasm perception by others.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Math-Aware Automated Classification and Similarity Search of Scientific Publications: Methods of Mathematical Content Representations. (arXiv:2110.04040v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04040">
<div class="article-summary-box-inner">
<span><p>In this paper, we investigate mathematical content representations suitable
for the automated classification of and the similarity search in STEM documents
using standard machine learning algorithms: the Latent Dirichlet Allocation
(LDA) and the Latent Semantic Indexing (LSI). The methods are evaluated on a
subset of arXiv.org papers with the Mathematics Subject Classification (MSC) as
a reference classification and using the standard precision/recall/F1-measure
metrics. The results give insight into how different math representations may
influence the performance of the classification and similarity search tasks in
STEM repositories. Non-surprisingly, machine learning methods are able to grab
distributional semantics from textual tokens. A proper selection of weighted
tokens representing math may improve the quality of the results slightly. A
structured math representation that imitates successful text-processing
techniques with math is shown to yield better results than flat TeX tokens.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Do Things without Words: Modeling Semantic Drift of Emoji. (arXiv:2110.04093v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04093">
<div class="article-summary-box-inner">
<span><p>Emoji have become a significant part of our informal textual communication.
Previous work addressing the societal and linguistic functions of emoji
overlook the evolving meaning of the symbol. This evolution could be addressed
through the framework of semantic drifts. In this paper we model and analyze
the semantic drift of emoji and discuss the features that may be contributing
to the drift, some are unique to emoji and some are more general.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Conditional End-to-End ASR with CTC and Multi-Granular Subword Units. (arXiv:2110.04109v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04109">
<div class="article-summary-box-inner">
<span><p>In end-to-end automatic speech recognition (ASR), a model is expected to
implicitly learn representations suitable for recognizing a word-level
sequence. However, the huge abstraction gap between input acoustic signals and
output linguistic tokens makes it challenging for a model to learn the
representations. In this work, to promote the word-level representation
learning in end-to-end ASR, we propose a hierarchical conditional model that is
based on connectionist temporal classification (CTC). Our model is trained by
auxiliary CTC losses applied to intermediate layers, where the vocabulary size
of each target subword sequence is gradually increased as the layer becomes
close to the word-level output. Here, we make each level of sequence prediction
explicitly conditioned on the previous sequences predicted at lower levels.
With the proposed approach, we expect the proposed model to learn the
word-level representations effectively by exploiting a hierarchy of linguistic
structures. Experimental results on LibriSpeech-{100h, 960h} and TEDLIUM2
demonstrate that the proposed model improves over a standard CTC-based model
and other competitive models from prior work. We further analyze the results to
confirm the effectiveness of the intended representation learning with our
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">I Do Not Understand What I Cannot Define: Automatic Question Generation With Pedagogically-Driven Content Selection. (arXiv:2110.04123v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04123">
<div class="article-summary-box-inner">
<span><p>Most learners fail to develop deep text comprehension when reading textbooks
passively. Posing questions about what learners have read is a well-established
way of fostering their text comprehension. However, many textbooks lack
self-assessment questions because authoring them is timeconsuming and
expensive. Automatic question generators may alleviate this scarcity by
generating sound pedagogical questions. However, generating questions
automatically poses linguistic and pedagogical challenges. What should we ask?
And, how do we phrase the question automatically? We address those challenges
with an automatic question generator grounded in learning theory. The paper
introduces a novel pedagogically meaningful content selection mechanism to find
question-worthy sentences and answers in arbitrary textbook contents. We
conducted an empirical evaluation study with educational experts, annotating
150 generated questions in six different domains. Results indicate a high
linguistic quality of the generated questions. Furthermore, the evaluation
results imply that the majority of the generated questions inquire central
information related to the given text and may foster text comprehension in
specific learning scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text analysis and deep learning: A network approach. (arXiv:2110.04151v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04151">
<div class="article-summary-box-inner">
<span><p>Much information available to applied researchers is contained within written
language or spoken text. Deep language models such as BERT have achieved
unprecedented success in many applications of computational linguistics.
However, much less is known about how these models can be used to analyze
existing text. We propose a novel method that combines transformer models with
network analysis to form a self-referential representation of language use
within a corpus of interest. Our approach produces linguistic relations
strongly consistent with the underlying model as well as mathematically
well-defined operations on them, while reducing the amount of discretionary
choices of representation and distance measures. It represents, to the best of
our knowledge, the first unsupervised method to extract semantic networks
directly from deep language models. We illustrate our approach in a semantic
analysis of the term "founder". Using the entire corpus of Harvard Business
Review from 1980 to 2020, we find that ties in our network track the semantics
of discourse over time, and across contexts, identifying and relating clusters
of semantic and syntactic relations. Finally, we discuss how this method can
also complement and inform analyses of the behavior of deep learning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iterative Decoding for Compositional Generalization in Transformers. (arXiv:2110.04169v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04169">
<div class="article-summary-box-inner">
<span><p>Deep learning models do well at generalizing to in-distribution data but
struggle to generalize compositionally, i.e., to combine a set of learned
primitives to solve more complex tasks. In particular, in sequence-to-sequence
(seq2seq) learning, transformers are often unable to predict correct outputs
for even marginally longer examples than those seen during training. This paper
introduces iterative decoding, an alternative to seq2seq learning that (i)
improves transformer compositional generalization and (ii) evidences that, in
general, seq2seq transformers do not learn iterations that are not unrolled.
Inspired by the idea of compositionality -- that complex tasks can be solved by
composing basic primitives -- training examples are broken down into a sequence
of intermediate steps that the transformer then learns iteratively. At
inference time, the intermediate outputs are fed back to the transformer as
intermediate inputs until an end-of-iteration token is predicted. Through
numerical experiments, we show that transfomers trained via iterative decoding
outperform their seq2seq counterparts on the PCFG dataset, and solve the
problem of calculating Cartesian products between vectors longer than those
seen during training with 100% accuracy, a task at which seq2seq models have
been shown to fail. We also illustrate a limitation of iterative decoding,
specifically, that it can make sorting harder to learn on the CFQ dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Development of an Extractive Title Generation System Using Titles of Papers of Top Conferences for Intermediate English Students. (arXiv:2110.04204v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04204">
<div class="article-summary-box-inner">
<span><p>The formulation of good academic paper titles in English is challenging for
intermediate English authors (particularly students). This is because such
authors are not aware of the type of titles that are generally in use. We aim
to realize a support system for formulating more effective English titles for
intermediate English and beginner authors. This study develops an extractive
title generation system that formulates titles from keywords extracted from an
abstract. Moreover, we realize a title evaluation model that can evaluate the
appropriateness of paper titles. We train the model with titles of
top-conference papers by using BERT. This paper describes the training data,
implementation, and experimental results. The results show that our evaluation
model can identify top-conference titles more effectively than intermediate
English and beginner students.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive String Representation Learning using Synthetic Data. (arXiv:2110.04217v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04217">
<div class="article-summary-box-inner">
<span><p>String representation Learning (SRL) is an important task in the field of
Natural Language Processing, but it remains under-explored. The goal of SRL is
to learn dense and low-dimensional vectors (or embeddings) for encoding
character sequences. The learned representation from this task can be used in
many downstream application tasks such as string similarity matching or lexical
normalization. In this paper, we propose a new method for to train a SRL model
by only using synthetic data. Our approach makes use of Contrastive Learning in
order to maximize similarity between related strings while minimizing it for
unrelated strings. We demonstrate the effectiveness of our approach by
evaluating the learned representation on the task of string similarity
matching. Codes, data and pretrained models will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">lambeq: An Efficient High-Level Python Library for Quantum NLP. (arXiv:2110.04236v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04236">
<div class="article-summary-box-inner">
<span><p>We present lambeq, the first high-level Python library for Quantum Natural
Language Processing (QNLP). The open-source toolkit offers a detailed hierarchy
of modules and classes implementing all stages of a pipeline for converting
sentences to string diagrams, tensor networks, and quantum circuits ready to be
used on a quantum computer. lambeq supports syntactic parsing, rewriting and
simplification of string diagrams, ansatz creation and manipulation, as well as
a number of compositional models for preparing quantum-friendly representations
of sentences, employing various degrees of syntax sensitivity. We present the
generic architecture and describe the most important modules in detail,
demonstrating the usage with illustrative examples. Further, we test the
toolkit in practice by using it to perform a number of experiments on simple
NLP tasks, implementing both classical and quantum pipelines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VieSum: How Robust Are Transformer-based Models on Vietnamese Summarization?. (arXiv:2110.04257v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04257">
<div class="article-summary-box-inner">
<span><p>Text summarization is a challenging task within natural language processing
that involves text generation from lengthy input sequences. While this task has
been widely studied in English, there is very limited research on summarization
for Vietnamese text. In this paper, we investigate the robustness of
transformer-based encoder-decoder architectures for Vietnamese abstractive
summarization. Leveraging transfer learning and self-supervised learning, we
validate the performance of the methods on two Vietnamese datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Taming Sparsely Activated Transformer with Stochastic Experts. (arXiv:2110.04260v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04260">
<div class="article-summary-box-inner">
<span><p>Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can
easily scale to have outrageously large amounts of parameters without
significant increase in computational cost. However, SAMs are reported to be
parameter inefficient such that larger models do not always lead to better
performance. While most on-going research focuses on improving SAMs models by
exploring methods of routing inputs to experts, our analysis reveals that such
research might not lead to the solution we expect, i.e., the commonly-used
routing methods based on gating mechanisms do not work better than randomly
routing inputs to experts. In this paper, we propose a new expert-based model,
THOR (Transformer witH StOchastic ExpeRts). Unlike classic expert-based models,
such as the Switch Transformer, experts in THOR are randomly activated for each
input during training and inference. THOR models are trained using a
consistency regularized loss, where experts learn not only from training data
but also from other experts as teachers, such that all the experts make
consistent predictions. We validate the effectiveness of THOR on machine
translation tasks. Results show that THOR models are more parameter efficient
in that they significantly outperform the Transformer and MoE models across
various settings. For example, in multilingual translation, THOR outperforms
the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as
that of a state-of-the-art MoE model that is 18 times larger. Our code is
publicly available at: github.com/microsoft/Stochastic-Mixture-of-Experts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Heterogeneous Characteristics of Layers in ASR Models for More Efficient Training. (arXiv:2110.04267v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04267">
<div class="article-summary-box-inner">
<span><p>Transformer-based architectures have been the subject of research aimed at
understanding their overparameterization and the non-uniform importance of
their layers. Applying these approaches to Automatic Speech Recognition, we
demonstrate that the state-of-the-art Conformer models generally have multiple
ambient layers. We study the stability of these layers across runs and model
sizes, propose that group normalization may be used without disrupting their
formation, and examine their correlation with model weight updates in each
layer. Finally, we apply these findings to Federated Learning in order to
improve the training procedure, by targeting Federated Dropout to layers by
importance. This allows us to reduce the model size optimized by clients
without quality degradation, and shows potential for future exploration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Local and Global Context-Based Pairwise Models for Sentence Ordering. (arXiv:2110.04291v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04291">
<div class="article-summary-box-inner">
<span><p>Sentence Ordering refers to the task of rearranging a set of sentences into
the appropriate coherent order. For this task, most previous approaches have
explored global context-based end-to-end methods using Sequence Generation
techniques. In this paper, we put forward a set of robust local and global
context-based pairwise ordering strategies, leveraging which our prediction
strategies outperform all previous works in this domain. Our proposed encoding
method utilizes the paragraph's rich global contextual information to predict
the pairwise order using novel transformer architectures. Analysis of the two
proposed decoding strategies helps better explain error propagation in pairwise
models. This approach is the most accurate pure pairwise model and our encoding
strategy also significantly improves the performance of other recent approaches
that use pairwise models, including the previous state-of-the-art,
demonstrating the research novelty and generalizability of this work.
Additionally, we show how the pre-training task for ALBERT helps it to
significantly outperform BERT, despite having considerably lesser parameters.
The extensive experimental results, architectural analysis and ablation studies
demonstrate the effectiveness and superiority of the proposed models compared
to the previous state-of-the-art, besides providing a much better understanding
of the functioning of pairwise models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From SCAN to Real Data: Systematic Generalization via Meaningful Learning. (arXiv:2003.06658v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06658">
<div class="article-summary-box-inner">
<span><p>Humans can systematically generalize to novel compositions of existing
concepts. There have been extensive conjectures into the extent to which neural
networks can do the same. Recent arguments supported by evidence on the SCAN
dataset claim that neural networks are inherently ineffective in such cognitive
capacity. In this paper, we revisit systematic generalization from the
perspective of meaningful learning, an exceptional capability of humans to
learn new concepts by connecting them with other previously known knowledge. We
propose to augment a training dataset in either an inductive or deductive
manner to build semantic links between new and old concepts. Our observations
on SCAN suggest that, following the meaningful learning principle, modern
sequence-to-sequence models, including RNNs, CNNs, and Transformers, can
successfully generalize to compositions of new concepts. We further validate
our findings on two real-world datasets on semantic parsing and consistent
compositional generalization is also observed. Moreover, our experiments
demonstrate that both prior knowledge and semantic linking play a key role to
achieve systematic generalization. Meanwhile, inductive learning generally
works better than deductive learning in our experiments. Finally, we provide an
explanation for data augmentation techniques by concluding them into either
inductive-based or deductive-based meaningful learning. We hope our findings
will encourage excavating existing neural networks' potential in systematic
generalization through more advanced learning schemes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">English Machine Reading Comprehension Datasets: A Survey. (arXiv:2101.10421v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10421">
<div class="article-summary-box-inner">
<span><p>This paper surveys 60 English Machine Reading Comprehension datasets, with a
view to providing a convenient resource for other researchers interested in
this problem. We categorize the datasets according to their question and answer
form and compare them across various dimensions including size, vocabulary,
data source, method of creation, human performance level, and first question
word. Our analysis reveals that Wikipedia is by far the most common data source
and that there is a relative lack of why, when, and where questions across
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-based end-to-end speech recognition with residual Gaussian-based self-attention. (arXiv:2103.15722v4 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15722">
<div class="article-summary-box-inner">
<span><p>Self-attention (SA), which encodes vector sequences according to their
pairwise similarity, is widely used in speech recognition due to its strong
context modeling ability. However, when applied to long sequence data, its
accuracy is reduced. This is caused by the fact that its weighted average
operator may lead to the dispersion of the attention distribution, which
results in the relationship between adjacent signals ignored. To address this
issue, in this paper, we introduce relative-position-awareness self-attention
(RPSA). It not only maintains the global-range dependency modeling ability of
self-attention, but also improves the localness modeling ability. Because the
local window length of the original RPSA is fixed and sensitive to different
test data, here we propose Gaussian-based self-attention (GSA) whose window
length is learnable and adaptive to the test data automatically. We further
generalize GSA to a new residual Gaussian self-attention (resGSA) for the
performance improvement. We apply RPSA, GSA, and resGSA to Transformer-based
speech recognition respectively. Experimental results on the AISHELL-1 Mandarin
speech recognition corpus demonstrate the effectiveness of the proposed
methods. For example, the resGSA-Transformer achieves a character error rate
(CER) of 5.86% on the test set, which is relative 7.8% lower than that of the
SA-Transformer. Although the performance of the proposed resGSA-Transformer is
only slightly better than that of the RPSA-Transformer, it does not have to
tune the window length manually.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relaxing the Conditional Independence Assumption of CTC-based ASR by Conditioning on Intermediate Predictions. (arXiv:2104.02724v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02724">
<div class="article-summary-box-inner">
<span><p>This paper proposes a method to relax the conditional independence assumption
of connectionist temporal classification (CTC)-based automatic speech
recognition (ASR) models. We train a CTC-based ASR model with auxiliary CTC
losses in intermediate layers in addition to the original CTC loss in the last
layer. During both training and inference, each generated prediction in the
intermediate layers is summed to the input of the next layer to condition the
prediction of the last layer on those intermediate predictions. Our method is
easy to implement and retains the merits of CTC-based ASR: a simple model
architecture and fast decoding speed. We conduct experiments on three different
ASR corpora. Our proposed method improves a standard CTC model significantly
(e.g., more than 20 % relative word error rate reduction on the WSJ corpus)
with a little computational overhead. Moreover, for the TEDLIUM2 corpus and the
AISHELL-1 corpus, it achieves a comparable performance to a strong
autoregressive model with beam search, but the decoding speed is at least 30
times faster.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Weakly Supervised Dataset of Fine-Grained Emotions in Portuguese. (arXiv:2108.07638v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07638">
<div class="article-summary-box-inner">
<span><p>Affective Computing is the study of how computers can recognize, interpret
and simulate human affects. Sentiment Analysis is a common task inNLP related
to this topic, but it focuses only on emotion valence (positive, negative,
neutral). An emerging approach in NLP is Emotion Recognition, which relies on
fined-grained classification. This research describes an approach to create a
lexical-based weakly supervised corpus for fine-grained emotion in Portuguese.
We evaluated our dataset by fine-tuning a transformer-based language model
(BERT) and validating it on a Gold Standard annotated validation set. Our
results (F1-score=.64) suggest lexical-based weak supervision as an appropriate
strategy for initial work in low resourced environment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rule-based Morphological Inflection Improves Neural Terminology Translation. (arXiv:2109.04620v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04620">
<div class="article-summary-box-inner">
<span><p>Current approaches to incorporating terminology constraints in machine
translation (MT) typically assume that the constraint terms are provided in
their correct morphological forms. This limits their application to real-world
scenarios where constraint terms are provided as lemmas. In this paper, we
introduce a modular framework for incorporating lemma constraints in neural MT
(NMT) in which linguistic knowledge and diverse types of NMT models can be
flexibly applied. It is based on a novel cross-lingual inflection module that
inflects the target lemma constraints based on the source context. We explore
linguistically motivated rule-based and data-driven neural-based inflection
modules and design English-German health and English-Lithuanian news test
suites to evaluate them in domain adaptation and low-resource MT settings.
Results show that our rule-based inflection module helps NMT models incorporate
lemma constraints more accurately than a neural module and outperforms the
existing end-to-end approach with lower training costs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language Understanding and Generation. (arXiv:2109.05729v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05729">
<div class="article-summary-box-inner">
<span><p>In this paper, we take the advantage of previous pre-trained models (PTMs)
and propose a novel Chinese Pre-trained Unbalanced Transformer (CPT). Different
from previous Chinese PTMs, CPT is designed for both natural language
understanding (NLU) and natural language generation (NLG) tasks. CPT consists
of three parts: a shared encoder, an understanding decoder, and a generation
decoder. Two specific decoders with a shared encoder are pre-trained with
masked language modeling (MLM) and denoising auto-encoding (DAE) tasks,
respectively. With the partially shared architecture and multi-task
pre-training, CPT can (1) learn specific knowledge of both NLU or NLG tasks
with two decoders and (2) be fine-tuned flexibly that fully exploits the
potential of the model. Moreover, the unbalanced Transformer saves the
computational and storage cost, which makes CPT competitive and greatly
accelerates the inference of text generation. Experimental results on a wide
range of Chinese NLU and NLG tasks show the effectiveness of CPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LM-Critic: Language Models for Unsupervised Grammatical Error Correction. (arXiv:2109.06822v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06822">
<div class="article-summary-box-inner">
<span><p>Training a model for grammatical error correction (GEC) requires a set of
labeled ungrammatical / grammatical sentence pairs, but manually annotating
such pairs can be expensive. Recently, the Break-It-Fix-It (BIFI) framework has
demonstrated strong results on learning to repair a broken program without any
labeled examples, but this relies on a perfect critic (e.g., a compiler) that
returns whether an example is valid or not, which does not exist for the GEC
task. In this work, we show how to leverage a pretrained language model (LM) in
defining an LM-Critic, which judges a sentence to be grammatical if the LM
assigns it a higher probability than its local perturbations. We apply this
LM-Critic and BIFI along with a large set of unlabeled sentences to bootstrap
realistic ungrammatical / grammatical pairs for training a corrector. We
evaluate our approach on GEC datasets across multiple domains (CoNLL-2014,
BEA-2019, GMEG-wiki and GMEG-yahoo) and show that it outperforms existing
methods in both the unsupervised setting (+7.7 F0.5) and the supervised setting
(+0.5 F0.5).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models. (arXiv:2109.11797v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11797">
<div class="article-summary-box-inner">
<span><p>Pre-Trained Vision-Language Models (VL-PTMs) have shown promising
capabilities in grounding natural language in image data, facilitating a broad
variety of cross-modal tasks. However, we note that there exists a significant
gap between the objective forms of model pre-training and fine-tuning,
resulting in a need for large amounts of labeled data to stimulate the visual
grounding capability of VL-PTMs for downstream tasks. To address the challenge,
we present Cross-modal Prompt Tuning (CPT, alternatively, Colorful Prompt
Tuning), a novel paradigm for tuning VL-PTMs, which reformulates visual
grounding into a fill-in-the-blank problem with color-based co-referential
markers in image and text, maximally mitigating the gap. In this way, CPT
enables strong few-shot and even zero-shot visual grounding capabilities of
VL-PTMs. Comprehensive experimental results show that the prompt-tuned VL-PTMs
outperform their fine-tuned counterparts by a large margin (e.g., 17.3%
absolute accuracy improvement, and 73.8% relative standard deviation reduction
on average with one shot in RefCOCO evaluation). All the data and codes will be
available to facilitate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FoodChem: A food-chemical relation extraction model. (arXiv:2110.02019v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02019">
<div class="article-summary-box-inner">
<span><p>In this paper, we present FoodChem, a new Relation Extraction (RE) model for
identifying chemicals present in the composition of food entities, based on
textual information provided in biomedical peer-reviewed scientific literature.
The RE task is treated as a binary classification problem, aimed at identifying
whether the contains relation exists between a food-chemical entity pair. This
is accomplished by fine-tuning BERT, BioBERT and RoBERTa transformer models.
For evaluation purposes, a novel dataset with annotated contains relations in
food-chemical entity pairs is generated, in a golden and silver version. The
models are integrated into a voting scheme in order to produce the silver
version of the dataset which we use for augmenting the individual models, while
the manually annotated golden version is used for their evaluation. Out of the
three evaluated models, the BioBERT model achieves the best results, with a
macro averaged F1 score of 0.902 in the unbalanced augmentation setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Conditional Text Generation for Aspect-Based Sentiment Analysis. (arXiv:2110.02334v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02334">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis (ABSA) is an NLP task that entails processing
user-generated reviews to determine (i) the target being evaluated, (ii) the
aspect category to which it belongs, and (iii) the sentiment expressed towards
the target and aspect pair. In this article, we propose transforming ABSA into
an abstract summary-like conditional text generation task that uses targets,
aspects, and polarities to generate auxiliary statements. To demonstrate the
efficacy of our task formulation and a proposed system, we fine-tune a
pre-trained model for conditional text generation tasks to get new
state-of-the-art results on a few restaurant domains and urban neighborhoods
domain benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cut the CARP: Fishing for zero-shot story evaluation. (arXiv:2110.03111v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03111">
<div class="article-summary-box-inner">
<span><p>Recent advances in large-scale language models (Raffel et al., 2019; Brown et
al., 2020) have brought significant qualitative and quantitative improvements
in machine-driven text generation. Despite this, generation and evaluation of
machine-generated narrative text remains a challenging problem. Objective
evaluation of computationally-generated stories may be prohibitively expensive,
require meticulously annotated datasets, or may not adequately measure the
logical coherence of a generated story's narratological structure.
</p>
<p>Informed by recent advances in contrastive learning (Radford et al., 2021),
we present Contrastive Authoring and Reviewing Pairing (CARP): a scalable,
efficient method for performing qualitatively superior, zero-shot evaluation of
stories. We show a strong correlation between human evaluation of stories and
those of CARP. Model outputs more significantly correlate with corresponding
human input than those language-model based methods which utilize finetuning or
prompt engineering approaches. We also present and analyze the Story-Critique
Dataset, a new corpora composed of 1.3 million aligned story-critique pairs
derived from over 80,000 stories. We expect this corpus to be of interest to
NLP researchers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Continual Knowledge Learning of Language Models. (arXiv:2110.03215v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03215">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LMs) are known to encode world knowledge in their
parameters as they pretrain on a vast amount of web corpus, which is often
utilized for performing knowledge-dependent downstream tasks such as question
answering, fact-checking, and open dialogue. In real-world scenarios, the world
knowledge stored in the LMs can quickly become outdated as the world changes,
but it is non-trivial to avoid catastrophic forgetting and reliably acquire new
knowledge while preserving invariant knowledge. To push the community towards
better maintenance of ever-changing LMs, we formulate a new continual learning
(CL) problem called Continual Knowledge Learning (CKL). We construct a new
benchmark and metric to quantify the retention of time-invariant world
knowledge, the update of outdated knowledge, and the acquisition of new
knowledge. We adopt applicable recent methods from literature to create several
strong baselines. Through extensive experiments, we find that CKL exhibits
unique challenges that are not addressed in previous CL setups, where parameter
expansion is necessary to reliably retain and learn knowledge simultaneously.
By highlighting the critical causes of knowledge forgetting, we show that CKL
is a challenging and important problem that helps us better understand and
train ever-changing LMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Logic-Based Framework for Natural Language Inference in Dutch. (arXiv:2110.03323v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03323">
<div class="article-summary-box-inner">
<span><p>We present a framework for deriving inference relations between Dutch
sentence pairs. The proposed framework relies on logic-based reasoning to
produce inspectable proofs leading up to inference labels; its judgements are
therefore transparent and formally verifiable. At its core, the system is
powered by two ${\lambda}$-calculi, used as syntactic and semantic theories,
respectively. Sentences are first converted to syntactic proofs and terms of
the linear ${\lambda}$-calculus using a choice of two parsers: an Alpino-based
pipeline, and Neural Proof Nets. The syntactic terms are then converted to
semantic terms of the simply typed ${\lambda}$-calculus, via a set of hand
designed type- and term-level transformations. Pairs of semantic terms are then
fed to an automated theorem prover for natural logic which reasons with them
while using lexical relations found in the Open Dutch WordNet. We evaluate the
reasoning pipeline on the recently created Dutch natural language inference
dataset, and achieve promising results, remaining only within a $1.1-3.2{\%}$
performance margin to strong neural baselines. To the best of our knowledge,
the reasoning pipeline is the first logic-based system for Dutch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Retriever-Ranker for dense text retrieval. (arXiv:2110.03611v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03611">
<div class="article-summary-box-inner">
<span><p>Current dense text retrieval models face two typical challenges. First, it
adopts a siamese dual-encoder architecture to encode query and document
independently for fast indexing and searching, whereas neglecting the
finer-grained term-wise interactions. This results in a sub-optimal recall
performance. Second, it highly relies on a negative sampling technique to build
up the negative documents in its contrastive loss. To address these challenges,
we present Adversarial Retriever-Ranker (AR2), which consists of a dual-encoder
retriever plus a cross-encoder ranker. The two models are jointly optimized
according to a minimax adversarial objective: the retriever learns to retrieve
negative documents to cheat the ranker, while the ranker learns to rank a
collection of candidates including both the ground-truth and the retrieved
ones, as well as providing progressive direct feedback to the dual-encoder
retriever. Through this adversarial game, the retriever gradually produces
harder negative documents to train a better ranker, whereas the cross-encoder
ranker provides progressive feedback to improve retriever. We evaluate AR2 on
three benchmarks. Experimental results show that AR2 consistently and
significantly outperforms existing dense retriever methods and achieves new
state-of-the-art results on all of them. This includes the improvements on
Natural Questions R@5 to 77.9%(+2.1%), TriviaQA R@5 to 78.2%(+1.4), and
MS-MARCO MRR@10 to 39.5%(+1.3%). We will make our code, models, and data
publicly available.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Higher-Order Dynamics in Video-Based Cardiac Measurement. (arXiv:2110.03690v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03690">
<div class="article-summary-box-inner">
<span><p>Computer vision methods typically optimize for first-order dynamics (e.g.,
optical flow). However, in many cases the properties of interest are subtle
variations in higher-order changes, such as acceleration. This is true in the
cardiac pulse, where the second derivative can be used as an indicator of blood
pressure and arterial disease. Recent developments in camera-based vital sign
measurement have shown that cardiac measurements can be recovered with
impressive accuracy from videos; however, the majority of research has focused
on extracting summary statistics such as heart rate. Less emphasis has been put
on the accuracy of waveform morphology that is necessary for many clinically
impactful scenarios. In this work, we provide evidence that higher-order
dynamics are better estimated by neural models when explicitly optimized for in
the loss function. Furthermore, adding second-derivative inputs also improves
performance when estimating second-order dynamics. By incorporating the second
derivative of both the input frames and the target vital sign signals into the
training procedure, our model is better able to estimate left ventricle
ejection time (LVET) intervals.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SVG-Net: An SVG-based Trajectory Prediction Model. (arXiv:2110.03706v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03706">
<div class="article-summary-box-inner">
<span><p>Anticipating motions of vehicles in a scene is an essential problem for safe
autonomous driving systems. To this end, the comprehension of the scene's
infrastructure is often the main clue for predicting future trajectories. Most
of the proposed approaches represent the scene with a rasterized format and
some of the more recent approaches leverage custom vectorized formats. In
contrast, we propose representing the scene's information by employing Scalable
Vector Graphics (SVG). SVG is a well-established format that matches the
problem of trajectory prediction better than rasterized formats while being
more general than arbitrary vectorized formats. SVG has the potential to
provide the convenience and generality of raster-based solutions if coupled
with a powerful tool such as CNNs, for which we introduce SVG-Net. SVG-Net is a
Transformer-based Neural Network that can effectively capture the scene's
information from SVG inputs. Thanks to the self-attention mechanism in its
Transformers, SVG-Net can also adequately apprehend relations amongst the scene
and the agents. We demonstrate SVG-Net's effectiveness by evaluating its
performance on the publicly available Argoverse forecasting dataset. Finally,
we illustrate how, by using SVG, one can benefit from datasets and advancements
in other research fronts that also utilize the same input format. Our code is
available at https://vita-epfl.github.io/SVGNet/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Unlearning of Backdoors via Implicit Hypergradient. (arXiv:2110.03735v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03735">
<div class="article-summary-box-inner">
<span><p>We propose a minimax formulation for removing backdoors from a given poisoned
model based on a small set of clean data. This formulation encompasses much of
prior work on backdoor removal. We propose the Implicit Bacdoor Adversarial
Unlearning (I-BAU) algorithm to solve the minimax. Unlike previous work, which
breaks down the minimax into separate inner and outer problems, our algorithm
utilizes the implicit hypergradient to account for the interdependence between
inner and outer optimization. We theoretically analyze its convergence and the
generalizability of the robustness gained by solving minimax on clean data to
unseen test data. In our evaluation, we compare I-BAU with six state-of-art
backdoor defenses on seven backdoor attacks over two datasets and various
attack settings, including the common setting where the attacker targets one
class as well as important but underexplored settings where multiple classes
are targeted. I-BAU's performance is comparable to and most often significantly
better than the best baseline. Particularly, its performance is more robust to
the variation on triggers, attack settings, poison ratio, and clean data size.
Moreover, I-BAU requires less computation to take effect; particularly, it is
more than $13\times$ faster than the most efficient baseline in the
single-target attack setting. Furthermore, it can remain effective in the
extreme case where the defender can only access 100 clean samples -- a setting
where all the baselines fail to produce acceptable results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Early-Learning Correction for Segmentation from Noisy Annotations. (arXiv:2110.03740v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03740">
<div class="article-summary-box-inner">
<span><p>Deep learning in the presence of noisy annotations has been studied
extensively in classification, but much less in segmentation tasks. In this
work, we study the learning dynamics of deep segmentation networks trained on
inaccurately-annotated data. We discover a phenomenon that has been previously
reported in the context of classification: the networks tend to first fit the
clean pixel-level labels during an "early-learning" phase, before eventually
memorizing the false annotations. However, in contrast to classification,
memorization in segmentation does not arise simultaneously for all semantic
categories. Inspired by these findings, we propose a new method for
segmentation from noisy annotations with two key elements. First, we detect the
beginning of the memorization phase separately for each category during
training. This allows us to adaptively correct the noisy annotations in order
to exploit early learning. Second, we incorporate a regularization term that
enforces consistency across scales to boost robustness against annotation
noise. Our method outperforms standard approaches on a medical-imaging
segmentation task where noises are synthesized to mimic human annotation
errors. It also provides robustness to realistic noisy annotations present in
weakly-supervised semantic segmentation, achieving state-of-the-art results on
PASCAL VOC 2012.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Attack by Limited Point Cloud Surface Modifications. (arXiv:2110.03745v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03745">
<div class="article-summary-box-inner">
<span><p>Recent research has revealed that the security of deep neural networks that
directly process 3D point clouds to classify objects can be threatened by
adversarial samples. Although existing adversarial attack methods achieve high
success rates, they do not restrict the point modifications enough to preserve
the point cloud appearance. To overcome this shortcoming, two constraints are
proposed. These include applying hard boundary constraints on the number of
modified points and on the point perturbation norms. Due to the restrictive
nature of the problem, the search space contains many local maxima. The
proposed method addresses this issue by using a high step-size at the beginning
of the algorithm to search the main surface of the point cloud fast and
effectively. Then, in order to converge to the desired output, the step-size is
gradually decreased. To evaluate the performance of the proposed method, it is
run on the ModelNet40 and ScanObjectNN datasets by employing the
state-of-the-art point cloud classification models; including PointNet,
PointNet++, and DGCNN. The obtained results show that it can perform successful
attacks and achieve state-of-the-art results by only a limited number of point
modifications while preserving the appearance of the point cloud. Moreover, due
to the effective search algorithm, it can perform successful attacks in just a
few steps. Additionally, the proposed step-size scheduling algorithm shows an
improvement of up to $14.5\%$ when adopted by other methods as well. The
proposed method also performs effectively against popular defense methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Proposing a System Level Machine Learning Hybrid Architecture and Approach for a Comprehensive Autism Spectrum Disorder Diagnosis. (arXiv:2110.03775v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03775">
<div class="article-summary-box-inner">
<span><p>Autism Spectrum Disorder (ASD) is a severe neuropsychiatric disorder that
affects intellectual development, social behavior, and facial features, and the
number of cases is still significantly increasing. Due to the variety of
symptoms ASD displays, the diagnosis process remains challenging, with numerous
misdiagnoses as well as lengthy and expensive diagnoses. Fortunately, if ASD is
diagnosed and treated early, then the patient will have a much higher chance of
developing normally. For an ASD diagnosis, machine learning algorithms can
analyze both social behavior and facial features accurately and efficiently,
providing an ASD diagnosis in a drastically shorter amount of time than through
current clinical diagnosis processes. Therefore, we propose to develop a hybrid
architecture fully utilizing both social behavior and facial feature data to
improve the accuracy of diagnosing ASD. We first developed a Linear Support
Vector Machine for the social behavior based module, which analyzes Autism
Diagnostic Observation Schedule (ADOS) social behavior data. For the facial
feature based module, a DenseNet model was utilized to analyze facial feature
image data. Finally, we implemented our hybrid model by incorporating different
features of the Support Vector Machine and the DenseNet into one model. Our
results show that the highest accuracy of 87% for ASD diagnosis has been
achieved by our proposed hybrid model. The pros and cons of each module will be
discussed in this paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning approaches to do size based reasoning on Retail Shelf objects to classify product variants. (arXiv:2110.03783v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03783">
<div class="article-summary-box-inner">
<span><p>There has been a surge in the number of Machine Learning methods to analyze
products kept on retail shelves images. Deep learning based computer vision
methods can be used to detect products on retail shelves and then classify
them. However, there are different sized variants of products which look
exactly the same visually and the method to differentiate them is to look at
their relative sizes with other products on shelves. This makes the process of
deciphering the sized based variants from each other using computer vision
algorithms alone impractical. In this work, we propose methods to ascertain the
size variant of the product as a downstream task to an object detector which
extracts products from shelf and a classifier which determines product brand.
Product variant determination is the task which assigns a product variant to
products of a brand based on the size of bounding boxes and brands predicted by
classifier. While gradient boosting based methods work well for products whose
facings are clear and distinct, a noise accommodating Neural Network method is
proposed for cases where the products are stacked irregularly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient large-scale image retrieval with deep feature orthogonality and Hybrid-Swin-Transformers. (arXiv:2110.03786v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03786">
<div class="article-summary-box-inner">
<span><p>We present an efficient end-to-end pipeline for largescale landmark
recognition and retrieval. We show how to combine and enhance concepts from
recent research in image retrieval and introduce two architectures especially
suited for large-scale landmark identification. A model with deep orthogonal
fusion of local and global features (DOLG) using an EfficientNet backbone as
well as a novel Hybrid-Swin-Transformer is discussed and details how to train
both architectures efficiently using a step-wise approach and a sub-center
arcface loss with dynamic margins are provided. Furthermore, we elaborate a
novel discriminative re-ranking methodology for image retrieval. The
superiority of our approach was demonstrated by winning the recognition and
retrieval track of the Google Landmark Competition 2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Probabilistic Graphical Model Approach to the Structure-and-Motion Problem. (arXiv:2110.03792v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03792">
<div class="article-summary-box-inner">
<span><p>We present a means of formulating and solving the well known
structure-and-motion problem in computer vision with probabilistic graphical
models. We model the unknown camera poses and 3D feature coordinates as well as
the observed 2D projections as Gaussian random variables, using sigma point
parameterizations to effectively linearize the nonlinear relationships between
these variables. Those variables involved in every projection are grouped into
a cluster, and we connect the clusters in a cluster graph. Loopy belief
propagation is performed over this graph, in an iterative re-initialization and
estimation procedure, and we find that our approach shows promise in both
simulation and on real-world data. The PGM is easily extendable to include
additional parameters or constraints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FOCUS: Familiar Objects in Common and Uncommon Settings. (arXiv:2110.03804v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03804">
<div class="article-summary-box-inner">
<span><p>Standard training datasets for deep learning often contain objects in common
settings (e.g., "a horse on grass" or "a ship in water") since they are usually
collected by randomly scraping the web. Uncommon and rare settings (e.g., "a
plane on water", "a car in snowy weather") are thus severely under-represented
in the training data. This can lead to an undesirable bias in model predictions
towards common settings and create a false sense of accuracy. In this paper, we
introduce FOCUS (Familiar Objects in Common and Uncommon Settings), a dataset
for stress-testing the generalization power of deep image classifiers. By
leveraging the power of modern search engines, we deliberately gather data
containing objects in common and uncommon settings in a wide range of
locations, weather conditions, and time of day. We present a detailed analysis
of the performance of various popular image classifiers on our dataset and
demonstrate a clear drop in performance when classifying images in uncommon
settings. By analyzing deep features of these models, we show that such errors
can be due to the use of spurious features in model predictions. We believe
that our dataset will aid researchers in understanding the inability of deep
models to generalize well to uncommon settings and drive future work on
improving their distributional robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StyleGAN-induced data-driven regularization for inverse problems. (arXiv:2110.03814v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03814">
<div class="article-summary-box-inner">
<span><p>Recent advances in generative adversarial networks (GANs) have opened up the
possibility of generating high-resolution photo-realistic images that were
impossible to produce previously. The ability of GANs to sample from
high-dimensional distributions has naturally motivated researchers to leverage
their power for modeling the image prior in inverse problems. We extend this
line of research by developing a Bayesian image reconstruction framework that
utilizes the full potential of a pre-trained StyleGAN2 generator, which is the
currently dominant GAN architecture, for constructing the prior distribution on
the underlying image. Our proposed approach, which we refer to as learned
Bayesian reconstruction with generative models (L-BRGM), entails joint
optimization over the style-code and the input latent code, and enhances the
expressive power of a pre-trained StyleGAN2 generator by allowing the
style-codes to be different for different generator layers. Considering the
inverse problems of image inpainting and super-resolution, we demonstrate that
the proposed approach is competitive with, and sometimes superior to,
state-of-the-art GAN-based image reconstruction methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks. (arXiv:2110.03825v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03825">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) are known to be vulnerable to adversarial
attacks. A range of defense methods have been proposed to train adversarially
robust DNNs, among which adversarial training has demonstrated promising
results. However, despite preliminary understandings developed for adversarial
training, it is still not clear, from the architectural perspective, what
configurations can lead to more robust DNNs. In this paper, we address this gap
via a comprehensive investigation on the impact of network width and depth on
the robustness of adversarially trained DNNs. Specifically, we make the
following key observations: 1) more parameters (higher model capacity) does not
necessarily help adversarial robustness; 2) reducing capacity at the last stage
(the last group of blocks) of the network can actually improve adversarial
robustness; and 3) under the same parameter budget, there exists an optimal
architectural configuration for adversarial robustness. We also provide a
theoretical analysis explaning why such network configuration can help
robustness. These architectural insights can help design adversarially robust
DNNs. Code is available at \url{https://github.com/HanxunH/RobustWRN}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SkullEngine: A Multi-stage CNN Framework for Collaborative CBCT Image Segmentation and Landmark Detection. (arXiv:2110.03828v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03828">
<div class="article-summary-box-inner">
<span><p>We propose a multi-stage coarse-to-fine CNN-based framework, called
SkullEngine, for high-resolution segmentation and large-scale landmark
detection through a collaborative, integrated, and scalable JSD model and three
segmentation and landmark detection refinement models. We evaluated our
framework on a clinical dataset consisting of 170 CBCT/CT images for the task
of segmenting 2 bones (midface and mandible) and detecting 175 clinically
common landmarks on bones, teeth, and soft tissues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic annotation of visual deep neural networks. (arXiv:2110.03851v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03851">
<div class="article-summary-box-inner">
<span><p>Computer vision is widely used in the fields of driverless, face recognition
and 3D reconstruction as a technology to help or replace human eye perception
images or multidimensional data through computers. Nowadays, with the
development and application of deep neural networks, the models of deep neural
networks proposed for computer vision are becoming more and more abundant, and
developers will use the already trained models on the way to solve problems,
and need to consult the relevant documents to understand the use of the model.
The class model, which creates the need to quickly and accurately find the
relevant models that you need. The automatic annotation method of visual depth
neural network proposed in this paper is based on natural language processing
technology such as semantic analysis, which realizes automatic labeling of
model application fields. In the three top international conferences on
computer vision: ICCV, CVPR and ECCV, the average correct rate of application
of the papers of 72 papers reached 90%, indicating the effectiveness of the
automatic labeling system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Learning 3D Shape Segmentation Functions. (arXiv:2110.03854v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03854">
<div class="article-summary-box-inner">
<span><p>Learning robust 3D shape segmentation functions with deep neural networks has
emerged as a powerful paradigm, offering promising performance in producing a
consistent part segmentation of each 3D shape. Generalizing across 3D shape
segmentation functions requires robust learning of priors over the respective
function space and enables consistent part segmentation of shapes in presence
of significant 3D structure variations. Existing generalization methods rely on
extensive training of 3D shape segmentation functions on large-scale labeled
datasets. In this paper, we proposed to formalize the learning of a 3D shape
segmentation function space as a meta-learning problem, aiming to predict a 3D
segmentation model that can be quickly adapted to new shapes with no or limited
training data. More specifically, we define each task as unsupervised learning
of shape-conditioned 3D segmentation function which takes as input points in 3D
space and predicts the part-segment labels. The 3D segmentation function is
trained by a self-supervised 3D shape reconstruction loss without the need for
part labels. Also, we introduce an auxiliary deep neural network as a
meta-learner which takes as input a 3D shape and predicts the prior over the
respective 3D segmentation function space. We show in experiments that our
meta-learning approach, denoted as Meta-3DSeg, leads to improvements on
unsupervised 3D shape segmentation over the conventional designs of deep neural
networks for 3D shape segmentation functions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ABCP: Automatic Block-wise and Channel-wise Network Pruning via Joint Search. (arXiv:2110.03858v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03858">
<div class="article-summary-box-inner">
<span><p>Currently, an increasing number of model pruning methods are proposed to
resolve the contradictions between the computer powers required by the deep
learning models and the resource-constrained devices. However, most of the
traditional rule-based network pruning methods can not reach a sufficient
compression ratio with low accuracy loss and are time-consuming as well as
laborious. In this paper, we propose Automatic Block-wise and Channel-wise
Network Pruning (ABCP) to jointly search the block-wise and channel-wise
pruning action with deep reinforcement learning. A joint sample algorithm is
proposed to simultaneously generate the pruning choice of each residual block
and the channel pruning ratio of each convolutional layer from the discrete and
continuous search space respectively. The best pruning action taking both the
accuracy and the complexity of the model into account is obtained finally.
Compared with the traditional rule-based pruning method, this pipeline saves
human labor and achieves a higher compression ratio with lower accuracy loss.
Tested on the mobile robot detection dataset, the pruned YOLOv3 model saves
99.5% FLOPs, reduces 99.5% parameters, and achieves 37.3 times speed up with
only 2.8% mAP loss. The results of the transfer task on the sim2real detection
dataset also show that our pruned model has much better robustness performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Token Pooling in Visual Transformers. (arXiv:2110.03860v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03860">
<div class="article-summary-box-inner">
<span><p>Despite the recent success in many applications, the high computational
requirements of vision transformers limit their use in resource-constrained
settings. While many existing methods improve the quadratic complexity of
attention, in most vision transformers, self-attention is not the major
computation bottleneck, e.g., more than 80% of the computation is spent on
fully-connected layers. To improve the computational complexity of all layers,
we propose a novel token downsampling method, called Token Pooling, efficiently
exploiting redundancies in the images and intermediate token representations.
We show that, under mild assumptions, softmax-attention acts as a
high-dimensional low-pass (smoothing) filter. Thus, its output contains
redundancy that can be pruned to achieve a better trade-off between the
computational cost and accuracy. Our new technique accurately approximates a
set of tokens by minimizing the reconstruction error caused by downsampling. We
solve this optimization problem via cost-efficient clustering. We rigorously
analyze and compare to prior downsampling methods. Our experiments show that
Token Pooling significantly improves the cost-accuracy trade-off over the
state-of-the-art downsampling. Token Pooling is a simple and effective operator
that can benefit many architectures. Applied to DeiT, it achieves the same
ImageNet top-1 accuracy using 42% fewer computations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QTN-VQC: An End-to-End Learning framework for Quantum Neural Networks. (arXiv:2110.03861v1 [quant-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03861">
<div class="article-summary-box-inner">
<span><p>The advent of noisy intermediate-scale quantum (NISQ) computers raises a
crucial challenge to design quantum neural networks for fully quantum learning
tasks. To bridge the gap, this work proposes an end-to-end learning framework
named QTN-VQC, by introducing a trainable quantum tensor network (QTN) for
quantum embedding on a variational quantum circuit (VQC). The architecture of
QTN is composed of a parametric tensor-train network for feature extraction and
a tensor product encoding for quantum encoding. We highlight the QTN for
quantum embedding in terms of two perspectives: (1) we theoretically
characterize QTN by analyzing its representation power of input features; (2)
QTN enables an end-to-end parametric model pipeline, namely QTN-VQC, from the
generation of quantum embedding to the output measurement. Our experiments on
the MNIST dataset demonstrate the advantages of QTN for quantum embedding over
other quantum embedding approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boundary-aware Transformers for Skin Lesion Segmentation. (arXiv:2110.03864v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03864">
<div class="article-summary-box-inner">
<span><p>Skin lesion segmentation from dermoscopy images is of great importance for
improving the quantitative analysis of skin cancer. However, the automatic
segmentation of melanoma is a very challenging task owing to the large
variation of melanoma and ambiguous boundaries of lesion areas. While
convolutional neutral networks (CNNs) have achieved remarkable progress in this
task, most of existing solutions are still incapable of effectively capturing
global dependencies to counteract the inductive bias caused by limited
receptive fields. Recently, transformers have been proposed as a promising tool
for global context modeling by employing a powerful global attention mechanism,
but one of their main shortcomings when applied to segmentation tasks is that
they cannot effectively extract sufficient local details to tackle ambiguous
boundaries. We propose a novel boundary-aware transformer (BAT) to
comprehensively address the challenges of automatic skin lesion segmentation.
Specifically, we integrate a new boundary-wise attention gate (BAG) into
transformers to enable the whole network to not only effectively model global
long-range dependencies via transformers but also, simultaneously, capture more
local details by making full use of boundary-wise prior knowledge.
Particularly, the auxiliary supervision of BAG is capable of assisting
transformers to learn position embedding as it provides much spatial
information. We conducted extensive experiments to evaluate the proposed BAT
and experiments corroborate its effectiveness, consistently outperforming
state-of-the-art methods in two famous datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diabetic Retinopathy Screening Using Custom-Designed Convolutional Neural Network. (arXiv:2110.03877v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03877">
<div class="article-summary-box-inner">
<span><p>The prevalence of diabetic retinopathy (DR) has reached 34.6% worldwide and
is a major cause of blindness among middle-aged diabetic patients. Regular DR
screening using fundus photography helps detect its complications and prevent
its progression to advanced levels. As manual screening is time-consuming and
subjective, machine learning (ML) and deep learning (DL) have been employed to
aid graders. However, the existing CNN-based methods use either pre-trained CNN
models or a brute force approach to design new CNN models, which are not
customized to the complexity of fundus images. To overcome this issue, we
introduce an approach for custom-design of CNN models, whose architectures are
adapted to the structural patterns of fundus images and better represent the
DR-relevant features. It takes the leverage of k-medoid clustering, principal
component analysis (PCA), and inter-class and intra-class variations to
automatically determine the depth and width of a CNN model. The designed models
are lightweight, adapted to the internal structures of fundus images, and
encode the discriminative patterns of DR lesions. The technique is validated on
a local dataset from King Saud University Medical City, Saudi Arabia, and two
challenging benchmark datasets from Kaggle: EyePACS and APTOS2019. The
custom-designed models outperform the famous pre-trained CNN models like
ResNet152, Densnet121, and ResNeSt50 with a significant decrease in the number
of parameters and compete well with the state-of-the-art CNN-based DR screening
methods. The proposed approach is helpful for DR screening under diverse
clinical settings and referring the patients who may need further assessment
and treatment to expert ophthalmologists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BDC: Bounding-Box Deep Calibration for High Performance Face Detection. (arXiv:2110.03892v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03892">
<div class="article-summary-box-inner">
<span><p>Modern CNN-based face detectors have achieved tremendous strides due to large
annotated datasets. However, misaligned results with high detection confidence
but low localization accuracy restrict the further improvement of detection
performance. In this paper, we first generate detection results on training set
itself. Surprisingly, a considerable part of them exist the same misalignment
problem. Then, we carefully examine these misaligned cases and point out
annotation inconsistency is the main reason. Finally, we propose a novel
Bounding-Box Deep Calibration (BDC) method to reasonably replace inconsistent
annotations with model predicted bounding-boxes and create a new annotation
file for training set. Extensive experiments on WIDER FACE dataset show the
effectiveness of BDC on improving models' precision and recall rate. Our simple
and effective method provides a new direction for improving face detection.
Source code is available at https://github.com/shiluo1990/BDC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Strokes: Stylized Line Drawing of 3D Shapes. (arXiv:2110.03900v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03900">
<div class="article-summary-box-inner">
<span><p>This paper introduces a model for producing stylized line drawings from 3D
shapes. The model takes a 3D shape and a viewpoint as input, and outputs a
drawing with textured strokes, with variations in stroke thickness,
deformation, and color learned from an artist's style. The model is fully
differentiable. We train its parameters from a single training drawing of
another 3D shape. We show that, in contrast to previous image-based methods,
the use of a geometric representation of 3D shape and 2D strokes allows the
model to transfer important aspects of shape and texture style while preserving
contours. Our method outputs the resulting drawing in a vector representation,
enabling richer downstream analysis or editing in interactive applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-19 Monitoring System using Social Distancing and Face Mask Detection on Surveillance video datasets. (arXiv:2110.03905v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03905">
<div class="article-summary-box-inner">
<span><p>In the current times, the fear and danger of COVID-19 virus still stands
large. Manual monitoring of social distancing norms is impractical with a large
population moving about and with insufficient task force and resources to
administer them. There is a need for a lightweight, robust and 24X7
video-monitoring system that automates this process. This paper proposes a
comprehensive and effective solution to perform person detection, social
distancing violation detection, face detection and face mask classification
using object detection, clustering and Convolution Neural Network (CNN) based
binary classifier. For this, YOLOv3, Density-based spatial clustering of
applications with noise (DBSCAN), Dual Shot Face Detector (DSFD) and
MobileNetV2 based binary classifier have been employed on surveillance video
datasets. This paper also provides a comparative study of different face
detection and face mask classification models. Finally, a video dataset
labelling method is proposed along with the labelled video dataset to
compensate for the lack of dataset in the community and is used for evaluation
of the system. The system performance is evaluated in terms of accuracy, F1
score as well as the prediction time, which has to be low for practical
applicability. The system performs with an accuracy of 91.2% and F1 score of
90.79% on the labelled video dataset and has an average prediction time of 7.12
seconds for 78 frames of a video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Learning with Task-Adaptive Loss Function for Few-Shot Learning. (arXiv:2110.03909v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03909">
<div class="article-summary-box-inner">
<span><p>In few-shot learning scenarios, the challenge is to generalize and perform
well on new unseen examples when only very few labeled examples are available
for each task. Model-agnostic meta-learning (MAML) has gained the popularity as
one of the representative few-shot learning methods for its flexibility and
applicability to diverse problems. However, MAML and its variants often resort
to a simple loss function without any auxiliary loss function or regularization
terms that can help achieve better generalization. The problem lies in that
each application and task may require different auxiliary loss function,
especially when tasks are diverse and distinct. Instead of attempting to
hand-design an auxiliary loss function for each application and task, we
introduce a new meta-learning framework with a loss function that adapts to
each task. Our proposed framework, named Meta-Learning with Task-Adaptive Loss
Function (MeTAL), demonstrates the effectiveness and the flexibility across
various domains, such as few-shot classification and few-shot regression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stereo Dense Scene Reconstruction and Accurate Laparoscope Localization for Learning-Based Navigation in Robot-Assisted Surgery. (arXiv:2110.03912v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03912">
<div class="article-summary-box-inner">
<span><p>The computation of anatomical information and laparoscope position is a
fundamental block of robot-assisted surgical navigation in Minimally Invasive
Surgery (MIS). Recovering a dense 3D structure of surgical scene using visual
cues remains a challenge, and the online laparoscopic tracking mostly relies on
external sensors, which increases system complexity. In this paper, we propose
a learning-driven framework, in which an image-guided laparoscopic localization
with 3D reconstructions of complex anatomical structures is hereby achieved. To
reconstruct the 3D structure of the whole surgical environment, we first
fine-tune a learning-based stereoscopic depth perception method, which is
robust to the texture-less and variant soft tissues, for depth estimation.
Then, we develop a dense visual reconstruction algorithm to represent the scene
by surfels, estimate the laparoscope pose and fuse the depth data into a
unified reference coordinate for tissue reconstruction. To estimate poses of
new laparoscope views, we realize a coarse-to-fine localization method, which
incorporates our reconstructed 3D model. We evaluate the reconstruction method
and the localization module on three datasets, namely, the stereo
correspondence and reconstruction of endoscopic data (SCARED), the ex-vivo
phantom and tissue data collected with Universal Robot (UR) and Karl Storz
Laparoscope, and the in-vivo DaVinci robotic surgery dataset. Extensive
experiments have been conducted to prove the superior performance of our method
in 3D anatomy reconstruction and laparoscopic localization, which demonstrates
its potential implementation to surgical navigation system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SCFlow: Optical Flow Estimation for Spiking Camera. (arXiv:2110.03916v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03916">
<div class="article-summary-box-inner">
<span><p>As a bio-inspired sensor with high temporal resolution, Spiking camera has an
enormous potential in real applications, especially for motion estimation in
high-speed scenes. Optical flow estimation has achieved remarkable success in
image-based and event-based vision, but % existing methods cannot be directly
applied in spike stream from spiking camera. conventional optical flow
algorithms are not well matched to the spike stream data. This paper presents,
SCFlow, a novel deep learning pipeline for optical flow estimation for spiking
camera. Importantly, we introduce an proper input representation of a given
spike stream, which is fed into SCFlow as the sole input. We introduce the
\textit{first} spiking camera simulator (SPCS). Furthermore, based on SPCS, we
first propose two optical flow datasets for spiking camera (SPIkingly Flying
Things and Photo-realistic High-speed Motion, denoted as SPIFT and PHM
respectively) corresponding to random high-speed and well-designed scenes.
Empirically, we show that the SCFlow can predict optical flow from spike stream
in different high-speed scenes, and express superiority to existing methods on
the datasets. \textit{All codes and constructed datasets will be released after
publication}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViDT: An Efficient and Effective Fully Transformer-based Object Detector. (arXiv:2110.03921v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03921">
<div class="article-summary-box-inner">
<span><p>Transformers are transforming the landscape of computer vision, especially
for recognition tasks. Detection transformers are the first fully end-to-end
learning systems for object detection, while vision transformers are the first
fully transformer-based architecture for image classification. In this paper,
we integrate Vision and Detection Transformers (ViDT) to build an effective and
efficient object detector. ViDT introduces a reconfigured attention module to
extend the recent Swin Transformer to be a standalone object detector, followed
by a computationally efficient transformer decoder that exploits multi-scale
features and auxiliary techniques essential to boost the detection performance
without much increase in computational load. Extensive evaluation results on
the Microsoft COCO benchmark dataset demonstrate that ViDT obtains the best AP
and latency trade-off among existing fully transformer-based object detectors,
and achieves 49.2AP owing to its high scalability for large models. We will
release the code and trained models athttps://github.com/naver-ai/vidt
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Directionally Decomposing Structured Light for Projector Calibration. (arXiv:2110.03924v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03924">
<div class="article-summary-box-inner">
<span><p>Intrinsic projector calibration is essential in projection mapping (PM)
applications, especially in dynamic PM. However, due to the shallow
depth-of-field (DOF) of a projector, more work is needed to ensure accurate
calibration. We aim to estimate the intrinsic parameters of a projector while
avoiding the limitation of shallow DOF. As the core of our technique, we
present a practical calibration device that requires a minimal working volume
directly in front of the projector lens regardless of the projector's focusing
distance and aperture size. The device consists of a flat-bed scanner and
pinhole-array masks. For calibration, a projector projects a series of
structured light patterns in the device. The pinholes directionally decompose
the structured light, and only the projected rays that pass through the
pinholes hit the scanner plane. For each pinhole, we extract a ray passing
through the optical center of the projector. Consequently, we regard the
projector as a pinhole projector that projects the extracted rays only, and we
calibrate the projector by applying the standard camera calibration technique,
which assumes a pinhole camera model. Using a proof-of-concept prototype, we
demonstrate that our technique can calibrate projectors with different focusing
distances and aperture sizes at the same accuracy as a conventional method.
Finally, we confirm that our technique can provide intrinsic parameters
accurate enough for a dynamic PM application, even when a projector is placed
too far from a projection target for a conventional method to calibrate the
projector using a fiducial object of reasonable size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pose Refinement with Joint Optimization of Visual Points and Lines. (arXiv:2110.03940v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03940">
<div class="article-summary-box-inner">
<span><p>High-precision camera re-localization technology in a pre-established 3D
environment map is the basis for many tasks, such as Augmented Reality,
Robotics and Autonomous Driving. The point-based visual re-localization
approaches are well-developed in recent decades, but are insufficient in some
feature-less cases. In this paper, we propose a point-line joint optimization
method for pose refinement with the help of the innovatively designed line
extracting CNN named VLSE, and the line matching and pose optimization
approach. We adopt a novel line representation and customize a hybrid
convolutional block based on the Stacked Hourglass network, to detect accurate
and stable line features on images. Then we apply a coarse-to-fine strategy to
obtain precise 2D-3D line correspondences based on the geometric constraint. A
following point-line joint cost function is constructed to optimize the camera
pose with the initial coarse pose. Sufficient experiments are conducted on open
datasets, i.e, line extractor on Wireframe and YorkUrban, localization
performance on Aachen Day-Night v1.1 and InLoc, to confirm the effectiveness of
our point-line joint pose optimization method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GaitPrivacyON: Privacy-Preserving Mobile Gait Biometrics using Unsupervised Learning. (arXiv:2110.03967v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03967">
<div class="article-summary-box-inner">
<span><p>Numerous studies in the literature have already shown the potential of
biometrics on mobile devices for authentication purposes. However, it has been
shown that, the learning processes associated to biometric systems might expose
sensitive personal information about the subjects. This study proposes
GaitPrivacyON, a novel mobile gait biometrics verification approach that
provides accurate authentication results while preserving the sensitive
information of the subject. It comprises two modules: i) a convolutional
Autoencoder that transforms attributes of the biometric raw data, such as the
gender or the activity being performed, into a new privacy-preserving
representation; and ii) a mobile gait verification system based on the
combination of Convolutional Neural Networks (CNNs) and Recurrent Neural
Networks (RNNs) with a Siamese architecture. The main advantage of
GaitPrivacyON is that the first module (convolutional Autoencoder) is trained
in an unsupervised way, without specifying the sensitive attributes of the
subject to protect. The experimental results achieved using two popular
databases (MotionSense and MobiAct) suggest the potential of GaitPrivacyON to
significantly improve the privacy of the subject while keeping user
authentication results higher than 99% Area Under the Curve (AUC). To the best
of our knowledge, this is the first mobile gait verification approach that
considers privacy-preserving methods trained in an unsupervised way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Build a Curb Dataset with LiDAR Data for Autonomous Driving. (arXiv:2110.03968v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03968">
<div class="article-summary-box-inner">
<span><p>Curbs are one of the essential elements of urban and highway traffic
environments. Robust curb detection provides road structure information for
motion planning in an autonomous driving system. Commonly, video cameras and 3D
LiDARs are mounted on autonomous vehicles for curb detection. However,
camera-based methods suffer from challenging illumination conditions. During
the long period of time before wide application of Deep Neural Network (DNN)
with point clouds, LiDAR-based curb detection methods are based on hand-crafted
features, which suffer from poor detection in some complex scenes. Recently,
DNN-based dynamic object detection using LiDAR data has become prevalent, while
few works pay attention to curb detection with a DNN approach due to lack of
labeled data. A dataset with curb annotations or an efficient curb labeling
approach, hence, is of high demand...
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Maximize the Exploration of Congeneric Semantics for Weakly Supervised Semantic Segmentation. (arXiv:2110.03982v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03982">
<div class="article-summary-box-inner">
<span><p>With the increase in the number of image data and the lack of corresponding
labels, weakly supervised learning has drawn a lot of attention recently in
computer vision tasks, especially in the fine-grained semantic segmentation
problem. To alleviate human efforts from expensive pixel-by-pixel annotations,
our method focuses on weakly supervised semantic segmentation (WSSS) with
image-level tags, which are much easier to obtain. As a huge gap exists between
pixel-level segmentation and image-level labels, how to reflect the image-level
semantic information on each pixel is an important question. To explore the
congeneric semantic regions from the same class to the maximum, we construct
the patch-level graph neural network (P-GNN) based on the self-detected patches
from different images that contain the same class labels. Patches can frame the
objects as much as possible and include as little background as possible. The
graph network that is established with patches as the nodes can maximize the
mutual learning of similar objects. We regard the embedding vectors of patches
as nodes, and use transformer-based complementary learning module to construct
weighted edges according to the embedding similarity between different nodes.
Moreover, to better supplement semantic information, we propose
soft-complementary loss functions matched with the whole network structure. We
conduct experiments on the popular PASCAL VOC 2012 benchmarks, and our model
yields state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Feature-Specific Tree Species Identification from Natural Images using Deep Semi-Supervised Learning. (arXiv:2110.03994v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03994">
<div class="article-summary-box-inner">
<span><p>Prior work on plant species classification predominantly focuses on building
models from isolated plant attributes. Hence, there is a need for tools that
can assist in species identification in the natural world. We present a novel
and robust two-fold approach capable of identifying trees in a real-world
natural setting. Further, we leverage unlabelled data through deep
semi-supervised learning and demonstrate superior performance to supervised
learning. Our single-GPU implementation for feature recognition uses minimal
annotated data and achieves accuracies of 93.96% and 93.11% for leaves and
bark, respectively. Further, we extract feature-specific datasets of 50 species
by employing this technique. Finally, our semi-supervised species
classification method attains 94.04% top-5 accuracy for leaves and 83.04% top-5
accuracy for bark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi Proxy Anchor Loss and Effectiveness of Deep Metric Learning Performance Metrics. (arXiv:2110.03997v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03997">
<div class="article-summary-box-inner">
<span><p>Deep metric learning (DML) learns the mapping, which maps into embedding
space in which similar data is near and dissimilar data is far. Most DML
frameworks apply L2 normalization to feature vectors, and these feature vectors
are non-sparse. In this paper, we propose to apply L1 regularization loss to
feature vectors. Proposed regularization emphasizes important features and
restraints unimportant features on L2 normalized features. L1 regularization
can combine with general DML losses because L1 regularization only regularizes
feature vectors. In this paper, we finally propose SparseSoftTriple loss, which
is a combination of SoftTriple loss and L1 regularization. We demonstrate the
effectiveness of the proposed SparseSoftTriple loss on some data sets for image
retrieval tasks and fine-grained images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trident Pyramid Networks: The importance of processing at the feature pyramid level for better object detection. (arXiv:2110.04004v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04004">
<div class="article-summary-box-inner">
<span><p>Feature pyramids have become ubiquitous in multi-scale computer vision tasks
such as object detection. Based on their importance, we divide a computer
vision network into three parts: a backbone (generating a feature pyramid), a
core (refining the feature pyramid) and a head (generating the final output).
Most existing networks operating on feature pyramids, named cores, are shallow
and mostly focus on communication-based processing in the form of top-down and
bottom-up operations. We present a new core architecture called Trident Pyramid
Network (TPN), that allows for a deeper design and for a better balance between
communication-based processing and self-processing. We show consistent
improvements when using our TPN core on the COCO object detection benchmark,
outperforming the popular BiFPN baseline by 1.5 AP. Additionally, we
empirically show that it is more beneficial to put additional computation into
the TPN core, rather than into the backbone, by outperforming a ResNet-101+FPN
baseline with our ResNet-50+TPN network by 1.7 AP, while operating under
similar computation budgets. This emphasizes the importance of performing
computation at the feature pyramid level in modern-day object detection
systems. Code will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An End-to-End Trainable Video Panoptic Segmentation Method usingTransformers. (arXiv:2110.04009v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04009">
<div class="article-summary-box-inner">
<span><p>In this paper, we present an algorithm to tackle a video panoptic
segmentation problem, a newly emerging area of research. The video panoptic
segmentation is a task that unifies the typical task of panoptic segmentation
and multi-object tracking. In other words, it requires generating the instance
tracking IDs along with panoptic segmentation results across video sequences.
Our proposed video panoptic segmentation algorithm uses the transformer and it
can be trained in end-to-end with an input of multiple video frames. We test
our method on the STEP dataset and report its performance with recently
proposed STQ metric. The method archived 57.81\% on the KITTI-STEP dataset and
31.8\% on the MOTChallenge-STEP dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multidirectional Conjugate Gradients for Scalable Bundle Adjustment. (arXiv:2110.04015v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04015">
<div class="article-summary-box-inner">
<span><p>We revisit the problem of large-scale bundle adjustment and propose a
technique called Multidirectional Conjugate Gradients that accelerates the
solution of the normal equation by up to 61%. The key idea is that we enlarge
the search space of classical preconditioned conjugate gradients to include
multiple search directions. As a consequence, the resulting algorithm requires
fewer iterations, leading to a significant speedup of large-scale
reconstruction, in particular for denser problems where traditional approaches
notoriously struggle. We provide a number of experimental ablation studies
revealing the robustness to variations in the hyper-parameters and the speedup
as a function of problem density.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chromatic Aberration Recovery on Arbitrary Images. (arXiv:2110.04030v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04030">
<div class="article-summary-box-inner">
<span><p>Digital imaging sensor technology has continued to outpace development in
optical technology in modern imaging systems. The resulting quality loss
attributable to lateral chromatic aberration is becoming increasingly
significant as sensor resolution increases; other classes of aberration are
less significant with classical image enhancement (e.g. sharpening), whereas
lateral chromatic aberration becomes more significant. The goals of
higher-performance and lighter lens systems drive a recent need to find new
ways to overcome resulting image quality limitations.
</p>
<p>This work demonstrates the robust and automatic minimisation of lateral
chromatic aberration, recovering the loss of image quality using both
artificial and real-world images. A series of test images are used to validate
the functioning of the algorithm, and changes across a series of real-world
images are used to evaluate the performance of the approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniNet: Unified Architecture Search with Convolution, Transformer, and MLP. (arXiv:2110.04035v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04035">
<div class="article-summary-box-inner">
<span><p>Recently, transformer and multi-layer perceptron (MLP) architectures have
achieved impressive results on various vision tasks. A few works investigated
manually combining those operators to design visual network architectures, and
can achieve satisfactory performances to some extent. In this paper, we propose
to jointly search the optimal combination of convolution, transformer, and MLP
for building a series of all-operator network architectures with high
performances on visual tasks. We empirically identify that the widely-used
strided convolution or pooling based down-sampling modules become the
performance bottlenecks when the operators are combined to form a network. To
better tackle the global context captured by the transformer and MLP operators,
we propose two novel context-aware down-sampling modules, which can better
adapt to the global information encoded by transformer and MLP operators. To
this end, we jointly search all operators and down-sampling modules in a
unified search space. Notably, Our searched network UniNet (Unified Network)
outperforms state-of-the-art pure convolution-based architecture, EfficientNet,
and pure transformer-based architecture, Swin-Transformer, on multiple public
visual benchmarks, ImageNet classification, COCO object detection, and ADE20K
semantic segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context-LGM: Leveraging Object-Context Relation for Context-Aware Object Recognition. (arXiv:2110.04042v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04042">
<div class="article-summary-box-inner">
<span><p>Context, as referred to situational factors related to the object of
interest, can help infer the object's states or properties in visual
recognition. As such contextual features are too diverse (across instances) to
be annotated, existing attempts simply exploit image labels as supervision to
learn them, resulting in various contextual tricks, such as features pyramid,
context attention, etc. However, without carefully modeling the context's
properties, especially its relation to the object, their estimated context can
suffer from large inaccuracy. To amend this problem, we propose a novel
Contextual Latent Generative Model (Context-LGM), which considers the
object-context relation and models it in a hierarchical manner. Specifically,
we firstly introduce a latent generative model with a pair of correlated latent
variables to respectively model the object and context, and embed their
correlation via the generative process. Then, to infer contextual features, we
reformulate the objective function of Variational Auto-Encoder (VAE), where
contextual features are learned as a posterior distribution conditioned on the
object. Finally, to implement this contextual posterior, we introduce a
Transformer that takes the object's information as a reference and locates
correlated contextual factors. The effectiveness of our method is verified by
state-of-the-art performance on two context-aware object recognition tasks,
i.e. lung cancer prediction and emotion recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curating Subject ID Labels using Keypoint Signatures. (arXiv:2110.04055v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04055">
<div class="article-summary-box-inner">
<span><p>Subject ID labels are unique, anonymized codes that can be used to group all
images of a subject while maintaining anonymity. ID errors may be inadvertently
introduced manually error during enrollment and may lead to systematic error
into machine learning evaluation (e.g. due to double-dipping) or potential
patient misdiagnosis in clinical contexts. Here we describe a highly efficient
system for curating subject ID labels in large generic medical image datasets,
based on the 3D image keypoint representation, which recently led to the
discovery of previously unknown labeling errors in widely-used public brain MRI
datasets
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Weakly Supervised Learning Approach for Real-time Iron Ore Feed Load Estimation. (arXiv:2110.04063v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04063">
<div class="article-summary-box-inner">
<span><p>Iron ore feed load control is one of the most critical settings in a mineral
grinding process, directly impacting the quality of final products. The setting
of the feed load is mainly determined by the characteristics of the ore
pellets. However, the characterisation of ore is challenging to acquire in many
production environments, leading to poor feed load settings and inefficient
production processes. This paper presents our work using deep learning models
for direct ore feed load estimation from ore pellet images. To address the
challenges caused by the large size of a full ore pellets image and the
shortage of accurately annotated data, we treat the whole modelling process as
a weakly supervised learning problem. A two-stage model training algorithm and
two neural network architectures are proposed. The experiment results show
competitive model performance, and the trained models can be used for real-time
feed load estimation for grind process optimisation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Neural Anthropometer Learning from Body Dimensions Computed on Human 3D Meshes. (arXiv:2110.04064v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04064">
<div class="article-summary-box-inner">
<span><p>Human shape estimation has become increasingly important both theoretically
and practically, for instance, in 3D mesh estimation, distance garment
production and computational forensics, to mention just a few examples. As a
further specialization, \emph{Human Body Dimensions Estimation} (HBDE) focuses
on estimating human body measurements like shoulder width or chest
circumference from images or 3D meshes usually using supervised learning
approaches. The main obstacle in this context is the data scarcity problem, as
collecting this ground truth requires expensive and difficult procedures. This
obstacle can be overcome by obtaining realistic human measurements from 3D
human meshes. However, a) there are no well established methods to calculate
HBDs from 3D meshes and b) there are no benchmarks to fairly compare results on
the HBDE task. Our contribution is twofold. On the one hand, we present a
method to calculate right and left arm length, shoulder width, and inseam
(crotch height) from 3D meshes with focus on potential medical, virtual try-on
and distance tailoring applications. On the other hand, we use four additional
body dimensions calculated using recently published methods to assemble a set
of eight body dimensions which we use as a supervision signal to our Neural
Anthropometer: a convolutional neural network capable of estimating these
dimensions. To assess the estimation, we train the Neural Anthropometer with
synthetic images of 3D meshes, from which we calculated the HBDs and observed
that the network's overall mean estimate error is $20.89$ mm (relative error of
2.84\%). The results we present are fully reproducible and establish a fair
baseline for research on the task of HBDE, therefore enabling the community
with a valuable method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Test-time Batch Statistics Calibration for Covariate Shift. (arXiv:2110.04065v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04065">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have a clear degradation when applying to the unseen
environment due to the covariate shift. Conventional approaches like domain
adaptation requires the pre-collected target data for iterative training, which
is impractical in real-world applications. In this paper, we propose to adapt
the deep models to the novel environment during inference. An previous solution
is test time normalization, which substitutes the source statistics in BN
layers with the target batch statistics. However, we show that test time
normalization may potentially deteriorate the discriminative structures due to
the mismatch between target batch statistics and source parameters. To this
end, we present a general formulation $\alpha$-BN to calibrate the batch
statistics by mixing up the source and target statistics for both alleviating
the domain shift and preserving the discriminative structures. Based on
$\alpha$-BN, we further present a novel loss function to form a unified test
time adaptation framework Core, which performs the pairwise class correlation
online optimization. Extensive experiments show that our approaches achieve the
state-of-the-art performance on total twelve datasets from three topics,
including model robustness to corruptions, domain generalization on image
classification and semantic segmentation. Particularly, our $\alpha$-BN
improves 28.4\% to 43.9\% on GTA5 $\rightarrow$ Cityscapes without any
training, even outperforms the latest source-free domain adaptation method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MToFNet: Object Anti-Spoofing with Mobile Time-of-Flight Data. (arXiv:2110.04066v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04066">
<div class="article-summary-box-inner">
<span><p>In online markets, sellers can maliciously recapture others' images on
display screens to utilize as spoof images, which can be challenging to
distinguish in human eyes. To prevent such harm, we propose an anti-spoofing
method using the paired rgb images and depth maps provided by the mobile camera
with a Time-of-Fight sensor. When images are recaptured on display screens,
various patterns differing by the screens as known as the moir\'e patterns can
be also captured in spoof images. These patterns lead the anti-spoofing model
to be overfitted and unable to detect spoof images recaptured on unseen media.
To avoid the issue, we build a novel representation model composed of two
embedding models, which can be trained without considering the recaptured
images. Also, we newly introduce mToF dataset, the largest and most diverse
object anti-spoofing dataset, and the first to utilize ToF data. Experimental
results confirm that our model achieves robust generalization even across
unseen domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Slap Fingerprint Segmentation for Juveniles and Adults. (arXiv:2110.04067v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04067">
<div class="article-summary-box-inner">
<span><p>Many fingerprint recognition systems capture four fingerprints in one image.
In such systems, the fingerprint processing pipeline must first segment each
four-fingerprint slap into individual fingerprints. Note that most of the
current fingerprint segmentation algorithms have been designed and evaluated
using only adult fingerprint datasets. In this work, we have developed a
human-annotated in-house dataset of 15790 slaps of which 9084 are adult samples
and 6706 are samples drawn from children from ages 4 to 12. Subsequently, the
dataset is used to evaluate the matching performance of the NFSEG, a slap
fingerprint segmentation system developed by NIST, on slaps from adults and
juvenile subjects. Our results reveal the lower performance of NFSEG on slaps
from juvenile subjects. Finally, we utilized our novel dataset to develop the
Mask-RCNN based Clarkson Fingerprint Segmentation (CFSEG). Our matching results
using the Verifinger fingerprint matcher indicate that CFSEG outperforms NFSEG
for both adults and juvenile slaps. The CFSEG model is publicly available at
\url{https://github.com/keivanB/Clarkson_Finger_Segment}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BI-RADS-Net: An Explainable Multitask Learning Approach for Cancer Diagnosis in Breast Ultrasound Images. (arXiv:2110.04069v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04069">
<div class="article-summary-box-inner">
<span><p>In healthcare, it is essential to explain the decision-making process of
machine learning models to establish the trustworthiness of clinicians. This
paper introduces BI-RADS-Net, a novel explainable deep learning approach for
cancer detection in breast ultrasound images. The proposed approach
incorporates tasks for explaining and classifying breast tumors, by learning
feature representations relevant to clinical diagnosis. Explanations of the
predictions (benign or malignant) are provided in terms of morphological
features that are used by clinicians for diagnosis and reporting in medical
practice. The employed features include the BI-RADS descriptors of shape,
orientation, margin, echo pattern, and posterior features. Additionally, our
approach predicts the likelihood of malignancy of the findings, which relates
to the BI-RADS assessment category reported by clinicians. Experimental
validation on a dataset consisting of 1,192 images indicates improved model
accuracy, supported by explanations in clinical terms using the BI-RADS
lexicon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dataset Structural Index: Understanding a machine's perspective towards visual data. (arXiv:2110.04070v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04070">
<div class="article-summary-box-inner">
<span><p>With advances in vision and perception architectures, we have realized that
working with data is equally crucial, if not more, than the algorithms. Till
today, we have trained machines based on our knowledge and perspective of the
world. The entire concept of Dataset Structural Index(DSI) revolves around
understanding a machine`s perspective of the dataset. With DSI, I show two meta
values with which we can get more information over a visual dataset and use it
to optimize data, create better architectures, and have an ability to guess
which model would work best. These two values are the Variety contribution
ratio and Similarity matrix. In the paper, I show many applications of DSI, one
of which is how the same level of accuracy can be achieved with the same model
architectures trained over less amount of data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KOHTD: Kazakh Offline Handwritten Text Dataset. (arXiv:2110.04075v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04075">
<div class="article-summary-box-inner">
<span><p>Despite the transition to digital information exchange, many documents, such
as invoices, taxes, memos and questionnaires, historical data, and answers to
exam questions, still require handwritten inputs. In this regard, there is a
need to implement Handwritten Text Recognition (HTR) which is an automatic way
to decrypt records using a computer. Handwriting recognition is challenging
because of the virtually infinite number of ways a person can write the same
message. For this proposal we introduce Kazakh handwritten text recognition
research, a comprehensive dataset of Kazakh handwritten texts is necessary.
This is particularly true given the lack of a dataset for handwritten Kazakh
text. In this paper, we proposed our extensive Kazakh offline Handwritten Text
dataset (KOHTD), which has 3000 handwritten exam papers and more than 140335
segmented images and there are approximately 922010 symbols. It can serve
researchers in the field of handwriting recognition tasks by using deep and
machine learning. We used a variety of popular text recognition methods for
word and line recognition in our studies, including CTC-based and
attention-based methods. The findings demonstrate KOHTD's diversity. Also, we
proposed a Genetic Algorithm (GA) for line and word segmentation based on
random enumeration of a parameter. The dataset and GA code are available at
https://github.com/abdoelsayed2016/KOHTD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Point Cloud Prediction Using 3D Spatio-temporal Convolutional Networks. (arXiv:2110.04076v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04076">
<div class="article-summary-box-inner">
<span><p>Exploiting past 3D LiDAR scans to predict future point clouds is a promising
method for autonomous mobile systems to realize foresighted state estimation,
collision avoidance, and planning. In this paper, we address the problem of
predicting future 3D LiDAR point clouds given a sequence of past LiDAR scans.
Estimating the future scene on the sensor level does not require any preceding
steps as in localization or tracking systems and can be trained
self-supervised. We propose an end-to-end approach that exploits a 2D range
image representation of each 3D LiDAR scan and concatenates a sequence of range
images to obtain a 3D tensor. Based on such tensors, we develop an
encoder-decoder architecture using 3D convolutions to jointly aggregate spatial
and temporal information of the scene and to predict the future 3D point
clouds. We evaluate our method on multiple datasets and the experimental
results suggest that our method outperforms existing point cloud prediction
architectures and generalizes well to new, unseen environments without
additional fine-tuning. Our method operates online and is faster than the
common LiDAR frame rate of 10 Hz.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Physical Context and Timing Aware Sequence Generating GANs. (arXiv:2110.04077v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04077">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GANs) have shown remarkable successes in
generating realistic images and interpolating changes between images. Existing
models, however, do not take into account physical contexts behind images in
generating the images, which may cause unrealistic changes. Furthermore, it is
difficult to generate the changes at a specific timing and they often do not
match with actual changes. This paper proposes a novel GAN, named Physical
Context and Timing aware sequence generating GANs (PCTGAN), that generates an
image in a sequence at a specific timing between two images with considering
physical contexts behind them. Our method consists of three components: an
encoder, a generator, and a discriminator. The encoder estimates latent vectors
from the beginning and ending images, their timings, and a target timing. The
generator generates images and the physical contexts at the beginning, ending,
and target timing from the corresponding latent vectors. The discriminator
discriminates whether the generated images and contexts are real or not. In the
experiments, PCTGAN is applied to a data set of sequential changes of shapes in
die forging processes. We show that both timing and physical contexts are
effective in generating sequential images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Hybrid Spatial-temporal Sequence-to-one Neural Network Model for Lane Detection. (arXiv:2110.04079v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04079">
<div class="article-summary-box-inner">
<span><p>Reliable and accurate lane detection is of vital importance for the safe
performance of Lane Keeping Assistance and Lane Departure Warning systems.
However, under certain challenging peculiar circumstances (e.g., marking
degradation, serious vehicle occlusion), it is difficult to get satisfactory
performance in accurately detecting the lane markings from one single image
which is often the case in current literature. Since road markings are
continuous lines on the road, the lanes that are difficult to be accurately
detected in the current image frame might potentially be better inferred out if
information from previous frames is incorporated. For this, we propose a novel
hybrid spatial-temporal sequence-to-one deep learning architecture making full
use of the spatial-temporal information in multiple frames of a continuous
sequence of images to detect lane markings in the very last current image
frame. Specifically, the hybrid model integrates the spatial convolutional
neural network (SCNN), which is powerful in extracting spatial features and
relationships in one single image, with convolutional long-short term memory
(ConvLSTM) neural network, which can capture the spatial-temporal correlations
and time dependencies among the image sequences. With the proposed model
architecture, the advantages of both SCNN and ConvLSTM are fully combined and
the spatial-temporal information is fully exploited. Treating lane detection as
the image segmentation problem, we applied encoder-decoder structures to make
it work in an end-to-end way. Extensive experiments on two large-scale datasets
reveal that our proposed model can effectively handle challenging driving
scenes and outperforms previous state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Landslide Detection in Real-Time Social Media Image Streams. (arXiv:2110.04080v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04080">
<div class="article-summary-box-inner">
<span><p>Lack of global data inventories obstructs scientific modeling of and response
to landslide hazards which are oftentimes deadly and costly. To remedy this
limitation, new approaches suggest solutions based on citizen science that
requires active participation. However, as a non-traditional data source,
social media has been increasingly used in many disaster response and
management studies in recent years. Inspired by this trend, we propose to
capitalize on social media data to mine landslide-related information
automatically with the help of artificial intelligence (AI) techniques.
Specifically, we develop a state-of-the-art computer vision model to detect
landslides in social media image streams in real time. To that end, we create a
large landslide image dataset labeled by experts and conduct extensive model
training experiments. The experimental results indicate that the proposed model
can be deployed in an online fashion to support global landslide susceptibility
maps and emergency response.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flow Plugin Network for conditional generation. (arXiv:2110.04081v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04081">
<div class="article-summary-box-inner">
<span><p>Generative models have gained many researchers' attention in the last years
resulting in models such as StyleGAN for human face generation or PointFlow for
the 3D point cloud generation. However, by default, we cannot control its
sampling process, i.e., we cannot generate a sample with a specific set of
attributes. The current approach is model retraining with additional inputs and
different architecture, which requires time and computational resources. We
propose a novel approach that enables to a generation of objects with a given
set of attributes without retraining the base model. For this purpose, we
utilize the normalizing flow models - Conditional Masked Autoregressive Flow
and Conditional Real NVP, as a Flow Plugin Network (FPN).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discover, Hallucinate, and Adapt: Open Compound Domain Adaptation for Semantic Segmentation. (arXiv:2110.04111v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04111">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation (UDA) for semantic segmentation has been
attracting attention recently, as it could be beneficial for various
label-scarce real-world scenarios (e.g., robot control, autonomous driving,
medical imaging, etc.). Despite the significant progress in this field, current
works mainly focus on a single-source single-target setting, which cannot
handle more practical settings of multiple targets or even unseen targets. In
this paper, we investigate open compound domain adaptation (OCDA), which deals
with mixed and novel situations at the same time, for semantic segmentation. We
present a novel framework based on three main design principles: discover,
hallucinate, and adapt. The scheme first clusters compound target data based on
style, discovering multiple latent domains (discover). Then, it hallucinates
multiple latent target domains in source by using image-translation
(hallucinate). This step ensures the latent domains in the source and the
target to be paired. Finally, target-to-source alignment is learned separately
between domains (adapt). In high-level, our solution replaces a hard OCDA
problem with much easier multiple UDA problems. We evaluate our solution on
standard benchmark GTA to C-driving, and achieved new state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-viewpoint Outdoor Dataset for Human Action Recognition. (arXiv:2110.04119v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04119">
<div class="article-summary-box-inner">
<span><p>Advancements in deep neural networks have contributed to near perfect results
for many computer vision problems such as object recognition, face recognition
and pose estimation. However, human action recognition is still far from
human-level performance. Owing to the articulated nature of the human body, it
is challenging to detect an action from multiple viewpoints, particularly from
an aerial viewpoint. This is further compounded by a scarcity of datasets that
cover multiple viewpoints of actions. To fill this gap and enable research in
wider application areas, we present a multi-viewpoint outdoor action
recognition dataset collected from YouTube and our own drone. The dataset
consists of 20 dynamic human action classes, 2324 video clips and 503086
frames. All videos are cropped and resized to 720x720 without distorting the
original aspect ratio of the human subjects in videos. This dataset should be
useful to many research areas including action recognition, surveillance and
situational awareness. We evaluated the dataset with a two-stream CNN
architecture coupled with a recently proposed temporal pooling scheme called
kernelized rank pooling that produces nonlinear feature subspace
representations. The overall baseline action recognition accuracy is 74.0%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rapid head-pose detection for automated slice prescription of fetal-brain MRI. (arXiv:2110.04140v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04140">
<div class="article-summary-box-inner">
<span><p>In fetal-brain MRI, head-pose changes between prescription and acquisition
present a challenge to obtaining the standard sagittal, coronal and axial views
essential to clinical assessment. As motion limits acquisitions to thick slices
that preclude retrospective resampling, technologists repeat ~55-second
stack-of-slices scans (HASTE) with incrementally reoriented field of view
numerous times, deducing the head pose from previous stacks. To address this
inefficient workflow, we propose a robust head-pose detection algorithm using
full-uterus scout scans (EPI) which take ~5 seconds to acquire. Our ~2-second
procedure automatically locates the fetal brain and eyes, which we derive from
maximally stable extremal regions (MSERs). The success rate of the method
exceeds 94% in the third trimester, outperforming a trained technologist by up
to 20%. The pipeline may be used to automatically orient the anatomical
sequence, removing the need to estimate the head pose from 2D views and
reducing delays during which motion can occur.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainability-Aware One Point Attack for Point Cloud Neural Networks. (arXiv:2110.04158v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04158">
<div class="article-summary-box-inner">
<span><p>With the proposition of neural networks for point clouds, deep learning has
started to shine in the field of 3D object recognition while researchers have
shown an increased interest to investigate the reliability of point cloud
networks by fooling them with perturbed instances. However, most studies focus
on the imperceptibility or surface consistency, with humans perceiving no
perturbations on the adversarial examples. This work proposes two new attack
methods: opa and cta, which go in the opposite direction: we restrict the
perturbation dimensions to a human cognizable range with the help of
explainability methods, which enables the working principle or decision
boundary of the models to be comprehensible through the observable perturbation
magnitude. Our results show that the popular point cloud networks can be
deceived with almost 100% success rate by shifting only one point from the
input instance. In addition, we attempt to provide a more persuasive viewpoint
of comparing the robustness of point cloud models against adversarial attacks.
We also show the interesting impact of different point attribution
distributions on the adversarial robustness of point cloud networks. Finally,
we discuss how our approaches facilitate the explainability study for point
cloud networks. To the best of our knowledge, this is the first
point-cloud-based adversarial approach concerning explainability. Our code is
available at https://github.com/Explain3D/Exp-One-Point-Atk-PC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Image Alignment for Vehicle Localization. (arXiv:2110.04162v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04162">
<div class="article-summary-box-inner">
<span><p>Accurate and reliable localization is a fundamental requirement for
autonomous vehicles to use map information in higher-level tasks such as
navigation or planning. In this paper, we present a novel approach to vehicle
localization in dense semantic maps, including vectorized high-definition maps
or 3D meshes, using semantic segmentation from a monocular camera. We formulate
the localization task as a direct image alignment problem on semantic images,
which allows our approach to robustly track the vehicle pose in semantically
labeled maps by aligning virtual camera views rendered from the map to
sequences of semantically segmented camera images. In contrast to existing
visual localization approaches, the system does not require additional keypoint
features, handcrafted localization landmark extractors or expensive LiDAR
sensors. We demonstrate the wide applicability of our method on a diverse set
of semantic mesh maps generated from stereo or LiDAR as well as manually
annotated HD maps and show that it achieves reliable and accurate localization
in real-time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lightweight Convolutional Neural Networks By Hypercomplex Parameterization. (arXiv:2110.04176v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04176">
<div class="article-summary-box-inner">
<span><p>Hypercomplex neural networks have proved to reduce the overall number of
parameters while ensuring valuable performances by leveraging the properties of
Clifford algebras. Recently, hypercomplex linear layers have been further
improved by involving efficient parameterized Kronecker products. In this
paper, we define the parameterization of hypercomplex convolutional layers to
develop lightweight and efficient large-scale convolutional models. Our method
grasps the convolution rules and the filters organization directly from data
without requiring a rigidly predefined domain structure to follow. The proposed
approach is flexible to operate in any user-defined or tuned domain, from 1D to
$n$D regardless of whether the algebra rules are preset. Such a malleability
allows processing multidimensional inputs in their natural domain without
annexing further dimensions, as done, instead, in quaternion neural networks
for 3D inputs like color images. As a result, the proposed method operates with
$1/n$ free parameters as regards its analog in the real domain. We demonstrate
the versatility of this approach to multiple domains of application by
performing experiments on various image datasets as well as audio datasets in
which our method outperforms real and quaternion-valued counterparts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dataset Condensation with Distribution Matching. (arXiv:2110.04181v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04181">
<div class="article-summary-box-inner">
<span><p>Computational cost to train state-of-the-art deep models in many learning
problems is rapidly increasing due to more sophisticated models and larger
datasets. A recent promising direction to reduce training time is dataset
condensation that aims to replace the original large training set with a
significantly smaller learned synthetic set while preserving its information.
While training deep models on the small set of condensed images can be
extremely fast, their synthesis remains computationally expensive due to the
complex bi-level optimization and second-order derivative computation. In this
work, we propose a simple yet effective dataset condensation technique that
requires significantly lower training cost with comparable performance by
matching feature distributions of the synthetic and original training images in
sampled embedding spaces. Thanks to its efficiency, we apply our method to more
realistic and larger datasets with sophisticated neural architectures and
achieve a significant performance boost while using larger synthetic training
set. We also show various practical benefits of our method in continual
learning and neural architecture search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation. (arXiv:2110.04202v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04202">
<div class="article-summary-box-inner">
<span><p>Domain adaptation (DA) aims to alleviate the domain shift between source
domain and target domain. Most DA methods require access to the source data,
but often that is not possible (e.g. due to data privacy or intellectual
property). In this paper, we address the challenging source-free domain
adaptation (SFDA) problem, where the source pretrained model is adapted to the
target domain in the absence of source data. Our method is based on the
observation that target data, which might no longer align with the source
domain classifier, still forms clear clusters. We capture this intrinsic
structure by defining local affinity of the target data, and encourage label
consistency among data with high local affinity. We observe that higher
affinity should be assigned to reciprocal neighbors, and propose a self
regularization loss to decrease the negative impact of noisy neighbors.
Furthermore, to aggregate information with more context, we consider expanded
neighborhoods with small affinity values. In the experimental results we verify
that the inherent structure of the target features is an important source of
information for domain adaptation. We demonstrate that this local structure can
be efficiently captured by considering the local neighbors, the reciprocal
neighbors, and the expanded neighborhood. Finally, we achieve state-of-the-art
performance on several 2D image and 3D point cloud recognition datasets. Code
is available in https://github.com/Albert0147/SFDA_neighbors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward a Human-Level Video Understanding Intelligence. (arXiv:2110.04203v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04203">
<div class="article-summary-box-inner">
<span><p>We aim to develop an AI agent that can watch video clips and have a
conversation with human about the video story. Developing video understanding
intelligence is a significantly challenging task, and evaluation methods for
adequately measuring and analyzing the progress of AI agent are lacking as
well. In this paper, we propose the Video Turing Test to provide effective and
practical assessments of video understanding intelligence as well as
human-likeness evaluation of AI agents. We define a general format and
procedure of the Video Turing Test and present a case study to confirm the
effectiveness and usefulness of the proposed test.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inferring Offensiveness In Images From Natural Language Supervision. (arXiv:2110.04222v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04222">
<div class="article-summary-box-inner">
<span><p>Probing or fine-tuning (large-scale) pre-trained models results in
state-of-the-art performance for many NLP tasks and, more recently, even for
computer vision tasks when combined with image data. Unfortunately, these
approaches also entail severe risks. In particular, large image datasets
automatically scraped from the web may contain derogatory terms as categories
and offensive images, and may also underrepresent specific classes.
Consequently, there is an urgent need to carefully document datasets and curate
their content. Unfortunately, this process is tedious and error-prone. We show
that pre-trained transformers themselves provide a methodology for the
automated curation of large-scale vision datasets. Based on human-annotated
examples and the implicit knowledge of a CLIP based model, we demonstrate that
one can select relevant prompts for rating the offensiveness of an image. In
addition to e.g. privacy violation and pornographic content previously
identified in ImageNet, we demonstrate that our approach identifies further
inappropriate and potentially offensive content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Observations on K-image Expansion of Image-Mixing Augmentation for Classification. (arXiv:2110.04248v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04248">
<div class="article-summary-box-inner">
<span><p>Image-mixing augmentations (e.g., Mixup or CutMix), which typically mix two
images, have become de-facto training tricks for image classification. Despite
their huge success on image classification, the number of images to mix has not
been profoundly investigated by the previous works, only showing the naive
K-image expansion leads to poor performance degradation. This paper derives a
new K-image mixing augmentation based on the stick-breaking process under
Dirichlet prior. We show that our method can train more robust and generalized
classifiers through extensive experiments and analysis on classification
accuracy, a shape of a loss landscape and adversarial robustness, than the
usual two-image methods. Furthermore, we show that our probabilistic model can
measure the sample-wise uncertainty and can boost the efficiency for Network
Architecture Search (NAS) with 7x reduced search time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active learning for interactive satellite image change detection. (arXiv:2110.04250v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04250">
<div class="article-summary-box-inner">
<span><p>We introduce in this paper a novel active learning algorithm for satellite
image change detection. The proposed solution is interactive and based on a
question and answer model, which asks an oracle (annotator) the most
informative questions about the relevance of sampled satellite image pairs, and
according to the oracle's responses, updates a decision function iteratively.
We investigate a novel framework which models the probability that samples are
relevant; this probability is obtained by minimizing an objective function
capturing representativity, diversity and ambiguity. Only data with a high
probability according to these criteria are selected and displayed to the
oracle for further annotation. Extensive experiments on the task of satellite
image change detection after natural hazards (namely tornadoes) show the
relevance of the proposed method against the related work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LCS: Learning Compressible Subspaces for Adaptive Network Compression at Inference Time. (arXiv:2110.04252v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04252">
<div class="article-summary-box-inner">
<span><p>When deploying deep learning models to a device, it is traditionally assumed
that available computational resources (compute, memory, and power) remain
static. However, real-world computing systems do not always provide stable
resource guarantees. Computational resources need to be conserved when load
from other processes is high or battery power is low. Inspired by recent works
on neural network subspaces, we propose a method for training a "compressible
subspace" of neural networks that contains a fine-grained spectrum of models
that range from highly efficient to highly accurate. Our models require no
retraining, thus our subspace of models can be deployed entirely on-device to
allow adaptive network compression at inference time. We present results for
achieving arbitrarily fine-grained accuracy-efficiency trade-offs at inference
time for structured and unstructured sparsity. We achieve accuracies on-par
with standard models when testing our uncompressed models, and maintain high
accuracy for sparsity rates above 90% when testing our compressed models. We
also demonstrate that our algorithm extends to quantization at variable bit
widths, achieving accuracy on par with individually trained networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StairwayGraphNet for Inter- and Intra-modality Multi-resolution Brain Graph Alignment and Synthesis. (arXiv:2110.04279v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04279">
<div class="article-summary-box-inner">
<span><p>Synthesizing multimodality medical data provides complementary knowledge and
helps doctors make precise clinical decisions. Although promising, existing
multimodal brain graph synthesis frameworks have several limitations. First,
they mainly tackle only one problem (intra- or inter-modality), limiting their
generalizability to synthesizing inter- and intra-modality simultaneously.
Second, while few techniques work on super-resolving low-resolution brain
graphs within a single modality (i.e., intra), inter-modality graph
super-resolution remains unexplored though this would avoid the need for costly
data collection and processing. More importantly, both target and source
domains might have different distributions, which causes a domain fracture
between them. To fill these gaps, we propose a multi-resolution
StairwayGraphNet (SG-Net) framework to jointly infer a target graph modality
based on a given modality and super-resolve brain graphs in both inter and
intra domains. Our SG-Net is grounded in three main contributions: (i)
predicting a target graph from a source one based on a novel graph generative
adversarial network in both inter (e.g., morphological-functional) and intra
(e.g., functional-functional) domains, (ii) generating high-resolution brain
graphs without resorting to the time consuming and expensive MRI processing
steps, and (iii) enforcing the source distribution to match that of the ground
truth graphs using an inter-modality aligner to relax the loss function to
optimize. Moreover, we design a new Ground Truth-Preserving loss function to
guide both generators in learning the topological structure of ground truth
brain graphs more accurately. Our comprehensive experiments on predicting
target brain graphs from source graphs using a multi-resolution stairway showed
the outperformance of our method in comparison with its variants and
state-of-the-art method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collaging Class-specific GANs for Semantic Image Synthesis. (arXiv:2110.04281v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04281">
<div class="article-summary-box-inner">
<span><p>We propose a new approach for high resolution semantic image synthesis. It
consists of one base image generator and multiple class-specific generators.
The base generator generates high quality images based on a segmentation map.
To further improve the quality of different objects, we create a bank of
Generative Adversarial Networks (GANs) by separately training class-specific
models. This has several benefits including -- dedicated weights for each
class; centrally aligned data for each model; additional training data from
other sources, potential of higher resolution and quality; and easy
manipulation of a specific object in the scene. Experiments show that our
approach can generate high quality images in high resolution while having
flexibility of object-level control by using class-specific generators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Field Extraction from Forms with Unlabeled Data. (arXiv:2110.04282v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04282">
<div class="article-summary-box-inner">
<span><p>We propose a novel framework to conduct field extraction from forms with
unlabeled data. To bootstrap the training process, we develop a rule-based
method for mining noisy pseudo-labels from unlabeled forms. Using the
supervisory signal from the pseudo-labels, we extract a discriminative token
representation from a transformer-based model by modeling the interaction
between text in the form. To prevent the model from overfitting to label noise,
we introduce a refinement module based on a progressive pseudo-label ensemble.
Experimental results demonstrate the effectiveness of our framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward a Visual Concept Vocabulary for GAN Latent Space. (arXiv:2110.04292v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04292">
<div class="article-summary-box-inner">
<span><p>A large body of recent work has identified transformations in the latent
spaces of generative adversarial networks (GANs) that consistently and
interpretably transform generated images. But existing techniques for
identifying these transformations rely on either a fixed vocabulary of
pre-specified visual concepts, or on unsupervised disentanglement techniques
whose alignment with human judgments about perceptual salience is unknown. This
paper introduces a new method for building open-ended vocabularies of primitive
visual concepts represented in a GAN's latent space. Our approach is built from
three components: (1) automatic identification of perceptually salient
directions based on their layer selectivity; (2) human annotation of these
directions with free-form, compositional natural language descriptions; and (3)
decomposition of these annotations into a visual concept vocabulary, consisting
of distilled directions labeled with single words. Experiments show that
concepts learned with our approach are reliable and composable -- generalizing
across classes, contexts, and observers, and enabling fine-grained manipulation
of image style and content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">2nd Place Solution to Google Landmark Retrieval 2021. (arXiv:2110.04294v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04294">
<div class="article-summary-box-inner">
<span><p>This paper presents the 2nd place solution to the Google Landmark Retrieval
2021 Competition on Kaggle. The solution is based on a baseline with training
tricks from person re-identification, a continent-aware sampling strategy is
presented to select training images according to their country tags and a
Landmark-Country aware reranking is proposed for the retrieval task. With these
contributions, we achieve 0.52995 mAP@100 on private leaderboard. Code
available at
https://github.com/WesleyZhang1991/Google_Landmark_Retrieval_2021_2nd_Place_Solution
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep localization of protein structures in fluorescence microscopy images. (arXiv:1910.04287v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.04287">
<div class="article-summary-box-inner">
<span><p>Accurate localization of proteins from fluorescence microscopy images is
challenging due to the inter-class similarities and intra-class disparities
introducing grave concerns in addressing multi-class classification problems.
Conventional machine learning-based image prediction pipelines rely heavily on
pre-processing such as normalization and segmentation followed by hand-crafted
feature extraction to identify useful, informative, and application-specific
features. Here, we demonstrate that deep learning-based pipelines can
effectively classify protein images from different datasets. We propose an
end-to-end Protein Localization Convolutional Neural Network (PLCNN) that
classifies protein images more accurately and reliably. PLCNN processes raw
imagery without involving any pre-processing steps and produces outputs without
any customization or parameter adjustment for a particular dataset.
Experimental analysis is performed on five benchmark datasets. PLCNN
consistently outperformed the existing state-of-the-art approaches from
traditional machine learning and deep architectures. This study highlights the
importance of deep learning for the analysis of fluorescence microscopy protein
imagery. The proposed deep pipeline can better guide drug designing procedures
in the pharmaceutical industry and open new avenues for researchers in
computational biology and bioinformatics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SynthMorph: learning contrast-invariant registration without acquired images. (arXiv:2004.10282v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.10282">
<div class="article-summary-box-inner">
<span><p>We introduce a strategy for learning image registration without acquired
imaging data, producing powerful networks agnostic to contrast introduced by
magnetic resonance imaging (MRI). While classical registration methods
accurately estimate the spatial correspondence between images, they solve an
optimization problem for every new image pair. Learning-based techniques are
fast at test time but limited to registering images with contrasts and
geometric content similar to those seen during training. We propose to remove
this dependency on training data by leveraging a generative strategy for
diverse synthetic label maps and images that exposes networks to a wide range
of variability, forcing them to learn more invariant features. This approach
results in powerful networks that accurately generalize to a broad array of MRI
contrasts. We present extensive experiments with a focus on 3D neuroimaging,
showing that this strategy enables robust and accurate registration of
arbitrary MRI contrasts even if the target contrast is not seen by the networks
during training. We demonstrate registration accuracy surpassing the state of
the art both within and across contrasts, using a single model. Critically,
training on arbitrary shapes synthesized from noise distributions results in
competitive performance, removing the dependency on acquired data of any kind.
Additionally, since anatomical label maps are often available for the anatomy
of interest, we show that synthesizing images from these dramatically boosts
performance, while still avoiding the need for real intensity images. Our code
is available at https://w3id.org/synthmorph.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Appearance-free Tripartite Matching for Multiple Object Tracking. (arXiv:2008.03628v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03628">
<div class="article-summary-box-inner">
<span><p>Multiple Object Tracking (MOT) detects the trajectories of multiple objects
given an input video. It has become more and more important for various
research and industry areas, such as cell tracking for biomedical research and
human tracking in video surveillance. Most existing algorithms depend on the
uniqueness of the object's appearance, and the dominating bipartite matching
scheme ignores the speed smoothness. Although several methods have incorporated
the velocity smoothness for tracking, they either fail to pursue global smooth
velocity or are often trapped in local optimums. We focus on the general MOT
problem regardless of the appearance and propose an appearance-free tripartite
matching to avoid the irregular velocity problem of the bipartite matching. The
tripartite matching is formulated as maximizing the likelihood of the state
vectors constituted of the position and velocity of objects, which results in a
chain-dependent structure. We resort to the dynamic programming algorithm to
find such a maximum likelihood estimate. To overcome the high computational
cost induced by the vast search space of dynamic programming when many objects
are to be tracked, we decompose the space by the number of disappearing objects
and propose a reduced-space approach by truncating the decomposition. Extensive
simulations have shown the superiority and efficiency of our proposed method,
and the comparisons with top methods on Cell Tracking Challenge also
demonstrate our competence. We also applied our method to track the motion of
natural killer cells around tumor cells in a cancer study.\footnote{The source
code is available on \url{https://github.com/szcf-weiya/TriMatchMOT}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Selective Combinatorial Embedding and Consistency Regularization for Light Field Super-resolution. (arXiv:2009.12537v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12537">
<div class="article-summary-box-inner">
<span><p>Light field (LF) images acquired by hand-held devices usually suffer from low
spatial resolution as the limited detector resolution has to be shared with the
angular dimension. LF spatial super-resolution (SR) thus becomes an
indispensable part of the LF camera processing pipeline. The
high-dimensionality characteristic and complex geometrical structure of LF
images make the problem more challenging than traditional single-image SR. The
performance of existing methods is still limited as they fail to thoroughly
explore the coherence among LF sub-aperture images (SAIs) and are insufficient
in accurately preserving the scene's parallax structure. To tackle this
challenge, we propose a novel learning-based LF spatial SR framework.
Specifically, each SAI of an LF image is first coarsely and individually
super-resolved by exploring the complementary information among SAIs with
selective combinatorial geometry embedding. To achieve efficient and effective
selection of the complementary information, we propose two novel sub-modules
conducted hierarchically: the patch selector provides an option of retrieving
similar image patches based on offline disparity estimation to handle
large-disparity correlations; and the SAI selector adaptively and flexibly
selects the most informative SAIs to improve the embedding efficiency. To
preserve the parallax structure among the reconstructed SAIs, we subsequently
append a consistency regularization network trained over a structure-aware loss
function to refine the parallax relationships over the coarse estimation. In
addition, we extend the proposed method to irregular LF data. To the best of
our knowledge, this is the first learning-based SR method for irregular LF
data. Experimental results over both synthetic and real-world LF datasets
demonstrate the significant advantage of our approach over state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptation in LiDAR Semantic Segmentation by Aligning Class Distributions. (arXiv:2010.12239v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12239">
<div class="article-summary-box-inner">
<span><p>LiDAR semantic segmentation provides 3D semantic information about the
environment, an essential cue for intelligent systems during their decision
making processes. Deep neural networks are achieving state-of-the-art results
on large public benchmarks on this task. Unfortunately, finding models that
generalize well or adapt to additional domains, where data distribution is
different, remains a major challenge. This work addresses the problem of
unsupervised domain adaptation for LiDAR semantic segmentation models. Our
approach combines novel ideas on top of the current state-of-the-art approaches
and yields new state-of-the-art results. We propose simple but effective
strategies to reduce the domain shift by aligning the data distribution on the
input space. Besides, we propose a learning-based approach that aligns the
distribution of the semantic classes of the target domain to the source domain.
The presented ablation study shows how each part contributes to the final
performance. Our strategy is shown to outperform previous approaches for domain
adaptation with comparisons run on three different domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skeleton-based Relational Reasoning for Group Activity Analysis. (arXiv:2011.05653v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05653">
<div class="article-summary-box-inner">
<span><p>Research on group activity recognition mostly leans on the standard
two-stream approach (RGB and Optical Flow) as their input features. Few have
explored explicit pose information, with none using it directly to reason about
the persons interactions. In this paper, we leverage the skeleton information
to learn the interactions between the individuals straight from it. With our
proposed method GIRN, multiple relationship types are inferred from independent
modules, that describe the relations between the body joints pair-by-pair.
Additionally to the joints relations, we also experiment with the previously
unexplored relationship between individuals and relevant objects (e.g.
volleyball). The individuals distinct relations are then merged through an
attention mechanism, that gives more importance to those individuals more
relevant for distinguishing the group activity. We evaluate our method in the
Volleyball dataset, obtaining competitive results to the state-of-the-art. Our
experiments demonstrate the potential of skeleton-based approaches for modeling
multi-person interactions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Train Neural Networks for Flare Removal. (arXiv:2011.12485v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12485">
<div class="article-summary-box-inner">
<span><p>When a camera is pointed at a strong light source, the resulting photograph
may contain lens flare artifacts. Flares appear in a wide variety of patterns
(halos, streaks, color bleeding, haze, etc.) and this diversity in appearance
makes flare removal challenging. Existing analytical solutions make strong
assumptions about the artifact's geometry or brightness, and therefore only
work well on a small subset of flares. Machine learning techniques have shown
success in removing other types of artifacts, like reflections, but have not
been widely applied to flare removal due to the lack of training data. To solve
this problem, we explicitly model the optical causes of flare either
empirically or using wave optics, and generate semi-synthetic pairs of
flare-corrupted and clean images. This enables us to train neural networks to
remove lens flare for the first time. Experiments show our data synthesis
approach is critical for accurate flare removal, and that models trained with
our technique generalize well to real lens flares across different scenes,
lighting conditions, and cameras.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study of the Collapsing Problem in Semi-Supervised 2D Human Pose Estimation. (arXiv:2011.12498v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12498">
<div class="article-summary-box-inner">
<span><p>Semi-supervised learning aims to boost the accuracy of a model by exploring
unlabeled images. The state-of-the-art methods are consistency-based which
learn about unlabeled images by encouraging the model to give consistent
predictions for images under different augmentations. However, when applied to
pose estimation, the methods degenerate and predict every pixel in unlabeled
images as background. This is because contradictory predictions are gradually
pushed to the background class due to highly imbalanced class distribution. But
this is not an issue in supervised learning because it has accurate labels.
This inspires us to stabilize the training by obtaining reliable pseudo labels.
Specifically, we learn two networks to mutually teach each other. In
particular, for each image, we compose an easy-hard pair by applying different
augmentations and feed them to both networks. The more reliable predictions on
easy images in each network are used to teach the other network to learn about
the corresponding hard images. The approach successfully avoids degeneration
and achieves promising results on public datasets. The source code and
pretrained models have been released at
https://github.com/xierc/Semi_Human_Pose.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Video Instance Segmentation with Transformers. (arXiv:2011.14503v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14503">
<div class="article-summary-box-inner">
<span><p>Video instance segmentation (VIS) is the task that requires simultaneously
classifying, segmenting and tracking object instances of interest in video.
Recent methods typically develop sophisticated pipelines to tackle this task.
Here, we propose a new video instance segmentation framework built upon
Transformers, termed VisTR, which views the VIS task as a direct end-to-end
parallel sequence decoding/prediction problem. Given a video clip consisting of
multiple image frames as input, VisTR outputs the sequence of masks for each
instance in the video in order directly. At the core is a new, effective
instance sequence matching and segmentation strategy, which supervises and
segments instances at the sequence level as a whole. VisTR frames the instance
segmentation and tracking in the same perspective of similarity learning, thus
considerably simplifying the overall pipeline and is significantly different
from existing approaches. Without bells and whistles, VisTR achieves the
highest speed among all existing VIS models, and achieves the best result among
methods using single model on the YouTube-VIS dataset. For the first time, we
demonstrate a much simpler and faster video instance segmentation framework
built upon Transformers, achieving competitive accuracy. We hope that VisTR can
motivate future research for more video understanding tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Spatial Nonstationarity via Deformable Convolutions for Deep Traffic Flow Prediction. (arXiv:2101.12010v2 [physics.soc-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12010">
<div class="article-summary-box-inner">
<span><p>Deep neural networks are being increasingly used for short-term traffic flow
prediction, which can be generally categorized as convolutional (CNNs) or graph
neural networks (GNNs). CNNs are preferable for region-wise traffic prediction
by taking advantage of localized spatial correlations, whilst GNNs achieves
better performance for graph-structured traffic data. When applied to
region-wise traffic prediction, CNNs typically partition an underlying
territory into grid-like spatial units, and employ standard convolutions to
learn spatial dependence among the units. However, standard convolutions with
fixed geometric structures cannot fully model the nonstationary characteristics
of local traffic flows. To overcome the deficiency, we introduce deformable
convolution that augments the spatial sampling locations with additional
offsets, to enhance the modeling capability of spatial nonstationarity. On this
basis, we design a deep deformable convolutional residual network, namely
DeFlow-Net, that can effectively model global spatial dependence, local spatial
nonstationarity, and temporal periodicity of traffic flows. Furthermore, to
better fit with convolutions, we suggest to first aggregate traffic flows
according to pre-conceived regions or self-organized regions based on traffic
flows, then dispose to sequentially organized raster images for network input.
Extensive experiments on real-world traffic flows demonstrate that DeFlow-Net
outperforms GNNs and existing CNNs using standard convolutions, and spatial
partition by pre-conceived regions or self-organized regions further enhances
the performance. We also demonstrate the advantage of DeFlow-Net in maintaining
spatial autocorrelation, and reveal the impacts of partition shapes and scales
on deep traffic flow prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Scene Graph Classification by Exploiting Knowledge from Texts. (arXiv:2102.04760v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04760">
<div class="article-summary-box-inner">
<span><p>Training scene graph classification models requires a large amount of
annotated image data. Meanwhile, scene graphs represent relational knowledge
that can be modeled with symbolic data from texts or knowledge graphs. While
image annotation demands extensive labor, collecting textual descriptions of
natural scenes requires less effort. In this work, we investigate whether
textual scene descriptions can substitute for annotated image data. To this
end, we employ a scene graph classification framework that is trained not only
from annotated images but also from symbolic data. In our architecture, the
symbolic entities are first mapped to their correspondent image-grounded
representations and then fed into the relational reasoning pipeline. Even
though a structured form of knowledge, such as the form in knowledge graphs, is
not always available, we can generate it from unstructured texts using a
transformer-based language model. We show that by fine-tuning the
classification pipeline with the extracted knowledge from texts, we can achieve
~8x more accurate results in scene graph classification, ~3x in object
classification, and ~1.5x in predicate classification, compared to the
supervised baselines with only 1% of the annotated images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding self-supervised Learning Dynamics without Contrastive Pairs. (arXiv:2102.06810v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06810">
<div class="article-summary-box-inner">
<span><p>While contrastive approaches of self-supervised learning (SSL) learn
representations by minimizing the distance between two augmented views of the
same data point (positive pairs) and maximizing views from different data
points (negative pairs), recent \emph{non-contrastive} SSL (e.g., BYOL and
SimSiam) show remarkable performance {\it without} negative pairs, with an
extra learnable predictor and a stop-gradient operation. A fundamental question
arises: why do these methods not collapse into trivial representations? We
answer this question via a simple theoretical study and propose a novel
approach, DirectPred, that \emph{directly} sets the linear predictor based on
the statistics of its inputs, without gradient training. On ImageNet, it
performs comparably with more complex two-layer non-linear predictors that
employ BatchNorm and outperforms a linear predictor by $2.5\%$ in 300-epoch
training (and $5\%$ in 60-epoch). DirectPred is motivated by our theoretical
study of the nonlinear learning dynamics of non-contrastive SSL in simple
linear networks. Our study yields conceptual insights into how non-contrastive
SSL methods learn, how they avoid representational collapse, and how multiple
factors, like predictor networks, stop-gradients, exponential moving averages,
and weight decay all come into play. Our simple theory recapitulates the
results of real-world ablation studies in both STL-10 and ImageNet. Code is
released https://github.com/facebookresearch/luckmatters/tree/master/ssl.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VAE Approximation Error: ELBO and Conditional Independence. (arXiv:2102.09310v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09310">
<div class="article-summary-box-inner">
<span><p>The importance of Variational Autoencoders reaches far beyond standalone
generative models -- the approach is also used for learning latent
representations and can be generalized to semi-supervised learning. This
requires a thorough analysis of their commonly known shortcomings: posterior
collapse and approximation errors. This paper analyzes VAE approximation errors
caused by the combination of the ELBO objective with the choice of the encoder
probability family, in particular under conditional independence assumptions.
We identify the subclass of generative models consistent with the encoder
family. We show that the ELBO optimizer is pulled from the likelihood optimizer
towards this consistent subset. Furthermore, this subset can not be enlarged,
and the respective error cannot be decreased, by only considering deeper
encoder networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VMAF And Variants: Towards A Unified VQA. (arXiv:2103.07770v7 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07770">
<div class="article-summary-box-inner">
<span><p>Video quality assessment (VQA) is now a fast-growing subject, maturing in the
full reference (FR) case, yet challenging in the exploding no reference (NR)
case. We investigate variants of the popular VMAF video quality assessment
algorithm for the FR case, using both support vector regression and feedforward
neural networks. We extend it to the NR case, using some different features but
similar learning, to develop a partially unified framework for VQA. When fully
trained, FR algorithms such as VMAF perform very well on test datasets,
reaching 90%+ match in PCC and SRCC; but for predicting performance in the
wild, we train/test from scratch for each database. With an 80/20 train/test
split, we still achieve about 90% performance on average in both PCC and SRCC,
with up to 7-9% gains over VMAF, using an improved motion feature and better
regression. Moreover, we even get decent performance (about 75%) if we ignore
the reference, treating FR as NR, partly justifying our attempts at
unification. In the true NR case, we reduce complexity vs. leading recent
algorithms VIDEVAL, RAPIQUE, yet achieve performance within 3-5%. Moreover, we
develop a method to analyze the saliency of features, and conclude that for
both VIDEVAL and RAPIQUE, a small subset of their features are providing the
bulk of the performance. In short, we find encouraging improvements in
trainability in FR, while constraining training complexity against leading
methods in NR, elucidating the saliency of features for feature selection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unveiling the Power of Mixup for Stronger Classifiers. (arXiv:2103.13027v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13027">
<div class="article-summary-box-inner">
<span><p>Mixup-based data augmentations have achieved great success as regularizers
for deep neural networks. However, existing methods rely on deliberately
handcrafted mixup policies, which ignore or oversell the semantic matching
between mixed samples and labels. Driven by their prior assumptions, early
methods attempt to smooth decision boundaries by random linear interpolation
while others focus on maximizing class-related information via offline saliency
optimization. As a result, the issue of label mismatch has not been well
addressed. Additionally, the optimization stability of mixup training is
constantly troubled by the label mismatch. To address these challenges, we
first reformulate mixup for supervised classification as two sub-tasks, mixup
sample generation and classification, then propose Automatic Mixup (AutoMix), a
revolutionary mixup framework. Specifically, a learnable lightweight Mix Block
(MB) with a cross-attention mechanism is proposed to generate a mixed sample by
modeling a fair relationship between the pair of samples under direct
supervision of the corresponding mixed label. Moreover, the proposed Momentum
Pipeline (MP) enhances training stability and accelerates convergence on top of
making the Mix Block fully trained end-to-end. Extensive experiments on five
popular classification benchmarks show that the proposed approach consistently
outperforms leading methods by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Robustness of Transformers for Image Classification. (arXiv:2103.14586v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14586">
<div class="article-summary-box-inner">
<span><p>Deep Convolutional Neural Networks (CNNs) have long been the architecture of
choice for computer vision tasks. Recently, Transformer-based architectures
like Vision Transformer (ViT) have matched or even surpassed ResNets for image
classification. However, details of the Transformer architecture -- such as the
use of non-overlapping patches -- lead one to wonder whether these networks are
as robust. In this paper, we perform an extensive study of a variety of
different measures of robustness of ViT models and compare the findings to
ResNet baselines. We investigate robustness to input perturbations as well as
robustness to model perturbations. We find that when pre-trained with a
sufficient amount of data, ViT models are at least as robust as the ResNet
counterparts on a broad range of perturbations. We also find that Transformers
are robust to the removal of almost any single layer, and that while
activations from later layers are highly correlated with each other, they
nevertheless play an important role in classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning with Memory-based Virtual Classes for Deep Metric Learning. (arXiv:2103.16940v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16940">
<div class="article-summary-box-inner">
<span><p>The core of deep metric learning (DML) involves learning visual similarities
in high-dimensional embedding space. One of the main challenges is to
generalize from seen classes of training data to unseen classes of test data.
Recent works have focused on exploiting past embeddings to increase the number
of instances for the seen classes. Such methods achieve performance improvement
via augmentation, while the strong focus on seen classes still remains. This
can be undesirable for DML, where training and test data exhibit entirely
different classes. In this work, we present a novel training strategy for DML
called MemVir. Unlike previous works, MemVir memorizes both embedding features
and class weights to utilize them as additional virtual classes. The
exploitation of virtual classes not only utilizes augmented information for
training but also alleviates a strong focus on seen classes for better
generalization. Moreover, we embed the idea of curriculum learning by slowly
adding virtual classes for a gradual increase in learning difficulty, which
improves the learning stability as well as the final performance. MemVir can be
easily applied to many existing loss functions without any modification.
Extensive experimental results on famous benchmarks demonstrate the superiority
of MemVir over state-of-the-art competitors. Code of MemVir is publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition. (arXiv:2104.03841v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03841">
<div class="article-summary-box-inner">
<span><p>Object recognition has made great advances in the last decade, but
predominately still relies on many high-quality training examples per object
category. In contrast, learning new objects from only a few examples could
enable many impactful applications from robotics to user personalization. Most
few-shot learning research, however, has been driven by benchmark datasets that
lack the high variation that these applications will face when deployed in the
real-world. To close this gap, we present the ORBIT dataset and benchmark,
grounded in the real-world application of teachable object recognizers for
people who are blind/low-vision. The dataset contains 3,822 videos of 486
objects recorded by people who are blind/low-vision on their mobile phones. The
benchmark reflects a realistic, highly challenging recognition problem,
providing a rich playground to drive research in robustness to few-shot,
high-variation conditions. We set the benchmark's first state-of-the-art and
show there is massive scope for further innovation, holding the potential to
impact a broad range of real-world vision applications including tools for the
blind/low-vision community. We release the dataset at
https://doi.org/10.25383/city.14294597 and benchmark code at
https://github.com/microsoft/ORBIT-Dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction. (arXiv:2104.10078v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10078">
<div class="article-summary-box-inner">
<span><p>Neural implicit 3D representations have emerged as a powerful paradigm for
reconstructing surfaces from multi-view images and synthesizing novel views.
Unfortunately, existing methods such as DVR or IDR require accurate per-pixel
object masks as supervision. At the same time, neural radiance fields have
revolutionized novel view synthesis. However, NeRF's estimated volume density
does not admit accurate surface reconstruction. Our key insight is that
implicit surface models and radiance fields can be formulated in a unified way,
enabling both surface and volume rendering using the same model. This unified
perspective enables novel, more efficient sampling procedures and the ability
to reconstruct accurate surfaces without input masks. We compare our method on
the DTU, BlendedMVS, and a synthetic indoor dataset. Our experiments
demonstrate that we outperform NeRF in terms of reconstruction quality while
performing on par with IDR without requiring masks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Less is more: Selecting informative and diverse subsets with balancing constraints. (arXiv:2104.12835v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12835">
<div class="article-summary-box-inner">
<span><p>Deep learning has yielded extraordinary results in vision and natural
language processing, but this achievement comes at a cost. Most models require
enormous resources during training, both in terms of computation and in human
labeling effort. We show that we can identify informative and diverse subsets
of data that lead to deep learning models with similar performance as the ones
trained with the original dataset. Prior methods have exploited diversity and
uncertainty in submodular objective functions for choosing subsets. In addition
to these measures, we show that balancing constraints on predicted class labels
and decision boundaries are beneficial. We propose a novel formulation of these
constraints using matroids, an algebraic structure that generalizes linear
independence in vector spaces, and present an efficient greedy algorithm with
constant approximation guarantees. We outperform competing baselines on
standard classification datasets such as CIFAR-10, CIFAR-100, ImageNet, as well
as long-tailed datasets such as CIFAR-100-LT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RandCrowns: A Quantitative Metric for Imprecisely Labeled Tree Crown Delineation. (arXiv:2105.02186v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02186">
<div class="article-summary-box-inner">
<span><p>Supervised methods for object delineation in remote sensing require labeled
ground-truth data. Gathering sufficient high quality ground-truth data is
difficult, especially when targets are of irregular shape or difficult to
distinguish from background or neighboring objects. Tree crown delineation
provides key information from remote sensing images for forestry, ecology, and
management. However, tree crowns in remote sensing imagery are often difficult
to label and annotate due to irregular shape, overlapping canopies, shadowing,
and indistinct edges. There are also multiple approaches to annotation in this
field (e.g., rectangular boxes vs. convex polygons) that further contribute to
annotation imprecision. However, current evaluation methods do not account for
this uncertainty in annotations, and quantitative metrics for evaluation can
vary across multiple annotators. In this paper, we address these limitations by
developing an adaptation of the Rand index for weakly-labeled crown delineation
that we call RandCrowns. Our new RandCrowns evaluation metric provides a method
to appropriately evaluate delineated tree crowns while taking into account
imprecision in the ground-truth delineations. The RandCrowns metric
reformulates the Rand index by adjusting the areas over which each term of the
index is computed to account for uncertain and imprecise object delineation
labels. Quantitative comparisons to the commonly used intersection over union
method shows a decrease in the variance generated by differences among multiple
annotators. Combined with qualitative examples, our results suggest that the
RandCrowns metric is more robust for scoring target delineations in the
presence of uncertainty and imprecision in annotations that are inherent to
tree crown delineation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is aspect ratio of cells important in deep learning? A robust comparison of deep learning methods for multi-scale cytopathology cell image classification: from convolutional neural networks to visual transformers. (arXiv:2105.07402v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07402">
<div class="article-summary-box-inner">
<span><p>Cervical cancer is a very common and fatal cancer in women. Cytopathology
images are often used to screen this cancer. Since there is a possibility of a
large number of errors in manual screening, the computer-aided diagnosis system
based on deep learning is developed. The deep learning methods required a fixed
size of input images, but the sizes of the clinical medical images are
inconsistent. The aspect ratios of the images are suffered while resizing it
directly. Clinically, the aspect ratios of cells inside cytopathological images
provide important information for doctors to diagnose cancer. Therefore, it is
illogical to resize directly. However, many existing studies resized the images
directly and obtained very robust classification results. To find a reasonable
interpretation, we have conducted a series of comparative experiments. First,
the raw data of the SIPaKMeD dataset are preprocessed to obtain the standard
and scaled datasets. Then, the datasets are resized to 224 x 224 pixels.
Finally, twenty-two deep learning models are used to classify standard and
scaled datasets. The conclusion is that the deep learning models are robust to
changes in the aspect ratio of cells in cervical cytopathological images. This
conclusion is also validated on the Herlev dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Remote Sensing Images Change Detection at Pixel-level. (arXiv:2105.08501v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08501">
<div class="article-summary-box-inner">
<span><p>Deep learning techniques have achieved great success in remote sensing image
change detection. Most of them are supervised techniques, which usually require
large amounts of training data and are limited to a particular application.
Self-supervised methods as an unsupervised approach are popularly used to solve
this problem and are widely used in unsupervised binary change detection tasks.
However, the existing self-supervised methods in change detection are based on
pre-tasks or at patch-level, which may be sub-optimal for pixel-wise change
detection tasks. Therefore, in this work, a pixel-wise contrastive approach is
proposed to overcome this limitation. This is achieved by using contrastive
loss in pixel-level features on an unlabeled multi-view setting. In this
approach, a Siamese ResUnet is trained to obtain pixel-wise representations and
to align features from shifted positive pairs. Meanwhile, vector quantization
is used to augment the learned features in two branches. The final binary
change map is obtained by subtracting features of one branch from features of
the other branch and using the Rosin thresholding method. To overcome the
effects of regular seasonal changes in binary change maps, we also used an
uncertainty method to enhance the temporal robustness of the proposed approach.
Two homogeneous (OSCD and MUDS) datasets and one heterogeneous (California
Flood) dataset are used to evaluate the performance of the proposed approach.
Results demonstrate improvements in both efficiency and accuracy over the
patch-wise multi-view contrastive method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VOILA: Visual-Observation-Only Imitation Learning for Autonomous Navigation. (arXiv:2105.09371v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09371">
<div class="article-summary-box-inner">
<span><p>While imitation learning for vision based autonomous mobile robot navigation
has recently received a great deal of attention in the research community,
existing approaches typically require state action demonstrations that were
gathered using the deployment platform. However, what if one cannot easily
outfit their platform to record these demonstration signals or worse yet the
demonstrator does not have access to the platform at all? Is imitation learning
for vision based autonomous navigation even possible in such scenarios? In this
work, we hypothesize that the answer is yes and that recent ideas from the
Imitation from Observation (IfO) literature can be brought to bear such that a
robot can learn to navigate using only ego centric video collected by a
demonstrator, even in the presence of viewpoint mismatch. To this end, we
introduce a new algorithm, Visual Observation only Imitation Learning for
Autonomous navigation (VOILA), that can successfully learn navigation policies
from a single video demonstration collected from a physically different agent.
We evaluate VOILA in the photorealistic AirSim simulator and show that VOILA
not only successfully imitates the expert, but that it also learns navigation
policies that can generalize to novel environments. Further, we demonstrate the
effectiveness of VOILA in a real world setting by showing that it allows a
wheeled Jackal robot to successfully imitate a human walking in an environment
using a video recorded using a mobile phone camera.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Unsupervised Document Image Blind Denoising. (arXiv:2105.09437v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09437">
<div class="article-summary-box-inner">
<span><p>Removing noise from scanned pages is a vital step before their submission to
the optical character recognition (OCR) system. Most available image denoising
methods are supervised where the pairs of noisy/clean pages are required.
However, this assumption is rarely met in real settings. Besides, there is no
single model that can remove various noise types from documents. Here, we
propose a unified end-to-end unsupervised deep learning model, for the first
time, that can effectively remove multiple types of noise, including salt \&amp;
pepper noise, blurred and/or faded text, as well as watermarks from documents
at various levels of intensity. We demonstrate that the proposed model
significantly improves the quality of scanned images and the OCR of the pages
on several test datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Representation mitosis in wide neural networks. (arXiv:2106.03485v2 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03485">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) defy the classical bias-variance trade-off:
adding parameters to a DNN that interpolates its training data will typically
improve its generalization performance. Explaining the mechanism behind this
``benign overfitting'' in deep networks remains an outstanding challenge. Here,
we study the last hidden layer representations of various state-of-the-art
convolutional neural networks and find evidence for an underlying mechanism
that we call "representation mitosis": if the last hidden representation is
wide enough, its neurons tend to split into groups which carry identical
information, and differ from each other only by a statistically independent
noise. Like in a mitosis process, the number of such groups, or ``clones'',
increases linearly with the width of the layer, but only if the width is above
a critical value. We show that a key ingredient to activate mitosis is
continuing the training process until the training error is zero.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FairCal: Fairness Calibration for Face Verification. (arXiv:2106.03761v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03761">
<div class="article-summary-box-inner">
<span><p>Despite being widely used, face recognition models suffer from bias: the
probability of a false positive (incorrect face match) strongly depends on
sensitive attributes such as the ethnicity of the face. As a result, these
models can disproportionately and negatively impact minority groups,
particularly when used by law enforcement. The majority of bias reduction
methods have several drawbacks: they use an end-to-end retraining approach, may
not be feasible due to privacy issues, and often reduce accuracy. An
alternative approach is post-processing methods that build fairer decision
classifiers using the features of pre-trained models. However, they still have
drawbacks: they reduce accuracy (AGENDA, FTC), or require retuning for
different false positive rates (FSN). In this work, we introduce the Fairness
Calibration (FairCal) method, a post-training approach that: (i) increases
model accuracy (improving the state-of-the-art), (ii) produces
fairly-calibrated probabilities, (iii) significantly reduces the gap in the
false positive rates, (iv) does not require knowledge of the sensitive
attribute, and (v) does not require retraining, training an additional model,
or retuning. We apply it to the task of Face Verification, and obtain
state-of-the-art results with all the above advantages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation. (arXiv:2106.05210v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05210">
<div class="article-summary-box-inner">
<span><p>This paper presents a simple yet effective approach to modeling space-time
correspondences in the context of video object segmentation. Unlike most
existing approaches, we establish correspondences directly between frames
without re-encoding the mask features for every object, leading to a highly
efficient and robust framework. With the correspondences, every node in the
current query frame is inferred by aggregating features from the past in an
associative fashion. We cast the aggregation process as a voting problem and
find that the existing inner-product affinity leads to poor use of memory with
a small (fixed) subset of memory nodes dominating the votes, regardless of the
query. In light of this phenomenon, we propose using the negative squared
Euclidean distance instead to compute the affinities. We validated that every
memory node now has a chance to contribute, and experimentally showed that such
diversified voting is beneficial to both memory efficiency and inference
accuracy. The synergy of correspondence networks and diversified voting works
exceedingly well, achieves new state-of-the-art results on both DAVIS and
YouTubeVOS datasets while running significantly faster at 20+ FPS for multiple
objects without bells and whistles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Looking Outside the Window: Wide-Context Transformer for the Semantic Segmentation of High-Resolution Remote Sensing Images. (arXiv:2106.15754v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15754">
<div class="article-summary-box-inner">
<span><p>Long-range contextual information is crucial for the semantic segmentation of
High-Resolution (HR) Remote Sensing Images (RSIs). However, image cropping
operations, commonly used for training neural networks, limit the perception of
long-range contexts in large RSIs. To overcome this limitation, we propose a
Wide-Context Network (WiCoNet) for the semantic segmentation of HR RSIs. Apart
from extracting local features with a conventional CNN, the WiCoNet has an
extra context branch to aggregate information from a larger image area.
Moreover, we introduce a Context Transformer to embed contextual information
from the context branch and selectively project it onto the local features. The
Context Transformer extends the Vision Transformer, an emerging kind of neural
networks, to model the dual-branch semantic correlations. It overcomes the
locality limitation of CNNs and enables the WiCoNet to see the bigger picture
before segmenting the land-cover/land-use (LCLU) classes. Ablation studies and
comparative experiments conducted on several benchmark datasets demonstrate the
effectiveness of the proposed method. In addition, we present a new Beijing
Land-Use (BLU) dataset. This is a large-scale HR satellite dataset with
high-quality and fine-grained reference labels, which can facilitate future
studies in this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Align Yourself: Self-supervised Pre-training for Fine-grained Recognition via Saliency Alignment. (arXiv:2106.15788v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15788">
<div class="article-summary-box-inner">
<span><p>Self-supervised contrastive learning has demonstrated great potential in
learning visual representations. Despite their success on various downstream
tasks such as image classification and object detection, self-supervised
pre-training for fine-grained scenarios is not fully explored. In this paper,
we first point out that current contrastive methods are prone to memorizing
background/foreground texture and therefore have a limitation in localizing the
foreground object. Analysis suggests that learning to extract discriminative
texture information and localization are equally crucial for self-supervised
pre-training in fine-grained scenarios. Based on our findings, we introduce
cross-view saliency alignment (CVSA), a contrastive learning framework that
first crops and swaps saliency regions of images as a novel view generation and
then guides the model to localize on the foreground object via a cross-view
alignment loss. Extensive experiments on four popular fine-grained
classification benchmarks show that CVSA significantly improves the learned
representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration. (arXiv:2107.05446v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05446">
<div class="article-summary-box-inner">
<span><p>Source-free domain adaptation (SFDA) aims to adapt a model trained on
labelled data in a source domain to unlabelled data in a target domain without
access to the source-domain data during adaptation. Existing methods for SFDA
leverage entropy-minimization techniques which: (i) apply only to
classification; (ii) destroy model calibration; and (iii) rely on the source
model achieving a good level of feature-space class-separation in the target
domain. We address these issues for a particularly pervasive type of domain
shift called measurement shift -- characterized by a change in measurement
system -- which can be resolved by restoring the source features. In the source
domain, we store a lightweight and flexible approximation of the feature
distribution under the source data. In the target domain, we adapt the
feature-extractor such that the approximate feature distribution under the
target data realigns with that saved on the source. We call this method Feature
Restoration (FR) as it seeks to extract features with the same semantics from
the target domain as were previously extracted from the source, rather than
extracting new ones. We additionally propose Bottom-Up Feature Restoration
(BUFR) -- a bottom-up training scheme for FR which boosts performance by
preserving learnt structure in the later layers of a network. We demonstrate
that BUFR outperforms existing SFDA methods on real and synthetic data in terms
of accuracy, calibration, and data efficiency, while being less reliant on the
performance of the source model in the target domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention. (arXiv:2108.00154v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00154">
<div class="article-summary-box-inner">
<span><p>Transformers have made great progress in dealing with computer vision tasks.
However, existing vision transformers do not yet possess the ability of
building the interactions among features of different scales, which is
perceptually important to visual inputs. The reasons are two-fold: (1) Input
embeddings of each layer are equal-scale, so no cross-scale feature can be
extracted; (2) to lower the computational cost, some vision transformers merge
adjacent embeddings inside the self-attention module, thus sacrificing
small-scale (fine-grained) features of the embeddings and also disabling the
cross-scale interactions. To this end, we propose Cross-scale Embedding Layer
(CEL) and Long Short Distance Attention (LSDA). On the one hand, CEL blends
each embedding with multiple patches of different scales, providing the
self-attention module itself with cross-scale features. On the other hand, LSDA
splits the self-attention module into a short-distance one and a long-distance
counterpart, which not only reduces the computational burden but also keeps
both small-scale and large-scale features in the embeddings. Through the above
two designs, we achieve cross-scale attention. Besides, we put forward a
dynamic position bias for vision transformers to make the popular relative
position bias apply to variable-sized images. Hinging on the cross-scale
attention module, we construct a versatile vision architecture, dubbed
CrossFormer, which accommodates variable-sized inputs. Extensive experiments
show that CrossFormer outperforms the other vision transformers on image
classification, object detection, instance segmentation, and semantic
segmentation tasks. The code has been released:
https://github.com/cheerss/CrossFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Source-free Domain Adaptation. (arXiv:2108.01614v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01614">
<div class="article-summary-box-inner">
<span><p>Domain adaptation (DA) aims to transfer the knowledge learned from a source
domain to an unlabeled target domain. Some recent works tackle source-free
domain adaptation (SFDA) where only a source pre-trained model is available for
adaptation to the target domain. However, those methods do not consider keeping
source performance which is of high practical value in real world applications.
In this paper, we propose a new domain adaptation paradigm called Generalized
Source-free Domain Adaptation (G-SFDA), where the learned model needs to
perform well on both the target and source domains, with only access to current
unlabeled target data during adaptation. First, we propose local structure
clustering (LSC), aiming to cluster the target features with its semantically
similar neighbors, which successfully adapts the model to the target domain in
the absence of source data. Second, we propose sparse domain attention (SDA),
it produces a binary domain specific attention to activate different feature
channels for different domains, meanwhile the domain attention will be utilized
to regularize the gradient during adaptation to keep source information. In the
experiments, for target performance our method is on par with or better than
existing DA and SFDA methods, specifically it achieves state-of-the-art
performance (85.4%) on VisDA, and our method works well for all domains after
adapting to single or multiple target domains. Code is available in
https://github.com/Albert0147/G-SFDA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solo-learn: A Library of Self-supervised Methods for Visual Representation Learning. (arXiv:2108.01775v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01775">
<div class="article-summary-box-inner">
<span><p>This paper presents solo-learn, a library of self-supervised methods for
visual representation learning. Implemented in Python, using Pytorch and
Pytorch lightning, the library fits both research and industry needs by
featuring distributed training pipelines with mixed-precision, faster data
loading via Nvidia DALI, online linear evaluation for better prototyping, and
many additional training tricks. Our goal is to provide an easy-to-use library
comprising a large amount of Self-supervised Learning (SSL) methods, that can
be easily extended and fine-tuned by the community. solo-learn opens up avenues
for exploiting large-budget SSL solutions on inexpensive smaller
infrastructures and seeks to democratize SSL by making it accessible to all.
The source code is available at https://github.com/vturrisi/solo-learn.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Embodied Vision Navigation: A Survey. (arXiv:2108.04097v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04097">
<div class="article-summary-box-inner">
<span><p>"Embodied visual navigation" problem requires an agent to navigate in a 3D
environment mainly rely on its first-person observation. This problem has
attracted rising attention in recent years due to its wide application in
autonomous driving, vacuum cleaner, and rescue robot. A navigation agent is
supposed to have various intelligent skills, such as visual perceiving,
mapping, planning, exploring and reasoning, etc. Building such an agent that
observes, thinks, and acts is a key to real intelligence. The remarkable
learning ability of deep learning methods empowered the agents to accomplish
embodied visual navigation tasks. Despite this, embodied visual navigation is
still in its infancy since a lot of advanced skills are required, including
perceiving partially observed visual input, exploring unseen areas, memorizing
and modeling seen scenarios, understanding cross-modal instructions, and
adapting to a new environment, etc. Recently, embodied visual navigation has
attracted rising attention of the community, and numerous works has been
proposed to learn these skills. This paper attempts to establish an outline of
the current works in the field of embodied visual navigation by providing a
comprehensive literature survey. We summarize the benchmarks and metrics,
review different methods, analysis the challenges, and highlight the
state-of-the-art methods. Finally, we discuss unresolved challenges in the
field of embodied visual navigation and give promising directions in pursuing
future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-domain Collaborative Feature Representation for Robust Visual Object Tracking. (arXiv:2108.04521v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04521">
<div class="article-summary-box-inner">
<span><p>Jointly exploiting multiple different yet complementary domain information
has been proven to be an effective way to perform robust object tracking. This
paper focuses on effectively representing and utilizing complementary features
from the frame domain and event domain for boosting object tracking performance
in challenge scenarios. Specifically, we propose Common Features Extractor
(CFE) to learn potential common representations from the RGB domain and event
domain. For learning the unique features of the two domains, we utilize a
Unique Extractor for Event (UEE) based on Spiking Neural Networks to extract
edge cues in the event domain which may be missed in RGB in some challenging
conditions, and a Unique Extractor for RGB (UER) based on Deep Convolutional
Neural Networks to extract texture and semantic information in RGB domain.
Extensive experiments on standard RGB benchmark and real event tracking dataset
demonstrate the effectiveness of the proposed approach. We show our approach
outperforms all compared state-of-the-art tracking algorithms and verify
event-based data is a powerful cue for tracking in challenging scenes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiagViB-6: A Diagnostic Benchmark Suite for Vision Models in the Presence of Shortcut and Generalization Opportunities. (arXiv:2108.05779v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05779">
<div class="article-summary-box-inner">
<span><p>Common deep neural networks (DNNs) for image classification have been shown
to rely on shortcut opportunities (SO) in the form of predictive and
easy-to-represent visual factors. This is known as shortcut learning and leads
to impaired generalization. In this work, we show that common DNNs also suffer
from shortcut learning when predicting only basic visual object factors of
variation (FoV) such as shape, color, or texture. We argue that besides
shortcut opportunities, generalization opportunities (GO) are also an inherent
part of real-world vision data and arise from partial independence between
predicted classes and FoVs. We also argue that it is necessary for DNNs to
exploit GO to overcome shortcut learning. Our core contribution is to introduce
the Diagnostic Vision Benchmark suite DiagViB-6, which includes datasets and
metrics to study a network's shortcut vulnerability and generalization
capability for six independent FoV. In particular, DiagViB-6 allows controlling
the type and degree of SO and GO in a dataset. We benchmark a wide range of
popular vision architectures and show that they can exploit GO only to a
limited extent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAMA: A Rapid Multicut Algorithm on GPU. (arXiv:2109.01838v2 [cs.DC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01838">
<div class="article-summary-box-inner">
<span><p>We propose a highly parallel primal-dual algorithm for the multicut (a.k.a.
correlation clustering) problem, a classical graph clustering problem widely
used in machine learning and computer vision. Our algorithm consists of three
steps executed recursively: (1) Finding conflicted cycles that correspond to
violated inequalities of the underlying multicut relaxation, (2) Performing
message passing between the edges and cycles to optimize the Lagrange
relaxation coming from the found violated cycles producing reduced costs and
(3) Contracting edges with high reduced costs through matrix-matrix
multiplications.
</p>
<p>Our algorithm produces primal solutions and dual lower bounds that estimate
the distance to optimum. We implement our algorithm on GPUs and show resulting
one to two order-of-magnitudes improvements in execution speed without
sacrificing solution quality compared to traditional serial algorithms that run
on CPUs. We can solve very large scale benchmark problems with up to
$\mathcal{O}(10^8)$ variables in a few seconds with small primal-dual gaps. We
make our code available at https://github.com/pawelswoboda/RAMA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identification of Driver Phone Usage Violations via State-of-the-Art Object Detection with Tracking. (arXiv:2109.02119v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02119">
<div class="article-summary-box-inner">
<span><p>The use of mobiles phones when driving have been a major factor when it comes
to road traffic incidents and the process of capturing such violations can be a
laborious task. Advancements in both modern object detection frameworks and
high-performance hardware has paved the way for a more automated approach when
it comes to video surveillance. In this work, we propose a custom-trained
state-of-the-art object detector to work with roadside cameras to capture
driver phone usage without the need for human intervention. The proposed
approach also addresses the issues caused by windscreen glare and introduces
the steps required to remedy this. Twelve pre-trained models are fine-tuned
with our custom dataset using four popular object detection methods: YOLO, SSD,
Faster R-CNN, and CenterNet. Out of all the object detectors tested, the YOLO
yields the highest accuracy levels of up to 96% (AP10) and frame rates of up to
~30 FPS. DeepSort object tracking algorithm is also integrated into the
best-performing model to collect records of only the unique violations, and
enable the proposed approach to count the number of vehicles. The proposed
automated system will collect the output images of the identified violations,
timestamps of each violation, and total vehicle count. Data can be accessed via
a purpose-built user interface.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation. (arXiv:2109.06165v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06165">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from
a labeled source domain to a different unlabeled target domain. Most existing
UDA methods focus on learning domain-invariant feature representation, either
from the domain level or category level, using convolution neural networks
(CNNs)-based frameworks. One fundamental problem for the category level based
UDA is the production of pseudo labels for samples in target domain, which are
usually too noisy for accurate domain alignment, inevitably compromising the
UDA performance. With the success of Transformer in various tasks, we find that
the cross-attention in Transformer is robust to the noisy input pairs for
better feature alignment, thus in this paper Transformer is adopted for the
challenging UDA task. Specifically, to generate accurate input pairs, we design
a two-way center-aware labeling algorithm to produce pseudo labels for target
samples. Along with the pseudo labels, a weight-sharing triple-branch
transformer framework is proposed to apply self-attention and cross-attention
for source/target feature learning and source-target domain alignment,
respectively. Such design explicitly enforces the framework to learn
discriminative domain-specific and domain-invariant representations
simultaneously. The proposed method is dubbed CDTrans (cross-domain
transformer), and it provides one of the first attempts to solve UDA tasks with
a pure transformer solution. Extensive experiments show that our proposed
method achieves the best performance on Office-Home, VisDA-2017, and DomainNet
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auto White-Balance Correction for Mixed-Illuminant Scenes. (arXiv:2109.08750v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08750">
<div class="article-summary-box-inner">
<span><p>Auto white balance (AWB) is applied by camera hardware at capture time to
remove the color cast caused by the scene illumination. The vast majority of
white-balance algorithms assume a single light source illuminates the scene;
however, real scenes often have mixed lighting conditions. This paper presents
an effective AWB method to deal with such mixed-illuminant scenes. A unique
departure from conventional AWB, our method does not require illuminant
estimation, as is the case in traditional camera AWB modules. Instead, our
method proposes to render the captured scene with a small set of predefined
white-balance settings. Given this set of rendered images, our method learns to
estimate weighting maps that are used to blend the rendered images to generate
the final corrected image. Through extensive experiments, we show this proposed
method produces promising results compared to other alternatives for single-
and mixed-illuminant scene color correction. Our source code and trained models
are available at https://github.com/mahmoudnafifi/mixedillWB.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Well Googled is Half Done: Multimodal Forecasting of New Fashion Product Sales with Image-based Google Trends. (arXiv:2109.09824v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09824">
<div class="article-summary-box-inner">
<span><p>This paper investigates the effectiveness of systematically probing Google
Trendsagainst textual translations of visual aspects as exogenous knowledge to
predict the sales of brand-new fashion items, where past sales data is not
available, but only an image and few metadata are available. In particular, we
propose GTM-Transformer, standing for Google Trends Multimodal Transformer,
whose encoder works on the representation of the exogenous time series, while
the decoder forecasts the sales using the Google Trends encoding, and the
available visual and metadata information. Our model works in a
non-autoregressive manner, avoiding the compounding effect of the first-step
errors. As a second contribution, we present the VISUELLE dataset, which is the
first publicly available dataset for the task of new fashion product sales
forecasting, containing the sales of 5577 new products sold between 2016-2019,
derived from genuine historical data ofNunalie, an Italian fast-fashion
company. Our dataset is equipped with images of products, metadata, related
sales, and associated Google Trends. We use VISUELLE to compare our approach
against state-of-the-art alternatives and numerous baselines, showing that
GTM-Transformer is the most accurate in terms of both percentage and absolute
error. It is worth noting that the addition of exogenous knowledge boosts the
forecasting accuracy by 1.5% WAPE wise, showing the importance of exploiting
Google Trends. The code and dataset are both available at
https://github.com/HumaticsLAB/GTM-Transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DVC-P: Deep Video Compression with Perceptual Optimizations. (arXiv:2109.10849v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10849">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the significant development of learning-based
video compression methods, which aim at optimizing objective or perceptual
quality and bit rates. In this paper, we introduce deep video compression with
perceptual optimizations (DVC-P), which aims at increasing perceptual quality
of decoded videos. Our proposed DVC-P is based on Deep Video Compression (DVC)
network, but improves it with perceptual optimizations. Specifically, a
discriminator network and a mixed loss are employed to help our network trade
off among distortion, perception and rate. Furthermore, nearest-neighbor
interpolation is used to eliminate checkerboard artifacts which can appear in
sequences encoded with DVC frameworks. Thanks to these two improvements, the
perceptual quality of decoded sequences is improved. Experimental results
demonstrate that, compared with the baseline DVC, our proposed method can
generate videos with higher perceptual quality achieving 12.27% reduction in a
perceptual BD-rate equivalent, on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models. (arXiv:2109.11797v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11797">
<div class="article-summary-box-inner">
<span><p>Pre-Trained Vision-Language Models (VL-PTMs) have shown promising
capabilities in grounding natural language in image data, facilitating a broad
variety of cross-modal tasks. However, we note that there exists a significant
gap between the objective forms of model pre-training and fine-tuning,
resulting in a need for large amounts of labeled data to stimulate the visual
grounding capability of VL-PTMs for downstream tasks. To address the challenge,
we present Cross-modal Prompt Tuning (CPT, alternatively, Colorful Prompt
Tuning), a novel paradigm for tuning VL-PTMs, which reformulates visual
grounding into a fill-in-the-blank problem with color-based co-referential
markers in image and text, maximally mitigating the gap. In this way, CPT
enables strong few-shot and even zero-shot visual grounding capabilities of
VL-PTMs. Comprehensive experimental results show that the prompt-tuned VL-PTMs
outperform their fine-tuned counterparts by a large margin (e.g., 17.3%
absolute accuracy improvement, and 73.8% relative standard deviation reduction
on average with one shot in RefCOCO evaluation). All the data and codes will be
available to facilitate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HSVA: Hierarchical Semantic-Visual Adaptation for Zero-Shot Learning. (arXiv:2109.15163v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.15163">
<div class="article-summary-box-inner">
<span><p>Zero-shot learning (ZSL) tackles the unseen class recognition problem,
transferring semantic knowledge from seen classes to unseen ones. Typically, to
guarantee desirable knowledge transfer, a common (latent) space is adopted for
associating the visual and semantic domains in ZSL. However, existing common
space learning methods align the semantic and visual domains by merely
mitigating distribution disagreement through one-step adaptation. This strategy
is usually ineffective due to the heterogeneous nature of the feature
representations in the two domains, which intrinsically contain both
distribution and structure variations. To address this and advance ZSL, we
propose a novel hierarchical semantic-visual adaptation (HSVA) framework.
Specifically, HSVA aligns the semantic and visual domains by adopting a
hierarchical two-step adaptation, i.e., structure adaptation and distribution
adaptation. In the structure adaptation step, we take two task-specific
encoders to encode the source data (visual domain) and the target data
(semantic domain) into a structure-aligned common space. To this end, a
supervised adversarial discrepancy (SAD) module is proposed to adversarially
minimize the discrepancy between the predictions of two task-specific
classifiers, thus making the visual and semantic feature manifolds more closely
aligned. In the distribution adaptation step, we directly minimize the
Wasserstein distance between the latent multivariate Gaussian distributions to
align the visual and semantic distributions using a common encoder. Finally,
the structure and distribution adaptation are derived in a unified framework
under two partially-aligned variational autoencoders. Extensive experiments on
four benchmark datasets demonstrate that HSVA achieves superior performance on
both conventional and generalized ZSL. The code is available at
\url{https://github.com/shiming-chen/HSVA} .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Efficient Instance Segmentation with a Single GPU. (arXiv:2110.00242v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00242">
<div class="article-summary-box-inner">
<span><p>Not everyone is wealthy enough to have hundreds of GPUs or TPUs. Therefore,
we've got to find a way out. In this paper, we introduce a data-efficient
instance segmentation method we used in the 2021 VIPriors Instance Segmentation
Challenge. Our solution is a modified version of Swin Transformer, based on the
mmdetection which is a powerful toolbox. To solve the problem of lack of data,
we utilize data augmentation including random flip and multiscale training to
train our model. During inference, multiscale fusion is used to boost the
performance. We only use a single GPU during the whole training and testing
stages. In the end, our team named THU_IVG_2018 achieved the result of 0.366
for AP@0.50:0.95 on the test set, which is competitive with other top-ranking
methods while only one GPU is used. Besides, our method achieved the
AP@0.50:0.95 (medium) of 0.592, which ranks second among all contestants. In
the end, our team ranked third among all the contestants, as announced by the
organizers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Transfer Learning for Land Use Land Cover Classification: A Comparative Study. (arXiv:2110.02580v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02580">
<div class="article-summary-box-inner">
<span><p>Efficiently implementing remote sensing image classification with high
spatial resolution imagery can provide great significant value in land-use
land-cover classification (LULC). The developments in remote sensing and deep
learning technologies have facilitated the extraction of spatiotemporal
information for LULC classification. Moreover, the diverse disciplines of
science, including remote sensing, have utilised tremendous improvements in
image classification by CNNs with Transfer Learning. In this study, instead of
training CNNs from scratch, we make use of transfer learning to fine-tune
pre-trained networks a) VGG16 and b) Wide Residual Networks (WRNs), by
replacing the final layer with additional layers, for LULC classification with
EuroSAT dataset. Further, the performance and computational time were compared
and optimized with techniques like early stopping, gradient clipping, adaptive
learning rates and data augmentation. With the proposed approaches we were able
to address the limited-data problem and achieved very good accuracy.
Comprehensive comparisons over the EuroSAT RGB version benchmark have
successfully established that our method outperforms the previous best-stated
results, with a significant improvement over the accuracy from 98.57% to
99.17%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MovingFashion: a Benchmark for the Video-to-Shop Challenge. (arXiv:2110.02627v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02627">
<div class="article-summary-box-inner">
<span><p>Retrieving clothes which are worn in social media videos (Instagram, TikTok)
is the latest frontier of e-fashion, referred to as "video-to-shop" in the
computer vision literature. In this paper we present MovingFashion, the first
publicly available dataset to cope with this challenge. MovingFashion is
composed of 14855 social videos, each one of them associated to e-commerce
"shop" images where the corresponding clothing items are clearly portrayed. In
addition, we present a network for retrieving the shop images in this scenario,
dubbed SEAM Match-RCNN. The model is trained by image-to-video domain
adaptation, allowing to use video sequences where only their association with a
shop image is given, eliminating the need of millions of annotated bounding
boxes. SEAM Match-RCNN builds an embedding, where an attention-based weighted
sum of few frames (10) of a social video is enough to individuate the correct
product within the first 5 retrieved items in a 14K+ shop element gallery with
an accuracy of 80%. This provides the best performance on MovingFashion,
comparing exhaustively against the related state-of-the-art approaches and
alternative baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Propagating State Uncertainty Through Trajectory Forecasting. (arXiv:2110.03267v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03267">
<div class="article-summary-box-inner">
<span><p>Uncertainty pervades through the modern robotic autonomy stack, with nearly
every component (e.g., sensors, detection, classification, tracking, behavior
prediction) producing continuous or discrete probabilistic distributions.
Trajectory forecasting, in particular, is surrounded by uncertainty as its
inputs are produced by (noisy) upstream perception and its outputs are
predictions that are often probabilistic for use in downstream planning.
However, most trajectory forecasting methods do not account for upstream
uncertainty, instead taking only the most-likely values. As a result,
perceptual uncertainties are not propagated through forecasting and predictions
are frequently overconfident. To address this, we present a novel method for
incorporating perceptual state uncertainty in trajectory forecasting, a key
component of which is a new statistical distance-based loss function which
encourages predicting uncertainties that better match upstream perception. We
evaluate our approach both in illustrative simulations and on large-scale,
real-world data, demonstrating its efficacy in propagating perceptual state
uncertainty through prediction and producing more calibrated predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Image Decomposition with Phase-Correlation Networks. (arXiv:2110.03473v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03473">
<div class="article-summary-box-inner">
<span><p>The ability to decompose scenes into their object components is a desired
property for autonomous agents, allowing them to reason and act in their
surroundings. Recently, different methods have been proposed to learn
object-centric representations from data in an unsupervised manner. These
methods often rely on latent representations learned by deep neural networks,
hence requiring high computational costs and large amounts of curated data.
Such models are also difficult to interpret. To address these challenges, we
propose the Phase-Correlation Decomposition Network (PCDNet), a novel model
that decomposes a scene into its object components, which are represented as
transformed versions of a set of learned object prototypes. The core building
block in PCDNet is the Phase-Correlation Cell (PC Cell), which exploits the
frequency-domain representation of the images in order to estimate the
transformation between an object prototype and its transformed version in the
image. In our experiments, we show how PCDNet outperforms state-of-the-art
methods for unsupervised object discovery and segmentation on simple benchmark
datasets and on more challenging data, while using a small number of learnable
parameters and being fully interpretable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Sharpness-aware Minimization for Improved Training of Neural Networks. (arXiv:2110.03141v1 [cs.AI] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03141">
<div class="article-summary-box-inner">
<span><p>Overparametrized Deep Neural Networks (DNNs) often achieve astounding
performances, but may potentially result in severe generalization error.
Recently, the relation between the sharpness of the loss landscape and the
generalization error has been established by Foret et al. (2020), in which the
Sharpness Aware Minimizer (SAM) was proposed to mitigate the degradation of the
generalization. Unfortunately, SAM s computational cost is roughly double that
of base optimizers, such as Stochastic Gradient Descent (SGD). This paper thus
proposes Efficient Sharpness Aware Minimizer (ESAM), which boosts SAM s
efficiency at no cost to its generalization performance. ESAM includes two
novel and efficient training strategies-StochasticWeight Perturbation and
Sharpness-Sensitive Data Selection. In the former, the sharpness measure is
approximated by perturbing a stochastically chosen set of weights in each
iteration; in the latter, the SAM loss is optimized using only a judiciously
selected subset of data that is sensitive to the sharpness. We provide
theoretical explanations as to why these strategies perform well. We also show,
via extensive experiments on the CIFAR and ImageNet datasets, that ESAM
enhances the efficiency over SAM from requiring 100% extra computations to 40%
vis-a-vis base optimizers, while test accuracies are preserved or even
improved.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-11 23:02:20.623690713 UTC">2021-10-11 23:02:20 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>