<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-06T01:30:00Z">10-06</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Privacy enabled Financial Text Classification using Differential Privacy and Federated Learning. (arXiv:2110.01643v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01643">
<div class="article-summary-box-inner">
<span><p>Privacy is important considering the financial Domain as such data is highly
confidential and sensitive. Natural Language Processing (NLP) techniques can be
applied for text classification and entity detection purposes in financial
domains such as customer feedback sentiment analysis, invoice entity detection,
categorisation of financial documents by type etc. Due to the sensitive nature
of such data, privacy measures need to be taken for handling and training large
models with such data. In this work, we propose a contextualized transformer
(BERT and RoBERTa) based text classification model integrated with privacy
features such as Differential Privacy (DP) and Federated Learning (FL). We
present how to privately train NLP models and desirable privacy-utility
tradeoffs and evaluate them on the Financial Phrase Bank dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rerunning OCR -- A Machine Learning Approach to Quality Assessment and Enhancement Prediction. (arXiv:2110.01661v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01661">
<div class="article-summary-box-inner">
<span><p>Iterating with new and improved OCR solutions enforces decisions to be taken
when it comes to targeting the right reprocessing candidates. This especially
applies when the underlying data collection is of considerable size and rather
diverse in terms of fonts, languages, periods of publication and consequently
OCR quality. This article captures the efforts of the National Library of
Luxembourg to support those exact decisions. They are crucial in order to
guarantee low computational overhead and reduced quality degradation risks,
combined with a more quantifiable OCR improvement. In particular, this work
explains the methodology of the library with respect to text block level
quality assessment. As an extension of this technique, another contribution
comes in the form of a regression model that takes the enhancement potential of
a new OCR engine into account. They both mark promising approaches, especially
for cultural institutions dealing with historic data of lower quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts. (arXiv:2110.01691v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01691">
<div class="article-summary-box-inner">
<span><p>Although large language models (LLMs) have demonstrated impressive potential
on simple tasks, their breadth of scope, lack of transparency, and insufficient
controllability can make them less effective when assisting humans on more
complex tasks. In response, we introduce the concept of Chaining LLM steps
together, where the output of one step becomes the input for the next, thus
aggregating the gains per step. We first define a set of LLM primitive
operations useful for Chain construction, then present an interactive system
where users can modify these Chains, along with their intermediate results, in
a modular way. In a 20-person user study, we found that Chaining not only
improved the quality of task outcomes, but also significantly enhanced system
transparency, controllability, and sense of collaboration. Additionally, we saw
that users developed new ways of interacting with LLMs through Chains: they
leveraged sub-tasks to calibrate model expectations, compared and contrasted
alternative strategies by observing parallel downstream effects, and debugged
unexpected model outputs by "unit-testing" sub-components of a Chain. In two
case studies, we further explore how LLM Chains may be used in future
applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoEfication: Conditional Computation of Transformer Models for Efficient Inference. (arXiv:2110.01786v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01786">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-trained language models can achieve superior
performance on most NLP tasks due to large parameter capacity, but also lead to
huge computation cost. Fortunately, we find by empirical study that, most
inputs only activate a tiny ratio of neurons during inference. Hence, we
explore to accelerate large-model inference by conditional computation based on
the sparse activation phenomenon. We propose to transform a large model into
its mixture-of-experts (MoE) version with equal model size, namely MoEfication.
Model MoEfication consists of two steps: (1) splitting the parameters of
feed-forward neural networks (FFNs) into multiple parts as experts, and (2)
building expert routers to decide which experts will be used for each input. To
further improve the performance of MoEfied models, we can also fine-tune the
models on downstream tasks, namely parameter calibration. Experimental results
show that the MoEfied models can significantly reduce computation cost, e.g.,
only activating 20% FFN parameters of a 700-million-parameter model without
performance degradation on several downstream tasks including text
classification and reading comprehension.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts. (arXiv:2110.01799v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01799">
<div class="article-summary-box-inner">
<span><p>Reviewing contracts is a time-consuming procedure that incurs large expenses
to companies and social inequality to those who cannot afford it. In this work,
we propose "document-level natural language inference (NLI) for contracts", a
novel, real-world application of NLI that addresses such problems. In this
task, a system is given a set of hypotheses (such as "Some obligations of
Agreement may survive termination.") and a contract, and it is asked to
classify whether each hypothesis is "entailed by", "contradicting to" or "not
mentioned by" (neutral to) the contract as well as identifying "evidence" for
the decision as spans in the contract. We annotated and release the largest
corpus to date consisting of 607 annotated contracts. We then show that
existing models fail badly on our task and introduce a strong baseline, which
(1) models evidence identification as multi-label classification over spans
instead of trying to predict start and end tokens, and (2) employs more
sophisticated context segmentation for dealing with long documents. We also
show that linguistic characteristics of contracts, such as negations by
exceptions, are contributing to the difficulty of this task and that there is
much room for improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey On Neural Word Embeddings. (arXiv:2110.01804v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01804">
<div class="article-summary-box-inner">
<span><p>Understanding human language has been a sub-challenge on the way of
intelligent machines. The study of meaning in natural language processing (NLP)
relies on the distributional hypothesis where language elements get meaning
from the words that co-occur within contexts. The revolutionary idea of
distributed representation for a concept is close to the working of a human
mind in that the meaning of a word is spread across several neurons, and a loss
of activation will only slightly affect the memory retrieval process.
</p>
<p>Neural word embeddings transformed the whole field of NLP by introducing
substantial improvements in all NLP tasks. In this survey, we provide a
comprehensive literature review on neural word embeddings. We give theoretical
foundations and describe existing work by an interplay between word embeddings
and language modelling. We provide broad coverage on neural word embeddings,
including early word embeddings, embeddings targeting specific semantic
relations, sense embeddings, morpheme embeddings, and finally, contextual
representations. Finally, we describe benchmark datasets in word embeddings'
performance evaluation and downstream tasks along with the performance results
of/due to word embeddings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Complementarity between Pre-Training and Back-Translation for Neural Machine Translation. (arXiv:2110.01811v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01811">
<div class="article-summary-box-inner">
<span><p>Pre-training (PT) and back-translation (BT) are two simple and powerful
methods to utilize monolingual data for improving the model performance of
neural machine translation (NMT). This paper takes the first step to
investigate the complementarity between PT and BT. We introduce two probing
tasks for PT and BT respectively and find that PT mainly contributes to the
encoder module while BT brings more benefits to the decoder. Experimental
results show that PT and BT are nicely complementary to each other,
establishing state-of-the-art performances on the WMT16 English-Romanian and
English-Russian benchmarks. Through extensive analyses on sentence originality
and word frequency, we also demonstrate that combining Tagged BT with PT is
more helpful to their complementarity, leading to better translation quality.
Source code is freely available at https://github.com/SunbowLiu/PTvsBT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Truth-Conditional Captioning of Time Series Data. (arXiv:2110.01839v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01839">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore the task of automatically generating natural
language descriptions of salient patterns in a time series, such as stock
prices of a company over a week. A model for this task should be able to
extract high-level patterns such as presence of a peak or a dip. While typical
contemporary neural models with attention mechanisms can generate fluent output
descriptions for this task, they often generate factually incorrect
descriptions. We propose a computational model with a truth-conditional
architecture which first runs small learned programs on the input time series,
then identifies the programs/patterns which hold true for the given input, and
finally conditions on only the chosen valid program (rather than the input time
series) to generate the output text description. A program in our model is
constructed from modules, which are small neural networks that are designed to
capture numerical patterns and temporal information. The modules are shared
across multiple programs, enabling compositionality as well as efficient
learning of module parameters. The modules, as well as the composition of the
modules, are unobserved in data, and we learn them in an end-to-end fashion
with the only training signal coming from the accompanying natural language
text descriptions. We find that the proposed model is able to generate
high-precision captions even though we consider a small and simple space of
module types.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation Approaches in Natural Language Processing: A Survey. (arXiv:2110.01852v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01852">
<div class="article-summary-box-inner">
<span><p>As an effective strategy, data augmentation (DA) alleviates data scarcity
scenarios where deep learning techniques may fail. It is widely applied in
computer vision then introduced to natural language processing and achieves
improvements in many tasks. One of the main focuses of the DA methods is to
improve the diversity of training data, thereby helping the model to better
generalize to unseen testing data. In this survey, we frame DA methods into
three categories based on the diversity of augmented data, including
paraphrasing, noising, and sampling. Our paper sets out to analyze DA methods
in detail according to the above categories. Further, we also introduce their
applications in NLP tasks as well as the challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASR Rescoring and Confidence Estimation with ELECTRA. (arXiv:2110.01857v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01857">
<div class="article-summary-box-inner">
<span><p>In automatic speech recognition (ASR) rescoring, the hypothesis with the
fewest errors should be selected from the n-best list using a language model
(LM). However, LMs are usually trained to maximize the likelihood of correct
word sequences, not to detect ASR errors. We propose an ASR rescoring method
for directly detecting errors with ELECTRA, which is originally a pre-training
method for NLP tasks. ELECTRA is pre-trained to predict whether each word is
replaced by BERT or not, which can simulate ASR error detection on large text
corpora. To make this pre-training closer to ASR error detection, we further
propose an extended version of ELECTRA called phone-attentive ELECTRA
(P-ELECTRA). In the pre-training of P-ELECTRA, each word is replaced by a
phone-to-word conversion model, which leverages phone information to generate
acoustically similar words. Since our rescoring method is optimized for
detecting errors, it can also be used for word-level confidence estimation.
Experimental evaluations on the Librispeech and TED-LIUM2 corpora show that our
rescoring method with ELECTRA is competitive with conventional rescoring
methods with faster inference. ELECTRA also performs better in confidence
estimation than BERT because it can learn to detect inappropriate words not
only in fine-tuning but also in pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Impact of Pre-trained Language Models on Dialog Evaluation. (arXiv:2110.01895v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01895">
<div class="article-summary-box-inner">
<span><p>Recently, there is a surge of interest in applying pre-trained language
models (Pr-LM) in automatic open-domain dialog evaluation. Pr-LMs offer a
promising direction for addressing the multi-domain evaluation challenge. Yet,
the impact of different Pr-LMs on the performance of automatic metrics is not
well-understood. This paper examines 8 different Pr-LMs and studies their
impact on three typical automatic dialog evaluation metrics across three
different dialog evaluation benchmarks. Specifically, we analyze how the choice
of Pr-LMs affects the performance of automatic metrics. Extensive correlation
analyses on each of the metrics are performed to assess the effects of
different Pr-LMs along various axes, including pre-training objectives, dialog
evaluation criteria, model size, and cross-dataset robustness. This study
serves as the first comprehensive assessment of the effects of different Pr-LMs
on automatic dialog evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DistilHuBERT: Speech Representation Learning by Layer-wise Distillation of Hidden-unit BERT. (arXiv:2110.01900v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01900">
<div class="article-summary-box-inner">
<span><p>Self-supervised speech representation learning methods like wav2vec 2.0 and
Hidden-unit BERT (HuBERT) leverage unlabeled speech data for pre-training and
offer good representations for numerous speech processing tasks. Despite the
success of these methods, they require large memory and high pre-training
costs, making them inaccessible for researchers in academia and small
companies. Therefore, this paper introduces DistilHuBERT, a novel multi-task
learning framework to distill hidden representations from a HuBERT model
directly. This method reduces HuBERT's size by 75% and 73% faster while
retaining most performance in ten different tasks. Moreover, DistilHuBERT
required little training time and data, opening the possibilities of
pre-training personal and on-device SSL models for speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sicilian Translator: A Recipe for Low-Resource NMT. (arXiv:2110.01938v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01938">
<div class="article-summary-box-inner">
<span><p>With 17,000 pairs of Sicilian-English translated sentences, Arba Sicula
developed the first neural machine translator for the Sicilian language. Using
small subword vocabularies, we trained small Transformer models with high
dropout parameters and achieved BLEU scores in the upper 20s. Then we
supplemented our dataset with backtranslation and multilingual translation and
pushed our scores into the mid 30s. We also attribute our success to
incorporating theoretical information in our dataset. Prior to training, we
biased the subword vocabulary towards the desinences one finds in a textbook.
And we included textbook exercises in our dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AraCOVID19-SSD: Arabic COVID-19 Sentiment and Sarcasm Detection Dataset. (arXiv:2110.01948v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01948">
<div class="article-summary-box-inner">
<span><p>Coronavirus disease (COVID-19) is an infectious respiratory disease that was
first discovered in late December 2019, in Wuhan, China, and then spread
worldwide causing a lot of panic and death. Users of social networking sites
such as Facebook and Twitter have been focused on reading, publishing, and
sharing novelties, tweets, and articles regarding the newly emerging pandemic.
A lot of these users often employ sarcasm to convey their intended meaning in a
humorous, funny, and indirect way making it hard for computer-based
applications to automatically understand and identify their goal and the harm
level that they can inflect. Motivated by the emerging need for annotated
datasets that tackle these kinds of problems in the context of COVID-19, this
paper builds and releases AraCOVID19-SSD a manually annotated Arabic COVID-19
sarcasm and sentiment detection dataset containing 5,162 tweets. To confirm the
practical utility of the built dataset, it has been carefully analyzed and
tested using several classification models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Objective Few-shot Learning for Fair Classification. (arXiv:2110.01951v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01951">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a general framework for mitigating the disparities
of the predicted classes with respect to secondary attributes within the data
(e.g., race, gender etc.). Our proposed method involves learning a
multi-objective function that in addition to learning the primary objective of
predicting the primary class labels from the data, also employs a
clustering-based heuristic to minimize the disparities of the class label
distribution with respect to the cluster memberships, with the assumption that
each cluster should ideally map to a distinct combination of attribute values.
Experiments demonstrate effective mitigation of cognitive biases on a benchmark
dataset without the use of annotations of secondary attribute values (the
zero-shot case) or with the use of a small number of attribute value
annotations (the few-shot case).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Transition System for End-to-End Opinion Role Labeling. (arXiv:2110.02001v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02001">
<div class="article-summary-box-inner">
<span><p>Unified opinion role labeling (ORL) aims to detect all possible opinion
structures of `opinion-holder-target' in one shot, given a text. The existing
transition-based unified method, unfortunately, is subject to longer opinion
terms and fails to solve the term overlap issue. Current top performance has
been achieved by employing the span-based graph model, which however still
suffers from both high model complexity and insufficient interaction among
opinions and roles. In this work, we investigate a novel solution by revisiting
the transition architecture, and augment it with a pointer network (PointNet).
The framework parses out all opinion structures in linear-time complexity,
meanwhile breaks through the limitation of any length of terms with PointNet.
To achieve the explicit opinion-role interactions, we further propose a unified
dependency-opinion graph (UDOG), co-modeling the syntactic dependency structure
and the partial opinion-role structure. We then devise a relation-centered
graph aggregator (RCGA) to encode the multi-relational UDOG, where the
resulting high-order representations are used to promote the predictions in the
vanilla transition system. Our model achieves new state-of-the-art results on
the MPQA benchmark. Analyses further demonstrate the superiority of our methods
on both efficacy and efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FoodChem: A food-chemical relation extraction model. (arXiv:2110.02019v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02019">
<div class="article-summary-box-inner">
<span><p>In this paper, we present FoodChem, a new Relation Extraction (RE) model for
identifying chemicals present in the composition of food entities, based on
textual information provided in biomedical peer-reviewed scientific literature.
The RE task is treated as a binary classification problem, aimed at identifying
whether the contains relation exists between a food-chemical entity pair. This
is accomplished by fine-tuning BERT, BioBERT and RoBERTa transformer models.
For evaluation purposes, a novel dataset with annotated contains relations in
food-chemical entity pairs is generated, in a golden and silver version. The
models are integrated into a voting scheme in order to produce the silver
version of the dataset which we use for augmenting the individual models, while
the manually annotated golden version is used for their evaluation. Out of the
three evaluated models, the BioBERT model achieves the best results, with a
macro averaged F1 score of 0.902 in the unbalanced augmentation setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Twitter as Source of Large Corpora of Weakly Similar Pairs for Semantic Sentence Embeddings. (arXiv:2110.02030v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02030">
<div class="article-summary-box-inner">
<span><p>Semantic sentence embeddings are usually supervisedly built minimizing
distances between pairs of embeddings of sentences labelled as semantically
similar by annotators. Since big labelled datasets are rare, in particular for
non-English languages, and expensive, recent studies focus on unsupervised
approaches that require not-paired input sentences. We instead propose a
language-independent approach to build large datasets of pairs of informal
texts weakly similar, without manual human effort, exploiting Twitter's
intrinsic powerful signals of relatedness: replies and quotes of tweets. We use
the collected pairs to train a Transformer model with triplet-like structures,
and we test the generated embeddings on Twitter NLP similarity tasks (PIT and
TURL) and STSb. We also introduce four new sentence ranking evaluation
benchmarks of informal texts, carefully extracted from the initial collections
of tweets, proving not only that our best model learns classical Semantic
Textual Similarity, but also excels on tasks where pairs of sentences are not
exact paraphrases. Ablation studies reveal how increasing the corpus size
influences positively the results, even at 2M samples, suggesting that bigger
collections of Tweets still do not contain redundant information about semantic
similarities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FooDI-ML: a large multi-language dataset of food, drinks and groceries images and descriptions. (arXiv:2110.02035v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02035">
<div class="article-summary-box-inner">
<span><p>In this paper we introduce the Food Drinks and groceries Images Multi Lingual
(FooDI-ML) dataset. This dataset contains over 1.5M unique images and over 9.5M
store names, product names descriptions, and collection sections gathered from
the Glovo application. The data made available corresponds to food, drinks and
groceries products from 37 countries in Europe, the Middle East, Africa and
Latin America. The dataset comprehends 33 languages, including 870K samples of
languages of countries from Eastern Europe and Western Asia such as Ukrainian
and Kazakh, which have been so far underrepresented in publicly available
visio-linguistic datasets. The dataset also includes widely spoken languages
such as Spanish and English. To assist further research, we include a benchmark
over the text-image retrieval task using ADAPT, a SotA existing technique.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ur-iw-hnt at GermEval 2021: An Ensembling Strategy with Multiple BERT Models. (arXiv:2110.02042v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02042">
<div class="article-summary-box-inner">
<span><p>This paper describes our approach (ur-iw-hnt) for the Shared Task of
GermEval2021 to identify toxic, engaging, and fact-claiming comments. We
submitted three runs using an ensembling strategy by majority (hard) voting
with multiple different BERT models of three different types: German-based,
Twitter-based, and multilingual models. All ensemble models outperform single
models, while BERTweet is the winner of all individual models in every subtask.
Twitter-based models perform better than GermanBERT models, and multilingual
models perform worse but by a small margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TENT: Text Classification Based on ENcoding Tree Learning. (arXiv:2110.02047v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02047">
<div class="article-summary-box-inner">
<span><p>Text classification is a primary task in natural language processing (NLP).
Recently, graph neural networks (GNNs) have developed rapidly and been applied
to text classification tasks. Although more complex models tend to achieve
better performance, research highly depends on the computing power of the
device used. In this article, we propose TENT (https://github.com/Daisean/TENT)
to obtain better text classification performance and reduce the reliance on
computing power. Specifically, we first establish a dependency analysis graph
for each text and then convert each graph into its corresponding encoding tree.
The representation of the entire graph is obtained by updating the
representation of the non-leaf nodes in the encoding tree. Experimental results
show that our method outperforms other baselines on several datasets while
having a simple structure and few parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transfer Learning for Multi-lingual Tasks -- a Survey. (arXiv:2110.02052v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02052">
<div class="article-summary-box-inner">
<span><p>These days different platforms such as social media provide their clients
from different backgrounds and languages the possibility to connect and
exchange information. It is not surprising anymore to see comments from
different languages in posts published by international celebrities or data
providers. In this era, understanding cross languages content and
multilingualism in natural language processing (NLP) are hot topics, and
multiple efforts have tried to leverage existing technologies in NLP to tackle
this challenging research problem. In this survey, we provide a comprehensive
overview of the existing literature with a focus on transfer learning
techniques in multilingual tasks. We also identify potential opportunities for
further research in this domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NoiER: An Approach for Training more Reliable Fine-TunedDownstream Task Models. (arXiv:2110.02054v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02054">
<div class="article-summary-box-inner">
<span><p>The recent development in pretrained language models trained in a
self-supervised fashion, such as BERT, is driving rapid progress in the field
of NLP. However, their brilliant performance is based on leveraging syntactic
artifacts of the training data rather than fully understanding the intrinsic
meaning of language. The excessive exploitation of spurious artifacts causes a
problematic issue: The distribution collapse problem, which is the phenomenon
that the model fine-tuned on downstream tasks is unable to distinguish
out-of-distribution (OOD) sentences while producing a high confidence score. In
this paper, we argue that distribution collapse is a prevalent issue in
pretrained language models and propose noise entropy regularisation (NoiER) as
an efficient learning paradigm that solves the problem without auxiliary models
and additional~data. The proposed approach improved traditional OOD detection
evaluation metrics by 55% on average compared to the original fine-tuned
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Training Resources Insufficient? Predict First Then Explain!. (arXiv:2110.02056v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02056">
<div class="article-summary-box-inner">
<span><p>Natural language free-text explanation generation is an efficient approach to
train explainable language processing models for
commonsense-knowledge-requiring tasks. The most predominant form of these
models is the explain-then-predict (EtP) structure, which first generates
explanations and uses them for making decisions. The performance of EtP models
is highly dependent on that of the explainer by the nature of their structure.
Therefore, large-sized explanation data are required to train a good explainer
model. However, annotating explanations is expensive. Also, recent works reveal
that free-text explanations might not convey sufficient information for
decision making. These facts cast doubts on the effectiveness of EtP models. In
this paper, we argue that the predict-then-explain (PtE) architecture is a more
efficient approach in terms of the modelling perspective. Our main contribution
is twofold. First, we show that the PtE structure is the most data-efficient
approach when explanation data are lacking. Second, we reveal that the PtE
structure is always more training-efficient than the EtP structure. We also
provide experimental results that confirm the theoretical advantages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Prediction in NLP -- A survey. (arXiv:2110.02057v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02057">
<div class="article-summary-box-inner">
<span><p>Over the last several years, the field of Structured prediction in NLP has
had seen huge advancements with sophisticated probabilistic graphical models,
energy-based networks, and its combination with deep learning-based approaches.
This survey provides a brief of major techniques in structured prediction and
its applications in the NLP domains like parsing, sequence labeling, text
generation, and sequence to sequence tasks. We also deep-dived into
energy-based and attention-based techniques in structured prediction,
identified some relevant open issues and gaps in the current state-of-the-art
research, and have come up with some detailed ideas for future research in
these fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactively Generating Explanations for Transformer-based Language Models. (arXiv:2110.02058v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02058">
<div class="article-summary-box-inner">
<span><p>Transformer language models are state-of-the-art in a multitude of NLP tasks.
Despite these successes, their opaqueness remains problematic. Recent methods
aiming to provide interpretability and explainability to black-box models
primarily focus on post-hoc explanations of (sometimes spurious) input-output
correlations. Instead, we emphasize using prototype networks directly
incorporated into the model architecture and hence explain the reasoning
process behind the network's decisions. Moreover, while our architecture
performs on par with several language models, it enables one to learn from user
interactions. This not only offers a better understanding of language models,
but uses human capabilities to incorporate knowledge outside of the rigid range
of purely data-driven approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Relational Graph based Heterogeneous Multi-Task Learning in Community Question Answering. (arXiv:2110.02059v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02059">
<div class="article-summary-box-inner">
<span><p>Various data mining tasks have been proposed to study Community Question
Answering (CQA) platforms like Stack Overflow. The relatedness between some of
these tasks provides useful learning signals to each other via Multi-Task
Learning (MTL). However, due to the high heterogeneity of these tasks, few
existing works manage to jointly solve them in a unified framework. To tackle
this challenge, we develop a multi-relational graph based MTL model called
Heterogeneous Multi-Task Graph Isomorphism Network (HMTGIN) which efficiently
solves heterogeneous CQA tasks. In each training forward pass, HMTGIN embeds
the input CQA forum graph by an extension of Graph Isomorphism Network and skip
connections. The embeddings are then shared across all task-specific output
layers to compute respective losses. Moreover, two cross-task constraints based
on the domain knowledge about tasks' relationships are used to regularize the
joint learning. In the evaluation, the embeddings are shared among different
task-specific output layers to make corresponding predictions. To the best of
our knowledge, HMTGIN is the first MTL model capable of tackling CQA tasks from
the aspect of multi-relational graphs. To evaluate HMTGIN's effectiveness, we
build a novel large-scale multi-relational graph CQA dataset with over two
million nodes from Stack Overflow. Extensive experiments show that: $(1)$
HMTGIN is superior to all baselines on five tasks; $(2)$ The proposed MTL
strategy and cross-task constraints have substantial advantages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teach Me What to Say and I Will Learn What to Pick: Unsupervised Knowledge Selection Through Response Generation with Pretrained Generative Models. (arXiv:2110.02067v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02067">
<div class="article-summary-box-inner">
<span><p>Knowledge Grounded Conversation Models (KGCM) are usually based on a
selection/retrieval module and a generation module, trained separately or
simultaneously, with or without having access to a gold knowledge option. With
the introduction of large pre-trained generative models, the selection and
generation part have become more and more entangled, shifting the focus towards
enhancing knowledge incorporation (from multiple sources) instead of trying to
pick the best knowledge option. These approaches however depend on knowledge
labels and/or a separate dense retriever for their best performance. In this
work we study the unsupervised selection abilities of pre-trained generative
models (e.g. BART) and show that by adding a score-and-aggregate module between
encoder and decoder, they are capable of learning to pick the proper knowledge
through minimising the language modelling loss (i.e. without having access to
knowledge labels). Trained as such, our model - K-Mine - shows competitive
selection and generation performance against models that benefit from knowledge
labels and/or separate dense retriever.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OPAD: An Optimized Policy-based Active Learning Framework for Document Content Analysis. (arXiv:2110.02069v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02069">
<div class="article-summary-box-inner">
<span><p>Documents are central to many business systems, and include forms, reports,
contracts, invoices or purchase orders. The information in documents is
typically in natural language, but can be organized in various layouts and
formats. There have been recent spurt of interest in understanding document
content with novel deep learning architectures. However, document understanding
tasks need dense information annotations, which are costly to scale and
generalize. Several active learning techniques have been proposed to reduce the
overall budget of annotation while maintaining the performance of the
underlying deep learning model. However, most of these techniques work only for
classification problems. But content detection is a more complex task, and has
been scarcely explored in active learning literature. In this paper, we propose
\textit{OPAD}, a novel framework using reinforcement policy for active learning
in content detection tasks for documents. The proposed framework learns the
acquisition function to decide the samples to be selected while optimizing
performance metrics that the tasks typically have. Furthermore, we extend to
weak labelling scenarios to further reduce the cost of annotation
significantly. We propose novel rewards to account for class imbalance and user
feedback in the annotation interface, to improve the active learning method. We
show superior performance of the proposed \textit{OPAD} framework for active
learning for various tasks related to document understanding like layout
parsing, object detection and named entity recognition. Ablation studies for
human feedback and class imbalance rewards are presented, along with a
comparison of annotation times for different approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NaRLE: Natural Language Models using Reinforcement Learning with Emotion Feedback. (arXiv:2110.02148v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02148">
<div class="article-summary-box-inner">
<span><p>Current research in dialogue systems is focused on conversational assistants
working on short conversations in either task-oriented or open domain settings.
In this paper, we focus on improving task-based conversational assistants
online, primarily those working on document-type conversations (e.g., emails)
whose contents may or may not be completely related to the assistant's task. We
propose "NARLE" a deep reinforcement learning (RL) framework for improving the
natural language understanding (NLU) component of dialogue systems online
without the need to collect human labels for customer data. The proposed
solution associates user emotion with the assistant's action and uses that to
improve NLU models using policy gradients. For two intent classification
problems, we empirically show that using reinforcement learning to fine tune
the pre-trained supervised learning models improves performance up to 43%.
Furthermore, we demonstrate the robustness of the method to partial and noisy
implicit feedback.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing the Impact of COVID-19 on Economy from the Perspective of Users Reviews. (arXiv:2110.02198v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02198">
<div class="article-summary-box-inner">
<span><p>One of the most important incidents in the world in 2020 is the outbreak of
the Coronavirus. Users on social networks publish a large number of comments
about this event. These comments contain important hidden information of public
opinion regarding this pandemic. In this research, a large number of
Coronavirus-related tweets are considered and analyzed using natural language
processing and information retrieval science. Initially, the location of the
tweets is determined using a dictionary prepared through the Geo-Names
geographic database, which contains detailed and complete information of places
such as city names, streets, and postal codes. Then, using a large dictionary
prepared from the terms of economics, related tweets are extracted and
sentiments corresponded to tweets are analyzed with the help of the RoBERTa
language-based model, which has high accuracy and good performance. Finally,
the frequency chart of tweets related to the economy and their sentiment scores
(positive and negative tweets) is plotted over time for the entire world and
the top 10 economies. From the analysis of the charts, we learn that the reason
for publishing economic tweets is not only the increase in the number of people
infected with the Coronavirus but also imposed restrictions and lockdowns in
countries. The consequences of these restrictions include the loss of millions
of jobs and the economic downturn.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Psuedolabels for training Sentiment Classifiers makes the model generalize better across datasets. (arXiv:2110.02200v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02200">
<div class="article-summary-box-inner">
<span><p>The problem statement addressed in this work is : For a public sentiment
classification API, how can we set up a classifier that works well on different
types of data, having limited ability to annotate data from across domains. We
show that given a large amount of unannotated data from across different
domains and pseudolabels on this dataset generated by a classifier trained on a
small annotated dataset from one domain, we can train a sentiment classifier
that generalizes better across different datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Sense-Specific Static Embeddings using Contextualised Word Embeddings as a Proxy. (arXiv:2110.02204v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02204">
<div class="article-summary-box-inner">
<span><p>Contextualised word embeddings generated from Neural Language Models (NLMs),
such as BERT, represent a word with a vector that considers the semantics of
the target word as well its context. On the other hand, static word embeddings
such as GloVe represent words by relatively low-dimensional, memory- and
compute-efficient vectors but are not sensitive to the different senses of the
word. We propose Context Derived Embeddings of Senses (CDES), a method that
extracts sense related information from contextualised embeddings and injects
it into static embeddings to create sense-specific static embeddings.
Experimental results on multiple benchmarks for word sense disambiguation and
sense discrimination tasks show that CDES can accurately learn sense-specific
static embeddings reporting comparable performance to the current
state-of-the-art sense embeddings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Waypoint Models for Instruction-guided Navigation in Continuous Environments. (arXiv:2110.02207v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02207">
<div class="article-summary-box-inner">
<span><p>Little inquiry has explicitly addressed the role of action spaces in
language-guided visual navigation -- either in terms of its effect on
navigation success or the efficiency with which a robotic agent could execute
the resulting trajectory. Building on the recently released VLN-CE setting for
instruction following in continuous environments, we develop a class of
language-conditioned waypoint prediction networks to examine this question. We
vary the expressivity of these models to explore a spectrum between low-level
actions and continuous waypoint prediction. We measure task performance and
estimated execution time on a profiled LoCoBot robot. We find more expressive
models result in simpler, faster to execute trajectories, but lower-level
actions can achieve better navigation metrics by approximating shortest paths
better. Further, our models outperform prior work in VLN-CE and set a new
state-of-the-art on the public leaderboard -- increasing success rate by 4%
with our best model on this challenging task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Legal Approach to Hate Speech: Operationalizing the EU's Legal Framework against the Expression of Hatred as an NLP Task. (arXiv:2004.03422v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.03422">
<div class="article-summary-box-inner">
<span><p>We propose a 'legal approach' to hate speech detection by operationalization
of the decision as to whether a post is subject to criminal law into an NLP
task. Comparing existing regulatory regimes for hate speech, we base our
investigation on the European Union's framework as it provides a widely
applicable legal minimum standard. Accurately judging whether a post is
punishable or not usually requires legal training. We show that, by breaking
the legal assessment down into a series of simpler sub-decisions, even
laypersons can annotate consistently. Based on a newly annotated dataset, our
experiments show that directly learning an automated model of punishable
content is challenging. However, learning the two sub-tasks of `target group'
and `targeting conduct' instead of an end-to-end approach to punishability
yields better results. Overall, our method also provides decisions that are
more transparent than those of end-to-end models, which is a crucial point in
legal decision-making.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enriched Pre-trained Transformers for Joint Slot Filling and Intent Detection. (arXiv:2004.14848v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.14848">
<div class="article-summary-box-inner">
<span><p>Detecting the user's intent and finding the corresponding slots among the
utterance's words are important tasks in natural language understanding. Their
interconnected nature makes their joint modeling a standard part of training
such models. Moreover, data scarceness and specialized vocabularies pose
additional challenges. Recently, the advances in pre-trained language models,
namely contextualized models such as ELMo and BERT have revolutionized the
field by tapping the potential of training very large models with just a few
steps of fine-tuning on a task-specific dataset. Here, we leverage such models,
namely BERT and RoBERTa, and we design a novel architecture on top of them.
Moreover, we propose an intent pooling attention mechanism, and we reinforce
the slot filling task by fusing intent distributions, word features, and token
representations. The experimental results on standard datasets show that our
model outperforms both the current non-BERT state of the art as well as some
stronger BERT-based baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dataset for Automatic Summarization of Russian News. (arXiv:2006.11063v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11063">
<div class="article-summary-box-inner">
<span><p>Automatic text summarization has been studied in a variety of domains and
languages. However, this does not hold for the Russian language. To overcome
this issue, we present Gazeta, the first dataset for summarization of Russian
news. We describe the properties of this dataset and benchmark several
extractive and abstractive models. We demonstrate that the dataset is a valid
task for methods of text summarization for Russian. Additionally, we prove the
pretrained mBART model to be useful for Russian text summarization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Book Success Prediction with Pretrained Sentence Embeddings and Readability Scores. (arXiv:2007.11073v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.11073">
<div class="article-summary-box-inner">
<span><p>Predicting the potential success of a book in advance is vital in many
applications. This could help both publishers and readers in their
decision-making process whether or not a book is worth publishing and reading,
respectively. In this paper, we propose a model that leverages pretrained
sentence embeddings along with various readability scores for book success
prediction. Unlike previous methods, the proposed method requires no
count-based, lexical, or syntactic features. Instead, we use a convolutional
neural network over pretrained sentence embeddings and leverage different
readability scores through a simple concatenation operation. Our proposed model
outperforms strong baselines for this task by as large as 6.4\% F1-score
points. Moreover, our experiments show that according to our model, only the
first 1K sentences are good enough to predict the potential success of books.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The optimality of syntactic dependency distances. (arXiv:2007.15342v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15342">
<div class="article-summary-box-inner">
<span><p>It is often stated that human languages, as other biological systems, are
shaped by cost-cutting pressures but, to what extent? Attempts to quantify the
degree of optimality of languages by means of an optimality score have been
scarce and focused mostly on English. Here we recast the problem of the
optimality of the word order of a sentence as an optimization problem on a
spatial network where the vertices are words, arcs indicate syntactic
dependencies and the space is defined by the linear order of the words in the
sentence. We introduce a new score to quantify the cognitive pressure to reduce
the distance between linked words in a sentence. The analysis of sentences from
93 languages representing 19 linguistic families reveals that half of languages
are optimized to a 70% or more. The score indicates that distances are not
significantly reduced in a few languages and confirms two theoretical
predictions, i.e. that longer sentences are more optimized and that distances
are more likely to be longer than expected by chance in short sentences. We
present a new hierarchical ranking of languages by their degree of
optimization. The new score has implications for various fields of language
research (dependency linguistics, typology, historical linguistics, clinical
linguistics and cognitive science). Finally, the principles behind the design
of the score have implications for network science.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Quality Assessment of Cognitive Behavioral Therapy Sessions Through Highly Contextualized Language Representations. (arXiv:2102.11573v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11573">
<div class="article-summary-box-inner">
<span><p>During a psychotherapy session, the counselor typically adopts techniques
which are codified along specific dimensions (e.g., 'displays warmth and
confidence', or 'attempts to set up collaboration') to facilitate the
evaluation of the session. Those constructs, traditionally scored by trained
human raters, reflect the complex nature of psychotherapy and highly depend on
the context of the interaction. Recent advances in deep contextualized language
models offer an avenue for accurate in-domain linguistic representations which
can lead to robust recognition and scoring of such psychotherapy-relevant
behavioral constructs, and support quality assurance and supervision. In this
work, we propose a BERT-based model for automatic behavioral scoring of a
specific type of psychotherapy, called Cognitive Behavioral Therapy (CBT),
where prior work is limited to frequency-based language features and/or short
text excerpts which do not capture the unique elements involved in a
spontaneous long conversational interaction. The model focuses on the
classification of therapy sessions with respect to the overall score achieved
on the widely-used Cognitive Therapy Rating Scale (CTRS), but is trained in a
multi-task manner in order to achieve higher interpretability. BERT-based
representations are further augmented with available therapy metadata,
providing relevant non-linguistic context and leading to consistent performance
improvements. We train and evaluate our models on a set of 1,118 real-world
therapy sessions, recorded and automatically transcribed. Our best model
achieves an F1 score equal to 72.61% on the binary classification task of low
vs. high total CTRS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is BERT a Cross-Disciplinary Knowledge Learner? A Surprising Finding of Pre-trained Models' Transferability. (arXiv:2103.07162v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07162">
<div class="article-summary-box-inner">
<span><p>This paper investigates whether the power of the models pre-trained on text
data, such as BERT, can be transferred to general token sequence classification
applications. To verify pre-trained models' transferability, we test the
pre-trained models on text classification tasks with meanings of tokens
mismatches, and real-world non-text token sequence classification data,
including amino acid, DNA, and music. We find that even on non-text data, the
models pre-trained on text converge faster, perform better than the randomly
initialized models, and only slightly worse than the models using task-specific
knowledge. We also find that the representations of the text and non-text
pre-trained models share non-trivial similarities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integer-only Zero-shot Quantization for Efficient Speech Recognition. (arXiv:2103.16827v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16827">
<div class="article-summary-box-inner">
<span><p>End-to-end neural network models achieve improved performance on various
automatic speech recognition (ASR) tasks. However, these models perform poorly
on edge hardware due to large memory and computation requirements. While
quantizing model weights and/or activations to low-precision can be a promising
solution, previous research on quantizing ASR models is limited. In particular,
the previous approaches use floating-point arithmetic during inference and thus
they cannot fully exploit efficient integer processing units. Moreover, they
require training/validation data during quantization, which may not be
available due to security/privacy concerns. To address these limitations, we
propose an integer-only, zero shot quantization scheme for ASR models. In
particular, we generate synthetic data whose runtime statistics resemble the
real data, and we use it to calibrate models during quantization. We apply our
method to quantize QuartzNet, Jasper, and Conformer and show negligible WER
change as compared to the full-precision baseline models, even without using
any training data. Moreover, we achieve up to 2.35x speedup on a T4 GPU and 4x
compression rate, with a modest WER degradation of &lt;1% with INT8 quantization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Architectures and Training for Raw Waveform Feature Extraction in ASR. (arXiv:2104.04298v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04298">
<div class="article-summary-box-inner">
<span><p>With the success of neural network based modeling in automatic speech
recognition (ASR), many studies investigated acoustic modeling and learning of
feature extractors directly based on the raw waveform. Recently, one line of
research has focused on unsupervised pre-training of feature extractors on
audio-only data to improve downstream ASR performance. In this work, we
investigate the usefulness of one of these front-end frameworks, namely
wav2vec, in a setting without additional untranscribed data for hybrid ASR
systems. We compare this framework both to the manually defined standard
Gammatone feature set, as well as to features extracted as part of the acoustic
model of an ASR system trained supervised. We study the benefits of using the
pre-trained feature extractor and explore how to additionally exploit an
existing acoustic model trained with different features. Finally, we
systematically examine combinations of the described features in order to
further advance the performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empathetic Dialog Generation with Fine-Grained Intents. (arXiv:2105.06829v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06829">
<div class="article-summary-box-inner">
<span><p>Empathetic dialog generation aims at generating coherent responses following
previous dialog turns and, more importantly, showing a sense of caring and a
desire to help. Existing models either rely on pre-defined emotion labels to
guide the response generation, or use deterministic rules to decide the emotion
of the response. With the advent of advanced language models, it is possible to
learn subtle interactions directly from the dataset, providing that the emotion
categories offer sufficient nuances and other non-emotional but emotional
regulating intents are included. In this paper, we describe how to incorporate
a taxonomy of 32 emotion categories and 8 additional emotion regulating intents
to succeed the task of empathetic response generation. To facilitate the
training, we also curated a large-scale emotional dialog dataset from movie
subtitles. Through a carefully designed crowdsourcing experiment, we evaluated
and demonstrated how our model produces more empathetic dialogs compared with
its baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Automated Topic Model Evaluation Broken?: The Incoherence of Coherence. (arXiv:2107.02173v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02173">
<div class="article-summary-box-inner">
<span><p>Topic model evaluation, like evaluation of other unsupervised methods, can be
contentious. However, the field has coalesced around automated estimates of
topic coherence, which rely on the frequency of word co-occurrences in a
reference corpus. Recent models relying on neural components surpass classical
topic models according to these metrics. At the same time, unlike classical
models, the practice of neural topic model evaluation suffers from a validation
gap: automatic coherence for neural models has not been validated using human
experimentation. In addition, as we show via a meta-analysis of topic modeling
literature, there is a substantial standardization gap in the use of automated
topic modeling benchmarks. We address both the standardization gap and the
validation gap. Using two of the most widely used topic model evaluation
datasets, we assess a dominant classical model and two state-of-the-art neural
models in a systematic, clearly documented, reproducible way. We use automatic
coherence along with the two most widely accepted human judgment tasks, namely,
topic rating and word intrusion. Automated evaluation will declare one model
significantly different from another when corresponding human evaluations do
not, calling into question the validity of fully automatic evaluations
independent of human judgments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finetuned Language Models Are Zero-Shot Learners. (arXiv:2109.01652v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01652">
<div class="article-summary-box-inner">
<span><p>This paper explores a simple method for improving the zero-shot learning
abilities of language models. We show that instruction tuning -- finetuning
language models on a collection of tasks described via instructions --
substantially boosts zero-shot performance on unseen tasks.
</p>
<p>We take a 137B parameter pretrained language model and instruction-tune it on
over 60 NLP tasks verbalized via natural language instruction templates. We
evaluate this instruction-tuned model, which we call FLAN, on unseen task
types. FLAN substantially improves the performance of its unmodified
counterpart and surpasses zero-shot 175B GPT-3 on 20 of 25 tasks that we
evaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE,
BoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number
of tasks and model scale are key components to the success of instruction
tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curb Your Carbon Emissions: Benchmarking Carbon Emissions in Machine Translation. (arXiv:2109.12584v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12584">
<div class="article-summary-box-inner">
<span><p>In recent times, there has been definitive progress in the field of NLP, with
its applications growing as the utility of our language models increases with
advances in their performance. However, these models require a large amount of
computational power and data to train, consequently leading to large carbon
footprints. Therefore, is it imperative that we study the carbon efficiency and
look for alternatives to reduce the overall environmental impact of training
models, in particular large language models. In our work, we assess the
performance of models for machine translation, across multiple language pairs
to assess the difference in computational power required to train these models
for each of these language pairs and examine the various components of these
models to analyze aspects of our pipeline that can be optimized to reduce these
carbon emissions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MFAQ: a Multilingual FAQ Dataset. (arXiv:2109.12870v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12870">
<div class="article-summary-box-inner">
<span><p>In this paper, we present the first multilingual FAQ dataset publicly
available. We collected around 6M FAQ pairs from the web, in 21 different
languages. Although this is significantly larger than existing FAQ retrieval
datasets, it comes with its own challenges: duplication of content and uneven
distribution of topics. We adopt a similar setup as Dense Passage Retrieval
(DPR) and test various bi-encoders on this dataset. Our experiments reveal that
a multilingual model based on XLM-RoBERTa achieves the best results, except for
English. Lower resources languages seem to learn from one another as a
multilingual model achieves a higher MRR than language-specific ones. Our
qualitative analysis reveals the brittleness of the model on simple word
changes. We publicly release our dataset, model and training script.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentiment-Aware Measure (SAM) for Evaluating Sentiment Transfer by Machine Translation Systems. (arXiv:2109.14895v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14895">
<div class="article-summary-box-inner">
<span><p>In translating text where sentiment is the main message, human translators
give particular attention to sentiment-carrying words. The reason is that an
incorrect translation of such words would miss the fundamental aspect of the
source text, i.e. the author's sentiment. In the online world, MT systems are
extensively used to translate User-Generated Content (UGC) such as reviews,
tweets, and social media posts, where the main message is often the author's
positive or negative attitude towards the topic of the text. It is important in
such scenarios to accurately measure how far an MT system can be a reliable
real-life utility in transferring the correct affect message. This paper
tackles an under-recognised problem in the field of machine translation
evaluation which is judging to what extent automatic metrics concur with the
gold standard of human evaluation for a correct translation of sentiment. We
evaluate the efficacy of conventional quality metrics in spotting a
mistranslation of sentiment, especially when it is the sole error in the MT
output. We propose a numerical `sentiment-closeness' measure appropriate for
assessing the accuracy of a translated affect message in UGC text by an MT
system. We will show that incorporating this sentiment-aware measure can
significantly enhance the correlation of some available quality metrics with
the human judgement of an accurate translation of sentiment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compositional generalization in semantic parsing with pretrained transformers. (arXiv:2109.15101v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.15101">
<div class="article-summary-box-inner">
<span><p>Large-scale pretraining instills large amounts of knowledge in deep neural
networks. This, in turn, improves the generalization behavior of these models
in downstream tasks. What exactly are the limits to the generalization benefits
of large-scale pretraining? Here, we report observations from some simple
experiments aimed at addressing this question in the context of two semantic
parsing tasks involving natural language, SCAN and COGS. We show that language
models pretrained exclusively with non-English corpora, or even with
programming language corpora, significantly improve out-of-distribution
generalization in these benchmarks, compared with models trained from scratch,
even though both benchmarks are English-based. This demonstrates the
surprisingly broad transferability of pretrained representations and knowledge.
Pretraining with a large-scale protein sequence prediction task, on the other
hand, mostly deteriorates the generalization performance in SCAN and COGS,
suggesting that pretrained representations do not transfer universally and that
there are constraints on the similarity between the pretraining and downstream
domains for successful transfer. Finally, we show that larger models are harder
to train from scratch and their generalization accuracy is lower when trained
up to convergence on the relatively small SCAN and COGS datasets, but the
benefits of large-scale pretraining become much clearer with larger models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TLDR9+: A Large Scale Resource for Extreme Summarization of Social Media Posts. (arXiv:2110.01159v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01159">
<div class="article-summary-box-inner">
<span><p>Recent models in developing summarization systems consist of millions of
parameters and the model performance is highly dependent on the abundance of
training data. While most existing summarization corpora contain data in the
order of thousands to one million, generation of large-scale summarization
datasets in order of couple of millions is yet to be explored. Practically,
more data is better at generalizing the training patterns to unseen data. In
this paper, we introduce TLDR9+ -- a large-scale summarization dataset --
containing over 9 million training instances extracted from Reddit discussion
forum (https://github.com/sajastu/reddit_collector). This dataset is
specifically gathered to perform extreme summarization (i.e., generating
one-sentence summary in high compression and abstraction) and is more than
twice larger than the previously proposed dataset. We go one step further and
with the help of human annotations, we distill a more fine-grained dataset by
sampling High-Quality instances from TLDR9+ and call it TLDRHQ dataset. We
further pinpoint different state-of-the-art summarization models on our
proposed datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LawSum: A weakly supervised approach for Indian Legal Document Summarization. (arXiv:2110.01188v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01188">
<div class="article-summary-box-inner">
<span><p>Unlike the courts in western countries, public records of Indian judiciary
are completely unstructured and noisy. No large scale publicly available
annotated datasets of Indian legal documents exist till date. This limits the
scope for legal analytics research. In this work, we propose a new dataset
consisting of over 10,000 judgements delivered by the supreme court of India
and their corresponding hand written summaries. The proposed dataset is
pre-processed by normalising common legal abbreviations, handling spelling
variations in named entities, handling bad punctuations and accurate sentence
tokenization. Each sentence is tagged with their rhetorical roles. We also
annotate each judgement with several attributes like date, names of the
plaintiffs, defendants and the people representing them, judges who delivered
the judgement, acts/statutes that are cited and the most common citations used
to refer the judgement. Further, we propose an automatic labelling technique
for identifying sentences which have summary worthy information. We demonstrate
that this auto labeled data can be used effectively to train a weakly
supervised sentence extractor with high accuracy. Some possible applications of
this dataset besides legal document summarization can be in retrieval, citation
analysis and prediction of decisions by a particular judge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factorized Neural Transducer for Efficient Language Model Adaptation. (arXiv:2110.01500v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01500">
<div class="article-summary-box-inner">
<span><p>In recent years, end-to-end (E2E) based automatic speech recognition (ASR)
systems have achieved great success due to their simplicity and promising
performance. Neural Transducer based models are increasingly popular in
streaming E2E based ASR systems and have been reported to outperform the
traditional hybrid system in some scenarios. However, the joint optimization of
acoustic model, lexicon and language model in neural Transducer also brings
about challenges to utilize pure text for language model adaptation. This
drawback might prevent their potential applications in practice. In order to
address this issue, in this paper, we propose a novel model, factorized neural
Transducer, by factorizing the blank and vocabulary prediction, and adopting a
standalone language model for the vocabulary prediction. It is expected that
this factorization can transfer the improvement of the standalone language
model to the Transducer for speech recognition, which allows various language
model adaptation techniques to be applied. We demonstrate that the proposed
factorized neural Transducer yields 15% to 20% WER improvements when
out-of-domain text data is used for language model adaptation, at the cost of a
minor degradation in WER on a general test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large-scale ASR Domain Adaptation using Self- and Semi-supervised Learning. (arXiv:2110.00165v2 [eess.AS] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00165">
<div class="article-summary-box-inner">
<span><p>Self- and semi-supervised learning methods have been actively investigated to
reduce labeled training data or enhance the model performance. However, the
approach mostly focus on in-domain performance for public datasets. In this
study, we utilize the combination of self- and semi-supervised learning methods
to solve unseen domain adaptation problem in a large-scale production setting
for online ASR model. This approach demonstrates that using the source domain
data with a small fraction of the target domain data (3%) can recover the
performance gap compared to a full data baseline: relative 13.5% WER
improvement for target domain data.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">CCS-GAN: COVID-19 CT-scan classification with very few positive training images. (arXiv:2110.01605v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01605">
<div class="article-summary-box-inner">
<span><p>We present a novel algorithm that is able to classify COVID-19 pneumonia from
CT Scan slices using a very small sample of training images exhibiting COVID-19
pneumonia in tandem with a larger number of normal images. This algorithm is
able to achieve high classification accuracy using as few as 10 positive
training slices (from 10 positive cases), which to the best of our knowledge is
one order of magnitude fewer than the next closest published work at the time
of writing. Deep learning with extremely small positive training volumes is a
very difficult problem and has been an important topic during the COVID-19
pandemic, because for quite some time it was difficult to obtain large volumes
of COVID-19 positive images for training. Algorithms that can learn to screen
for diseases using few examples are an important area of research. We present
the Cycle Consistent Segmentation Generative Adversarial Network (CCS-GAN).
CCS-GAN combines style transfer with pulmonary segmentation and relevant
transfer learning from negative images in order to create a larger volume of
synthetic positive images for the purposes of improving diagnostic
classification performance. The performance of a VGG-19 classifier plus CCS-GAN
was trained using a small sample of positive image slices ranging from at most
50 down to as few as 10 COVID-19 positive CT-scan images. CCS-GAN achieves high
accuracy with few positive images and thereby greatly reduces the barrier of
acquiring large training volumes in order to train a diagnostic classifier for
COVID-19.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breast Cancer Diagnosis in Two-View Mammography Using End-to-End Trained EfficientNet-Based Convolutional Network. (arXiv:2110.01606v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01606">
<div class="article-summary-box-inner">
<span><p>Some recent studies have described deep convolutional neural networks to
diagnose breast cancer in mammograms with similar or even superior performance
to that of human experts. Shen et al. (2019) present one of the best techniques
that consists of two transfer learnings. The first uses a model trained on
natural images to create a "patch classifier" that categorizes small subimages.
The second uses the patch classifier to scan the whole mammogram and create the
"single-view whole-image classifier". We propose to make a third transfer
learning to obtain a "two-view classifier" to use the two mammographic views:
bilateral craniocaudal and mediolateral oblique. We use modern EfficientNet as
the basis of our model. We "end-to-end" train the entire system using CBIS-DDSM
dataset. To ensure statistical robustness, we test our system twice using: (a)
5-fold cross validation; and (b) the original training/test division of the
dataset. Our technique reached an AUC of 0.934 using 5-fold cross validation
(sensitivity and specificity are 85.13% at the equal error rate of ROC). Using
the original dataset division, our technique achieved an AUC of 0.8483, the
largest AUC reported for this problem, as far as we know.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Out-of-the-Box Frameworks for Unpaired Image Translation and Image Segmentation for the crossMoDA Challenge. (arXiv:2110.01607v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01607">
<div class="article-summary-box-inner">
<span><p>The purpose of this study is to apply and evaluate out-of-the-box deep
learning frameworks for the crossMoDA challenge. We use the CUT model for
domain adaptation from contrast-enhanced T1 MR to high-resolution T2 MR. As
data augmentation, we generated additional images with vestibular schwannomas
with lower signal intensity. For the segmentation task, we use the nnU-Net
framework. Our final submission achieved a mean Dice score of 0.8299 (0.0465)
in the validation phase.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Experimental Evaluation on Deepfake Detection using Deep Face Recognition. (arXiv:2110.01640v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01640">
<div class="article-summary-box-inner">
<span><p>Significant advances in deep learning have obtained hallmark accuracy rates
for various computer vision applications. However, advances in deep generative
models have also led to the generation of very realistic fake content, also
known as deepfakes, causing a threat to privacy, democracy, and national
security. Most of the current deepfake detection methods are deemed as a binary
classification problem in distinguishing authentic images or videos from fake
ones using two-class convolutional neural networks (CNNs). These methods are
based on detecting visual artifacts, temporal or color inconsistencies produced
by deep generative models. However, these methods require a large amount of
real and fake data for model training and their performance drops significantly
in cross dataset evaluation with samples generated using advanced deepfake
generation techniques. In this paper, we thoroughly evaluate the efficacy of
deep face recognition in identifying deepfakes, using different loss functions
and deepfake generation techniques. Experimental investigations on challenging
Celeb-DF and FaceForensics++ deepfake datasets suggest the efficacy of deep
face recognition in identifying deepfakes over two-class CNNs and the ocular
modality. Reported results suggest a maximum Area Under Curve (AUC) of 0.98 and
an Equal Error Rate (EER) of 7.1% in detecting deepfakes using face recognition
on the Celeb-DF dataset. This EER is lower by 16.6% compared to the EER
obtained for the two-class CNN and the ocular modality on the Celeb-DF dataset.
Further on the FaceForensics++ dataset, an AUC of 0.99 and EER of 2.04% were
obtained. The use of biometric facial recognition technology has the advantage
of bypassing the need for a large amount of fake data for model training and
obtaining better generalizability to evolving deepfake creation techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Fairness of Ocular Biometrics Among Young, Middle-Aged, and Older Adults. (arXiv:2110.01641v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01641">
<div class="article-summary-box-inner">
<span><p>A number of studies suggest bias of the face biometrics, i.e., face
recognition and soft-biometric estimation methods, across gender, race, and age
groups. There is a recent urge to investigate the bias of different biometric
modalities toward the deployment of fair and trustworthy biometric solutions.
Ocular biometrics has obtained increased attention from academia and industry
due to its high accuracy, security, privacy, and ease of use in mobile devices.
A recent study in $2020$ also suggested the fairness of ocular-based user
recognition across males and females. This paper aims to evaluate the fairness
of ocular biometrics in the visible spectrum among age groups; young, middle,
and older adults. Thanks to the availability of the latest large-scale 2020
UFPR ocular biometric dataset, with subjects acquired in the age range 18 - 79
years, to facilitate this study. Experimental results suggest the overall
equivalent performance of ocular biometrics across gender and age groups in
user verification and gender classification. Performance difference for older
adults at lower false match rate and young adults was noted at user
verification and age classification, respectively. This could be attributed to
inherent characteristics of the biometric data from these age groups impacting
specific applications, which suggest a need for advancement in sensor
technology and software solutions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pixel-Level Bijective Matching for Video Object Segmentation. (arXiv:2110.01644v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01644">
<div class="article-summary-box-inner">
<span><p>Semi-supervised video object segmentation (VOS) aims to track the designated
objects present in the initial frame of a video at the pixel level. To fully
exploit the appearance information of an object, pixel-level feature matching
is widely used in VOS. Conventional feature matching runs in a surjective
manner, i.e., only the best matches from the query frame to the reference frame
are considered. Each location in the query frame refers to the optimal location
in the reference frame regardless of how often each reference frame location is
referenced. This works well in most cases and is robust against rapid
appearance variations, but may cause critical errors when the query frame
contains background distractors that look similar to the target object. To
mitigate this concern, we introduce a bijective matching mechanism to find the
best matches from the query frame to the reference frame and vice versa. Before
finding the best matches for the query frame pixels, the optimal matches for
the reference frame pixels are first considered to prevent each reference frame
pixel from being overly referenced. As this mechanism operates in a strict
manner, i.e., pixels are connected if and only if they are the sure matches for
each other, it can effectively eliminate background distractors. In addition,
we propose a mask embedding module to improve the existing mask propagation
method. By embedding multiple historic masks with coordinate information, it
can effectively capture the position information of a target object.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VTAMIQ: Transformers for Attention Modulated Image Quality Assessment. (arXiv:2110.01655v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01655">
<div class="article-summary-box-inner">
<span><p>Following the major successes of self-attention and Transformers for image
analysis, we investigate the use of such attention mechanisms in the context of
Image Quality Assessment (IQA) and propose a novel full-reference IQA method,
Vision Transformer for Attention Modulated Image Quality (VTAMIQ). Our method
achieves competitive or state-of-the-art performance on the existing IQA
datasets and significantly outperforms previous metrics in cross-database
evaluations. Most patch-wise IQA methods treat each patch independently; this
partially discards global information and limits the ability to model
long-distance interactions. We avoid this problem altogether by employing a
transformer to encode a sequence of patches as a single global representation,
which by design considers interdependencies between patches. We rely on various
attention mechanisms -- first with self-attention within the Transformer, and
second with channel attention within our difference modulation network --
specifically to reveal and enhance the more salient features throughout our
architecture. With large-scale pre-training for both classification and IQA
tasks, VTAMIQ generalizes well to unseen sets of images and distortions,
further demonstrating the strength of transformer-based networks for vision
modelling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HDR-cGAN: Single LDR to HDR Image Translation using Conditional GAN. (arXiv:2110.01660v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01660">
<div class="article-summary-box-inner">
<span><p>The prime goal of digital imaging techniques is to reproduce the realistic
appearance of a scene. Low Dynamic Range (LDR) cameras are incapable of
representing the wide dynamic range of the real-world scene. The captured
images turn out to be either too dark (underexposed) or too bright
(overexposed). Specifically, saturation in overexposed regions makes the task
of reconstructing a High Dynamic Range (HDR) image from single LDR image
challenging. In this paper, we propose a deep learning based approach to
recover details in the saturated areas while reconstructing the HDR image. We
formulate this problem as an image-to-image (I2I) translation task. To this
end, we present a novel conditional GAN (cGAN) based framework trained in an
end-to-end fashion over the HDR-REAL and HDR-SYNTH datasets. Our framework uses
an overexposed mask obtained from a pre-trained segmentation model to
facilitate the hallucination task of adding details in the saturated regions.
We demonstrate the effectiveness of the proposed method by performing an
extensive quantitative and qualitative comparison with several state-of-the-art
single-image HDR reconstruction techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Approach Protecting Privacy in Camera-Based Critical Applications. (arXiv:2110.01676v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01676">
<div class="article-summary-box-inner">
<span><p>Many critical applications rely on cameras to capture video footage for
analytical purposes. This has led to concerns about these cameras accidentally
capturing more information than is necessary. In this paper, we propose a deep
learning approach towards protecting privacy in camera-based systems. Instead
of specifying specific objects (e.g. faces) are privacy sensitive, our
technique distinguishes between salient (visually prominent) and non-salient
objects based on the intuition that the latter is unlikely to be needed by the
application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How You Move Your Head Tells What You Do: Self-supervised Video Representation Learning with Egocentric Cameras and IMU Sensors. (arXiv:2110.01680v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01680">
<div class="article-summary-box-inner">
<span><p>Understanding users' activities from head-mounted cameras is a fundamental
task for Augmented and Virtual Reality (AR/VR) applications. A typical approach
is to train a classifier in a supervised manner using data labeled by humans.
This approach has limitations due to the expensive annotation cost and the
closed coverage of activity labels. A potential way to address these
limitations is to use self-supervised learning (SSL). Instead of relying on
human annotations, SSL leverages intrinsic properties of data to learn
representations. We are particularly interested in learning egocentric video
representations benefiting from the head-motion generated by users' daily
activities, which can be easily obtained from IMU sensors embedded in AR/VR
devices. Towards this goal, we propose a simple but effective approach to learn
video representation by learning to tell the corresponding pairs of video clip
and head-motion. We demonstrate the effectiveness of our learned representation
for recognizing egocentric activities of people and dogs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Let there be a clock on the beach: Reducing Object Hallucination in Image Captioning. (arXiv:2110.01705v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01705">
<div class="article-summary-box-inner">
<span><p>Explaining an image with missing or non-existent objects is known as object
bias (hallucination) in image captioning. This behaviour is quite common in the
state-of-the-art captioning models which is not desirable by humans. To
decrease the object hallucination in captioning, we propose three simple yet
efficient training augmentation method for sentences which requires no new
training data or increase in the model size. By extensive analysis, we show
that the proposed methods can significantly diminish our models' object bias on
hallucination metrics. Moreover, we experimentally demonstrate that our methods
decrease the dependency on the visual features. All of our code, configuration
files and model weights will be made public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdjointBackMapV2: Precise Reconstruction of Arbitrary CNN Unit's Activation via Adjoint Operators. (arXiv:2110.01736v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01736">
<div class="article-summary-box-inner">
<span><p>Adjoint operators have been found to be effective in the exploration of CNN's
inner workings [1]. However, the previous no-bias assumption restricted its
generalization. We overcome the restriction via embedding input images into an
extended normed space that includes bias in all CNN layers as part of the
extended input space and propose an adjoint-operator-based algorithm that maps
high-level weights back to the extended input space for reconstructing an
effective hypersurface. Such hypersurface can be computed for an arbitrary unit
in the CNN, and we prove that this reconstructed hypersurface, when multiplied
by the original input (through an inner product), will precisely replicate the
output value of each unit. We show experimental results based on the CIFAR-10
dataset that the proposed approach achieves near $0$ reconstruction error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Integrated System for Mobile Image-Based Dietary Assessment. (arXiv:2110.01754v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01754">
<div class="article-summary-box-inner">
<span><p>Accurate assessment of dietary intake requires improved tools to overcome
limitations of current methods including user burden and measurement error.
Emerging technologies such as image-based approaches using advanced machine
learning techniques coupled with widely available mobile devices present new
opportunities to improve the accuracy of dietary assessment that is
cost-effective, convenient and timely. However, the quality and quantity of
datasets are essential for achieving good performance for automated image
analysis. Building a large image dataset with high quality groundtruth
annotation is a challenging problem, especially for food images as the
associated nutrition information needs to be provided or verified by trained
dietitians with domain knowledge. In this paper, we present the design and
development of a mobile, image-based dietary assessment system to capture and
analyze dietary intake, which has been deployed in both controlled-feeding and
community-dwelling dietary studies. Our system is capable of collecting high
quality food images in naturalistic settings and provides groundtruth
annotations for developing new computational approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bottom-up Hierarchical Classification Using Confusion-based Logit Compression. (arXiv:2110.01756v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01756">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a method to efficiently compute label posteriors of
a base flat classifier in the presence of few validation examples within a
bottom-up hierarchical inference framework. A stand-alone validation set (not
used to train the base classifier) is preferred for posterior estimation to
avoid overfitting the base classifier, however a small validation set limits
the number of features one can effectively use. We propose a simple, yet
robust, logit vector compression approach based on generalized logits and label
confusions for the task of label posterior estimation within the context of
hierarchical classification. Extensive comparative experiments with other
compression techniques are provided across multiple sized validation sets, and
a comparison with related hierarchical classification approaches is also
conducted. The proposed approach mitigates the problem of not having enough
validation examples for reliable posterior estimation while maintaining strong
hierarchical classification performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantified Facial Expressiveness for Affective Behavior Analytics. (arXiv:2110.01758v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01758">
<div class="article-summary-box-inner">
<span><p>The quantified measurement of facial expressiveness is crucial to analyze
human affective behavior at scale. Unfortunately, methods for expressiveness
quantification at the video frame-level are largely unexplored, unlike the
study of discrete expression. In this work, we propose an algorithm that
quantifies facial expressiveness using a bounded, continuous expressiveness
score using multimodal facial features, such as action units (AUs), landmarks,
head pose, and gaze. The proposed algorithm more heavily weights AUs with high
intensities and large temporal changes. The proposed algorithm can compute the
expressiveness in terms of discrete expression, and can be used to perform
tasks including facial behavior tracking and subjectivity quantification in
context. Our results on benchmark datasets show the proposed algorithm is
effective in terms of capturing temporal changes and expressiveness, measuring
subjective differences in context, and extracting useful insight.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Proxy-bridged Image Reconstruction Network for Anomaly Detection in Medical Images. (arXiv:2110.01761v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01761">
<div class="article-summary-box-inner">
<span><p>Anomaly detection in medical images refers to the identification of abnormal
images with only normal images in the training set. Most existing methods solve
this problem with a self-reconstruction framework, which tends to learn an
identity mapping and reduces the sensitivity to anomalies. To mitigate this
problem, in this paper, we propose a novel Proxy-bridged Image Reconstruction
Network (ProxyAno) for anomaly detection in medical images. Specifically, we
use an intermediate proxy to bridge the input image and the reconstructed
image. We study different proxy types, and we find that the superpixel-image
(SI) is the best one. We set all pixels' intensities within each superpixel as
their average intensity, and denote this image as SI. The proposed ProxyAno
consists of two modules, a Proxy Extraction Module and an Image Reconstruction
Module. In the Proxy Extraction Module, a memory is introduced to memorize the
feature correspondence for normal image to its corresponding SI, while the
memorized correspondence does not apply to the abnormal images, which leads to
the information loss for abnormal image and facilitates the anomaly detection.
In the Image Reconstruction Module, we map an SI to its reconstructed image.
Further, we crop a patch from the image and paste it on the normal SI to mimic
the anomalies, and enforce the network to reconstruct the normal image even
with the pseudo abnormal SI. In this way, our network enlarges the
reconstruction error for anomalies. Extensive experiments on brain MR images,
retinal OCT images and retinal fundus images verify the effectiveness of our
method for both image-level and pixel-level anomaly detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Procedure Planning in Instructional Videosvia Contextual Modeling and Model-based Policy Learning. (arXiv:2110.01770v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01770">
<div class="article-summary-box-inner">
<span><p>Learning new skills by observing humans' behaviors is an essential capability
of AI. In this work, we leverage instructional videos to study humans'
decision-making processes, focusing on learning a model to plan goal-directed
actions in real-life videos. In contrast to conventional action recognition,
goal-directed actions are based on expectations of their outcomes requiring
causal knowledge of potential consequences of actions. Thus, integrating the
environment structure with goals is critical for solving this task. Previous
works learn a single world model will fail to distinguish various tasks,
resulting in an ambiguous latent space; planning through it will gradually
neglect the desired outcomes since the global information of the future goal
degrades quickly as the procedure evolves. We address these limitations with a
new formulation of procedure planning and propose novel algorithms to model
human behaviors through Bayesian Inference and model-based Imitation Learning.
Experiments conducted on real-world instructional videos show that our method
can achieve state-of-the-art performance in reaching the indicated goals.
Furthermore, the learned contextual information presents interesting features
for planning in a latent space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HighlightMe: Detecting Highlights from Human-Centric Videos. (arXiv:2110.01774v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01774">
<div class="article-summary-box-inner">
<span><p>We present a domain- and user-preference-agnostic approach to detect
highlightable excerpts from human-centric videos. Our method works on the
graph-based representation of multiple observable human-centric modalities in
the videos, such as poses and faces. We use an autoencoder network equipped
with spatial-temporal graph convolutions to detect human activities and
interactions based on these modalities. We train our network to map the
activity- and interaction-based latent structural representations of the
different modalities to per-frame highlight scores based on the
representativeness of the frames. We use these scores to compute which frames
to highlight and stitch contiguous frames to produce the excerpts. We train our
network on the large-scale AVA-Kinetics action dataset and evaluate it on four
benchmark video highlight datasets: DSH, TVSum, PHD2, and SumMe. We observe a
4-12% improvement in the mean average precision of matching the human-annotated
highlights over state-of-the-art methods in these datasets, without requiring
any user-provided preferences or dataset-specific fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Instance Segmentation with High-Resolution Automotive Radar. (arXiv:2110.01775v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01775">
<div class="article-summary-box-inner">
<span><p>Automotive radar has been widely used in the modern advanced driver
assistance systems (ADAS) and autonomous driving system as it provides reliable
environmental perception in all-weather conditions with affordable cost.
However, automotive radar usually only plays as an auxiliary sensor since it
hardly supplies semantic and geometry information due to the sparsity of radar
detection points. Nonetheless, as development of high-resolution automotive
radar in recent years, more advanced perception functionality like instance
segmentation which has only been well explored using Lidar point clouds,
becomes possible by using automotive radar. Its data comes with rich contexts
such as Radar Cross Section (RCS) and micro-doppler effects which may
potentially be pertinent, and sometimes can even provide detection when the
field of view is completely obscured. Therefore, the effective utilization of
radar detection points data is an integral part of automotive perception. The
outcome from instance segmentation could be seen as comparable result of
clustering, and could be potentially used as the input of tracker for tracking
the targets. In this paper, we propose two efficient methods for instance
segmentation with radar detection points, one is implemented in an end-to-end
deep learning driven fashion using PointNet++ framework, and the other is based
on clustering of the radar detection points with semantic information. Both
approaches can be further improved by implementing visual multi-layer
perceptron (MLP). The effectiveness of the proposed methods is verified using
experimental results on the recent RadarScenes dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaPix: Domain Transfer for Semantic Segmentation by Meta Pixel Weighting. (arXiv:2110.01777v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01777">
<div class="article-summary-box-inner">
<span><p>Training a deep neural model for semantic segmentation requires collecting a
large amount of pixel-level labeled data. To alleviate the data scarcity
problem presented in the real world, one could utilize synthetic data whose
label is easy to obtain. Previous work has shown that the performance of a
semantic segmentation model can be improved by training jointly with real and
synthetic examples with a proper weighting on the synthetic data. Such
weighting was learned by a heuristic to maximize the similarity between
synthetic and real examples. In our work, we instead learn a pixel-level
weighting of the synthetic data by meta-learning, i.e., the learning of
weighting should only be minimizing the loss on the target task. We achieve
this by gradient-on-gradient technique to propagate the target loss back into
the parameters of the weighting model. The experiments show that our method
with only one single meta module can outperform a complicated combination of an
adversarial feature alignment, a reconstruction loss, plus a hierarchical
heuristic weighting at pixel, region and image levels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Subspace analysing for Semi-Supervised multi-label classification of Diabetic Foot Ulcer. (arXiv:2110.01795v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01795">
<div class="article-summary-box-inner">
<span><p>Diabetes is a global raising pandemic. Diabetes patients are at risk of
developing foot ulcer that usually leads to limb amputation. In order to
develop a self monitoring mobile application, in this work, we propose a novel
deep subspace analysis pipeline for semi-supervised diabetic foot ulcer
mulit-label classification. To avoid any chance of over-fitting, unlike recent
state of the art deep semi-supervised methods, the proposed pipeline dose not
include any data augmentation. Whereas, after extracting deep features, in
order to make the representation shift invariant, we employ variety of data
augmentation methods on each image and generate an image-sets, which is then
mapped into a linear subspace. Moreover, the proposed pipeline reduces the cost
of retraining when more new unlabelled data become available. Thus, the first
stage of the pipeline employs the concept of transfer learning for feature
extraction purpose through modifying and retraining a deep convolutional
network architect known as Xception. Then, the output of a mid-layer is
extracted to generate an image set representer of any given image with help of
data augmentation methods. At this stage, each image is transferred to a linear
subspace which is a point on a Grassmann Manifold topological space. Hence, to
perform analyse them, the geometry of such manifold must be considered. As
such, each labelled image is represented as a vector of distances to number of
unlabelled images using geodesic distance on Grassmann manifold. Finally,
Random Forest is trained for multi-label classification of diabetic foot ulcer
images. The method is then evaluated on the blind test set provided by DFU2021
competition, and the result considerable improvement compared to using
classical transfer learning with data augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning of Perceptually Optimized Block Motion Estimates for Video Compression. (arXiv:2110.01805v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01805">
<div class="article-summary-box-inner">
<span><p>Block based motion estimation is integral to inter prediction processes
performed in hybrid video codecs. Prevalent block matching based methods that
are used to compute block motion vectors (MVs) rely on computationally
intensive search procedures. They also suffer from the aperture problem, which
can worsen as the block size is reduced. Moreover, the block matching criteria
used in typical codecs do not account for the resulting levels of perceptual
quality of the motion compensated pictures that are created upon decoding.
Towards achieving the elusive goal of perceptually optimized motion estimation,
we propose a search-free block motion estimation framework using a multi-stage
convolutional neural network, which is able to conduct motion estimation on
multiple block sizes simultaneously, using a triplet of frames as input. This
composite block translation network (CBT-Net) is trained in a self-supervised
manner on a large database that we created from publicly available uncompressed
video content. We deploy the multi-scale structural similarity (MS-SSIM) loss
function to optimize the perceptual quality of the motion compensated predicted
frames. Our experimental results highlight the computational efficiency of our
proposed model relative to conventional block matching based motion estimation
algorithms, for comparable prediction errors. Further, when used to perform
inter prediction in AV1, the MV predictions of the perceptually optimized model
result in average Bjontegaard-delta rate (BD-rate) improvements of -1.70% and
-1.52% with respect to the MS-SSIM and Video Multi-Method Assessment Fusion
(VMAF) quality metrics, respectively as compared to the block matching based
motion estimation system employed in the SVT-AV1 encoder.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DA-DRN: Degradation-Aware Deep Retinex Network for Low-Light Image Enhancement. (arXiv:2110.01809v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01809">
<div class="article-summary-box-inner">
<span><p>Images obtained in real-world low-light conditions are not only low in
brightness, but they also suffer from many other types of degradation, such as
color distortion, unknown noise, detail loss and halo artifacts. In this paper,
we propose a Degradation-Aware Deep Retinex Network (denoted as DA-DRN) for
low-light image enhancement and tackle the above degradation. Based on Retinex
Theory, the decomposition net in our model can decompose low-light images into
reflectance and illumination maps and deal with the degradation in the
reflectance during the decomposition phase directly. We propose a
Degradation-Aware Module (DA Module) which can guide the training process of
the decomposer and enable the decomposer to be a restorer during the training
phase without additional computational cost in the test phase. DA Module can
achieve the purpose of noise removal while preserving detail information into
the illumination map as well as tackle color distortion and halo artifacts. We
introduce Perceptual Loss to train the enhancement network to generate the
brightness-improved illumination maps which are more consistent with human
visual perception. We train and evaluate the performance of our proposed model
over the LOL real-world and LOL synthetic datasets, and we also test our model
over several other frequently used datasets without Ground-Truth (LIME, DICM,
MEF and NPE datasets). We conduct extensive experiments to demonstrate that our
approach achieves a promising effect with good rubustness and generalization
and outperforms many other state-of-the-art methods qualitatively and
quantitatively. Our method only takes 7 ms to process an image with 600x400
resolution on a TITAN Xp GPU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UHP-SOT: An Unsupervised High-Performance Single Object Tracker. (arXiv:2110.01812v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01812">
<div class="article-summary-box-inner">
<span><p>An unsupervised online object tracking method that exploits both foreground
and background correlations is proposed and named UHP-SOT (Unsupervised
High-Performance Single Object Tracker) in this work. UHP-SOT consists of three
modules: 1) appearance model update, 2) background motion modeling, and 3)
trajectory-based box prediction. A state-of-the-art discriminative correlation
filters (DCF) based tracker is adopted by UHP-SOT as the first module. We point
out shortcomings of using the first module alone such as failure in recovering
from tracking loss and inflexibility in object box adaptation and then propose
the second and third modules to overcome them. Both are novel in single object
tracking (SOT). We test UHP-SOT on two popular object tracking benchmarks,
TB-50 and TB-100, and show that it outperforms all previous unsupervised SOT
methods, achieves a performance comparable with the best supervised
deep-learning-based SOT methods, and operates at a fast speed (i.e. 22.7-32.0
FPS on a CPU).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Attacks on Black Box Video Classifiers: Leveraging the Power of Geometric Transformations. (arXiv:2110.01823v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01823">
<div class="article-summary-box-inner">
<span><p>When compared to the image classification models, black-box adversarial
attacks against video classification models have been largely understudied.
This could be possible because, with video, the temporal dimension poses
significant additional challenges in gradient estimation. Query-efficient
black-box attacks rely on effectively estimated gradients towards maximizing
the probability of misclassifying the target video. In this work, we
demonstrate that such effective gradients can be searched for by parameterizing
the temporal structure of the search space with geometric transformations.
Specifically, we design a novel iterative algorithm Geometric TRAnsformed
Perturbations (GEO-TRAP), for attacking video classification models. GEO-TRAP
employs standard geometric transformation operations to reduce the search space
for effective gradients into searching for a small group of parameters that
define these operations. This group of parameters describes the geometric
progression of gradients, resulting in a reduced and structured search space.
Our algorithm inherently leads to successful perturbations with surprisingly
few queries. For example, adversarial examples generated from GEO-TRAP have
better attack success rates with ~73.55% fewer queries compared to the
state-of-the-art method for video adversarial attacks on the widely used Jester
dataset. Overall, our algorithm exposes vulnerabilities of diverse video
classification models and achieves new state-of-the-art results under black-box
settings on two large datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep reinforcement learning for guidewire navigation in coronary artery phantom. (arXiv:2110.01840v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01840">
<div class="article-summary-box-inner">
<span><p>In percutaneous intervention for treatment of coronary plaques, guidewire
navigation is a primary procedure for stent delivery. Steering a flexible
guidewire within coronary arteries requires considerable training, and the
non-linearity between the control operation and the movement of the guidewire
makes precise manipulation difficult. Here, we introduce a deep reinforcement
learning(RL) framework for autonomous guidewire navigation in a robot-assisted
coronary intervention. Using Rainbow, a segment-wise learning approach is
applied to determine how best to accelerate training using human demonstrations
with deep Q-learning from demonstrations (DQfD), transfer learning, and weight
initialization. `State' for RL is customized as a focus window near the
guidewire tip, and subgoals are placed to mitigate a sparse reward problem. The
RL agent improves performance, eventually enabling the guidewire to reach all
valid targets in `stable' phase. Our framework opens anew direction in the
automation of robot-assisted intervention, providing guidance on RL in physical
spaces involving mechanical fatigue.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hypernetworks for Continual Semi-Supervised Learning. (arXiv:2110.01856v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01856">
<div class="article-summary-box-inner">
<span><p>Learning from data sequentially arriving, possibly in a non i.i.d. way, with
changing task distribution over time is called continual learning. Much of the
work thus far in continual learning focuses on supervised learning and some
recent works on unsupervised learning. In many domains, each task contains a
mix of labelled (typically very few) and unlabelled (typically plenty) training
examples, which necessitates a semi-supervised learning approach. To address
this in a continual learning setting, we propose a framework for
semi-supervised continual learning called Meta-Consolidation for Continual
Semi-Supervised Learning (MCSSL). Our framework has a hypernetwork that learns
the meta-distribution that generates the weights of a semi-supervised auxiliary
classifier generative adversarial network $(\textit{Semi-ACGAN})$ as the base
network. We consolidate the knowledge of sequential tasks in the hypernetwork,
and the base network learns the semi-supervised learning task. Further, we
present $\textit{Semi-Split CIFAR-10}$, a new benchmark for continual
semi-supervised learning, obtained by modifying the $\textit{Split CIFAR-10}$
dataset, in which the tasks with labelled and unlabelled data arrive
sequentially. Our proposed model yields significant improvements in the
continual semi-supervised learning setting. We compare the performance of
several existing continual learning approaches on the proposed continual
semi-supervised learning benchmark of the Semi-Split CIFAR-10 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Frequency Aware Face Hallucination Generative Adversarial Network with Semantic Structural Constraint. (arXiv:2110.01880v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01880">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the issue of face hallucination. Most current face
hallucination methods rely on two-dimensional facial priors to generate high
resolution face images from low resolution face images. These methods are only
capable of assimilating global information into the generated image. Still
there exist some inherent problems in these methods; such as, local features,
subtle structural details and missing depth information in final output image.
Present work proposes a Generative Adversarial Network (GAN) based novel
progressive Face Hallucination (FH) network to address these issues present
among current methods. The generator of the proposed model comprises of FH
network and two sub-networks, assisting FH network to generate high resolution
images. The first sub-network leverages on explicitly adding high frequency
components into the model. To explicitly encode the high frequency components,
an auto encoder is proposed to generate high resolution coefficients of
Discrete Cosine Transform (DCT). To add three dimensional parametric
information into the network, second sub-network is proposed. This network uses
a shape model of 3D Morphable Models (3DMM) to add structural constraint to the
FH network. Extensive experimentation results in the paper shows that the
proposed model outperforms the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">De-rendering Stylized Texts. (arXiv:2110.01890v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01890">
<div class="article-summary-box-inner">
<span><p>Editing raster text is a promising but challenging task. We propose to apply
text vectorization for the task of raster text editing in display media, such
as posters, web pages, or advertisements. In our approach, instead of applying
image transformation or generation in the raster domain, we learn a text
vectorization model to parse all the rendering parameters including text,
location, size, font, style, effects, and hidden background, then utilize those
parameters for reconstruction and any editing task. Our text vectorization
takes advantage of differentiable text rendering to accurately reproduce the
input raster text in a resolution-free parametric format. We show in the
experiments that our approach can successfully parse text, styling, and
background information in the unified model, and produces artifact-free text
editing compared to a raster baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RapidAI4EO: A Corpus for Higher Spatial and Temporal Reasoning. (arXiv:2110.01919v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01919">
<div class="article-summary-box-inner">
<span><p>Under the sponsorship of the European Union Horizon 2020 program, RapidAI4EO
will establish the foundations for the next generation of Copernicus Land
Monitoring Service (CLMS) products. The project aims to provide intensified
monitoring of Land Use (LU), Land Cover (LC), and LU change at a much higher
level of detail and temporal cadence than it is possible today. Focus is on
disentangling phenology from structural change and in providing critical
training data to drive advancement in the Copernicus community and ecosystem
well beyond the lifetime of this project. To this end we are creating the
densest spatiotemporal training sets ever by fusing open satellite data with
Planet imagery at as many as 500,000 patch locations over Europe and delivering
high resolution daily time series at all locations. We plan to open source
these datasets for the benefit of the entire remote sensing community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CNN-based Human Detection for UAVs in Search and Rescue. (arXiv:2110.01930v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01930">
<div class="article-summary-box-inner">
<span><p>The use of Unmanned Aerial Vehicles (UAVs) as a substitute for ordinary
vehicles in applications of search and rescue is being studied all over the
world due to its flexible mobility and less obstruction, including two main
tasks: search and rescue. This paper proposes an approach for the first task of
searching and detecting victims using a type of convolutional neural network
technique, the Single Shot Detector (SSD) model, with the Quadcopter hardware
platform, a type of UAVs. The model used in the research is a pre-trained model
and is applied to test on a Raspberry Pi model B, which is attached on a
Quadcopter, while a single camera is equipped at the bottom of the Quadcopter
to look from above for search and detection. The Quadcopter in this research is
a DIY hardware model that uses accelerometer and gyroscope sensors and
ultrasonic sensor as the essential components for balancing control, however,
these sensors are susceptible to noise caused by the driving forces on the
model, such as the vibration of the motors, therefore, the issues about the PID
controller, noise processing for the sensors are also mentioned in the paper.
Experimental results proved that the Quadcopter is able to stably flight and
the SSD model works well on the Raspberry Pi model B with a processing speed of
3 fps and produces the best detection results at the distance of 1 to 20 meters
to objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anchor-free Oriented Proposal Generator for Object Detection. (arXiv:2110.01931v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01931">
<div class="article-summary-box-inner">
<span><p>Oriented object detection is a practical and challenging task in remote
sensing image interpretation. Nowadays, oriented detectors mostly use
horizontal boxes as intermedium to derive oriented boxes from them. However,
the horizontal boxes are inclined to get a small Intersection-over-Unions
(IoUs) with ground truths, which may have some undesirable effects, such as
introducing redundant noise, mismatching with ground truths, detracting from
the robustness of detectors, etc. In this paper, we propose a novel Anchor-free
Oriented Proposal Generator (AOPG) that abandons the horizontal boxes-related
operations from the network architecture. AOPG first produces coarse oriented
boxes by Coarse Location Module (CLM) in an anchor-free manner and then refines
them into high-quality oriented proposals. After AOPG, we apply a Fast R-CNN
head to produce the final detection results. Furthermore, the shortage of
large-scale datasets is also a hindrance to the development of oriented object
detection. To alleviate the data insufficiency, we release a new dataset on the
basis of our DIOR dataset and name it DIOR-R. Massive experiments demonstrate
the effectiveness of AOPG. Particularly, without bells and whistles, we achieve
the highest accuracy of 64.41$\%$, 75.24$\%$ and 96.22$\%$ mAP on the DIOR-R,
DOTA and HRSC2016 datasets respectively. Code and models are available at
https://github.com/jbwang1997/AOPG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Double Encoder-Decoder Networks for Gastrointestinal Polyp Segmentation. (arXiv:2110.01939v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01939">
<div class="article-summary-box-inner">
<span><p>Polyps represent an early sign of the development of Colorectal Cancer. The
standard procedure for their detection consists of colonoscopic examination of
the gastrointestinal tract. However, the wide range of polyp shapes and visual
appearances, as well as the reduced quality of this image modality, turn their
automatic identification and segmentation with computational tools into a
challenging computer vision task. In this work, we present a new strategy for
the delineation of gastrointestinal polyps from endoscopic images based on a
direct extension of common encoder-decoder networks for semantic segmentation.
In our approach, two pretrained encoder-decoder networks are sequentially
stacked: the second network takes as input the concatenation of the original
frame and the initial prediction generated by the first network, which acts as
an attention mechanism enabling the second network to focus on interesting
areas within the image, thereby improving the quality of its predictions.
Quantitative evaluation carried out on several polyp segmentation databases
shows that double encoder-decoder networks clearly outperform their single
encoder-decoder counterparts in all cases. In addition, our best double
encoder-decoder combination attains excellent segmentation accuracy and reaches
state-of-the-art performance results in all the considered datasets, with a
remarkable boost of accuracy on images extracted from datasets not used for
training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distribution Mismatch Correction for Improved Robustness in Deep Neural Networks. (arXiv:2110.01955v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01955">
<div class="article-summary-box-inner">
<span><p>Deep neural networks rely heavily on normalization methods to improve their
performance and learning behavior. Although normalization methods spurred the
development of increasingly deep and efficient architectures, they also
increase the vulnerability with respect to noise and input corruptions. In most
applications, however, noise is ubiquitous and diverse; this can often lead to
complete failure of machine learning systems as they fail to cope with
mismatches between the input distribution during training- and test-time. The
most common normalization method, batch normalization, reduces the distribution
shift during training but is agnostic to changes in the input distribution
during test time. This makes batch normalization prone to performance
degradation whenever noise is present during test-time. Sample-based
normalization methods can correct linear transformations of the activation
distribution but cannot mitigate changes in the distribution shape; this makes
the network vulnerable to distribution changes that cannot be reflected in the
normalization parameters. We propose an unsupervised non-parametric
distribution correction method that adapts the activation distribution of each
layer. This reduces the mismatch between the training and test-time
distribution by minimizing the 1-D Wasserstein distance. In our experiments, we
empirically show that the proposed method effectively reduces the impact of
intense image corruptions and thus improves the classification performance
without the need for retraining or fine-tuning the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Bird's-Eye-View Traffic Scene Understanding from Onboard Images. (arXiv:2110.01997v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01997">
<div class="article-summary-box-inner">
<span><p>Autonomous navigation requires structured representation of the road network
and instance-wise identification of the other traffic agents. Since the traffic
scene is defined on the ground plane, this corresponds to scene understanding
in the bird's-eye-view (BEV). However, the onboard cameras of autonomous cars
are customarily mounted horizontally for a better view of the surrounding,
making this task very challenging. In this work, we study the problem of
extracting a directed graph representing the local road network in BEV
coordinates, from a single onboard camera image. Moreover, we show that the
method can be extended to detect dynamic objects on the BEV plane. The
semantics, locations, and orientations of the detected objects together with
the road graph facilitates a comprehensive understanding of the scene. Such
understanding becomes fundamental for the downstream tasks, such as path
planning and navigation. We validate our approach against powerful baselines
and show that our network achieves superior performance. We also demonstrate
the effects of various design choices through ablation studies. Code:
https://github.com/ybarancan/STSU
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FooDI-ML: a large multi-language dataset of food, drinks and groceries images and descriptions. (arXiv:2110.02035v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02035">
<div class="article-summary-box-inner">
<span><p>In this paper we introduce the Food Drinks and groceries Images Multi Lingual
(FooDI-ML) dataset. This dataset contains over 1.5M unique images and over 9.5M
store names, product names descriptions, and collection sections gathered from
the Glovo application. The data made available corresponds to food, drinks and
groceries products from 37 countries in Europe, the Middle East, Africa and
Latin America. The dataset comprehends 33 languages, including 870K samples of
languages of countries from Eastern Europe and Western Asia such as Ukrainian
and Kazakh, which have been so far underrepresented in publicly available
visio-linguistic datasets. The dataset also includes widely spoken languages
such as Spanish and English. To assist further research, we include a benchmark
over the text-image retrieval task using ADAPT, a SotA existing technique.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Object Tracking with Deep Learning Ensemble for Unmanned Aerial System Applications. (arXiv:2110.02044v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02044">
<div class="article-summary-box-inner">
<span><p>Multi-object tracking (MOT) is a crucial component of situational awareness
in military defense applications. With the growing use of unmanned aerial
systems (UASs), MOT methods for aerial surveillance is in high demand.
Application of MOT in UAS presents specific challenges such as moving sensor,
changing zoom levels, dynamic background, illumination changes, obscurations
and small objects. In this work, we present a robust object tracking
architecture aimed to accommodate for the noise in real-time situations. We
propose a kinematic prediction model, called Deep Extended Kalman Filter
(DeepEKF), in which a sequence-to-sequence architecture is used to predict
entity trajectories in latent space. DeepEKF utilizes a learned image embedding
along with an attention mechanism trained to weight the importance of areas in
an image to predict future states. For the visual scoring, we experiment with
different similarity measures to calculate distance based on entity
appearances, including a convolutional neural network (CNN) encoder,
pre-trained using Siamese networks. In initial evaluation experiments, we show
that our method, combining scoring structure of the kinematic and visual models
within a MHT framework, has improved performance especially in edge cases where
entity motion is unpredictable, or the data presents frames with significant
gaps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial Context Awareness for Unsupervised Change Detection in Optical Satellite Images. (arXiv:2110.02068v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02068">
<div class="article-summary-box-inner">
<span><p>Detecting changes on the ground in multitemporal Earth observation data is
one of the key problems in remote sensing. In this paper, we introduce Sibling
Regression for Optical Change detection (SiROC), an unsupervised method for
change detection in optical satellite images with medium and high resolution.
SiROC is a spatial context-based method that models a pixel as a linear
combination of its distant neighbors. It uses this model to analyze differences
in the pixel and its spatial context-based predictions in subsequent time
periods for change detection. We combine this spatial context-based change
detection with ensembling over mutually exclusive neighborhoods and
transitioning from pixel to object-level changes with morphological operations.
SiROC achieves competitive performance for change detection with
medium-resolution Sentinel-2 and high-resolution Planetscope imagery on four
datasets. Besides accurate predictions without the need for training, SiROC
also provides a well-calibrated uncertainty of its predictions. This makes the
method especially useful in conjunction with deep-learning based methods for
applications such as pseudo-labeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Methodology to Identify Cognition Gaps in Visual Recognition Applications Based on Convolutional Neural Networks. (arXiv:2110.02080v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02080">
<div class="article-summary-box-inner">
<span><p>Developing consistently well performing visual recognition applications based
on convolutional neural networks, e.g. for autonomous driving, is very
challenging. One of the obstacles during the development is the opaqueness of
their cognitive behaviour. A considerable amount of literature has been
published which describes irrational behaviour of trained CNNs showcasing gaps
in their cognition. In this paper, a methodology is presented that creates
worstcase images using image augmentation techniques. If the CNN's cognitive
performance on such images is weak while the augmentation techniques are
supposedly harmless, a potential gap in the cognition has been found. The
presented worst-case image generator is using adversarial search approaches to
efficiently identify the most challenging image. This is evaluated with the
well-known AlexNet CNN using images depicting a typical driving scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Limits of Large Scale Pre-training. (arXiv:2110.02095v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02095">
<div class="article-summary-box-inner">
<span><p>Recent developments in large-scale machine learning suggest that by scaling
up data, model size and training time properly, one might observe that
improvements in pre-training would transfer favorably to most downstream tasks.
In this work, we systematically study this phenomena and establish that, as we
increase the upstream accuracy, the performance of downstream tasks saturates.
In particular, we investigate more than 4800 experiments on Vision
Transformers, MLP-Mixers and ResNets with number of parameters ranging from ten
million to ten billion, trained on the largest scale of available image data
(JFT, ImageNet21K) and evaluated on more than 20 downstream image recognition
tasks. We propose a model for downstream performance that reflects the
saturation phenomena and captures the nonlinear relationship in performance of
upstream and downstream tasks. Delving deeper to understand the reasons that
give rise to these phenomena, we show that the saturation behavior we observe
is closely related to the way that representations evolve through the layers of
the models. We showcase an even more extreme scenario where performance on
upstream and downstream are at odds with each other. That is, to have a better
downstream performance, we need to hurt upstream accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Generative Style Transfer for One-Shot Medical Image Segmentation. (arXiv:2110.02117v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02117">
<div class="article-summary-box-inner">
<span><p>In medical image segmentation, supervised deep networks' success comes at the
cost of requiring abundant labeled data. While asking domain experts to
annotate only one or a few of the cohort's images is feasible, annotating all
available images is impractical. This issue is further exacerbated when
pre-trained deep networks are exposed to a new image dataset from an unfamiliar
distribution. Using available open-source data for ad-hoc transfer learning or
hand-tuned techniques for data augmentation only provides suboptimal solutions.
Motivated by atlas-based segmentation, we propose a novel volumetric
self-supervised learning for data augmentation capable of synthesizing
volumetric image-segmentation pairs via learning transformations from a single
labeled atlas to the unlabeled data. Our work's central tenet benefits from a
combined view of one-shot generative learning and the proposed self-supervised
training strategy that cluster unlabeled volumetric images with similar styles
together. Unlike previous methods, our method does not require input volumes at
inference time to synthesize new images. Instead, it can generate diversified
volumetric image-segmentation pairs from a prior distribution given a single or
multi-site dataset. Augmented data generated by our method used to train the
segmentation network provide significant improvements over state-of-the-art
deep one-shot learning methods on the task of brain MRI segmentation. Ablation
studies further exemplified that the proposed appearance model and joint
training are crucial to synthesize realistic examples compared to existing
medical registration methods. The code, data, and models are available at
https://github.com/devavratTomar/SST.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Modelling Across Time of Human Actions and Interactions. (arXiv:2110.02120v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02120">
<div class="article-summary-box-inner">
<span><p>This thesis focuses on video understanding for human action and interaction
recognition. We start by identifying the main challenges related to action
recognition from videos and review how they have been addressed by current
methods.
</p>
<p>Based on these challenges, and by focusing on the temporal aspect of actions,
we argue that current fixed-sized spatio-temporal kernels in 3D convolutional
neural networks (CNNs) can be improved to better deal with temporal variations
in the input. Our contributions are based on the enlargement of the
convolutional receptive fields through the introduction of spatio-temporal
size-varying segments of videos, as well as the discovery of the local feature
relevance over the entire video sequence. The resulting extracted features
encapsulate information that includes the importance of local features across
multiple temporal durations, as well as the entire video sequence.
</p>
<p>Subsequently, we study how we can better handle variations between classes of
actions, by enhancing their feature differences over different layers of the
architecture. The hierarchical extraction of features models variations of
relatively similar classes the same as very dissimilar classes. Therefore,
distinctions between similar classes are less likely to be modelled. The
proposed approach regularises feature maps by amplifying features that
correspond to the class of the video that is processed. We move away from
class-agnostic networks and make early predictions based on feature
amplification mechanism.
</p>
<p>The proposed approaches are evaluated on several benchmark action recognition
datasets and show competitive results. In terms of performance, we compete with
the state-of-the-art while being more efficient in terms of GFLOPs.
</p>
<p>Finally, we present a human-understandable approach aimed at providing visual
explanations for features learned over spatio-temporal networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$\textit{FacialFilmroll}$: High-resolution multi-shot video editing. (arXiv:2110.02124v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02124">
<div class="article-summary-box-inner">
<span><p>We present $\textit{FacialFilmroll}$, a solution for spatially and temporally
consistent editing of faces in one or multiple shots. We build upon unwrap
mosaic [Rav-Acha et al. 2008] by specializing it to faces. We leverage recent
techniques to fit a 3D face model on monocular videos to (i) improve the
quality of the mosaic for edition and (ii) permit the automatic transfer of
edits from one shot to other shots of the same actor. We explain how
$\textit{FacialFilmroll}$ is integrated in post-production facility. Finally,
we present video editing results using $\textit{FacialFilmroll}$ on high
resolution videos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine learning attack on copy detection patterns: are 1x1 patterns cloneable?. (arXiv:2110.02176v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02176">
<div class="article-summary-box-inner">
<span><p>Nowadays, the modern economy critically requires reliable yet cheap
protection solutions against product counterfeiting for the mass market. Copy
detection patterns (CDP) are considered as such solution in several
applications. It is assumed that being printed at the maximum achievable limit
of a printing resolution of an industrial printer with the smallest symbol size
1x1 elements, the CDP cannot be copied with sufficient accuracy and thus are
unclonable. In this paper, we challenge this hypothesis and consider a copy
attack against the CDP based on machine learning. The experimental based on
samples produced on two industrial printers demonstrate that simple detection
metrics used in the CDP authentication cannot reliably distinguish the original
CDP from their fakes. Thus, the paper calls for a need of careful
reconsideration of CDP cloneability and search for new authentication
techniques and CDP optimization because of the current attack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer. (arXiv:2110.02178v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02178">
<div class="article-summary-box-inner">
<span><p>Light-weight convolutional neural networks (CNNs) are the de-facto for mobile
vision tasks. Their spatial inductive biases allow them to learn
representations with fewer parameters across different vision tasks. However,
these networks are spatially local. To learn global representations,
self-attention-based vision trans-formers (ViTs) have been adopted. Unlike
CNNs, ViTs are heavy-weight. In this paper, we ask the following question: is
it possible to combine the strengths of CNNs and ViTs to build a light-weight
and low latency network for mobile vision tasks? Towards this end, we introduce
MobileViT, a light-weight and general-purpose vision transformer for mobile
devices. MobileViT presents a different perspective for the global processing
of information with transformers, i.e., transformers as convolutions. Our
results show that MobileViT significantly outperforms CNN- and ViT-based
networks across different tasks and datasets. On the ImageNet-1k dataset,
MobileViT achieves top-1 accuracy of 78.4% with about 6 million parameters,
which is 3.2% and 6.2% more accurate than MobileNetv3 (CNN-based) and DeIT
(ViT-based) for a similar number of parameters. On the MS-COCO object detection
task, MobileViT is 5.7% more accurate than Mo-bileNetv3 for a similar number of
parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transfer Learning U-Net Deep Learning for Lung Ultrasound Segmentation. (arXiv:2110.02196v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02196">
<div class="article-summary-box-inner">
<span><p>Transfer learning (TL) for medical image segmentation helps deep learning
models achieve more accurate performances when there are scarce medical images.
This study focuses on completing segmentation of the ribs from lung ultrasound
images and finding the best TL technique with U-Net, a convolutional neural
network for precise and fast image segmentation. Two approaches of TL were
used, using a pre-trained VGG16 model to build the U-Net (V-Unet) and
pre-training U-Net network with grayscale natural salient object dataset
(X-Unet). Visual results and dice coefficients (DICE) of the models were
compared. X-Unet showed more accurate and artifact-free visual performances on
the actual mask prediction, despite its lower DICE than V-Unet. A
partial-frozen network fine-tuning (FT) technique was also applied to X-Unet to
compare results between different FT strategies, which FT all layers slightly
outperformed freezing part of the network. The effect of dataset sizes was also
evaluated, showing the importance of the combination between TL and data
augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$\Delta$-UQ: Accurate Uncertainty Quantification via Anchor Marginalization. (arXiv:2110.02197v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02197">
<div class="article-summary-box-inner">
<span><p>We present $\Delta$-UQ -- a novel, general-purpose uncertainty estimator
using the concept of anchoring in predictive models. Anchoring works by first
transforming the input into a tuple consisting of an anchor point drawn from a
prior distribution, and a combination of the input sample with the anchor using
a pretext encoding scheme. This encoding is such that the original input can be
perfectly recovered from the tuple -- regardless of the choice of the anchor.
Therefore, any predictive model should be able to predict the target response
from the tuple alone (since it implicitly represents the input). Moreover, by
varying the anchors for a fixed sample, we can estimate uncertainty in the
prediction even using only a single predictive model. We find this uncertainty
is deeply connected to improper sampling of the input data, and inherent noise,
enabling us to estimate the total uncertainty in any system. With extensive
empirical studies on a variety of use-cases, we demonstrate that $\Delta$-UQ
outperforms several competitive baselines. Specifically, we study model
fitting, sequential model optimization, model based inversion in the regression
setting and out of distribution detection, &amp; calibration under distribution
shifts for classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Waypoint Models for Instruction-guided Navigation in Continuous Environments. (arXiv:2110.02207v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02207">
<div class="article-summary-box-inner">
<span><p>Little inquiry has explicitly addressed the role of action spaces in
language-guided visual navigation -- either in terms of its effect on
navigation success or the efficiency with which a robotic agent could execute
the resulting trajectory. Building on the recently released VLN-CE setting for
instruction following in continuous environments, we develop a class of
language-conditioned waypoint prediction networks to examine this question. We
vary the expressivity of these models to explore a spectrum between low-level
actions and continuous waypoint prediction. We measure task performance and
estimated execution time on a profiled LoCoBot robot. We find more expressive
models result in simpler, faster to execute trajectories, but lower-level
actions can achieve better navigation metrics by approximating shortest paths
better. Further, our models outperform prior work in VLN-CE and set a new
state-of-the-art on the public leaderboard -- increasing success rate by 4%
with our best model on this challenging task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mix3D: Out-of-Context Data Augmentation for 3D Scenes. (arXiv:2110.02210v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02210">
<div class="article-summary-box-inner">
<span><p>We present Mix3D, a data augmentation technique for segmenting large-scale 3D
scenes. Since scene context helps reasoning about object semantics, current
works focus on models with large capacity and receptive fields that can fully
capture the global context of an input 3D scene. However, strong contextual
priors can have detrimental implications like mistaking a pedestrian crossing
the street for a car. In this work, we focus on the importance of balancing
global scene context and local geometry, with the goal of generalizing beyond
the contextual priors in the training set. In particular, we propose a "mixing"
technique which creates new training samples by combining two augmented scenes.
By doing so, object instances are implicitly placed into novel out-of-context
environments and therefore making it harder for models to rely on scene context
alone, and instead infer semantics from local structure as well. We perform
detailed analysis to understand the importance of global context, local
structures and the effect of mixing scenes. In experiments, we show that models
trained with Mix3D profit from a significant performance boost on indoor
(ScanNet, S3DIS) and outdoor datasets (SemanticKITTI). Mix3D can be trivially
used with any existing method, e.g., trained with Mix3D, MinkowskiNet
outperforms all prior state-of-the-art methods by a significant margin on the
ScanNet test benchmark 78.1 mIoU. Code is available at:
https://nekrasov.dev/mix3d/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Normalized Diversification. (arXiv:1904.03608v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.03608">
<div class="article-summary-box-inner">
<span><p>Generating diverse yet specific data is the goal of the generative
adversarial network (GAN), but it suffers from the problem of mode collapse. We
introduce the concept of normalized diversity which force the model to preserve
the normalized pairwise distance between the sparse samples from a latent
parametric distribution and their corresponding high-dimensional outputs. The
normalized diversification aims to unfold the manifold of unknown topology and
non-uniform distribution, which leads to safe interpolation between valid
latent variables. By alternating the maximization over the pairwise distance
and updating the total distance (normalizer), we encourage the model to
actively explore in the high-dimensional output space. We demonstrate that by
combining the normalized diversity loss and the adversarial loss, we generate
diverse data without suffering from mode collapsing. Experimental results show
that our method achieves consistent improvement on unsupervised image
generation, conditional image generation and hand pose estimation over strong
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive LiDAR Sampling and Depth Completion using Ensemble Variance. (arXiv:2007.13834v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.13834">
<div class="article-summary-box-inner">
<span><p>This work considers the problem of depth completion, with or without image
data, where an algorithm may measure the depth of a prescribed limited number
of pixels. The algorithmic challenge is to choose pixel positions strategically
and dynamically to maximally reduce overall depth estimation error. This
setting is realized in daytime or nighttime depth completion for autonomous
vehicles with a programmable LiDAR. Our method uses an ensemble of predictors
to define a sampling probability over pixels. This probability is proportional
to the variance of the predictions of ensemble members, thus highlighting
pixels that are difficult to predict. By additionally proceeding in several
prediction phases, we effectively reduce redundant sampling of similar pixels.
Our ensemble-based method may be implemented using any depth-completion
learning algorithm, such as a state-of-the-art neural network, treated as a
black box. In particular, we also present a simple and effective Random
Forest-based algorithm, and similarly use its internal ensemble in our design.
We conduct experiments on the KITTI dataset, using the neural network algorithm
of Ma et al. and our Random Forest based learner for implementing our method.
The accuracy of both implementations exceeds the state of the art. Compared
with a random or grid sampling pattern, our method allows a reduction by a
factor of 4-10 in the number of measurements required to attain the same
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robust Neural Networks via Orthogonal Diversity. (arXiv:2010.12190v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12190">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks (DNNs) are vulnerable to invisible perturbations on the
images generated by adversarial attacks, which raises researches on the
adversarial robustness of DNNs. A series of methods represented by the
\textit{adversarial training} and its variants have proved the most practical
techniques in enhancing the DNN robustness. Generally, adversarial training
focuses on enriching the training data by involving perturbed data into clean
data. Despite of the efficiency on defending specific attacks, adversarial
training essentially benefits from the data augmentation, but does not
contribute to the robustness of DNN itself, and usually suffers accuracy drop
on clean data as well as inefficiency on unknown attacks. Towards the
robustness of DNN itself, we propose a novel defense that aims at augmenting
the model in order to learn features adaptive to diverse inputs, including
adversarial examples. Specifically, we introduce multiple paths to augment the
network, and impose orthogonality constraint on these paths. In addition, a
margin-maximization loss is designed to further boost DIversity via
Orthogonality (DIO). Extensive empirical results on various data sets,
architectures, and attacks demonstrate the robustness of DIO: it does not need
any adversarial example and yet achieves greater robustness compared with
state-of-the-art adversarial training methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Similarity-Based Clustering for Enhancing Image Classification Architectures. (arXiv:2011.04728v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04728">
<div class="article-summary-box-inner">
<span><p>Convolutional networks are at the center of best in class computer vision
applications for a wide assortment of undertakings. Since 2014, profound amount
of work began to make better convolutional architectures, yielding generous
additions in different benchmarks. Albeit expanded model size and computational
cost will, in general, mean prompt quality increases for most undertakings but,
the architectures now need to have some additional information to increase the
performance. We show empirical evidence that with the amalgamation of
content-based image similarity and deep learning models, we can provide the
flow of information which can be used in making clustered learning possible. We
show how parallel training of sub-dataset clusters not only reduces the cost of
computation but also increases the benchmark accuracies by 5-11 percent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EvoPose2D: Pushing the Boundaries of 2D Human Pose Estimation using Accelerated Neuroevolution with Weight Transfer. (arXiv:2011.08446v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08446">
<div class="article-summary-box-inner">
<span><p>Neural architecture search has proven to be highly effective in the design of
efficient convolutional neural networks that are better suited for mobile
deployment than hand-designed networks. Hypothesizing that neural architecture
search holds great potential for human pose estimation, we explore the
application of neuroevolution, a form of neural architecture search inspired by
biological evolution, in the design of 2D human pose networks for the first
time. Additionally, we propose a new weight transfer scheme that enables us to
accelerate neuroevolution in a flexible manner. Our method produces network
designs that are more efficient and more accurate than state-of-the-art
hand-designed networks. In fact, the generated networks process images at
higher resolutions using less computation than previous hand-designed networks
at lower resolutions, allowing us to push the boundaries of 2D human pose
estimation. Our base network designed via neuroevolution, which we refer to as
EvoPose2D-S, achieves comparable accuracy to SimpleBaseline while being 50%
faster and 12.7x smaller in terms of file size. Our largest network,
EvoPose2D-L, achieves new state-of-the-art accuracy on the Microsoft COCO
Keypoints benchmark, is 4.3x smaller than its nearest competitor, and has
similar inference speed. The code is publicly available at
https://github.com/wmcnally/evopose2d.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Monocular Depth Reconstruction of Non-Rigid Scenes. (arXiv:2012.15680v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15680">
<div class="article-summary-box-inner">
<span><p>Monocular depth reconstruction of complex and dynamic scenes is a highly
challenging problem. While for rigid scenes learning-based methods have been
offering promising results even in unsupervised cases, there exists little to
no literature addressing the same for dynamic and deformable scenes. In this
work, we present an unsupervised monocular framework for dense depth estimation
of dynamic scenes, which jointly reconstructs rigid and non-rigid parts without
explicitly modelling the camera motion. Using dense correspondences, we derive
a training objective that aims to opportunistically preserve pairwise distances
between reconstructed 3D points. In this process, the dense depth map is
learned implicitly using the as-rigid-as-possible hypothesis. Our method
provides promising results, demonstrating its capability of reconstructing 3D
from challenging videos of non-rigid scenes. Furthermore, the proposed method
also provides unsupervised motion segmentation results as an auxiliary output.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAAS: Multi-modal Assignation for Active Speaker Detection. (arXiv:2101.03682v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03682">
<div class="article-summary-box-inner">
<span><p>Active speaker detection requires a solid integration of multi-modal cues.
While individual modalities can approximate a solution, accurate predictions
can only be achieved by explicitly fusing the audio and visual features and
modeling their temporal progression. Despite its inherent muti-modal nature,
current methods still focus on modeling and fusing short-term audiovisual
features for individual speakers, often at frame level. In this paper we
present a novel approach to active speaker detection that directly addresses
the multi-modal nature of the problem, and provides a straightforward strategy
where independent visual features from potential speakers in the scene are
assigned to a previously detected speech event. Our experiments show that, an
small graph data structure built from a single frame, allows to approximate an
instantaneous audio-visual assignment problem. Moreover, the temporal extension
of this initial graph achieves a new state-of-the-art on the AVA-ActiveSpeaker
dataset with a mAP of 88.8\%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Continual Learning in Image Classification: An Empirical Survey. (arXiv:2101.10423v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10423">
<div class="article-summary-box-inner">
<span><p>Online continual learning for image classification studies the problem of
learning to classify images from an online stream of data and tasks, where
tasks may include new classes (class incremental) or data nonstationarity
(domain incremental). One of the key challenges of continual learning is to
avoid catastrophic forgetting (CF), i.e., forgetting old tasks in the presence
of more recent tasks. Over the past few years, many methods and tricks have
been introduced to address this problem, but many have not been fairly and
systematically compared under a variety of realistic and practical settings. To
better understand the relative advantages of various approaches and the
settings where they work best, this survey aims to (1) compare state-of-the-art
methods such as MIR, iCARL, and GDumb and determine which works best at
different experimental settings; (2) determine if the best class incremental
methods are also competitive in domain incremental setting; (3) evaluate the
performance of 7 simple but effective trick such as "review" trick and nearest
class mean (NCM) classifier to assess their relative impact. Regarding (1), we
observe iCaRL remains competitive when the memory buffer is small; GDumb
outperforms many recently proposed methods in medium-size datasets and MIR
performs the best in larger-scale datasets. For (2), we note that GDumb
performs quite poorly while MIR -- already competitive for (1) -- is also
strongly competitive in this very different but important setting. Overall,
this allows us to conclude that MIR is overall a strong and versatile method
across a wide variety of settings. For (3), we find that all 7 tricks are
beneficial, and when augmented with the "review" trick and NCM classifier, MIR
produces performance levels that bring online continual learning much closer to
its ultimate goal of matching offline training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Damage detection using in-domain and cross-domain transfer learning. (arXiv:2102.03858v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03858">
<div class="article-summary-box-inner">
<span><p>We investigate the capabilities of transfer learning in the area of
structural health monitoring. In particular, we are interested in damage
detection for concrete structures. Typical image datasets for such problems are
relatively small, calling for the transfer of learned representation from a
related large-scale dataset. Past efforts of damage detection using images have
mainly considered cross-domain transfer learning approaches using pre-trained
IMAGENET models that are subsequently fine-tuned for the target task. However,
there are rising concerns about the generalizability of IMAGENET
representations for specific target domains, such as for visual inspection and
medical imaging. We, therefore, evaluate a combination of in-domain and
cross-domain transfer learning strategies for damage detection in bridges. We
perform comprehensive comparisons to study the impact of cross-domain and
in-domain transfer, with various initialization strategies, using six publicly
available visual inspection datasets. The pre-trained models are also evaluated
for their ability to cope with the extremely low-data regime. We show that the
combination of cross-domain and in-domain transfer persistently shows superior
performance specially with tiny datasets. Likewise, we also provide visual
explanations of predictive models to enable algorithmic transparency and
provide insights to experts about the intrinsic decision logic of typically
black-box deep models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">K-Hairstyle: A Large-scale Korean Hairstyle Dataset for Virtual Hair Editing and Hairstyle Classification. (arXiv:2102.06288v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06288">
<div class="article-summary-box-inner">
<span><p>The hair and beauty industry is a fast-growing industry. This led to the
development of various applications, such as virtual hair dyeing or hairstyle
transfer, to satisfy the customer's needs. Although several hairstyle datasets
are available for these applications, they often consist of a relatively small
number of images with low resolution, thus limiting their performance on
high-quality hair editing. In response, we introduce a novel large-scale Korean
hairstyle dataset, K-hairstyle, containing 500,000 high-resolution images. In
addition, K-hairstyle includes various hair attributes annotated by Korean
expert hairstylists as well as hair segmentation masks. We validate the
effectiveness of our dataset via several applications, such as hair dyeing,
hairstyle transfer, and hairstyle classification. K-hairstyle is publicly
available at https://psh01087.github.io/K-Hairstyle/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Bio-Inspired Texture Descriptor based on Biodiversity and Taxonomic Measures. (arXiv:2102.06997v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06997">
<div class="article-summary-box-inner">
<span><p>Texture can be defined as the change of image intensity that forms repetitive
patterns, resulting from physical properties of the object's roughness or
differences in a reflection on the surface. Considering that texture forms a
complex system of patterns in a non-deterministic way, biodiversity concepts
can help texture characterization in images. This paper proposes a novel
approach capable of quantifying such a complex system of diverse patterns
through species diversity and richness and taxonomic distinctiveness. The
proposed approach considers each image channel as a species ecosystem and
computes species diversity and richness measures as well as taxonomic measures
to describe the texture. The proposed approach takes advantage of ecological
patterns' invariance characteristics to build a permutation, rotation, and
translation invariant descriptor. Experimental results on three datasets of
natural texture images and two datasets of histopathological images have shown
that the proposed texture descriptor has advantages over several texture
descriptors and deep methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VA-RED$^2$: Video Adaptive Redundancy Reduction. (arXiv:2102.07887v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07887">
<div class="article-summary-box-inner">
<span><p>Performing inference on deep learning models for videos remains a challenge
due to the large amount of computational resources required to achieve robust
recognition. An inherent property of real-world videos is the high correlation
of information across frames which can translate into redundancy in either
temporal or spatial feature maps of the models, or both. The type of redundant
features depends on the dynamics and type of events in the video: static videos
have more temporal redundancy while videos focusing on objects tend to have
more channel redundancy. Here we present a redundancy reduction framework,
termed VA-RED$^2$, which is input-dependent. Specifically, our VA-RED$^2$
framework uses an input-dependent policy to decide how many features need to be
computed for temporal and channel dimensions. To keep the capacity of the
original model, after fully computing the necessary features, we reconstruct
the remaining redundant features from those using cheap linear operations. We
learn the adaptive policy jointly with the network weights in a differentiable
way with a shared-weight mechanism, making it highly efficient. Extensive
experiments on multiple video datasets and different visual tasks show that our
framework achieves $20\% - 40\%$ reduction in computation (FLOPs) when compared
to state-of-the-art methods without any performance loss. Project page:
<a href="http://people.csail.mit.edu/bpan/va-red/.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PrivateMail: Supervised Manifold Learning of Deep Features With Differential Privacy for Image Retrieval. (arXiv:2102.10802v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10802">
<div class="article-summary-box-inner">
<span><p>Differential Privacy offers strong guarantees such as immutable privacy under
post processing. Thus it is often looked to as a solution to learning on
scattered and isolated data. This work focuses on supervised manifold learning,
a paradigm that can generate fine-tuned manifolds for a target use case. Our
contributions are two fold. 1) We present a novel differentially private method
\textit{PrivateMail} for supervised manifold learning, the first of its kind to
our knowledge. 2) We provide a novel private geometric embedding scheme for our
experimental use case. We experiment on private "content based image retrieval"
- embedding and querying the nearest neighbors of images in a private manner -
and show extensive privacy-utility tradeoff results, as well as the
computational efficiency and practicality of our methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards clinically applicable automated aneurysm detection in TOF-MRA: weak labels, anatomical knowledge, and open data. (arXiv:2103.06168v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06168">
<div class="article-summary-box-inner">
<span><p>Purpose: 1) Develop a deep learning algorithm for brain aneurysm detection
exploiting weak labels and prior anatomical knowledge. 2) Describe and release
the largest Time-Of-Flight Magnetic Resonance Angiography (TOF-MRA) dataset to
the community.
</p>
<p>Materials and Methods: In this retrospective study we retrieved TOF-MRA
images of 284 subjects (170 females) scanned between 2010 and 2015. Out of
these, 157 are patients with a total of 198 aneurysms, while 127 are controls.
We used spherical weak labels as detection ground truth, thus making data
annotation, a major bottleneck for medical AI, noticeably faster. Since
aneurysms mainly occur in specific locations, we built our deep neural network
leveraging the anatomy of the brain vasculature. To assess model robustness, we
participated in the first public challenge for TOF-MRA data (93 patients, 20
controls, 125 aneurysms). We stratified results according to aneurysm
risk-of-rupture, location, and size.
</p>
<p>Results: Our network achieves a sensitivity of 80% on the in-house data, with
False Positive (FP) rate of 1.2 per patient. On the public challenge data,
sensitivity was 68% (FP rate = 2.5), ranking 4th/16 on the open leaderboard. We
found no significant difference in sensitivity between risk groups (p = 0.75),
locations (p = 0.72), or sizes (p = 0.15).
</p>
<p>Conclusion: Competitive results can be obtained using fast weak labels and
anatomical knowledge for automated aneurysm detection. Our open-source code and
open access dataset can foster reproducibility, and bring us closer to clinical
application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The impact of data volume on performance of deep learning based building rooftop extraction using very high spatial resolution aerial images. (arXiv:2103.09300v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09300">
<div class="article-summary-box-inner">
<span><p>Building rooftop data are of importance in several urban applications and in
natural disaster management. In contrast to traditional surveying and mapping,
by using high spatial resolution aerial images, deep learning-based building
rooftops extraction methods are efficient and accurate. Although more training
data is preferred in deep learning-based tasks, the effect of data volume on
building extraction models is underexplored. Therefore, the paper explores the
impact of data volume on the performance of building rooftop extraction from
very-high-spatial-resolution (VHSR) images using deep learning-based methods.
To do so, we manually labelled 0.12m spatial resolution aerial images and
perform a comparative analysis of models trained on datasets of different sizes
using popular deep learning architectures for segmentation tasks, including
Fully Convolutional Networks (FCN)-8s, U-Net and DeepLabv3+. The experiments
showed that with more training data, algorithms converged faster and achieved
higher accuracy, while better algorithms were able to better mitigate the lack
of training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep learning on fundus images detects glaucoma beyond the optic disc. (arXiv:2103.11895v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11895">
<div class="article-summary-box-inner">
<span><p>Although unprecedented sensitivity and specificity values are reported,
recent glaucoma detection deep learning models lack in decision transparency.
Here, we propose a methodology that advances explainable deep learning in the
field of glaucoma detection and vertical cup-disc ratio (VCDR), an important
risk factor. We trained and evaluated deep learning models using fundus images
that underwent a certain cropping policy. We defined the crop radius as a
percentage of image size, centered on the optic nerve head (ONH), with an
equidistant spaced range from 10%-60% (ONH crop policy). The inverse of the
cropping mask was also applied (periphery crop policy). Trained models using
original images resulted in an area under the curve (AUC) of 0.94 [95% CI:
0.92-0.96] for glaucoma detection, and a coefficient of determination (R^2)
equal to 77% [95% CI: 0.77-0.79] for VCDR estimation. Models that were trained
on images with absence of the ONH are still able to obtain significant
performance (0.88 [95% CI: 0.85-0.90] AUC for glaucoma detection and 37% [95%
CI: 0.35-0.40] R^2 score for VCDR estimation in the most extreme setup of 60%
ONH crop). Our findings provide the first irrefutable evidence that deep
learning can detect glaucoma from fundus image regions outside the ONH.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Virtual Light Transport Matrices for Non-Line-Of-Sight Imaging. (arXiv:2103.12622v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12622">
<div class="article-summary-box-inner">
<span><p>The light transport matrix (LTM) is an instrumental tool in line-of-sight
(LOS) imaging, describing how light interacts with the scene and enabling
applications such as relighting or separation of illumination components. We
introduce a framework to estimate the LTM of non-line-of-sight (NLOS)
scenarios, coupling recent virtual forward light propagation models for NLOS
imaging with the LOS light transport equation. We design computational
projector-camera setups, and use these virtual imaging systems to estimate the
transport matrix of hidden scenes. We introduce the specific illumination
functions to compute the different elements of the matrix, overcoming the
challenging wide-aperture conditions of NLOS setups. Our NLOS light transport
matrix allows us to (re)illuminate specific locations of a hidden scene, and
separate direct, first-order indirect, and higher-order indirect illumination
of complex cluttered hidden scenes, similar to existing LOS techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YOLinO: Generic Single Shot Polyline Detection in Real Time. (arXiv:2103.14420v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14420">
<div class="article-summary-box-inner">
<span><p>The detection of polylines is usually either bound to branchless polylines or
formulated in a recurrent way, prohibiting their use in real-time systems.
</p>
<p>We propose an approach that builds upon the idea of single shot object
detection. Reformulating the problem of polyline detection as a bottom-up
composition of small line segments allows to detect bounded, dashed and
continuous polylines with a single head. This has several major advantages over
previous methods. Not only is the method at 187 fps more than suited for
real-time applications with virtually any restriction on the shapes of the
detected polylines. By predicting multiple line segments for each cell, even
branching or crossing polylines can be detected.
</p>
<p>We evaluate our approach on three different applications for road marking,
lane border and center line detection. Hereby, we demonstrate the ability to
generalize to different domains as well as both implicit and explicit polyline
detection tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Broaden Your Views for Self-Supervised Video Learning. (arXiv:2103.16559v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16559">
<div class="article-summary-box-inner">
<span><p>Most successful self-supervised learning methods are trained to align the
representations of two independent views from the data. State-of-the-art
methods in video are inspired by image techniques, where these two views are
similarly extracted by cropping and augmenting the resulting crop. However,
these methods miss a crucial element in the video domain: time. We introduce
BraVe, a self-supervised learning framework for video. In BraVe, one of the
views has access to a narrow temporal window of the video while the other view
has a broad access to the video content. Our models learn to generalise from
the narrow view to the general content of the video. Furthermore, BraVe
processes the views with different backbones, enabling the use of alternative
augmentations or modalities into the broad view such as optical flow, randomly
convolved RGB frames, audio or their combinations. We demonstrate that BraVe
achieves state-of-the-art results in self-supervised representation learning on
standard video and audio classification benchmarks including UCF101, HMDB51,
Kinetics, ESC-50 and AudioSet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Discriminator Adversarial Distillation for Data-free Model Compression. (arXiv:2104.05382v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05382">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation has been widely used to produce portable and efficient
neural networks which can be well applied on edge devices for computer vision
tasks. However, almost all top-performing knowledge distillation methods need
to access the original training data, which usually has a huge size and is
often unavailable. To tackle this problem, we propose a novel data-free
approach in this paper, named Dual Discriminator Adversarial Distillation
(DDAD) to distill a neural network without any training data or meta-data. To
be specific, we use a generator to create samples through dual discriminator
adversarial distillation, which mimics the original training data. The
generator not only uses the pre-trained teacher's intrinsic statistics in
existing batch normalization layers but also obtains the maximum discrepancy
from the student model. Then the generated samples are used to train the
compact student network under the supervision of the teacher. The proposed
method obtains an efficient student network which closely approximates its
teacher network, despite using no original training data. Extensive experiments
are conducted to to demonstrate the effectiveness of the proposed approach on
CIFAR-10, CIFAR-100 and Caltech101 datasets for classification tasks. Moreover,
we extend our method to semantic segmentation tasks on several public datasets
such as CamVid and NYUv2. All experiments show that our method outperforms all
baselines for data-free knowledge distillation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-19 detection using deep convolutional neural networks and binary-differential-algorithm-based feature selection on X-ray images. (arXiv:2104.07279v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07279">
<div class="article-summary-box-inner">
<span><p>The new Coronavirus is spreading rapidly, and it has taken the lives of many
people so far. The virus has destructive effects on the human lung, and early
detection is very important. Deep Convolution neural networks are such powerful
tools in classifying images. Therefore, in this paper, a hybrid approach based
on a deep network is presented. Feature vectors were extracted by applying a
deep convolution neural network on the images, and useful features were
selected by the binary differential meta-heuristic algorithm. These optimized
features were given to the SVM classifier. A database consisting of three
categories of images such as COVID-19, pneumonia, and healthy included in 1092
X-ray samples was considered. The proposed method achieved an accuracy of
99.43%, a sensitivity of 99.16%, and a specificity of 99.57%. Our results
demonstrate that the suggested approach is better than recent studies on
COVID-19 detection with X-ray images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TricubeNet: 2D Kernel-Based Object Representation for Weakly-Occluded Oriented Object Detection. (arXiv:2104.11435v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11435">
<div class="article-summary-box-inner">
<span><p>We present a novel approach for oriented object detection, named TricubeNet,
which localizes oriented objects using visual cues ($i.e.,$ heatmap) instead of
oriented box offsets regression. We represent each object as a 2D Tricube
kernel and extract bounding boxes using simple image-processing algorithms. Our
approach is able to (1) obtain well-arranged boxes from visual cues, (2) solve
the angle discontinuity problem, and (3) can save computational complexity due
to our anchor-free modeling. To further boost the performance, we propose some
effective techniques for size-invariant loss, reducing false detections,
extracting rotation-invariant features, and heatmap refinement. To demonstrate
the effectiveness of our TricubeNet, we experiment on various tasks for
weakly-occluded oriented object detection: detection in an aerial image,
densely packed object image, and text image. The extensive experimental results
show that our TricubeNet is quite effective for oriented object detection. Code
is available at https://github.com/qjadud1994/TricubeNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One-shot Compositional Data Generation for Low Resource Handwritten Text Recognition. (arXiv:2105.05300v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05300">
<div class="article-summary-box-inner">
<span><p>Low resource Handwritten Text Recognition (HTR) is a hard problem due to the
scarce annotated data and the very limited linguistic information (dictionaries
and language models). For example, in the case of historical ciphered
manuscripts, which are usually written with invented alphabets to hide the
message contents. Thus, in this paper we address this problem through a data
generation technique based on Bayesian Program Learning (BPL). Contrary to
traditional generation approaches, which require a huge amount of annotated
images, our method is able to generate human-like handwriting using only one
sample of each symbol in the alphabet. After generating symbols, we create
synthetic lines to train state-of-the-art HTR architectures in a segmentation
free fashion. Quantitative and qualitative analyses were carried out and
confirm the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fit4CAD: A point cloud benchmark for fitting simple geometric primitives in CAD objects. (arXiv:2105.06858v3 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06858">
<div class="article-summary-box-inner">
<span><p>We propose Fit4CAD, a benchmark for the evaluation and comparison of methods
for fitting simple geometric primitives in point clouds representing CAD
objects. This benchmark is meant to help both method developers and those who
want to identify the best performing tools. The Fit4CAD dataset is composed by
225 high quality point clouds, each of which has been obtained by sampling a
CAD object. The way these elements were created by using existing platforms and
datasets makes the benchmark easily expandable. The dataset is already split
into a training set and a test set. To assess performance and accuracy of the
different primitive fitting methods, various measures are defined. To
demonstrate the effective use of Fit4CAD, we have tested it on two methods
belonging to two different categories of approaches to the primitive fitting
problem: a clustering method based on a primitive growing framework and a
parametric method based on the Hough transform.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoMate: A Dataset and Learning Approach for Automatic Mating of CAD Assemblies. (arXiv:2105.12238v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12238">
<div class="article-summary-box-inner">
<span><p>Assembly modeling is a core task of computer aided design (CAD), comprising
around one third of the work in a CAD workflow. Optimizing this process
therefore represents a huge opportunity in the design of a CAD system, but
current research of assembly based modeling is not directly applicable to
modern CAD systems because it eschews the dominant data structure of modern
CAD: parametric boundary representations (BREPs). CAD assembly modeling defines
assemblies as a system of pairwise constraints, called mates, between parts,
which are defined relative to BREP topology rather than in world coordinates
common to existing work. We propose SB-GCN, a representation learning scheme on
BREPs that retains the topological structure of parts, and use these learned
representations to predict CAD type mates. To train our system, we compiled the
first large scale dataset of BREP CAD assemblies, which we are releasing along
with benchmark mate prediction tasks. Finally, we demonstrate the compatibility
of our model with an existing commercial CAD system by building a tool that
assists users in mate creation by suggesting mate completions, with 72.2%
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fidelity Estimation Improves Noisy-Image Classification With Pretrained Networks. (arXiv:2106.00673v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00673">
<div class="article-summary-box-inner">
<span><p>Image classification has significantly improved using deep learning. This is
mainly due to convolutional neural networks (CNNs) that are capable of learning
rich feature extractors from large datasets. However, most deep learning
classification methods are trained on clean images and are not robust when
handling noisy ones, even if a restoration preprocessing step is applied. While
novel methods address this problem, they rely on modified feature extractors
and thus necessitate retraining. We instead propose a method that can be
applied on a $pretrained$ classifier. Our method exploits a fidelity map
estimate that is fused into the internal representations of the feature
extractor, thereby guiding the attention of the network and making it more
robust to noisy data. We improve the noisy-image classification (NIC) results
by significantly large margins, especially at high noise levels, and come close
to the fully retrained approaches. Furthermore, as proof of concept, we show
that when using our oracle fidelity map we even outperform the fully retrained
methods, whether trained on noisy or restored images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Digital Taxonomist: Identifying Plant Species in Community Scientists' Photographs. (arXiv:2106.03774v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03774">
<div class="article-summary-box-inner">
<span><p>Automatic identification of plant specimens from amateur photographs could
improve species range maps, thus supporting ecosystems research as well as
conservation efforts. However, classifying plant specimens based on image data
alone is challenging: some species exhibit large variations in visual
appearance, while at the same time different species are often visually
similar; additionally, species observations follow a highly imbalanced,
long-tailed distribution due to differences in abundance as well as observer
biases. On the other hand, most species observations are accompanied by side
information about the spatial, temporal and ecological context. Moreover,
biological species are not an unordered list of classes but embedded in a
hierarchical taxonomic structure. We propose a multimodal deep learning model
that takes into account these additional cues in a unified framework. Our
Digital Taxonomist is able to identify plant species in photographs better than
a classifier trained on the image content alone, the performance gained is over
6 percent points in terms of accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A multi-stage GAN for multi-organ chest X-ray image generation and segmentation. (arXiv:2106.05132v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05132">
<div class="article-summary-box-inner">
<span><p>Multi-organ segmentation of X-ray images is of fundamental importance for
computer aided diagnosis systems. However, the most advanced semantic
segmentation methods rely on deep learning and require a huge amount of labeled
images, which are rarely available due to both the high cost of human resources
and the time required for labeling. In this paper, we present a novel
multi-stage generation algorithm based on Generative Adversarial Networks
(GANs) that can produce synthetic images along with their semantic labels and
can be used for data augmentation. The main feature of the method is that,
unlike other approaches, generation occurs in several stages, which simplifies
the procedure and allows it to be used on very small datasets. The method has
been evaluated on the segmentation of chest radiographic images, showing
promising results. The multistage approach achieves state-of-the-art and, when
very few images are used to train the GANs, outperforms the corresponding
single-stage approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Resolution Continuous Normalizing Flows. (arXiv:2106.08462v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08462">
<div class="article-summary-box-inner">
<span><p>Recent work has shown that Neural Ordinary Differential Equations (ODEs) can
serve as generative models of images using the perspective of Continuous
Normalizing Flows (CNFs). Such models offer exact likelihood calculation, and
invertible generation/density estimation. In this work we introduce a
Multi-Resolution variant of such models (MRCNF), by characterizing the
conditional distribution over the additional information required to generate a
fine image that is consistent with the coarse image. We introduce a
transformation between resolutions that allows for no change in the log
likelihood. We show that this approach yields comparable likelihood values for
various image datasets, with improved performance at higher resolutions, with
fewer parameters, using only 1 GPU. Further, we examine the out-of-distribution
properties of (Multi-Resolution) Continuous Normalizing Flows, and find that
they are similar to those of other likelihood-based generative models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?. (arXiv:2106.11297v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11297">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a novel visual representation learning which
relies on a handful of adaptively learned tokens, and which is applicable to
both image and video understanding tasks. Instead of relying on hand-designed
splitting strategies to obtain visual tokens and processing a large number of
densely sampled patches for attention, our approach learns to mine important
tokens in visual data. This results in efficiently and effectively finding a
few important visual tokens and enables modeling of pairwise attention between
such tokens, over a longer temporal horizon for videos, or the spatial content
in images. Our experiments demonstrate strong performance on several
challenging benchmarks for both image and video recognition tasks. Importantly,
due to our tokens being adaptive, we accomplish competitive results at
significantly reduced compute amount. We obtain comparable results to the
state-of-the-arts on ImageNet while being computationally more efficient. We
establish new state-of-the-arts on multiple video datasets, including
Kinetics-400, Kinetics-600, Charades, and AViD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Technical Document Classification. (arXiv:2106.14269v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14269">
<div class="article-summary-box-inner">
<span><p>In large technology companies, the requirements for managing and organizing
technical documents created by engineers and managers in supporting relevant
decision making have increased dramatically in recent years, which has led to a
higher demand for more scalable, accurate, and automated document
classification. Prior studies have only focused on processing text for
classification, whereas technical documents often contain multimodal
information. This paper presents a novel multimodal deep learning architecture,
TechDoc, for technical document classification, which utilizes three types of
information, including natural language texts and descriptive images within
documents and the associations among the documents. The architecture
synthesizes the convolutional neural network, recurrent neural network, and
graph neural network through an integrated multimodal training process. We
applied the architecture to a large multimodal technical document database and
trained the model for classifying documents based on the hierarchical
International Patent Classification system. Our results show that TechDoc
presents a greater classification accuracy than the unimodal methods and other
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable Mammographic Image Classification using Case-Based Reasoning and Deep Learning. (arXiv:2107.05605v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05605">
<div class="article-summary-box-inner">
<span><p>When we deploy machine learning models in high-stakes medical settings, we
must ensure these models make accurate predictions that are consistent with
known medical science. Inherently interpretable networks address this need by
explaining the rationale behind each decision while maintaining equal or higher
accuracy compared to black-box models. In this work, we present a novel
interpretable neural network algorithm that uses case-based reasoning for
mammography. Designed to aid a radiologist in their decisions, our network
presents both a prediction of malignancy and an explanation of that prediction
using known medical features. In order to yield helpful explanations, the
network is designed to mimic the reasoning processes of a radiologist: our
network first detects the clinically relevant semantic features of each image
by comparing each new image with a learned set of prototypical image parts from
the training images, then uses those clinical features to predict malignancy.
Compared to other methods, our model detects clinical features (mass margins)
with equal or higher accuracy, provides a more detailed explanation of its
prediction, and is better able to differentiate the classification-relevant
parts of the image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Urban Driving by Imitating a Reinforcement Learning Coach. (arXiv:2108.08265v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08265">
<div class="article-summary-box-inner">
<span><p>End-to-end approaches to autonomous driving commonly rely on expert
demonstrations. Although humans are good drivers, they are not good coaches for
end-to-end algorithms that demand dense on-policy supervision. On the contrary,
automated experts that leverage privileged information can efficiently generate
large scale on-policy and off-policy demonstrations. However, existing
automated experts for urban driving make heavy use of hand-crafted rules and
perform suboptimally even on driving simulators, where ground-truth information
is available. To address these issues, we train a reinforcement learning expert
that maps bird's-eye view images to continuous low-level actions. While setting
a new performance upper-bound on CARLA, our expert is also a better coach that
provides informative supervision signals for imitation learning agents to learn
from. Supervised by our reinforcement learning coach, a baseline end-to-end
agent with monocular camera-input achieves expert-level performance. Our
end-to-end agent achieves a 78% success rate while generalizing to a new town
and new weather on the NoCrash-dense benchmark and state-of-the-art performance
on the challenging public routes of the CARLA LeaderBoard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning-based Spacecraft Relative Navigation Methods: A Survey. (arXiv:2108.08876v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08876">
<div class="article-summary-box-inner">
<span><p>Autonomous spacecraft relative navigation technology has been planned for and
applied to many famous space missions. The development of on-board electronics
systems has enabled the use of vision-based and LiDAR-based methods to achieve
better performances. Meanwhile, deep learning has reached great success in
different areas, especially in computer vision, which has also attracted the
attention of space researchers. However, spacecraft navigation differs from
ground tasks due to high reliability requirements but lack of large datasets.
This survey aims to systematically investigate the current deep learning-based
autonomous spacecraft relative navigation methods, focusing on concrete orbital
applications such as spacecraft rendezvous and landing on small bodies or the
Moon. The fundamental characteristics, primary motivations, and contributions
of deep learning-based relative navigation algorithms are first summarised from
three perspectives of spacecraft rendezvous, asteroid exploration, and terrain
navigation. Furthermore, popular visual tracking benchmarks and their
respective properties are compared and summarised. Finally, potential
applications are discussed, along with expected impediments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep few-shot learning for bi-temporal building change detection. (arXiv:2108.11262v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11262">
<div class="article-summary-box-inner">
<span><p>In real-world applications (e.g., change detection), annotating images is
very expensive. To build effective deep learning models in these applications,
deep few-shot learning methods have been developed and prove to be a robust
approach in small training data. The analysis of building change detection from
high spatial resolution remote sensing observations is important research in
photogrammetry, computer vision, and remote sensing nowadays, which can be
widely used in a variety of real-world applications, such as map updating. As
manual high resolution image interpretation is expensive and time-consuming,
building change detection methods are of high interest. The interest in
developing building change detection approaches from optical remote sensing
images is rapidly increasing due to larger coverages, and lower costs of
optical images. In this study, we focus on building change detection analysis
on a small set of building change from different regions that sit in several
cities. In this paper, a new deep few-shot learning method is proposed for
building change detection using Monte Carlo dropout and remote sensing
observations. The setup is based on a small dataset, including bitemporal
optical images labeled for building change detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-view Stereo. (arXiv:2109.01129v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01129">
<div class="article-summary-box-inner">
<span><p>In this work, we present a new multi-view depth estimation method that
utilizes both conventional reconstruction and learning-based priors over the
recently proposed neural radiance fields (NeRF). Unlike existing neural network
based optimization method that relies on estimated correspondences, our method
directly optimizes over implicit volumes, eliminating the challenging step of
matching pixels in indoor scenes. The key to our approach is to utilize the
learning-based priors to guide the optimization process of NeRF. Our system
firstly adapts a monocular depth network over the target scene by finetuning on
its sparse SfM+MVS reconstruction from COLMAP. Then, we show that the
shape-radiance ambiguity of NeRF still exists in indoor environments and
propose to address the issue by employing the adapted depth priors to monitor
the sampling process of volume rendering. Finally, a per-pixel confidence map
acquired by error computation on the rendered image can be used to further
improve the depth quality. Experiments show that our proposed framework
significantly outperforms state-of-the-art methods on indoor scenes, with
surprising findings presented on the effectiveness of correspondence-based
optimization and NeRF-based optimization over the adapted depth priors. In
addition, we show that the guided optimization scheme does not sacrifice the
original synthesis capability of neural radiance fields, improving the
rendering quality on both seen and novel views. Code is available at
https://github.com/weiyithu/NerfingMVS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Common Assumptions to Mitigate Racial Bias in Face Recognition Datasets. (arXiv:2109.03229v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03229">
<div class="article-summary-box-inner">
<span><p>Many existing works have made great strides towards reducing racial bias in
face recognition. However, most of these methods attempt to rectify bias that
manifests in models during training instead of directly addressing a major
source of the bias, the dataset itself. Exceptions to this are
BUPT-Balancedface/RFW and Fairface, but these works assume that primarily
training on a single race or not racially balancing the dataset are inherently
disadvantageous. We demonstrate that these assumptions are not necessarily
valid. In our experiments, training on only African faces induced less bias
than training on a balanced distribution of faces and distributions skewed to
include more African faces produced more equitable models. We additionally
notice that adding more images of existing identities to a dataset in place of
adding new identities can lead to accuracy boosts across racial categories. Our
code is available at
https://github.com/j-alex-hanson/rethinking-race-face-datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigation of condominium building collapse in Surfside, Florida: A video feature tracking approach. (arXiv:2109.06629v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06629">
<div class="article-summary-box-inner">
<span><p>On June 24, 2021, a 12-story condominium building (Champlain Towers South) in
Surfside, Florida partially collapsed, resulting in one of the deadliest
building collapses in United States history with 98 people confirmed deceased.
In this work, we analyze the collapse event using a video clip that is publicly
available from social media. In our analysis, we apply computer vision
algorithms to corroborate new information from the video clip that may not be
readily interpreted by human eyes. By comparing the differential features
against different video frames, our proposed method is used to quantify the
falling structural components by mapping the directions and magnitudes of their
movements. We demonstrate the potential of this video processing methodology in
investigations of catastrophic structural failures and hope our approach may
serve as a basis for further investigations into structure collapse events.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Designing Counterfactual Generators using Deep Model Inversion. (arXiv:2109.14274v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14274">
<div class="article-summary-box-inner">
<span><p>Explanation techniques that synthesize small, interpretable changes to a
given image while producing desired changes in the model prediction have become
popular for introspecting black-box models. Commonly referred to as
counterfactuals, the synthesized explanations are required to contain
discernible changes (for easy interpretability) while also being realistic
(consistency to the data manifold). In this paper, we focus on the case where
we have access only to the trained deep classifier and not the actual training
data. While the problem of inverting deep models to synthesize images from the
training distribution has been explored, our goal is to develop a deep
inversion approach to generate counterfactual explanations for a given query
image. Despite their effectiveness in conditional image synthesis, we show that
existing deep inversion methods are insufficient for producing meaningful
counterfactuals. We propose DISC (Deep Inversion for Synthesizing
Counterfactuals) that improves upon deep inversion by utilizing (a) stronger
image priors, (b) incorporating a novel manifold consistency objective and (c)
adopting a progressive optimization strategy. We find that, in addition to
producing visually meaningful explanations, the counterfactuals from DISC are
effective at learning classifier decision boundaries and are robust to unknown
test-time corruptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fake It Till You Make It: Face analysis in the wild using synthetic data alone. (arXiv:2109.15102v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.15102">
<div class="article-summary-box-inner">
<span><p>We demonstrate that it is possible to perform face-related computer vision in
the wild using synthetic data alone. The community has long enjoyed the
benefits of synthesizing training data with graphics, but the domain gap
between real and synthetic data has remained a problem, especially for human
faces. Researchers have tried to bridge this gap with data mixing, domain
adaptation, and domain-adversarial training, but we show that it is possible to
synthesize data with minimal domain gap, so that models trained on synthetic
data generalize to real in-the-wild datasets. We describe how to combine a
procedurally-generated parametric 3D face model with a comprehensive library of
hand-crafted assets to render training images with unprecedented realism and
diversity. We train machine learning systems for face-related tasks such as
landmark localization and face parsing, showing that synthetic data can both
match real data in accuracy as well as open up new approaches where manual
labelling would be impossible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identity-Disentangled Neural Deformation Model for Dynamic Meshes. (arXiv:2109.15299v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.15299">
<div class="article-summary-box-inner">
<span><p>Neural shape models can represent complex 3D shapes with a compact latent
space. When applied to dynamically deforming shapes such as the human hands,
however, they would need to preserve temporal coherence of the deformation as
well as the intrinsic identity of the subject. These properties are difficult
to regularize with manually designed loss functions. In this paper, we learn a
neural deformation model that disentangles the identity-induced shape
variations from pose-dependent deformations using implicit neural functions. We
perform template-free unsupervised learning on 3D scans without explicit mesh
correspondence or semantic correspondences of shapes across subjects. We can
then apply the learned model to reconstruct partial dynamic 4D scans of novel
subjects performing unseen actions. We propose two methods to integrate global
pose alignment with our neural deformation model. Experiments demonstrate the
efficacy of our method in the disentanglement of identities and pose. Our
method also outperforms traditional skeleton-driven models in reconstructing
surface details such as palm prints or tendons without limitations from a fixed
template.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Spiking Variational Autoencoder. (arXiv:2110.00375v2 [cs.NE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00375">
<div class="article-summary-box-inner">
<span><p>Spiking neural networks (SNNs) can be run on neuromorphic devices with
ultra-high speed and ultra-low energy consumption because of their binary and
event-driven nature. Therefore, SNNs are expected to have various applications,
including as generative models being running on edge devices to create
high-quality images. In this study, we build a variational autoencoder (VAE)
with SNN to enable image generation. VAE is known for its stability among
generative models; recently, its quality advanced. In vanilla VAE, the latent
space is represented as a normal distribution, and floating-point calculations
are required in sampling. However, this is not possible in SNNs because all
features must be binary time series data. Therefore, we constructed the latent
space with an autoregressive SNN model, and randomly selected samples from its
output to sample the latent variables. This allows the latent variables to
follow the Bernoulli process and allows variational learning. Thus, we build
the Fully Spiking Variational Autoencoder where all modules are constructed
with SNN. To the best of our knowledge, we are the first to build a VAE only
with SNN layers. We experimented with several datasets, and confirmed that it
can generate images with the same or better quality compared to conventional
ANNs. The code is available at https://github.com/kamata1729/FullySpikingVAE
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Unfolding Total Variation Network for Low-Light Image Enhancement. (arXiv:2110.00984v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00984">
<div class="article-summary-box-inner">
<span><p>Real-world low-light images suffer from two main degradations, namely,
inevitable noise and poor visibility. Since the noise exhibits different
levels, its estimation has been implemented in recent works when enhancing
low-light images from raw Bayer space. When it comes to sRGB color space, the
noise estimation becomes more complicated due to the effect of the image
processing pipeline. Nevertheless, most existing enhancing algorithms in sRGB
space only focus on the low visibility problem or suppress the noise under a
hypothetical noise level, leading them impractical due to the lack of
robustness. To address this issue,we propose an adaptive unfolding total
variation network (UTVNet), which approximates the noise level from the real
sRGB low-light image by learning the balancing parameter in the model-based
denoising method with total variation regularization. Meanwhile, we learn the
noise level map by unrolling the corresponding minimization process for
providing the inferences of smoothness and fidelity constraints. Guided by the
noise level map, our UTVNet can recover finer details and is more capable to
suppress noise in real captured low-light scenes. Extensive experiments on
real-world low-light images clearly demonstrate the superior performance of
UTVNet over state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supervised Contrastive Replay: Revisiting the Nearest Class Mean Classifier in Online Class-Incremental Continual Learning. (arXiv:2103.13885v3 [cs.LG] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13885">
<div class="article-summary-box-inner">
<span><p>Online class-incremental continual learning (CL) studies the problem of
learning new classes continually from an online non-stationary data stream,
intending to adapt to new data while mitigating catastrophic forgetting. While
memory replay has shown promising results, the recency bias in online learning
caused by the commonly used Softmax classifier remains an unsolved challenge.
Although the Nearest-Class-Mean (NCM) classifier is significantly undervalued
in the CL community, we demonstrate that it is a simple yet effective
substitute for the Softmax classifier. It addresses the recency bias and avoids
structural changes in the fully-connected layer for new classes. Moreover, we
observe considerable and consistent performance gains when replacing the
Softmax classifier with the NCM classifier for several state-of-the-art replay
methods. To leverage the NCM classifier more effectively, data embeddings
belonging to the same class should be clustered and well-separated from those
with a different class label. To this end, we contribute Supervised Contrastive
Replay (SCR), which explicitly encourages samples from the same class to
cluster tightly in embedding space while pushing those of different classes
further apart during replay-based training. Overall, we observe that our
proposed SCR substantially reduces catastrophic forgetting and outperforms
state-of-the-art CL methods by a significant margin on a variety of datasets.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-06 23:02:04.280353965 UTC">2021-10-06 23:02:04 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>