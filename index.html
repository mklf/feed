<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-05-24T01:30:00Z">05-24</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Task-Oriented Dialogue Generation with Contrastive Pre-training and Adversarial Filtering. (arXiv:2205.10363v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10363">
<div class="article-summary-box-inner">
<span><p>Data artifacts incentivize machine learning models to learn non-transferable
generalizations by taking advantage of shortcuts in the data, and there is
growing evidence that data artifacts play a role for the strong results that
deep learning models achieve in recent natural language processing benchmarks.
In this paper, we focus on task-oriented dialogue and investigate whether
popular datasets such as MultiWOZ contain such data artifacts. We found that by
only keeping frequent phrases in the training examples, state-of-the-art models
perform similarly compared to the variant trained with full data, suggesting
they exploit these spurious correlations to solve the task. Motivated by this,
we propose a contrastive learning based framework to encourage the model to
ignore these cues and focus on learning generalisable patterns. We also
experiment with adversarial filtering to remove "easy" training instances so
that the model would focus on learning from the "harder" instances. We conduct
a number of generalization experiments -- e.g., cross-domain/dataset and
adversarial tests -- to assess the robustness of our approach and found that it
works exceptionally well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modernizing Open-Set Speech Language Identification. (arXiv:2205.10397v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10397">
<div class="article-summary-box-inner">
<span><p>While most modern speech Language Identification methods are closed-set, we
want to see if they can be modified and adapted for the open-set problem. When
switching to the open-set problem, the solution gains the ability to reject an
audio input when it fails to match any of our known language options. We tackle
the open-set task by adapting two modern-day state-of-the-art approaches to
closed-set language identification: the first using a CRNN with attention and
the second using a TDNN. In addition to enhancing our input feature embeddings
using MFCCs, log spectral features, and pitch, we will be attempting two
approaches to out-of-set language detection: one using thresholds, and the
other essentially performing a verification task. We will compare both the
performance of the TDNN and the CRNN, as well as our detection approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Normalization of Temporal Expressions with Masked Language Models. (arXiv:2205.10399v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10399">
<div class="article-summary-box-inner">
<span><p>The detection and normalization of temporal expressions is an important task
and a preprocessing step for many applications. However, prior work on
normalization is rule-based, which severely limits the applicability in
real-world multilingual settings, due to the costly creation of new rules. We
propose a novel neural method for normalizing temporal expressions based on
masked language modeling. Our multilingual method outperforms prior rule-based
systems in many languages, and in particular, for low-resource languages with
performance improvements of up to 35 F1 on average compared to the state of the
art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi2WOZ: A Robust Multilingual Dataset and Conversational Pretraining for Task-Oriented Dialog. (arXiv:2205.10400v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10400">
<div class="article-summary-box-inner">
<span><p>Research on (multi-domain) task-oriented dialog (TOD) has predominantly
focused on the English language, primarily due to the shortage of robust TOD
datasets in other languages, preventing the systematic investigation of
cross-lingual transfer for this crucial NLP application area. In this work, we
introduce Multi2WOZ, a new multilingual multi-domain TOD dataset, derived from
the well-established English dataset MultiWOZ, that spans four typologically
diverse languages: Chinese, German, Arabic, and Russian. In contrast to
concurrent efforts, Multi2WOZ contains gold-standard dialogs in target
languages that are directly comparable with development and test portions of
the English dataset, enabling reliable and comparative estimates of
cross-lingual transfer performance for TOD. We then introduce a new framework
for multilingual conversational specialization of pretrained language models
(PrLMs) that aims to facilitate cross-lingual transfer for arbitrary downstream
TOD tasks. Using such conversational PrLMs specialized for concrete target
languages, we systematically benchmark a number of zero-shot and few-shot
cross-lingual transfer approaches on two standard TOD tasks: Dialog State
Tracking and Response Retrieval. Our experiments show that, in most setups, the
best performance entails the combination of (I) conversational specialization
in the target language and (ii) few-shot transfer for the concrete TOD task.
Most importantly, we show that our conversational specialization in the target
language allows for an exceptionally sample-efficient few-shot transfer for
downstream TOD tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Forecasting COVID-19 Caseloads Using Unsupervised Embedding Clusters of Social Media Posts. (arXiv:2205.10408v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10408">
<div class="article-summary-box-inner">
<span><p>We present a novel approach incorporating transformer-based language models
into infectious disease modelling. Text-derived features are quantified by
tracking high-density clusters of sentence-level representations of Reddit
posts within specific US states' COVID-19 subreddits. We benchmark these
clustered embedding features against features extracted from other high-quality
datasets. In a threshold-classification task, we show that they outperform all
other feature types at predicting upward trend signals, a significant result
for infectious disease modelling in areas where epidemiological data is
unreliable. Subsequently, in a time-series forecasting task we fully utilise
the predictive power of the caseload and compare the relative strengths of
using different supplementary datasets as covariate feature sets in a
transformer-based time-series model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Educational Tools for Mapuzugun. (arXiv:2205.10411v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10411">
<div class="article-summary-box-inner">
<span><p>Mapuzugun is the language of the Mapuche people. Due to political and
historical reasons, its number of speakers has decreased and the language has
been excluded from the educational system in Chile and Argentina. For this
reason, it is very important to support the revitalization of the Mapuzugun in
all spaces and media of society. In this work we present a tool towards
supporting educational activities of Mapuzugun, tailored to the characteristics
of the language. The tool consists of three parts: design and development of an
orthography detector and converter; a morphological analyzer; and an informal
translator. We also present a case study with Mapuzugun students showing
promising results.
</p>
<p>Short Abstract in Mapuzuzgun: T\"ufachi k\"uzaw pegelfi ki\~ne zugun
k\"uzawpey\"um kelluaetew pu mapuzugun chillkatufe kimal kizu ta\~ni zugun.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Current Trends and Approaches in Synonyms Extraction: Potential Adaptation to Arabic. (arXiv:2205.10412v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10412">
<div class="article-summary-box-inner">
<span><p>Extracting synonyms from dictionaries or corpora is gaining special attention
as synonyms play an important role in improving NLP application performance.
This paper presents a survey of the different approaches and trends used in
automatically extracting the synonyms. These approaches can be divided into
four main categories. The first approach is to find the Synonyms using a
translation graph. The second approach is to discover new transition pairs such
as (Arabic-English) (English-France) then (Arabic-France). The third approach
is to construct new WordNets by exploring synonymy graphs, and the fourth
approach is to find similar words from corpora using Deep Learning methods,
such as word embeddings and recently BERT models. The paper also presents a
comparative analysis between these approaches and highlights potential
adaptation to generate synonyms automatically in the Arabic language as future
work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Down and Across: Introducing Crossword-Solving as a New NLP Benchmark. (arXiv:2205.10442v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10442">
<div class="article-summary-box-inner">
<span><p>Solving crossword puzzles requires diverse reasoning capabilities, access to
a vast amount of knowledge about language and the world, and the ability to
satisfy the constraints imposed by the structure of the puzzle. In this work,
we introduce solving crossword puzzles as a new natural language understanding
task. We release the specification of a corpus of crossword puzzles collected
from the New York Times daily crossword spanning 25 years and comprised of a
total of around nine thousand puzzles. These puzzles include a diverse set of
clues: historic, factual, word meaning, synonyms/antonyms, fill-in-the-blank,
abbreviations, prefixes/suffixes, wordplay, and cross-lingual, as well as clues
that depend on the answers to other clues. We separately release the
clue-answer pairs from these puzzles as an open-domain question answering
dataset containing over half a million unique clue-answer pairs. For the
question answering task, our baselines include several sequence-to-sequence and
retrieval-based generative models. We also introduce a non-parametric
constraint satisfaction baseline for solving the entire crossword puzzle.
Finally, we propose an evaluation framework which consists of several
complementary performance metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for PETs: Using Distributional and Sentiment-Based Methods to Find Potentially Euphemistic Terms. (arXiv:2205.10451v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10451">
<div class="article-summary-box-inner">
<span><p>This paper presents a linguistically driven proof of concept for finding
potentially euphemistic terms, or PETs. Acknowledging that PETs tend to be
commonly used expressions for a certain range of sensitive topics, we make use
of distributional similarities to select and filter phrase candidates from a
sentence and rank them using a set of simple sentiment-based metrics. We
present the results of our approach tested on a corpus of sentences containing
euphemisms, demonstrating its efficacy for detecting single and multi-word PETs
from a broad range of topics. We also discuss future potential for
sentiment-based methods on this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-training Transformer Models with Sentence-Level Objectives for Answer Sentence Selection. (arXiv:2205.10455v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10455">
<div class="article-summary-box-inner">
<span><p>An important task for designing QA systems is answer sentence selection
(AS2): selecting the sentence containing (or constituting) the answer to a
question from a set of retrieved relevant documents. In this paper, we propose
three novel sentence-level transformer pre-training objectives that incorporate
paragraph-level semantics within and across documents, to improve the
performance of transformers for AS2, and mitigate the requirement of large
labeled datasets. Our experiments on three public and one industrial AS2
datasets demonstrate the empirical superiority of our pre-trained transformers
over baseline models such as RoBERTa and ELECTRA for AS2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retrieval-Augmented Multilingual Keyphrase Generation with Retriever-Generator Iterative Training. (arXiv:2205.10471v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10471">
<div class="article-summary-box-inner">
<span><p>Keyphrase generation is the task of automatically predicting keyphrases given
a piece of long text. Despite its recent flourishing, keyphrase generation on
non-English languages haven't been vastly investigated. In this paper, we call
attention to a new setting named multilingual keyphrase generation and we
contribute two new datasets, EcommerceMKP and AcademicMKP, covering six
languages. Technically, we propose a retrieval-augmented method for
multilingual keyphrase generation to mitigate the data shortage problem in
non-English languages. The retrieval-augmented model leverages keyphrase
annotations in English datasets to facilitate generating keyphrases in
low-resource languages. Given a non-English passage, a cross-lingual dense
passage retrieval module finds relevant English passages. Then the associated
English keyphrases serve as external knowledge for keyphrase generation in the
current language. Moreover, we develop a retriever-generator iterative training
algorithm to mine pseudo parallel passage pairs to strengthen the cross-lingual
passage retriever. Comprehensive experiments and ablations show that the
proposed approach outperforms all baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepStruct: Pretraining of Language Models for Structure Prediction. (arXiv:2205.10475v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10475">
<div class="article-summary-box-inner">
<span><p>We introduce a method for improving the structural understanding abilities of
language models. Unlike previous approaches that finetune the models with
task-specific augmentation, we pretrain language models on a collection of
task-agnostic corpora to generate structures from text. Our structure
pretraining enables zero-shot transfer of the learned knowledge that models
have about the structure tasks. We study the performance of this approach on 28
datasets, spanning 10 structure prediction tasks including open information
extraction, joint entity and relation extraction, named entity recognition,
relation classification, semantic role labeling, event extraction, coreference
resolution, factual probe, intent detection, and dialogue state tracking. We
further enhance the pretraining with the task-specific training sets. We show
that a 10B parameter language model transfers non-trivially to most tasks and
obtains state-of-the-art performance on 21 of 28 datasets that we evaluate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DKG: A Descriptive Knowledge Graph for Explaining Relationships between Entities. (arXiv:2205.10479v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10479">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose Descriptive Knowledge Graph (DKG) - an open and
interpretable form of modeling relationships between entities. In DKGs,
relationships between entities are represented by relation descriptions. For
instance, the relationship between entities of machine learning and algorithm
can be described as "Machine learning explores the study and construction of
algorithms that can learn from and make predictions on data." To construct
DKGs, we propose a self-supervised learning method to extract relation
descriptions with the analysis of dependency patterns and a transformer-based
relation description synthesizing model to generate relation descriptions.
Experiments demonstrate that our system can extract and generate high-quality
relation descriptions for explaining entity relationships.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Named Entity Linking on Namesakes. (arXiv:2205.10498v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10498">
<div class="article-summary-box-inner">
<span><p>We propose a simple and practical method of named entity linking (NEL), and
explore its features and performance on a dataset of ambiguous named entities -
Namesakes. We represent knowledge base (KB) entity by a set of embeddings. Our
observations suggest that it is reasonable to keep a limited number of such
embeddings, and that the number of mentions required to create a KB entity is
important. We show that representations of entities in the knowledge base (KB)
can be adjusted using only KB data, and the adjustment improves NEL
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deeper vs Wider: A Revisit of Transformer Configuration. (arXiv:2205.10505v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10505">
<div class="article-summary-box-inner">
<span><p>Transformer-based models have delivered impressive results on many tasks,
particularly vision and language tasks. In many model training situations,
conventional configurations are typically adopted. For example, we often set
the base model with hidden dimensions (i.e. model width) to be 768 and the
number of transformer layers (i.e. model depth) to be 12. In this paper, we
revisit these conventional configurations. Through theoretical analysis and
experimental evaluation, we show that the masked autoencoder is effective in
alleviating the over-smoothing issue in deep transformer training. Based on
this finding, we propose Bamboo, an idea of using deeper and narrower
transformer configurations, for masked autoencoder training. On ImageNet, with
such a simple change in configuration, re-designed model achieves 87.1% top-1
accuracy and outperforms SoTA models like MAE and BEiT. On language tasks,
re-designed model outperforms BERT with default setting by 1.1 points on
average, on GLUE datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Long Tailed Document-Level Relation Extraction via Easy Relation Augmentation and Contrastive Learning. (arXiv:2205.10511v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10511">
<div class="article-summary-box-inner">
<span><p>Towards real-world information extraction scenario, research of relation
extraction is advancing to document-level relation extraction(DocRE). Existing
approaches for DocRE aim to extract relation by encoding various information
sources in the long context by novel model architectures. However, the inherent
long-tailed distribution problem of DocRE is overlooked by prior work. We argue
that mitigating the long-tailed distribution problem is crucial for DocRE in
the real-world scenario. Motivated by the long-tailed distribution problem, we
propose an Easy Relation Augmentation(ERA) method for improving DocRE by
enhancing the performance of tailed relations. In addition, we further propose
a novel contrastive learning framework based on our ERA, i.e., ERACL, which can
further improve the model performance on tailed relations and achieve
competitive overall DocRE performance compared to the state-of-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-training Data Quality and Quantity for a Low-Resource Language: New Corpus and BERT Models for Maltese. (arXiv:2205.10517v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10517">
<div class="article-summary-box-inner">
<span><p>Multilingual language models such as mBERT have seen impressive cross-lingual
transfer to a variety of languages, but many languages remain excluded from
these models. In this paper, we analyse the effect of pre-training with
monolingual data for a low-resource language that is not included in mBERT --
Maltese -- with a range of pre-training set ups. We conduct evaluations with
the newly pre-trained models on three morphosyntactic tasks -- dependency
parsing, part-of-speech tagging, and named-entity recognition -- and one
semantic classification task -- sentiment analysis. We also present a newly
created corpus for Maltese, and determine the effect that the pre-training data
size and domain have on the downstream performance. Our results show that using
a mixture of pre-training domains is often superior to using Wikipedia text
only. We also find that a fraction of this corpus is enough to make significant
leaps in performance over Wikipedia-trained models. We pre-train and compare
two models on the new corpus: a monolingual BERT model trained from scratch
(BERTu), and a further pre-trained multilingual BERT (mBERTu). The models
achieve state-of-the-art performance on these tasks, despite the new corpus
being considerably smaller than typically used corpora for high-resourced
languages. On average, BERTu outperforms or performs competitively with mBERTu,
and the largest gains are observed for higher-level tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CORAL: Contextual Response Retrievability Loss Function for Training Dialog Generation Models. (arXiv:2205.10558v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10558">
<div class="article-summary-box-inner">
<span><p>Natural Language Generation (NLG) represents a large collection of tasks in
the field of NLP. While many of these tasks have been tackled well by the
cross-entropy (CE) loss, the task of dialog generation poses a few unique
challenges for this loss function. First, CE loss assumes that for any given
input, the only possible output is the one available as the ground truth in the
training dataset. In general, this is not true for any task, as there can be
multiple semantically equivalent sentences, each with a different surface form.
This problem gets exaggerated further for the dialog generation task, as there
can be multiple valid responses (for a given context) that not only have
different surface forms but are also not semantically equivalent. Second, CE
loss does not take the context into consideration while processing the response
and, hence, it treats all ground truths with equal importance irrespective of
the context. But, we may want our final agent to avoid certain classes of
responses (e.g. bland, non-informative or biased responses) and give relatively
higher weightage for more context-specific responses. To circumvent these
shortcomings of the CE loss, in this paper, we propose a novel loss function,
CORAL, that directly optimizes recently proposed estimates of human preference
for generated responses. Using CORAL, we can train dialog generation models
without assuming non-existence of response other than the ground-truth. Also,
the CORAL loss is computed based on both the context and the response.
Extensive comparisons on two benchmark datasets show that the proposed methods
outperform strong state-of-the-art baseline models of different sizes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Sign Language Phoneme Clustering using HamNoSys Notation. (arXiv:2205.10560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10560">
<div class="article-summary-box-inner">
<span><p>Traditionally, sign language resources have been collected in controlled
settings for specific tasks involving supervised sign classification or
linguistic studies accompanied by specific annotation type. To date, very few
who explored signing videos found online on social media platforms as well as
the use of unsupervised methods applied to such resources. Due to the fact that
the field is striving to achieve acceptable model performance on the data that
differs from that seen during training calls for more diversity in sign
language data, stepping away from the data obtained in controlled laboratory
settings. Moreover, since the sign language data collection and annotation
carries large overheads, it is desirable to accelerate the annotation process.
Considering the aforementioned tendencies, this paper takes the side of
harvesting online data in a pursuit for automatically generating and annotating
sign language corpora through phoneme clustering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HLATR: Enhance Multi-stage Text Retrieval with Hybrid List Aware Transformer Reranking. (arXiv:2205.10569v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10569">
<div class="article-summary-box-inner">
<span><p>Deep pre-trained language models (e,g. BERT) are effective at large-scale
text retrieval task. Existing text retrieval systems with state-of-the-art
performance usually adopt a retrieve-then-reranking architecture due to the
high computational cost of pre-trained language models and the large corpus
size. Under such a multi-stage architecture, previous studies mainly focused on
optimizing single stage of the framework thus improving the overall retrieval
performance. However, how to directly couple multi-stage features for
optimization has not been well studied. In this paper, we design Hybrid List
Aware Transformer Reranking (HLATR) as a subsequent reranking module to
incorporate both retrieval and reranking stage features. HLATR is lightweight
and can be easily parallelized with existing text retrieval systems so that the
reranking process can be performed in a single yet efficient processing.
Empirical experiments on two large-scale text retrieval datasets show that
HLATR can efficiently improve the ranking performance of existing multi-stage
text retrieval methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-Autoregressive Neural Machine Translation: A Call for Clarity. (arXiv:2205.10577v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10577">
<div class="article-summary-box-inner">
<span><p>Non-autoregressive approaches aim to improve the inference speed of
translation models by only requiring a single forward pass to generate the
output sequence instead of iteratively producing each predicted token.
Consequently, their translation quality still tends to be inferior to their
autoregressive counterparts due to several issues involving output token
interdependence. In this work, we take a step back and revisit several
techniques that have been proposed for improving non-autoregressive translation
models and compare their combined translation quality and speed implications
under third-party testing environments. We provide novel insights for
establishing strong baselines using length prediction or CTC-based architecture
variants and contribute standardized BLEU, chrF++, and TER scores using
sacreBLEU on four translation tasks, which crucially have been missing as
inconsistencies in the use of tokenized BLEU lead to deviations of up to 1.7
BLEU points. Our open-sourced code is integrated into fairseq for
reproducibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibration of Natural Language Understanding Models with Venn--ABERS Predictors. (arXiv:2205.10586v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10586">
<div class="article-summary-box-inner">
<span><p>Transformers, currently the state-of-the-art in natural language
understanding (NLU) tasks, are prone to generate uncalibrated predictions or
extreme probabilities, making the process of taking different decisions based
on their output relatively difficult. In this paper we propose to build several
inductive Venn--ABERS predictors (IVAP), which are guaranteed to be well
calibrated under minimal assumptions, based on a selection of pre-trained
transformers. We test their performance over a set of diverse NLU tasks and
show that they are capable of producing well-calibrated probabilistic
predictions that are uniformly spread over the [0,1] interval -- all while
retaining the original model's predictive accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Natural Language Inference Generation with PDD: Prompt and Dynamic Demonstration. (arXiv:2205.10593v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10593">
<div class="article-summary-box-inner">
<span><p>Natural Language Inference Generation task is to generate a text hypothesis
given a text premise and a logical relation between the two. This task can be
used in data augmentation and controllable text generation in practice. In this
paper, we propose language models with prompt and dynamic demonstration
(LM-PDD) to tackle this problem in few-shot settings. Our framework outperforms
standard fine-tuned models with low resource, achieving an average 8% absolute
improvement on SNLI and MNLI datasets, and the results on 13 natural language
classification tasks also show that our dynamic demonstration method has good
generalizability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. (arXiv:2205.10625v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10625">
<div class="article-summary-box-inner">
<span><p>We propose a novel prompting strategy, least-to-most prompting, that enables
large language models to better perform multi-step reasoning tasks.
Least-to-most prompting first reduces a complex problem into a list of
subproblems, and then sequentially solves the subproblems, whereby solving a
given subproblem is facilitated by the model's answers to previously solved
subproblems. Experiments on symbolic manipulation, compositional generalization
and numerical reasoning demonstrate that least-to-most prompting can generalize
to examples that are harder than those seen in the prompt context,
outperforming other prompting-based approaches by a large margin. A notable
empirical result is that the GPT-3 code-davinci-002 model with
least-to-most-prompting can solve the SCAN benchmark with an accuracy of 99.7%
using 14 examples. As a comparison, the neural-symbolic models in the
literature specialized for solving SCAN are trained with the full training set
of more than 15,000 examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Speech Representation Learning: A Review. (arXiv:2205.10643v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10643">
<div class="article-summary-box-inner">
<span><p>Although supervised deep learning has revolutionized speech and audio
processing, it has necessitated the building of specialist models for
individual tasks and application scenarios. It is likewise difficult to apply
this to dialects and languages for which only limited labeled data is
available. Self-supervised representation learning methods promise a single
universal model that would benefit a wide variety of tasks and domains. Such
methods have shown success in natural language processing and computer vision
domains, achieving new levels of performance while reducing the number of
labels required for many downstream scenarios. Speech representation learning
is experiencing similar progress in three main categories: generative,
contrastive, and predictive methods. Other approaches rely on multi-modal data
for pre-training, mixing text or visual data streams with speech. Although
self-supervised speech representation is still a nascent research area, it is
closely related to acoustic word embedding and learning with zero lexical
resources, both of which have seen active research for many years. This review
presents approaches for self-supervised speech representation learning and
their connection to other research areas. Since many current methods focus
solely on automatic speech recognition as a downstream task, we review recent
efforts on benchmarking learned representations to extend the application
beyond speech recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context Matters for Image Descriptions for Accessibility: Challenges for Referenceless Evaluation Metrics. (arXiv:2205.10646v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10646">
<div class="article-summary-box-inner">
<span><p>Few images on the Web receive alt-text descriptions that would make them
accessible to blind and low vision (BLV) users. Image-based NLG systems have
progressed to the point where they can begin to address this persistent
societal problem, but these systems will not be fully successful unless we
evaluate them on metrics that guide their development correctly. Here, we argue
against current referenceless metrics -- those that don't rely on
human-generated ground-truth descriptions -- on the grounds that they do not
align with the needs of BLV users. The fundamental shortcoming of these metrics
is that they cannot take context into account, whereas contextual information
is highly valued by BLV users. To substantiate these claims, we present a study
with BLV participants who rated descriptions along a variety of dimensions. An
in-depth analysis reveals that the lack of context-awareness makes current
referenceless metrics inadequate for advancing image accessibility, requiring a
rethinking of referenceless evaluation metrics for image-based NLG systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Investigation of Commonsense Self-Supervision with Knowledge Graphs. (arXiv:2205.10661v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10661">
<div class="article-summary-box-inner">
<span><p>Self-supervision based on the information extracted from large knowledge
graphs has been shown to improve the generalization of language models, in
zero-shot evaluation on various downstream language reasoning tasks. Since
these improvements are reported in aggregate, however, little is known about
(i) how to select the appropriate knowledge for solid performance across tasks,
(ii) how to combine this knowledge with neural language models, and (iii) how
these pairings affect granular task performance. In this paper, we study the
effect of knowledge sampling strategies and sizes that can be used to generate
synthetic data for adapting language models. We study the effect of different
synthetic datasets on language models with various architectures and sizes. The
resulting models are evaluated against four task properties: domain overlap,
answer similarity, vocabulary overlap, and answer length. Our experiments show
that encoder-decoder models benefit from more data to learn from, whereas
sampling strategies that balance across different aspects yield best
performance. Most of the improvement occurs on questions with short answers and
dissimilar answer candidates, which corresponds to the characteristics of the
data used for pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Coreference Resolution for Dialogue Processing: Improving Mention-Linking on Real-Time Conversations. (arXiv:2205.10670v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10670">
<div class="article-summary-box-inner">
<span><p>This paper suggests a direction of coreference resolution for online decoding
on actively generated input such as dialogue, where the model accepts an
utterance and its past context, then finds mentions in the current utterance as
well as their referents, upon each dialogue turn. A baseline and four
incremental-updated models adapted from the mention-linking paradigm are
proposed for this new setting, which address different aspects including the
singletons, speaker-grounded encoding and cross-turn mention contextualization.
Our approach is assessed on three datasets: Friends, OntoNotes, and BOLT.
Results show that each aspect brings out steady improvement, and our best
models outperform the baseline by over 10%, presenting an effective system for
this setting. Further analysis highlights the task characteristics, such as the
significance of addressing the mention recall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Understanding. (arXiv:2205.10687v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10687">
<div class="article-summary-box-inner">
<span><p>There is a growing body of work in recent years to develop pre-trained
language models (PLMs) for the Arabic language. This work concerns addressing
two major problems in existing Arabic PLMs which constraint progress of the
Arabic NLU and NLG fields.First, existing Arabic PLMs are not well-explored and
their pre-trainig can be improved significantly using a more methodical
approach. Second, there is a lack of systematic and reproducible evaluation of
these models in the literature. In this work, we revisit both the pre-training
and evaluation of Arabic PLMs. In terms of pre-training, we explore improving
Arabic LMs from three perspectives: quality of the pre-training data, size of
the model, and incorporating character-level information. As a result, we
release three new Arabic BERT-style models ( JABER, Char-JABER, and SABER), and
two T5-style models (AT5S and AT5B). In terms of evaluation, we conduct a
comprehensive empirical study to systematically evaluate the performance of
existing state-of-the-art models on ALUE that is a leaderboard-powered
benchmark for Arabic NLU tasks, and on a subset of the ARGEN benchmark for
Arabic NLG tasks. We show that our models significantly outperform existing
Arabic PLMs and achieve a new state-of-the-art performance on discriminative
and generative Arabic NLU and NLG tasks. Our models and source code to
reproduce of results will be made available shortly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Life after BERT: What do Other Muppets Understand about Language?. (arXiv:2205.10696v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10696">
<div class="article-summary-box-inner">
<span><p>Existing pre-trained transformer analysis works usually focus only on one or
two model families at a time, overlooking the variability of the architecture
and pre-training objectives. In our work, we utilize the oLMpics benchmark and
psycholinguistic probing datasets for a diverse set of 29 models including T5,
BART, and ALBERT. Additionally, we adapt the oLMpics zero-shot setup for
autoregressive models and evaluate GPT networks of different sizes. Our
findings show that none of these models can resolve compositional questions in
a zero-shot fashion, suggesting that this skill is not learnable using existing
pre-training objectives. Furthermore, we find that global model decisions such
as architecture, directionality, size of the dataset, and pre-training
objective are not predictive of a model's linguistic capabilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phrase-level Textual Adversarial Attack with Label Preservation. (arXiv:2205.10710v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10710">
<div class="article-summary-box-inner">
<span><p>Generating high-quality textual adversarial examples is critical for
investigating the pitfalls of natural language processing (NLP) models and
further promoting their robustness. Existing attacks are usually realized
through word-level or sentence-level perturbations, which either limit the
perturbation space or sacrifice fluency and textual quality, both affecting the
attack effectiveness. In this paper, we propose Phrase-Level Textual
Adversarial aTtack (PLAT) that generates adversarial samples through
phrase-level perturbations. PLAT first extracts the vulnerable phrases as
attack targets by a syntactic parser, and then perturbs them by a pre-trained
blank-infilling model. Such flexible perturbation design substantially expands
the search space for more effective attacks without introducing too many
modifications, and meanwhile maintaining the textual fluency and grammaticality
via contextualized generation using surrounding texts. Moreover, we develop a
label-preservation filter leveraging the likelihoods of language models
fine-tuned on each class, rather than textual similarity, to rule out those
perturbations that potentially alter the original class label for humans.
Extensive experiments and human evaluation demonstrate that PLAT has a superior
attack effectiveness as well as a better label consistency than strong
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable Proof Generation via Iterative Backward Reasoning. (arXiv:2205.10714v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10714">
<div class="article-summary-box-inner">
<span><p>We present IBR, an Iterative Backward Reasoning model to solve the proof
generation tasks on rule-based Question Answering (QA), where models are
required to reason over a series of textual rules and facts to find out the
related proof path and derive the final answer. We handle the limitations of
existed works in two folds: 1) enhance the interpretability of reasoning
procedures with detailed tracking, by predicting nodes and edges in the proof
path iteratively backward from the question; 2) promote the efficiency and
accuracy via reasoning on the elaborate representations of nodes and history
paths, without any intermediate texts that may introduce external noise during
proof generation. There are three main modules in IBR, QA and proof strategy
prediction to obtain the answer and offer guidance for the following procedure;
parent node prediction to determine a node in the existing proof that a new
child node will link to; child node prediction to find out which new node will
be added to the proof. Experiments on both synthetic and paraphrased datasets
demonstrate that IBR has better in-domain performance as well as cross-domain
transferability than several strong baselines. Our code and models are
available at https://github.com/find-knowledge/IBR .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TWEET-FID: An Annotated Dataset for Multiple Foodborne Illness Detection Tasks. (arXiv:2205.10726v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10726">
<div class="article-summary-box-inner">
<span><p>Foodborne illness is a serious but preventable public health problem -- with
delays in detecting the associated outbreaks resulting in productivity loss,
expensive recalls, public safety hazards, and even loss of life. While social
media is a promising source for identifying unreported foodborne illnesses,
there is a dearth of labeled datasets for developing effective outbreak
detection models. To accelerate the development of machine learning-based
models for foodborne outbreak detection, we thus present TWEET-FID
(TWEET-Foodborne Illness Detection), the first publicly available annotated
dataset for multiple foodborne illness incident detection tasks. TWEET-FID
collected from Twitter is annotated with three facets: tweet class, entity
type, and slot type, with labels produced by experts as well as by crowdsource
workers. We introduce several domain tasks leveraging these three facets: text
relevance classification (TRC), entity mention detection (EMD), and slot
filling (SF). We describe the end-to-end methodology for dataset design,
creation, and labeling for supporting model development for these tasks. A
comprehensive set of results for these tasks leveraging state-of-the-art
single- and multi-task deep learning methods on the TWEET-FID dataset are
provided. This dataset opens opportunities for future research in foodborne
outbreak detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">All Birds with One Stone: Multi-task Text Classification for Efficient Inference with One Forward Pass. (arXiv:2205.10744v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10744">
<div class="article-summary-box-inner">
<span><p>Multi-Task Learning (MTL) models have shown their robustness, effectiveness,
and efficiency for transferring learned knowledge across tasks. In real
industrial applications such as web content classification, multiple
classification tasks are predicted from the same input text such as a web
article. However, at the serving time, the existing multitask transformer
models such as prompt or adaptor based approaches need to conduct N forward
passes for N tasks with O(N) computation cost. To tackle this problem, we
propose a scalable method that can achieve stronger performance with close to
O(1) computation cost via only one forward pass. To illustrate real application
usage, we release a multitask dataset on news topic and style classification.
Our experiments show that our proposed method outperforms strong baselines on
both the GLUE benchmark and our news dataset. Our code and dataset are publicly
available at https://bit.ly/mtop-code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How sensitive are translation systems to extra contexts? Mitigating gender bias in Neural Machine Translation models through relevant contexts. (arXiv:2205.10762v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10762">
<div class="article-summary-box-inner">
<span><p>Neural Machine Translation systems built on top of Transformer-based
architectures are routinely improving the state-of-the-art in translation
quality according to word-overlap metrics. However, a growing number of studies
also highlight the inherent gender bias that these models incorporate during
training, which reflects poorly in their translations. In this work, we
investigate whether these models can be instructed to fix their bias during
inference using targeted, guided instructions as contexts. By translating
relevant contextual sentences during inference along with the input, we observe
large improvements in reducing the gender bias in translations, across three
popular test suites (WinoMT, BUG, SimpleGen). We further propose a novel metric
to assess several large pretrained models (OPUS-MT, M2M-100) on their
sensitivity towards using contexts during translation to correct their biases.
Our approach requires no fine-tuning, and thus can be used easily in production
systems to de-bias translations from stereotypical gender-occupation bias. We
hope our method, along with our metric, can be used to build better, bias-free
translation systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evidence for Hypodescent in Visual Semantic AI. (arXiv:2205.10764v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10764">
<div class="article-summary-box-inner">
<span><p>We examine the state-of-the-art multimodal "visual semantic" model CLIP
("Contrastive Language Image Pretraining") for the rule of hypodescent, or
one-drop rule, whereby multiracial people are more likely to be assigned a
racial or ethnic label corresponding to a minority or disadvantaged racial or
ethnic group than to the equivalent majority or advantaged group. A face
morphing experiment grounded in psychological research demonstrating
hypodescent indicates that, at the midway point of 1,000 series of morphed
images, CLIP associates 69.7% of Black-White female images with a Black text
label over a White text label, and similarly prefers Latina (75.8%) and Asian
(89.1%) text labels at the midway point for Latina-White female and Asian-White
female morphs, reflecting hypodescent. Additionally, assessment of the
underlying cosine similarities in the model reveals that association with White
is correlated with association with "person," with Pearson's rho as high as
0.82 over a 21,000-image morph series, indicating that a White person
corresponds to the default representation of a person in CLIP. Finally, we show
that the stereotype-congruent pleasantness association of an image correlates
with association with the Black text label in CLIP, with Pearson's rho = 0.48
for 21,000 Black-White multiracial male images, and rho = 0.41 for Black-White
multiracial female images. CLIP is trained on English-language text gathered
using data collected from an American website (Wikipedia), and our findings
demonstrate that CLIP embeds the values of American racial hierarchy,
reflecting the implicit and explicit beliefs that are present in human minds.
We contextualize these findings within the history and psychology of
hypodescent. Overall, the data suggests that AI supervised using natural
language will, unless checked, learn biases that reflect racial hierarchies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. (arXiv:2205.10770v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10770">
<div class="article-summary-box-inner">
<span><p>Despite their wide adoption, the underlying training and memorization
dynamics of very large language models is not well understood. We empirically
study exact memorization in causal and masked language modeling, across model
sizes and throughout the training process. We measure the effects of dataset
size, learning rate, and model size on memorization, finding that larger
language models memorize training data faster across all settings.
Surprisingly, we show that larger models can memorize a larger portion of the
data before over-fitting and tend to forget less throughout the training
process. We also analyze the memorization dynamics of different parts of speech
and find that models memorize nouns and numbers first; we hypothesize and
provide empirical evidence that nouns and numbers act as a unique identifier
for memorizing individual training examples. Together, these findings present
another piece of the broader puzzle of trying to understand what actually
improves as models get bigger.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Domain-adaptive Pre-training Approach for Language Bias Detection in News. (arXiv:2205.10773v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10773">
<div class="article-summary-box-inner">
<span><p>Media bias is a multi-faceted construct influencing individual behavior and
collective decision-making. Slanted news reporting is the result of one-sided
and polarized writing which can occur in various forms. In this work, we focus
on an important form of media bias, i.e. bias by word choice. Detecting biased
word choices is a challenging task due to its linguistic complexity and the
lack of representative gold-standard corpora. We present DA-RoBERTa, a new
state-of-the-art transformer-based model adapted to the media bias domain which
identifies sentence-level bias with an F1 score of 0.814. In addition, we also
train, DA-BERT and DA-BART, two more transformer models adapted to the bias
domain. Our proposed domain-adapted models outperform prior bias detection
approaches on the same data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instruction Induction: From Few Examples to Natural Language Task Descriptions. (arXiv:2205.10782v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10782">
<div class="article-summary-box-inner">
<span><p>Large language models are able to perform a task by conditioning on a few
input-output demonstrations - a paradigm known as in-context learning. We show
that language models can explicitly infer an underlying task from a few
demonstrations by prompting them to generate a natural language instruction
that fits the examples. To explore this ability, we introduce the instruction
induction challenge, compile a dataset consisting of 24 tasks, and define a
novel evaluation metric based on executing the generated instruction. We
discover that, to a large extent, the ability to generate instructions does
indeed emerge when using a model that is both large enough and aligned to
follow instructions; InstructGPT achieves 65.7% of human performance in our
execution-based metric, while the original GPT-3 model reaches only 9.8% of
human performance. This surprising result suggests that instruction induction
might be a viable learning paradigm in and of itself, where instead of fitting
a set of latent continuous parameters to the data, one searches for the best
description in the natural language hypothesis space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Graph Enhanced BERT Model for Event Prediction. (arXiv:2205.10822v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10822">
<div class="article-summary-box-inner">
<span><p>Predicting the subsequent event for an existing event context is an important
but challenging task, as it requires understanding the underlying relationship
between events. Previous methods propose to retrieve relational features from
event graph to enhance the modeling of event correlation. However, the sparsity
of event graph may restrict the acquisition of relevant graph information, and
hence influence the model performance. To address this issue, we consider
automatically building of event graph using a BERT model. To this end, we
incorporate an additional structured variable into BERT to learn to predict the
event connections in the training process. Hence, in the test process, the
connection relationship for unseen events can be predicted by the structured
variable. Results on two event prediction tasks: script event prediction and
story ending prediction, show that our approach can outperform state-of-the-art
baseline methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Do Compressed Multilingual Machine Translation Models Forget?. (arXiv:2205.10828v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10828">
<div class="article-summary-box-inner">
<span><p>Recently, very large pre-trained models achieve state-of-the-art results in
various natural language processing (NLP) tasks, but their size makes it more
challenging to apply them in resource-constrained environments. Compression
techniques allow to drastically reduce the size of the model and therefore its
inference time with negligible impact on top-tier metrics. However, the general
performance hides a drastic performance drop on under-represented features,
which could result in the amplification of biases encoded by the model. In this
work, we analyze the impacts of compression methods on Multilingual Neural
Machine Translation models (MNMT) for various language groups and semantic
features by extensive analysis of compressed models on different NMT
benchmarks, e.g. FLORES-101, MT-Gender, and DiBiMT. Our experiments show that
the performance of under-represented languages drops significantly, while the
average BLEU metric slightly decreases. Interestingly, the removal of noisy
memorization with the compression leads to a significant improvement for some
medium-resource languages. Finally, we demonstrate that the compression
amplifies intrinsic gender and semantic biases, even in high-resource
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Machine Translation with Hyper-Adapters. (arXiv:2205.10835v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10835">
<div class="article-summary-box-inner">
<span><p>Multilingual machine translation suffers from negative interference across
languages. A common solution is to relax parameter sharing with
language-specific modules like adapters. However, adapters of related languages
are unable to transfer information, and their total number of parameters
becomes prohibitively expensive as the number of languages grows. In this work,
we overcome these drawbacks using hyper-adapters -- hyper-networks that
generate adapters from language and layer embeddings. While past work had poor
results when scaling hyper-networks, we propose a rescaling fix that
significantly improves convergence and enables training larger hyper-networks.
We find that hyper-adapters are more parameter efficient than regular adapters,
reaching the same performance with up to 12 times less parameters. When using
the same number of parameters and FLOPS, our approach consistently outperforms
regular adapters. Also, hyper-adapters converge faster than alternative
approaches and scale better than regular dense networks. Our analysis shows
that hyper-adapters learn to encode language relatedness, enabling positive
transfer across languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain Detection. (arXiv:2101.03778v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03778">
<div class="article-summary-box-inner">
<span><p>Real-life applications, heavily relying on machine learning, such as dialog
systems, demand out-of-domain detection methods. Intent classification models
should be equipped with a mechanism to distinguish seen intents from unseen
ones so that the dialog agent is capable of rejecting the latter and avoiding
undesired behavior. However, despite increasing attention paid to the task, the
best practices for out-of-domain intent detection have not yet been fully
established.
</p>
<p>This paper conducts a thorough comparison of out-of-domain intent detection
methods. We prioritize the methods, not requiring access to out-of-domain data
during training, gathering of which is extremely time- and labor-consuming due
to lexical and stylistic variation of user utterances. We evaluate multiple
contextual encoders and methods, proven to be efficient, on three standard
datasets for intent classification, expanded with out-of-domain utterances. Our
main findings show that fine-tuning Transformer-based encoders on in-domain
data leads to superior results. Mahalanobis distance, together with utterance
representations, derived from Transformer-based encoders, outperforms other
methods by a wide margin and establishes new state-of-the-art results for all
datasets.
</p>
<p>The broader analysis shows that the reason for success lies in the fact that
the fine-tuned Transformer is capable of constructing homogeneous
representations of in-domain utterances, revealing geometrical disparity to out
of domain utterances. In turn, the Mahalanobis distance captures this disparity
easily.
</p>
<p>The code is available in our GitHub repo:
https://github.com/huawei-noah/noah-research/tree/master/Maha_OOD .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Structured Feature Networks for Table Detection and Tabular Data Extraction from Scanned Financial Document Images. (arXiv:2102.10287v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10287">
<div class="article-summary-box-inner">
<span><p>Automatic table detection in PDF documents has achieved a great success but
tabular data extraction are still challenging due to the integrity and noise
issues in detected table areas. The accurate data extraction is extremely
crucial in finance area. Inspired by this, the aim of this research is
proposing an automated table detection and tabular data extraction from
financial PDF documents. We proposed a method that consists of three main
processes, which are detecting table areas with a Faster R-CNN (Region-based
Convolutional Neural Network) model with Feature Pyramid Network (FPN) on each
page image, extracting contents and structures by a compounded layout
segmentation technique based on optical character recognition (OCR) and
formulating regular expression rules for table header separation. The tabular
data extraction feature is embedded with rule-based filtering and restructuring
functions that are highly scalable. We annotate a new Financial Documents
dataset with table regions for the experiment. The excellent table detection
performance of the detection model is obtained from our customized dataset. The
main contributions of this paper are proposing the Financial Documents dataset
with table-area annotations, the superior detection model and the rule-based
layout segmentation technique for the tabular data extraction from PDF files.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LiGCN: Label-interpretable Graph Convolutional Networks for Multi-label Text Classification. (arXiv:2103.14620v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14620">
<div class="article-summary-box-inner">
<span><p>Multi-label text classification (MLTC) is an attractive and challenging task
in natural language processing (NLP). Compared with single-label text
classification, MLTC has a wider range of applications in practice. In this
paper, we propose a label-interpretable graph convolutional network model to
solve the MLTC problem by modeling tokens and labels as nodes in a
heterogeneous graph. In this way, we are able to take into account multiple
relationships including token-level relationships. Besides, the model allows
better interpretability for predicted labels as the token-label edges are
exposed. We evaluate our method on four real-world datasets and it achieves
competitive scores against selected baseline methods. Specifically, this model
achieves a gain of 0.14 on the F1 score in the small label set MLTC, and 0.07
in the large label set scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Schema Curation via Causal Association Rule Mining. (arXiv:2104.08811v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08811">
<div class="article-summary-box-inner">
<span><p>Event schemas are structured knowledge sources defining typical real-world
scenarios (e.g., going to an airport). We present a framework for efficient
human-in-the-loop construction of a schema library, based on a novel script
induction system and a well-crafted interface that allows non-experts to
"program" complex event structures. Associated with this work we release a
schema library: a machine readable resource of 232 detailed event schemas, each
of which describe a distinct typical scenario in terms of its relevant
sub-event structure (what happens in the scenario), participants (who plays a
role in the scenario), fine-grained typing of each participant, and the implied
relational constraints between them. We make our schema library and the
SchemaBlocks interface available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dependency Parsing as MRC-based Span-Span Prediction. (arXiv:2105.07654v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07654">
<div class="article-summary-box-inner">
<span><p>Higher-order methods for dependency parsing can partially but not fully
address the issue that edges in dependency trees should be constructed at the
text span/subtree level rather than word level. In this paper, we propose a new
method for dependency parsing to address this issue. The proposed method
constructs dependency trees by directly modeling span-span (in other words,
subtree-subtree) relations. It consists of two modules: the {\it text span
proposal module} which proposes candidate text spans, each of which represents
a subtree in the dependency tree denoted by (root, start, end); and the {\it
span linking module}, which constructs links between proposed spans. We use the
machine reading comprehension (MRC) framework as the backbone to formalize the
span linking module, where one span is used as a query to extract the text
span/subtree it should be linked to. The proposed method has the following
merits: (1) it addresses the fundamental problem that edges in a dependency
tree should be constructed between subtrees; (2) the MRC framework allows the
method to retrieve missing spans in the span proposal stage, which leads to
higher recall for eligible spans. Extensive experiments on the PTB, CTB and
Universal Dependencies (UD) benchmarks demonstrate the effectiveness of the
proposed method. The code is available at
\url{https://github.com/ShannonAI/mrc-for-dependency-parsing}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conscious AI. (arXiv:2105.07879v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07879">
<div class="article-summary-box-inner">
<span><p>Recent advances in artificial intelligence (AI) have achieved human-scale
speed and accuracy for classification tasks. In turn, these capabilities have
made AI a viable replacement for many human activities that at their core
involve classification, such as basic mechanical and analytical tasks in
low-level service jobs. Current systems do not need to be conscious to
recognize patterns and classify them. However, for AI to progress to more
complicated tasks requiring intuition and empathy, it must develop capabilities
such as metathinking, creativity, and empathy akin to human self-awareness or
consciousness. We contend that such a paradigm shift is possible only through a
fundamental shift in the state of artificial intelligence toward consciousness,
a shift similar to what took place for humans through the process of natural
selection and evolution. As such, this paper aims to theoretically explore the
requirements for the emergence of consciousness in AI. It also provides a
principled understanding of how conscious AI can be detected and how it might
be manifested in contrast to the dominant paradigm that seeks to ultimately
create machines that are linguistically indistinguishable from humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEAP: Learnable Pruning for Transformer-based Models. (arXiv:2105.14636v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14636">
<div class="article-summary-box-inner">
<span><p>Pruning is an effective method to reduce the memory footprint and
computational cost associated with large natural language processing models.
However, current pruning algorithms either only focus on one pruning category,
e.g., structured pruning and unstructured, or need extensive hyperparameter
tuning in order to get reasonable accuracy performance. To address these
challenges, we propose LEArnable Pruning (LEAP), an effective method to
gradually prune the model based on thresholds learned by gradient descent.
Different than previous learnable pruning methods, which utilize $L_0$ or $L_1$
penalty to indirectly affect the final pruning ratio, LEAP introduces a novel
regularization function, that directly interacts with the preset target pruning
ratio. Moreover, in order to reduce hyperparameter tuning, a novel adaptive
regularization coefficient is deployed to control the regularization penalty
adaptively. With the new regularization term and its associated adaptive
regularization coefficient, LEAP is able to be applied for different pruning
granularity, including unstructured pruning, structured pruning, and hybrid
pruning, with minimal hyperparameter tuning. We apply LEAP for BERT models on
QQP/MNLI/SQuAD for different pruning settings. Our result shows that for all
datasets, pruning granularity, and pruning ratios, LEAP achieves on-par or
better results as compared to previous heavily hand-tuned methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WALNUT: A Benchmark on Semi-weakly Supervised Learning for Natural Language Understanding. (arXiv:2108.12603v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12603">
<div class="article-summary-box-inner">
<span><p>Building machine learning models for natural language understanding (NLU)
tasks relies heavily on labeled data. Weak supervision has been proven valuable
when large amount of labeled data is unavailable or expensive to obtain.
Existing works studying weak supervision for NLU either mostly focus on a
specific task or simulate weak supervision signals from ground-truth labels. It
is thus hard to compare different approaches and evaluate the benefit of weak
supervision without access to a unified and systematic benchmark with diverse
tasks and real-world weak labeling rules. In this paper, we propose such a
benchmark, named WALNUT (semi-WeAkly supervised Learning for Natural language
Understanding Testbed), to advocate and facilitate research on weak supervision
for NLU. WALNUT consists of NLU tasks with different types, including
document-level and token-level prediction tasks. WALNUT is the first
semi-weakly supervised learning benchmark for NLU, where each task contains
weak labels generated by multiple real-world weak sources, together with a
small set of clean labels. We conduct baseline evaluations on WALNUT to
systematically evaluate the effectiveness of various weak supervision methods
and model architectures. Our results demonstrate the benefit of weak
supervision for low-resource NLU tasks and highlight interesting patterns
across tasks. We expect WALNUT to stimulate further research on methodologies
to leverage weak supervision more effectively. The benchmark and code for
baselines are available at \url{aka.ms/walnut_benchmark}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">So Cloze yet so Far: N400 Amplitude is Better Predicted by Distributional Information than Human Predictability Judgements. (arXiv:2109.01226v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01226">
<div class="article-summary-box-inner">
<span><p>More predictable words are easier to process - they are read faster and
elicit smaller neural signals associated with processing difficulty, most
notably, the N400 component of the event-related brain potential. Thus, it has
been argued that prediction of upcoming words is a key component of language
comprehension, and that studying the amplitude of the N400 is a valuable way to
investigate the predictions we make. In this study, we investigate whether the
linguistic predictions of computational language models or humans better
reflect the way in which natural language stimuli modulate the amplitude of the
N400. One important difference in the linguistic predictions of humans versus
computational language models is that while language models base their
predictions exclusively on the preceding linguistic context, humans may rely on
other factors. We find that the predictions of three top-of-the-line
contemporary language models - GPT-3, RoBERTa, and ALBERT - match the N400 more
closely than human predictions. This suggests that the predictive processes
underlying the N400 may be more sensitive to the surface-level statistics of
language than previously thought.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification. (arXiv:2109.07319v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07319">
<div class="article-summary-box-inner">
<span><p>Automatic annotation of short-text data to a large number of target labels,
referred to as Short Text Extreme Classification, has found numerous
applications including prediction of related searches and product
recommendation tasks. In this paper, we propose a convolutional architecture
InceptionXML which is light-weight, yet powerful, and robust to the inherent
lack of word-order in short-text queries encountered in search and
recommendation tasks. We demonstrate the efficacy of applying convolutions by
recasting the operation along the embedding dimension instead of the word
dimension as applied in conventional CNNs for text classification. Towards
scaling our model to datasets with millions of labels, we also propose
InceptionXML+ framework which improves upon the shortcomings of the recently
proposed dynamic hard-negative mining technique for label shortlisting by
synchronizing the label-shortlister and extreme classifier. InceptionXML+ not
only reduces the inference time to half but is also an order of magnitude
smaller than previous state-of-the-art Astec in terms of model size. Through
our proposed models, we outperform all existing approaches on popular benchmark
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Spread of Propaganda by Coordinated Communities on Social Media. (arXiv:2109.13046v3 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13046">
<div class="article-summary-box-inner">
<span><p>Large-scale manipulations on social media have two important characteristics:
(i) use of propaganda to influence others, and (ii) adoption of coordinated
behavior to spread it and to amplify its impact. Despite the connection between
them, these two characteristics have so far been considered in isolation. Here
we aim to bridge this gap. In particular, we analyze the spread of propaganda
and its interplay with coordinated behavior on a large Twitter dataset about
the 2019 UK general election. We first propose and evaluate several metrics for
measuring the use of propaganda on Twitter. Then, we investigate the use of
propaganda by different coordinated communities that participated in the online
debate. The combination of the use of propaganda and coordinated behavior
allows us to uncover the authenticity and harmfulness of the different
communities. Finally, we compare our measures of propaganda and coordination
with automation (i.e., bot) scores and Twitter suspensions, revealing
interesting trends. From a theoretical viewpoint, we introduce a methodology
for analyzing several important dimensions of online behavior that are seldom
conjointly considered. From a practical viewpoint, we provide new insights into
authentic and inauthentic online activities during the 2019 UK general
election.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Lingual GenQA: Open-Domain Question Answering with Answer Sentence Generation. (arXiv:2110.07150v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07150">
<div class="article-summary-box-inner">
<span><p>Recent approaches for question answering systems have achieved impressive
performance on English by combining document-level retrieval with answer
generation. These approaches, which we refer to as GenQA, are able to generate
full sentences, effectively answering both factoid and non-factoid questions.
In this paper, we extend GenQA beyond English and present the first
Cross-Lingual answer sentence generation system (CrossGenQA). Our system
produces natural, full-sentence answers to questions in several languages by
exploiting passages written in multiple other languages. To foster further
development on this topic, we introduce GenTyDiQA, an extension of the TyDiQA
dataset with well-formed and complete answers for Arabic, Bengali, English,
Japanese, and Russian questions. Using GenTyDiQA, we show that multi-language
models outperform monolingual GenQA in the four non-English languages; for
three of them, our CrossGenQA system achieves the best results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge of Pre-trained Language Models. (arXiv:2110.08173v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08173">
<div class="article-summary-box-inner">
<span><p>Knowledge probing is crucial for understanding the knowledge transfer
mechanism behind the pre-trained language models (PLMs). Despite the growing
progress of probing knowledge for PLMs in the general domain, specialised areas
such as biomedical domain are vastly under-explored. To catalyse the research
in this direction, we release a well-curated biomedical knowledge probing
benchmark, MedLAMA, which is constructed based on the Unified Medical Language
System (UMLS) Metathesaurus. We test a wide spectrum of state-of-the-art PLMs
and probing approaches on our benchmark, reaching at most 3% of acc@10. While
highlighting various sources of domain-specific challenges that amount to this
underwhelming performance, we illustrate that the underlying PLMs have a higher
potential for probing tasks. To achieve this, we propose Contrastive-Probe, a
novel self-supervised contrastive probing approach, that adjusts the underlying
PLMs without using any probing data. While Contrastive-Probe pushes the acc@10
to 28%, the performance gap still remains notable. Our human expert evaluation
suggests that the probing performance of our Contrastive-Probe is still
under-estimated as UMLS still does not include the full spectrum of factual
knowledge. We hope MedLAMA and Contrastive-Probe facilitate further
developments of more suited probing techniques for this domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DS-TOD: Efficient Domain Specialization for Task Oriented Dialog. (arXiv:2110.08395v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08395">
<div class="article-summary-box-inner">
<span><p>Recent work has shown that self-supervised dialog-specific pretraining on
large conversational datasets yields substantial gains over traditional
language modeling (LM) pretraining in downstream task-oriented dialog (TOD).
These approaches, however, exploit general dialogic corpora (e.g., Reddit) and
thus presumably fail to reliably embed domain-specific knowledge useful for
concrete downstream TOD domains. In this work, we investigate the effects of
domain specialization of pretrained language models (PLMs) for TOD. Within our
DS-TOD framework, we first automatically extract salient domain-specific terms,
and then use them to construct DomainCC and DomainReddit -- resources that we
leverage for domain-specific pretraining, based on (i) masked language modeling
(MLM) and (ii) response selection (RS) objectives, respectively. We further
propose a resource-efficient and modular domain specialization by means of
domain adapters -- additional parameter-light layers in which we encode the
domain knowledge. Our experiments with prominent TOD tasks -- dialog state
tracking (DST) and response retrieval (RR) -- encompassing five domains from
the MultiWOZ benchmark demonstrate the effectiveness of DS-TOD. Moreover, we
show that the light-weight adapter-based specialization (1) performs comparably
to full fine-tuning in single domain setups and (2) is particularly suitable
for multi-domain specialization, where besides advantageous computational
footprint, it can offer better TOD performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Double Trouble: How to not explain a text classifier's decisions using counterfactuals synthesized by masked language models?. (arXiv:2110.11929v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11929">
<div class="article-summary-box-inner">
<span><p>A principle behind dozens of attribution methods is to take the prediction
difference between before-and-after an input feature (here, a token) is removed
as its attribution. A popular Input Marginalization (IM) method (Kim et al.,
2020) uses BERT to replace a token, yielding more plausible counterfactuals.
While Kim et al. (2020) reported that IM is effective, we find this conclusion
not convincing as the DeletionBERT metric used in their paper is biased towards
IM. Importantly, this bias exists in Deletion-based metrics, including
Insertion, Sufficiency, and Comprehensiveness. Furthermore, our rigorous
evaluation using 6 metrics and 3 datasets finds no evidence that IM is better
than a Leave-One-Out (LOO) baseline. We find two reasons why IM is not better
than LOO: (1) deleting a single word from the input only marginally reduces a
classifier's accuracy; and (2) a highly predictable word is always given
near-zero attribution, regardless of its true importance to the classifier. In
contrast, making LIME samples more natural via BERT consistently improves LIME
accuracy under several ROAR metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pay attention to emoji: Feature Fusion Network with EmoGraph2vec Model for Sentiment Analysis. (arXiv:2110.14636v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14636">
<div class="article-summary-box-inner">
<span><p>With the explosive growth of social media, opinionated postings with emojis
have increased explosively. Many emojis are used to express emotions,
attitudes, and opinions. Emoji representation learning can be helpful to
improve the performance of emoji-related natural language processing tasks,
especially in text sentiment analysis. However, most studies have only utilized
the fixed descriptions provided by the Unicode Consortium without consideration
of actual usage scenarios. As for the sentiment analysis task, many researchers
ignore the emotional impact of the interaction between text and emojis. It
results that the emotional semantics of emojis cannot be fully explored. In
this work, we propose a method called EmoGraph2vec to learn emoji
representations by constructing a co-occurrence graph network from social data
and enriching the semantic information based on an external knowledge base
EmojiNet to embed emoji nodes. Based on EmoGraph2vec model, we design a novel
neural network to incorporate text and emoji information into sentiment
analysis, which uses a hybrid-attention module combined with TextCNN-based
classifier to improve performance. Experimental results show that the proposed
model can outperform several baselines for sentiment analysis on benchmark
datasets. Additionally, we conduct a series of ablation and comparison
experiments to investigate the effectiveness and interpretability of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discourse-Aware Soft Prompting for Text Generation. (arXiv:2112.05717v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.05717">
<div class="article-summary-box-inner">
<span><p>Current efficient fine-tuning methods (e.g., adapters, prefix-tuning, etc.)
have optimized conditional text generation via training a small set of extra
parameters of the neural language model, while freezing the rest for
efficiency. While showing strong performance on some generation tasks, they
don't generalize across all generation tasks. We show that soft-prompt based
conditional text generation can be improved with simple and efficient methods
that simulate modeling the discourse structure of human written text. We
investigate two design choices: First, we apply \textit{hierarchical blocking}
on the prefix parameters to simulate a higher-level discourse structure of
human written text. Second, we apply \textit{attention sparsity} on the prefix
parameters at different layers of the network and learn sparse transformations
on the softmax-function. We show that structured design of prefix parameters
yields more coherent, faithful and relevant generations than the baseline
prefix-tuning on all generation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards More Efficient Insertion Transformer with Fractional Positional Encoding. (arXiv:2112.06295v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06295">
<div class="article-summary-box-inner">
<span><p>Auto-regressive neural sequence models have been shown to be effective across
text generation tasks. However, their left-to-right decoding order prevents
generation from being parallelized. Insertion Transformer (Stern et al., 2019)
is an attractive alternative that allows outputting multiple tokens in a single
generation step. Nevertheless, due to the incompatibility between absolute
positional encoding and insertion-based generation schemes, it needs to refresh
the encoding of every token in the generated partial hypothesis at each step,
which could be costly. We design a novel reusable positional encoding scheme
for insertion transformers called Fractional Positional Encoding (FPE), which
allows reusing representations calculated in previous steps. Empirical studies
on various text generation tasks demonstrate the effectiveness of FPE, which
leads to floating-point operation reduction and latency improvements on batched
decoding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conversational Search with Mixed-Initiative -- Asking Good Clarification Questions backed-up by Passage Retrieval. (arXiv:2112.07308v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07308">
<div class="article-summary-box-inner">
<span><p>We deal with the scenario of conversational search, where user queries are
under-specified or ambiguous. This calls for a mixed-initiative setup.
User-asks (queries) and system-answers, as well as system-asks (clarification
questions) and user response, in order to clarify her information needs. We
focus on the task of selecting the next clarification question, given the
conversation context. Our method leverages passage retrieval from a background
content to fine-tune two deep-learning models for ranking candidate
clarification questions. We evaluated our method on two different use-cases.
The first is an open domain conversational search in a large web collection.
The second is a task-oriented customer-support setup. We show that our method
performs well on both use-cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Rich Self-Supervision for Biomedical Entity Linking. (arXiv:2112.07887v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07887">
<div class="article-summary-box-inner">
<span><p>Entity linking faces significant challenges such as prolific variations and
prevalent ambiguities, especially in high-value domains with myriad entities.
Standard classification approaches suffer from the annotation bottleneck and
cannot effectively handle unseen entities. Zero-shot entity linking has emerged
as a promising direction for generalizing to new entities, but it still
requires example gold entity mentions during training and canonical
descriptions for all entities, both of which are rarely available outside of
Wikipedia. In this paper, we explore Knowledge-RIch Self-Supervision ($\tt
KRISS$) for biomedical entity linking, by leveraging readily available domain
knowledge. In training, it generates self-supervised mention examples on
unlabeled text using a domain ontology and trains a contextual encoder using
contrastive learning. For inference, it samples self-supervised mentions as
prototypes for each entity and conducts linking by mapping the test mention to
the most similar prototype. Our approach can easily incorporate entity
descriptions and gold mention labels if available. We conducted extensive
experiments on seven standard datasets spanning biomedical literature and
clinical notes. Without using any labeled information, our method produces $\tt
KRISSBERT$, a universal entity linker for four million UMLS entities that
attains new state of the art, outperforming prior self-supervised methods by as
much as 20 absolute points in accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLIN-X: pre-trained language models and a study on cross-task transfer for concept extraction in the clinical domain. (arXiv:2112.08754v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08754">
<div class="article-summary-box-inner">
<span><p>The field of natural language processing (NLP) has recently seen a large
change towards using pre-trained language models for solving almost any task.
Despite showing great improvements in benchmark datasets for various tasks,
these models often perform sub-optimal in non-standard domains like the
clinical domain where a large gap between pre-training documents and target
documents is observed. In this paper, we aim at closing this gap with
domain-specific training of the language model and we investigate its effect on
a diverse set of downstream tasks and settings. We introduce the pre-trained
CLIN-X (Clinical XLM-R) language models and show how CLIN-X outperforms other
pre-trained transformer models by a large margin for ten clinical concept
extraction tasks from two languages. In addition, we demonstrate how the
transformer model can be further improved with our proposed task- and
language-agnostic model architecture based on ensembles over random splits and
cross-sentence context. Our studies in low-resource and transfer settings
reveal stable model performance despite a lack of annotated data with
improvements of up to 47 F1 points when only 250 labeled sentences are
available. Our results highlight the importance of specialized language models
as CLIN-X for concept extraction in non-standard domains, but also show that
our task-agnostic model architecture is robust across the tested tasks and
languages so that domain- or task-specific adaptations are not required.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEMON: Language-Based Environment Manipulation via Execution-Guided Pre-training. (arXiv:2201.08081v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08081">
<div class="article-summary-box-inner">
<span><p>Language-based environment manipulation requires agents to manipulate the
environment following natural language instructions, which is challenging due
to the huge space of the environments. To address this challenge, various
approaches have been proposed in recent work. Although these approaches work
well for their intended environments, they are difficult to generalize across
environments. In this work, we propose LEMON, a general framework for
language-based environment manipulation tasks. Specifically, we first specify a
general approach for language-based environment manipulation tasks, which can
deal with various environments using the same generative language model. Then
we propose an execution-guided pre-training strategy to inject prior knowledge
of environments to the language model with a pure synthetic pre-training
corpus. Experimental results on tasks including Alchemy, Scene, Tangrams,
ProPara and Recipes demonstrate the effectiveness of LEMON: it achieves new
state-of-the-art results on Alchemy, Scene, ProPara, and Recipes, and the
execution-guided pre-training strategy brings remarkable improvements on all
experimental tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Student Knows All Experts Know: From Sparse to Dense. (arXiv:2201.10890v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10890">
<div class="article-summary-box-inner">
<span><p>Human education system trains one student by multiple experts.
Mixture-of-experts (MoE) is a powerful sparse architecture including multiple
experts. However, sparse MoE model is hard to implement, easy to overfit, and
not hardware-friendly. In this work, inspired by human education model, we
propose a novel task, knowledge integration, to obtain a dense student model
(OneS) as knowledgeable as one sparse MoE. We investigate this task by
proposing a general training framework including knowledge gathering and
knowledge distillation. Specifically, we first propose Singular Value
Decomposition Knowledge Gathering (SVD-KG) to gather key knowledge from
different pretrained experts. We then refine the dense student model by
knowledge distillation to offset the noise from gathering. On ImageNet, our
OneS preserves $61.7\%$ benefits from MoE. OneS can achieve $78.4\%$ top-1
accuracy with only $15$M parameters. On four natural language processing
datasets, OneS obtains $88.2\%$ MoE benefits and outperforms SoTA by $51.7\%$
using the same architecture and training data. In addition, compared with the
MoE counterpart, OneS can achieve $3.7 \times$ inference speedup due to the
hardware-friendly architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpreting Language Models with Contrastive Explanations. (arXiv:2202.10419v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10419">
<div class="article-summary-box-inner">
<span><p>Model interpretability methods are often used to explain NLP model decisions
on tasks such as text classification, where the output space is relatively
small. However, when applied to language generation, where the output space
often consists of tens of thousands of tokens, these methods are unable to
provide informative explanations. Language models must consider various
features to predict a token, such as its part of speech, number, tense, or
semantics. Existing explanation methods conflate evidence for all these
features into a single explanation, which is less interpretable for human
understanding.
</p>
<p>To disentangle the different decisions in language modeling, we focus on
explaining language models contrastively: we look for salient input tokens that
explain why the model predicted one token instead of another. We demonstrate
that contrastive explanations are quantifiably better than non-contrastive
explanations in verifying major grammatical phenomena, and that they
significantly improve contrastive model simulatability for human observers. We
also identify groups of contrastive decisions where the model uses similar
evidence, and we are able to characterize what input tokens models use during
various language generation decisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistent Representation Learning for Continual Relation Extraction. (arXiv:2203.02721v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.02721">
<div class="article-summary-box-inner">
<span><p>Continual relation extraction (CRE) aims to continuously train a model on
data with new relations while avoiding forgetting old ones. Some previous work
has proved that storing a few typical samples of old relations and replaying
them when learning new relations can effectively avoid forgetting. However,
these memory-based methods tend to overfit the memory samples and perform
poorly on imbalanced datasets. To solve these challenges, a consistent
representation learning method is proposed, which maintains the stability of
the relation embedding by adopting contrastive learning and knowledge
distillation when replaying memory. Specifically, supervised contrastive
learning based on a memory bank is first used to train each new task so that
the model can effectively learn the relation representation. Then, contrastive
replay is conducted of the samples in memory and makes the model retain the
knowledge of historical relations through memory knowledge distillation to
prevent the catastrophic forgetting of the old task. The proposed method can
better learn consistent representations to alleviate forgetting effectively.
Extensive experiments on FewRel and TACRED datasets show that our method
significantly outperforms state-of-the-art baselines and yield strong
robustness on the imbalanced dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Internet-augmented language models through few-shot prompting for open-domain question answering. (arXiv:2203.05115v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.05115">
<div class="article-summary-box-inner">
<span><p>In this work, we aim to capitalize on the unique few-shot capabilities of
large-scale language models (LSLMs) to overcome some of their challenges with
respect to grounding to factual and up-to-date information. Motivated by
semi-parametric language models (LMs), which ground their decisions in external
retrieved evidence, we use few-shot prompting to learn to condition LMs on
information returned from the web using Google Search, a broad and constantly
updated knowledge source. Our approach does not involve fine-tuning or learning
additional parameters, thus making it applicable to any LM, offering therefore
a strong baseline. Indeed, we find that LMs conditioned on the web surpass
performance of closed-book models of similar, or even larger, model sizes in
open-domain question answering. Finally, we find that increasing the
inference-time compute of models, achieved via using multiple retrieved
evidences to generate multiple answers followed by a reranking stage that uses
scores generated by the same LMs, leads to better performance and alleviates
lower performance of smaller few-shot LMs. All in all, our findings suggest
that it might be beneficial to slow down the race towards the biggest model and
instead shift attention towards finding more effective ways to use models,
including but not limited to, better prompting or increasing inference-time
compute.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RED-ACE: Robust Error Detection for ASR using Confidence Embeddings. (arXiv:2203.07172v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07172">
<div class="article-summary-box-inner">
<span><p>ASR Error Detection (AED) models aim to post-process the output of Automatic
Speech Recognition (ASR) systems, in order to detect transcription errors.
Modern approaches usually use text-based input, comprised solely of the ASR
transcription hypothesis, disregarding additional signals from the ASR model.
Instead, we propose to utilize the ASR system's word-level confidence scores
for improving AED performance. Specifically, we add an ASR Confidence Embedding
(ACE) layer to the AED model's encoder, allowing us to jointly encode the
confidence scores and the transcribed text into a contextualized
representation. Our experiments show the benefits of ASR confidence scores for
AED, their complementary effect over the textual signal, as well as the
effectiveness and robustness of ACE for combining these signals. To foster
further research, we publish a novel AED dataset consisting of ASR outputs on
the LibriSpeech corpus with annotated transcription errors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models. (arXiv:2203.07259v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07259">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models have become a key building block for
natural language processing. While these models are extremely accurate, they
can be too large and computationally intensive to run on standard deployments.
A variety of compression methods, including distillation, quantization,
structured and unstructured pruning are known to decrease model size and
increase inference speed, with low accuracy loss. In this context, this paper's
contributions are two-fold. We perform an in-depth study of the
accuracy-compression trade-off for unstructured weight pruning of BERT models.
We introduce Optimal BERT Surgeon (oBERT), an efficient and accurate weight
pruning method based on approximate second-order information, which we show to
yield state-of-the-art results in both stages of language tasks: pre-training
and fine-tuning. Specifically, oBERT extends existing work on unstructured
second-order pruning by allowing for pruning blocks of weights, and by being
applicable at the BERT scale. Second, we investigate the impact of this pruning
method when compounding compression approaches to obtain highly compressed but
accurate models for deployment on edge devices. These models significantly push
boundaries of the current state-of-the-art sparse BERT models with respect to
all metrics: model size, inference speed and task accuracy. For example,
relative to the dense BERT-base, we obtain 10x model size compression (in MB)
with &lt; 1% accuracy drop, 10x CPU-inference speedup with &lt; 2% accuracy drop, and
29x CPU-inference speedup with &lt; 7.5% accuracy drop.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In-Context Learning for Few-Shot Dialogue State Tracking. (arXiv:2203.08568v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08568">
<div class="article-summary-box-inner">
<span><p>Collecting and annotating task-oriented dialogues is time-consuming and
costly. Thus, zero and few shot learning for dialogue tasks presents an
exciting opportunity. In this work, we propose an in-context (IC) learning
framework for zero-shot and few-shot learning dialogue state tracking (DST),
where a large pretrained language model (LM) takes a test instance and a few
exemplars as input, and directly decodes the dialogue state without any
parameter updates. This approach is more flexible and scalable than prior DST
work when adapting to new domains and scenarios. To better leverage a tabular
domain description in the LM prompt, we reformulate DST into a text-to-SQL
problem. We also propose a novel approach to retrieve annotated dialogues as
exemplars. Empirical results on MultiWOZ show that our method IC-DST
substantially outperforms previous fine-tuned state-of-the-art models in
few-shot settings. In addition, we test IC-DST in zero-shot settings, in which
the model only takes a fixed task instruction as input, finding that it
outperforms previous zero-shot methods by a large margin on MultiWOZ.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EVA2.0: Investigating Open-Domain Chinese Dialogue Systems with Large-Scale Pre-Training. (arXiv:2203.09313v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09313">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-training has shown remarkable performance in building
open-domain dialogue systems. However, previous works mainly focus on showing
and evaluating the conversational performance of the released dialogue model,
ignoring the discussion of some key factors towards a powerful human-like
chatbot, especially in Chinese scenarios. In this paper, we conduct extensive
experiments to investigate these under-explored factors, including data quality
control, model architecture designs, training approaches, and decoding
strategies. We propose EVA2.0, a large-scale pre-trained open-domain Chinese
dialogue model with 2.8 billion parameters, and make our models and code
publicly available. To our knowledge, EVA2.0 is the largest open-source Chinese
dialogue model. Automatic and human evaluations show that our model
significantly outperforms other open-source counterparts. We also discuss the
limitations of this work by presenting some failure cases and pose some future
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibration of Machine Reading Systems at Scale. (arXiv:2203.10623v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.10623">
<div class="article-summary-box-inner">
<span><p>In typical machine learning systems, an estimate of the probability of the
prediction is used to assess the system's confidence in the prediction. This
confidence measure is usually uncalibrated; i.e.\ the system's confidence in
the prediction does not match the true probability of the predicted output. In
this paper, we present an investigation into calibrating open setting machine
reading systems such as open-domain question answering and claim verification
systems. We show that calibrating such complex systems which contain discrete
retrieval and deep reading components is challenging and current calibration
techniques fail to scale to these settings. We propose simple extensions to
existing calibration approaches that allows us to adapt them to these settings.
Our experimental results reveal that the approach works well, and can be useful
to selectively predict answers when question answering systems are posed with
unanswerable or out-of-the-training distribution questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and BERT models. (arXiv:2203.13778v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.13778">
<div class="article-summary-box-inner">
<span><p>Social media platforms are used by a large number of people prominently to
express their thoughts and opinions. However, these platforms have contributed
to a substantial amount of hateful and abusive content as well. Therefore, it
is important to curb the spread of hate speech on these platforms. In India,
Marathi is one of the most popular languages used by a wide audience. In this
work, we present L3Cube-MahaHate, the first major Hate Speech Dataset in
Marathi. The dataset is curated from Twitter, annotated manually. Our dataset
consists of over 25000 distinct tweets labeled into four major classes i.e
hate, offensive, profane, and not. We present the approaches used for
collecting and annotating the data and the challenges faced during the process.
Finally, we present baseline classification results using deep learning models
based on CNN, LSTM, and Transformers. We explore mono-lingual and multi-lingual
variants of BERT like MahaBERT, IndicBERT, mBERT, and xlm-RoBERTa and show that
mono-lingual models perform better than their multi-lingual counterparts. The
MahaBERT model provides the best results on L3Cube-MahaHate Corpus. The data
and models are available at https://github.com/l3cube-pune/MarathiNLP .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Filter-based Discriminative Autoencoders for Children Speech Recognition. (arXiv:2204.00164v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.00164">
<div class="article-summary-box-inner">
<span><p>Children speech recognition is indispensable but challenging due to the
diversity of children's speech. In this paper, we propose a filter-based
discriminative autoencoder for acoustic modeling. To filter out the influence
of various speaker types and pitches, auxiliary information of the speaker and
pitch features is input into the encoder together with the acoustic features to
generate phonetic embeddings. In the training phase, the decoder uses the
auxiliary information and the phonetic embedding extracted by the encoder to
reconstruct the input acoustic features. The autoencoder is trained by
simultaneously minimizing the ASR loss and feature reconstruction error. The
framework can make the phonetic embedding purer, resulting in more accurate
senone (triphone-state) scores. Evaluated on the test set of the CMU Kids
corpus, our system achieves a 7.8% relative WER reduction compared to the
baseline system. In the domain adaptation experiment, our system also
outperforms the baseline system on the British-accent PF-STAR task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Biomedical Entity Linking via Knowledge Base-Guided Pre-training and Synonyms-Aware Fine-tuning. (arXiv:2204.05164v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05164">
<div class="article-summary-box-inner">
<span><p>Entities lie in the heart of biomedical natural language understanding, and
the biomedical entity linking (EL) task remains challenging due to the
fine-grained and diversiform concept names. Generative methods achieve
remarkable performances in general domain EL with less memory usage while
requiring expensive pre-training. Previous biomedical EL methods leverage
synonyms from knowledge bases (KB) which is not trivial to inject into a
generative method. In this work, we use a generative approach to model
biomedical EL and propose to inject synonyms knowledge in it. We propose
KB-guided pre-training by constructing synthetic samples with synonyms and
definitions from KB and require the model to recover concept names. We also
propose synonyms-aware fine-tuning to select concept names for training, and
propose decoder prompt and multi-synonyms constrained prefix tree for
inference. Our method achieves state-of-the-art results on several biomedical
EL tasks without candidate selection which displays the effectiveness of
proposed pre-training and fine-tuning strategies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProtoTEx: Explaining Model Decisions with Prototype Tensors. (arXiv:2204.05426v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05426">
<div class="article-summary-box-inner">
<span><p>We present ProtoTEx, a novel white-box NLP classification architecture based
on prototype networks. ProtoTEx faithfully explains model decisions based on
prototype tensors that encode latent clusters of training examples. At
inference time, classification decisions are based on the distances between the
input text and the prototype tensors, explained via the training examples most
similar to the most influential prototypes. We also describe a novel
interleaved training algorithm that effectively handles classes characterized
by the absence of indicative features. On a propaganda detection task, ProtoTEx
accuracy matches BART-large and exceeds BERT-large with the added benefit of
providing faithful explanations. A user study also shows that prototype-based
explanations help non-experts to better recognize propaganda in online news.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syntax-informed Question Answering with Heterogeneous Graph Transformer. (arXiv:2204.09655v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.09655">
<div class="article-summary-box-inner">
<span><p>Large neural language models are steadily contributing state-of-the-art
performance to question answering and other natural language and information
processing tasks. These models are expensive to train. We propose to evaluate
whether such pre-trained models can benefit from the addition of explicit
linguistics information without requiring retraining from scratch.
</p>
<p>We present a linguistics-informed question answering approach that extends
and fine-tunes a pre-trained transformer-based neural language model with
symbolic knowledge encoded with a heterogeneous graph transformer. We
illustrate the approach by the addition of syntactic information in the form of
dependency and constituency graphic structures connecting tokens and virtual
vertices.
</p>
<p>A comparative empirical performance evaluation with BERT as its baseline and
with Stanford Question Answering Dataset demonstrates the competitiveness of
the proposed approach. We argue, in conclusion and in the light of further
results of preliminary experiments, that the approach is extensible to further
linguistics information including semantics and pragmatics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Local Hypergraph-based Nested Named Entity Recognition as Query-based Sequence Labeling. (arXiv:2204.11467v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11467">
<div class="article-summary-box-inner">
<span><p>There has been a growing academic interest in the recognition of nested named
entities in many domains. We tackle the task with a novel local
hypergraph-based method: We first propose start token candidates and generate
corresponding queries with their surrounding context, then use a query-based
sequence labeling module to form a local hypergraph for each candidate. An end
token estimator is used to correct the hypergraphs and get the final
predictions. Compared to span-based approaches, our method is free of the high
computation cost of span sampling and the risk of losing long entities.
Sequential prediction makes it easier to leverage information in word order
inside nested structures, and richer representations are built with a local
hypergraph. Experiments show that our proposed method outperforms all the
previous hypergraph-based and sequence labeling approaches with large margins
on all four nested datasets. It achieves a new state-of-the-art F1 score on the
ACE 2004 dataset and competitive F1 scores with previous state-of-the-art
methods on three other nested NER datasets: ACE 2005, GENIA, and KBP 2017.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FastRE: Towards Fast Relation Extraction with Convolutional Encoder and Improved Cascade Binary Tagging Framework. (arXiv:2205.02490v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02490">
<div class="article-summary-box-inner">
<span><p>Recent work for extracting relations from texts has achieved excellent
performance. However, most existing methods pay less attention to the
efficiency, making it still challenging to quickly extract relations from
massive or streaming text data in realistic scenarios. The main efficiency
bottleneck is that these methods use a Transformer-based pre-trained language
model for encoding, which heavily affects the training speed and inference
speed. To address this issue, we propose a fast relation extraction model
(FastRE) based on convolutional encoder and improved cascade binary tagging
framework. Compared to previous work, FastRE employs several innovations to
improve efficiency while also keeping promising performance. Concretely, FastRE
adopts a novel convolutional encoder architecture combined with dilated
convolution, gated unit and residual connection, which significantly reduces
the computation cost of training and inference, while maintaining the
satisfactory performance. Moreover, to improve the cascade binary tagging
framework, FastRE first introduces a type-relation mapping mechanism to
accelerate tagging efficiency and alleviate relation redundancy, and then
utilizes a position-dependent adaptive thresholding strategy to obtain higher
tagging accuracy and better model generalization. Experimental results
demonstrate that FastRE is well balanced between efficiency and performance,
and achieves 3-10x training speed, 7-15x inference speed faster, and 1/100
parameters compared to the state-of-the-art models, while the performance is
still competitive.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Use of BERT for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation. (arXiv:2205.03835v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03835">
<div class="article-summary-box-inner">
<span><p>In recent years, pre-trained models have become dominant in most natural
language processing (NLP) tasks. However, in the area of Automated Essay
Scoring (AES), pre-trained models such as BERT have not been properly used to
outperform other deep learning models such as LSTM. In this paper, we introduce
a novel multi-scale essay representation for BERT that can be jointly learned.
We also employ multiple losses and transfer learning from out-of-domain essays
to further improve the performance. Experiment results show that our approach
derives much benefit from joint learning of multi-scale essay representation
and obtains almost the state-of-the-art result among all deep learning models
in the ASAP task. Our multi-scale essay representation also generalizes well to
CommonLit Readability Prize data set, which suggests that the novel text
representation proposed in this paper may be a new and effective choice for
long-text tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chart Question Answering: State of the Art and Future Directions. (arXiv:2205.03966v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03966">
<div class="article-summary-box-inner">
<span><p>Information visualizations such as bar charts and line charts are very common
for analyzing data and discovering critical insights. Often people analyze
charts to answer questions that they have in mind. Answering such questions can
be challenging as they often require a significant amount of perceptual and
cognitive effort. Chart Question Answering (CQA) systems typically take a chart
and a natural language question as input and automatically generate the answer
to facilitate visual data analysis. Over the last few years, there has been a
growing body of literature on the task of CQA. In this survey, we
systematically review the current state-of-the-art research focusing on the
problem of chart question answering. We provide a taxonomy by identifying
several important dimensions of the problem domain including possible inputs
and outputs of the task and discuss the advantages and limitations of proposed
solutions. We then summarize various evaluation techniques used in the surveyed
papers. Finally, we outline the open challenges and future research
opportunities related to chart question answering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Distributional Properties Drive Emergent In-Context Learning in Transformers. (arXiv:2205.05055v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05055">
<div class="article-summary-box-inner">
<span><p>Large transformer-based language models are able to perform few-shot learning
(also known as in-context learning), without having been explicitly trained for
it. We hypothesized that specific distributional properties of natural language
might drive this emergent phenomenon, as these characteristics might lead to a
kind of interpolation between few-shot meta-training (designed to elicit rapid
few-shot learning) and standard supervised training (designed to elicit gradual
in-weights learning). We also hypothesized that these distributional properties
could lead to emergent few-shot learning in domains outside of language.
Inspired by this idea, we ran a series of experiments on a standard image-based
few-shot dataset. We discovered that a number of data properties did indeed
promote the emergence of few-shot learning in transformer models. All of these
properties are present in natural language -- burstiness, long-tailedness, and
many-to-one or one-to-many label mappings. The data influenced whether models
were biased towards either few-shot learning vs. memorizing information in
their weights; models could generally perform well at only one or the other.
However, we discovered that an additional distributional property could allow
the two capabilities to co-exist in the same model -- a skewed, Zipfian
distribution over classes -- which occurs in language as well. Notably,
training data that could elicit few-shot learning in transformers were unable
to elicit few-shot learning in recurrent models. In sum, we find that few-shot
learning emerges only from applying the right architecture to the right data
distribution; neither component is sufficient on its own.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Generalizability of Fine-Tuned Models for Fake News Detection. (arXiv:2205.07154v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07154">
<div class="article-summary-box-inner">
<span><p>The Covid-19 pandemic has caused a dramatic and parallel rise in dangerous
misinformation, denoted an `infodemic' by the CDC and WHO. Misinformation tied
to the Covid-19 infodemic changes continuously; this can lead to performance
degradation of fine-tuned models due to concept drift. Degredation can be
mitigated if models generalize well-enough to capture some cyclical aspects of
drifted data. In this paper, we explore generalizability of pre-trained and
fine-tuned fake news detectors across 9 fake news datasets. We show that
existing models often overfit on their training dataset and have poor
performance on unseen data. However, on some subsets of unseen data that
overlap with training data, models have higher accuracy. Based on this
observation, we also present KMeans-Proxy, a fast and effective method based on
K-Means clustering for quickly identifying these overlapping subsets of unseen
data. KMeans-Proxy improves generalizability on unseen fake news datasets by
0.1-0.2 f1-points across datasets. We present both our generalizability
experiments as well as KMeans-Proxy to further research in tackling the fake
news problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Wojood: Nested Arabic Named Entity Corpus and Recognition using BERT. (arXiv:2205.09651v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09651">
<div class="article-summary-box-inner">
<span><p>This paper presents Wojood, a corpus for Arabic nested Named Entity
Recognition (NER). Nested entities occur when one entity mention is embedded
inside another entity mention. Wojood consists of about 550K Modern Standard
Arabic (MSA) and dialect tokens that are manually annotated with 21 entity
types including person, organization, location, event and date. More
importantly, the corpus is annotated with nested entities instead of the more
common flat annotations. The data contains about 75K entities and 22.5% of
which are nested. The inter-annotator evaluation of the corpus demonstrated a
strong agreement with Cohen's Kappa of 0.979 and an F1-score of 0.976. To
validate our data, we used the corpus to train a nested NER model based on
multi-task learning and AraBERT (Arabic BERT). The model achieved an overall
micro F1-score of 0.884. Our corpus, the annotation guidelines, the source code
and the pre-trained model are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Slot Tagging with Intent Features for Task Oriented Natural Language Understanding using BERT. (arXiv:2205.09732v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09732">
<div class="article-summary-box-inner">
<span><p>Recent joint intent detection and slot tagging models have seen improved
performance when compared to individual models. In many real-world datasets,
the slot labels and values have a strong correlation with their intent labels.
In such cases, the intent label information may act as a useful feature to the
slot tagging model. In this paper, we examine the effect of leveraging intent
label features through 3 techniques in the slot tagging task of joint intent
and slot detection models. We evaluate our techniques on benchmark spoken
language datasets SNIPS and ATIS, as well as over a large private Bixby dataset
and observe an improved slot-tagging performance over state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Branch Prior-SegNet: CNN for Interventional CBCT using Planning Scan and Auxiliary Segmentation Loss. (arXiv:2205.10353v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10353">
<div class="article-summary-box-inner">
<span><p>This paper proposes an extension to the Dual Branch Prior-Net for sparse view
interventional CBCT reconstruction incorporating a high quality planning scan.
An additional head learns to segment interventional instruments and thus guides
the reconstruction task. The prior scans are misaligned by up to +-5deg
in-plane during training. Experiments show that the proposed model, Dual Branch
Prior-SegNet, significantly outperforms any other evaluated model by &gt;2.8dB
PSNR. It also stays robust wrt. rotations of up to +-5.5deg.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prediction of stent under-expansion in calcified coronary arteries using machine-learning on intravascular optical coherence tomography. (arXiv:2205.10354v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10354">
<div class="article-summary-box-inner">
<span><p>BACKGROUND Careful evaluation of the risk of stent under-expansions before
the intervention will aid treatment planning, including the application of a
pre-stent plaque modification strategy.
</p>
<p>OBJECTIVES It remains challenging to achieve a proper stent expansion in the
presence of severely calcified coronary lesions. Building on our work in deep
learning segmentation, we created an automated machine learning approach that
uses lesion attributes to predict stent under-expansion from pre-stent images,
suggesting the need for plaque modification.
</p>
<p>METHODS Pre- and post-stent intravascular optical coherence tomography image
data were obtained from 110 coronary lesions. Lumen and calcifications in
pre-stent images were segmented using deep learning, and numerous features per
lesion were extracted. We analyzed stent expansion along the lesion, enabling
frame, segmental, and whole-lesion analyses. We trained regression models to
predict the poststent lumen area and then to compute the stent expansion index
(SEI). Stents with an SEI &lt; or &gt;/= 80% were classified as "under-expanded" and
"well-expanded," respectively.
</p>
<p>RESULTS Best performance (root-mean-square-error = 0.04+/-0.02 mm2, r =
0.94+/-0.04, p &lt; 0.0001) was achieved when we used features from both the lumen
and calcification to train a Gaussian regression model for a segmental analysis
over a segment length of 31 frames. Under-expansion classification results
(AUC=0.85+/-0.02) were significantly improved over other approaches.
</p>
<p>CONCLUSIONS We used calcifications and lumen features to identify lesions at
risk of stent under-expansion. Results suggest that the use of pre-stent images
can inform physicians of the need to apply plaque modification approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Quality Estimation: Creating Surrogate Models for Human Quality Ratings. (arXiv:2205.10355v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10355">
<div class="article-summary-box-inner">
<span><p>Human ratings are abstract representations of segmentation quality. To
approximate human quality ratings on scarce expert data, we train surrogate
quality estimation models. We evaluate on a complex multi-class segmentation
problem, specifically glioma segmentation following the BraTS annotation
protocol. The training data features quality ratings from 15 expert
neuroradiologists on a scale ranging from 1 to 6 stars for various
computer-generated and manual 3D annotations. Even though the networks operate
on 2D images and with scarce training data, we can approximate segmentation
quality within a margin of error comparable to human intra-rater reliability.
Segmentation quality prediction has broad applications. While an understanding
of segmentation quality is imperative for successful clinical translation of
automatic segmentation quality algorithms, it can play an essential role in
training new segmentation models. Due to the split-second inference times, it
can be directly applied within a loss function or as a fully-automatic dataset
curation mechanism in a federated learning setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EXPANSE: A Deep Continual / Progressive Learning System for Deep Transfer Learning. (arXiv:2205.10356v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10356">
<div class="article-summary-box-inner">
<span><p>Deep transfer learning techniques try to tackle the limitations of deep
learning, the dependency on extensive training data and the training costs, by
reusing obtained knowledge. However, the current DTL techniques suffer from
either catastrophic forgetting dilemma (losing the previously obtained
knowledge) or overly biased pre-trained models (harder to adapt to target data)
in finetuning pre-trained models or freezing a part of the pre-trained model,
respectively. Progressive learning, a sub-category of DTL, reduces the effect
of the overly biased model in the case of freezing earlier layers by adding a
new layer to the end of a frozen pre-trained model. Even though it has been
successful in many cases, it cannot yet handle distant source and target data.
We propose a new continual/progressive learning approach for deep transfer
learning to tackle these limitations. To avoid both catastrophic forgetting and
overly biased-model problems, we expand the pre-trained model by expanding
pre-trained layers (adding new nodes to each layer) in the model instead of
only adding new layers. Hence the method is named EXPANSE. Our experimental
results confirm that we can tackle distant source and target data using this
technique. At the same time, the final model is still valid on the source data,
achieving a promising deep continual learning approach. Moreover, we offer a
new way of training deep learning models inspired by the human education
system. We termed this two-step training: learning basics first, then adding
complexities and uncertainties. The evaluation implies that the two-step
training extracts more meaningful features and a finer basin on the error
surface since it can achieve better accuracy in comparison to regular training.
EXPANSE (model expansion and two-step training) is a systematic continual
learning approach applicable to different problems and DL models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nonlinear motion separation via untrained generator networks with disentangled latent space variables and applications to cardiac MRI. (arXiv:2205.10367v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10367">
<div class="article-summary-box-inner">
<span><p>In this paper, a nonlinear approach to separate different motion types in
video data is proposed. This is particularly relevant in dynamic medical
imaging (e.g. PET, MRI), where patient motion poses a significant challenge due
to its effects on the image reconstruction as well as for its subsequent
interpretation. Here, a new method is proposed where dynamic images are
represented as the forward mapping of a sequence of latent variables via a
generator neural network. The latent variables are structured so that temporal
variations in the data are represented via dynamic latent variables, which are
independent of static latent variables characterizing the general structure of
the frames. In particular, different kinds of motion are also characterized
independently of each other via latent space disentanglement using
one-dimensional prior information on all but one of the motion types. This
representation allows to freeze any selection of motion types, and to obtain
accurate independent representations of other dynamics of interest. Moreover,
the proposed algorithm is training-free, i.e., all the network parameters are
learned directly from a single video. We illustrate the performance of this
method on phantom and real-data MRI examples, where we successfully separate
respiratory and cardiac motion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Generation of Synthetic Colonoscopy Videos for Domain Randomization. (arXiv:2205.10368v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10368">
<div class="article-summary-box-inner">
<span><p>An increasing number of colonoscopic guidance and assistance systems rely on
machine learning algorithms which require a large amount of high-quality
training data. In order to ensure high performance, the latter has to resemble
a substantial portion of possible configurations. This particularly addresses
varying anatomy, mucosa appearance and image sensor characteristics which are
likely deteriorated by motion blur and inadequate illumination. The limited
amount of readily available training data hampers to account for all of these
possible configurations which results in reduced generalization capabilities of
machine learning models. We propose an exemplary solution for synthesizing
colonoscopy videos with substantial appearance and anatomical variations which
enables to learn discriminative domain-randomized representations of the
interior colon while mimicking real-world settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A SSIM Guided cGAN Architecture For Clinically Driven Generative Image Synthesis of Multiplexed Spatial Proteomics Channels. (arXiv:2205.10373v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10373">
<div class="article-summary-box-inner">
<span><p>Here we present a structural similarity index measure (SSIM) guided
conditional Generative Adversarial Network (cGAN) that generatively performs
image-to-image (i2i) synthesis to generate photo-accurate protein channels in
multiplexed spatial proteomics images. This approach can be utilized to
accurately generate missing spatial proteomics channels that were not included
during experimental data collection either at the bench or the clinic.
Experimental spatial proteomic data from the Human BioMolecular Atlas Program
(HuBMAP) was used to generate spatial representations of missing proteins
through a U-Net based image synthesis pipeline. HuBMAP channels were
hierarchically clustered by the (SSIM) as a heuristic to obtain the minimal set
needed to recapitulate the underlying biology represented by the spatial
landscape of proteins. We subsequently prove that our SSIM based architecture
allows for scaling of generative image synthesis to slides with up to 100
channels, which is better than current state of the art algorithms which are
limited to data with 11 channels. We validate these claims by generating a new
experimental spatial proteomics data set from human lung adenocarcinoma tissue
sections and show that a model trained on HuBMAP can accurately synthesize
channels from our new data set. The ability to recapitulate experimental data
from sparsely stained multiplexed histological slides containing spatial
proteomic will have tremendous impact on medical diagnostics and drug
development, and also raises important questions on the medical ethics of
utilizing data produced by generative image synthesis in the clinical setting.
The algorithm that we present in this paper will allow researchers and
clinicians to save time and costs in proteomics based histological staining
while also increasing the amount of data that they can generate through their
experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Dynamic Weighted Tabular Method for Convolutional Neural Networks. (arXiv:2205.10386v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10386">
<div class="article-summary-box-inner">
<span><p>Traditional Machine Learning (ML) models like Support Vector Machine, Random
Forest, and Logistic Regression are generally preferred for classification
tasks on tabular datasets. Tabular data consists of rows and columns
corresponding to instances and features, respectively. Past studies indicate
that traditional classifiers often produce unsatisfactory results in complex
tabular datasets. Hence, researchers attempt to use the powerful Convolutional
Neural Networks (CNN) for tabular datasets. Recent studies propose several
techniques like SuperTML, Conditional GAN (CTGAN), and Tabular Convolution
(TAC) for applying Convolutional Neural Networks (CNN) on tabular data. These
models outperform the traditional classifiers and substantially improve the
performance on tabular data. This study introduces a novel technique, namely,
Dynamic Weighted Tabular Method (DWTM), that uses feature weights dynamically
based on statistical techniques to apply CNNs on tabular datasets. The method
assigns weights dynamically to each feature based on their strength of
associativity to the class labels. Each data point is converted into images and
fed to a CNN model. The features are allocated image canvas space based on
their weights. The DWTM is an improvement on the previously mentioned methods
as it dynamically implements the entire experimental setting rather than using
the static configuration provided in the previous methods. Furthermore, it uses
the novel idea of using feature weights to create image canvas space. In this
paper, the DWTM is applied to six benchmarked tabular datasets and it achieves
outstanding performance (i.e., average accuracy = 95%) on all of them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing visual acuity in visual prostheses through a virtual-reality system. (arXiv:2205.10395v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10395">
<div class="article-summary-box-inner">
<span><p>Current visual implants still provide very low resolution and limited field
of view, thus limiting visual acuity in implanted patients. Developments of new
strategies of artificial vision simulation systems by harnessing new
advancements in technologies are of upmost priorities for the development of
new visual devices. In this work, we take advantage of virtual-reality software
paired with a portable head-mounted display and evaluated the performance of
normally sighted participants under simulated prosthetic vision with variable
field of view and number of pixels. Our simulated prosthetic vision system
allows simple experimentation in order to study the design parameters of future
visual prostheses. Ten normally sighted participants volunteered for a visual
acuity study. Subjects were required to identify computer-generated Landolt-C
gap orientation and different stimulus based on light perception,
time-resolution, light location and motion perception commonly used for visual
acuity examination in the sighted. Visual acuity scores were recorded across
different conditions of number of electrodes and size of field of view. Our
results showed that of all conditions tested, a field of view of 20{\deg} and
1000 phosphenes of resolution proved the best, with a visual acuity of 1.3
logMAR. Furthermore, performance appears to be correlated with phosphene
density, but showing a diminishing return when field of view is less than
20{\deg}. The development of new artificial vision simulation systems can be
useful to guide the development of new visual devices and the optimization of
field of view and resolution to provide a helpful and valuable visual aid to
profoundly or totally blind patients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining Contrastive and Supervised Learning for Video Super-Resolution Detection. (arXiv:2205.10406v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10406">
<div class="article-summary-box-inner">
<span><p>Upscaled video detection is a helpful tool in multimedia forensics, but it is
a challenging task that involves various upscaling and compression algorithms.
There are many resolution-enhancement methods, including interpolation and
deep-learning-based super-resolution, and they leave unique traces. In this
work, we propose a new upscaled-resolution-detection method based on learning
of visual representations using contrastive and cross-entropy losses. To
explain how the method detects videos, we systematically review the major
components of our framework - in particular, we show that most
data-augmentation approaches hinder the learning of the method. Through
extensive experiments on various datasets, we demonstrate that our method
effectively detects upscaling even in compressed videos and outperforms the
state-of-the-art alternatives. The code and models are publicly available at
https://github.com/msu-video-group/SRDM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using machine learning on new feature sets extracted from 3D models of broken animal bones to classify fragments according to break agent. (arXiv:2205.10430v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10430">
<div class="article-summary-box-inner">
<span><p>Distinguishing agents of bone modification at paleoanthropological sites is
at the root of much of the research directed at understanding early hominin
exploitation of large animal resources and the effects those subsistence
behaviors had on early hominin evolution. However, current methods,
particularly in the area of fracture pattern analysis as a signal of marrow
exploitation, have failed to overcome equifinality. Furthermore, researchers
debate the replicability and validity of current and emerging methods for
analyzing bone modifications. Here we present a new approach to fracture
pattern analysis aimed at distinguishing bone fragments resulting from hominin
bone breakage and those produced by carnivores. This new method uses 3D models
of fragmentary bone to extract a much richer dataset that is more transparent
and replicable than feature sets previously used in fracture pattern analysis.
Supervised machine learning algorithms are properly used to classify bone
fragments according to agent of breakage with average mean accuracy of 77%
across tests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Better Understanding Attribution Methods. (arXiv:2205.10435v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10435">
<div class="article-summary-box-inner">
<span><p>Deep neural networks are very successful on many vision tasks, but hard to
interpret due to their black box nature. To overcome this, various post-hoc
attribution methods have been proposed to identify image regions most
influential to the models' decisions. Evaluating such methods is challenging
since no ground truth attributions exist. We thus propose three novel
evaluation schemes to more reliably measure the faithfulness of those methods,
to make comparisons between them more fair, and to make visual inspection more
systematic. To address faithfulness, we propose a novel evaluation setting
(DiFull) in which we carefully control which parts of the input can influence
the output in order to distinguish possible from impossible attributions. To
address fairness, we note that different methods are applied at different
layers, which skews any comparison, and so evaluate all methods on the same
layers (ML-Att) and discuss how this impacts their performance on quantitative
metrics. For more systematic visualizations, we propose a scheme (AggAtt) to
qualitatively evaluate the methods on complete datasets. We use these
evaluation schemes to study strengths and shortcomings of some widely used
attribution methods. Finally, we propose a post-processing smoothing step that
significantly improves the performance of some attribution methods, and discuss
its applicability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporally Precise Action Spotting in Soccer Videos Using Dense Detection Anchors. (arXiv:2205.10450v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10450">
<div class="article-summary-box-inner">
<span><p>We present a model for temporally precise action spotting in videos, which
uses a dense set of detection anchors, predicting a detection confidence and
corresponding fine-grained temporal displacement for each anchor. We experiment
with two trunk architectures, both of which are able to incorporate large
temporal contexts while preserving the smaller-scale features required for
precise localization: a one-dimensional version of a u-net, and a Transformer
encoder (TE). We also suggest best practices for training models of this kind,
by applying Sharpness-Aware Minimization (SAM) and mixup data augmentation. We
achieve a new state-of-the-art on SoccerNet-v2, the largest soccer video
dataset of its kind, with marked improvements in temporal localization.
Additionally, our ablations show: the importance of predicting the temporal
displacements; the trade-offs between the u-net and TE trunks; and the benefits
of training with SAM and mixup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PSO-Convolutional Neural Networks with Heterogeneous Learning Rate. (arXiv:2205.10456v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10456">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks (ConvNets) have been candidly deployed in the
scope of computer vision and related fields. Nevertheless, the dynamics of
training of these neural networks lie still elusive: it is hard and
computationally expensive to train them. A myriad of architectures and training
strategies have been proposed to overcome this challenge and address several
problems in image processing such as speech, image and action recognition as
well as object detection. In this article, we propose a novel Particle Swarm
Optimization (PSO) based training for ConvNets. In such framework, the vector
of weights of each ConvNet is typically cast as the position of a particle in
phase space whereby PSO collaborative dynamics intertwines with Stochastic
Gradient Descent (SGD) in order to boost training performance and
generalization. Our approach goes as follows: i) [warm-up phase] each ConvNet
is trained independently via SGD; ii) [collaborative phase] ConvNets share
among themselves their current vector of weights (or particle-position) along
with their gradient estimates of the Loss function. Distinct step sizes are
coined by distinct ConvNets. By properly blending ConvNets with large (possibly
random) step-sizes along with more conservative ones, we propose an algorithm
with competitive performance with respect to other PSO-based approaches on
Cifar-10 (accuracy of 98.31%). These accuracy levels are obtained by resorting
to only four ConvNets -- such results are expected to scale with the number of
collaborative ConvNets accordingly. We make our source codes available for
download https://github.com/leonlha/PSO-ConvNet-Dynamics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Sensible Adversarial Learning of Deep Neural Networks for Image Classification. (arXiv:2205.10457v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10457">
<div class="article-summary-box-inner">
<span><p>The idea of robustness is central and critical to modern statistical
analysis. However, despite the recent advances of deep neural networks (DNNs),
many studies have shown that DNNs are vulnerable to adversarial attacks. Making
imperceptible changes to an image can cause DNN models to make the wrong
classification with high confidence, such as classifying a benign mole as a
malignant tumor and a stop sign as a speed limit sign. The trade-off between
robustness and standard accuracy is common for DNN models. In this paper, we
introduce sensible adversarial learning and demonstrate the synergistic effect
between pursuits of standard natural accuracy and robustness. Specifically, we
define a sensible adversary which is useful for learning a robust model while
keeping high natural accuracy. We theoretically establish that the Bayes
classifier is the most robust multi-class classifier with the 0-1 loss under
sensible adversarial learning. We propose a novel and efficient algorithm that
trains a robust model using implicit loss truncation. We apply sensible
adversarial learning for large-scale image classification to a handwritten
digital image dataset called MNIST and an object recognition colored image
dataset called CIFAR10. We have performed an extensive comparative study to
compare our method with other competitive methods. Our experiments empirically
demonstrate that our method is not sensitive to its hyperparameter and does not
collapse even with a small model capacity while promoting robustness against
various attacks and keeping high natural accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Omnidirectional Vision: A Survey and New Perspectives. (arXiv:2205.10468v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10468">
<div class="article-summary-box-inner">
<span><p>Omnidirectional image (ODI) data is captured with a 360x180 field-of-view,
which is much wider than the pinhole cameras and contains richer spatial
information than the conventional planar images. Accordingly, omnidirectional
vision has attracted booming attention due to its more advantageous performance
in numerous applications, such as autonomous driving and virtual reality. In
recent years, the availability of customer-level 360 cameras has made
omnidirectional vision more popular, and the advance of deep learning (DL) has
significantly sparked its research and applications. This paper presents a
systematic and comprehensive review and analysis of the recent progress in DL
methods for omnidirectional vision. Our work covers four main contents: (i) An
introduction to the principle of omnidirectional imaging, the convolution
methods on the ODI, and datasets to highlight the differences and difficulties
compared with the 2D planar image data; (ii) A structural and hierarchical
taxonomy of the DL methods for omnidirectional vision; (iii) A summarization of
the latest novel learning strategies and applications; (iv) An insightful
discussion of the challenges and open problems by highlighting the potential
research directions to trigger more research in the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masterful: A Training Platform for Computer Vision Models. (arXiv:2205.10469v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10469">
<div class="article-summary-box-inner">
<span><p>Masterful is a software platform to train deep learning computer vision
models. Data and model architecture are inputs to the platform, and the output
is a trained model. The platform's primary goal is to maximize a trained
model's accuracy, which it achieves through its regularization and
semi-supervised learning implementations. The platform's secondary goal is to
minimize the amount of manual experimentation typically required to tune
training hyperparameters, which it achieves via multiple metalearning
algorithms which are custom built to control the platform's regularization and
semi-supervised learning implementations. The platform's tertiary goal is to
minimize the computing resources required to train a model, which it achieves
via another set of metalearning algorithms which are purpose built to control
Tensorflow's optimization implementations. The platform builds on top of
Tensorflow's data management, architecture, automatic differentiation, and
optimization implementations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-Supervised Subspace Clustering via Tensor Low-Rank Representation. (arXiv:2205.10481v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10481">
<div class="article-summary-box-inner">
<span><p>In this letter, we propose a novel semi-supervised subspace clustering
method, which is able to simultaneously augment the initial supervisory
information and construct a discriminative affinity matrix. By representing the
limited amount of supervisory information as a pairwise constraint matrix, we
observe that the ideal affinity matrix for clustering shares the same low-rank
structure as the ideal pairwise constraint matrix. Thus, we stack the two
matrices into a 3-D tensor, where a global low-rank constraint is imposed to
promote the affinity matrix construction and augment the initial pairwise
constraints synchronously. Besides, we use the local geometry structure of
input samples to complement the global low-rank prior to achieve better
affinity matrix learning. The proposed model is formulated as a Laplacian graph
regularized convex low-rank tensor representation problem, which is further
solved with an alternative iterative algorithm. In addition, we propose to
refine the affinity matrix with the augmented pairwise constraints.
Comprehensive experimental results on six commonly-used benchmark datasets
demonstrate the superiority of our method over state-of-the-art methods. The
code is publicly available at
https://github.com/GuanxingLu/Subspace-Clustering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mapping Emulation for Knowledge Distillation. (arXiv:2205.10490v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10490">
<div class="article-summary-box-inner">
<span><p>This paper formalizes the source-blind knowledge distillation problem that is
essential to federated learning. A new geometric perspective is presented to
view such a problem as aligning generated distributions between the teacher and
student. With its guidance, a new architecture MEKD is proposed to emulate the
inverse mapping through generative adversarial training. Unlike mimicking
logits and aligning logit distributions, reconstructing the mapping from
classifier-logits has a geometric intuition of decreasing empirical distances,
and theoretical guarantees using the universal function approximation and
optimal mass transportation theories. A new algorithm is also proposed to train
the student model that reaches the teacher's performance source-blindly. On
various benchmarks, MEKD outperforms existing source-blind KD methods,
explainable with ablation studies and visualized results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enriched Robust Multi-View Kernel Subspace Clustering. (arXiv:2205.10495v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10495">
<div class="article-summary-box-inner">
<span><p>Subspace clustering is to find underlying low-dimensional subspaces and
cluster the data points correctly. In this paper, we propose a novel multi-view
subspace clustering method. Most existing methods suffer from two critical
issues. First, they usually adopt a two-stage framework and isolate the
processes of affinity learning, multi-view information fusion and clustering.
Second, they assume the data lies in a linear subspace which may fail in
practice as most real-world datasets may have non-linearity structures. To
address the above issues, in this paper we propose a novel Enriched Robust
Multi-View Kernel Subspace Clustering framework where the consensus affinity
matrix is learned from both multi-view data and spectral clustering. Due to the
objective and constraints which is difficult to optimize, we propose an
iterative optimization method which is easy to implement and can yield closed
solution in each step. Extensive experiments have validated the superiority of
our method over state-of-the-art clustering methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making Video Quality Assessment Models Sensitive to Frame Rate Distortions. (arXiv:2205.10501v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10501">
<div class="article-summary-box-inner">
<span><p>We consider the problem of capturing distortions arising from changes in
frame rate as part of Video Quality Assessment (VQA). Variable frame rate (VFR)
videos have become much more common, and streamed videos commonly range from 30
frames per second (fps) up to 120 fps. VFR-VQA offers unique challenges in
terms of distortion types as well as in making non-uniform comparisons of
reference and distorted videos having different frame rates. The majority of
current VQA models require compared videos to be of the same frame rate, but
are unable to adequately account for frame rate artifacts. The recently
proposed Generalized Entropic Difference (GREED) VQA model succeeds at this
task, using natural video statistics models of entropic differences of temporal
band-pass coefficients, delivering superior performance on predicting video
quality changes arising from frame rate distortions. Here we propose a simple
fusion framework, whereby temporal features from GREED are combined with
existing VQA models, towards improving model sensitivity towards frame rate
distortions. We find through extensive experiments that this feature fusion
significantly boosts model performance on both HFR/VFR datasets as well as
fixed frame rate (FFR) VQA databases. Our results suggest that employing
efficient temporal representations can result much more robust and accurate VQA
models when frame rate variations can occur.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deeper vs Wider: A Revisit of Transformer Configuration. (arXiv:2205.10505v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10505">
<div class="article-summary-box-inner">
<span><p>Transformer-based models have delivered impressive results on many tasks,
particularly vision and language tasks. In many model training situations,
conventional configurations are typically adopted. For example, we often set
the base model with hidden dimensions (i.e. model width) to be 768 and the
number of transformer layers (i.e. model depth) to be 12. In this paper, we
revisit these conventional configurations. Through theoretical analysis and
experimental evaluation, we show that the masked autoencoder is effective in
alleviating the over-smoothing issue in deep transformer training. Based on
this finding, we propose Bamboo, an idea of using deeper and narrower
transformer configurations, for masked autoencoder training. On ImageNet, with
such a simple change in configuration, re-designed model achieves 87.1% top-1
accuracy and outperforms SoTA models like MAE and BEiT. On language tasks,
re-designed model outperforms BERT with default setting by 1.1 points on
average, on GLUE datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Travel Time, Distance and Costs Optimization for Paratransit Operations using Graph Convolutional Neural Network. (arXiv:2205.10507v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10507">
<div class="article-summary-box-inner">
<span><p>The provision of paratransit services is one option to meet the
transportation needs of Vulnerable Road Users (VRUs). Like any other means of
transportation, paratransit has obstacles such as high operational costs and
longer trip times. As a result, customers are dissatisfied, and paratransit
operators have a low approval rating. Researchers have undertaken various
studies over the years to better understand the travel behaviors of paratransit
customers and how they are operated. According to the findings of these
researches, paratransit operators confront the challenge of determining the
optimal route for their trips in order to save travel time. Depending on the
nature of the challenge, most research used different optimization techniques
to solve these routing problems. As a result, the goal of this study is to use
Graph Convolutional Neural Networks (GCNs) to assist paratransit operators in
researching various operational scenarios in a strategic setting in order to
optimize routing, minimize operating costs and minimize their users' travel
time. The study was carried out by using a randomized simulated dataset to help
determine the decision to make in terms of fleet composition and capacity under
different situations. For the various scenarios investigated, the GCN assisted
in determining the minimum optimal gap.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visualizing CoAtNet Predictions for Aiding Melanoma Detection. (arXiv:2205.10515v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10515">
<div class="article-summary-box-inner">
<span><p>Melanoma is considered to be the most aggressive form of skin cancer. Due to
the similar shape of malignant and benign cancerous lesions, doctors spend
considerably more time when diagnosing these findings. At present, the
evaluation of malignancy is performed primarily by invasive histological
examination of the suspicious lesion. Developing an accurate classifier for
early and efficient detection can minimize and monitor the harmful effects of
skin cancer and increase patient survival rates. This paper proposes a
multi-class classification task using the CoAtNet architecture, a hybrid model
that combines the depthwise convolution matrix operation of traditional
convolutional neural networks with the strengths of Transformer models and
self-attention mechanics to achieve better generalization and capacity. The
proposed multi-class classifier achieves an overall precision of 0.901, recall
0.895, and AP 0.923, indicating high performance compared to other
state-of-the-art networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point is a Vector: A Feature Representation in Point Analysis. (arXiv:2205.10528v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10528">
<div class="article-summary-box-inner">
<span><p>The irregularity and disorder of point clouds bring many challenges to point
cloud analysis. PointMLP suggests that geometric information is not the only
critical point in point cloud analysis. It achieves promising result based on a
simple multi-layer perception (MLP) structure with geometric affine module.
However, these MLP-like structures aggregate features only with fixed weights,
while differences in the semantic information of different point features are
ignored. So we propose a novel Point-Vector Representation of the point feature
to improve feature aggregation by using inductive bias. The direction of the
introduced vector representation can dynamically modulate the aggregation of
two point features according to the semantic relationship. Based on it, we
design a novel Point2Vector MLP architecture. Experiments show that it achieves
state-of-the-art performance on the classification task of ScanObjectNN
dataset, with 1% increase, compared with the previous best method. We hope our
method can help people better understand the role of semantic information in
point cloud analysis and lead to explore more and better feature
representations or other ways.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-Grained Visual Classification using Self Assessment Classifier. (arXiv:2205.10529v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10529">
<div class="article-summary-box-inner">
<span><p>Extracting discriminative features plays a crucial role in the fine-grained
visual classification task. Most of the existing methods focus on developing
attention or augmentation mechanisms to achieve this goal. However, addressing
the ambiguity in the top-k prediction classes is not fully investigated. In
this paper, we introduce a Self Assessment Classifier, which simultaneously
leverages the representation of the image and top-k prediction classes to
reassess the classification results. Our method is inspired by continual
learning with coarse-grained and fine-grained classifiers to increase the
discrimination of features in the backbone and produce attention maps of
informative areas on the image. In practice, our method works as an auxiliary
branch and can be easily integrated into different architectures. We show that
by effectively addressing the ambiguity in the top-k prediction classes, our
method achieves new state-of-the-art results on CUB200-2011, Stanford Dog, and
FGVC Aircraft datasets. Furthermore, our method also consistently improves the
accuracy of different existing fine-grained classifiers with a unified setup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Distillation from A Stronger Teacher. (arXiv:2205.10536v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10536">
<div class="article-summary-box-inner">
<span><p>Unlike existing knowledge distillation methods focus on the baseline
settings, where the teacher models and training strategies are not that strong
and competing as state-of-the-art approaches, this paper presents a method
dubbed DIST to distill better from a stronger teacher. We empirically find that
the discrepancy of predictions between the student and a stronger teacher may
tend to be fairly severer. As a result, the exact match of predictions in KL
divergence would disturb the training and make existing methods perform poorly.
In this paper, we show that simply preserving the relations between the
predictions of teacher and student would suffice, and propose a
correlation-based loss to capture the intrinsic inter-class relations from the
teacher explicitly. Besides, considering that different instances have
different semantic similarities to each class, we also extend this relational
match to the intra-class level. Our method is simple yet practical, and
extensive experiments demonstrate that it adapts well to various architectures,
model sizes and training strategies, and can achieve state-of-the-art
performance consistently on image classification, object detection, and
semantic segmentation tasks. Code is available at:
https://github.com/hunto/DIST_KD .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Feasibility and Generality of Patch-based Adversarial Attacks on Semantic Segmentation Problems. (arXiv:2205.10539v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10539">
<div class="article-summary-box-inner">
<span><p>Deep neural networks were applied with success in a myriad of applications,
but in safety critical use cases adversarial attacks still pose a significant
threat. These attacks were demonstrated on various classification and detection
tasks and are usually considered general in a sense that arbitrary network
outputs can be generated by them.
</p>
<p>In this paper we will demonstrate through simple case studies both in
simulation and in real-life, that patch based attacks can be utilised to alter
the output of segmentation networks. Through a few examples and the
investigation of network complexity, we will also demonstrate that the number
of possible output maps which can be generated via patch-based attacks of a
given size is typically smaller than the area they effect or areas which should
be attacked in case of practical applications.
</p>
<p>We will prove that based on these results most patch-based attacks cannot be
general in practice, namely they can not generate arbitrary output maps or if
they could, they are spatially limited and this limit is significantly smaller
than the receptive field of the patches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improvements to Self-Supervised Representation Learning for Masked Image Modeling. (arXiv:2205.10546v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10546">
<div class="article-summary-box-inner">
<span><p>This paper explores improvements to the masked image modeling (MIM) paradigm.
The MIM paradigm enables the model to learn the main object features of the
image by masking the input image and predicting the masked part by the unmasked
part. We found the following three main directions for MIM to be improved.
First, since both encoders and decoders contribute to representation learning,
MIM uses only encoders for downstream tasks, which ignores the impact of
decoders on representation learning. Although the MIM paradigm already employs
small decoders with asymmetric structures, we believe that continued reduction
of decoder parameters is beneficial to improve the representational learning
capability of the encoder . Second, MIM solves the image prediction task by
training the encoder and decoder together , and does not design a separate task
for the encoder . To further enhance the performance of the encoder when
performing downstream tasks, we designed the encoder for the tasks of
comparative learning and token position prediction. Third, since the input
image may contain background and other objects, and the proportion of each
object in the image varies, reconstructing the tokens related to the background
or to other objects is not meaningful for MIM to understand the main object
representations. Therefore we use ContrastiveCrop to crop the input image so
that the input image contains as much as possible only the main objects. Based
on the above three improvements to MIM, we propose a new model, Contrastive
Masked AutoEncoders (CMAE). We achieved a Top-1 accuracy of 65.84% on
tinyimagenet using the ViT-B backbone, which is +2.89 outperforming the MAE of
competing methods when all conditions are equal. Code will be made available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Three-Dimensional Segmentation of the Left Ventricle in Late Gadolinium Enhanced MR Images of Chronic Infarction Combining Long- and Short-Axis Information. (arXiv:2205.10548v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10548">
<div class="article-summary-box-inner">
<span><p>Automatic segmentation of the left ventricle (LV) in late gadolinium enhanced
(LGE) cardiac MR (CMR) images is difficult due to the intensity heterogeneity
arising from accumulation of contrast agent in infarcted myocardium. In this
paper, we present a comprehensive framework for automatic 3D segmentation of
the LV in LGE CMR images. Given myocardial contours in cine images as a priori
knowledge, the framework initially propagates the a priori segmentation from
cine to LGE images via 2D translational registration. Two meshes representing
respectively endocardial and epicardial surfaces are then constructed with the
propagated contours. After construction, the two meshes are deformed towards
the myocardial edge points detected in both short-axis and long-axis LGE images
in a unified 3D coordinate system. Taking into account the intensity
characteristics of the LV in LGE images, we propose a novel parametric model of
the LV for consistent myocardial edge points detection regardless of
pathological status of the myocardium (infarcted or healthy) and of the type of
the LGE images (short-axis or long-axis). We have evaluated the proposed
framework with 21 sets of real patient and 4 sets of simulated phantom data.
Both distance- and region-based performance metrics confirm the observation
that the framework can generate accurate and reliable results for myocardial
segmentation of LGE images. We have also tested the robustness of the framework
with respect to varied a priori segmentation in both practical and simulated
settings. Experimental results show that the proposed framework can greatly
compensate variations in the given a priori knowledge and consistently produce
accurate segmentations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robot Person Following in Uniform Crowd Environment. (arXiv:2205.10553v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10553">
<div class="article-summary-box-inner">
<span><p>Person-tracking robots have many applications, such as in security, elderly
care, and socializing robots. Such a task is particularly challenging when the
person is moving in a Uniform crowd. Also, despite significant progress of
trackers reported in the literature, state-of-the-art trackers have hardly
addressed person following in such scenarios. In this work, we focus on
improving the perceptivity of a robot for a person following task by developing
a robust and real-time applicable object tracker. We present a new robot person
tracking system with a new RGB-D tracker, Deep Tracking with RGB-D (DTRD) that
is resilient to tricky challenges introduced by the uniform crowd environment.
Our tracker utilizes transformer encoder-decoder architecture with RGB and
depth information to discriminate the target person from similar distractors. A
substantial amount of comprehensive experiments and results demonstrate that
our tracker has higher performance in two quantitative evaluation metrics and
confirms its superiority over other SOTA trackers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cycle-GAN for eye-tracking. (arXiv:2205.10556v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10556">
<div class="article-summary-box-inner">
<span><p>This manuscript presents a not typical implementation of the cycle generative
adversarial networks (Cycle-GAN) method for eye-tracking tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Sign Language Phoneme Clustering using HamNoSys Notation. (arXiv:2205.10560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10560">
<div class="article-summary-box-inner">
<span><p>Traditionally, sign language resources have been collected in controlled
settings for specific tasks involving supervised sign classification or
linguistic studies accompanied by specific annotation type. To date, very few
who explored signing videos found online on social media platforms as well as
the use of unsupervised methods applied to such resources. Due to the fact that
the field is striving to achieve acceptable model performance on the data that
differs from that seen during training calls for more diversity in sign
language data, stepping away from the data obtained in controlled laboratory
settings. Moreover, since the sign language data collection and annotation
carries large overheads, it is desirable to accelerate the annotation process.
Considering the aforementioned tendencies, this paper takes the side of
harvesting online data in a pursuit for automatically generating and annotating
sign language corpora through phoneme clustering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ADT-SSL: Adaptive Dual-Threshold for Semi-Supervised Learning. (arXiv:2205.10571v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10571">
<div class="article-summary-box-inner">
<span><p>Semi-Supervised Learning (SSL) has advanced classification tasks by inputting
both labeled and unlabeled data to train a model jointly. However, existing SSL
methods only consider the unlabeled data whose predictions are beyond a fixed
threshold (e.g., 0.95), ignoring the valuable information from those less than
0.95. We argue that these discarded data have a large proportion and are
usually of hard samples, thereby benefiting the model training. This paper
proposes an Adaptive Dual-Threshold method for Semi-Supervised Learning
(ADT-SSL). Except for the fixed threshold, ADT extracts another class-adaptive
threshold from the labeled data to take full advantage of the unlabeled data
whose predictions are less than 0.95 but more than the extracted one.
Accordingly, we engage CE and $L_2$ loss functions to learn from these two
types of unlabeled data, respectively. For highly similar unlabeled data, we
further design a novel similar loss to make the prediction of the model
consistency. Extensive experiments are conducted on benchmark datasets,
including CIFAR-10, CIFAR-100, and SVHN. Experimental results show that the
proposed ADT-SSL achieves state-of-the-art classification accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive 3-D Framework for Automatic Quantification of Late Gadolinium Enhanced Cardiac Magnetic Resonance Images. (arXiv:2205.10572v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10572">
<div class="article-summary-box-inner">
<span><p>Late gadolinium enhanced (LGE) cardiac magnetic resonance (CMR) can directly
visualize nonviable myocardium with hyperenhanced intensities with respect to
normal myocardium. For heart attack patients, it is crucial to facilitate the
decision of appropriate therapy by analyzing and quantifying their LGE CMR
images. To achieve accurate quantification, LGE CMR images need to be processed
in two steps: segmentation of the myocardium followed by classification of
infarcts within the segmented myocardium. However, automatic segmentation is
difficult usually due to the intensity heterogeneity of the myocardium and
intensity similarity between the infarcts and blood pool. Besides, the slices
of an LGE CMR dataset often suffer from spatial and intensity distortions,
causing further difficulties in segmentation and classification. In this paper,
we present a comprehensive 3-D framework for automatic quantification of LGE
CMR images. In this framework, myocardium is segmented with a novel method that
deforms coupled endocardial and epicardial meshes and combines information in
both short- and long-axis slices, while infarcts are classified with a
graph-cut algorithm incorporating intensity and spatial information. Moreover,
both spatial and intensity distortions are effectively corrected with specially
designed countermeasures. Experiments with 20 sets of real patient data show
visually good segmentation and classification results that are quantitatively
in strong agreement with those manually obtained by experts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-feature Co-learning for Image Inpainting. (arXiv:2205.10578v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10578">
<div class="article-summary-box-inner">
<span><p>Image inpainting has achieved great advances by simultaneously leveraging
image structure and texture features. However, due to lack of effective
multi-feature fusion techniques, existing image inpainting methods still show
limited improvement. In this paper, we design a deep multi-feature co-learning
network for image inpainting, which includes Soft-gating Dual Feature Fusion
(SDFF) and Bilateral Propagation Feature Aggregation (BPFA) modules. To be
specific, we first use two branches to learn structure features and texture
features separately. Then the proposed SDFF module integrates structure
features into texture features, and meanwhile uses texture features as an
auxiliary in generating structure features. Such a co-learning strategy makes
the structure and texture features more consistent. Next, the proposed BPFA
module enhances the connection from local feature to overall consistency by
co-learning contextual attention, channel-wise information and feature space,
which can further refine the generated structures and textures. Finally,
extensive experiments are performed on benchmark datasets, including CelebA,
Places2, and Paris StreetView. Experimental results demonstrate the superiority
of the proposed method over the state-of-the-art. The source codes are
available at https://github.com/GZHU-DVL/MFCL-Inpainting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Camouflaged Object Detection with Dual-Task Interactive Transformer. (arXiv:2205.10579v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10579">
<div class="article-summary-box-inner">
<span><p>Camouflaged object detection intends to discover the concealed objects hidden
in the surroundings. Existing methods follow the bio-inspired framework, which
first locates the object and second refines the boundary. We argue that the
discovery of camouflaged objects depends on the recurrent search for the object
and the boundary. The recurrent processing makes the human tired and helpless,
but it is just the advantage of the transformer with global search ability.
Therefore, a dual-task interactive transformer is proposed to detect both
accurate position of the camouflaged object and its detailed boundary. The
boundary feature is considered as Query to improve the camouflaged object
detection, and meanwhile the object feature is considered as Query to improve
the boundary detection. The camouflaged object detection and the boundary
detection are fully interacted by multi-head self-attention. Besides, to obtain
the initial object feature and boundary feature, transformer-based backbones
are adopted to extract the foreground and background. The foreground is just
object, while foreground minus background is considered as boundary. Here, the
boundary feature can be obtained from blurry boundary region of the foreground
and background. Supervised by the object, the background and the boundary
ground truth, the proposed model achieves state-of-the-art performance in
public datasets. https://github.com/liuzywen/COD
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A comprehensive survey on semantic facial attribute editing using generative adversarial networks. (arXiv:2205.10587v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10587">
<div class="article-summary-box-inner">
<span><p>Generating random photo-realistic images has experienced tremendous growth
during the past few years due to the advances of the deep convolutional neural
networks and generative models. Among different domains, face photos have
received a great deal of attention and a large number of face generation and
manipulation models have been proposed. Semantic facial attribute editing is
the process of varying the values of one or more attributes of a face image
while the other attributes of the image are not affected. The requested
modifications are provided as an attribute vector or in the form of driving
face image and the whole process is performed by the corresponding models. In
this paper, we survey the recent works and advances in semantic facial
attribute editing. We cover all related aspects of these models including the
related definitions and concepts, architectures, loss functions, datasets,
evaluation metrics, and applications. Based on their architectures, the
state-of-the-art models are categorized and studied as encoder-decoder,
image-to-image, and photo-guided models. The challenges and restrictions of the
current state-of-the-art methods are discussed as well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Facing the Void: Overcoming Missing Data in Multi-View Imagery. (arXiv:2205.10592v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10592">
<div class="article-summary-box-inner">
<span><p>In some scenarios, a single input image may not be enough to allow the object
classification. In those cases, it is crucial to explore the complementary
information extracted from images presenting the same object from multiple
perspectives (or views) in order to enhance the general scene understanding
and, consequently, increase the performance. However, this task, commonly
called multi-view image classification, has a major challenge: missing data. In
this paper, we propose a novel technique for multi-view image classification
robust to this problem. The proposed method, based on state-of-the-art deep
learning-based approaches and metric learning, can be easily adapted and
exploited in other applications and domains. A systematic evaluation of the
proposed algorithm was conducted using two multi-view aerial-ground datasets
with very distinct properties. Results show that the proposed algorithm
provides improvements in multi-view image classification accuracy when compared
to state-of-the-art methods. Code available at
\url{https://github.com/Gabriellm2003/remote_sensing_missing_data}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Myocardial Segmentation of Late Gadolinium Enhanced MR Images by Propagation of Contours from Cine MR Images. (arXiv:2205.10595v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10595">
<div class="article-summary-box-inner">
<span><p>Automatic segmentation of myocardium in Late Gadolinium Enhanced (LGE)
Cardiac MR (CMR) images is often difficult due to the intensity heterogeneity
resulting from accumulation of contrast agent in infarcted areas. In this
paper, we propose an automatic segmentation framework that fully utilizes
shared information between corresponding cine and LGE images of a same patient.
Given myocardial contours in cine CMR images, the proposed framework achieves
accurate segmentation of LGE CMR images in a coarse-to-fine manner. Affine
registration is first performed between the corresponding cine and LGE image
pair, followed by nonrigid registration, and finally local deformation of
myocardial contours driven by forces derived from local features of the LGE
image. Experimental results on real patient data with expert outlined ground
truth show that the proposed framework can generate accurate and reliable
results for myocardial segmentation of LGE CMR images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Brain Cortical Functional Gradients Predict Cortical Folding Patterns via Attention Mesh Convolution. (arXiv:2205.10605v1 [q-bio.NC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10605">
<div class="article-summary-box-inner">
<span><p>Since gyri and sulci, two basic anatomical building blocks of cortical
folding patterns, were suggested to bear different functional roles, a precise
mapping from brain function to gyro-sulcal patterns can provide profound
insights into both biological and artificial neural networks. However, there
lacks a generic theory and effective computational model so far, due to the
highly nonlinear relation between them, huge inter-individual variabilities and
a sophisticated description of brain function regions/networks distribution as
mosaics, such that spatial patterning of them has not been considered. we
adopted brain functional gradients derived from resting-state fMRI to embed the
"gradual" change of functional connectivity patterns, and developed a novel
attention mesh convolution model to predict cortical gyro-sulcal segmentation
maps on individual brains. The convolution on mesh considers the spatial
organization of functional gradients and folding patterns on a cortical sheet
and the newly designed channel attention block enhances the interpretability of
the contribution of different functional gradients to cortical folding
prediction. Experiments show that the prediction performance via our model
outperforms other state-of-the-art models. In addition, we found that the
dominant functional gradients contribute less to folding prediction. On the
activation maps of the last layer, some well-studied cortical landmarks are
found on the borders of, rather than within, the highly activated regions.
These results and findings suggest that a specifically designed artificial
neural network can improve the precision of the mapping between brain functions
and cortical folding patterns, and can provide valuable insight of brain
anatomy-function relation for neuroscience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lightweight Human Pose Estimation Using Heatmap-Weighting Loss. (arXiv:2205.10611v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10611">
<div class="article-summary-box-inner">
<span><p>Recent research on human pose estimation exploits complex structures to
improve performance on benchmark datasets, ignoring the resource overhead and
inference speed when the model is actually deployed. In this paper, we lighten
the computation cost and parameters of the deconvolution head network in
SimpleBaseline and introduce an attention mechanism that utilizes original,
inter-level, and intra-level information to intensify the accuracy.
Additionally, we propose a novel loss function called heatmap weighting loss,
which generates weights for each pixel on the heatmap that makes the model more
focused on keypoints. Experiments demonstrate our method achieves a balance
between performance, resource volume, and inference speed. Specifically, our
method can achieve 65.3 AP score on COCO test-dev, while the inference speed is
55 FPS and 18 FPS on the mobile GPU and CPU, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient Concealment: Free Lunch for Defending Adversarial Attacks. (arXiv:2205.10617v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10617">
<div class="article-summary-box-inner">
<span><p>Recent studies show that the deep neural networks (DNNs) have achieved great
success in various tasks. However, even the \emph{state-of-the-art} deep
learning based classifiers are extremely vulnerable to adversarial examples,
resulting in sharp decay of discrimination accuracy in the presence of enormous
unknown attacks. Given the fact that neural networks are widely used in the
open world scenario which can be safety-critical situations, mitigating the
adversarial effects of deep learning methods has become an urgent need.
Generally, conventional DNNs can be attacked with a dramatically high success
rate since their gradient is exposed thoroughly in the white-box scenario,
making it effortless to ruin a well trained classifier with only imperceptible
perturbations in the raw data space. For tackling this problem, we propose a
plug-and-play layer that is training-free, termed as \textbf{G}radient
\textbf{C}oncealment \textbf{M}odule (GCM), concealing the vulnerable direction
of gradient while guaranteeing the classification accuracy during the inference
time. GCM reports superior defense results on the ImageNet classification
benchmark, improving up to 63.41\% top-1 attack robustness (AR) when faced with
adversarial inputs compared to the vanilla DNNs. Moreover, we use GCM in the
CVPR 2022 Robust Classification Challenge, currently achieving \textbf{2nd}
place in Phase II with only a tiny version of ConvNext. The code will be made
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Pilot Study of Relating MYCN-Gene Amplification with Neuroblastoma-Patient CT Scans. (arXiv:2205.10619v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10619">
<div class="article-summary-box-inner">
<span><p>Neuroblastoma is one of the most common cancers in infants, and the initial
diagnosis of this disease is difficult. At present, the MYCN gene amplification
(MNA) status is detected by invasive pathological examination of tumor samples.
This is time-consuming and may have a hidden impact on children. To handle this
problem, we adopt multiple machine learning (ML) algorithms to predict the
presence or absence of MYCN gene amplification. The dataset is composed of
retrospective CT images of 23 neuroblastoma patients. Different from previous
work, we develop the algorithm without manually-segmented primary tumors which
is time-consuming and not practical. Instead, we only need the coordinate of
the center point and the number of tumor slices given by a subspecialty-trained
pediatric radiologist. Specifically, CNN-based method uses pre-trained
convolutional neural network, and radiomics-based method extracts radiomics
features. Our results show that CNN-based method outperforms the
radiomics-based method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoLink: Self-supervised Learning of Human Skeletons and Object Outlines by Linking Keypoints. (arXiv:2205.10636v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10636">
<div class="article-summary-box-inner">
<span><p>Structured representations such as keypoints are widely used in pose
transfer, conditional image generation, animation, and 3D reconstruction.
However, their supervised learning requires expensive annotation for each
target domain. We propose a self-supervised method that learns to disentangle
object structure from the appearance with a graph of 2D keypoints linked by
straight edges. Both the keypoint location and their pairwise edge weights are
learned, given only a collection of images depicting the same object class. The
graph is interpretable, for example, AutoLink recovers the human skeleton
topology when applied to images showing people. Our key ingredients are i) an
encoder that predicts keypoint locations in an input image, ii) a shared graph
as a latent variable that links the same pairs of keypoints in every image,
iii) an intermediate edge map that combines the latent graph edge weights and
keypoint locations in a soft, differentiable manner, and iv) an inpainting
objective on randomly masked images. Although simpler, AutoLink outperforms
existing self-supervised methods on the established keypoint and pose
estimation benchmarks and paves the way for structure-conditioned generative
models on more diverse datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-based out-of-distribution detection for clinically safe segmentation. (arXiv:2205.10650v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10650">
<div class="article-summary-box-inner">
<span><p>In a clinical setting it is essential that deployed image processing systems
are robust to the full range of inputs they might encounter and, in particular,
do not make confidently wrong predictions. The most popular approach to safe
processing is to train networks that can provide a measure of their
uncertainty, but these tend to fail for inputs that are far outside the
training data distribution. Recently, generative modelling approaches have been
proposed as an alternative; these can quantify the likelihood of a data sample
explicitly, filtering out any out-of-distribution (OOD) samples before further
processing is performed. In this work, we focus on image segmentation and
evaluate several approaches to network uncertainty in the far-OOD and near-OOD
cases for the task of segmenting haemorrhages in head CTs. We find all of these
approaches are unsuitable for safe segmentation as they provide confidently
wrong predictions when operating OOD. We propose performing full 3D OOD
detection using a VQ-GAN to provide a compressed latent representation of the
image and a transformer to estimate the data likelihood. Our approach
successfully identifies images in both the far- and near-OOD cases. We find a
strong relationship between image likelihood and the quality of a model's
segmentation, making this approach viable for filtering images unsuitable for
segmentation. To our knowledge, this is the first time transformers have been
applied to perform OOD detection on 3D image data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards real-time and energy efficient Siamese tracking -- a hardware-software approach. (arXiv:2205.10653v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10653">
<div class="article-summary-box-inner">
<span><p>Siamese trackers have been among the state-of-the-art solutions in each
Visual Object Tracking (VOT) challenge over the past few years. However, with
great accuracy comes great computational complexity: to achieve real-time
processing, these trackers have to be massively parallelised and are usually
run on high-end GPUs. Easy to implement, this approach is energy consuming, and
thus cannot be used in many low-power applications. To overcome this, one can
use energy-efficient embedded devices, such as heterogeneous platforms joining
the ARM processor system with programmable logic (FPGA). In this work, we
propose a hardware-software implementation of the well-known fully connected
Siamese tracker (SiamFC). We have developed a quantised Siamese network for the
FINN accelerator, using algorithm-accelerator co-design, and performed design
space exploration to achieve the best efficiency-to-energy ratio (determined by
FPS and used resources). For our network, running in the programmable logic
part of the Zynq UltraScale+ MPSoC ZCU104, we achieved the processing of almost
50 frames-per-second with tracker accuracy on par with its floating point
counterpart, as well as the original SiamFC network. The complete tracking
system, implemented in ARM with the network accelerated on FPGA, achieves up to
17 fps. These results bring us towards bridging the gap between the highly
accurate but energy-demanding algorithms and energy-efficient solutions ready
to be used in low-power, edge systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Swept-Angle Synthetic Wavelength Interferometry. (arXiv:2205.10655v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10655">
<div class="article-summary-box-inner">
<span><p>We present a new imaging technique, swept-angle synthetic wavelength
interferometry, for full-field micron-scale 3D sensing. As in conventional
synthetic wavelength interferometry, our technique uses light consisting of two
optical wavelengths, resulting in per-pixel interferometric measurements whose
phase encodes scene depth. Our technique additionally uses a new type of light
source that, by emulating spatially-incoherent illumination, makes
interferometric measurements insensitive to global illumination effects that
confound depth information. The resulting technique combines the speed of
full-field interferometric setups with the robustness to global illumination of
scanning interferometric setups. Overall, our technique can recover full-frame
depth at a spatial and axial resolution of a few micrometers using as few as 16
measurements, resulting in fast acquisition at frame rates of 10 Hz. We build
an experimental prototype and use it to demonstrate these capabilities, by
scanning a variety of scenes that contain challenging light transport effects
such as interreflections, subsurface scattering, and specularities. We validate
the accuracy of our measurements by showing that they closely match reference
measurements from a full-field optical coherence tomography system, despite
being captured at orders of magnitude faster acquisition times and while
operating under strong ambient light.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Transformers in 2022: An Update on Tiny ImageNet. (arXiv:2205.10660v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10660">
<div class="article-summary-box-inner">
<span><p>The recent advances in image transformers have shown impressive results and
have largely closed the gap between traditional CNN architectures. The standard
procedure is to train on large datasets like ImageNet-21k and then finetune on
ImageNet-1k. After finetuning, researches will often consider the transfer
learning performance on smaller datasets such as CIFAR-10/100 but have left out
Tiny ImageNet. This paper offers an update on vision transformers' performance
on Tiny ImageNet. I include Vision Transformer (ViT) , Data Efficient Image
Transformer (DeiT), Class Attention in Image Transformer (CaiT), and Swin
Transformers. In addition, Swin Transformers beats the current state-of-the-art
result with a validation accuracy of 91.35%. Code is available here:
https://github.com/ehuynh1106/TinyImageNet-Transformers
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Equivariant Mesh Attention Networks. (arXiv:2205.10662v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10662">
<div class="article-summary-box-inner">
<span><p>Equivariance to symmetries has proven to be a powerful inductive bias in deep
learning research. Recent works on mesh processing have concentrated on various
kinds of natural symmetries, including translations, rotations, scaling, node
permutations, and gauge transformations. To date, no existing architecture is
equivariant to all of these transformations. Moreover, previous implementations
have not always applied these symmetry transformations to the test dataset.
This inhibits the ability to determine whether the model attains the claimed
equivariance properties. In this paper, we present an attention-based
architecture for mesh data that is provably equivariant to all transformations
mentioned above. We carry out experiments on the FAUST and TOSCA datasets, and
apply the mentioned symmetries to the test set only. Our results confirm that
our proposed architecture is equivariant, and therefore robust, to these
local/global transformations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer based Generative Adversarial Network for Liver Segmentation. (arXiv:2205.10663v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10663">
<div class="article-summary-box-inner">
<span><p>Automated liver segmentation from radiology scans (CT, MRI) can improve
surgery and therapy planning and follow-up assessment in addition to
conventional use for diagnosis and prognosis. Although convolutional neural
networks (CNNs) have become the standard image segmentation tasks, more
recently this has started to change towards Transformers based architectures
because Transformers are taking advantage of capturing long range dependence
modeling capability in signals, so called attention mechanism. In this study,
we propose a new segmentation approach using a hybrid approach combining the
Transformer(s) with the Generative Adversarial Network (GAN) approach. The
premise behind this choice is that the self-attention mechanism of the
Transformers allows the network to aggregate the high dimensional feature and
provide global information modeling. This mechanism provides better
segmentation performance compared with traditional methods. Furthermore, we
encode this generator into the GAN based architecture so that the discriminator
network in the GAN can classify the credibility of the generated segmentation
masks compared with the real masks coming from human (expert) annotations. This
allows us to extract the high dimensional topology information in the mask for
biomedical image segmentation and provide more reliable segmentation results.
Our model achieved a high dice coefficient of 0.9433, recall of 0.9515, and
precision of 0.9376 and outperformed other Transformer based approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Individual Topology Structure of Eye Movement Trajectories. (arXiv:2205.10667v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10667">
<div class="article-summary-box-inner">
<span><p>Traditionally, extracting patterns from eye movement data relies on
statistics of different macro-events such as fixations and saccades. This
requires an additional preprocessing step to separate the eye movement
subtypes, often with a number of parameters on which the classification results
depend. Besides that, definitions of such macro events are formulated in
different ways by different researchers.
</p>
<p>We propose an application of a new class of features to the quantitative
analysis of personal eye movement trajectories structure. This new class of
features based on algebraic topology allows extracting patterns from different
modalities of gaze such as time series of coordinates and amplitudes, heatmaps,
and point clouds in a unified way at all scales from micro to macro. We
experimentally demonstrate the competitiveness of the new class of features
with the traditional ones and their significant synergy while being used
together for the person authentication task on the recently published eye
movement trajectories dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable and Efficient Training of Large Convolutional Neural Networks with Differential Privacy. (arXiv:2205.10683v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10683">
<div class="article-summary-box-inner">
<span><p>Large convolutional neural networks (CNN) can be difficult to train in the
differentially private (DP) regime, since the optimization algorithms require a
computationally expensive operation, known as the per-sample gradient clipping.
We propose an efficient and scalable implementation of this clipping on
convolutional layers, termed as the mixed ghost clipping, that significantly
eases the private training in terms of both time and space complexities,
without affecting the accuracy. The improvement in efficiency is rigorously
studied through the first complexity analysis for the mixed ghost clipping and
existing DP training algorithms.
</p>
<p>Extensive experiments on vision classification tasks, with large ResNet, VGG,
and Vision Transformers, demonstrate that DP training with mixed ghost clipping
adds $1\sim 10\%$ memory overhead and $&lt;2\times$ slowdown to the standard
non-private training. Specifically, when training VGG19 on CIFAR10, the mixed
ghost clipping is $3\times$ faster than state-of-the-art Opacus library with
$18\times$ larger maximum batch size. To emphasize the significance of
efficient DP training on convolutional layers, we achieve 96.7\% accuracy on
CIFAR10 and 83.0\% on CIFAR100 at $\epsilon=1$ using BEiT, while the previous
best results are 94.8\% and 67.4\%, respectively. We open-source a privacy
engine (\url{https://github.com/JialinMao/private_CNN}) that implements DP
training of CNN with a few lines of code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Producing Histopathology Phantom Images using Generative Adversarial Networks to improve Tumor Detection. (arXiv:2205.10691v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10691">
<div class="article-summary-box-inner">
<span><p>Advance in medical imaging is an important part in deep learning research.
One of the goals of computer vision is development of a holistic, comprehensive
model which can identify tumors from histology slides obtained via biopsies. A
major problem that stands in the way is lack of data for a few cancer-types. In
this paper, we ascertain that data augmentation using GANs can be a viable
solution to reduce the unevenness in the distribution of different cancer types
in our dataset. Our demonstration showed that a dataset augmented to a 50%
increase causes an increase in tumor detection from 80% to 87.5%
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GL-RG: Global-Local Representation Granularity for Video Captioning. (arXiv:2205.10706v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10706">
<div class="article-summary-box-inner">
<span><p>Video captioning is a challenging task as it needs to accurately transform
visual understanding into natural language description. To date,
state-of-the-art methods inadequately model global-local representation across
video frames for caption generation, leaving plenty of room for improvement. In
this work, we approach the video captioning task from a new perspective and
propose a GL-RG framework for video captioning, namely a
\textbf{G}lobal-\textbf{L}ocal \textbf{R}epresentation \textbf{G}ranularity.
Our GL-RG demonstrates three advantages over the prior efforts: 1) we
explicitly exploit extensive visual representations from different video ranges
to improve linguistic expression; 2) we devise a novel global-local encoder to
produce rich semantic vocabulary to obtain a descriptive granularity of video
contents across frames; 3) we develop an incremental training strategy which
organizes model learning in an incremental fashion to incur an optimal
captioning behavior. Experimental results on the challenging MSR-VTT and MSVD
datasets show that our DL-RG outperforms recent state-of-the-art methods by a
significant margin. Code is available at \url{https://github.com/ylqi/GL-RG}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Housekeep: Tidying Virtual Households using Commonsense Reasoning. (arXiv:2205.10712v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10712">
<div class="article-summary-box-inner">
<span><p>We introduce Housekeep, a benchmark to evaluate commonsense reasoning in the
home for embodied AI. In Housekeep, an embodied agent must tidy a house by
rearranging misplaced objects without explicit instructions specifying which
objects need to be rearranged. Instead, the agent must learn from and is
evaluated against human preferences of which objects belong where in a tidy
house. Specifically, we collect a dataset of where humans typically place
objects in tidy and untidy houses constituting 1799 objects, 268 object
categories, 585 placements, and 105 rooms. Next, we propose a modular baseline
approach for Housekeep that integrates planning, exploration, and navigation.
It leverages a fine-tuned large language model (LLM) trained on an internet
text corpus for effective planning. We show that our baseline agent generalizes
to rearranging unseen objects in unknown environments. See our webpage for more
details: https://yashkant.github.io/housekeep/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learnable Visual Words for Interpretable Image Recognition. (arXiv:2205.10724v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10724">
<div class="article-summary-box-inner">
<span><p>To interpret deep models' predictions, attention-based visual cues are widely
used in addressing \textit{why} deep models make such predictions. Beyond that,
the current research community becomes more interested in reasoning
\textit{how} deep models make predictions, where some prototype-based methods
employ interpretable representations with their corresponding visual cues to
reveal the black-box mechanism of deep model behaviors. However, these
pioneering attempts only either learn the category-specific prototypes and
deteriorate their generalizing capacities, or demonstrate several illustrative
examples without a quantitative evaluation of visual-based interpretability
with further limitations on their practical usages. In this paper, we revisit
the concept of visual words and propose the Learnable Visual Words (LVW) to
interpret the model prediction behaviors with two novel modules: semantic
visual words learning and dual fidelity preservation. The semantic visual words
learning relaxes the category-specific constraint, enabling the general visual
words shared across different categories. Beyond employing the visual words for
prediction to align visual words with the base model, our dual fidelity
preservation also includes the attention guided semantic alignment that
encourages the learned visual words to focus on the same conceptual regions for
prediction. Experiments on six visual benchmarks demonstrate the superior
effectiveness of our proposed LVW in both accuracy and model interpretation
over the state-of-the-art methods. Moreover, we elaborate on various in-depth
analyses to further explore the learned visual words and the generalizability
of our method for unseen categories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OTAdapt: Optimal Transport-based Approach For Unsupervised Domain Adaptation. (arXiv:2205.10738v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10738">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation is one of the challenging problems in computer
vision. This paper presents a novel approach to unsupervised domain adaptations
based on the optimal transport-based distance. Our approach allows aligning
target and source domains without the requirement of meaningful metrics across
domains. In addition, the proposal can associate the correct mapping between
source and target domains and guarantee a constraint of topology between source
and target domains. The proposed method is evaluated on different datasets in
various problems, i.e. (i) digit recognition on MNIST, MNIST-M, USPS datasets,
(ii) Object recognition on Amazon, Webcam, DSLR, and VisDA datasets, (iii)
Insect Recognition on the IP102 dataset. The experimental results show that our
proposed method consistently improves performance accuracy. Also, our framework
could be incorporated with any other CNN frameworks within an end-to-end deep
network design for recognition problems to improve their performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of Quasars, Galaxies, and Stars in the Mapping of the Universe Multi-modal Deep Learning. (arXiv:2205.10745v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10745">
<div class="article-summary-box-inner">
<span><p>In this paper, the fourth version the Sloan Digital Sky Survey (SDSS-4), Data
Release 16 dataset was used to classify the SDSS dataset into galaxies, stars,
and quasars using machine learning and deep learning architectures. We
efficiently utilize both image and metadata in tabular format to build a novel
multi-modal architecture and achieve state-of-the-art results. In addition, our
experiments on transfer learning using Imagenet weights on five different
architectures (Resnet-50, DenseNet-121 VGG-16, Xception, and EfficientNet)
reveal that freezing all layers and adding a final trainable layer may not be
an optimal solution for transfer learning. It is hypothesized that higher the
number of trainable layers, higher will be the training time and accuracy of
predictions. It is also hypothesized that any subsequent increase in the number
of training layers towards the base layers will not increase in accuracy as the
pre trained lower layers only help in low level feature extraction which would
be quite similar in all the datasets. Hence the ideal level of trainable layers
needs to be identified for each model in respect to the number of parameters.
For the tabular data, we compared classical machine learning algorithms
(Logistic Regression, Random Forest, Decision Trees, Adaboost, LightGBM etc.,)
with artificial neural networks. Our works shed new light on transfer learning
and multi-modal deep learning architectures. The multi-modal architecture not
only resulted in higher metrics (accuracy, precision, recall, F1 score) than
models using only image data or tabular data. Furthermore, multi-modal
architecture achieved the best metrics in lesser training epochs and improved
the metrics on all classes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners. (arXiv:2205.10747v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10747">
<div class="article-summary-box-inner">
<span><p>The goal of this work is to build flexible video-language models that can
generalize to various video-to-text tasks from few examples, such as
domain-specific captioning, question answering, and future event prediction.
Existing few-shot video-language learners focus exclusively on the encoder,
resulting in the absence of a video-to-text decoder to handle generative tasks.
Video captioners have been pretrained on large-scale video-language datasets,
but they rely heavily on finetuning and lack the ability to generate text for
unseen tasks in a few-shot setting. We propose VidIL, a few-shot Video-language
Learner via Image and Language models, which demonstrates strong performance on
few-shot video-to-text tasks without the necessity of pretraining or finetuning
on any video datasets. We use the image-language models to translate the video
content into frame captions, object, attribute, and event phrases, and compose
them into a temporal structure template. We then instruct a language model,
with a prompt containing a few in-context examples, to generate a target output
from the composed content. The flexibility of prompting allows the model to
capture any form of text input, such as automatic speech recognition (ASR)
transcripts. Our experiments demonstrate the power of language models in
understanding videos on a wide variety of video-language tasks, including video
captioning, video question answering, video caption retrieval, and video future
event prediction. Especially, on video future event prediction, our few-shot
model significantly outperforms state-of-the-art supervised models trained on
large-scale video datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Preparing data for pathological artificial intelligence with clinical-grade performance. (arXiv:2205.10748v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10748">
<div class="article-summary-box-inner">
<span><p>[Purpose] The pathology is decisive for disease diagnosis, but relies heavily
on the experienced pathologists. Recently, pathological artificial intelligence
(PAI) is thought to improve diagnostic accuracy and efficiency. However, the
high performance of PAI based on deep learning in the laboratory generally
cannot be reproduced in the clinic. [Methods] Because the data preparation is
important for PAI, the paper has reviewed PAI-related studies in the PubMed
database published from January 2017 to February 2022, and 118 studies were
included. The in-depth analysis of methods for preparing data is performed,
including obtaining slides of pathological tissue, cleaning, screening, and
then digitizing. Expert review, image annotation, dataset division for model
training and validation are also discussed. We further discuss the reasons why
the high performance of PAI is not reproducible in the clinical practices and
show some effective ways to improve clinical performances of PAI. [Results] The
robustness of PAI depend on randomized collection of representative disease
slides, including rigorous quality control and screening, correction of digital
discrepancies, reasonable annotation, and the amount of data. The digital
pathology is fundamental of clinical-grade PAI, and the techniques of data
standardization and weakly supervised learning methods based on whole slide
image (WSI) are effective ways to overcome obstacles of performance
reproduction. [Conclusion] The representative data, the amount of labeling and
consistency from multi-centers is the key to performance reproduction. The
digital pathology for clinical diagnosis, data standardization and technique of
WSI-based weakly supervised learning hopefully build clinical-grade PAI.
Keywords: pathological artificial intelligence; data preparation;
clinical-grade; deep learning
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real Time Detection Free Tracking of Multiple Objects Via Equilibrium Optimizer. (arXiv:2205.10756v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10756">
<div class="article-summary-box-inner">
<span><p>Multiple objects tracking (MOT) is a difficult task, as it usually requires
special hardware and higher computation complexity. In this work, we present a
new framework of MOT by using of equilibrium optimizer (EO) algorithm and
reducing the resolution of the bounding boxes of the objects to solve such
problems in the detection free framework. First, in the first frame the target
objects are initialized and its size is computed, then its resolution is
reduced if it is higher than a threshold, and then modeled by their kernel
color histogram to establish a feature model. The Bhattacharya distances
between the histogram of object models and other candidates are used as the
fitness function to be optimized. Multiple agents are generated by EO,
according to the number of the target objects to be tracked. EO algorithm is
used because of its efficiency and lower computation cost compared to other
algorithms in global optimization. Experimental results confirm that EO
multi-object tracker achieves satisfying tracking results then other trackers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Feature Fusion via Graph Convolutional Network for Intracranial Artery Labeling. (arXiv:2205.10757v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10757">
<div class="article-summary-box-inner">
<span><p>Intracranial arteries are critical blood vessels that supply the brain with
oxygenated blood. Intracranial artery labels provide valuable guidance and
navigation to numerous clinical applications and disease diagnoses. Various
machine learning algorithms have been carried out for automation in the
anatomical labeling of cerebral arteries. However, the task remains challenging
because of the high complexity and variations of intracranial arteries. This
study investigates a novel graph convolutional neural network with deep feature
fusion for cerebral artery labeling. We introduce stacked graph convolutions in
an encoder-core-decoder architecture, extracting high-level representations
from graph nodes and their neighbors. Furthermore, we efficiently aggregate
intermediate features from different hierarchies to enhance the proposed
model's representation capability and labeling performance. We perform
extensive experiments on public datasets, in which the results prove the
superiority of our approach over baselines by a clear margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Residual Channel Attention Network for Brain Glioma Segmentation. (arXiv:2205.10758v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10758">
<div class="article-summary-box-inner">
<span><p>A glioma is a malignant brain tumor that seriously affects cognitive
functions and lowers patients' life quality. Segmentation of brain glioma is
challenging because of interclass ambiguities in tumor regions. Recently, deep
learning approaches have achieved outstanding performance in the automatic
segmentation of brain glioma. However, existing algorithms fail to exploit
channel-wise feature interdependence to select semantic attributes for glioma
segmentation. In this study, we implement a novel deep neural network that
integrates residual channel attention modules to calibrate intermediate
features for glioma segmentation. The proposed channel attention mechanism
adaptively weights feature channel-wise to optimize the latent representation
of gliomas. We evaluate our method on the established dataset BraTS2017.
Experimental results indicate the superiority of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CNNs are Myopic. (arXiv:2205.10760v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10760">
<div class="article-summary-box-inner">
<span><p>We claim that Convolutional Neural Networks (CNNs) learn to classify images
using only small seemingly unrecognizable tiles. We show experimentally that
CNNs trained only using such tiles can match or even surpass the performance of
CNNs trained on full images. Conversely, CNNs trained on full images show
similar predictions on small tiles. We also propose the first a priori
theoretical model for convolutional data sets that seems to explain this
behavior. This gives additional support to the long standing suspicion that
CNNs do not need to understand the global structure of images to achieve
state-of-the-art accuracies. Surprisingly it also suggests that over-fitting is
not needed either.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evidence for Hypodescent in Visual Semantic AI. (arXiv:2205.10764v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10764">
<div class="article-summary-box-inner">
<span><p>We examine the state-of-the-art multimodal "visual semantic" model CLIP
("Contrastive Language Image Pretraining") for the rule of hypodescent, or
one-drop rule, whereby multiracial people are more likely to be assigned a
racial or ethnic label corresponding to a minority or disadvantaged racial or
ethnic group than to the equivalent majority or advantaged group. A face
morphing experiment grounded in psychological research demonstrating
hypodescent indicates that, at the midway point of 1,000 series of morphed
images, CLIP associates 69.7% of Black-White female images with a Black text
label over a White text label, and similarly prefers Latina (75.8%) and Asian
(89.1%) text labels at the midway point for Latina-White female and Asian-White
female morphs, reflecting hypodescent. Additionally, assessment of the
underlying cosine similarities in the model reveals that association with White
is correlated with association with "person," with Pearson's rho as high as
0.82 over a 21,000-image morph series, indicating that a White person
corresponds to the default representation of a person in CLIP. Finally, we show
that the stereotype-congruent pleasantness association of an image correlates
with association with the Black text label in CLIP, with Pearson's rho = 0.48
for 21,000 Black-White multiracial male images, and rho = 0.41 for Black-White
multiracial female images. CLIP is trained on English-language text gathered
using data collected from an American website (Wikipedia), and our findings
demonstrate that CLIP embeds the values of American racial hierarchy,
reflecting the implicit and explicit beliefs that are present in human minds.
We contextualize these findings within the history and psychology of
hypodescent. Overall, the data suggests that AI supervised using natural
language will, unless checked, learn biases that reflect racial hierarchies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recent Advances in Embedding Methods for Multi-Object Tracking: A Survey. (arXiv:2205.10766v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10766">
<div class="article-summary-box-inner">
<span><p>Multi-object tracking (MOT) aims to associate target objects across video
frames in order to obtain entire moving trajectories. With the advancement of
deep neural networks and the increasing demand for intelligent video analysis,
MOT has gained significantly increased interest in the computer vision
community. Embedding methods play an essential role in object location
estimation and temporal identity association in MOT. Unlike other computer
vision tasks, such as image classification, object detection,
re-identification, and segmentation, embedding methods in MOT have large
variations, and they have never been systematically analyzed and summarized. In
this survey, we first conduct a comprehensive overview with in-depth analysis
for embedding methods in MOT from seven different perspectives, including
patch-level embedding, single-frame embedding, cross-frame joint embedding,
correlation embedding, sequential embedding, tracklet embedding, and
cross-track relational embedding. We further summarize the existing widely used
MOT datasets and analyze the advantages of existing state-of-the-art methods
according to their embedding strategies. Finally, some critical yet
under-investigated areas and future research directions are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Instance Matting via Mutual Guidance and Multi-Instance Refinement. (arXiv:2205.10767v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10767">
<div class="article-summary-box-inner">
<span><p>This paper introduces a new matting task called human instance matting (HIM),
which requires the pertinent model to automatically predict a precise alpha
matte for each human instance. Straightforward combination of closely related
techniques, namely, instance segmentation, soft segmentation and
human/conventional matting, will easily fail in complex cases requiring
disentangling mingled colors belonging to multiple instances along hairy and
thin boundary structures. To tackle these technical challenges, we propose a
human instance matting framework, called InstMatt, where a novel mutual
guidance strategy working in tandem with a multi-instance refinement module is
used, for delineating multi-instance relationship among humans with complex and
overlapping boundaries if present. A new instance matting metric called
instance matting quality (IMQ) is proposed, which addresses the absence of a
unified and fair means of evaluation emphasizing both instance recognition and
matting quality. Finally, we construct a HIM benchmark for evaluation, which
comprises of both synthetic and natural benchmark images. In addition to
thorough experimental results on complex cases with multiple and overlapping
human instances each has intricate boundaries, preliminary results are
presented on general instance matting. Code and benchmark are available in
https://github.com/nowsyn/InstMatt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Muti-expert Distribution Calibration for Long-tailed Video Classification. (arXiv:2205.10788v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10788">
<div class="article-summary-box-inner">
<span><p>Most existing state-of-the-art video classification methods assume the
training data obey a uniform distribution. However, video data in the real
world typically exhibit long-tail class distribution and imbalance, which
extensively results in a model bias towards head class and leads to relatively
low performance on tail class. While the current long-tail classification
methods usually focus on image classification, adapting it to video data is not
a trivial extension. We propose an end-to-end multi-experts distribution
calibration method based on two-level distribution information to address these
challenges. The method jointly considers the distribution of samples in each
class (intra-class distribution) and the diverse distributions of overall data
(inter-class distribution) to solve the problem of imbalanced data under
long-tailed distribution. By modeling this two-level distribution information,
the model can consider the head classes and the tail classes and significantly
transfer the knowledge from the head classes to improve the performance of the
tail classes. Extensive experiments verify that our method achieves
state-of-the-art performance on the long-tailed video classification task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Distillation via the Target-aware Transformer. (arXiv:2205.10793v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10793">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation becomes a de facto standard to improve the performance
of small neural networks. Most of the previous works propose to regress the
representational features from the teacher to the student in a one-to-one
spatial matching fashion. However, people tend to overlook the fact that, due
to the architecture differences, the semantic information on the same spatial
location usually vary. This greatly undermines the underlying assumption of the
one-to-one distillation approach. To this end, we propose a novel one-to-all
spatial matching knowledge distillation approach. Specifically, we allow each
pixel of the teacher feature to be distilled to all spatial locations of the
student features given its similarity, which is generated from a target-aware
transformer. Our approach surpasses the state-of-the-art methods by a
significant margin on various computer vision benchmarks, such as ImageNet,
Pascal VOC and COCOStuff10k. Code will be released soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReLU Fields: The Little Non-linearity That Could. (arXiv:2205.10824v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10824">
<div class="article-summary-box-inner">
<span><p>In many recent works, multi-layer perceptions (MLPs) have been shown to be
suitable for modeling complex spatially-varying functions including images and
3D scenes. Although the MLPs are able to represent complex scenes with
unprecedented quality and memory footprint, this expressive power of the MLPs,
however, comes at the cost of long training and inference times. On the other
hand, bilinear/trilinear interpolation on regular grid based representations
can give fast training and inference times, but cannot match the quality of
MLPs without requiring significant additional memory. Hence, in this work, we
investigate what is the smallest change to grid-based representations that
allows for retaining the high fidelity result of MLPs while enabling fast
reconstruction and rendering times. We introduce a surprisingly simple change
that achieves this task -- simply allowing a fixed non-linearity (ReLU) on
interpolated grid values. When combined with coarse to-fine optimization, we
show that such an approach becomes competitive with the state-of-the-art. We
report results on radiance fields, and occupancy fields, and compare against
multiple existing alternatives. Code and data for the paper are available at
https://geometry.cs.ucl.ac.uk/projects/2022/relu_fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grad-CAM++ is Equivalent to Grad-CAM With Positive Gradients. (arXiv:2205.10838v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10838">
<div class="article-summary-box-inner">
<span><p>The Grad-CAM algorithm provides a way to identify what parts of an image
contribute most to the output of a classifier deep network. The algorithm is
simple and widely used for localization of objects in an image, although some
researchers have point out its limitations, and proposed various alternatives.
One of them is Grad-CAM++, that according to its authors can provide better
visual explanations for network predictions, and does a better job at locating
objects even for occurrences of multiple object instances in a single image.
Here we show that Grad-CAM++ is practically equivalent to a very simple
variation of Grad-CAM in which gradients are replaced with positive gradients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Visual Speech Analysis: A Survey. (arXiv:2205.10839v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10839">
<div class="article-summary-box-inner">
<span><p>Visual speech, referring to the visual domain of speech, has attracted
increasing attention due to its wide applications, such as public security,
medical treatment, military defense, and film entertainment. As a powerful AI
strategy, deep learning techniques have extensively promoted the development of
visual speech learning. Over the past five years, numerous deep learning based
methods have been proposed to address various problems in this area, especially
automatic visual speech recognition and generation. To push forward future
research on visual speech, this paper aims to present a comprehensive review of
recent progress in deep learning methods on visual speech analysis. We cover
different aspects of visual speech, including fundamental problems, challenges,
benchmark datasets, a taxonomy of existing methods, and state-of-the-art
performance. Besides, we also identify gaps in current research and discuss
inspiring future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised U-net for few-shot learning of object segmentation in microscopy images. (arXiv:2205.10840v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10840">
<div class="article-summary-box-inner">
<span><p>State-of-the-art segmentation performances are achieved by deep neural
networks. Training these networks from only a few training examples is
challenging while producing annotated images that provide supervision is
tedious. Recently, self-supervision, i.e. designing a neural pipeline providing
synthetic or indirect supervision, has proved to significantly increase
generalization performances of models trained on few shots. This paper
introduces one such neural pipeline in the context of microscopic image
segmentation. By leveraging the rather simple content of these images a trainee
network can be mentored by a referee network which has been previously trained
on synthetically generated pairs of corrupted/correct region masks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Road surface 3d reconstruction based on dense subpixel disparity map estimation. (arXiv:1807.01874v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1807.01874">
<div class="article-summary-box-inner">
<span><p>Various 3D reconstruction methods have enabled civil engineers to detect
damage on a road surface. To achieve the millimetre accuracy required for road
condition assessment, a disparity map with subpixel resolution needs to be
used. However, none of the existing stereo matching algorithms are specially
suitable for the reconstruction of the road surface. Hence in this paper, we
propose a novel dense subpixel disparity estimation algorithm with high
computational efficiency and robustness. This is achieved by first transforming
the perspective view of the target frame into the reference view, which not
only increases the accuracy of the block matching for the road surface but also
improves the processing speed. The disparities are then estimated iteratively
using our previously published algorithm where the search range is propagated
from three estimated neighbouring disparities. Since the search range is
obtained from the previous iteration, errors may occur when the propagated
search range is not sufficient. Therefore, a correlation maxima verification is
performed to rectify this issue, and the subpixel resolution is achieved by
conducting a parabola interpolation enhancement. Furthermore, a novel disparity
global refinement approach developed from the Markov Random Fields and Fast
Bilateral Stereo is introduced to further improve the accuracy of the estimated
disparity map, where disparities are updated iteratively by minimising the
energy function that is related to their interpolated correlation polynomials.
The algorithm is implemented in C language with a near real-time performance.
The experimental results illustrate that the absolute error of the
reconstruction varies from 0.1 mm to 3 mm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pothole Detection Based on Disparity Transformation and Road Surface Modeling. (arXiv:1908.00894v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.00894">
<div class="article-summary-box-inner">
<span><p>Pothole detection is one of the most important tasks for road maintenance.
Computer vision approaches are generally based on either 2D road image analysis
or 3D road surface modeling. However, these two categories are always used
independently. Furthermore, the pothole detection accuracy is still far from
satisfactory. Therefore, in this paper, we present a robust pothole detection
algorithm that is both accurate and computationally efficient. A dense
disparity map is first transformed to better distinguish between damaged and
undamaged road areas. To achieve greater disparity transformation efficiency,
golden section search and dynamic programming are utilized to estimate the
transformation parameters. Otsu's thresholding method is then used to extract
potential undamaged road areas from the transformed disparity map. The
disparities in the extracted areas are modeled by a quadratic surface using
least squares fitting. To improve disparity map modeling robustness, the
surface normal is also integrated into the surface modeling process.
Furthermore, random sample consensus is utilized to reduce the effects caused
by outliers. By comparing the difference between the actual and modeled
disparity maps, the potholes can be detected accurately. Finally, the point
clouds of the detected potholes are extracted from the reconstructed 3D road
surface. The experimental results show that the successful detection accuracy
of the proposed system is around 98.7% and the overall pixel-level accuracy is
approximately 99.6%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RGBT Salient Object Detection: A Large-scale Dataset and Benchmark. (arXiv:2007.03262v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03262">
<div class="article-summary-box-inner">
<span><p>Salient object detection in complex scenes and environments is a challenging
research topic. Most works focus on RGB-based salient object detection, which
limits its performance of real-life applications when confronted with adverse
conditions such as dark environments and complex backgrounds. Taking advantage
of RGB and thermal infrared images becomes a new research direction for
detecting salient object in complex scenes recently, as thermal infrared
spectrum imaging provides the complementary information and has been applied to
many computer vision tasks. However, current research for RGBT salient object
detection is limited by the lack of a large-scale dataset and comprehensive
benchmark. This work contributes such a RGBT image dataset named VT5000,
including 5000 spatially aligned RGBT image pairs with ground truth
annotations. VT5000 has 11 challenges collected in different scenes and
environments for exploring the robustness of algorithms. With this dataset, we
propose a powerful baseline approach, which extracts multi-level features
within each modality and aggregates these features of all modalities with the
attention mechanism, for accurate RGBT salient object detection. Extensive
experiments show that the proposed baseline approach outperforms the
state-of-the-art methods on VT5000 dataset and other two public datasets. In
addition, we carry out a comprehensive analysis of different algorithms of RGBT
salient object detection on VT5000 dataset, and then make several valuable
conclusions and provide some potential research directions for RGBT salient
object detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bayesian Multi Scale Neural Network for Crowd Counting. (arXiv:2007.14245v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14245">
<div class="article-summary-box-inner">
<span><p>Crowd Counting is a difficult but important problem in computer vision.
Convolutional Neural Networks based on estimating the density map over the
image has been highly successful in this domain. However dense crowd counting
remains an open problem because of severe occlusion and perspective view in
which people can be present at various sizes. In this work, we propose a new
network which uses a ResNet based feature extractor, downsampling block which
uses dilated convolutions and upsampling block using transposed convolutions.
We present a novel aggregation module which makes our network robust to the
perspective view problem. We present the optimization details, loss functions
and the algorithm used in our work. On evaluating on ShanghaiTech, UCF-CC-50
and UCF-QNRF datasets using MSE and MAE as evaluation metrics, our network
outperforms previous state of the art approaches while giving uncertainty
estimates in a principled bayesian manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">D-Unet: A Dual-encoder U-Net for Image Splicing Forgery Detection and Localization. (arXiv:2012.01821v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01821">
<div class="article-summary-box-inner">
<span><p>Recently, many detection methods based on convolutional neural networks
(CNNs) have been proposed for image splicing forgery detection. Most of these
detection methods focus on the local patches or local objects. In fact, image
splicing forgery detection is a global binary classification task that
distinguishes the tampered and non-tampered regions by image fingerprints.
However, some specific image contents are hardly retained by CNN-based
detection networks, but if included, would improve the detection accuracy of
the networks. To resolve these issues, we propose a novel network called
dual-encoder U-Net (D-Unet) for image splicing forgery detection, which employs
an unfixed encoder and a fixed encoder. The unfixed encoder autonomously learns
the image fingerprints that differentiate between the tampered and non-tampered
regions, whereas the fixed encoder intentionally provides the direction
information that assists the learning and detection of the network. This
dual-encoder is followed by a spatial pyramid global-feature extraction module
that expands the global insight of D-Unet for classifying the tampered and
non-tampered regions more accurately. In an experimental comparison study of
D-Unet and state-of-the-art methods, D-Unet outperformed the other methods in
image-level and pixel-level detection, without requiring pre-training or
training on a large number of forgery images. Moreover, it was stably robust to
different attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tasting the cake: evaluating self-supervised generalization on out-of-distribution multimodal MRI data. (arXiv:2103.15914v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15914">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning has enabled significant improvements on natural
image benchmarks. However, there is less work in the medical imaging domain in
this area. The optimal models have not yet been determined among the various
options. Moreover, little work has evaluated the current applicability limits
of novel self-supervised methods. In this paper, we evaluate a range of current
contrastive self-supervised methods on out-of-distribution generalization in
order to evaluate their applicability to medical imaging. We show that
self-supervised models are not as robust as expected based on their results in
natural imaging benchmarks and can be outperformed by supervised learning with
dropout. We also show that this behavior can be countered with extensive
augmentation. Our results highlight the need for out-of-distribution
generalization standards and benchmarks to adopt the self-supervised methods in
the medical imaging community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diverse Gaussian Noise Consistency Regularization for Robustness and Uncertainty Calibration. (arXiv:2104.01231v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01231">
<div class="article-summary-box-inner">
<span><p>Deep neural networks achieve high prediction accuracy when the train and test
distributions coincide. In practice though, various types of corruptions occur
which deviate from this setup and cause severe performance degradations. Few
methods have been proposed to address generalization in the presence of
unforeseen domain shifts. In particular, digital noise corruptions arise
commonly in practice during the image acquisition stage and present a
significant challenge for current robustness approaches. In this paper, we
propose a diverse Gaussian noise consistency regularization method for
improving robustness of image classifiers under a variety of noise corruptions
while still maintaining high clean accuracy. We derive bounds to motivate and
understand the behavior of our Gaussian noise consistency regularization using
a local loss landscape analysis. We show that this simple approach improves
robustness against various unforeseen noise corruptions by 4.2-18.4\% over
adversarial training and other strong diverse data augmentation baselines
across several benchmarks. Furthermore, when combined with state-of-the-art
diverse data augmentation techniques, we empirically show our method further
improves robustness by 0.6-3\% and uncertainty calibration by 2.1-10.6\% for
common corruptions for several image classification benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Achieving Domain Generalization in Underwater Object Detection by Domain Mixup and Contrastive Learning. (arXiv:2104.02230v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02230">
<div class="article-summary-box-inner">
<span><p>The performance of existing underwater object detection methods degrades
seriously when facing domain shift caused by complicated underwater
environments. Due to the limitation of the number of domains in the dataset,
deep detectors easily memorize a few seen domains, which leads to low
generalization ability. There are two common ideas to improve the domain
generalization performance. First, it can be inferred that the detector trained
on as many domains as possible is domain-invariant. Second, for the images with
the same semantic content in different domains, their hidden features should be
equivalent. This paper further excavates these two ideas and proposes a domain
generalization framework (named DMC) that learns how to generalize across
domains from Domain Mixup and Contrastive Learning. First, based on the
formation of underwater images, an image in an underwater environment is the
linear transformation of another underwater environment. Thus, a style transfer
model, which outputs a linear transformation matrix instead of the whole image,
is proposed to transform images from one source domain to another, enriching
the domain diversity of the training data. Second, mixup operation interpolates
different domains on the feature level, sampling new domains on the domain
manifold. Third, contrastive loss is selectively applied to features from
different domains to force the model to learn domain invariant features but
retain the discriminative capacity. With our method, detectors will be robust
to domain shift. Also, a domain generalization benchmark S-UODAC2020 for
detection is set up to measure the performance of our method. Comprehensive
experiments on S-UODAC2020 and two object recognition benchmarks (PACS and
VLCS) demonstrate that the proposed method is able to learn domain-invariant
representations, and outperforms other domain generalization methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PrivateSNN: Privacy-Preserving Spiking Neural Networks. (arXiv:2104.03414v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03414">
<div class="article-summary-box-inner">
<span><p>How can we bring both privacy and energy-efficiency to a neural system? In
this paper, we propose PrivateSNN, which aims to build low-power Spiking Neural
Networks (SNNs) from a pre-trained ANN model without leaking sensitive
information contained in a dataset. Here, we tackle two types of leakage
problems: 1) Data leakage is caused when the networks access real training data
during an ANN-SNN conversion process. 2) Class leakage is caused when
class-related features can be reconstructed from network parameters. In order
to address the data leakage issue, we generate synthetic images from the
pre-trained ANNs and convert ANNs to SNNs using the generated images. However,
converted SNNs remain vulnerable to class leakage since the weight parameters
have the same (or scaled) value with respect to ANN parameters. Therefore, we
encrypt SNN weights by training SNNs with a temporal spike-based learning rule.
Updating weight parameters with temporal data makes SNNs difficult to be
interpreted in the spatial domain. We observe that the encrypted PrivateSNN
eliminates data and class leakage issues with a slight performance drop (less
than ~2) and significant energy-efficiency gain (about 55x) compared to the
standard ANN. We conduct extensive experiments on various datasets including
CIFAR10, CIFAR100, and TinyImageNet, highlighting the importance of
privacy-preserving SNN training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Geometric Consistency for Monocular 3D Object Detection. (arXiv:2104.05858v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05858">
<div class="article-summary-box-inner">
<span><p>This paper investigates the geometric consistency for monocular 3D object
detection, which suffers from the ill-posed depth estimation. We first conduct
a thorough analysis to reveal how existing methods fail to consistently
localize objects when different geometric shifts occur. In particular, we
design a series of geometric manipulations to diagnose existing detectors and
then illustrate their vulnerability to consistently associate the depth with
object apparent sizes and positions. To alleviate this issue, we propose four
geometry-aware data augmentation approaches to enhance the geometric
consistency of the detectors. We first modify some commonly used data
augmentation methods for 2D images so that they can maintain geometric
consistency in 3D spaces. We demonstrate such modifications are important. In
addition, we propose a 3D-specific image perturbation method that employs the
camera movement. During the augmentation process, the camera system with the
corresponding image is manipulated, while the geometric visual cues for depth
recovery are preserved. We show that by using the geometric consistency
constraints, the proposed augmentation techniques lead to improvements on the
KITTI and nuScenes monocular 3D detection benchmarks with state-of-the-art
results. In addition, we demonstrate that the augmentation methods are well
suited for semi-supervised training and cross-dataset generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DOC3-Deep One Class Classification using Contradictions. (arXiv:2105.07636v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07636">
<div class="article-summary-box-inner">
<span><p>This paper introduces the notion of learning from contradictions (a.k.a
Universum learning) for deep one class classification problems. We formalize
this notion for the widely adopted one class large-margin loss, and propose the
Deep One Class Classification using Contradictions (DOC3) algorithm. We show
that learning from contradictions incurs lower generalization error by
comparing the Empirical Rademacher Complexity (ERC) of DOC3 against its
traditional inductive learning counterpart. Our empirical results demonstrate
the efficacy of DOC3 compared to popular baseline algorithms on several
real-life data sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robust Vision Transformer. (arXiv:2105.07926v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07926">
<div class="article-summary-box-inner">
<span><p>Recent advances on Vision Transformer (ViT) and its improved variants have
shown that self-attention-based networks surpass traditional Convolutional
Neural Networks (CNNs) in most vision tasks. However, existing ViTs focus on
the standard accuracy and computation cost, lacking the investigation of the
intrinsic influence on model robustness and generalization. In this work, we
conduct systematic evaluation on components of ViTs in terms of their impact on
robustness to adversarial examples, common corruptions and distribution shifts.
We find some components can be harmful to robustness. By using and combining
robust components as building blocks of ViTs, we propose Robust Vision
Transformer (RVT), which is a new vision transformer and has superior
performance with strong robustness. We further propose two new plug-and-play
techniques called position-aware attention scaling and patch-wise augmentation
to augment our RVT, which we abbreviate as RVT*. The experimental results on
ImageNet and six robustness benchmarks show the advanced robustness and
generalization ability of RVT compared with previous ViTs and state-of-the-art
CNNs. Furthermore, RVT-S* also achieves Top-1 rank on multiple robustness
leaderboards including ImageNet-C and ImageNet-Sketch. The code will be
available at \url{https://github.com/alibaba/easyrobust}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">White Paper Assistance: A Step Forward Beyond the Shortcut Learning. (arXiv:2106.04178v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04178">
<div class="article-summary-box-inner">
<span><p>The promising performances of CNNs often overshadow the need to examine
whether they are doing in the way we are actually interested. We show through
experiments that even over-parameterized models would still solve a dataset by
recklessly leveraging spurious correlations, or so-called 'shortcuts'. To
combat with this unintended propensity, we borrow the idea of printer test page
and propose a novel approach called White Paper Assistance. Our proposed method
involves the white paper to detect the extent to which the model has preference
for certain characterized patterns and alleviates it by forcing the model to
make a random guess on the white paper. We show the consistent accuracy
improvements that are manifest in various architectures, datasets and
combinations with other techniques. Experiments have also demonstrated the
versatility of our approach on fine-grained recognition, imbalanced
classification and robustness to corruptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalization and Robustness Implications in Object-Centric Learning. (arXiv:2107.00637v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00637">
<div class="article-summary-box-inner">
<span><p>The idea behind object-centric representation learning is that natural scenes
can better be modeled as compositions of objects and their relations as opposed
to distributed representations. This inductive bias can be injected into neural
networks to potentially improve systematic generalization and performance of
downstream tasks in scenes with multiple objects. In this paper, we train
state-of-the-art unsupervised models on five common multi-object datasets and
evaluate segmentation metrics and downstream object property prediction. In
addition, we study generalization and robustness by investigating the settings
where either a single object is out of distribution -- e.g., having an unseen
color, texture, or shape -- or global properties of the scene are altered --
e.g., by occlusions, cropping, or increasing the number of objects. From our
experimental study, we find object-centric representations to be useful for
downstream tasks and generally robust to most distribution shifts affecting
objects. However, when the distribution shift affects the input in a less
structured manner, robustness in terms of segmentation and downstream task
performance may vary significantly across models and distribution shifts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI assisted method for efficiently generating breast ultrasound screening reports. (arXiv:2107.13431v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13431">
<div class="article-summary-box-inner">
<span><p>Background: Ultrasound is one of the preferred choices for early screening of
dense breast cancer. Clinically, doctors have to manually write the screening
report which is time-consuming and laborious, and it is easy to miss and
miswrite. Aim: We proposed a new pipeline to automatically generate AI breast
ultrasound screening reports based on ultrasound images, aiming to assist
doctors in improving the efficiency of clinical screening and reducing
repetitive report writing. Methods: AI was used to efficiently generate
personalized breast ultrasound screening preliminary reports, especially for
benign and normal cases which account for the majority. Based on the
preliminary AI report, doctors then make simple adjustments or corrections to
quickly generate the final report. The approach has been trained and tested
using a database of 4809 breast tumor instances. Results: Experimental results
indicate that this pipeline improves doctors' work efficiency by up to 90%,
which greatly reduces repetitive work. Conclusion: Personalized report
generation is more widely recognized by doctors in clinical practice compared
with non-intelligent reports based on fixed templates or containing options to
fill in the blanks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discovering Distinctive "Semantics" in Super-Resolution Networks. (arXiv:2108.00406v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00406">
<div class="article-summary-box-inner">
<span><p>Image super-resolution (SR) is a representative low-level vision problem.
Although deep SR networks have achieved extraordinary success, we are still
unaware of their working mechanisms. Specifically, whether SR networks can
learn semantic information, or just perform complex mapping function? What
hinders SR networks from generalizing to real-world data? These questions not
only raise our curiosity, but also influence SR network development. In this
paper, we make the primary attempt to answer the above fundamental questions.
After comprehensively analyzing the feature representations (via dimensionality
reduction and visualization), we successfully discover the distinctive
"semantics" in SR networks, i.e., deep degradation representations (DDR), which
relate to image degradation instead of image content. We show that a
well-trained deep SR network is naturally a good descriptor of degradation
information. Our experiments also reveal two key factors (adversarial learning
and global residual) that influence the extraction of such semantics. We
further apply DDR in several interesting applications (such as distortion
identification, blind SR and generalization evaluation) and achieve promising
results, demonstrating the correctness and effectiveness of our findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CERL: A Unified Optimization Framework for Light Enhancement with Realistic Noise. (arXiv:2108.00478v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00478">
<div class="article-summary-box-inner">
<span><p>Low-light images captured in the real world are inevitably corrupted by
sensor noise. Such noise is spatially variant and highly dependent on the
underlying pixel intensity, deviating from the oversimplified assumptions in
conventional denoising. Existing light enhancement methods either overlook the
important impact of real-world noise during enhancement, or treat noise removal
as a separate pre- or post-processing step. We present \underline{C}oordinated
\underline{E}nhancement for \underline{R}eal-world \underline{L}ow-light Noisy
Images (CERL), that seamlessly integrates light enhancement and noise
suppression parts into a unified and physics-grounded optimization framework.
For the real low-light noise removal part, we customize a self-supervised
denoising model that can easily be adapted without referring to clean
ground-truth images. For the light enhancement part, we also improve the design
of a state-of-the-art backbone. The two parts are then joint formulated into
one principled plug-and-play optimization. Our approach is compared against
state-of-the-art low-light enhancement methods both qualitatively and
quantitatively. Besides standard benchmarks, we further collect and test on a
new realistic low-light mobile photography dataset (RLMP), whose
mobile-captured photos display heavier realistic noise than those taken by
high-quality cameras. CERL consistently produces the most visually pleasing and
artifact-free results across all experiments. Our RLMP dataset and codes are
available at: https://github.com/VITA-Group/CERL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Branch with Attention Network for Hand-Based Person Recognition. (arXiv:2108.02234v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02234">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel hand-based person recognition method for
the purpose of criminal investigations since the hand image is often the only
available information in cases of serious crime such as sexual abuse. Our
proposed method, Multi-Branch with Attention Network (MBA-Net), incorporates
both channel and spatial attention modules in branches in addition to a global
(without attention) branch to capture global structural information for
discriminative feature learning. The attention modules focus on the relevant
features of the hand image while suppressing the irrelevant backgrounds. In
order to overcome the weakness of the attention mechanisms, equivariant to
pixel shuffling, we integrate relative positional encodings into the spatial
attention module to capture the spatial positions of pixels. Extensive
evaluations on two large multi-ethnic and publicly available hand datasets
demonstrate that our proposed method achieves state-of-the-art performance,
surpassing the existing hand-based identification methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eyes Tell All: Irregular Pupil Shapes Reveal GAN-generated Faces. (arXiv:2109.00162v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00162">
<div class="article-summary-box-inner">
<span><p>Generative adversary network (GAN) generated high-realistic human faces have
been used as profile images for fake social media accounts and are visually
challenging to discern from real ones. In this work, we show that GAN-generated
faces can be exposed via irregular pupil shapes. This phenomenon is caused by
the lack of physiological constraints in the GAN models. We demonstrate that
such artifacts exist widely in high-quality GAN-generated faces and further
describe an automatic method to extract the pupils from two eyes and analysis
their shapes for exposing the GAN-generated faces. Qualitative and quantitative
evaluations of our method suggest its simplicity and effectiveness in
distinguishing GAN-generated faces.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IFBiD: Inference-Free Bias Detection. (arXiv:2109.04374v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04374">
<div class="article-summary-box-inner">
<span><p>This paper is the first to explore an automatic way to detect bias in deep
convolutional neural networks by simply looking at their weights. Furthermore,
it is also a step towards understanding neural networks and how they work. We
show that it is indeed possible to know if a model is biased or not simply by
looking at its weights, without the model inference for an specific input. We
analyze how bias is encoded in the weights of deep networks through a toy
example using the Colored MNIST database and we also provide a realistic case
study in gender detection from face images using state-of-the-art methods and
experimental resources. To do so, we generated two databases with 36K and 48K
biased models each. In the MNIST models we were able to detect whether they
presented a strong or low bias with more than 99% accuracy, and we were also
able to classify between four levels of bias with more than 70% accuracy. For
the face models, we achieved 90% accuracy in distinguishing between models
biased towards Asian, Black, or Caucasian ethnicity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Learning is More Robust to Dataset Imbalance. (arXiv:2110.05025v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05025">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) is a scalable way to learn general visual
representations since it learns without labels. However, large-scale unlabeled
datasets in the wild often have long-tailed label distributions, where we know
little about the behavior of SSL. In this work, we systematically investigate
self-supervised learning under dataset imbalance. First, we find out via
extensive experiments that off-the-shelf self-supervised representations are
already more robust to class imbalance than supervised representations. The
performance gap between balanced and imbalanced pre-training with SSL is
significantly smaller than the gap with supervised learning, across sample
sizes, for both in-domain and, especially, out-of-domain evaluation. Second,
towards understanding the robustness of SSL, we hypothesize that SSL learns
richer features from frequent data: it may learn
label-irrelevant-but-transferable features that help classify the rare classes
and downstream tasks. In contrast, supervised learning has no incentive to
learn features irrelevant to the labels from frequent examples. We validate
this hypothesis with semi-synthetic experiments and theoretical analyses on a
simplified setting. Third, inspired by the theoretical insights, we devise a
re-weighted regularization technique that consistently improves the SSL
representation quality on imbalanced datasets with several evaluation criteria,
closing the small gap between balanced and imbalanced datasets with the same
number of examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Composition and Style Attributes Guided Image Aesthetic Assessment. (arXiv:2111.04647v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.04647">
<div class="article-summary-box-inner">
<span><p>The aesthetic quality of an image is defined as the measure or appreciation
of the beauty of an image. Aesthetics is inherently a subjective property but
there are certain factors that influence it such as, the semantic content of
the image, the attributes describing the artistic aspect, the photographic
setup used for the shot, etc. In this paper we propose a method for the
automatic prediction of the aesthetics of an image that is based on the
analysis of the semantic content, the artistic style and the composition of the
image. The proposed network includes: a pre-trained network for semantic
features extraction (the Backbone); a Multi Layer Perceptron (MLP) network that
relies on the Backbone features for the prediction of image attributes (the
AttributeNet); a self-adaptive Hypernetwork that exploits the attributes prior
encoded into the embedding generated by the AttributeNet to predict the
parameters of the target network dedicated to aesthetic estimation (the
AestheticNet). Given an image, the proposed multi-network is able to predict:
style and composition attributes, and aesthetic score distribution. Results on
three benchmark datasets demonstrate the effectiveness of the proposed method,
while the ablation study gives a better understanding of the proposed network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PhysFormer: Facial Video-based Physiological Measurement with Temporal Difference Transformer. (arXiv:2111.12082v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12082">
<div class="article-summary-box-inner">
<span><p>Remote photoplethysmography (rPPG), which aims at measuring heart activities
and physiological signals from facial video without any contact, has great
potential in many applications (e.g., remote healthcare and affective
computing). Recent deep learning approaches focus on mining subtle rPPG clues
using convolutional neural networks with limited spatio-temporal receptive
fields, which neglect the long-range spatio-temporal perception and interaction
for rPPG modeling. In this paper, we propose the PhysFormer, an end-to-end
video transformer based architecture, to adaptively aggregate both local and
global spatio-temporal features for rPPG representation enhancement. As key
modules in PhysFormer, the temporal difference transformers first enhance the
quasi-periodic rPPG features with temporal difference guided global attention,
and then refine the local spatio-temporal representation against interference.
Furthermore, we also propose the label distribution learning and a curriculum
learning inspired dynamic constraint in frequency domain, which provide
elaborate supervisions for PhysFormer and alleviate overfitting. Comprehensive
experiments are performed on four benchmark datasets to show our superior
performance on both intra- and cross-dataset testings. One highlight is that,
unlike most transformer networks needed pretraining from large-scale datasets,
the proposed PhysFormer can be easily trained from scratch on rPPG datasets,
which makes it promising as a novel transformer baseline for the rPPG
community. The codes will be released at
https://github.com/ZitongYu/PhysFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating the Bias of Centered Objects in Common Datasets. (arXiv:2112.09195v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.09195">
<div class="article-summary-box-inner">
<span><p>Convolutional networks are considered shift invariant, but it was
demonstrated that their response may vary according to the exact location of
the objects. In this paper we will demonstrate that most commonly investigated
datasets have a bias, where objects are over-represented at the center of the
image during training. This bias and the boundary condition of these networks
can have a significant effect on the performance of these architectures and
their accuracy drops significantly as an object approaches the boundary. We
will also demonstrate how this effect can be mitigated with data augmentation
techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Facial-Sketch Synthesis: A New Challenge. (arXiv:2112.15439v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.15439">
<div class="article-summary-box-inner">
<span><p>This paper aims to conduct a comprehensive study on facial-sketch synthesis
(FSS). However, due to the high costs of obtaining hand-drawn sketch datasets,
there lacks a complete benchmark for assessing the development of FSS
algorithms over the last decade. We first introduce a high-quality dataset for
FSS, named FS2K, which consists of 2,104 image-sketch pairs spanning three
types of sketch styles, image backgrounds, lighting conditions, skin colors,
and facial attributes. FS2K differs from previous FSS datasets in difficulty,
diversity, and scalability and should thus facilitate the progress of FSS
research. Second, we present the largest-scale FSS investigation by reviewing
89 classical methods, including 25 handcrafted feature-based facial-sketch
synthesis approaches, 29 general translation methods, and 35 image-to-sketch
approaches. Besides, we elaborate comprehensive experiments on the existing 19
cutting-edge models. Third, we present a simple baseline for FSS, named FSGAN.
With only two straightforward components, i.e., facial-aware masking and
style-vector expansion, FSGAN surpasses the performance of all previous
state-of-the-art models on the proposed FS2K dataset by a large margin.
Finally, we conclude with lessons learned over the past years and point out
several unsolved challenges. Our code is available at
https://github.com/DengPingFan/FSGAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RestoreFormer: High-Quality Blind Face Restoration from Undegraded Key-Value Pairs. (arXiv:2201.06374v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.06374">
<div class="article-summary-box-inner">
<span><p>Blind face restoration is to recover a high-quality face image from unknown
degradations. As face image contains abundant contextual information, we
propose a method, RestoreFormer, which explores fully-spatial attentions to
model contextual information and surpasses existing works that use local
operators. RestoreFormer has several benefits compared to prior arts. First,
unlike the conventional multi-head self-attention in previous Vision
Transformers (ViTs), RestoreFormer incorporates a multi-head cross-attention
layer to learn fully-spatial interactions between corrupted queries and
high-quality key-value pairs. Second, the key-value pairs in ResotreFormer are
sampled from a reconstruction-oriented high-quality dictionary, whose elements
are rich in high-quality facial features specifically aimed for face
reconstruction, leading to superior restoration results. Third, RestoreFormer
outperforms advanced state-of-the-art methods on one synthetic dataset and
three real-world datasets, as well as produces images with better visual
quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ShapeFormer: Transformer-based Shape Completion via Sparse Representation. (arXiv:2201.10326v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10326">
<div class="article-summary-box-inner">
<span><p>We present ShapeFormer, a transformer-based network that produces a
distribution of object completions, conditioned on incomplete, and possibly
noisy, point clouds. The resultant distribution can then be sampled to generate
likely completions, each exhibiting plausible shape details while being
faithful to the input. To facilitate the use of transformers for 3D, we
introduce a compact 3D representation, vector quantized deep implicit function,
that utilizes spatial sparsity to represent a close approximation of a 3D shape
by a short sequence of discrete variables. Experiments demonstrate that
ShapeFormer outperforms prior art for shape completion from ambiguous partial
inputs in terms of both completion quality and diversity. We also show that our
approach effectively handles a variety of shape types, incomplete patterns, and
real-world scans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Student Knows All Experts Know: From Sparse to Dense. (arXiv:2201.10890v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10890">
<div class="article-summary-box-inner">
<span><p>Human education system trains one student by multiple experts.
Mixture-of-experts (MoE) is a powerful sparse architecture including multiple
experts. However, sparse MoE model is hard to implement, easy to overfit, and
not hardware-friendly. In this work, inspired by human education model, we
propose a novel task, knowledge integration, to obtain a dense student model
(OneS) as knowledgeable as one sparse MoE. We investigate this task by
proposing a general training framework including knowledge gathering and
knowledge distillation. Specifically, we first propose Singular Value
Decomposition Knowledge Gathering (SVD-KG) to gather key knowledge from
different pretrained experts. We then refine the dense student model by
knowledge distillation to offset the noise from gathering. On ImageNet, our
OneS preserves $61.7\%$ benefits from MoE. OneS can achieve $78.4\%$ top-1
accuracy with only $15$M parameters. On four natural language processing
datasets, OneS obtains $88.2\%$ MoE benefits and outperforms SoTA by $51.7\%$
using the same architecture and training data. In addition, compared with the
MoE counterpart, OneS can achieve $3.7 \times$ inference speedup due to the
hardware-friendly architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HCSC: Hierarchical Contrastive Selective Coding. (arXiv:2202.00455v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.00455">
<div class="article-summary-box-inner">
<span><p>Hierarchical semantic structures naturally exist in an image dataset, in
which several semantically relevant image clusters can be further integrated
into a larger cluster with coarser-grained semantics. Capturing such structures
with image representations can greatly benefit the semantic understanding on
various downstream tasks. Existing contrastive representation learning methods
lack such an important model capability. In addition, the negative pairs used
in these methods are not guaranteed to be semantically distinct, which could
further hamper the structural correctness of learned image representations. To
tackle these limitations, we propose a novel contrastive learning framework
called Hierarchical Contrastive Selective Coding (HCSC). In this framework, a
set of hierarchical prototypes are constructed and also dynamically updated to
represent the hierarchical semantic structures underlying the data in the
latent space. To make image representations better fit such semantic
structures, we employ and further improve conventional instance-wise and
prototypical contrastive learning via an elaborate pair selection scheme. This
scheme seeks to select more diverse positive pairs with similar semantics and
more precise negative pairs with truly distinct semantics. On extensive
downstream tasks, we verify the superior performance of HCSC over
state-of-the-art contrastive methods, and the effectiveness of major model
components is proved by plentiful analytical studies. We build a comprehensive
model zoo in Sec. D. Our source code and model weights are available at
https://github.com/gyfastas/HCSC
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterizing and overcoming the greedy nature of learning in multi-modal deep neural networks. (arXiv:2202.05306v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.05306">
<div class="article-summary-box-inner">
<span><p>We hypothesize that due to the greedy nature of learning in multi-modal deep
neural networks, these models tend to rely on just one modality while
under-fitting the other modalities. Such behavior is counter-intuitive and
hurts the models' generalization, as we observe empirically. To estimate the
model's dependence on each modality, we compute the gain on the accuracy when
the model has access to it in addition to another modality. We refer to this
gain as the conditional utilization rate. In the experiments, we consistently
observe an imbalance in conditional utilization rates between modalities,
across multiple tasks and architectures. Since conditional utilization rate
cannot be computed efficiently during training, we introduce a proxy for it
based on the pace at which the model learns from each modality, which we refer
to as the conditional learning speed. We propose an algorithm to balance the
conditional learning speeds between modalities during training and demonstrate
that it indeed addresses the issue of greedy learning. The proposed algorithm
improves the model's generalization on three datasets: Colored MNIST,
ModelNet40, and NVIDIA Dynamic Hand Gesture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GroupViT: Semantic Segmentation Emerges from Text Supervision. (arXiv:2202.11094v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11094">
<div class="article-summary-box-inner">
<span><p>Grouping and recognition are important components of visual scene
understanding, e.g., for object detection and semantic segmentation. With
end-to-end deep learning systems, grouping of image regions usually happens
implicitly via top-down supervision from pixel-level recognition labels.
Instead, in this paper, we propose to bring back the grouping mechanism into
deep networks, which allows semantic segments to emerge automatically with only
text supervision. We propose a hierarchical Grouping Vision Transformer
(GroupViT), which goes beyond the regular grid structure representation and
learns to group image regions into progressively larger arbitrary-shaped
segments. We train GroupViT jointly with a text encoder on a large-scale
image-text dataset via contrastive losses. With only text supervision and
without any pixel-level annotations, GroupViT learns to group together semantic
regions and successfully transfers to the task of semantic segmentation in a
zero-shot manner, i.e., without any further fine-tuning. It achieves a
zero-shot accuracy of 52.3% mIoU on the PASCAL VOC 2012 and 22.4% mIoU on
PASCAL Context datasets, and performs competitively to state-of-the-art
transfer-learning methods requiring greater levels of supervision. We
open-source our code at https://github.com/NVlabs/GroupViT .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Transformer Meets Robotic Grasping: Exploits Context for Efficient Grasp Detection. (arXiv:2202.11911v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11911">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a transformer-based architecture, namely TF-Grasp,
for robotic grasp detection. The developed TF-Grasp framework has two elaborate
designs making it well suitable for visual grasping tasks. The first key design
is that we adopt the local window attention to capture local contextual
information and detailed features of graspable objects. Then, we apply the
cross window attention to model the long-term dependencies between distant
pixels. Object knowledge, environmental configuration, and relationships
between different visual entities are aggregated for subsequent grasp
detection. The second key design is that we build a hierarchical
encoder-decoder architecture with skip-connections, delivering shallow features
from encoder to decoder to enable a multi-scale feature fusion. Due to the
powerful attention mechanism, the TF-Grasp can simultaneously obtain the local
information (i.e., the contours of objects), and model long-term connections
such as the relationships between distinct visual concepts in clutter.
Extensive computational experiments demonstrate that the TF-Grasp achieves
superior results versus state-of-art grasping convolutional models and attain a
higher accuracy of 97.99% and 94.6% on Cornell and Jacquard grasping datasets,
respectively. Real-world experiments using a 7DoF Franka Emika Panda robot also
demonstrate its capability of grasping unseen objects in a variety of
scenarios. The code and pre-trained models will be available at
https://github.com/WangShaoSUN/grasp-transformer
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Data-scalable Transformer for Medical Image Segmentation: Architecture, Model Efficiency, and Benchmark. (arXiv:2203.00131v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.00131">
<div class="article-summary-box-inner">
<span><p>Transformer, as a new generation of neural architecture, has demonstrated
remarkable performance in natural language processing and computer vision.
However, existing vision Transformers struggle to learn with limited medical
data and are unable to generalize on diverse medical image tasks. To tackle
these challenges, we present UTNetV2 as a data-scalable Transformer towards
generalizable medical image segmentation. The key designs incorporate desirable
inductive bias, hierarchical modeling with linear-complexity attention, and
multi-scale feature fusion in a spatially and semantically global manner.
UTNetV2 can learn across tiny- to large-scale data without pre-training.
Extensive experiments demonstrate the potential of UTNetV2 as a general
segmentation backbone, outperforming CNNs and vision Transformers on three
public datasets with multiple modalities (e.g., CT and MRI) and diverse medical
targets (e.g., healthy organ, diseased tissue, and tumor). We make the data
processing, models and evaluation pipeline publicly available, offering solid
baselines and unbiased comparisons for promoting a wide range of downstream
clinical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SynWoodScape: Synthetic Surround-view Fisheye Camera Dataset for Autonomous Driving. (arXiv:2203.05056v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.05056">
<div class="article-summary-box-inner">
<span><p>Surround-view cameras are a primary sensor for automated driving, used for
near field perception. It is one of the most commonly used sensors in
commercial vehicles. Four fisheye cameras with a 190{\deg} field of view cover
the 360{\deg} around the vehicle. Due to its high radial distortion, the
standard algorithms do not extend easily. Previously, we released the first
public fisheye surround-view dataset named WoodScape. In this work, we release
a synthetic version of the surround-view dataset, covering many of its
weaknesses and extending it. Firstly, it is not possible to obtain ground truth
for pixel-wise optical flow and depth. Secondly, WoodScape did not have all
four cameras simultaneously in order to sample diverse frames. However, this
means that multi-camera algorithms cannot be designed, which is enabled in the
new dataset. We implemented surround-view fisheye geometric projections in
CARLA Simulator matching WoodScape's configuration and created SynWoodScape. We
release 80k images from the synthetic dataset with annotations for 10+ tasks.
We also release the baseline code and supporting scripts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-generative Generalized Zero-shot Learning via Task-correlated Disentanglement and Controllable Samples Synthesis. (arXiv:2203.05335v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.05335">
<div class="article-summary-box-inner">
<span><p>Synthesizing pseudo samples is currently the most effective way to solve the
Generalized Zero-Shot Learning (GZSL) problem. Most models achieve competitive
performance but still suffer from two problems: (1) Feature confounding, the
overall representations confound task-correlated and task-independent features,
and existing models disentangle them in a generative way, but they are
unreasonable to synthesize reliable pseudo samples with limited samples; (2)
Distribution uncertainty, that massive data is needed when existing models
synthesize samples from the uncertain distribution, which causes poor
performance in limited samples of seen classes. In this paper, we propose a
non-generative model to address these problems correspondingly in two modules:
(1) Task-correlated feature disentanglement, to exclude the task-correlated
features from task-independent ones by adversarial learning of domain adaption
towards reasonable synthesis; (2) Controllable pseudo sample synthesis, to
synthesize edge-pseudo and center-pseudo samples with certain characteristics
towards more diversity generated and intuitive transfer. In addation, to
describe the new scene that is the limit seen class samples in the training
process, we further formulate a new ZSL task named the 'Few-shot Seen class and
Zero-shot Unseen class learning' (FSZU). Extensive experiments on four
benchmarks verify that the proposed method is competitive in the GZSL and the
FSZU tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Modeling via Information Tree for One-Shot Natural Language Spatial Video Grounding. (arXiv:2203.08013v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08013">
<div class="article-summary-box-inner">
<span><p>Natural language spatial video grounding aims to detect the relevant objects
in video frames with descriptive sentences as the query. In spite of the great
advances, most existing methods rely on dense video frame annotations, which
require a tremendous amount of human effort. To achieve effective grounding
under a limited annotation budget, we investigate one-shot video grounding, and
learn to ground natural language in all video frames with solely one frame
labeled, in an end-to-end manner. One major challenge of end-to-end one-shot
video grounding is the existence of videos frames that are either irrelevant to
the language query or the labeled frames. Another challenge relates to the
limited supervision, which might result in ineffective representation learning.
To address these challenges, we designed an end-to-end model via Information
Tree for One-Shot video grounding (IT-OS). Its key module, the information
tree, can eliminate the interference of irrelevant frames based on branch
search and branch cropping techniques. In addition, several self-supervised
tasks are proposed based on the information tree to improve the representation
learning under insufficient labeling. Experiments on the benchmark dataset
demonstrate the effectiveness of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Modal Masked Pre-Training for Monocular Panoramic Depth Completion. (arXiv:2203.09855v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09855">
<div class="article-summary-box-inner">
<span><p>In this paper, we formulate a potentially valuable panoramic depth completion
(PDC) task as panoramic 3D cameras often produce 360{\deg} depth with missing
data in complex scenes. Its goal is to recover dense panoramic depths from raw
sparse ones and panoramic RGB images. To deal with the PDC task, we train a
deep network that takes both depth and image as inputs for the dense panoramic
depth recovery. However, it needs to face a challenging optimization problem of
the network parameters due to its non-convex objective function. To address
this problem, we propose a simple yet effective approach termed M{^3}PT:
multi-modal masked pre-training. Specifically, during pre-training, we
simultaneously cover up patches of the panoramic RGB image and sparse depth by
shared random mask, then reconstruct the sparse depth in the masked regions. To
our best knowledge, it is the first time that we show the effectiveness of
masked pre-training in a multi-modal vision task, instead of the single-modal
task resolved by masked autoencoders (MAE). Different from MAE where
fine-tuning completely discards the decoder part of pre-training, there is no
architectural difference between the pre-training and fine-tuning stages in our
M$^{3}$PT as they only differ in the prediction density, which potentially
makes the transfer learning more convenient and effective. Extensive
experiments verify the effectiveness of M{^3}PT on three panoramic datasets.
Notably, we improve the state-of-the-art baselines by averagely 26.2% in RMSE,
51.7% in MRE, 49.7% in MAE, and 37.5% in RMSElog on three benchmark datasets.
Codes and pre-trained models are available at
https://github.com/anonymoustbd/MMMPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Representation Learning as Multimodal Variational Inference. (arXiv:2203.11437v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.11437">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a probabilistic extension of the recent
self-supervised learning (SSL) method, SimSiam. The proposed extension makes
SimSiam uncertainty-aware by considering SimSiam as a generative model of
augmented views and learning it in terms of variational inference. SimSiam
trains a model by maximizing the similarity between image representations of
different augmented views of the same image. The augmentation process sometimes
produces ambiguous images, and their representations potentially have
uncertainty. Although the use of uncertainty-aware machine learning becoming
common, such as in deep variational inference, SimSiam and other SSL methods
are insufficiently uncertainty-aware, leading to limitations in the use of
augmented ambiguous images. Our main contributions are twofold: Firstly, we
clarify the theoretical relationship between non-contrastive SSL and multimodal
variational inference. Secondly, we introduce a novel SSL called variational
inference SimSiam (VI-SimSiam), which incorporates uncertainty by involving
spherical posterior distributions. The experiment results show that VI-SimSiam
outperforms SimSiam in classification tasks in several datasets, such as
ImageNette and ImageWoof by successfully estimating the representation
uncertainty.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Fixed Sub-Center: A Better Way to Capture Data Complexity. (arXiv:2203.12928v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12928">
<div class="article-summary-box-inner">
<span><p>Treating class with a single center may hardly capture data distribution
complexities. Using multiple sub-centers is an alternative way to address this
problem. However, highly correlated sub-classes, the classifier's parameters
grow linearly with the number of classes, and lack of intra-class compactness
are three typical issues that need to be addressed in existing multi-subclass
methods. To this end, we propose to use Fixed Sub-Center (F-SC), which allows
the model to create more discrepant sub-centers while saving memory and cutting
computational costs considerably. The F-SC specifically, first samples a class
center Ui for each class from a uniform distribution, and then generates a
normal distribution for each class, where the mean is equal to Ui. Finally, the
sub-centers are sampled based on the normal distribution corresponding to each
class, and the sub-centers are fixed during the training process avoiding the
overhead of gradient calculation. Moreover, F-SC penalizes the Euclidean
distance between the samples and their corresponding sub-centers, it helps
remain intra-compactness. The experimental results show that F-SC significantly
improves the accuracy of both image classification and fine-grained recognition
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-distillation Augmented Masked Autoencoders for Histopathological Image Classification. (arXiv:2203.16983v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16983">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) has drawn increasing attention in pathological
image analysis in recent years. However, the prevalent contrastive SSL is
suboptimal in feature representation under this scenario due to the homogeneous
visual appearance. Alternatively, masked autoencoders (MAE) build SSL from a
generative paradigm. In this paper, we introduce MAE to pathological image
analysis and verify the effect of visible patches. Based on it, a novel SD-MAE
model is proposed to enable a self-distillation augmented SSL on top of the raw
MAE. Besides the reconstruction loss on masked image patches, SD-MAE further
imposes the self-distillation loss on visible patches. It enhances the
attention of the encoder, as shown by focusing more on fewer parts in
visualization results of attention map. We apply SD-MAE to the image
classification task on two pathological and one natural image datasets.
Experiments demonstrate that SD-MAE performs highly competitive when compared
with leading contrastive SSL methods. The results, which are pre-trained using
a moderate size of pathological images, are also comparable to the method
pre-trained with two orders of magnitude more images. Our code will be released
soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MDA GAN: Adversarial-Learning-based 3-D Seismic Data Interpolation and Reconstruction for Complex Missing. (arXiv:2204.03197v3 [physics.geo-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03197">
<div class="article-summary-box-inner">
<span><p>The interpolation and reconstruction of missing traces is a crucial step in
seismic data processing, moreover it is also a highly ill-posed problem,
especially for complex cases such as high-ratio random discrete missing,
continuous missing and missing in fault-rich or salt body surveys. These
complex cases are rarely mentioned in current works. To cope with complex
missing cases, we propose Multi-Dimensional Adversarial GAN (MDA GAN), a novel
3-D GAN framework. It employs three discriminators to ensure the consistency of
the reconstructed data with the original data distribution in each dimension.
The feature splicing module (FSM) is designed and embedded into the generator
of this framework, which automatically splices the features of the unmissing
part with those of the reconstructed part (missing part), thus fully preserving
the information of the unmissing part. To prevent pixel distortion in the
seismic data caused by the adversarial learning process, we propose a new
reconstruction loss Tanh Cross Entropy (TCE) loss to provide smoother
gradients. We experimentally verified the effectiveness of the individual
components of the study and then tested the method on multiple publicly
available data. The method achieves reasonable reconstructions for up to 95% of
random discrete missing, 100 traces of continuous missing and a mixture of both
types with a cumulative 99.4% missing. In fault and salt body enriched surveys,
MDA GAN still yields promising results for complex cases. Experimentally it has
been demonstrated that our method achieves better performance than other
methods in both simple and complex cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental Prototype Prompt-tuning with Pre-trained Representation for Class Incremental Learning. (arXiv:2204.03410v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03410">
<div class="article-summary-box-inner">
<span><p>Class incremental learning has attracted much attention, but most existing
related works focus on fine-tuning the entire representation model, which
inevitably results in much catastrophic forgetting. Instead of struggling to
fight against such forgetting by replaying or distilling like most of the
existing methods, we take a novel pre-train-and-prompt-tuning paradigm to
sequentially learn new visual concepts based on a fixed semantic-rich
pre-trained representation model. In detail, we incrementally prompt-tune
category prototypes for classification and example prototypes to compensate for
semantic drift, the problem caused by learning bias at different learning
phases. Extensive experiments conducted on the mainstream incremental learning
benchmarks demonstrate that our method outperforms other state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Glass Segmentation with RGB-Thermal Image Pairs. (arXiv:2204.05453v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05453">
<div class="article-summary-box-inner">
<span><p>This paper proposes a new glass segmentation method utilizing paired RGB and
thermal images. Due to the large difference between the transmission property
of visible light and that of the thermal energy through the glass where most
glass is transparent to the visible light but opaque to thermal energy, glass
regions of a scene are made more distinguishable with a pair of RGB and thermal
images than solely with an RGB image. To exploit such a unique property, we
propose a neural network architecture that effectively combines an RGB-thermal
image pair with a new multi-modal fusion module based on attention, and
integrate CNN and transformer to extract local features and long-range
dependencies, respectively. As well, we have collected a new dataset containing
5551 RGB-thermal image pairs with ground-truth segmentation annotations. The
qualitative and quantitative evaluations demonstrate the effectiveness of the
proposed approach on fusing RGB and thermal data for glass segmentation. Our
code and data are available at
https://github.com/Dong-Huo/RGB-T-Glass-Segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pushing the Performance Limit of Scene Text Recognizer without Human Annotation. (arXiv:2204.07714v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07714">
<div class="article-summary-box-inner">
<span><p>Scene text recognition (STR) attracts much attention over the years because
of its wide application. Most methods train STR model in a fully supervised
manner which requires large amounts of labeled data. Although synthetic data
contributes a lot to STR, it suffers from the real-tosynthetic domain gap that
restricts model performance. In this work, we aim to boost STR models by
leveraging both synthetic data and the numerous real unlabeled images,
exempting human annotation cost thoroughly. A robust consistency regularization
based semi-supervised framework is proposed for STR, which can effectively
solve the instability issue due to domain inconsistency between synthetic and
real images. A character-level consistency regularization is designed to
mitigate the misalignment between characters in sequence recognition. Extensive
experiments on standard text recognition benchmarks demonstrate the
effectiveness of the proposed method. It can steadily improve existing STR
models, and boost an STR model to achieve new state-of-the-art results. To our
best knowledge, this is the first consistency regularization based framework
that applies successfully to STR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Where and What: Driver Attention-based Object Detection. (arXiv:2204.12150v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12150">
<div class="article-summary-box-inner">
<span><p>Human drivers use their attentional mechanisms to focus on critical objects
and make decisions while driving. As human attention can be revealed from gaze
data, capturing and analyzing gaze information has emerged in recent years to
benefit autonomous driving technology. Previous works in this context have
primarily aimed at predicting "where" human drivers look at and lack knowledge
of "what" objects drivers focus on. Our work bridges the gap between
pixel-level and object-level attention prediction. Specifically, we propose to
integrate an attention prediction module into a pretrained object detection
framework and predict the attention in a grid-based style. Furthermore,
critical objects are recognized based on predicted attended-to areas. We
evaluate our proposed method on two driver attention datasets, BDD-A and
DR(eye)VE. Our framework achieves competitive state-of-the-art performance in
the attention prediction on both pixel-level and object-level but is far more
efficient (75.3 GFLOPs less) in computation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controllable Image Captioning. (arXiv:2204.13324v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.13324">
<div class="article-summary-box-inner">
<span><p>State-of-the-art image captioners can generate accurate sentences to describe
images in a sequence to sequence manner without considering the controllability
and interpretability. This, however, is far from making image captioning widely
used as an image can be interpreted in infinite ways depending on the target
and the context at hand. Achieving controllability is important especially when
the image captioner is used by different people with different way of
interpreting the images. In this paper, we introduce a novel framework for
image captioning which can generate diverse descriptions by capturing the
co-dependence between Part-Of-Speech tags and semantics. Our model decouples
direct dependence between successive variables. In this way, it allows the
decoder to exhaustively search through the latent Part-Of-Speech choices, while
keeping decoding speed proportional to the size of the POS vocabulary. Given a
control signal in the form of a sequence of Part-Of-Speech tags, we propose a
method to generate captions through a Transformer network, which predicts words
based on the input Part-Of-Speech tag sequences. Experiments on publicly
available datasets show that our model significantly outperforms
state-of-the-art methods on generating diverse image captions with high
qualities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SVTR: Scene Text Recognition with a Single Visual Model. (arXiv:2205.00159v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.00159">
<div class="article-summary-box-inner">
<span><p>Dominant scene text recognition models commonly contain two building blocks,
a visual model for feature extraction and a sequence model for text
transcription. This hybrid architecture, although accurate, is complex and less
efficient. In this study, we propose a Single Visual model for Scene Text
recognition within the patch-wise image tokenization framework, which dispenses
with the sequential modeling entirely. The method, termed SVTR, firstly
decomposes an image text into small patches named character components.
Afterward, hierarchical stages are recurrently carried out by component-level
mixing, merging and/or combining. Global and local mixing blocks are devised to
perceive the inter-character and intra-character patterns, leading to a
multi-grained character component perception. Thus, characters are recognized
by a simple linear prediction. Experimental results on both English and Chinese
scene text recognition tasks demonstrate the effectiveness of SVTR. SVTR-L
(Large) achieves highly competitive accuracy in English and outperforms
existing methods by a large margin in Chinese, while running faster. In
addition, SVTR-T (Tiny) is an effective and much smaller model, which shows
appealing speed at inference. The code is publicly available at
https://github.com/PaddlePaddle/PaddleOCR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution Neural Network. (arXiv:2205.01550v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01550">
<div class="article-summary-box-inner">
<span><p>In recent years, with the development of computing resources and LiDAR, point
cloud semantic segmentation has attracted many researchers. For the sparsity of
point clouds, although there is already a way to deal with sparse convolution,
multi-scale features are not considered. In this letter, we propose a feature
extraction module based on multi-scale sparse convolution and a feature
selection module based on channel attention and build a point cloud
segmentation network framework based on this. By introducing multi-scale sparse
convolution, the network could capture richer feature information based on
convolution kernels with different sizes, improving the segmentation result of
point cloud segmentation. Experimental results on Stanford large-scale 3-D
Indoor Spaces(S3DIS) dataset and outdoor dataset(SemanticKITTI), demonstrate
effectiveness and superiority of the proposed mothod.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simpler is Better: off-the-shelf Continual Learning Through Pretrained Backbones. (arXiv:2205.01586v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01586">
<div class="article-summary-box-inner">
<span><p>In this short paper, we propose a baseline (off-the-shelf) for Continual
Learning of Computer Vision problems, by leveraging the power of pretrained
models. By doing so, we devise a simple approach achieving strong performance
for most of the common benchmarks. Our approach is fast since requires no
parameters updates and has minimal memory requirements (order of KBytes). In
particular, the "training" phase reorders data and exploit the power of
pretrained models to compute a class prototype and fill a memory bank. At
inference time we match the closest prototype through a knn-like approach,
providing us the prediction. We will see how this naive solution can act as an
off-the-shelf continual learning system. In order to better consolidate our
results, we compare the devised pipeline with common CNN models and show the
superiority of Vision Transformers, suggesting that such architectures have the
ability to produce features of higher quality. Moreover, this simple pipeline,
raises the same questions raised by previous works \cite{gdumb} on the
effective progresses made by the CL community especially in the dataset
considered and the usage of pretrained models. Code is live at
https://github.com/francesco-p/off-the-shelf-cl
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Modeling Creative Processes for Algorithmic Painting. (arXiv:2205.01605v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01605">
<div class="article-summary-box-inner">
<span><p>This paper proposes a framework for computational modeling of artistic
painting algorithms, inspired by human creative practices. Based on examples
from expert artists and from the author's own experience, the paper argues that
creative processes often involve two important components: vague, high-level
goals (e.g., "make a good painting"), and exploratory processes for discovering
new ideas. This paper then sketches out possible computational mechanisms for
imitating those elements of the painting process, including underspecified loss
functions and iterative painting procedures with explicit task decompositions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compressive Ptychography using Deep Image and Generative Priors. (arXiv:2205.02397v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02397">
<div class="article-summary-box-inner">
<span><p>Ptychography is a well-established coherent diffraction imaging technique
that enables non-invasive imaging of samples at a nanometer scale. It has been
extensively used in various areas such as the defense industry or materials
science. One major limitation of ptychography is the long data acquisition time
due to mechanical scanning of the sample; therefore, approaches to reduce the
scan points are highly desired. However, reconstructions with less number of
scan points lead to imaging artifacts and significant distortions, hindering a
quantitative evaluation of the results. To address this bottleneck, we propose
a generative model combining deep image priors with deep generative priors. The
self-training approach optimizes the deep generative neural network to create a
solution for a given dataset. We complement our approach with a prior acquired
from a previously trained discriminator network to avoid a possible divergence
from the desired output caused by the noise in the measurements. We also
suggest using the total variation as a complementary before combat artifacts
due to measurement noise. We analyze our approach with numerical experiments
through different probe overlap percentages and varying noise levels. We also
demonstrate improved reconstruction accuracy compared to the state-of-the-art
method and discuss the advantages and disadvantages of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Scale Transfer Learning for Differentially Private Image Classification. (arXiv:2205.02973v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02973">
<div class="article-summary-box-inner">
<span><p>Differential Privacy (DP) provides a formal framework for training machine
learning models with individual example level privacy. In the field of deep
learning, Differentially Private Stochastic Gradient Descent (DP-SGD) has
emerged as a popular private training algorithm. Unfortunately, the
computational cost of training large-scale models with DP-SGD is substantially
higher than non-private training. This is further exacerbated by the fact that
increasing the number of parameters leads to larger degradation in utility with
DP. In this work, we zoom in on the ImageNet dataset and demonstrate that,
similar to the non-private case, pre-training over-parameterized models on a
large public dataset can lead to substantial gains when the model is finetuned
privately. Moreover, by systematically comparing private and non-private models
across a range of large batch sizes, we find that similar to non-private
setting, choice of optimizer can further improve performance substantially with
DP. By using LAMB optimizer with DP-SGD we saw improvement of up to 20$\%$
points (absolute). Finally, we show that finetuning just the last layer for a
\emph{single step} in the full batch setting, combined with extremely
small-scale (near-zero) initialization leads to both SOTA results of 81.7 $\%$
under a wide privacy budget range of $\epsilon \in [4, 10]$ and $\delta$ =
$10^{-6}$ while minimizing the computational overhead substantially.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HierAttn: Effectively Learn Representations from Stage Attention and Branch Attention for Skin Lesions Diagnosis. (arXiv:2205.04326v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.04326">
<div class="article-summary-box-inner">
<span><p>Accurate and unbiased examinations of skin lesions are critical for the early
diagnosis and treatment of skin conditions and disorders. Visual features of
skin lesions vary significantly because the skin images are collected from
patients with different skin colours and morphologies by using dissimilar
imaging equipment. Recent studies have reported ensembled convolutional neural
networks (CNNs) to classify the images for early diagnosis of skin disorders.
However, the practical use of these ensembled CNNs is limited because they are
heavyweight and inadequate for using contextual information. Although
lightweight networks (e.g., MobileNetV3 and EfficientNet) were developed to
achieve parameters reduction for implementing deep neural networks on mobile
devices, insufficient depth of feature representation restricts the
performance. To address the existing limitations, we introduce a new lite and
effective neural network, namely HierAttn. The HierAttn applies a novel
strategy to learn the local and global features by using multi-stage and
multi-branch attention mechanisms. The efficacy of HierAttn was evaluated by
using the dermoscopy images dataset ISIC2019 and smartphone photos dataset
PAD-UFES-20. The experimental results show that HierAttn achieves the best
top-1 accuracy and AUC among the state-of-the-art lightweight networks. The
code is available at https://github.com/anthonyweidai/HierAttn.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HULC: 3D Human Motion Capture with Pose Manifold Sampling and Dense Contact Guidance. (arXiv:2205.05677v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05677">
<div class="article-summary-box-inner">
<span><p>Marker-less monocular 3D human motion capture (MoCap) with scene interactions
is a challenging research topic relevant for extended reality, robotics and
virtual avatar generation. Due to the inherent depth ambiguity of monocular
settings, 3D motions captured with existing methods often contain severe
artefacts such as incorrect body-scene inter-penetrations, jitter and body
floating. To tackle these issues, we propose HULC, a new approach for 3D human
MoCap which is aware of the scene geometry. HULC estimates 3D poses and dense
body-environment surface contacts for improved 3D localisations, as well as the
absolute scale of the subject. Furthermore, we introduce a 3D pose trajectory
optimisation based on a novel pose manifold sampling that resolves erroneous
body-environment inter-penetrations. Although the proposed method requires less
structured inputs compared to existing scene-aware monocular MoCap algorithms,
it produces more physically-plausible poses: HULC significantly and
consistently outperforms the existing approaches in various experiments and on
different metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topologically-Aware Deformation Fields for Single-View 3D Reconstruction. (arXiv:2205.06267v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06267">
<div class="article-summary-box-inner">
<span><p>We present a framework for learning 3D object shapes and dense cross-object
3D correspondences from just an unaligned category-specific image collection.
The 3D shapes are generated implicitly as deformations to a category-specific
signed distance field and are learned in an unsupervised manner solely from
unaligned image collections and their poses without any 3D supervision.
Generally, image collections on the internet contain several intra-category
geometric and topological variations, for example, different chairs can have
different topologies, which makes the task of joint shape and correspondence
estimation much more challenging. Because of this, prior works either focus on
learning each 3D object shape individually without modeling cross-instance
correspondences or perform joint shape and correspondence estimation on
categories with minimal intra-category topological variations. We overcome
these restrictions by learning a topologically-aware implicit deformation field
that maps a 3D point in the object space to a higher dimensional point in the
category-specific canonical space. At inference time, given a single image, we
reconstruct the underlying 3D shape by first implicitly deforming each 3D point
in the object space to the learned category-specific canonical space using the
topologically-aware deformation field and then reconstructing the 3D shape as a
canonical signed distance field. Both canonical shape and deformation field are
learned end-to-end in an inverse-graphics fashion using a learned recurrent ray
marcher (SRN) as a differentiable rendering module. Our approach, dubbed TARS,
achieves state-of-the-art reconstruction fidelity on several datasets:
ShapeNet, Pascal3D+, CUB, and Pix3D chairs. Result videos and code at
https://shivamduggal4.github.io/tars-3D/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collaborative Attention Memory Network for Video Object Segmentation. (arXiv:2205.08075v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08075">
<div class="article-summary-box-inner">
<span><p>Semi-supervised video object segmentation is a fundamental yet Challenging
task in computer vision. Embedding matching based CFBI series networks have
achieved promising results by foreground-background integration approach.
Despite its superior performance, these works exhibit distinct shortcomings,
especially the false predictions caused by little appearance instances in first
frame, even they could easily be recognized by previous frame. Moreover, they
suffer from object's occlusion and error drifts. In order to overcome the
shortcomings , we propose Collaborative Attention Memory Network with an
enhanced segmentation head. We introduce a object context scheme that
explicitly enhances the object information, which aims at only gathering the
pixels that belong to the same category as a given pixel as its context.
Additionally, a segmentation head with Feature Pyramid Attention(FPA) module is
adopted to perform spatial pyramid attention structure on high-level output.
Furthermore, we propose an ensemble network to combine STM network with all
these new refined CFBI network. Finally, we evaluated our approach on the 2021
Youtube-VOS challenge where we obtain 6th place with an overall score of
83.5\%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pairwise Comparison Network for Remote Sensing Scene Classification. (arXiv:2205.08147v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08147">
<div class="article-summary-box-inner">
<span><p>Remote sensing scene classification aims to assign a specific semantic label
to a remote sensing image. Recently, convolutional neural networks have greatly
improved the performance of remote sensing scene classification. However, some
confused images may be easily recognized as the incorrect category, which
generally degrade the performance. The differences between image pairs can be
used to distinguish image categories. This paper proposed a pairwise comparison
network, which contains two main steps: pairwise selection and pairwise
representation. The proposed network first selects similar image pairs, and
then represents the image pairs with pairwise representations. The
self-representation is introduced to highlight the informative parts of each
image itself, while the mutual-representation is proposed to capture the subtle
differences between image pairs. Comprehensive experimental results on two
challenging datasets (AID, NWPU-RESISC45) demonstrate the effectiveness of the
proposed network. The codes are provided in
https://github.com/spectralpublic/PCNet.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Interactive Image Matting. (arXiv:2205.08324v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08324">
<div class="article-summary-box-inner">
<span><p>Recent image matting studies are developing towards proposing trimap-free or
interactive methods for complete complex image matting tasks. Although avoiding
the extensive labors of trimap annotation, existing methods still suffer from
two limitations: (1) For the single image with multiple objects, it is
essential to provide extra interaction information to help determining the
matting target; (2) For transparent objects, the accurate regression of alpha
matte from RGB image is much more difficult compared with the opaque ones. In
this work, we propose a Unified Interactive image Matting method, named UIM,
which solves the limitations and achieves satisfying matting results for any
scenario. Specifically, UIM leverages multiple types of user interaction to
avoid the ambiguity of multiple matting targets, and we compare the pros and
cons of different annotation types in detail. To unify the matting performance
for transparent and opaque objects, we decouple image matting into two stages,
i.e., foreground segmentation and transparency prediction. Moreover, we design
a multi-scale attentive fusion module to alleviate the vagueness in the
boundary region. Experimental results demonstrate that UIM achieves
state-of-the-art performance on the Composition-1K test set and a synthetic
unified dataset. Our code and models will be released soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global Contrast Masked Autoencoders Are Powerful Pathological Representation Learners. (arXiv:2205.09048v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09048">
<div class="article-summary-box-inner">
<span><p>Based on digital whole slide scanning technique, artificial intelligence
algorithms represented by deep learning have achieved remarkable results in the
field of computational pathology. Compared with other medical images such as
Computed Tomography (CT) or Magnetic Resonance Imaging (MRI), pathological
images are more difficult to annotate, thus there is an extreme lack of data
sets that can be used for supervised learning. In this study, a self-supervised
learning (SSL) model, Global Contrast Masked Autoencoders (GCMAE), is proposed,
which has the ability to represent both global and local domain-specific
features of whole slide image (WSI), as well as excellent cross-data transfer
ability. The Camelyon16 and NCTCRC datasets are used to evaluate the
performance of our model. When dealing with transfer learning tasks with
different data sets, the experimental results show that GCMAE has better linear
classification accuracy than MAE, which can reach 81.10% and 89.22%
respectively. Our method outperforms the previous state-of-the-art algorithm
and even surpass supervised learning (improved by 3.86% on NCTCRC data sets).
The source code of this paper is publicly available at
https://github.com/StarUniversus/gcmae
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TRT-ViT: TensorRT-oriented Vision Transformer. (arXiv:2205.09579v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09579">
<div class="article-summary-box-inner">
<span><p>We revisit the existing excellent Transformers from the perspective of
practical application. Most of them are not even as efficient as the basic
ResNets series and deviate from the realistic deployment scenario. It may be
due to the current criterion to measure computation efficiency, such as FLOPs
or parameters is one-sided, sub-optimal, and hardware-insensitive. Thus, this
paper directly treats the TensorRT latency on the specific hardware as an
efficiency metric, which provides more comprehensive feedback involving
computational capacity, memory cost, and bandwidth. Based on a series of
controlled experiments, this work derives four practical guidelines for
TensorRT-oriented and deployment-friendly network design, e.g., early CNN and
late Transformer at stage-level, early Transformer and late CNN at block-level.
Accordingly, a family of TensortRT-oriented Transformers is presented,
abbreviated as TRT-ViT. Extensive experiments demonstrate that TRT-ViT
significantly outperforms existing ConvNets and vision Transformers with
respect to the latency/accuracy trade-off across diverse visual tasks, e.g.,
image classification, object detection and semantic segmentation. For example,
at 82.7% ImageNet-1k top-1 accuracy, TRT-ViT is 2.7$\times$ faster than CSWin
and 2.0$\times$ faster than Twins. On the MS-COCO object detection task,
TRT-ViT achieves comparable performance with Twins, while the inference speed
is increased by 2.8$\times$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Font Generation by Learning Fine-Grained Local Styles. (arXiv:2205.09965v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09965">
<div class="article-summary-box-inner">
<span><p>Few-shot font generation (FFG), which aims to generate a new font with a few
examples, is gaining increasing attention due to the significant reduction in
labor cost. A typical FFG pipeline considers characters in a standard font
library as content glyphs and transfers them to a new target font by extracting
style information from the reference glyphs. Most existing solutions explicitly
disentangle content and style of reference glyphs globally or component-wisely.
However, the style of glyphs mainly lies in the local details, i.e. the styles
of radicals, components, and strokes together depict the style of a glyph.
Therefore, even a single character can contain different styles distributed
over spatial locations. In this paper, we propose a new font generation
approach by learning 1) the fine-grained local styles from references, and 2)
the spatial correspondence between the content and reference glyphs. Therefore,
each spatial location in the content glyph can be assigned with the right
fine-grained style. To this end, we adopt cross-attention over the
representation of the content glyphs as the queries and the representations of
the reference glyphs as the keys and values. Instead of explicitly
disentangling global or component-wise modeling, the cross-attention mechanism
can attend to the right local styles in the reference glyphs and aggregate the
reference styles into a fine-grained style representation for the given content
glyphs. The experiments show that the proposed method outperforms the
state-of-the-art methods in FFG. In particular, the user studies also
demonstrate the style consistency of our approach significantly outperforms
previous methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MSTRIQ: No Reference Image Quality Assessment Based on Swin Transformer with Multi-Stage Fusion. (arXiv:2205.10101v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10101">
<div class="article-summary-box-inner">
<span><p>Measuring the perceptual quality of images automatically is an essential task
in the area of computer vision, as degradations on image quality can exist in
many processes from image acquisition, transmission to enhancing. Many Image
Quality Assessment(IQA) algorithms have been designed to tackle this problem.
However, it still remains un settled due to the various types of image
distortions and the lack of large-scale human-rated datasets. In this paper, we
propose a novel algorithm based on the Swin Transformer [31] with fused
features from multiple stages, which aggregates information from both local and
global features to better predict the quality. To address the issues of
small-scale datasets, relative rankings of images have been taken into account
together with regression loss to simultaneously optimize the model.
Furthermore, effective data augmentation strategies are also used to improve
the performance. In comparisons with previous works, experiments are carried
out on two standard IQA datasets and a challenge dataset. The results
demonstrate the effectiveness of our work. The proposed method outperforms
other methods on standard datasets and ranks 2nd in the no-reference track of
NTIRE 2022 Perceptual Image Quality Assessment Challenge [53]. It verifies that
our method is promising in solving diverse IQA problems and thus can be used to
real-word applications.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-05-24 23:09:13.721583098 UTC">2022-05-24 23:09:13 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>