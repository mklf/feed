<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-01-13T01:30:00Z">01-13</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">A Feature Extraction based Model for Hate Speech Identification. (arXiv:2201.04227v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04227">
<div class="article-summary-box-inner">
<span><p>The detection of hate speech online has become an important task, as
offensive language such as hurtful, obscene and insulting content can harm
marginalized people or groups. This paper presents TU Berlin team experiments
and results on the task 1A and 1B of the shared task on hate speech and
offensive content identification in Indo-European languages 2021. The success
of different Natural Language Processing models is evaluated for the respective
subtasks throughout the competition. We tested different models based on
recurrent neural networks in word and character levels and transfer learning
approaches based on Bert on the provided dataset by the competition. Among the
tested models that have been used for the experiments, the transfer
learning-based models achieved the best results in both subtasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PhysNLU: A Language Resource for Evaluating Natural Language Understanding and Explanation Coherence in Physics. (arXiv:2201.04275v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04275">
<div class="article-summary-box-inner">
<span><p>In order for language models to aid physics research, they must first encode
representations of mathematical and natural language discourse which lead to
coherent explanations, with correct ordering and relevance of statements. We
present a collection of datasets developed to evaluate the performance of
language models in this regard, which measure capabilities with respect to
sentence ordering, position, section prediction, and discourse coherence.
Analysis of the data reveals equations and sub-disciplines which are most
common in physics discourse, as well as the sentence-level frequency of
equations and expressions. We present baselines which demonstrate how
contemporary language models are challenged by coherence related tasks in
physics, even when trained on mathematical natural language objectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptBERT: Improving BERT Sentence Embeddings with Prompts. (arXiv:2201.04337v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04337">
<div class="article-summary-box-inner">
<span><p>The poor performance of the original BERT for sentence semantic similarity
has been widely discussed in previous works. We find that unsatisfactory
performance is mainly due to the static token embeddings biases and the
ineffective BERT layers, rather than the high cosine similarity of the sentence
embeddings. To this end, we propose a prompt based sentence embeddings method
which can reduce token embeddings biases and make the original BERT layers more
effective. By reformulating the sentence embeddings task as the
fillin-the-blanks problem, our method significantly improves the performance of
original BERT. We discuss two prompt representing methods and three prompt
searching methods for prompt based sentence embeddings. Moreover, we propose a
novel unsupervised training objective by the technology of template denoising,
which substantially shortens the performance gap between the supervised and
unsupervised setting. For experiments, we evaluate our method on both non
fine-tuned and fine-tuned settings. Even a non fine-tuned method can outperform
the fine-tuned methods like unsupervised ConSERT on STS tasks. Our fine-tuned
method outperforms the state-of-the-art method SimCSE in both unsupervised and
supervised settings. Compared to SimCSE, we achieve 2.29 and 2.58 points
improvements on BERT and RoBERTa respectively under the unsupervised setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computational analyses of the topics, sentiments, literariness, creativity and beauty of texts in a large Corpus of English Literature. (arXiv:2201.04356v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04356">
<div class="article-summary-box-inner">
<span><p>The Gutenberg Literary English Corpus (GLEC, Jacobs, 2018a) provides a rich
source of textual data for research in digital humanities, computational
linguistics or neurocognitive poetics. In this study we address differences
among the different literature categories in GLEC, as well as differences
between authors. We report the results of three studies providing i) topic and
sentiment analyses for six text categories of GLEC (i.e., children and youth,
essays, novels, plays, poems, stories) and its &gt;100 authors, ii) novel measures
of semantic complexity as indices of the literariness, creativity and book
beauty of the works in GLEC (e.g., Jane Austen's six novels), and iii) two
experiments on text classification and authorship recognition using novel
features of semantic complexity. The data on two novel measures estimating a
text's literariness, intratextual variance and stepwise distance (van
Cranenburgh et al., 2019) revealed that plays are the most literary texts in
GLEC, followed by poems and novels. Computation of a novel index of text
creativity (Gray et al., 2016) revealed poems and plays as the most creative
categories with the most creative authors all being poets (Milton, Pope, Keats,
Byron, or Wordsworth). We also computed a novel index of perceived beauty of
verbal art (Kintsch, 2012) for the works in GLEC and predict that Emma is the
theoretically most beautiful of Austen's novels. Finally, we demonstrate that
these novel measures of semantic complexity are important features for text
classification and authorship recognition with overall predictive accuracies in
the range of .75 to .97. Our data pave the way for future computational and
empirical studies of literature or experiments in reading psychology and offer
multiple baselines and benchmarks for analysing and validating other book
corpora.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Modeling on Podcast Short-Text Metadata. (arXiv:2201.04419v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04419">
<div class="article-summary-box-inner">
<span><p>Podcasts have emerged as a massively consumed online content, notably due to
wider accessibility of production means and scaled distribution through large
streaming platforms. Categorization systems and information access technologies
typically use topics as the primary way to organize or navigate podcast
collections. However, annotating podcasts with topics is still quite
problematic because the assigned editorial genres are broad, heterogeneous or
misleading, or because of data challenges (e.g. short metadata text, noisy
transcripts). Here, we assess the feasibility to discover relevant topics from
podcast metadata, titles and descriptions, using topic modeling techniques for
short text. We also propose a new strategy to leverage named entities (NEs),
often present in podcast metadata, in a Non-negative Matrix Factorization (NMF)
topic modeling framework. Our experiments on two existing datasets from Spotify
and iTunes and Deezer, a new dataset from an online service providing a catalog
of podcasts, show that our proposed document representation, NEiCE, leads to
improved topic coherence over the baselines. We release the code for
experimental reproducibility of the results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiating Geographic Movement Described in Text Documents. (arXiv:2201.04427v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04427">
<div class="article-summary-box-inner">
<span><p>Understanding movement described in text documents is important since text
descriptions of movement contain a wealth of geographic and contextual
information about the movement of people, wildlife, goods, and much more. Our
research makes several contributions to improve our understanding of movement
descriptions in text. First, we show how interpreting geographic movement
described in text is challenging because of general spatial terms, linguistic
constructions that make the thing(s) moving unclear, and many types of temporal
references and groupings, among others. Next, as a step to overcome these
challenges, we report on an experiment with human subjects through which we
identify multiple important characteristics of movement descriptions (found in
text) that humans use to differentiate one movement description from another.
Based on our empirical results, we provide recommendations for computational
analysis using movement described in text documents. Our findings contribute
towards an improved understanding of the important characteristics of the
underused information about geographic movement that is in the form of text
descriptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Biaffine Discourse Dependency Parsing. (arXiv:2201.04450v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04450">
<div class="article-summary-box-inner">
<span><p>We provide a study of using the biaffine model for neural discourse
dependency parsing and achieve significant performance improvement compared
with the baseline parsers. We compare the Eisner algorithm and the
Chu-Liu-Edmonds algorithm in the task and find that using the Chu-Liu-Edmonds
algorithm generates deeper trees and achieves better performance. We also
evaluate the structure of the output of the parser with average maximum path
length and average proportion of leaf nodes and find that the dependency trees
generated by the parser are close to the gold trees. As the corpus allows
non-projective structures, we analyze the complexity of non-projectivity of the
corpus and find that the dependency structures in this corpus have gap degree
at most one and edge degree at most one.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diagnosing BERT with Retrieval Heuristics. (arXiv:2201.04458v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04458">
<div class="article-summary-box-inner">
<span><p>Word embeddings, made widely popular in 2013 with the release of word2vec,
have become a mainstay of NLP engineering pipelines. Recently, with the release
of BERT, word embeddings have moved from the term-based embedding space to the
contextual embedding space -- each term is no longer represented by a single
low-dimensional vector but instead each term and \emph{its context} determine
the vector weights. BERT's setup and architecture have been shown to be general
enough to be applicable to many natural language tasks. Importantly for
Information Retrieval (IR), in contrast to prior deep learning solutions to IR
problems which required significant tuning of neural net architectures and
training regimes, "vanilla BERT" has been shown to outperform existing
retrieval algorithms by a wide margin, including on tasks and corpora that have
long resisted retrieval effectiveness gains over traditional IR baselines (such
as Robust04). In this paper, we employ the recently proposed axiomatic dataset
analysis technique -- that is, we create diagnostic datasets that each fulfil a
retrieval heuristic (both term matching and semantic-based) -- to explore what
BERT is able to learn. In contrast to our expectations, we find BERT, when
applied to a recently released large-scale web corpus with ad-hoc topics, to
\emph{not} adhere to any of the explored axioms. At the same time, BERT
outperforms the traditional query likelihood retrieval model by 40\%. This
means that the axiomatic approach to IR (and its extension of diagnostic
datasets created for retrieval heuristics) may in its current form not be
applicable to large-scale corpora. Additional -- different -- axioms are
needed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Does Data Corruption Affect Natural Language Understanding Models? A Study on GLUE datasets. (arXiv:2201.04467v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04467">
<div class="article-summary-box-inner">
<span><p>A central question in natural language understanding (NLU) research is
whether high performance demonstrates the models' strong reasoning
capabilities. We present an extensive series of controlled experiments where
pre-trained language models are exposed to data that have undergone specific
corruption transformations. The transformations involve removing instances of
specific word classes and often lead to non-sensical sentences. Our results
show that performance remains high for most GLUE tasks when the models are
fine-tuned or tested on corrupted data, suggesting that the models leverage
other cues for prediction even in non-sensical contexts. Our proposed data
transformations can be used as a diagnostic tool for assessing the extent to
which a specific dataset constitutes a proper testbed for evaluating models'
language understanding capabilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interacting with Explanations through Critiquing. (arXiv:2005.11067v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.11067">
<div class="article-summary-box-inner">
<span><p>Using personalized explanations to support recommendations has been shown to
increase trust and perceived quality. However, to actually obtain better
recommendations, there needs to be a means for users to modify the
recommendation criteria by interacting with the explanation. We present a novel
technique using aspect markers that learns to generate personalized
explanations of recommendations from review texts, and we show that human users
significantly prefer these explanations over those produced by state-of-the-art
techniques. Our work's most important innovation is that it allows users to
react to a recommendation by critiquing the textual explanation: removing
(symmetrically adding) certain aspects they dislike or that are no longer
relevant (symmetrically that are of interest). The system updates its user
model and the resulting recommendations according to the critique. This is
based on a novel unsupervised critiquing method for single- and multi-step
critiquing with textual explanations. Experiments on two real-world datasets
show that our system is the first to achieve good performance in adapting to
the preferences expressed in multi-step critiquing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence Level Contrastive Learning for Text Summarization. (arXiv:2109.03481v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03481">
<div class="article-summary-box-inner">
<span><p>Contrastive learning models have achieved great success in unsupervised
visual representation learning, which maximize the similarities between feature
representations of different views of the same image, while minimize the
similarities between feature representations of views of different images. In
text summarization, the output summary is a shorter form of the input document
and they have similar meanings. In this paper, we propose a contrastive
learning model for supervised abstractive text summarization, where we view a
document, its gold summary and its model generated summaries as different views
of the same mean representation and maximize the similarities between them
during training. We improve over a strong sequence-to-sequence text generation
model (i.e., BART) on three different summarization datasets. Human evaluation
also shows that our model achieves better faithfulness ratings compared to its
counterpart without contrastive objectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entity-Based Knowledge Conflicts in Question Answering. (arXiv:2109.05052v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05052">
<div class="article-summary-box-inner">
<span><p>Knowledge-dependent tasks typically use two sources of knowledge: parametric,
learned at training time, and contextual, given as a passage at inference time.
To understand how models use these sources together, we formalize the problem
of knowledge conflicts, where the contextual information contradicts the
learned information. Analyzing the behaviour of popular models, we measure
their over-reliance on memorized information (the cause of hallucinations), and
uncover important factors that exacerbate this behaviour. Lastly, we propose a
simple method to mitigate over-reliance on parametric knowledge, which
minimizes hallucination, and improves out-of-distribution generalization by
4%-7%. Our findings demonstrate the importance for practitioners to evaluate
model tendency to hallucinate rather than read, and show that our mitigation
strategy encourages generalization to evolving information (i.e.,
time-dependent queries). To encourage these practices, we have released our
framework for generating knowledge conflicts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text is no more Enough! A Benchmark for Profile-based Spoken Language Understanding. (arXiv:2112.11953v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11953">
<div class="article-summary-box-inner">
<span><p>Current researches on spoken language understanding (SLU) heavily are limited
to a simple setting: the plain text-based SLU that takes the user utterance as
input and generates its corresponding semantic frames (e.g., intent and slots).
Unfortunately, such a simple setting may fail to work in complex real-world
scenarios when an utterance is semantically ambiguous, which cannot be achieved
by the text-based SLU models. In this paper, we first introduce a new and
important task, Profile-based Spoken Language Understanding (ProSLU), which
requires the model that not only relies on the plain text but also the
supporting profile information to predict the correct intents and slots. To
this end, we further introduce a large-scale human-annotated Chinese dataset
with over 5K utterances and their corresponding supporting profile information
(Knowledge Graph (KG), User Profile (UP), Context Awareness (CA)). In addition,
we evaluate several state-of-the-art baseline models and explore a multi-level
knowledge adapter to effectively incorporate profile information. Experimental
results reveal that all existing text-based SLU models fail to work when the
utterances are semantically ambiguous and our proposed framework can
effectively fuse the supporting information for sentence-level intent detection
and token-level slot filling. Finally, we summarize key challenges and provide
new points for future directions, which hopes to facilitate the research.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Overview of the HECKTOR Challenge at MICCAI 2021: Automatic Head and Neck Tumor Segmentation and Outcome Prediction in PET/CT Images. (arXiv:2201.04138v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04138">
<div class="article-summary-box-inner">
<span><p>This paper presents an overview of the second edition of the HEad and neCK
TumOR (HECKTOR) challenge, organized as a satellite event of the 24th
International Conference on Medical Image Computing and Computer Assisted
Intervention (MICCAI) 2021. The challenge is composed of three tasks related to
the automatic analysis of PET/CT images for patients with Head and Neck cancer
(H&amp;N), focusing on the oropharynx region. Task 1 is the automatic segmentation
of H&amp;N primary Gross Tumor Volume (GTVt) in FDG-PET/CT images. Task 2 is the
automatic prediction of Progression Free Survival (PFS) from the same
FDG-PET/CT. Finally, Task 3 is the same as Task 2 with ground truth GTVt
annotations provided to the participants. The data were collected from six
centers for a total of 325 images, split into 224 training and 101 testing
cases. The interest in the challenge was highlighted by the important
participation with 103 registered teams and 448 result submissions. The best
methods obtained a Dice Similarity Coefficient (DSC) of 0.7591 in the first
task, and a Concordance index (C-index) of 0.7196 and 0.6978 in Tasks 2 and 3,
respectively. In all tasks, simplicity of the approach was found to be key to
ensure generalization performance. The comparison of the PFS prediction
performance in Tasks 2 and 3 suggests that providing the GTVt contour was not
crucial to achieve best results, which indicates that fully automatic methods
can be used. This potentially obviates the need for GTVt contouring, opening
avenues for reproducible and large scale radiomics studies including thousands
potential subjects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HyperTransformer: Model Generation for Supervised and Semi-Supervised Few-Shot Learning. (arXiv:2201.04182v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04182">
<div class="article-summary-box-inner">
<span><p>In this work we propose a HyperTransformer, a transformer-based model for
few-shot learning that generates weights of a convolutional neural network
(CNN) directly from support samples. Since the dependence of a small generated
CNN model on a specific task is encoded by a high-capacity transformer model,
we effectively decouple the complexity of the large task space from the
complexity of individual tasks. Our method is particularly effective for small
target CNN architectures where learning a fixed universal task-independent
embedding is not optimal and better performance is attained when the
information about the task can modulate all model parameters. For larger models
we discover that generating the last layer alone allows us to produce
competitive or better results than those obtained with state-of-the-art methods
while being end-to-end differentiable. Finally, we extend our approach to a
semi-supervised regime utilizing unlabeled samples in the support set and
further improving few-shot performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Capacitance: A New Perspective of Neural Network Selection via Edge Dynamics. (arXiv:2201.04194v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04194">
<div class="article-summary-box-inner">
<span><p>Efficient model selection for identifying a suitable pre-trained neural
network to a downstream task is a fundamental yet challenging task in deep
learning. Current practice requires expensive computational costs in model
training for performance prediction. In this paper, we propose a novel
framework for neural network selection by analyzing the governing dynamics over
synaptic connections (edges) during training. Our framework is built on the
fact that back-propagation during neural network training is equivalent to the
dynamical evolution of synaptic connections. Therefore, a converged neural
network is associated with an equilibrium state of a networked system composed
of those edges. To this end, we construct a network mapping $\phi$, converting
a neural network $G_A$ to a directed line graph $G_B$ that is defined on those
edges in $G_A$. Next, we derive a neural capacitance metric $\beta_{\rm eff}$
as a predictive measure universally capturing the generalization capability of
$G_A$ on the downstream task using only a handful of early training results. We
carried out extensive experiments using 17 popular pre-trained ImageNet models
and five benchmark datasets, including CIFAR10, CIFAR100, SVHN, Fashion MNIST
and Birds, to evaluate the fine-tuning performance of our framework. Our neural
capacitance metric is shown to be a powerful indicator for model selection
based only on early training results and is more efficient than
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MDPose: Human Skeletal Motion Reconstruction Using WiFi Micro-Doppler Signatures. (arXiv:2201.04212v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04212">
<div class="article-summary-box-inner">
<span><p>Motion tracking systems based on optical sensors typically often suffer from
issues, such as poor lighting conditions, occlusion, limited coverage, and may
raise privacy concerns. More recently, radio frequency (RF)-based approaches
using commercial WiFi devices have emerged which offer low-cost ubiquitous
sensing whilst preserving privacy. However, the output of an RF sensing system,
such as Range-Doppler spectrograms, cannot represent human motion intuitively
and usually requires further processing. In this study, MDPose, a novel
framework for human skeletal motion reconstruction based on WiFi micro-Doppler
signatures, is proposed. It provides an effective solution to track human
activities by reconstructing a skeleton model with 17 key points, which can
assist with the interpretation of conventional RF sensing outputs in a more
understandable way. Specifically, MDPose has various incremental stages to
gradually address a series of challenges: First, a denoising algorithm is
implemented to remove any unwanted noise that may affect the feature extraction
and enhance weak Doppler signatures. Secondly, the convolutional neural network
(CNN)-recurrent neural network (RNN) architecture is applied to learn
temporal-spatial dependency from clean micro-Doppler signatures and restore key
points' velocity information. Finally, a pose optimising mechanism is employed
to estimate the initial state of the skeleton and to limit the increase of
error. We have conducted comprehensive tests in a variety of environments using
numerous subjects with a single receiver radar system to demonstrate the
performance of MDPose, and report 29.4mm mean absolute error over all key
points positions, which outperforms state-of-the-art RF-based pose estimation
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Region-based Layout Analysis of Music Score Images. (arXiv:2201.04214v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04214">
<div class="article-summary-box-inner">
<span><p>The Layout Analysis (LA) stage is of vital importance to the correct
performance of an Optical Music Recognition (OMR) system. It identifies the
regions of interest, such as staves or lyrics, which must then be processed in
order to transcribe their content. Despite the existence of modern approaches
based on deep learning, an exhaustive study of LA in OMR has not yet been
carried out with regard to the precision of different models, their
generalization to different domains or, more importantly, their impact on
subsequent stages of the pipeline. This work focuses on filling this gap in
literature by means of an experimental study of different neural architectures,
music document types and evaluation scenarios. The need for training data has
also led to a proposal for a new semi-synthetic data generation technique that
enables the efficient applicability of LA approaches in real scenarios. Our
results show that: (i) the choice of the model and its performance are crucial
for the entire transcription process; (ii) the metrics commonly used to
evaluate the LA stage do not always correlate with the final performance of the
OMR system, and (iii) the proposed data-generation technique enables
state-of-the-art results to be achieved with a limited set of labeled data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Brain Signals Analysis Based Deep Learning Methods: Recent advances in the study of non-invasive brain signals. (arXiv:2201.04229v1 [q-bio.NC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04229">
<div class="article-summary-box-inner">
<span><p>Brain signals constitute the information that are processed by millions of
brain neurons (nerve cells and brain cells). These brain signals can be
recorded and analyzed using various of non-invasive techniques such as the
Electroencephalograph (EEG), Magneto-encephalograph (MEG) as well as
brain-imaging techniques such as Magnetic Resonance Imaging (MRI), Computed
Tomography (CT) and others, which will be discussed briefly in this paper. This
paper discusses about the currently emerging techniques such as the usage of
different Deep Learning (DL) algorithms for the analysis of these brain signals
and how these algorithms will be helpful in determining the neurological status
of a person by applying the signal decoding strategy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SmartDet: Context-Aware Dynamic Control of Edge Task Offloading for Mobile Object Detection. (arXiv:2201.04235v1 [cs.DC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04235">
<div class="article-summary-box-inner">
<span><p>Mobile devices increasingly rely on object detection (OD) through deep neural
networks (DNNs) to perform critical tasks. Due to their high complexity, the
execution of these DNNs requires excessive time and energy. Low-complexity
object tracking (OT) can be used with OD, where the latter is periodically
applied to generate "fresh" references for tracking. However, the frames
processed with OD incur large delays, which may make the reference outdated and
degrade tracking quality. Herein, we propose to use edge computing in this
context, and establish parallel OT (at the mobile device) and OD (at the edge
server) processes that are resilient to large OD latency. We propose Katch-Up,
a novel tracking mechanism that improves the system resilience to excessive OD
delay. However, while Katch-Up significantly improves performance, it also
increases the computing load of the mobile device. Hence, we design SmartDet, a
low-complexity controller based on deep reinforcement learning (DRL) that
learns controlling the trade-off between resource utilization and OD
performance. SmartDet takes as input context-related information related to the
current video content and the current network conditions to optimize frequency
and type of OD offloading, as well as Katch-Up utilization. We extensively
evaluate SmartDet on a real-world testbed composed of a JetSon Nano as mobile
device and a GTX 980 Ti as edge server, connected through a Wi-Fi link.
Experimental results show that SmartDet achieves an optimal balance between
tracking performance - mean Average Recall (mAR) and resource usage. With
respect to a baseline with full Katch-Upusage and maximum channel usage, we
still increase mAR by 4% while using 50% less of the channel and 30% power
resources associated with Katch-Up. With respect to a fixed strategy using
minimal resources, we increase mAR by 20% while using Katch-Up on 1/3 of the
frames.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incidents1M: a large-scale dataset of images with natural disasters, damage, and incidents. (arXiv:2201.04236v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04236">
<div class="article-summary-box-inner">
<span><p>Natural disasters, such as floods, tornadoes, or wildfires, are increasingly
pervasive as the Earth undergoes global warming. It is difficult to predict
when and where an incident will occur, so timely emergency response is critical
to saving the lives of those endangered by destructive events. Fortunately,
technology can play a role in these situations. Social media posts can be used
as a low-latency data source to understand the progression and aftermath of a
disaster, yet parsing this data is tedious without automated methods. Prior
work has mostly focused on text-based filtering, yet image and video-based
filtering remains largely unexplored. In this work, we present the Incidents1M
Dataset, a large-scale multi-label dataset which contains 977,088 images, with
43 incident and 49 place categories. We provide details of the dataset
construction, statistics and potential biases; introduce and train a model for
incident detection; and perform image-filtering experiments on millions of
images on Flickr and Twitter. We also present some applications on incident
analysis to encourage and enable future work in computer vision for
humanitarian aid. Code, data, and models are available at
<a href="http://incidentsdataset.csail.mit.edu.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamical Audio-Visual Navigation: Catching Unheard Moving Sound Sources in Unmapped 3D Environments. (arXiv:2201.04279v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04279">
<div class="article-summary-box-inner">
<span><p>Recent work on audio-visual navigation targets a single static sound in
noise-free audio environments and struggles to generalize to unheard sounds. We
introduce the novel dynamic audio-visual navigation benchmark in which an
embodied AI agent must catch a moving sound source in an unmapped environment
in the presence of distractors and noisy sounds. We propose an end-to-end
reinforcement learning approach that relies on a multi-modal architecture that
fuses the spatial audio-visual information from a binaural audio signal and
spatial occupancy maps to encode the features needed to learn a robust
navigation policy for our new complex task settings. We demonstrate that our
approach outperforms the current state-of-the-art with better generalization to
unheard sounds and better robustness to noisy scenarios on the two challenging
3D scanned real-world datasets Replica and Matterport3D, for the static and
dynamic audio-visual navigation benchmarks. Our novel benchmark will be made
available at <a href="http://dav-nav.cs.uni-freiburg.de.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiview Transformers for Video Recognition. (arXiv:2201.04288v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04288">
<div class="article-summary-box-inner">
<span><p>Video understanding requires reasoning at multiple spatiotemporal resolutions
-- from short fine-grained motions to events taking place over longer
durations. Although transformer architectures have recently advanced the
state-of-the-art, they have not explicitly modelled different spatiotemporal
resolutions. To this end, we present Multiview Transformers for Video
Recognition (MTV). Our model consists of separate encoders to represent
different views of the input video with lateral connections to fuse information
across views. We present thorough ablation studies of our model and show that
MTV consistently performs better than single-view counterparts in terms of
accuracy and computational cost across a range of model sizes. Furthermore, we
achieve state-of-the-art results on five standard datasets, and improve even
further with large-scale pretraining. We will release code and pretrained
checkpoints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Contrastive Learning against Noisy Views. (arXiv:2201.04309v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04309">
<div class="article-summary-box-inner">
<span><p>Contrastive learning relies on an assumption that positive pairs contain
related views, e.g., patches of an image or co-occurring multimodal signals of
a video, that share certain underlying information about an instance. But what
if this assumption is violated? The literature suggests that contrastive
learning produces suboptimal representations in the presence of noisy views,
e.g., false positive pairs with no apparent shared information. In this work,
we propose a new contrastive loss function that is robust against noisy views.
We provide rigorous theoretical justifications by showing connections to robust
symmetric losses for noisy binary classification and by establishing a new
contrastive bound for mutual information maximization based on the Wasserstein
distance measure. The proposed loss is completely modality-agnostic and a
simple drop-in replacement for the InfoNCE loss, which makes it easy to apply
to existing contrastive frameworks. We show that our approach provides
consistent improvements over the state-of-the-art on image, video, and graph
contrastive learning benchmarks that exhibit a variety of real-world noise
patterns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knee Cartilage Defect Assessment by Graph Representation and Surface Convolution. (arXiv:2201.04318v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04318">
<div class="article-summary-box-inner">
<span><p>Knee osteoarthritis (OA) is the most common osteoarthritis and a leading
cause of disability. Cartilage defects are regarded as major manifestations of
knee OA, which are visible by magnetic resonance imaging (MRI). Thus early
detection and assessment for knee cartilage defects are important for
protecting patients from knee OA. In this way, many attempts have been made on
knee cartilage defect assessment by applying convolutional neural networks
(CNNs) to knee MRI. However, the physiologic characteristics of the cartilage
may hinder such efforts: the cartilage is a thin curved layer, implying that
only a small portion of voxels in knee MRI can contribute to the cartilage
defect assessment; heterogeneous scanning protocols further challenge the
feasibility of the CNNs in clinical practice; the CNN-based knee cartilage
evaluation results lack interpretability. To address these challenges, we model
the cartilages structure and appearance from knee MRI into a graph
representation, which is capable of handling highly diverse clinical data.
Then, guided by the cartilage graph representation, we design a non-Euclidean
deep learning network with the self-attention mechanism, to extract cartilage
features in the local and global, and to derive the final assessment with a
visualized result. Our comprehensive experiments show that the proposed method
yields superior performance in knee cartilage defect assessment, plus its
convenient 3D visualization for interpretability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Residual Flow Fields for Efficient Video Representations. (arXiv:2201.04329v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04329">
<div class="article-summary-box-inner">
<span><p>Implicit neural representation (INR) has emerged as a powerful paradigm for
representing signals, such as images, videos, 3D shapes, etc. Although it has
shown the ability to represent fine details, its efficiency as a data
representation has not been extensively studied. In INR, the data is stored in
the form of parameters of a neural network and general purpose optimization
algorithms do not generally exploit the spatial and temporal redundancy in
signals. In this paper, we suggest a novel INR approach to representing and
compressing videos by explicitly removing data redundancy. Instead of storing
raw RGB colors, we propose Neural Residual Flow Fields (NRFF), using motion
information across video frames and residuals that are necessary to reconstruct
a video. Maintaining the motion information, which is usually smoother and less
complex than the raw signals, requires far fewer parameters. Furthermore,
reusing redundant pixel values further improves the network parameter
efficiency. Experimental results have shown that the proposed method
outperforms the baseline methods by a significant margin. The code is available
in https://github.com/daniel03c1/eff_video_representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MDS-Net: A Multi-scale Depth Stratification Based Monocular 3D Object Detection Algorithm. (arXiv:2201.04341v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04341">
<div class="article-summary-box-inner">
<span><p>Monocular 3D object detection is very challenging in autonomous driving due
to the lack of depth information. This paper proposes a one-stage monocular 3D
object detection algorithm based on multi-scale depth stratification, which
uses the anchor-free method to detect 3D objects in a per-pixel prediction. In
the proposed MDS-Net, a novel depth-based stratification structure is developed
to improve the network's ability of depth prediction by establishing
mathematical models between depth and image size of objects. A new angle loss
function is then developed to further improve the accuracy of the angle
prediction and increase the convergence speed of training. An optimized
soft-NMS is finally applied in the post-processing stage to adjust the
confidence of candidate boxes. Experiments on the KITTI benchmark show that the
MDS-Net outperforms the existing monocular 3D detection methods in 3D detection
and BEV detection tasks while fulfilling real-time requirements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution. (arXiv:2201.04358v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04358">
<div class="article-summary-box-inner">
<span><p>Reference-based super-resolution (RefSR) has made significant progress in
producing realistic textures using an external reference (Ref) image. However,
existing RefSR methods obtain high-quality correspondence matchings consuming
quadratic computation resources with respect to the input size, limiting its
application. Moreover, these approaches usually suffer from scale misalignments
between the low-resolution (LR) image and Ref image. In this paper, we propose
an Accelerated Multi-Scale Aggregation network (AMSA) for Reference-based
Super-Resolution, including Coarse-to-Fine Embedded PatchMatch (CFE-PatchMatch)
and Multi-Scale Dynamic Aggregation (MSDA) module. To improve matching
efficiency, we design a novel Embedded PatchMacth scheme with random samples
propagation, which involves end-to-end training with asymptotic linear
computational cost to the input size. To further reduce computational cost and
speed up convergence, we apply the coarse-to-fine strategy on Embedded
PatchMacth constituting CFE-PatchMatch. To fully leverage reference information
across multiple scales and enhance robustness to scale misalignment, we develop
the MSDA module consisting of Dynamic Aggregation and Multi-Scale Aggregation.
The Dynamic Aggregation corrects minor scale misalignment by dynamically
aggregating features, and the Multi-Scale Aggregation brings robustness to
large scale misalignment by fusing multi-scale information. Experimental
results show that the proposed AMSA achieves superior performance over
state-of-the-art approaches on both quantitative and qualitative evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SCSNet: An Efficient Paradigm for Learning Simultaneously Image Colorization and Super-Resolution. (arXiv:2201.04364v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04364">
<div class="article-summary-box-inner">
<span><p>In the practical application of restoring low-resolution gray-scale images,
we generally need to run three separate processes of image colorization,
super-resolution, and dows-sampling operation for the target device. However,
this pipeline is redundant and inefficient for the independent processes, and
some inner features could have been shared. Therefore, we present an efficient
paradigm to perform {S}imultaneously Image {C}olorization and
{S}uper-resolution (SCS) and propose an end-to-end SCSNet to achieve this goal.
The proposed method consists of two parts: colorization branch for learning
color information that employs the proposed plug-and-play \emph{Pyramid Valve
Cross Attention} (PVCAttn) module to aggregate feature maps between source and
reference images; and super-resolution branch for integrating color and texture
information to predict target images, which uses the designed \emph{Continuous
Pixel Mapping} (CPM) module to predict high-resolution images at continuous
magnification. Furthermore, our SCSNet supports both automatic and referential
modes that is more flexible for practical application. Abundant experiments
demonstrate the superiority of our method for generating authentic images over
state-of-the-art methods, e.g., averagely decreasing FID by 1.8$\downarrow$ and
5.1 $\downarrow$ compared with current best scores for automatic and
referential modes, respectively, while owning fewer parameters (more than
$\times$2$\downarrow$) and faster running speed (more than
$\times$3$\uparrow$).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Alzheimer's Disease Using 3DMgNet. (arXiv:2201.04370v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04370">
<div class="article-summary-box-inner">
<span><p>Alzheimer's disease (AD) is an irreversible neurode generative disease of the
brain.The disease may causes memory loss, difficulty communicating and
disorientation. For the diagnosis of Alzheimer's disease, a series of scales
are often needed to evaluate the diagnosis clinically, which not only increases
the workload of doctors, but also makes the results of diagnosis highly
subjective. Therefore, for Alzheimer's disease, imaging means to find early
diagnostic markers has become a top priority.
</p>
<p>In this paper, we propose a novel 3DMgNet architecture which is a unified
framework of multigrid and convolutional neural network to diagnose Alzheimer's
disease (AD). The model is trained using an open dataset (ADNI dataset) and
then test with a smaller dataset of ours. Finally, the model achieved 92.133%
accuracy for AD vs NC classification and significantly reduced the model
parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Maximizing Self-supervision from Thermal Image for Effective Self-supervised Learning of Depth and Ego-motion. (arXiv:2201.04387v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04387">
<div class="article-summary-box-inner">
<span><p>Recently, self-supervised learning of depth and ego-motion from thermal
images shows strong robustness and reliability under challenging scenarios.
However, the inherent thermal image properties such as weak contrast, blurry
edges, and noise hinder to generate effective self-supervision from thermal
images. Therefore, most research relies on additional self-supervision sources
such as well-lit RGB images, generative models, and Lidar information. In this
paper, we conduct an in-depth analysis of thermal image characteristics that
degenerates self-supervision from thermal images. Based on the analysis, we
propose an effective thermal image mapping method that significantly increases
image information, such as overall structure, contrast, and details, while
preserving temporal consistency. The proposed method shows outperformed depth
and pose results than previous state-of-the-art networks without leveraging
additional RGB guidance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OCSampler: Compressing Videos to One Clip with Single-step Sampling. (arXiv:2201.04388v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04388">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a framework named OCSampler to explore a compact
yet effective video representation with one short clip for efficient video
recognition. Recent works prefer to formulate frame sampling as a sequential
decision task by selecting frames one by one according to their importance,
while we present a new paradigm of learning instance-specific video
condensation policies to select informative frames for representing the entire
video only in a single step. Our basic motivation is that the efficient video
recognition task lies in processing a whole sequence at once rather than
picking up frames sequentially. Accordingly, these policies are derived from a
light-weighted skim network together with a simple yet effective policy network
within one step. Moreover, we extend the proposed method with a frame number
budget, enabling the framework to produce correct predictions in high
confidence with as few frames as possible. Experiments on four benchmarks,
i.e., ActivityNet, Mini-Kinetics, FCVID, Mini-Sports1M, demonstrate the
effectiveness of our OCSampler over previous methods in terms of accuracy,
theoretical computational expense, actual inference speed. We also evaluate its
generalization power across different classifiers, sampled frames, and search
spaces. Especially, we achieve 76.9% mAP and 21.7 GFLOPs on ActivityNet with an
impressive throughput: 123.9 Videos/s on a single TITAN Xp GPU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Adversarially Robust Deep Image Denoising. (arXiv:2201.04397v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04397">
<div class="article-summary-box-inner">
<span><p>This work systematically investigates the adversarial robustness of deep
image denoisers (DIDs), i.e, how well DIDs can recover the ground truth from
noisy observations degraded by adversarial perturbations. Firstly, to evaluate
DIDs' robustness, we propose a novel adversarial attack, namely
Observation-based Zero-mean Attack ({\sc ObsAtk}), to craft adversarial
zero-mean perturbations on given noisy images. We find that existing DIDs are
vulnerable to the adversarial noise generated by {\sc ObsAtk}. Secondly, to
robustify DIDs, we propose an adversarial training strategy, hybrid adversarial
training ({\sc HAT}), that jointly trains DIDs with adversarial and
non-adversarial noisy data to ensure that the reconstruction quality is high
and the denoisers around non-adversarial data are locally smooth. The resultant
DIDs can effectively remove various types of synthetic and adversarial noise.
We also uncover that the robustness of DIDs benefits their generalization
capability on unseen real-world noise. Indeed, {\sc HAT}-trained DIDs can
recover high-quality clean images from real-world noise even without training
on real noisy data. Extensive experiments on benchmark datasets, including
Set68, PolyU, and SIDD, corroborate the effectiveness of {\sc ObsAtk} and {\sc
HAT}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoViDNN: A Mobile Platform for Evaluating Video Quality Enhancement with Deep Neural Networks. (arXiv:2201.04402v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04402">
<div class="article-summary-box-inner">
<span><p>Deep neural network (DNN) based approaches have been intensively studied to
improve video quality thanks to their fast advancement in recent years. These
approaches are designed mainly for desktop devices due to their high
computational cost. However, with the increasing performance of mobile devices
in recent years, it became possible to execute DNN based approaches in mobile
devices. Despite having the required computational power, utilizing DNNs to
improve the video quality for mobile devices is still an active research area.
In this paper, we propose an open-source mobile platform, namely MoViDNN, to
evaluate DNN based video quality enhancement methods, such as super-resolution,
denoising, and deblocking. Our proposed platform can be used to evaluate the
DNN based approaches both objectively and subjectively. For objective
evaluation, we report common metrics such as execution time, PSNR, and SSIM.
For subjective evaluation, Mean Score Opinion (MOS) is reported. The proposed
platform is available publicly at https://github.com/cd-athena/MoViDNN
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using Adversarial Learning. (arXiv:2201.04416v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04416">
<div class="article-summary-box-inner">
<span><p>Glioblastoma Multiforme (GBM) is a malignant brain cancer forming around 48%
of al brain and Central Nervous System (CNS) cancers. It is estimated that
annually over 13,000 deaths occur in the US due to GBM, making it crucial to
have early diagnosis systems that can lead to predictable and effective
treatment. The most common treatment after GBM diagnosis is chemotherapy, which
works by sending rapidly dividing cells to apoptosis. However, this form of
treatment is not effective when the MGMT promoter sequence is methylated, and
instead leads to severe side effects decreasing patient survivability.
Therefore, it is important to be able to identify the MGMT promoter methylation
status through non-invasive magnetic resonance imaging (MRI) based machine
learning (ML) models. This is accomplished using the Brain Tumor Segmentation
(BraTS) 2021 dataset, which was recently used for an international Kaggle
competition. We developed four primary models - two radiomic models and two CNN
models - each solving the binary classification task with progressive
improvements. We built a novel ML model termed as the Intermediate State
Generator which was used to normalize the slice thicknesses of all MRI scans.
With further improvements, our best model was able to achieve performance
significantly ($p &lt; 0.05$) better than the best performing Kaggle model with a
6% increase in average cross-validation accuracy. This improvement could
potentially lead to a more informed choice of chemotherapy as a treatment
option, prolonging lives of thousands of patients with GBM each year.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond the Visible: A Survey on Cross-spectral Face Recognition. (arXiv:2201.04435v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04435">
<div class="article-summary-box-inner">
<span><p>Cross-spectral face recognition (CFR) is aimed at recognizing individuals,
where compared face images stem from different sensing modalities, for example
infrared vs. visible. While CFR is inherently more challenging than classical
face recognition due to significant variation in facial appearance associated
to a modality gap, it is superior in scenarios with limited or challenging
illumination, as well as in the presence of presentation attacks. Recent
advances in artificial intelligence related to convolutional neural networks
(CNNs) have brought to the fore a significant performance improvement in CFR.
Motivated by this, the contributions of this survey are three-fold. We provide
an overview of CFR, targeted to compare face images captured in different
spectra, by firstly formalizing CFR and then presenting concrete related
applications. Secondly, we explore suitable spectral bands for recognition and
discuss recent CFR-methods, placing emphasis on deep neural networks. In
particular we revisit techniques that have been proposed to extract and compare
heterogeneous features, as well as datasets. We enumerate strengths and
limitations of different spectra and associated algorithms. Finally, we discuss
research challenges and future lines of research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-Time Style Modelling of Human Locomotion via Feature-Wise Transformations and Local Motion Phases. (arXiv:2201.04439v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04439">
<div class="article-summary-box-inner">
<span><p>Controlling the manner in which a character moves in a real-time animation
system is a challenging task with useful applications. Existing style transfer
systems require access to a reference content motion clip, however, in
real-time systems the future motion content is unknown and liable to change
with user input. In this work we present a style modelling system that uses an
animation synthesis network to model motion content based on local motion
phases. An additional style modulation network uses feature-wise
transformations to modulate style in real-time. To evaluate our method, we
create and release a new style modelling dataset, 100STYLE, containing over 4
million frames of stylised locomotion data in 100 different styles that present
a number of challenges for existing systems. To model these styles, we extend
the local phase calculation with a contact-free formulation. In comparison to
other methods for real-time style modelling, we show our system is more robust
and efficient in its style representation while improving motion quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Globally Optimal Multi-Scale Monocular Hand-Eye Calibration Using Dual Quaternions. (arXiv:2201.04473v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04473">
<div class="article-summary-box-inner">
<span><p>In this work, we present an approach for monocular hand-eye calibration from
per-sensor ego-motion based on dual quaternions. Due to non-metrically scaled
translations of monocular odometry, a scaling factor has to be estimated in
addition to the rotation and translation calibration. For this, we derive a
quadratically constrained quadratic program that allows a combined estimation
of all extrinsic calibration parameters. Using dual quaternions leads to low
run-times due to their compact representation. Our problem formulation further
allows to estimate multiple scalings simultaneously for different sequences of
the same sensor setup. Based on our problem formulation, we derive both, a fast
local and a globally optimal solving approach. Finally, our algorithms are
evaluated and compared to state-of-the-art approaches on simulated and
real-world data, e.g., the EuRoC MAV dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Depth Estimation from Single-shot Monocular Endoscope Image Using Image Domain Adaptation And Edge-Aware Depth Estimation. (arXiv:2201.04485v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04485">
<div class="article-summary-box-inner">
<span><p>We propose a depth estimation method from a single-shot monocular endoscopic
image using Lambertian surface translation by domain adaptation and depth
estimation using multi-scale edge loss. We employ a two-step estimation process
including Lambertian surface translation from unpaired data and depth
estimation. The texture and specular reflection on the surface of an organ
reduce the accuracy of depth estimations. We apply Lambertian surface
translation to an endoscopic image to remove these texture and reflections.
Then, we estimate the depth by using a fully convolutional network (FCN).
During the training of the FCN, improvement of the object edge similarity
between an estimated image and a ground truth depth image is important for
getting better results. We introduced a muti-scale edge loss function to
improve the accuracy of depth estimation. We quantitatively evaluated the
proposed method using real colonoscopic images. The estimated depth values were
proportional to the real depth values. Furthermore, we applied the estimated
depth images to automated anatomical location identification of colonoscopic
images using a convolutional neural network. The identification accuracy of the
network improved from 69.2% to 74.1% by using the estimated depth images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SensatUrban: Learning Semantics from Urban-Scale Photogrammetric Point Clouds. (arXiv:2201.04494v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04494">
<div class="article-summary-box-inner">
<span><p>With the recent availability and affordability of commercial depth sensors
and 3D scanners, an increasing number of 3D (i.e., RGBD, point cloud) datasets
have been publicized to facilitate research in 3D computer vision. However,
existing datasets either cover relatively small areas or have limited semantic
annotations. Fine-grained understanding of urban-scale 3D scenes is still in
its infancy. In this paper, we introduce SensatUrban, an urban-scale UAV
photogrammetry point cloud dataset consisting of nearly three billion points
collected from three UK cities, covering 7.6 km^2. Each point in the dataset
has been labelled with fine-grained semantic annotations, resulting in a
dataset that is three times the size of the previous existing largest
photogrammetric point cloud dataset. In addition to the more commonly
encountered categories such as road and vegetation, urban-level categories
including rail, bridge, and river are also included in our dataset. Based on
this dataset, we further build a benchmark to evaluate the performance of
state-of-the-art segmentation algorithms. In particular, we provide a
comprehensive analysis and identify several key challenges limiting urban-scale
point cloud understanding. The dataset is available at
<a href="http://point-cloud-analysis.cs.ox.ac.uk.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structure and position-aware graph neural network for airway labeling. (arXiv:2201.04532v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04532">
<div class="article-summary-box-inner">
<span><p>We present a novel graph-based approach for labeling the anatomical branches
of a given airway tree segmentation. The proposed method formulates airway
labeling as a branch classification problem in the airway tree graph, where
branch features are extracted using convolutional neural networks (CNN) and
enriched using graph neural networks. Our graph neural network is
structure-aware by having each node aggregate information from its local
neighbors and position-aware by encoding node positions in the graph.
</p>
<p>We evaluated the proposed method on 220 airway trees from subjects with
various severity stages of Chronic Obstructive Pulmonary Disease (COPD). The
results demonstrate that our approach is computationally efficient and
significantly improves branch classification performance than the baseline
method. The overall average accuracy of our method reaches 91.18\% for labeling
all 18 segmental airway branches, compared to 83.83\% obtained by the standard
CNN method. We published our source code at
https://github.com/DIAGNijmegen/spgnn. The proposed algorithm is also publicly
available at
https://grand-challenge.org/algorithms/airway-anatomical-labeling/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Get your Foes Fooled: Proximal Gradient Split Learning for Defense against Model Inversion Attacks on IoMT data. (arXiv:2201.04569v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04569">
<div class="article-summary-box-inner">
<span><p>The past decade has seen a rapid adoption of Artificial Intelligence (AI),
specifically the deep learning networks, in Internet of Medical Things (IoMT)
ecosystem. However, it has been shown recently that the deep learning networks
can be exploited by adversarial attacks that not only make IoMT vulnerable to
the data theft but also to the manipulation of medical diagnosis. The existing
studies consider adding noise to the raw IoMT data or model parameters which
not only reduces the overall performance concerning medical inferences but also
is ineffective to the likes of deep leakage from gradients method. In this
work, we propose proximal gradient split learning (PSGL) method for defense
against the model inversion attacks. The proposed method intentionally attacks
the IoMT data when undergoing the deep neural network training process at
client side. We propose the use of proximal gradient method to recover gradient
maps and a decision-level fusion strategy to improve the recognition
performance. Extensive analysis show that the PGSL not only provides effective
defense mechanism against the model inversion attacks but also helps in
improving the recognition performance on publicly available datasets. We report
17.9$\%$ and 36.9$\%$ gains in accuracy over reconstructed and adversarial
attacked images, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation. (arXiv:2201.04584v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04584">
<div class="article-summary-box-inner">
<span><p>Automatic segmentation of lung lesions associated with COVID-19 in CT images
requires large amount of annotated volumes. Annotations mandate expert
knowledge and are time-intensive to obtain through fully manual segmentation
methods. Additionally, lung lesions have large inter-patient variations, with
some pathologies having similar visual appearance as healthy lung tissues. This
poses a challenge when applying existing semi-automatic interactive
segmentation techniques for data labelling. To address these challenges, we
propose an efficient convolutional neural networks (CNNs) that can be learned
online while the annotator provides scribble-based interaction. To accelerate
learning from only the samples labelled through user-interactions, a
patch-based approach is used for training the network. Moreover, we use
weighted cross-entropy loss to address the class imbalance that may result from
user-interactions. During online inference, the learned network is applied to
the whole input volume using a fully convolutional approach. We compare our
proposed method with state-of-the-art and show that it outperforms existing
methods on the task of annotating lung lesions associated with COVID-19,
achieving 16% higher Dice score while reducing execution time by 3$\times$ and
requiring 9000 lesser scribbles-based labelled voxels. Due to the online
learning aspect, our approach adapts quickly to user input, resulting in high
quality segmentation labels. Source code will be made available upon
acceptance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparsely Annotated Object Detection: A Region-based Semi-supervised Approach. (arXiv:2201.04620v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04620">
<div class="article-summary-box-inner">
<span><p>Research shows a noticeable drop in performance of object detectors when the
training data has missing annotations, i.e. sparsely annotated data.
Contemporary methods focus on proxies for missing ground-truth annotations
either in the form of pseudo-labels or by re-weighing gradients for unlabeled
boxes during training. In this work, we revisit the formulation of sparsely
annotated object detection. We observe that sparsely annotated object detection
can be considered a semi-supervised object detection problem at a region level.
Building on this insight, we propose a region-based semi-supervised algorithm,
that automatically identifies regions containing unlabeled foreground objects.
Our algorithm then processes the labeled and un-labeled foreground regions
differently, a common practice in semi-supervised methods. To evaluate the
effectiveness of the proposed approach, we conduct exhaustive experiments on
five splits commonly used by sparsely annotated approaches on the PASCAL-VOC
and COCO datasets and achieve state-of-the-art performance. In addition to
this, we show that our approach achieves competitive performance on standard
semi-supervised setups demonstrating the strength and broad applicability of
our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Virtual Elastic Objects. (arXiv:2201.04623v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04623">
<div class="article-summary-box-inner">
<span><p>We present Virtual Elastic Objects (VEOs): virtual objects that not only look
like their real-world counterparts but also behave like them, even when subject
to novel interactions. Achieving this presents multiple challenges: not only do
objects have to be captured including the physical forces acting on them, then
faithfully reconstructed and rendered, but also plausible material parameters
found and simulated. To create VEOs, we built a multi-view capture system that
captures objects under the influence of a compressed air stream. Building on
recent advances in model-free, dynamic Neural Radiance Fields, we reconstruct
the objects and corresponding deformation fields. We propose to use a
differentiable, particle-based simulator to use these deformation fields to
find representative material parameters, which enable us to run new
simulations. To render simulated objects, we devise a method for integrating
the simulation results with Neural Radiance Fields. The resulting method is
applicable to a wide range of scenarios: it can handle objects composed of
inhomogeneous material, with very different shapes, and it can simulate
interactions with other virtual objects. We present our results using a newly
collected dataset of 12 objects under a variety of force fields, which will be
shared with the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Continual Learning under Extreme Memory Constraints. (arXiv:2008.01510v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01510">
<div class="article-summary-box-inner">
<span><p>Continual Learning (CL) aims to develop agents emulating the human ability to
sequentially learn new tasks while being able to retain knowledge obtained from
past experiences. In this paper, we introduce the novel problem of
Memory-Constrained Online Continual Learning (MC-OCL) which imposes strict
constraints on the memory overhead that a possible algorithm can use to avoid
catastrophic forgetting. As most, if not all, previous CL methods violate these
constraints, we propose an algorithmic solution to MC-OCL: Batch-level
Distillation (BLD), a regularization-based CL approach, which effectively
balances stability and plasticity in order to learn from data streams, while
preserving the ability to solve old tasks through distillation. Our extensive
experimental evaluation, conducted on three publicly available benchmarks,
empirically demonstrates that our approach successfully addresses the MC-OCL
problem and achieves comparable accuracy to prior distillation methods
requiring higher memory overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MED-TEX: Transferring and Explaining Knowledge with Less Data from Pretrained Medical Imaging Models. (arXiv:2008.02593v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02593">
<div class="article-summary-box-inner">
<span><p>Deep learning methods usually require a large amount of training data and
lack interpretability. In this paper, we propose a novel knowledge distillation
and model interpretation framework for medical image classification that
jointly solves the above two issues. Specifically, to address the data-hungry
issue, a small student model is learned with less data by distilling knowledge
from a cumbersome pretrained teacher model. To interpret the teacher model and
assist the learning of the student, an explainer module is introduced to
highlight the regions of an input that are important for the predictions of the
teacher model. Furthermore, the joint framework is trained by a principled way
derived from the information-theoretic perspective. Our framework outperforms
on the knowledge distillation and model interpretation tasks compared to
state-of-the-art methods on a fundus dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MobileSal: Extremely Efficient RGB-D Salient Object Detection. (arXiv:2012.13095v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13095">
<div class="article-summary-box-inner">
<span><p>The high computational cost of neural networks has prevented recent successes
in RGB-D salient object detection (SOD) from benefiting real-world
applications. Hence, this paper introduces a novel network, MobileSal, which
focuses on efficient RGB-D SOD using mobile networks for deep feature
extraction. However, mobile networks are less powerful in feature
representation than cumbersome networks. To this end, we observe that the depth
information of color images can strengthen the feature representation related
to SOD if leveraged properly. Therefore, we propose an implicit depth
restoration (IDR) technique to strengthen the mobile networks' feature
representation capability for RGB-D SOD. IDR is only adopted in the training
phase and is omitted during testing, so it is computationally free. Besides, we
propose compact pyramid refinement (CPR) for efficient multi-level feature
aggregation to derive salient objects with clear boundaries. With IDR and CPR
incorporated, MobileSal performs favorably against state-of-the-art methods on
six challenging RGB-D SOD datasets with much faster speed (450fps for the input
size of 320 $\times$ 320) and fewer parameters (6.5M). The code is released at
https://mmcheng.net/mobilesal.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProxyFAUG: Proximity-based Fingerprint Augmentation. (arXiv:2102.02706v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02706">
<div class="article-summary-box-inner">
<span><p>The proliferation of data-demanding machine learning methods has brought to
light the necessity for methodologies which can enlarge the size of training
datasets, with simple, rule-based methods. In-line with this concept, the
fingerprint augmentation scheme proposed in this work aims to augment
fingerprint datasets which are used to train positioning models. The proposed
method utilizes fingerprints which are recorded in spacial proximity, in order
to perform fingerprint augmentation, creating new fingerprints which combine
the features of the original ones. The proposed method of composing the new,
augmented fingerprints is inspired by the crossover and mutation operators of
genetic algorithms. The ProxyFAUG method aims to improve the achievable
positioning accuracy of fingerprint datasets, by introducing a rule-based,
stochastic, proximity-based method of fingerprint augmentation. The performance
of ProxyFAUG is evaluated in an outdoor Sigfox setting using a public dataset.
The best performing published positioning method on this dataset is improved by
40% in terms of median error and 6% in terms of mean error, with the use of the
augmented dataset. The analysis of the results indicate a systematic and
significant performance improvement at the lower error quartiles, as indicated
by the impressive improvement of the median error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CharacterGAN: Few-Shot Keypoint Character Animation and Reposing. (arXiv:2102.03141v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03141">
<div class="article-summary-box-inner">
<span><p>We introduce CharacterGAN, a generative model that can be trained on only a
few samples (8 - 15) of a given character. Our model generates novel poses
based on keypoint locations, which can be modified in real time while providing
interactive feedback, allowing for intuitive reposing and animation. Since we
only have very limited training samples, one of the key challenges lies in how
to address (dis)occlusions, e.g. when a hand moves behind or in front of a
body. To address this, we introduce a novel layering approach which explicitly
splits the input keypoints into different layers which are processed
independently. These layers represent different parts of the character and
provide a strong implicit bias that helps to obtain realistic results even with
strong (dis)occlusions. To combine the features of individual layers we use an
adaptive scaling approach conditioned on all keypoints. Finally, we introduce a
mask connectivity constraint to reduce distortion artifacts that occur with
extreme out-of-distribution poses at test time. We show that our approach
outperforms recent baselines and creates realistic animations for diverse
characters. We also show that our model can handle discrete state changes, for
example a profile facing left or right, that the different layers do indeed
learn features specific for the respective keypoints in those layers, and that
our model scales to larger datasets when more data is available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bayesian imaging using Plug & Play priors: when Langevin meets Tweedie. (arXiv:2103.04715v6 [stat.ME] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04715">
<div class="article-summary-box-inner">
<span><p>Since the seminal work of Venkatakrishnan et al. in 2013, Plug &amp; Play (PnP)
methods have become ubiquitous in Bayesian imaging. These methods derive
Minimum Mean Square Error (MMSE) or Maximum A Posteriori (MAP) estimators for
inverse problems in imaging by combining an explicit likelihood function with a
prior that is implicitly defined by an image denoising algorithm. The PnP
algorithms proposed in the literature mainly differ in the iterative schemes
they use for optimisation or for sampling. In the case of optimisation schemes,
some recent works guarantee the convergence to a fixed point, albeit not
necessarily a MAP estimate. In the case of sampling schemes, to the best of our
knowledge, there is no known proof of convergence. There also remain important
open questions regarding whether the underlying Bayesian models and estimators
are well defined, well-posed, and have the basic regularity properties required
to support these numerical schemes. To address these limitations, this paper
develops theory, methods, and provably convergent algorithms for performing
Bayesian inference with PnP priors. We introduce two algorithms: 1) PnP-ULA
(Unadjusted Langevin Algorithm) for Monte Carlo sampling and MMSE inference;
and 2) PnP-SGD (Stochastic Gradient Descent) for MAP inference. Using recent
results on the quantitative convergence of Markov chains, we establish detailed
convergence guarantees for these two algorithms under realistic assumptions on
the denoising operators used, with special attention to denoisers based on deep
neural networks. We also show that these algorithms approximately target a
decision-theoretically optimal Bayesian model that is well-posed. The proposed
algorithms are demonstrated on several canonical problems such as image
deblurring, inpainting, and denoising, where they are used for point estimation
as well as for uncertainty visualisation and quantification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Domain Invariant Representations for Generalizable Person Re-Identification. (arXiv:2103.15890v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15890">
<div class="article-summary-box-inner">
<span><p>Generalizable person Re-Identification (ReID) has attracted growing attention
in recent computer vision community. In this work, we construct a structural
causal model among identity labels, identity-specific factors (clothes/shoes
color etc), and domain-specific factors (background, viewpoints etc). According
to the causal analysis, we propose a novel Domain Invariant Representation
Learning for generalizable person Re-Identification (DIR-ReID) framework.
Specifically, we first propose to disentangle the identity-specific and
domain-specific feature spaces, based on which we propose an effective
algorithmic implementation for backdoor adjustment, essentially serving as a
causal intervention towards the SCM. Extensive experiments have been conducted,
showing that DIR-ReID outperforms state-of-the-art methods on large-scale
domain generalization ReID benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skin3D: Detection and Longitudinal Tracking of Pigmented Skin Lesions in 3D Total-Body Textured Meshes. (arXiv:2105.00374v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00374">
<div class="article-summary-box-inner">
<span><p>We present an automated approach to detect and longitudinally track skin
lesions on 3D total-body skin surface scans. The acquired 3D mesh of the
subject is unwrapped to a 2D texture image, where a trained objected detection
model, Faster R-CNN, localizes the lesions within the 2D domain. These detected
skin lesions are mapped back to the 3D surface of the subject and, for subjects
imaged multiple times, we construct a graph-based matching procedure to
longitudinally track lesions that considers the anatomical correspondences
among pairs of meshes and the geodesic proximity of corresponding lesions and
the inter-lesion geodesic distances.
</p>
<p>We evaluated the proposed approach using 3DBodyTex, a publicly available
dataset composed of 3D scans imaging the coloured skin (textured meshes) of 200
human subjects. We manually annotated locations that appeared to the human eye
to contain a pigmented skin lesion as well as tracked a subset of lesions
occurring on the same subject imaged in different poses. Our results, when
compared to three human annotators, suggest that the trained Faster R-CNN
detects lesions at a similar performance level as the human annotators. Our
lesion tracking algorithm achieves an average matching accuracy of 88% on a set
of detected corresponding pairs of prominent lesions of subjects imaged in
different poses, and an average longitudinal accuracy of 71% when encompassing
additional errors due to lesion detection. As there currently is no other
large-scale publicly available dataset of 3D total-body skin lesions, we
publicly release over 25,000 3DBodyTex manual annotations, which we hope will
further research on total-body skin lesion analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KVT: k-NN Attention for Boosting Vision Transformers. (arXiv:2106.00515v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00515">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks (CNNs) have dominated computer vision for
years, due to its ability in capturing locality and translation invariance.
Recently, many vision transformer architectures have been proposed and they
show promising performance. A key component in vision transformers is the
fully-connected self-attention which is more powerful than CNNs in modelling
long range dependencies. However, since the current dense self-attention uses
all image patches (tokens) to compute attention matrix, it may neglect locality
of images patches and involve noisy tokens (e.g., clutter background and
occlusion), leading to a slow training process and potential degradation of
performance. To address these problems, we propose the $k$-NN attention for
boosting vision transformers. Specifically, instead of involving all the tokens
for attention matrix calculation, we only select the top-$k$ similar tokens
from the keys for each query to compute the attention map. The proposed $k$-NN
attention naturally inherits the local bias of CNNs without introducing
convolutional operations, as nearby tokens tend to be more similar than others.
In addition, the $k$-NN attention allows for the exploration of long range
correlation and at the same time filters out irrelevant tokens by choosing the
most similar tokens from the entire image. Despite its simplicity, we verify,
both theoretically and empirically, that $k$-NN attention is powerful in
speeding up training and distilling noise from input tokens. Extensive
experiments are conducted by using 11 different vision transformer
architectures to verify that the proposed $k$-NN attention can work with any
existing transformer architectures to improve its prediction performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v9 [math.OC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08208">
<div class="article-summary-box-inner">
<span><p>Adaptive gradient methods have shown excellent performances for solving many
machine learning problems. Although multiple adaptive gradient methods were
recently studied, they mainly focus on either empirical or theoretical aspects
and also only work for specific problems by using some specific adaptive
learning rates. Thus, it is desired to design a universal framework for
practical algorithms of adaptive gradients with theoretical guarantee to solve
general problems. To fill this gap, we propose a faster and universal framework
of adaptive gradients (i.e., SUPER-ADAM) by introducing a universal adaptive
matrix that includes most existing adaptive gradient forms. Moreover, our
framework can flexibly integrate the momentum and variance reduced techniques.
In particular, our novel framework provides the convergence analysis support
for adaptive gradient methods under the nonconvex setting. In theoretical
analysis, we prove that our SUPER-ADAM algorithm can achieve the best known
gradient (i.e., stochastic first-order oracle (SFO)) complexity of
$\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary point of
nonconvex optimization, which matches the lower bound for stochastic smooth
nonconvex optimization. In numerical experiments, we employ various deep
learning tasks to validate that our algorithm consistently outperforms the
existing adaptive algorithms. Code is available at
https://github.com/LIJUNYI95/SuperAdam
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects. (arXiv:2108.07368v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07368">
<div class="article-summary-box-inner">
<span><p>Segmenting medical images accurately and reliably is important for disease
diagnosis and treatment. It is a challenging task because of the wide variety
of objects' sizes, shapes, and scanning modalities. Recently, many
convolutional neural networks (CNN) have been designed for segmentation tasks
and achieved great success. Few studies, however, have fully considered the
sizes of objects and thus most demonstrate poor performance on segmentation of
small objects segmentation. This can have significant impact on early detection
of disease. This paper proposes a Context Axial Reserve Attention Network
(CaraNet) to improve the segmentation performance on small objects compared
with recent state-of-the-art models. We test our CaraNet on brain tumor (BraTS
2018) and polyp (Kvasir-SEG, CVC-ColonDB, CVC-ClinicDB, CVC-300 and
ETIS-LaribPolypDB) segmentation. Our CaraNet not only achieves the top-rank
mean Dice segmentation accuracy, but also shows a distinct advantage in
segmentation of small medical objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep MRI Reconstruction with Radial Subsampling. (arXiv:2108.07619v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07619">
<div class="article-summary-box-inner">
<span><p>In spite of its extensive adaptation in almost every medical diagnostic and
examinatorial application, Magnetic Resonance Imaging (MRI) is still a slow
imaging modality which limits its use for dynamic imaging. In recent years,
Parallel Imaging (PI) and Compressed Sensing (CS) have been utilised to
accelerate the MRI acquisition. In clinical settings, subsampling the k-space
measurements during scanning time using Cartesian trajectories, such as
rectilinear sampling, is currently the most conventional CS approach applied
which, however, is prone to producing aliased reconstructions. With the advent
of the involvement of Deep Learning (DL) in accelerating the MRI,
reconstructing faithful images from subsampled data became increasingly
promising. Retrospectively applying a subsampling mask onto the k-space data is
a way of simulating the accelerated acquisition of k-space data in real
clinical setting. In this paper we compare and provide a review for the effect
of applying either rectilinear or radial retrospective subsampling on the
quality of the reconstructions outputted by trained deep neural networks. With
the same choice of hyper-parameters, we train and evaluate two distinct
Recurrent Inference Machines (RIMs), one for each type of subsampling. The
qualitative and quantitative results of our experiments indicate that the model
trained on data with radial subsampling attains higher performance and learns
to estimate reconstructions with higher fidelity paving the way for other DL
approaches to involve radial subsampling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Moving Object Detection for Event-based Vision using k-means Clustering. (arXiv:2109.01879v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01879">
<div class="article-summary-box-inner">
<span><p>Moving object detection is important in computer vision. Event-based cameras
are bio-inspired cameras that work by mimicking the working of the human eye.
These cameras have multiple advantages over conventional frame-based cameras,
like reduced latency, HDR, reduced motion blur during high motion, low power
consumption, etc. In spite of these advantages, event-based cameras are
noise-sensitive and have low resolution. Moreover, the task of moving object
detection in these cameras is difficult, as event-based sensors lack useful
visual features like texture and color. In this paper, we investigate the
application of the k-means clustering technique in detecting moving objects in
event-based data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Product Quantization for Deep Unsupervised Image Retrieval. (arXiv:2109.02244v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02244">
<div class="article-summary-box-inner">
<span><p>Supervised deep learning-based hash and vector quantization are enabling fast
and large-scale image retrieval systems. By fully exploiting label annotations,
they are achieving outstanding retrieval performances compared to the
conventional methods. However, it is painstaking to assign labels precisely for
a vast amount of training data, and also, the annotation process is
error-prone. To tackle these issues, we propose the first deep unsupervised
image retrieval method dubbed Self-supervised Product Quantization (SPQ)
network, which is label-free and trained in a self-supervised manner. We design
a Cross Quantized Contrastive learning strategy that jointly learns codewords
and deep visual descriptors by comparing individually transformed images
(views). Our method analyzes the image contents to extract descriptive
features, allowing us to understand image representations for accurate
retrieval. By conducting extensive experiments on benchmarks, we demonstrate
that the proposed method yields state-of-the-art results even without
supervised pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaled ReLU Matters for Training Vision Transformers. (arXiv:2109.03810v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03810">
<div class="article-summary-box-inner">
<span><p>Vision transformers (ViTs) have been an alternative design paradigm to
convolutional neural networks (CNNs). However, the training of ViTs is much
harder than CNNs, as it is sensitive to the training parameters, such as
learning rate, optimizer and warmup epoch. The reasons for training difficulty
are empirically analysed in ~\cite{xiao2021early}, and the authors conjecture
that the issue lies with the \textit{patchify-stem} of ViT models and propose
that early convolutions help transformers see better. In this paper, we further
investigate this problem and extend the above conclusion: only early
convolutions do not help for stable training, but the scaled ReLU operation in
the \textit{convolutional stem} (\textit{conv-stem}) matters. We verify, both
theoretically and empirically, that scaled ReLU in \textit{conv-stem} not only
improves training stabilization, but also increases the diversity of patch
tokens, thus boosting peak performance with a large margin via adding few
parameters and flops. In addition, extensive experiments are conducted to
demonstrate that previous ViTs are far from being well trained, further showing
that ViTs have great potential to be a better substitute of CNNs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IFBiD: Inference-Free Bias Detection. (arXiv:2109.04374v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04374">
<div class="article-summary-box-inner">
<span><p>This paper is the first to explore an automatic way to detect bias in deep
convolutional neural networks by simply looking at their weights. Furthermore,
it is also a step towards understanding neural networks and how they work. We
show that it is indeed possible to know if a model is biased or not simply by
looking at its weights, without the model inference for an specific input. We
analyze how bias is encoded in the weights of deep networks through a toy
example using the Colored MNIST database and we also provide a realistic case
study in gender detection from face images using state-of-the-art methods and
experimental resources. To do so, we generated two databases with 36K and 48K
biased models each. In the MNIST models we were able to detect whether they
presented a strong or low bias with more than 99% accuracy, and we were also
able to classify between four levels of bias with more than 70% accuracy. For
the face models, we achieved 90% accuracy in distinguishing between models
biased towards Asian, Black, or Caucasian ethnicity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ARKitScenes: A Diverse Real-World Dataset For 3D Indoor Scene Understanding Using Mobile RGB-D Data. (arXiv:2111.08897v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08897">
<div class="article-summary-box-inner">
<span><p>Scene understanding is an active research area. Commercial depth sensors,
such as Kinect, have enabled the release of several RGB-D datasets over the
past few years which spawned novel methods in 3D scene understanding. More
recently with the launch of the LiDAR sensor in Apple's iPads and iPhones, high
quality RGB-D data is accessible to millions of people on a device they
commonly use. This opens a whole new era in scene understanding for the
Computer Vision community as well as app developers. The fundamental research
in scene understanding together with the advances in machine learning can now
impact people's everyday experiences. However, transforming these scene
understanding methods to real-world experiences requires additional innovation
and development. In this paper we introduce ARKitScenes. It is not only the
first RGB-D dataset that is captured with a now widely available depth sensor,
but to our best knowledge, it also is the largest indoor scene understanding
data released. In addition to the raw and processed data from the mobile
device, ARKitScenes includes high resolution depth maps captured using a
stationary laser scanner, as well as manually labeled 3D oriented bounding
boxes for a large taxonomy of furniture. We further analyze the usefulness of
the data for two downstream tasks: 3D object detection and color-guided depth
upsampling. We demonstrate that our dataset can help push the boundaries of
existing state-of-the-art methods and it introduces new challenges that better
represent real-world scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Convolutional Neural Networks to Detect Compression Algorithms. (arXiv:2111.09034v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09034">
<div class="article-summary-box-inner">
<span><p>Machine learning is penetrating various domains virtually, thereby
proliferating excellent results. It has also found an outlet in digital
forensics, wherein it is becoming the prime driver of computational efficiency.
A prominent feature that exhibits the effectiveness of ML algorithms is feature
extraction that can be instrumental in the applications for digital forensics.
Convolutional Neural Networks are further used to identify parts of the file.
To this end, we observed that the literature does not include sufficient
information about the identification of the algorithms used to compress file
fragments. With this research, we attempt to address this gap as compression
algorithms are beneficial in generating higher entropy comparatively as they
make the data more compact. We used a base dataset, compressed every file with
various algorithms, and designed a model based on that. The used model was
accurately able to identify files compressed using compress, lzip and bzip2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Confidence Propagation Cluster: Unleash Full Potential of Object Detectors. (arXiv:2112.00342v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00342">
<div class="article-summary-box-inner">
<span><p>It has been a long history that most object detection methods obtain objects
by using the non-maximum suppression (NMS) and its improved versions like
Soft-NMS to remove redundant bounding boxes. We challenge those NMS-based
methods from three aspects: 1) The bounding box with highest confidence value
may not be the true positive having the biggest overlap with the ground-truth
box. 2) Not only suppression is required for redundant boxes, but also
confidence enhancement is needed for those true positives. 3) Sorting candidate
boxes by confidence values is not necessary so that full parallelism is
achievable.
</p>
<p>In this paper, inspired by belief propagation (BP), we propose the Confidence
Propagation Cluster (CP-Cluster) to replace NMS-based methods, which is fully
parallelizable as well as better in accuracy. In CP-Cluster, we borrow the
message passing mechanism from BP to penalize redundant boxes and enhance true
positives simultaneously in an iterative way until convergence. We verified the
effectiveness of CP-Cluster by applying it to various mainstream detectors such
as FasterRCNN, SSD, FCOS, YOLOv3, YOLOv5, Centernet etc. Experiments on MS COCO
show that our plug and play method, without retraining detectors, is able to
steadily improve average mAP of all those state-of-the-art models with a clear
margin from 0.2 to 1.9 respectively when compared with NMS-based methods.
Source code is available at https://github.com/shenyi0220/CP-Cluster
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HHF: Hashing-guided Hinge Function for Deep Hashing Retrieval. (arXiv:2112.02225v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.02225">
<div class="article-summary-box-inner">
<span><p>Deep hashing has shown promising performance in large-scale image retrieval.
However, latent codes extracted by Deep Neural Networks (DNNs) will inevitably
lose semantic information during the binarization process, which damages the
retrieval accuracy and makes it challenging. Although many existing approaches
perform regularization to alleviate quantization errors, we figure out an
incompatible conflict between metric learning and quantization learning. The
metric loss penalizes the inter-class distances to push different classes
unconstrained far away. Worse still, it tends to map the latent code deviate
from ideal binarization point and generate severe ambiguity in the binarization
process. Based on the minimum distance of the binary linear code, we creatively
propose Hashing-guided Hinge Function (HHF) to avoid such conflict. In detail,
the carefully-designed inflection point, which relies on the hash bit length
and category numbers, is explicitly adopted to balance the metric term and
quantization term. Such a modification prevents the network from falling into
local metric optimal minima in deep hashing. Extensive experiments in CIFAR-10,
CIFAR-100, ImageNet, and MS-COCO show that HHF consistently outperforms
existing techniques, and is robust and flexible to transplant into other
methods. Code is available at https://github.com/JerryXu0129/HHF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Encouraging Disentangled and Convex Representation with Controllable Interpolation Regularization. (arXiv:2112.03163v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03163">
<div class="article-summary-box-inner">
<span><p>We focus on controllable disentangled representation learning (C-Dis-RL),
where users can control the partition of the disentangled latent space to
factorize dataset attributes (concepts) for downstream tasks. Two general
problems remain under-explored in current methods: (1) They lack comprehensive
disentanglement constraints, especially missing the minimization of mutual
information between different attributes across latent and observation domains.
(2) They lack convexity constraints in disentangled latent space, which is
important for meaningfully manipulating specific attributes for downstream
tasks. To encourage both comprehensive C-Dis-RL and convexity simultaneously,
we propose a simple yet efficient method: Controllable Interpolation
Regularization (CIR), which creates a positive loop where the disentanglement
and convexity can help each other. Specifically, we conduct controlled
interpolation in latent space during training and 'reuse' the encoder to help
form a 'perfect disentanglement' regularization. In that case, (a)
disentanglement loss implicitly enlarges the potential 'understandable'
distribution to encourage convexity; (b) convexity can in turn improve robust
and precise disentanglement. CIR is a general module and we merge CIR with
three different algorithms: ELEGANT, I2I-Dis, and GZS-Net to show the
compatibility and effectiveness. Qualitative and quantitative experiments show
improvement in C-Dis-RL and latent convexity by CIR. This further improves
downstream tasks: controllable image synthesis, cross-modality image
translation and zero-shot synthesis. More experiments demonstrate CIR can also
improve other downstream tasks, such as new attribute value mining, data
augmentation, and eliminating bias for fairness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trajectory-Constrained Deep Latent Visual Attention for Improved Local Planning in Presence of Heterogeneous Terrain. (arXiv:2112.04684v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04684">
<div class="article-summary-box-inner">
<span><p>We present a reward-predictive, model-based deep learning method featuring
trajectory-constrained visual attention for use in mapless, local visual
navigation tasks. Our method learns to place visual attention at locations in
latent image space which follow trajectories caused by vehicle control actions
to enhance predictive accuracy during planning. The attention model is jointly
optimized by the task-specific loss and an additional trajectory-constraint
loss, allowing adaptability yet encouraging a regularized structure for
improved generalization and reliability. Importantly, visual attention is
applied in latent feature map space instead of raw image space to promote
efficient planning. We validated our model in visual navigation tasks of
planning low turbulence, collision-free trajectories in off-road settings and
hill climbing with locking differentials in the presence of slippery terrain.
Experiments involved randomized procedural generated simulation and real-world
environments. We found our method improved generalization and learning
efficiency when compared to no-attention and self-attention alternatives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Spatiotemporal Representation Learning by Exploiting Video Continuity. (arXiv:2112.05883v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.05883">
<div class="article-summary-box-inner">
<span><p>Recent self-supervised video representation learning methods have found
significant success by exploring essential properties of videos, e.g. speed,
temporal order, etc. This work exploits an essential yet under-explored
property of videos, the video continuity, to obtain supervision signals for
self-supervised representation learning. Specifically, we formulate three novel
continuity-related pretext tasks, i.e. continuity justification, discontinuity
localization, and missing section approximation, that jointly supervise a
shared backbone for video representation learning. This self-supervision
approach, termed as Continuity Perception Network (CPNet), solves the three
tasks altogether and encourages the backbone network to learn local and
long-ranged motion and context representations. It outperforms prior arts on
multiple downstream tasks, such as action recognition, video retrieval, and
action localization. Additionally, the video continuity can be complementary to
other coarse-grained video properties for representation learning, and
integrating the proposed pretext task to prior arts can yield much performance
gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EPNet++: Cascade Bi-directional Fusion for Multi-Modal 3D Object Detection. (arXiv:2112.11088v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11088">
<div class="article-summary-box-inner">
<span><p>Recently, fusing the LiDAR point cloud and camera image to improve the
performance and robustness of 3D object detection has received more and more
attention, as these two modalities naturally possess strong complementarity. In
this paper, we propose EPNet++ for multi-modal 3D object detection by
introducing a novel Cascade Bi-directional Fusion~(CB-Fusion) module and a
Multi-Modal Consistency~(MC) loss. More concretely, the proposed CB-Fusion
module boosts the plentiful semantic information of point features with the
image features in a cascade bi-directional interaction fusion manner, leading
to more comprehensive and discriminative feature representations. The MC loss
explicitly guarantees the consistency between predicted scores from two
modalities to obtain more comprehensive and reliable confidence scores. The
experiment results on the KITTI, JRDB and SUN-RGBD datasets demonstrate the
superiority of EPNet++ over the state-of-the-art methods. Besides, we emphasize
a critical but easily overlooked problem, which is to explore the performance
and robustness of a 3D detector in a sparser scene. Extensive experiments
present that EPNet++ outperforms the existing SOTA methods with remarkable
margins in highly sparse point cloud cases, which might be an available
direction to reduce the expensive cost of LiDAR sensors. Code will be released
in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The cluster structure function. (arXiv:2201.01222v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01222">
<div class="article-summary-box-inner">
<span><p>For each partition of a data set into a given number of parts there is a
partition such that every part is as much as possible a good model (an
"algorithmic sufficient statistic") for the data in that part. Since this can
be done for every number between one and the number of data, the result is a
function, the cluster structure function. It maps the number of parts of a
partition to values related to the deficiencies of being good models by the
parts. Such a function starts with a value at least zero for no partition of
the data set and descents to zero for the partition of the data set into
singleton parts. The optimal clustering is the one chosen to minimize the
cluster structure function. The theory behind the method is expressed in
algorithmic information theory (Kolmogorov complexity). In practice the
Kolmogorov complexities involved are approximated by a concrete compressor. We
give examples using real data sets: the MNIST handwritten digits and the
segmentation of real cells as used in stem cell research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effect of Prior-based Losses on Segmentation Performance: A Benchmark. (arXiv:2201.02428v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02428">
<div class="article-summary-box-inner">
<span><p>Today, deep convolutional neural networks (CNNs) have demonstrated
state-of-the-art performance for medical image segmentation, on various imaging
modalities and tasks. Despite early success, segmentation networks may still
generate anatomically aberrant segmentations, with holes or inaccuracies near
the object boundaries. To enforce anatomical plausibility, recent research
studies have focused on incorporating prior knowledge such as object shape or
boundary, as constraints in the loss function. Prior integrated could be
low-level referring to reformulated representations extracted from the
ground-truth segmentations, or high-level representing external medical
information such as the organ's shape or size. Over the past few years,
prior-based losses exhibited a rising interest in the research field since they
allow integration of expert knowledge while still being architecture-agnostic.
However, given the diversity of prior-based losses on different medical imaging
challenges and tasks, it has become hard to identify what loss works best for
which dataset. In this paper, we establish a benchmark of recent prior-based
losses for medical image segmentation. The main objective is to provide
intuition onto which losses to choose given a particular task or dataset. To
this end, four low-level and high-level prior-based losses are selected. The
considered losses are validated on 8 different datasets from a variety of
medical image segmentation challenges including the Decathlon, the ISLES and
the WMH challenge. Results show that whereas low-level prior-based losses can
guarantee an increase in performance over the Dice loss baseline regardless of
the dataset characteristics, high-level prior-based losses can increase
anatomical plausibility as per data characteristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision in adverse weather: Augmentation using CycleGANs with various object detectors for robust perception in autonomous racing. (arXiv:2201.03246v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03246">
<div class="article-summary-box-inner">
<span><p>In an autonomous driving system, perception - identification of features and
objects from the environment - is crucial. In autonomous racing, high speeds
and small margins demand rapid and accurate detection systems. During the race,
the weather can change abruptly, causing significant degradation in perception,
resulting in ineffective manoeuvres. In order to improve detection in adverse
weather, deep-learning-based models typically require extensive datasets
captured in such conditions - the collection of which is a tedious, laborious,
and costly process. However, recent developments in CycleGAN architectures
allow the synthesis of highly realistic scenes in multiple weather conditions.
To this end, we introduce an approach of using synthesised adverse condition
datasets in autonomous racing (generated using CycleGAN) to improve the
performance of four out of five state-of-the-art detectors by an average of
42.7 and 4.4 mAP percentage points in the presence of night-time conditions and
droplets, respectively. Furthermore, we present a comparative analysis of five
object detectors - identifying the optimal pairing of detector and training
data for use during autonomous racing in challenging conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Similarity-based Gray-box Adversarial Attack Against Deep Face Recognition. (arXiv:2201.04011v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04011">
<div class="article-summary-box-inner">
<span><p>The majority of adversarial attack techniques perform well against deep face
recognition when the full knowledge of the system is revealed
(\emph{white-box}). However, such techniques act unsuccessfully in the gray-box
setting where the face templates are unknown to the attackers. In this work, we
propose a similarity-based gray-box adversarial attack (SGADV) technique with a
newly developed objective function. SGADV utilizes the dissimilarity score to
produce the optimized adversarial example, i.e., similarity-based adversarial
attack. This technique applies to both white-box and gray-box attacks against
authentication systems that determine genuine or imposter users using the
dissimilarity score. To validate the effectiveness of SGADV, we conduct
extensive experiments on face datasets of LFW, CelebA, and CelebA-HQ against
deep face recognition models of FaceNet and InsightFace in both white-box and
gray-box settings. The results suggest that the proposed method significantly
outperforms the existing adversarial attack techniques in the gray-box setting.
We hence summarize that the similarity-base approaches to develop the
adversarial example could satisfactorily cater to the gray-box attack scenarios
for de-authentication.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-01-13 23:07:21.022111264 UTC">2022-01-13 23:07:21 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>