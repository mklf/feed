<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-03T01:30:00Z">09-03</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.AI updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">The Role of Explainability in Assuring Safety of Machine Learning in Healthcare. (arXiv:2109.00520v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00520">
<div class="article-summary-box-inner">
<span><p>Established approaches to assuring safety-critical systems and software are
difficult to apply to systems employing machine learning (ML). In many cases,
ML is used on ill-defined problems, e.g. optimising sepsis treatment, where
there is no clear, pre-defined specification against which to assess validity.
This problem is exacerbated by the "opaque" nature of ML where the learnt model
is not amenable to human scrutiny. Explainable AI methods have been proposed to
tackle this issue by producing human-interpretable representations of ML models
which can help users to gain confidence and build trust in the ML system.
However, there is not much work explicitly investigating the role of
explainability for safety assurance in the context of ML development. This
paper identifies ways in which explainable AI methods can contribute to safety
assurance of ML-based systems. It then uses a concrete ML-based clinical
decision support system, concerning weaning of patients from mechanical
ventilation, to demonstrate how explainable AI methods can be employed to
produce evidence to support safety assurance. The results are also represented
in a safety argument to show where, and in what way, explainable AI methods can
contribute to a safety case. Overall, we conclude that explainable AI methods
have a valuable role in safety assurance of ML-based systems in healthcare but
that they are not sufficient in themselves to assure safety.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Catastrophic Interference in Reinforcement Learning: A Solution Based on Context Division and Knowledge Distillation. (arXiv:2109.00525v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00525">
<div class="article-summary-box-inner">
<span><p>The powerful learning ability of deep neural networks enables reinforcement
learning (RL) agents to learn competent control policies directly from
high-dimensional and continuous environments. In theory, to achieve stable
performance, neural networks assume i.i.d. inputs, which unfortunately does no
hold in the general RL paradigm where the training data is temporally
correlated and non-stationary. This issue may lead to the phenomenon of
"catastrophic interference" and the collapse in performance as later training
is likely to overwrite and interfer with previously learned policies. In this
paper, we introduce the concept of "context" into single-task RL and develop a
novel scheme, termed as Context Division and Knowledge Distillation (CDaKD)
driven RL, to divide all states experienced during training into a series of
contexts. Its motivation is to mitigate the challenge of aforementioned
catastrophic interference in deep RL, thereby improving the stability and
plasticity of RL models. At the heart of CDaKD is a value function,
parameterized by a neural network feature extractor shared across all contexts,
and a set of output heads, each specializing on an individual context. In
CDaKD, we exploit online clustering to achieve context division, and
interference is further alleviated by a knowledge distillation regularization
term on the output layers for learned contexts. In addition, to effectively
obtain the context division in high-dimensional state spaces (e.g., image
inputs), we perform clustering in the lower-dimensional representation space of
a randomly initialized convolutional encoder, which is fixed throughout
training. Our results show that, with various replay memory capacities, CDaKD
can consistently improve the performance of existing RL algorithms on classic
OpenAI Gym tasks and the more complex high-dimensional Atari tasks, incurring
only moderate computational overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Search Engines with Interactive Agents. (arXiv:2109.00527v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00527">
<div class="article-summary-box-inner">
<span><p>Can machines learn to use a search engine as an interactive tool for finding
information? That would have far reaching consequences for making the world's
knowledge more accessible. This paper presents first steps in designing agents
that learn meta-strategies for contextual query refinements. Our approach uses
machine reading to guide the selection of refinement terms from aggregated
search results. Agents are then empowered with simple but effective search
operators to exert fine-grained and transparent control over queries and search
results. We develop a novel way of generating synthetic search sessions, which
leverages the power of transformer-based generative language models through
(self-)supervised learning. We also present a reinforcement learning agent with
dynamically constrained actions that can learn interactive search strategies
completely from scratch. In both cases, we obtain significant improvements over
one-shot search with a strong information retrieval baseline. Finally, we
provide an in-depth analysis of the learned search policies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variational Quantum Reinforcement Learning via Evolutionary Optimization. (arXiv:2109.00540v1 [quant-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00540">
<div class="article-summary-box-inner">
<span><p>Recent advance in classical reinforcement learning (RL) and quantum
computation (QC) points to a promising direction of performing RL on a quantum
computer. However, potential applications in quantum RL are limited by the
number of qubits available in the modern quantum devices. Here we present two
frameworks of deep quantum RL tasks using a gradient-free evolution
optimization: First, we apply the amplitude encoding scheme to the Cart-Pole
problem; Second, we propose a hybrid framework where the quantum RL agents are
equipped with hybrid tensor network-variational quantum circuit (TN-VQC)
architecture to handle inputs with dimensions exceeding the number of qubits.
This allows us to perform quantum RL on the MiniGrid environment with
147-dimensional inputs. We demonstrate the quantum advantage of parameter
saving using the amplitude encoding. The hybrid TN-VQC architecture provides a
natural way to perform efficient compression of the input dimension, enabling
further quantum RL applications on noisy intermediate-scale quantum devices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Improving Adversarial Training of NLP Models. (arXiv:2109.00544v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00544">
<div class="article-summary-box-inner">
<span><p>Adversarial training, a method for learning robust deep neural networks,
constructs adversarial examples during training. However, recent methods for
generating NLP adversarial examples involve combinatorial search and expensive
sentence encoders for constraining the generated instances. As a result, it
remains challenging to use vanilla adversarial training to improve NLP models'
performance, and the benefits are mainly uninvestigated. This paper proposes a
simple and improved vanilla adversarial training process for NLP, which we name
Attacking to Training ($\texttt{A2T}$). The core part of $\texttt{A2T}$ is a
new and cheaper word substitution attack optimized for vanilla adversarial
training. We use $\texttt{A2T}$ to train BERT and RoBERTa models on IMDB,
Rotten Tomatoes, Yelp, and SNLI datasets. Our results show that it is possible
to train empirically robust NLP models using a much cheaper adversary. We
demonstrate that vanilla adversarial training with $\texttt{A2T}$ can improve
an NLP model's robustness to the attack it was originally trained with and also
defend the model against other types of attacks. Furthermore, we show that
$\texttt{A2T}$ can improve NLP models' standard accuracy, cross-domain
generalization, and interpretability. Code is available at
<a href="http://github.com/jinyongyoo/A2T">this http URL</a> .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FaVoA: Face-Voice Association Favours Ambiguous Speaker Detection. (arXiv:2109.00577v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00577">
<div class="article-summary-box-inner">
<span><p>The strong relation between face and voice can aid active speaker detection
systems when faces are visible, even in difficult settings, when the face of a
speaker is not clear or when there are several people in the same scene. By
being capable of estimating the frontal facial representation of a person from
his/her speech, it becomes easier to determine whether he/she is a potential
candidate for being classified as an active speaker, even in challenging cases
in which no mouth movement is detected from any person in that same scene. By
incorporating a face-voice association neural network into an existing
state-of-the-art active speaker detection model, we introduce FaVoA (Face-Voice
Association Ambiguous Speaker Detector), a neural network model that can
correctly classify particularly ambiguous scenarios. FaVoA not only finds
positive associations, but helps to rule out non-matching face-voice
associations, where a face does not match a voice. Its use of a
gated-bimodal-unit architecture for the fusion of those models offers a way to
quantitatively determine how much each modality contributes to the
classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebQA: Multihop and Multimodal QA. (arXiv:2109.00590v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00590">
<div class="article-summary-box-inner">
<span><p>Web search is fundamentally multimodal and multihop. Often, even before
asking a question we choose to go directly to image search to find our answers.
Further, rarely do we find an answer from a single source but aggregate
information and reason through implications. Despite the frequency of this
everyday occurrence, at present, there is no unified question answering
benchmark that requires a single model to answer long-form natural language
questions from text and open-ended visual sources -- akin to a human's
experience. We propose to bridge this gap between the natural language and
computer vision communities with WebQA. We show that A. our multihop text
queries are difficult for a large-scale transformer model, and B. existing
multi-modal transformers and visual representations do not perform well on
open-domain visual queries. Our challenge for the community is to create a
unified multimodal reasoning model that seamlessly transitions and reasons
regardless of the source modality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fight Fire with Fire: Fine-tuning Hate Detectors using Large Samples of Generated Hate Speech. (arXiv:2109.00591v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00591">
<div class="article-summary-box-inner">
<span><p>Automatic hate speech detection is hampered by the scarcity of labeled
datasetd, leading to poor generalization. We employ pretrained language models
(LMs) to alleviate this data bottleneck. We utilize the GPT LM for generating
large amounts of synthetic hate speech sequences from available labeled
examples, and leverage the generated data in fine-tuning large pretrained LMs
on hate detection. An empirical study using the models of BERT, RoBERTa and
ALBERT, shows that this approach improves generalization significantly and
consistently within and across data distributions. In fact, we find that
generating relevant labeled hate speech sequences is preferable to using
out-of-domain, and sometimes also within-domain, human-labeled examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning compositional programs with arguments and sampling. (arXiv:2109.00619v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00619">
<div class="article-summary-box-inner">
<span><p>One of the most challenging goals in designing intelligent systems is
empowering them with the ability to synthesize programs from data. Namely,
given specific requirements in the form of input/output pairs, the goal is to
train a machine learning model to discover a program that satisfies those
requirements. A recent class of methods exploits combinatorial search
procedures and deep learning to learn compositional programs. However, they
usually generate only toy programs using a domain-specific language that does
not provide any high-level feature, such as function arguments, which reduces
their applicability in real-world settings. We extend upon a state of the art
model, AlphaNPI, by learning to generate functions that can accept arguments.
This improvement will enable us to move closer to real computer programs.
Moreover, we investigate employing an Approximate version of Monte Carlo Tree
Search (A-MCTS) to speed up convergence. We showcase the potential of our
approach by learning the Quicksort algorithm, showing how the ability to deal
with arguments is crucial for learning and generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Multi-Centroid Template Matching Algorithm and Its Application to Cough Detection. (arXiv:2109.00630v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00630">
<div class="article-summary-box-inner">
<span><p>Cough is a major symptom of respiratory-related diseases. There exists a
tremendous amount of work in detecting coughs from audio but there has been no
effort to identify coughs from solely inertial measurement unit (IMU). Coughing
causes motion across the whole body and especially on the neck and head.
Therefore, head motion data during coughing captured by a head-worn IMU sensor
could be leveraged to detect coughs using a template matching algorithm. In
time series template matching problems, K-Nearest Neighbors (KNN) combined with
elastic distance measurement (esp. Dynamic Time Warping (DTW)) achieves
outstanding performance. However, it is often regarded as prohibitively
time-consuming. Nearest Centroid Classifier is thereafter proposed. But the
accuracy is comprised of only one centroid obtained for each class.
Centroid-based Classifier performs clustering and averaging for each cluster,
but requires manually setting the number of clusters. We propose a novel
self-tuning multi-centroid template-matching algorithm, which can automatically
adjust the number of clusters to balance accuracy and inference time. Through
experiments conducted on synthetic datasets and a real-world earbud-based cough
dataset, we demonstrate the superiority of our proposed algorithm and present
the result of cough detection with a single accelerometer sensor on the earbuds
platform.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controllable deep melody generation via hierarchical music structure representation. (arXiv:2109.00663v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00663">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning have expanded possibilities to generate
music, but generating a customizable full piece of music with consistent
long-term structure remains a challenge. This paper introduces MusicFrameworks,
a hierarchical music structure representation and a multi-step generative
process to create a full-length melody guided by long-term repetitive
structure, chord, melodic contour, and rhythm constraints. We first organize
the full melody with section and phrase-level structure. To generate melody in
each phrase, we generate rhythm and basic melody using two separate
transformer-based networks, and then generate the melody conditioned on the
basic melody, rhythm and chords in an auto-regressive manner. By factoring
music generation into sub-problems, our approach allows simpler models and
requires less data. To customize or add variety, one can alter chords, basic
melody, and rhythm structure in the music frameworks, letting our networks
generate the melody accordingly. Additionally, we introduce new features to
encode musical positional information, rhythm patterns, and melodic contours
based on musical domain knowledge. A listening test reveals that melodies
generated by our method are rated as good as or better than human-composed
music in the POP909 dataset about half the time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TabFairGAN: Fair Tabular Data Generation with Generative Adversarial Networks. (arXiv:2109.00666v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00666">
<div class="article-summary-box-inner">
<span><p>With the increasing reliance on automated decision making, the issue of
algorithmic fairness has gained increasing importance. In this paper, we
propose a Generative Adversarial Network for tabular data generation. The model
includes two phases of training. In the first phase, the model is trained to
accurately generate synthetic data similar to the reference dataset. In the
second phase we modify the value function to add fairness constraint, and
continue training the network to generate data that is both accurate and fair.
We test our results in both cases of unconstrained, and constrained fair data
generation. In the unconstrained case, i.e. when the model is only trained in
the first phase and is only meant to generate accurate data following the same
joint probability distribution of the real data, the results show that the
model beats state-of-the-art GANs proposed in the literature to produce
synthetic tabular data. Also, in the constrained case in which the first phase
of training is followed by the second phase, we train the network and test it
on four datasets studied in the fairness literature and compare our results
with another state-of-the-art pre-processing method, and present the promising
results that it achieves. Comparing to other studies utilizing GANs for fair
data generation, our model is comparably more stable by using only one critic,
and also by avoiding major problems of original GAN model, such as
mode-dropping and non-convergence, by implementing a Wasserstein GAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AnANet: Modeling Association and Alignment for Cross-modal Correlation Classification. (arXiv:2109.00693v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00693">
<div class="article-summary-box-inner">
<span><p>The explosive increase of multimodal data makes a great demand in many
cross-modal applications that follow the strict prior related assumption. Thus
researchers study the definition of cross-modal correlation category and
construct various classification systems and predictive models. However, those
systems pay more attention to the fine-grained relevant types of cross-modal
correlation, ignoring lots of implicit relevant data which are often divided
into irrelevant types. What's worse is that none of previous predictive models
manifest the essence of cross-modal correlation according to their definition
at the modeling stage. In this paper, we present a comprehensive analysis of
the image-text correlation and redefine a new classification system based on
implicit association and explicit alignment. To predict the type of image-text
correlation, we propose the Association and Alignment Network according to our
proposed definition (namely AnANet) which implicitly represents the global
discrepancy and commonality between image and text and explicitly captures the
cross-modal local relevance. The experimental results on our constructed new
image-text correlation dataset show the effectiveness of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Algorithms For Fair Clustering with a New Fairness Notion. (arXiv:2109.00708v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00708">
<div class="article-summary-box-inner">
<span><p>We revisit the problem of fair clustering, first introduced by Chierichetti
et al., that requires each protected attribute to have approximately equal
representation in every cluster; i.e., a balance property. Existing solutions
to fair clustering are either not scalable or do not achieve an optimal
trade-off between clustering objective and fairness. In this paper, we propose
a new notion of fairness, which we call $tau$-fair fairness, that strictly
generalizes the balance property and enables a fine-grained efficiency vs.
fairness trade-off. Furthermore, we show that simple greedy round-robin based
algorithms achieve this trade-off efficiently. Under a more general setting of
multi-valued protected attributes, we rigorously analyze the theoretical
properties of the our algorithms. Our experimental results suggest that the
proposed solution outperforms all the state-of-the-art algorithms and works
exceptionally well even for a large number of clusters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RF-LighGBM: A probabilistic ensemble way to predict customer repurchase behaviour in community e-commerce. (arXiv:2109.00724v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00724">
<div class="article-summary-box-inner">
<span><p>It is reported that the number of online payment users in China has reached
854 million; with the emergence of community e-commerce platforms, the trend of
integration of e-commerce and social applications is increasingly intense.
Community e-commerce is not a mature and sound comprehensive e-commerce with
fewer categories and low brand value. To effectively retain community users and
fully explore customer value has become an important challenge for community
e-commerce operators. Given the above problems, this paper uses the data-driven
method to study the prediction of community e-commerce customers' repurchase
behaviour. The main research contents include 1. Given the complex problem of
feature engineering, the classic model RFM in the field of customer
relationship management is improved, and an improved model is proposed to
describe the characteristics of customer buying behaviour, which includes five
indicators. 2. In view of the imbalance of machine learning training samples in
SMOTE-ENN, a training sample balance using SMOTE-ENN is proposed. The
experimental results show that the machine learning model can be trained more
effectively on balanced samples. 3. Aiming at the complexity of the parameter
adjustment process, an automatic hyperparameter optimization method based on
the TPE method was proposed. Compared with other methods, the model's
prediction performance is improved, and the training time is reduced by more
than 450%. 4. Aiming at the weak prediction ability of a single model, the soft
voting based RF-LightgBM model was proposed. The experimental results show that
the RF-LighTGBM model proposed in this paper can effectively predict customer
repurchase behaviour, and the F1 value is 0.859, which is better than the
single model and previous research results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Some Inapproximability Results of MAP Inference and Exponentiated Determinantal Point Processes. (arXiv:2109.00727v1 [cs.DS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00727">
<div class="article-summary-box-inner">
<span><p>We study the computational complexity of two hard problems on determinantal
point processes (DPPs). One is maximum a posteriori (MAP) inference, i.e., to
find a principal submatrix having the maximum determinant. The other is
probabilistic inference on exponentiated DPPs (E-DPPs), which can sharpen or
weaken the diversity preference of DPPs with an exponent parameter $p$. We
prove the following complexity-theoretic hardness results that explain the
difficulty in approximating MAP inference and the normalizing constant for
E-DPPs.
</p>
<p>1. Unconstrained MAP inference for an $n \times n$ matrix is NP-hard to
approximate within a factor of $2^{\beta n}$, where $\beta = 10^{-10^{13}} $.
This result improves upon a $(\frac{9}{8}-\epsilon)$-factor inapproximability
given by Kulesza and Taskar (2012).
</p>
<p>2. Log-determinant maximization is NP-hard to approximate within a factor of
$\frac{5}{4}$ for the unconstrained case and within a factor of
$1+10^{-10^{13}}$ for the size-constrained monotone case.
</p>
<p>3. The normalizing constant for E-DPPs of any (fixed) constant exponent $p
\geq \beta^{-1} = 10^{10^{13}}$ is NP-hard to approximate within a factor of
$2^{\beta pn}$. This gives a(nother) negative answer to open questions posed by
Kulesza and Taskar (2012); Ohsaka and Matsuoka (2020).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConQX: Semantic Expansion of Spoken Queries for Intent Detection based on Conditioned Text Generation. (arXiv:2109.00729v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00729">
<div class="article-summary-box-inner">
<span><p>Intent detection of spoken queries is a challenging task due to their noisy
structure and short length. To provide additional information regarding the
query and enhance the performance of intent detection, we propose a method for
semantic expansion of spoken queries, called ConQX, which utilizes the text
generation ability of an auto-regressive language model, GPT-2. To avoid
off-topic text generation, we condition the input query to a structured context
with prompt mining. We then apply zero-shot, one-shot, and few-shot learning.
We lastly use the expanded queries to fine-tune BERT and RoBERTa for intent
detection. The experimental results show that the performance of intent
detection can be improved by our semantic expansion method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Energy-Efficient Multi-Orchestrator Mobile Edge Learning. (arXiv:2109.00757v1 [cs.NI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00757">
<div class="article-summary-box-inner">
<span><p>Mobile Edge Learning (MEL) is a collaborative learning paradigm that features
distributed training of Machine Learning (ML) models over edge devices (e.g.,
IoT devices). In MEL, possible coexistence of multiple learning tasks with
different datasets may arise. The heterogeneity in edge devices' capabilities
will require the joint optimization of the learners-orchestrator association
and task allocation. To this end, we aim to develop an energy-efficient
framework for learners-orchestrator association and learning task allocation,
in which each orchestrator gets associated with a group of learners with the
same learning task based on their communication channel qualities and
computational resources, and allocate the tasks accordingly. Therein, a multi
objective optimization problem is formulated to minimize the total energy
consumption and maximize the learning tasks' accuracy. However, solving such
optimization problem requires centralization and the presence of the whole
environment information at a single entity, which becomes impractical in
large-scale systems. To reduce the solution complexity and to enable solution
decentralization, we propose lightweight heuristic algorithms that can achieve
near-optimal performance and facilitate the trade-offs between energy
consumption, accuracy, and solution complexity. Simulation results show that
the proposed approaches reduce the energy consumption significantly while
executing multiple learning tasks compared to recent state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VIbCReg: Variance-Invariance-better-Covariance Regularization for Self-Supervised Learning on Time Series. (arXiv:2109.00783v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00783">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning for image representations has recently had many
breakthroughs with respect to linear evaluation and fine-tuning evaluation.
These approaches rely on both cleverly crafted loss functions and training
setups to avoid the feature collapse problem. In this paper, we improve on the
recently proposed VICReg paper, which introduced a loss function that does not
rely on specialized training loops to converge to useful representations. Our
method improves on a covariance term proposed in VICReg, and in addition we
augment the head of the architecture by an IterNorm layer that greatly
accelerates convergence of the model. Our model achieves superior performance
on linear evaluation and fine-tuning evaluation on a subset of the UCR time
series classification archive and the PTB-XL ECG dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NASI: Label- and Data-agnostic Neural Architecture Search at Initialization. (arXiv:2109.00817v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00817">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed a surging interest in Neural Architecture Search
(NAS). Various algorithms have been proposed to improve the search efficiency
and effectiveness of NAS, i.e., to reduce the search cost and improve the
generalization performance of the selected architectures, respectively.
However, the search efficiency of these algorithms is severely limited by the
need for model training during the search process. To overcome this limitation,
we propose a novel NAS algorithm called NAS at Initialization (NASI) that
exploits the capability of a Neural Tangent Kernel in being able to
characterize the converged performance of candidate architectures at
initialization, hence allowing model training to be completely avoided to boost
the search efficiency. Besides the improved search efficiency, NASI also
achieves competitive search effectiveness on various datasets like CIFAR-10/100
and ImageNet. Further, NASI is shown to be label- and data-agnostic under mild
conditions, which guarantees the transferability of architectures selected by
our NASI over different datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SlowFast Rolling-Unrolling LSTMs for Action Anticipation in Egocentric Videos. (arXiv:2109.00829v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00829">
<div class="article-summary-box-inner">
<span><p>Action anticipation in egocentric videos is a difficult task due to the
inherently multi-modal nature of human actions. Additionally, some actions
happen faster or slower than others depending on the actor or surrounding
context which could vary each time and lead to different predictions. Based on
this idea, we build upon RULSTM architecture, which is specifically designed
for anticipating human actions, and propose a novel attention-based technique
to evaluate, simultaneously, slow and fast features extracted from three
different modalities, namely RGB, optical flow, and extracted objects. Two
branches process information at different time scales, i.e., frame-rates, and
several fusion schemes are considered to improve prediction accuracy. We
perform extensive experiments on EpicKitchens-55 and EGTEA Gaze+ datasets, and
demonstrate that our technique systematically improves the results of RULSTM
architecture for Top-5 accuracy metric at different anticipation times.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knot invariants and their relations: a topological perspective. (arXiv:2109.00831v1 [math.AT])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00831">
<div class="article-summary-box-inner">
<span><p>This work brings methods from topological data analysis to knot theory and
develops new data analysis tools inspired by this application. We explore a
vast collection of knot invariants and relations between then using Mapper and
Ball Mapper algorithms. In particular, we develop versions of the Ball Mapper
algorithm that incorporate symmetries and other relations within the data, and
provide ways to compare data arising from different descriptors, such as knot
invariants. Additionally, we extend the Mapper construction to the case where
the range of the lens function is high dimensional rather than a 1-dimensional
space, that also provides ways of visualizing functions between
high-dimensional spaces. We illustrate the use of these techniques on knot
theory data and draw attention to potential implications of our findings in
knot theory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Automated Framework for Supporting Data-Governance Rule Compliance in Decentralized MIMO Contexts. (arXiv:2109.00838v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00838">
<div class="article-summary-box-inner">
<span><p>We propose Dr.Aid, a logic-based AI framework for automated compliance
checking of data governance rules over data-flow graphs. The rules are modelled
using a formal language based on situation calculus and are suitable for
decentralized contexts with multi-input-multi-output (MIMO) processes. Dr.Aid
models data rules and flow rules and checks compliance by reasoning about the
propagation, combination, modification and application of data rules over the
data flow graphs. Our approach is driven and evaluated by real-world datasets
using provenance graphs from data-intensive research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning. (arXiv:2109.00840v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00840">
<div class="article-summary-box-inner">
<span><p>Though language model text embeddings have revolutionized NLP research, their
ability to capture high-level semantic information, such as relations between
entities in text, is limited. In this paper, we propose a novel contrastive
learning framework that trains sentence embeddings to encode the relations in a
graph structure. Given a sentence (unstructured text) and its graph, we use
contrastive learning to impose relation-related structure on the token-level
representations of the sentence obtained with a CharacterBERT (El Boukkouri et
al.,2020) model. The resulting relation-aware sentence embeddings achieve
state-of-the-art results on the relation extraction task using only a simple
KNN classifier, thereby demonstrating the success of the proposed method.
Additional visualization by a tSNE analysis shows the effectiveness of the
learned representation space compared to baselines. Furthermore, we show that
we can learn a different space for named entity recognition, again using a
contrastive learning objective, and demonstrate how to successfully combine
both representation spaces in an entity-relation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPU-accelerated Optimal Path Planning in Stochastic Dynamic Environments. (arXiv:2109.00857v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00857">
<div class="article-summary-box-inner">
<span><p>Autonomous marine vehicles play an essential role in many ocean science and
engineering applications. Planning time and energy optimal paths for these
vehicles to navigate in stochastic dynamic ocean environments is essential to
reduce operational costs. In some missions, they must also harvest solar, wind,
or wave energy (modeled as a stochastic scalar field) and move in optimal paths
that minimize net energy consumption. Markov Decision Processes (MDPs) provide
a natural framework for sequential decision-making for robotic agents in such
environments. However, building a realistic model and solving the modeled MDP
becomes computationally expensive in large-scale real-time applications,
warranting the need for parallel algorithms and efficient implementation. In
the present work, we introduce an efficient end-to-end GPU-accelerated
algorithm that (i) builds the MDP model (computing transition probabilities and
expected one-step rewards); and (ii) solves the MDP to compute an optimal
policy. We develop methodical and algorithmic solutions to overcome the limited
global memory of GPUs by (i) using a dynamic reduced-order representation of
the ocean flows, (ii) leveraging the sparse nature of the state transition
probability matrix, (iii) introducing a neighbouring sub-grid concept and (iv)
proving that it is sufficient to use only the stochastic scalar field's mean to
compute the expected one-step rewards for missions involving energy harvesting
from the environment; thereby saving memory and reducing the computational
effort. We demonstrate the algorithm on a simulated stochastic dynamic
environment and highlight that it builds the MDP model and computes the optimal
policy 600-1000x faster than conventional CPU implementations, making it
suitable for real-time use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VORRT-COLREGs: A Hybrid Velocity Obstacles and RRT Based COLREGs-Compliant Path Planner for Autonomous Surface Vessels. (arXiv:2109.00862v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00862">
<div class="article-summary-box-inner">
<span><p>This paper presents VORRT-COLREGs, a hybrid technique that combines velocity
obstacles (VO) and rapidly-exploring random trees (RRT) to generate safe
trajectories for autonomous surface vessels (ASVs) while following nautical
rules of the road. RRT generates a set of way points and the velocity obstacles
method ensures safe travel between way points. We also ensure that the actions
of ASVs do not violate maritime collision guidelines. Earlier work has used RRT
and VO separately to generate paths for ASVs. However, RRT does not handle
highly dynamic situations well and and VO seems most suitable as a local path
planner. Combining both approaches, VORRT-COLREGs is a global path planner that
uses a joint forward simulation to ensure that generated paths remain valid and
collision free as the situation changes. Experiments were conducted in
different types of collision scenarios and with different numbers of ASVs.
Results show that VORRT-COLREGS generated collision regulations (COLREGs)
complaint paths in open ocean scenarios. Furthermore, VORRT-COLREGS
successfully generated compliant paths within traffic separation schemes. These
results show the applicability of our technique for generating paths for ASVs
in different collision scenarios. To the best of our knowledge, this is the
first work that combines velocity obstacles and RRT to produce safe and COLREGs
complaint path for ASVs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Habitual and Reflective Control in Hierarchical Predictive Coding. (arXiv:2109.00866v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00866">
<div class="article-summary-box-inner">
<span><p>In cognitive science, behaviour is often separated into two types. Reflexive
control is habitual and immediate, whereas reflective is deliberative and time
consuming. We examine the argument that Hierarchical Predictive Coding (HPC)
can explain both types of behaviour as a continuum operating across a
multi-layered network, removing the need for separate circuits in the brain. On
this view, "fast" actions may be triggered using only the lower layers of the
HPC schema, whereas more deliberative actions need higher layers. We
demonstrate that HPC can distribute learning throughout its hierarchy, with
higher layers called into use only as required.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MACRPO: Multi-Agent Cooperative Recurrent Policy Optimization. (arXiv:2109.00882v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00882">
<div class="article-summary-box-inner">
<span><p>This work considers the problem of learning cooperative policies in
multi-agent settings with partially observable and non-stationary environments
without a communication channel. We focus on improving information sharing
between agents and propose a new multi-agent actor-critic method called
\textit{Multi-Agent Cooperative Recurrent Proximal Policy Optimization}
(MACRPO). We propose two novel ways of integrating information across agents
and time in MACRPO: First, we use a recurrent layer in critic's network
architecture and propose a new framework to use a meta-trajectory to train the
recurrent layer. This allows the network to learn the cooperation and dynamics
of interactions between agents, and also handle partial observability. Second,
we propose a new advantage function that incorporates other agents' rewards and
value functions. We evaluate our algorithm on three challenging multi-agent
environments with continuous and discrete action spaces, Deepdrive-Zero,
Multi-Walker, and Particle environment. We compare the results with several
ablations and state-of-the-art multi-agent algorithms such as QMIX and MADDPG
and also single-agent methods with shared parameters between agents such as
IMPALA and APEX. The results show superior performance against other
algorithms. The code is available online at
https://github.com/kargarisaac/macrpo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Perceived Multi-modal Pretraining in E-commerce. (arXiv:2109.00895v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00895">
<div class="article-summary-box-inner">
<span><p>In this paper, we address multi-modal pretraining of product data in the
field of E-commerce. Current multi-modal pretraining methods proposed for image
and text modalities lack robustness in the face of modality-missing and
modality-noise, which are two pervasive problems of multi-modal product data in
real E-commerce scenarios. To this end, we propose a novel method, K3M, which
introduces knowledge modality in multi-modal pretraining to correct the noise
and supplement the missing of image and text modalities. The modal-encoding
layer extracts the features of each modality. The modal-interaction layer is
capable of effectively modeling the interaction of multiple modalities, where
an initial-interactive feature fusion model is designed to maintain the
independence of image modality and text modality, and a structure aggregation
module is designed to fuse the information of image, text, and knowledge
modalities. We pretrain K3M with three pretraining tasks, including masked
object modeling (MOM), masked language modeling (MLM), and link prediction
modeling (LPM). Experimental results on a real-world E-commerce dataset and a
series of product-based downstream tasks demonstrate that K3M achieves
significant improvements in performances than the baseline and state-of-the-art
methods when modality-noise or modality-missing exists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effect of the output activation function on the probabilities and errors in medical image segmentation. (arXiv:2109.00903v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00903">
<div class="article-summary-box-inner">
<span><p>The sigmoid activation is the standard output activation function in binary
classification and segmentation with neural networks. Still, there exist a
variety of other potential output activation functions, which may lead to
improved results in medical image segmentation. In this work, we consider how
the asymptotic behavior of different output activation and loss functions
affects the prediction probabilities and the corresponding segmentation errors.
For cross entropy, we show that a faster rate of change of the activation
function correlates with better predictions, while a slower rate of change can
improve the calibration of probabilities. For dice loss, we found that the
arctangent activation function is superior to the sigmoid function.
Furthermore, we provide a test space for arbitrary output activation functions
in the area of medical image segmentation. We tested seven activation functions
in combination with three loss functions on four different medical image
segmentation tasks to provide a classification of which function is best suited
in this application scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparsifying the Update Step in Graph Neural Networks. (arXiv:2109.00909v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00909">
<div class="article-summary-box-inner">
<span><p>Message-Passing Neural Networks (MPNNs), the most prominent Graph Neural
Network (GNN) framework, celebrate much success in the analysis of
graph-structured data. Concurrently, the sparsification of Neural Network
models attracts a great amount of academic and industrial interest. In this
paper, we conduct a structured study of the effect of sparsification on the
trainable part of MPNNs known as the Update step. To this end, we design a
series of models to successively sparsify the linear transform in the Update
step. Specifically, we propose the ExpanderGNN model with a tuneable
sparsification rate and the Activation-Only GNN, which has no linear transform
in the Update step. In agreement with a growing trend in the literature, the
sparsification paradigm is changed by initialising sparse neural network
architectures rather than expensively sparsifying already trained
architectures. Our novel benchmark models enable a better understanding of the
influence of the Update step on model performance and outperform existing
simplified benchmark models such as the Simple Graph Convolution. The
ExpanderGNNs, and in some cases the Activation-Only models, achieve performance
on par with their vanilla counterparts on several downstream tasks while
containing significantly fewer trainable parameters. In experiments with
matching parameter numbers, our benchmark models outperform the
state-of-the-art GNN models. Our code is publicly available at:
https://github.com/ChangminWu/ExpanderGNN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-task learning from fixed-wing UAV images for 2D/3D city modeling. (arXiv:2109.00918v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00918">
<div class="article-summary-box-inner">
<span><p>Single-task learning in artificial neural networks will be able to learn the
model very well, and the benefits brought by transferring knowledge thus become
limited. In this regard, when the number of tasks increases (e.g., semantic
segmentation, panoptic segmentation, monocular depth estimation, and 3D point
cloud), duplicate information may exist across tasks, and the improvement
becomes less significant. Multi-task learning has emerged as a solution to
knowledge-transfer issues and is an approach to scene understanding which
involves multiple related tasks each with potentially limited training data.
Multi-task learning improves generalization by leveraging the domain-specific
information contained in the training data of related tasks. In urban
management applications such as infrastructure development, traffic monitoring,
smart 3D cities, and change detection, automated multi-task data analysis for
scene understanding based on the semantic, instance, and panoptic annotation,
as well as monocular depth estimation, is required to generate precise urban
models. In this study, a common framework for the performance assessment of
multi-task learning methods from fixed-wing UAV images for 2D/3D city modeling
is presented.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Multimodal fusion via Mutual Dependency Maximisation. (arXiv:2109.00922v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00922">
<div class="article-summary-box-inner">
<span><p>Multimodal sentiment analysis is a trending area of research, and the
multimodal fusion is one of its most active topic. Acknowledging humans
communicate through a variety of channels (i.e visual, acoustic, linguistic),
multimodal systems aim at integrating different unimodal representations into a
synthetic one. So far, a consequent effort has been made on developing complex
architectures allowing the fusion of these modalities. However, such systems
are mainly trained by minimising simple losses such as $L_1$ or cross-entropy.
In this work, we investigate unexplored penalties and propose a set of new
objectives that measure the dependency between modalities. We demonstrate that
our new penalties lead to a consistent improvement (up to $4.3$ on accuracy)
across a large variety of state-of-the-art models on two well-known sentiment
analysis datasets: \texttt{CMU-MOSI} and \texttt{CMU-MOSEI}. Our method not
only achieves a new SOTA on both datasets but also produces representations
that are more robust to modality drops. Finally, a by-product of our methods
includes a statistical network which can be used to interpret the high
dimensional representations learnt by the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Autonomous Curiosity for Real-Time Training Onboard Robotic Agents. (arXiv:2109.00927v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00927">
<div class="article-summary-box-inner">
<span><p>Learning requires both study and curiosity. A good learner is not only good
at extracting information from the data given to it, but also skilled at
finding the right new information to learn from. This is especially true when a
human operator is required to provide the ground truth - such a source should
only be queried sparingly. In this work, we address the problem of curiosity as
it relates to online, real-time, human-in-the-loop training of an object
detection algorithm onboard a robotic platform, one where motion produces new
views of the subject. We propose a deep reinforcement learning approach that
decides when to ask the human user for ground truth, and when to move. Through
a series of experiments, we demonstrate that our agent learns a movement and
request policy that is at least 3x more effective at using human user
interactions to train an object detector than untrained approaches, and is
generalizable to a variety of subjects and environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Study of Algorithms for Intelligent Traffic Signal Control. (arXiv:2109.00937v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00937">
<div class="article-summary-box-inner">
<span><p>In this paper, methods have been explored to effectively optimise traffic
signal control to minimise waiting times and queue lengths, thereby increasing
traffic flow. The traffic intersection was first defined as a Markov Decision
Process, and a state representation, actions and rewards were chosen.
Simulation of Urban MObility (SUMO) was used to simulate an intersection and
then compare a Round Robin Scheduler, a Feedback Control mechanism and two
Reinforcement Learning techniques - Deep Q Network (DQN) and Advantage
Actor-Critic (A2C), as the policy for the traffic signal in the simulation
under different scenarios. Finally, the methods were tested on a simulation of
a real-world intersection in Bengaluru, India.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAM: Explainable Visual Similarity and Classification via Gradient Activation Maps. (arXiv:2109.00951v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00951">
<div class="article-summary-box-inner">
<span><p>We present Gradient Activation Maps (GAM) - a machinery for explaining
predictions made by visual similarity and classification models. By gleaning
localized gradient and activation information from multiple network layers, GAM
offers improved visual explanations, when compared to existing alternatives.
The algorithmic advantages of GAM are explained in detail, and validated
empirically, where it is shown that GAM outperforms its alternatives across
various tasks and datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TrouSPI-Net: Spatio-temporal attention on parallel atrous convolutions and U-GRUs for skeletal pedestrian crossing prediction. (arXiv:2109.00953v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00953">
<div class="article-summary-box-inner">
<span><p>Understanding the behaviors and intentions of pedestrians is still one of the
main challenges for vehicle autonomy, as accurate predictions of their
intentions can guarantee their safety and driving comfort of vehicles. In this
paper, we address pedestrian crossing prediction in urban traffic environments
by linking the dynamics of a pedestrian's skeleton to a binary crossing
intention. We introduce TrouSPI-Net: a context-free, lightweight, multi-branch
predictor. TrouSPI-Net extracts spatio-temporal features for different time
resolutions by encoding pseudo-images sequences of skeletal joints' positions
and processes them with parallel attention modules and atrous convolutions. The
proposed approach is then enhanced by processing features such as relative
distances of skeletal joints, bounding box positions, or ego-vehicle speed with
U-GRUs. Using the newly proposed evaluation procedures for two large public
naturalistic data sets for studying pedestrian behavior in traffic: JAAD and
PIE, we evaluate TrouSPI-Net and analyze its performance. Experimental results
show that TrouSPI-Net achieved 0.76 F1 score on JAAD and 0.80 F1 score on PIE,
therefore outperforming current state-of-the-art while being lightweight and
context-free.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Infrared Image Super-Resolution via Heterogeneous Convolutional WGAN. (arXiv:2109.00960v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00960">
<div class="article-summary-box-inner">
<span><p>Image super-resolution is important in many fields, such as surveillance and
remote sensing. However, infrared (IR) images normally have low resolution
since the optical equipment is relatively expensive. Recently, deep learning
methods have dominated image super-resolution and achieved remarkable
performance on visible images; however, IR images have received less attention.
IR images have fewer patterns, and hence, it is difficult for deep neural
networks (DNNs) to learn diverse features from IR images. In this paper, we
present a framework that employs heterogeneous convolution and adversarial
training, namely, heterogeneous kernel-based super-resolution Wasserstein GAN
(HetSRWGAN), for IR image super-resolution. The HetSRWGAN algorithm is a
lightweight GAN architecture that applies a plug-and-play heterogeneous
kernel-based residual block. Moreover, a novel loss function that employs image
gradients is adopted, which can be applied to an arbitrary model. The proposed
HetSRWGAN achieves consistently better performance in both qualitative and
quantitative evaluations. According to the experimental results, the whole
training process is more stable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Dedicated CDCL Strategies for PB Solvers. (arXiv:2109.01013v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01013">
<div class="article-summary-box-inner">
<span><p>Current implementations of pseudo-Boolean (PB) solvers working on native PB
constraints are based on the CDCL architecture which empowers highly efficient
modern SAT solvers. In particular, such PB solvers not only implement a
(cutting-planes-based) conflict analysis procedure, but also complementary
strategies for components that are crucial for the efficiency of CDCL, namely
branching heuristics, learned constraint deletion and restarts. However, these
strategies are mostly reused by PB solvers without considering the particular
form of the PB constraints they deal with. In this paper, we present and
evaluate different ways of adapting CDCL strategies to take the specificities
of PB constraints into account while preserving the behavior they have in the
clausal setting. We implemented these strategies in two different solvers,
namely Sat4j (for which we consider three configurations) and RoundingSat. Our
experiments show that these dedicated strategies allow to improve, sometimes
significantly, the performance of these solvers, both on decision and
optimization problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterizing possible failure modes in physics-informed neural networks. (arXiv:2109.01050v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01050">
<div class="article-summary-box-inner">
<span><p>Recent work in scientific machine learning has developed so-called
physics-informed neural network (PINN) models. The typical approach is to
incorporate physical domain knowledge as soft constraints on an empirical loss
function and use existing machine learning methodologies to train the model. We
demonstrate that, while existing PINN methodologies can learn good models for
relatively trivial problems, they can easily fail to learn relevant physical
phenomena even for simple PDEs. In particular, we analyze several distinct
situations of widespread physical interest, including learning differential
equations with convection, reaction, and diffusion operators. We provide
evidence that the soft regularization in PINNs, which involves differential
operators, can introduce a number of subtle problems, including making the
problem ill-conditioned. Importantly, we show that these possible failure modes
are not due to the lack of expressivity in the NN architecture, but that the
PINN's setup makes the loss landscape very hard to optimize. We then describe
two promising solutions to address these failure modes. The first approach is
to use curriculum regularization, where the PINN's loss term starts from a
simple PDE regularization, and becomes progressively more complex as the NN
gets trained. The second approach is to pose the problem as a
sequence-to-sequence learning task, rather than learning to predict the entire
space-time at once. Extensive testing shows that we can achieve up to 1-2
orders of magnitude lower error with these methods as compared to regular PINN
training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards disease-aware image editing of chest X-rays. (arXiv:2109.01071v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01071">
<div class="article-summary-box-inner">
<span><p>Disease-aware image editing by means of generative adversarial networks
(GANs) constitutes a promising avenue for advancing the use of AI in the
healthcare sector. Here, we present a proof of concept of this idea. While
GAN-based techniques have been successful in generating and manipulating
natural images, their application to the medical domain, however, is still in
its infancy. Working with the CheXpert data set, we show that StyleGAN can be
trained to generate realistic chest X-rays. Inspired by the Cyclic Reverse
Generator (CRG) framework, we train an encoder that allows for faithfully
inverting the generator on synthetic X-rays and provides organ-level
reconstructions of real ones. Employing a guided manipulation of latent codes,
we confer the medical condition of cardiomegaly (increased heart size) onto
real X-rays from healthy patients. This work was presented in the Medical
Imaging meets Neurips Workshop 2020, which was held as part of the 34th
Conference on Neural Information Processing Systems (NeurIPS 2020) in
Vancouver, Canada
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Classification for Predicting Multi-level Product Categories. (arXiv:2109.01084v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01084">
<div class="article-summary-box-inner">
<span><p>In an online shopping platform, a detailed classification of the products
facilitates user navigation. It also helps online retailers keep track of the
price fluctuations in a certain industry or special discounts on a specific
product category. Moreover, an automated classification system may help to
pinpoint incorrect or subjective categories suggested by an operator. In this
study, we focus on product title classification of the grocery products. We
perform a comprehensive comparison of six different text classification models
to establish a strong baseline for this task, which involves testing both
traditional and recent machine learning methods. In our experiments, we
investigate the generalizability of the trained models to the products of other
online retailers, the dynamic masking of infeasible subcategories for
pretrained language models, and the benefits of incorporating product titles in
multiple languages. Our numerical results indicate that dynamic masking of
subcategories is effective in improving prediction accuracy. In addition, we
observe that using bilingual product titles is generally beneficial, and neural
network-based models perform significantly better than SVM and XGBoost models.
Lastly, we investigate the reasons for the misclassified products and propose
future research directions to further enhance the prediction models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On-target Adaptation. (arXiv:2109.01087v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01087">
<div class="article-summary-box-inner">
<span><p>Domain adaptation seeks to mitigate the shift between training on the
\emph{source} domain and testing on the \emph{target} domain. Most adaptation
methods rely on the source data by joint optimization over source data and
target data. Source-free methods replace the source data with a source model by
fine-tuning it on target. Either way, the majority of the parameter updates for
the model representation and the classifier are derived from the source, and
not the target. However, target accuracy is the goal, and so we argue for
optimizing as much as possible on the target data. We show significant
improvement by on-target adaptation, which learns the representation purely
from target data while taking only the source predictions for supervision. In
the long-tailed classification setting, we show further improvement by
on-target class distribution learning, which learns the (im)balance of classes
from target data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Language-Conditioned Robot Behavior from Offline Data and Crowd-Sourced Annotation. (arXiv:2109.01115v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01115">
<div class="article-summary-box-inner">
<span><p>We study the problem of learning a range of vision-based manipulation tasks
from a large offline dataset of robot interaction. In order to accomplish this,
humans need easy and effective ways of specifying tasks to the robot. Goal
images are one popular form of task specification, as they are already grounded
in the robot's observation space. However, goal images also have a number of
drawbacks: they are inconvenient for humans to provide, they can over-specify
the desired behavior leading to a sparse reward signal, or under-specify task
information in the case of non-goal reaching tasks. Natural language provides a
convenient and flexible alternative for task specification, but comes with the
challenge of grounding language in the robot's observation space. To scalably
learn this grounding we propose to leverage offline robot datasets (including
highly sub-optimal, autonomously collected data) with crowd-sourced natural
language labels. With this data, we learn a simple classifier which predicts if
a change in state completes a language instruction. This provides a
language-conditioned reward function that can then be used for offline
multi-task RL. In our experiments, we find that on language-conditioned
manipulation tasks our approach outperforms both goal-image specifications and
language conditioned imitation techniques by more than 25%, and is able to
perform visuomotor tasks from natural language, such as "open the right drawer"
and "move the stapler", on a Franka Emika Panda robot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Reasoning Engine for the Gamification of Loop-Invariant Discovery. (arXiv:2109.01121v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01121">
<div class="article-summary-box-inner">
<span><p>We describe the design and implementation of a reasoning engine that
facilitates the gamification of loop-invariant discovery. Our reasoning engine
enables students, computational agents and regular software engineers with no
formal methods expertise to collaboratively prove interesting theorems about
simple programs using browser-based, online games. Within an hour, players are
able to specify and verify properties of programs that are beyond the
capabilities of fully-automated tools. The hour limit includes the time for
setting up the system, completing a short tutorial explaining game play and
reasoning about simple imperative programs. Players are never required to
understand formal proofs; they only provide insights by proposing invariants.
The reasoning engine is responsible for managing and evaluating the proposed
invariants, as well as generating actionable feedback.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking the Robustness of Instance Segmentation Models. (arXiv:2109.01123v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01123">
<div class="article-summary-box-inner">
<span><p>This paper presents a comprehensive evaluation of instance segmentation
models with respect to real-world image corruptions and out-of-domain image
collections, e.g. datasets collected with different set-ups than the training
datasets the models learned from. The out-of-domain image evaluation shows the
generalization capability of models, an essential aspect of real-world
applications, and an extensively studied topic of domain adaptation. These
presented robustness and generalization evaluations are important when
designing instance segmentation models for real-world applications and picking
an off-the-shelf pretrained model to directly use for the task at hand.
Specifically, this benchmark study includes state-of-the-art network
architectures, network backbones, normalization layers, models trained starting
from scratch or ImageNet pretrained networks, and the effect of multi-task
training on robustness and generalization. Through this study, we gain several
insights e.g. we find that normalization layers play an essential role in
robustness, ImageNet pretraining does not help the robustness and the
generalization of models, excluding JPEG corruption, and network backbones and
copy-paste augmentations affect robustness significantly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01134">
<div class="article-summary-box-inner">
<span><p>Vision-language pre-training has recently emerged as a promising alternative
for representation learning. It shifts from the tradition of using images and
discrete labels for learning a fixed set of weights, seen as visual concepts,
to aligning images and raw text for two separate encoders. Such a paradigm
benefits from a broader source of supervision and allows zero-shot transfer to
downstream tasks since visual concepts can be diametrically generated from
natural language, known as prompt. In this paper, we identify that a major
challenge of deploying such models in practice is prompt engineering. This is
because designing a proper prompt, especially for context words surrounding a
class name, requires domain expertise and typically takes a significant amount
of time for words tuning since a slight change in wording could have a huge
impact on performance. Moreover, different downstream tasks require specific
designs, further hampering the efficiency of deployment. To overcome this
challenge, we propose a novel approach named context optimization (CoOp). The
main idea is to model context in prompts using continuous representations and
perform end-to-end learning from data while keeping the pre-trained parameters
fixed. In this way, the design of task-relevant prompts can be fully automated.
Experiments on 11 datasets show that CoOp effectively turns pre-trained
vision-language models into data-efficient visual learners, requiring as few as
one or two shots to beat hand-crafted prompts with a decent margin and able to
gain significant improvements when using more shots (e.g., at 16 shots the
average gain is around 17% with the highest reaching over 50%). CoOp also
exhibits strong robustness to distribution shift.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable robotic systems: Understanding goal-driven actions in a reinforcement learning scenario. (arXiv:2006.13615v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.13615">
<div class="article-summary-box-inner">
<span><p>Robotic systems are more present in our society everyday. In human-robot
environments, it is crucial that end-users may correctly understand their
robotic team-partners, in order to collaboratively complete a task. To increase
action understanding, users demand more explainability about the decisions by
the robot in particular situations. Recently, explainable robotic systems have
emerged as an alternative focused not only on completing a task satisfactorily,
but also on justifying, in a human-like manner, the reasons that lead to making
a decision. In reinforcement learning scenarios, a great effort has been
focused on providing explanations using data-driven approaches, particularly
from the visual input modality in deep learning-based systems. In this work, we
focus rather on the decision-making process of reinforcement learning agents
performing a task in a robotic scenario. Experimental results are obtained
using 3 different set-ups, namely, a deterministic navigation task, a
stochastic navigation task, and a continuous visual-based sorting object task.
As a way to explain the goal-driven robot's actions, we use the probability of
success computed by three different proposed approaches: memory-based,
learning-based, and introspection-based. The difference between these
approaches is the amount of memory required to compute or estimate the
probability of success as well as the kind of reinforcement learning
representation where they could be used. In this regard, we use the
memory-based approach as a baseline since it is obtained directly from the
agent's observations. When comparing the learning-based and the
introspection-based approaches to this baseline, both are found to be suitable
alternatives to compute the probability of success, obtaining high levels of
similarity when compared using both the Pearson's correlation and the mean
squared error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GMH: A General Multi-hop Reasoning Model for KG Completion. (arXiv:2010.07620v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07620">
<div class="article-summary-box-inner">
<span><p>Knowledge graphs are essential for numerous downstream natural language
processing applications, but are typically incomplete with many facts missing.
This results in research efforts on multi-hop reasoning task, which can be
formulated as a search process and current models typically perform short
distance reasoning. However, the long-distance reasoning is also vital with the
ability to connect the superficially unrelated entities. To the best of our
knowledge, there lacks a general framework that approaches multi-hop reasoning
in mixed long-short distance reasoning scenarios. We argue that there are two
key issues for a general multi-hop reasoning model: i) where to go, and ii)
when to stop. Therefore, we propose a general model which resolves the issues
with three modules: 1) the local-global knowledge module to estimate the
possible paths, 2) the differentiated action dropout module to explore a
diverse set of paths, and 3) the adaptive stopping search module to avoid over
searching. The comprehensive results on three datasets demonstrate the
superiority of our model with significant improvements against baselines in
both short and long distance reasoning scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">USCL: Pretraining Deep Ultrasound Image Diagnosis Model through Video Contrastive Representation Learning. (arXiv:2011.13066v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13066">
<div class="article-summary-box-inner">
<span><p>Most deep neural networks (DNNs) based ultrasound (US) medical image analysis
models use pretrained backbones (e.g., ImageNet) for better model
generalization. However, the domain gap between natural and medical images
causes an inevitable performance bottleneck. To alleviate this problem, an US
dataset named US-4 is constructed for direct pretraining on the same domain. It
contains over 23,000 images from four US video sub-datasets. To learn robust
features from US-4, we propose an US semi-supervised contrastive learning
method, named USCL, for pretraining. In order to avoid high similarities
between negative pairs as well as mine abundant visual features from limited US
videos, USCL adopts a sample pair generation method to enrich the feature
involved in a single step of contrastive optimization. Extensive experiments on
several downstream tasks show the superiority of USCL pretraining against
ImageNet pretraining and other state-of-the-art (SOTA) pretraining approaches.
In particular, USCL pretrained backbone achieves fine-tuning accuracy of over
94% on POCUS dataset, which is 10% higher than 84% of the ImageNet pretrained
model. The source codes of this work are available at
https://github.<a href="/abs/com/9836328">com/9836328</a>47/USCL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factorizing Perception and Policy for Interactive Instruction Following. (arXiv:2012.03208v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03208">
<div class="article-summary-box-inner">
<span><p>Performing simple household tasks based on language directives is very
natural to humans, yet it remains an open challenge for AI agents. The
'interactive instruction following' task attempts to make progress towards
building agents that jointly navigate, interact, and reason in the environment
at every step. To address the multifaceted problem, we propose a model that
factorizes the task into interactive perception and action policy streams with
enhanced components and name it as MOCA, a Modular Object-Centric Approach. We
empirically validate that MOCA outperforms prior arts by significant margins on
the ALFRED benchmark with improved generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Real-World Adversarial Patches through 3D Modeling of Complex Target Scenes. (arXiv:2102.05334v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05334">
<div class="article-summary-box-inner">
<span><p>Adversarial examples have proven to be a concerning threat to deep learning
models, particularly in the image domain. However, while many studies have
examined adversarial examples in the real world, most of them relied on 2D
photos of the attack scene. As a result, the attacks proposed may have limited
effectiveness when implemented in realistic environments with 3D objects or
varied conditions. There are few studies on adversarial learning that use 3D
objects, and in many cases, other researchers are unable to replicate the
real-world evaluation process. In this study, we present a framework that uses
3D modeling to craft adversarial patches for an existing real-world scene. Our
approach uses a 3D digital approximation of the scene as a simulation of the
real world. With the ability to add and manipulate any element in the digital
scene, our framework enables the attacker to improve the adversarial patch's
impact in real-world settings. We use the framework to create a patch for an
everyday scene and evaluate its performance using a novel evaluation process
that ensures that our results are reproducible in both the digital space and
the real world. Our evaluation results show that the framework can generate
adversarial patches that are robust to different settings in the real world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Physical Reasoning Using Dynamics-Aware Models. (arXiv:2102.10336v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10336">
<div class="article-summary-box-inner">
<span><p>A common approach to solving physical reasoning tasks is to train a value
learner on example tasks. A limitation of such an approach is that it requires
learning about object dynamics solely from reward values assigned to the final
state of a rollout of the environment. This study aims to address this
limitation by augmenting the reward value with self-supervised signals about
object dynamics. Specifically, we train the model to characterize the
similarity of two environment rollouts, jointly with predicting the outcome of
the reasoning task. This similarity can be defined as a distance measure
between the trajectory of objects in the two rollouts, or learned directly from
pixels using a contrastive formulation. Empirically, we find that this approach
leads to substantial performance improvements on the PHYRE benchmark for
physical reasoning (Bakhtin et al., 2019), establishing a new state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CURE: Code-Aware Neural Machine Translation for Automatic Program Repair. (arXiv:2103.00073v4 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00073">
<div class="article-summary-box-inner">
<span><p>Automatic program repair (APR) is crucial to improve software reliability.
Recently, neural machine translation (NMT) techniques have been used to fix
software bugs automatically. While promising, these approaches have two major
limitations. Their search space often does not contain the correct fix, and
their search strategy ignores software knowledge such as strict code syntax.
Due to these limitations, existing NMT-based techniques underperform the best
template-based approaches.
</p>
<p>We propose CURE, a new NMT-based APR technique with three major novelties.
First, CURE pre-trains a programming language (PL) model on a large software
codebase to learn developer-like source code before the APR task. Second, CURE
designs a new code-aware search strategy that finds more correct fixes by
focusing on compilable patches and patches that are close in length to the
buggy code. Finally, CURE uses a subword tokenization technique to generate a
smaller search space that contains more correct fixes.
</p>
<p>Our evaluation on two widely-used benchmarks shows that CURE correctly fixes
57 Defects4J bugs and 26 QuixBugs bugs, outperforming all existing APR
techniques on both benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Data-Centric Framework for Composable NLP Workflows. (arXiv:2103.01834v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01834">
<div class="article-summary-box-inner">
<span><p>Empirical natural language processing (NLP) systems in application domains
(e.g., healthcare, finance, education) involve interoperation among multiple
components, ranging from data ingestion, human annotation, to text retrieval,
analysis, generation, and visualization. We establish a unified open-source
framework to support fast development of such sophisticated NLP workflows in a
composable manner. The framework introduces a uniform data representation to
encode heterogeneous results by a wide range of NLP tasks. It offers a large
repository of processors for NLP tasks, visualization, and annotation, which
can be easily assembled with full interoperability under the unified
representation. The highly extensible framework allows plugging in custom
processors from external off-the-shelf NLP and deep learning libraries. The
whole framework is delivered through two modularized yet integratable
open-source projects, namely Forte (for workflow infrastructure and NLP
function processors) and Stave (for user interaction, visualization, and
annotation).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">White Box Methods for Explanations of Convolutional Neural Networks in Image Classification Tasks. (arXiv:2104.02548v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02548">
<div class="article-summary-box-inner">
<span><p>In recent years, deep learning has become prevalent to solve applications
from multiple domains. Convolutional Neural Networks (CNNs) particularly have
demonstrated state of the art performance for the task of image classification.
However, the decisions made by these networks are not transparent and cannot be
directly interpreted by a human. Several approaches have been proposed to
explain to understand the reasoning behind a prediction made by a network. In
this paper, we propose a topology of grouping these methods based on their
assumptions and implementations. We focus primarily on white box methods that
leverage the information of the internal architecture of a network to explain
its decision. Given the task of image classification and a trained CNN, this
work aims to provide a comprehensive and detailed overview of a set of methods
that can be used to create explanation maps for a particular image, that assign
an importance score to each pixel of the image based on its contribution to the
decision of the network. We also propose a further classification of the white
box methods based on their implementations to enable better comparisons and
help researchers find methods best suited for different scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Autodidactic Universe. (arXiv:2104.03902v2 [hep-th] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03902">
<div class="article-summary-box-inner">
<span><p>We present an approach to cosmology in which the Universe learns its own
physical laws. It does so by exploring a landscape of possible laws, which we
express as a certain class of matrix models. We discover maps that put each of
these matrix models in correspondence with both a gauge/gravity theory and a
mathematical model of a learning machine, such as a deep recurrent, cyclic
neural network. This establishes a correspondence between each solution of the
physical theory and a run of a neural network. This correspondence is not an
equivalence, partly because gauge theories emerge from $N \rightarrow \infty $
limits of the matrix models, whereas the same limits of the neural networks
used here are not well-defined. We discuss in detail what it means to say that
learning takes place in autodidactic systems, where there is no supervision. We
propose that if the neural network model can be said to learn without
supervision, the same can be said for the corresponding physical theory. We
consider other protocols for autodidactic physical systems, such as
optimization of graph variety, subset-replication using self-attention and
look-ahead, geometrogenesis guided by reinforcement learning, structural
learning using renormalization group techniques, and extensions. These
protocols together provide a number of directions in which to explore the
origin of physical laws based on putting machine learning architectures in
correspondence with physical theories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing Commonsense Explanation in Dialogue Response Generation. (arXiv:2104.09574v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09574">
<div class="article-summary-box-inner">
<span><p>Humans use commonsense reasoning (CSR) implicitly to produce natural and
coherent responses in conversations. Aiming to close the gap between current
response generation (RG) models and human communication abilities, we want to
understand why RG models respond as they do by probing RG model's understanding
of commonsense reasoning that elicits proper responses. We formalize the
problem by framing commonsense as a latent variable in the RG task and using
explanations for responses as textual form of commonsense. We collect 6k
annotated explanations justifying responses from four dialogue datasets and ask
humans to verify them and propose two probing settings to evaluate RG models'
CSR capabilities. Probing results show that models fail to capture the logical
relations between commonsense explanations and responses and fine-tuning on
in-domain data and increasing model sizes do not lead to understanding of CSR
for RG. We hope our study motivates more research in making RG models emulate
the human reasoning process in pursuit of smooth human-AI communication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AMMU : A Survey of Transformer-based Biomedical Pretrained Language Models. (arXiv:2105.00827v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00827">
<div class="article-summary-box-inner">
<span><p>Transformer-based pretrained language models (PLMs) have started a new era in
modern natural language processing (NLP). These models combine the power of
transformers, transfer learning, and self-supervised learning (SSL). Following
the success of these models in the general domain, the biomedical research
community has developed various in-domain PLMs starting from BioBERT to the
latest BioELECTRA and BioALBERT models. We strongly believe there is a need for
a survey paper that can provide a comprehensive survey of various
transformer-based biomedical pretrained language models (BPLMs). In this
survey, we start with a brief overview of foundational concepts like
self-supervised learning, embedding layer and transformer encoder layers. We
discuss core concepts of transformer-based PLMs like pretraining methods,
pretraining tasks, fine-tuning methods, and various embedding types specific to
biomedical domain. We introduce a taxonomy for transformer-based BPLMs and then
discuss all the models. We discuss various challenges and present possible
solutions. We conclude by highlighting some of the open issues which will drive
the research community to further improve transformer-based BPLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Software Engineering for AI-Based Systems: A Survey. (arXiv:2105.01984v2 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01984">
<div class="article-summary-box-inner">
<span><p>AI-based systems are software systems with functionalities enabled by at
least one AI component (e.g., for image- and speech-recognition, and autonomous
driving). AI-based systems are becoming pervasive in society due to advances in
AI. However, there is limited synthesized knowledge on Software Engineering
(SE) approaches for building, operating, and maintaining AI-based systems. To
collect and analyze state-of-the-art knowledge about SE for AI-based systems,
we conducted a systematic mapping study. We considered 248 studies published
between January 2010 and March 2020. SE for AI-based systems is an emerging
research area, where more than 2/3 of the studies have been published since
2018. The most studied properties of AI-based systems are dependability and
safety. We identified multiple SE approaches for AI-based systems, which we
classified according to the SWEBOK areas. Studies related to software testing
and software quality are very prevalent, while areas like software maintenance
seem neglected. Data-related issues are the most recurrent challenges. Our
results are valuable for: researchers, to quickly understand the state of the
art and learn which topics need more research; practitioners, to learn about
the approaches and challenges that SE entails for AI-based systems; and,
educators, to bridge the gap among SE and AI in their curricula.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmenter: Transformer for Semantic Segmentation. (arXiv:2105.05633v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05633">
<div class="article-summary-box-inner">
<span><p>Image segmentation is often ambiguous at the level of individual image
patches and requires contextual information to reach label consensus. In this
paper we introduce Segmenter, a transformer model for semantic segmentation. In
contrast to convolution-based methods, our approach allows to model global
context already at the first layer and throughout the network. We build on the
recent Vision Transformer (ViT) and extend it to semantic segmentation. To do
so, we rely on the output embeddings corresponding to image patches and obtain
class labels from these embeddings with a point-wise linear decoder or a mask
transformer decoder. We leverage models pre-trained for image classification
and show that we can fine-tune them on moderate sized datasets available for
semantic segmentation. The linear decoder allows to obtain excellent results
already, but the performance can be further improved by a mask transformer
generating class masks. We conduct an extensive ablation study to show the
impact of the different parameters, in particular the performance is better for
large models and small patch sizes. Segmenter attains excellent results for
semantic segmentation. It outperforms the state of the art on both ADE20K and
Pascal Context datasets and is competitive on Cityscapes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding peacefulness through the world news. (arXiv:2106.00306v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00306">
<div class="article-summary-box-inner">
<span><p>Peacefulness is a principal dimension of well-being for all humankind and is
the way out of inequity and every single form of violence. Thus, its
measurement has lately drawn the attention of researchers and policy-makers.
During the last years, novel digital data streams have drastically changed the
research in this field. In the current study, we exploit information extracted
from Global Data on Events, Location, and Tone (GDELT) digital news database,
to capture peacefulness through the Global Peace Index (GPI). Applying
predictive machine learning models, we demonstrate that news media attention
from GDELT can be used as a proxy for measuring GPI at a monthly level.
Additionally, we use the SHAP methodology to obtain the most important
variables that drive the predictions. This analysis highlights each country's
profile and provides explanations for the predictions overall, and particularly
for the errors and the events that drive these errors. We believe that digital
data exploited by Social Good researchers, policy-makers, and peace-builders,
with data science tools as powerful as machine learning, could contribute to
maximize the societal benefits and minimize the risks to peacefulness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PonderNet: Learning to Ponder. (arXiv:2107.05407v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05407">
<div class="article-summary-box-inner">
<span><p>In standard neural networks the amount of computation used grows with the
size of the inputs, but not with the complexity of the problem being learnt. To
overcome this limitation we introduce PonderNet, a new algorithm that learns to
adapt the amount of computation based on the complexity of the problem at hand.
PonderNet learns end-to-end the number of computational steps to achieve an
effective compromise between training prediction accuracy, computational cost
and generalization. On a complex synthetic problem, PonderNet dramatically
improves performance over previous adaptive computation methods and
additionally succeeds at extrapolation tests where traditional neural networks
fail. Also, our method matched the current state of the art results on a real
world question and answering dataset, but using less compute. Finally,
PonderNet reached state of the art results on a complex task designed to test
the reasoning capabilities of neural networks.1
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Answer-Set Programs for Reasoning about Counterfactual Interventions and Responsibility Scores for Classification. (arXiv:2107.10159v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10159">
<div class="article-summary-box-inner">
<span><p>We describe how answer-set programs can be used to declaratively specify
counterfactual interventions on entities under classification, and reason about
them. In particular, they can be used to define and compute responsibility
scores as attribution-based explanations for outcomes from classification
models. The approach allows for the inclusion of domain knowledge and supports
query answering. A detailed example with a naive-Bayes classifier is presented.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leaf Recognition Using Convolutional Neural Networks Based Features. (arXiv:2108.01808v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01808">
<div class="article-summary-box-inner">
<span><p>There is a warning light for the loss of plant habitats worldwide that
entails concerted efforts to conserve plant biodiversity. Thus, plant species
classification is of crucial importance to address this environmental
challenge. In recent years, there is a considerable increase in the number of
studies related to plant taxonomy. While some researchers try to improve their
recognition performance using novel approaches, others concentrate on
computational optimization for their framework. In addition, a few studies are
diving into feature extraction to gain significantly in terms of accuracy. In
this paper, we propose an effective method for the leaf recognition problem. In
our proposed approach, a leaf goes through some pre-processing to extract its
refined color image, vein image, xy-projection histogram, handcrafted shape,
texture features, and Fourier descriptors. These attributes are then
transformed into a better representation by neural network-based encoders
before a support vector machine (SVM) model is utilized to classify different
leaves. Overall, our approach performs a state-of-the-art result on the Flavia
leaf dataset, achieving the accuracy of 99.58\% on test sets under random
10-fold cross-validation and bypassing the previous methods. We also release
our codes (Scripts are available at
https://github.com/dinhvietcuong1996/LeafRecognition) for contributing to the
research community in the leaf classification problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Imperceptible Adversarial Examples by Spatial Chroma-Shift. (arXiv:2108.02502v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02502">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks have been shown to be vulnerable to various kinds of
adversarial perturbations. In addition to widely studied additive noise based
perturbations, adversarial examples can also be created by applying a per pixel
spatial drift on input images. While spatial transformation based adversarial
examples look more natural to human observers due to absence of additive noise,
they still possess visible distortions caused by spatial transformations. Since
the human vision is more sensitive to the distortions in the luminance compared
to those in chrominance channels, which is one of the main ideas behind the
lossy visual multimedia compression standards, we propose a spatial
transformation based perturbation method to create adversarial examples by only
modifying the color components of an input image. While having competitive
fooling rates on CIFAR-10 and NIPS2017 Adversarial Learning Challenge datasets,
examples created with the proposed method have better scores with regards to
various perceptual quality metrics. Human visual perception studies validate
that the examples are more natural looking and often indistinguishable from
their original counterparts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Chatbot Per Person: Creating Personalized Chatbots based on Implicit User Profiles. (arXiv:2108.09355v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09355">
<div class="article-summary-box-inner">
<span><p>Personalized chatbots focus on endowing chatbots with a consistent
personality to behave like real users, give more informative responses, and
further act as personal assistants. Existing personalized approaches tried to
incorporate several text descriptions as explicit user profiles. However, the
acquisition of such explicit profiles is expensive and time-consuming, thus
being impractical for large-scale real-world applications. Moreover, the
restricted predefined profile neglects the language behavior of a real user and
cannot be automatically updated together with the change of user interests. In
this paper, we propose to learn implicit user profiles automatically from
large-scale user dialogue history for building personalized chatbots.
Specifically, leveraging the benefits of Transformer on language understanding,
we train a personalized language model to construct a general user profile from
the user's historical responses. To highlight the relevant historical responses
to the input post, we further establish a key-value memory network of
historical post-response pairs, and build a dynamic post-aware user profile.
The dynamic profile mainly describes what and how the user has responded to
similar posts in history. To explicitly utilize users' frequently used words,
we design a personalized decoder to fuse two decoding strategies, including
generating a word from the generic vocabulary and copying one word from the
user's personalized vocabulary. Experiments on two real-world datasets show the
significant improvement of our model compared with existing methods. Our code
is available at https://github.com/zhengyima/DHAP
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Accuracy of Permutation DAG Search using Best Order Score Search. (arXiv:2108.10141v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10141">
<div class="article-summary-box-inner">
<span><p>The Sparsest Permutation (SP) algorithm is accurate but limited to about 9
variables in practice; the Greedy Sparest Permutation (GSP) algorithm is faster
but less weak theoretically. A compromise can be given, the Best Order Score
Search, which gives results as accurate as SP but for much larger and denser
graphs. BOSS (Best Order Score Search) is more accurate for two reason: (a) It
assumes the "brute faithfuness" assumption, which is weaker than faithfulness,
and (b) it uses a different traversal of permutations than the depth first
traversal used by GSP, obtained by taking each variable in turn and moving it
to the position in the permutation that optimizes the model score. Results are
given comparing BOSS to several related papers in the literature in terms of
performance, for linear, Gaussian data. In all cases, with the proper parameter
settings, accuracy of BOSS is lifted considerably with respect to competing
approaches. In configurations tested, models with 60 variables are feasible
with large samples out to about an average degree of 12 in reasonable time,
with near-perfect accuracy, and sparse models with an average degree of 4 are
feasible out to about 300 variables on a laptop, again with near-perfect
accuracy. Mixed continuous discrete and all-discrete datasets were also tested.
The mixed data analysis showed advantage for BOSS over GES more apparent at
higher depths with the same score; the discrete data analysis showed a very
small advantage for BOSS over GES with the same score, perhaps not enough to
prefer it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smoothing Dialogue States for Open Conversational Machine Reading. (arXiv:2108.12599v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12599">
<div class="article-summary-box-inner">
<span><p>Conversational machine reading (CMR) requires machines to communicate with
humans through multi-turn interactions between two salient dialogue states of
decision making and question generation processes. In open CMR settings, as the
more realistic scenario, the retrieved background knowledge would be noisy,
which results in severe challenges in the information transmission. Existing
studies commonly train independent or pipeline systems for the two subtasks.
However, those methods are trivial by using hard-label decisions to activate
question generation, which eventually hinders the model performance. In this
work, we propose an effective gating strategy by smoothing the two dialogue
states in only one decoder and bridge decision making and question generation
to provide a richer dialogue state reference. Experiments on the OR-ShARC
dataset show the effectiveness of our method, which achieves new
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Proceedings of KDD 2021 Workshop on Data-driven Humanitarian Mapping: Harnessing Human-Machine Intelligence for High-Stake Public Policy and Resilience Planning. (arXiv:2109.00100v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00100">
<div class="article-summary-box-inner">
<span><p>Humanitarian challenges, including natural disasters, food insecurity,
climate change, racial and gender violence, environmental crises, the COVID-19
coronavirus pandemic, human rights violations, and forced displacements,
disproportionately impact vulnerable communities worldwide. According to UN
OCHA, 235 million people will require humanitarian assistance in 20211 .
Despite these growing perils, there remains a notable paucity of data science
research to scientifically inform equitable public policy decisions for
improving the livelihood of at-risk populations. Scattered data science efforts
exist to address these challenges, but they remain isolated from practice and
prone to algorithmic harms concerning lack of privacy, fairness,
interpretability, accountability, transparency, and ethics. Biases in
data-driven methods carry the risk of amplifying inequalities in high-stakes
policy decisions that impact the livelihood of millions of people.
Consequently, proclaimed benefits of data-driven innovations remain
inaccessible to policymakers, practitioners, and marginalized communities at
the core of humanitarian actions and global development. To help fill this gap,
we propose the Data-driven Humanitarian Mapping Research Program, which focuses
on developing novel data science methodologies that harness human-machine
intelligence for high-stakes public policy and resilience planning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Exploration Methods in Reinforcement Learning. (arXiv:2109.00157v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00157">
<div class="article-summary-box-inner">
<span><p>Exploration is an essential component of reinforcement learning algorithms,
where agents need to learn how to predict and control unknown and often
stochastic environments. Reinforcement learning agents depend crucially on
exploration to obtain informative data for the learning process as the lack of
enough information could hinder effective learning. In this article, we provide
a survey of modern exploration methods in (Sequential) reinforcement learning,
as well as a taxonomy of exploration methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Proceedings of KDD 2020 Workshop on Data-driven Humanitarian Mapping: Harnessing Human-Machine Intelligence for High-Stake Public Policy and Resilience Planning. (arXiv:2109.00435v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00435">
<div class="article-summary-box-inner">
<span><p>Humanitarian challenges, including natural disasters, food insecurity,
climate change, racial and gender violence, environmental crises, the COVID-19
coronavirus pandemic, human rights violations, and forced displacements,
disproportionately impact vulnerable communities worldwide. According to UN
OCHA, 235 million people will require humanitarian assistance in 20211 .
Despite these growing perils, there remains a notable paucity of data science
research to scientifically inform equitable public policy decisions for
improving the livelihood of at-risk populations. Scattered data science efforts
exist to address these challenges, but they remain isolated from practice and
prone to algorithmic harms concerning lack of privacy, fairness,
interpretability, accountability, transparency, and ethics. Biases in
data-driven methods carry the risk of amplifying inequalities in high-stakes
policy decisions that impact the livelihood of millions of people.
Consequently, proclaimed benefits of data-driven innovations remain
inaccessible to policymakers, practitioners, and marginalized communities at
the core of humanitarian actions and global development. To help fill this gap,
we propose the Data-driven Humanitarian Mapping Research Program, which focuses
on developing novel data science methodologies that harness human-machine
intelligence for high-stakes public policy and resilience planning.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't Discard All the Biased Instances: Investigating a Core Assumption in Dataset Bias Mitigation Techniques. (arXiv:2109.00521v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00521">
<div class="article-summary-box-inner">
<span><p>Existing techniques for mitigating dataset bias often leverage a biased model
to identify biased instances. The role of these biased instances is then
reduced during the training of the main model to enhance its robustness to
out-of-distribution data. A common core assumption of these techniques is that
the main model handles biased instances similarly to the biased model, in that
it will resort to biases whenever available. In this paper, we show that this
assumption does not hold in general. We carry out a critical investigation on
two well-known datasets in the domain, MNLI and FEVER, along with two biased
instance detection methods, partial-input and limited-capacity models. Our
experiments show that in around a third to a half of instances, the biased
model is unable to predict the main model's behavior, highlighted by the
significantly different parts of the input on which they base their decisions.
Based on a manual validation, we also show that this estimate is highly in line
with human interpretation. Our findings suggest that down-weighting of
instances detected by bias detection methods, which is a widely-practiced
procedure, is an unnecessary waste of training data. We release our code to
facilitate reproducibility and future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text AutoAugment: Learning Compositional Augmentation Policy for Text Classification. (arXiv:2109.00523v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00523">
<div class="article-summary-box-inner">
<span><p>Data augmentation aims to enrich training samples for alleviating the
overfitting issue in low-resource or class-imbalanced situations. Traditional
methods first devise task-specific operations such as Synonym Substitute, then
preset the corresponding parameters such as the substitution rate artificially,
which require a lot of prior knowledge and are prone to fall into the
sub-optimum. Besides, the number of editing operations is limited in the
previous methods, which decreases the diversity of the augmented data and thus
restricts the performance gain. To overcome the above limitations, we propose a
framework named Text AutoAugment (TAA) to establish a compositional and
learnable paradigm for data augmentation. We regard a combination of various
operations as an augmentation policy and utilize an efficient Bayesian
Optimization algorithm to automatically search for the best policy, which
substantially improves the generalization capability of models. Experiments on
six benchmark datasets show that TAA boosts classification accuracy in
low-resource and class-imbalanced regimes by an average of 8.8% and 9.7%,
respectively, outperforming strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Search Engines with Interactive Agents. (arXiv:2109.00527v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00527">
<div class="article-summary-box-inner">
<span><p>Can machines learn to use a search engine as an interactive tool for finding
information? That would have far reaching consequences for making the world's
knowledge more accessible. This paper presents first steps in designing agents
that learn meta-strategies for contextual query refinements. Our approach uses
machine reading to guide the selection of refinement terms from aggregated
search results. Agents are then empowered with simple but effective search
operators to exert fine-grained and transparent control over queries and search
results. We develop a novel way of generating synthetic search sessions, which
leverages the power of transformer-based generative language models through
(self-)supervised learning. We also present a reinforcement learning agent with
dynamically constrained actions that can learn interactive search strategies
completely from scratch. In both cases, we obtain significant improvements over
one-shot search with a strong information retrieval baseline. Finally, we
provide an in-depth analysis of the learned search policies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Improving Adversarial Training of NLP Models. (arXiv:2109.00544v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00544">
<div class="article-summary-box-inner">
<span><p>Adversarial training, a method for learning robust deep neural networks,
constructs adversarial examples during training. However, recent methods for
generating NLP adversarial examples involve combinatorial search and expensive
sentence encoders for constraining the generated instances. As a result, it
remains challenging to use vanilla adversarial training to improve NLP models'
performance, and the benefits are mainly uninvestigated. This paper proposes a
simple and improved vanilla adversarial training process for NLP, which we name
Attacking to Training ($\texttt{A2T}$). The core part of $\texttt{A2T}$ is a
new and cheaper word substitution attack optimized for vanilla adversarial
training. We use $\texttt{A2T}$ to train BERT and RoBERTa models on IMDB,
Rotten Tomatoes, Yelp, and SNLI datasets. Our results show that it is possible
to train empirically robust NLP models using a much cheaper adversary. We
demonstrate that vanilla adversarial training with $\texttt{A2T}$ can improve
an NLP model's robustness to the attack it was originally trained with and also
defend the model against other types of attacks. Furthermore, we show that
$\texttt{A2T}$ can improve NLP models' standard accuracy, cross-domain
generalization, and interpretability. Code is available at
<a href="http://github.com/jinyongyoo/A2T">this http URL</a> .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Knowledge Help General NLU? An Empirical Study. (arXiv:2109.00563v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00563">
<div class="article-summary-box-inner">
<span><p>It is often observed in knowledge-centric tasks (e.g., common sense question
and answering, relation classification) that the integration of external
knowledge such as entity representation into language models can help provide
useful information to boost the performance. However, it is still unclear
whether this benefit can extend to general natural language understanding (NLU)
tasks. In this work, we empirically investigated the contribution of external
knowledge by measuring the end-to-end performance of language models with
various knowledge integration methods. We find that the introduction of
knowledge can significantly improve the results on certain tasks while having
no adverse effects on other tasks. We then employ mutual information to reflect
the difference brought by knowledge and a neural interpretation model to reveal
how a language model utilizes external knowledge. Our study provides valuable
insights and guidance for practitioners to equip NLP models with knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DILBERT: Customized Pre-Training for Domain Adaptation withCategory Shift, with an Application to Aspect Extraction. (arXiv:2109.00571v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00571">
<div class="article-summary-box-inner">
<span><p>The rise of pre-trained language models has yielded substantial progress in
the vast majority of Natural Language Processing (NLP) tasks. However, a
generic approach towards the pre-training procedure can naturally be
sub-optimal in some cases. Particularly, fine-tuning a pre-trained language
model on a source domain and then applying it to a different target domain,
results in a sharp performance decline of the eventual classifier for many
source-target domain pairs. Moreover, in some NLP tasks, the output categories
substantially differ between domains, making adaptation even more challenging.
This, for example, happens in the task of aspect extraction, where the aspects
of interest of reviews of, e.g., restaurants or electronic devices may be very
different. This paper presents a new fine-tuning scheme for BERT, which aims to
address the above challenges. We name this scheme DILBERT: Domain Invariant
Learning with BERT, and customize it for aspect extraction in the unsupervised
domain adaptation setting. DILBERT harnesses the categorical information of
both the source and the target domains to guide the pre-training process
towards a more domain and category invariant representation, thus closing the
gap between the domains. We show that DILBERT yields substantial improvements
over state-of-the-art baselines while using a fraction of the unlabeled data,
particularly in more challenging domain adaptation setups.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebQA: Multihop and Multimodal QA. (arXiv:2109.00590v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00590">
<div class="article-summary-box-inner">
<span><p>Web search is fundamentally multimodal and multihop. Often, even before
asking a question we choose to go directly to image search to find our answers.
Further, rarely do we find an answer from a single source but aggregate
information and reason through implications. Despite the frequency of this
everyday occurrence, at present, there is no unified question answering
benchmark that requires a single model to answer long-form natural language
questions from text and open-ended visual sources -- akin to a human's
experience. We propose to bridge this gap between the natural language and
computer vision communities with WebQA. We show that A. our multihop text
queries are difficult for a large-scale transformer model, and B. existing
multi-modal transformers and visual representations do not perform well on
open-domain visual queries. Our challenge for the community is to create a
unified multimodal reasoning model that seamlessly transitions and reasons
regardless of the source modality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fight Fire with Fire: Fine-tuning Hate Detectors using Large Samples of Generated Hate Speech. (arXiv:2109.00591v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00591">
<div class="article-summary-box-inner">
<span><p>Automatic hate speech detection is hampered by the scarcity of labeled
datasetd, leading to poor generalization. We employ pretrained language models
(LMs) to alleviate this data bottleneck. We utilize the GPT LM for generating
large amounts of synthetic hate speech sequences from available labeled
examples, and leverage the generated data in fine-tuning large pretrained LMs
on hate detection. An empirical study using the models of BERT, RoBERTa and
ALBERT, shows that this approach improves generalization significantly and
consistently within and across data distributions. In fact, we find that
generating relevant labeled hate speech sequences is preferable to using
out-of-domain, and sometimes also within-domain, human-labeled examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Latin writing styles analysis with Machine Learning: New approach to old questions. (arXiv:2109.00601v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00601">
<div class="article-summary-box-inner">
<span><p>In the Middle Ages texts were learned by heart and spread using oral means of
communication from generation to generation. Adaptation of the art of prose and
poems allowed keeping particular descriptions and compositions characteristic
for many literary genres. Taking into account such a specific construction of
literature composed in Latin, we can search for and indicate the probability
patterns of familiar sources of specific narrative texts. Consideration of
Natural Language Processing tools allowed us the transformation of textual
objects into numerical ones and then application of machine learning algorithms
to extract information from the dataset. We carried out the task consisting of
the practical use of those concepts and observation to create a tool for
analyzing narrative texts basing on open-source databases. The tool focused on
creating specific search tools resources which could enable us detailed
searching throughout the text. The main objectives of the study take into
account finding similarities between sentences and between documents. Next, we
applied machine learning algorithms on chosen texts to calculate specific
features of them (for instance authorship or centuries) and to recognize
sources of anonymous texts with a certain percentage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point-of-Interest Type Prediction using Text and Images. (arXiv:2109.00602v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00602">
<div class="article-summary-box-inner">
<span><p>Point-of-interest (POI) type prediction is the task of inferring the type of
a place from where a social media post was shared. Inferring a POI's type is
useful for studies in computational social science including sociolinguistics,
geosemiotics, and cultural geography, and has applications in geosocial
networking technologies such as recommendation and visualization systems. Prior
efforts in POI type prediction focus solely on text, without taking visual
information into account. However in reality, the variety of modalities, as
well as their semiotic relationships with one another, shape communication and
interactions in social media. This paper presents a study on POI type
prediction using multimodal information from text and images available at
posting time. For that purpose, we enrich a currently available data set for
POI type prediction with the images that accompany the text messages. Our
proposed method extracts relevant information from each modality to effectively
capture interactions between text and image achieving a macro F1 of 47.21
across eight categories significantly outperforming the state-of-the-art method
for POI type prediction based on text-only methods. Finally, we provide a
detailed analysis to shed light on cross-modal interactions and the limitations
of our best performing model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An unsupervised framework for tracing textual sources of moral change. (arXiv:2109.00608v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00608">
<div class="article-summary-box-inner">
<span><p>Morality plays an important role in social well-being, but people's moral
perception is not stable and changes over time. Recent advances in natural
language processing have shown that text is an effective medium for informing
moral change, but no attempt has been made to quantify the origins of these
changes. We present a novel unsupervised framework for tracing textual sources
of moral change toward entities through time. We characterize moral change with
probabilistic topical distributions and infer the source text that exerts
prominent influence on the moral time course. We evaluate our framework on a
diverse set of data ranging from social media to news articles. We show that
our framework not only captures fine-grained human moral judgments, but also
identifies coherent source topics of moral change triggered by historical
events. We apply our methodology to analyze the news in the COVID-19 pandemic
and demonstrate its utility in identifying sources of moral change in
high-impact and real-time social events.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Algorithme de recherche approximative dans un dictionnaire fond\'e sur une distance d'\'edition d\'efinie par blocs. (arXiv:2109.00624v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00624">
<div class="article-summary-box-inner">
<span><p>We propose an algorithm for approximative dictionary lookup, where altered
strings are matched against reference forms. The algorithm makes use of a
divergence function between strings -- broadly belonging to the family of edit
distances; it finds dictionary entries whose distance to the search string is
below a certain threshold. The divergence function is not the classical edit
distance (DL distance); it is adaptable to a particular corpus, and is based on
elementary alteration costs defined on character blocks, rather than on
individual characters.
</p>
<p>Nous proposons un algorithme de recherche approximative de cha\^ines dans un
dictionnaire \`a partir de formes alt\'er\'ees. Cet algorithme est fond\'e sur
une fonction de divergence entre cha\^ines~ -- une sorte de distance
d'\'edition: il recherche des entr\'ees pour lesquelles la distance \`a la
cha\^ine cherch\'ee est inf\'erieure \`a un certain seuil. La fonction
utilis\'ee n'est pas la distance d'\'edition classique (distance DL); elle est
adapt\'ee \`a un corpus, et se fonde sur la prise en compte de co\^uts
d'alt\'eration \'el\'ementaires d\'efinis non pas sur des caract\`eres, mais
sur des sous-cha\^ines (des blocs de caract\`eres).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tree-constrained Pointer Generator for End-to-end Contextual Speech Recognition. (arXiv:2109.00627v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00627">
<div class="article-summary-box-inner">
<span><p>Contextual knowledge is important for real-world automatic speech recognition
(ASR) applications. In this paper, a novel tree-constrained pointer generator
(TCPGen) component is proposed that incorporates such knowledge as a list of
biasing words into both attention-based encoder-decoder and transducer
end-to-end ASR models in a neural-symbolic way. TCPGen structures the biasing
words into an efficient prefix tree to serve as its symbolic input and creates
a neural shortcut between the tree and the final ASR output distribution to
facilitate recognising biasing words during decoding. Systems were trained and
evaluated on the Librispeech corpus where biasing words were extracted at the
scales of an utterance, a chapter, or a book to simulate different application
scenarios. Experimental results showed that TCPGen consistently improved word
error rates (WERs) compared to the baselines, and in particular, achieved
significant WER reductions on the biasing words. TCPGen is highly efficient: it
can handle 5,000 biasing words and distractors and only add a small overhead to
memory use and computation cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Ensemble Approach for Annotating Source Code Identifiers with Part-of-speech Tags. (arXiv:2109.00629v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00629">
<div class="article-summary-box-inner">
<span><p>This paper presents an ensemble part-of-speech tagging approach for source
code identifiers. Ensemble tagging is a technique that uses machine-learning
and the output from multiple part-of-speech taggers to annotate natural
language text at a higher quality than the part-of-speech taggers are able to
obtain independently. Our ensemble uses three state-of-the-art part-of-speech
taggers: SWUM, POSSE, and Stanford. We study the quality of the ensemble's
annotations on five different types of identifier names: function, class,
attribute, parameter, and declaration statement at the level of both individual
words and full identifier names. We also study and discuss the weaknesses of
our tagger to promote the future amelioration of these problems through further
research. Our results show that the ensemble achieves 75\% accuracy at the
identifier level and 84-86\% accuracy at the word level. This is an increase of
+17\% points at the identifier level from the closest independent
part-of-speech tagger.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The VoicePrivacy 2020 Challenge: Results and findings. (arXiv:2109.00648v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00648">
<div class="article-summary-box-inner">
<span><p>This paper presents the results and analyses stemming from the first
VoicePrivacy 2020 Challenge which focuses on developing anonymization solutions
for speech technology. We provide a systematic overview of the challenge design
with an analysis of submitted systems and evaluation results. In particular, we
describe the voice anonymization task and datasets used for system development
and evaluation. Also, we present different attack models and the associated
objective and subjective evaluation metrics. We introduce two anonymization
baselines and provide a summary description of the anonymization systems
developed by the challenge participants. We report objective and subjective
evaluation results for baseline and submitted systems. In addition, we present
experimental results for alternative privacy metrics and attack models
developed as a part of the post-evaluation analysis. Finally, we summarize our
insights and observations that will influence the design of the next
VoicePrivacy challenge edition and some directions for future voice
anonymization research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Making the Most of Dialogue Characteristics for Neural Chat Translation. (arXiv:2109.00668v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00668">
<div class="article-summary-box-inner">
<span><p>Neural Chat Translation (NCT) aims to translate conversational text between
speakers of different languages. Despite the promising performance of
sentence-level and context-aware neural machine translation models, there still
remain limitations in current NCT models because the inherent dialogue
characteristics of chat, such as dialogue coherence and speaker personality,
are neglected. In this paper, we propose to promote the chat translation by
introducing the modeling of dialogue characteristics into the NCT model. To
this end, we design four auxiliary tasks including monolingual response
generation, cross-lingual response generation, next utterance discrimination,
and speaker identification. Together with the main chat translation task, we
optimize the NCT model through the training objectives of all these tasks. By
this means, the NCT model can be enhanced by capturing the inherent dialogue
characteristics, thus generating more coherent and speaker-relevant
translations. Comprehensive experiments on four language directions
(English-German and English-Chinese) verify the effectiveness and superiority
of the proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Exploration in Quality Filtering of Text Data. (arXiv:2109.00698v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00698">
<div class="article-summary-box-inner">
<span><p>While conventional wisdom suggests that more aggressively filtering data from
low-quality sources like Common Crawl always monotonically improves the quality
of training data, we find that aggressive filtering can in fact lead to a
decrease in model quality on a wide array of downstream tasks for a GPT-like
language model. We speculate that this is because optimizing sufficiently
strongly for a proxy metric harms performance on the true objective, suggesting
a need for more robust filtering objectives when attempting to filter more
aggressively. We hope this work leads to detailed analysis of the effects of
dataset filtering design choices on downstream model performance in future
work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ShopTalk: A System for Conversational Faceted Search. (arXiv:2109.00702v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00702">
<div class="article-summary-box-inner">
<span><p>We present ShopTalk, a multi-turn conversational faceted search system for
shopping that is designed to handle large and complex schemas that are beyond
the scope of state of the art slot-filling systems. ShopTalk decouples dialog
management from fulfillment, thereby allowing the dialog understanding system
to be domain-agnostic and not tied to the particular shopping application. The
dialog understanding system consists of a deep-learned Contextual Language
Understanding module, which interprets user utterances, and a primarily
rules-based Dialog-State Tracker (DST), which updates the dialog state and
formulates search requests intended for the fulfillment engine. The interface
between the two modules consists of a minimal set of domain-agnostic "intent
operators," which instruct the DST on how to update the dialog state. ShopTalk
was deployed in 2020 on the Google Assistant for Shopping searches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LightNER: A Lightweight Generative Framework with Prompt-guided Attention for Low-resource NER. (arXiv:2109.00720v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00720">
<div class="article-summary-box-inner">
<span><p>NER in low-resource languages or domains suffers from inadequate training
data. Existing transfer learning approaches for low-resource NER usually have
the challenge that the target domain has different label sets compared with a
resource-rich source domain, which can be concluded as class transfer and
domain transfer problems. In this paper, we propose a lightweight generative
framework with prompt-guided attention for low-resource NER (LightNER) to
address these issues. Concretely, instead of tackling the problem by training
label-specific discriminative classifiers, we convert sequence labeling to
generate the entity pointer index sequence and entity categories without any
label-specific classifiers, which can address the class transfer issue. We
further propose prompt-guided attention by incorporating continuous prompts
into the self-attention layer to re-modulate the attention and adapt
pre-trained weights. Note that we only tune those continuous prompts with the
whole parameter of the pre-trained language model fixed, thus, making our
approach lightweight and flexible for low-resource scenarios and can better
transfer knowledge across domains. Experimental results show that by tuning
only 0.16% of the parameters, LightNER can obtain comparable performance in the
standard setting and outperform standard sequence labeling and prototype-based
methods in low-resource settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond. (arXiv:2109.00725v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00725">
<div class="article-summary-box-inner">
<span><p>A fundamental goal of scientific research is to learn about causal
relationships. However, despite its critical role in the life and social
sciences, causality has not had the same importance in Natural Language
Processing (NLP), which has traditionally placed more emphasis on predictive
tasks. This distinction is beginning to fade, with an emerging area of
interdisciplinary research at the convergence of causal inference and language
processing. Still, research on causality in NLP remains scattered across
domains without unified definitions, benchmark datasets and clear articulations
of the remaining challenges. In this survey, we consolidate research across
academic areas and situate it in the broader NLP landscape. We introduce the
statistical challenge of estimating causal effects, encompassing settings where
text is used as an outcome, treatment, or as a means to address confounding. In
addition, we explore potential uses of causal inference to improve the
performance, robustness, fairness, and interpretability of NLP models. We thus
provide a unified overview of causal inference for the computational
linguistics community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConQX: Semantic Expansion of Spoken Queries for Intent Detection based on Conditioned Text Generation. (arXiv:2109.00729v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00729">
<div class="article-summary-box-inner">
<span><p>Intent detection of spoken queries is a challenging task due to their noisy
structure and short length. To provide additional information regarding the
query and enhance the performance of intent detection, we propose a method for
semantic expansion of spoken queries, called ConQX, which utilizes the text
generation ability of an auto-regressive language model, GPT-2. To avoid
off-topic text generation, we condition the input query to a structured context
with prompt mining. We then apply zero-shot, one-shot, and few-shot learning.
We lastly use the expanded queries to fine-tune BERT and RoBERTa for intent
detection. The experimental results show that the performance of intent
detection can be improved by our semantic expansion method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural News Recommendation with Collaborative News Encoding and Structural User Encoding. (arXiv:2109.00750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00750">
<div class="article-summary-box-inner">
<span><p>Automatic news recommendation has gained much attention from the academic
community and industry. Recent studies reveal that the key to this task lies
within the effective representation learning of both news and users. Existing
works typically encode news title and content separately while neglecting their
semantic interaction, which is inadequate for news text comprehension. Besides,
previous models encode user browsing history without leveraging the structural
correlation of user browsed news to reflect user interests explicitly. In this
work, we propose a news recommendation framework consisting of collaborative
news encoding (CNE) and structural user encoding (SUE) to enhance news and user
representation learning. CNE equipped with bidirectional LSTMs encodes news
title and content collaboratively with cross-selection and cross-attention
modules to learn semantic-interactive news representations. SUE utilizes graph
convolutional networks to extract cluster-structural features of user history,
followed by intra-cluster and inter-cluster attention modules to learn
hierarchical user interest representations. Experiment results on the MIND
dataset validate the effectiveness of our model to improve the performance of
news recommendation. Our code is released at
https://github.com/Veason-silverbullet/NNR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MWPToolkit: An Open-Source Framework for Deep Learning-Based Math Word Problem Solvers. (arXiv:2109.00799v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00799">
<div class="article-summary-box-inner">
<span><p>Developing automatic Math Word Problem (MWP) solvers has been an interest of
NLP researchers since the 1960s. Over the last few years, there are a growing
number of datasets and deep learning-based methods proposed for effectively
solving MWPs. However, most existing methods are benchmarked soly on one or two
datasets, varying in different configurations, which leads to a lack of
unified, standardized, fair, and comprehensive comparison between methods. This
paper presents MWPToolkit, the first open-source framework for solving MWPs. In
MWPToolkit, we decompose the procedure of existing MWP solvers into multiple
core components and decouple their models into highly reusable modules. We also
provide a hyper-parameter search function to boost the performance. In total,
we implement and compare 17 MWP solvers on 4 widely-used single equation
generation benchmarks and 2 multiple equations generation benchmarks. These
features enable our MWPToolkit to be suitable for researchers to reproduce
advanced baseline models and develop new MWP solvers quickly. Code and
documents are available at https://github.com/LYH-YF/MWPToolkit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning. (arXiv:2109.00840v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00840">
<div class="article-summary-box-inner">
<span><p>Though language model text embeddings have revolutionized NLP research, their
ability to capture high-level semantic information, such as relations between
entities in text, is limited. In this paper, we propose a novel contrastive
learning framework that trains sentence embeddings to encode the relations in a
graph structure. Given a sentence (unstructured text) and its graph, we use
contrastive learning to impose relation-related structure on the token-level
representations of the sentence obtained with a CharacterBERT (El Boukkouri et
al.,2020) model. The resulting relation-aware sentence embeddings achieve
state-of-the-art results on the relation extraction task using only a simple
KNN classifier, thereby demonstrating the success of the proposed method.
Additional visualization by a tSNE analysis shows the effectiveness of the
learned representation space compared to baselines. Furthermore, we show that
we can learn a different space for named entity recognition, again using a
contrastive learning objective, and demonstrate how to successfully combine
both representation spaces in an entity-relation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation. (arXiv:2109.00859v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00859">
<div class="article-summary-box-inner">
<span><p>Pre-trained models for Natural Languages (NL) like BERT and GPT have been
recently shown to transfer well to Programming Languages (PL) and largely
benefit a broad set of code-related tasks. Despite their success, most current
methods either rely on an encoder-only (or decoder-only) pre-training that is
suboptimal for generation (resp. understanding) tasks or process the code
snippet in the same way as NL, neglecting the special characteristics of PL
such as token types. We present CodeT5, a unified pre-trained encoder-decoder
Transformer model that better leverages the code semantics conveyed from the
developer-assigned identifiers. Our model employs a unified framework to
seamlessly support both code understanding and generation tasks and allows for
multi-task learning. Besides, we propose a novel identifier-aware pre-training
task that enables the model to distinguish which code tokens are identifiers
and to recover them when they are masked. Furthermore, we propose to exploit
the user-written code comments with a bimodal dual generation task for better
NL-PL alignment. Comprehensive experiments show that CodeT5 significantly
outperforms prior methods on understanding tasks such as code defect detection
and clone detection, and generation tasks across various directions including
PL-NL, NL-PL, and PL-PL. Further analysis reveals that our model can better
capture semantic information from code. Our code and pre-trained models are
released at https: //github.com/salesforce/CodeT5 .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Perceived Multi-modal Pretraining in E-commerce. (arXiv:2109.00895v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00895">
<div class="article-summary-box-inner">
<span><p>In this paper, we address multi-modal pretraining of product data in the
field of E-commerce. Current multi-modal pretraining methods proposed for image
and text modalities lack robustness in the face of modality-missing and
modality-noise, which are two pervasive problems of multi-modal product data in
real E-commerce scenarios. To this end, we propose a novel method, K3M, which
introduces knowledge modality in multi-modal pretraining to correct the noise
and supplement the missing of image and text modalities. The modal-encoding
layer extracts the features of each modality. The modal-interaction layer is
capable of effectively modeling the interaction of multiple modalities, where
an initial-interactive feature fusion model is designed to maintain the
independence of image modality and text modality, and a structure aggregation
module is designed to fuse the information of image, text, and knowledge
modalities. We pretrain K3M with three pretraining tasks, including masked
object modeling (MOM), masked language modeling (MLM), and link prediction
modeling (LPM). Experimental results on a real-world E-commerce dataset and a
series of product-based downstream tasks demonstrate that K3M achieves
significant improvements in performances than the baseline and state-of-the-art
methods when modality-noise or modality-missing exists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MultiEURLEX -- A multi-lingual and multi-label legal document classification dataset for zero-shot cross-lingual transfer. (arXiv:2109.00904v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00904">
<div class="article-summary-box-inner">
<span><p>We introduce MULTI-EURLEX, a new multilingual dataset for topic
classification of legal documents. The dataset comprises 65k European Union
(EU) laws, officially translated in 23 languages, annotated with multiple
labels from the EUROVOC taxonomy. We highlight the effect of temporal concept
drift and the importance of chronological, instead of random splits. We use the
dataset as a testbed for zero-shot cross-lingual transfer, where we exploit
annotated training documents in one language (source) to classify documents in
another language (target). We find that fine-tuning a multilingually pretrained
model (XLM-ROBERTA, MT5) in a single source language leads to catastrophic
forgetting of multilingual knowledge and, consequently, poor zero-shot transfer
to other languages. Adaptation strategies, namely partial fine-tuning,
adapters, BITFIT, LNFIT, originally proposed to accelerate fine-tuning for new
end-tasks, help retain multilingual knowledge from pretraining, substantially
improving zero-shot cross-lingual transfer, but their impact also depends on
the pretrained model used and the size of the label set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coarse-To-Fine And Cross-Lingual ASR Transfer. (arXiv:2109.00916v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00916">
<div class="article-summary-box-inner">
<span><p>End-to-end neural automatic speech recognition systems achieved recently
state-of-the-art results, but they require large datasets and extensive
computing resources. Transfer learning has been proposed to overcome these
difficulties even across languages, e.g., German ASR trained from an English
model. We experiment with much less related languages, reusing an English model
for Czech ASR. To simplify the transfer, we propose to use an intermediate
alphabet, Czech without accents, and document that it is a highly effective
strategy. The technique is also useful on Czech data alone, in the style of
coarse-to-fine training. We achieve substantial eductions in training time as
well as word error rate (WER).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Multimodal fusion via Mutual Dependency Maximisation. (arXiv:2109.00922v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00922">
<div class="article-summary-box-inner">
<span><p>Multimodal sentiment analysis is a trending area of research, and the
multimodal fusion is one of its most active topic. Acknowledging humans
communicate through a variety of channels (i.e visual, acoustic, linguistic),
multimodal systems aim at integrating different unimodal representations into a
synthetic one. So far, a consequent effort has been made on developing complex
architectures allowing the fusion of these modalities. However, such systems
are mainly trained by minimising simple losses such as $L_1$ or cross-entropy.
In this work, we investigate unexplored penalties and propose a set of new
objectives that measure the dependency between modalities. We demonstrate that
our new penalties lead to a consistent improvement (up to $4.3$ on accuracy)
across a large variety of state-of-the-art models on two well-known sentiment
analysis datasets: \texttt{CMU-MOSI} and \texttt{CMU-MOSEI}. Our method not
only achieves a new SOTA on both datasets but also produces representations
that are more robust to modality drops. Finally, a by-product of our methods
includes a statistical network which can be used to interpret the high
dimensional representations learnt by the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speaker-Conditioned Hierarchical Modeling for Automated Speech Scoring. (arXiv:2109.00928v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00928">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Scoring (ASS) is the computer-assisted evaluation of a
candidate's speaking proficiency in a language. ASS systems face many
challenges like open grammar, variable pronunciations, and unstructured or
semi-structured content. Recent deep learning approaches have shown some
promise in this domain. However, most of these approaches focus on extracting
features from a single audio, making them suffer from the lack of
speaker-specific context required to model such a complex task. We propose a
novel deep learning technique for non-native ASS, called speaker-conditioned
hierarchical modeling. In our technique, we take advantage of the fact that
oral proficiency tests rate multiple responses for a candidate. We extract
context vectors from these responses and feed them as additional
speaker-specific context to our network to score a particular response. We
compare our technique with strong baselines and find that such modeling
improves the model's average performance by 6.92% (maximum = 12.86%, minimum =
4.51%). We further show both quantitative and qualitative insights into the
importance of this additional context in solving the problem of ASS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coordinating Narratives and the Capitol Riots on Parler. (arXiv:2109.00945v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00945">
<div class="article-summary-box-inner">
<span><p>Coordinated disinformation campaigns are used to influence social media
users, potentially leading to offline violence. In this study, we introduce a
general methodology to uncover coordinated messaging through analysis of user
parleys on Parler. The proposed method constructs a user-to-user coordination
network graph induced by a user-to-text graph and a text-to-text similarity
graph. The text-to-text graph is constructed based on the textual similarity of
Parler posts. We study three influential groups of users in the 6 January 2020
Capitol riots and detect networks of coordinated user clusters that are all
posting similar textual content in support of different disinformation
narratives related to the U.S. 2020 elections.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LegaLMFiT: Efficient Short Legal Text Classification with LSTM Language Model Pre-Training. (arXiv:2109.00993v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00993">
<div class="article-summary-box-inner">
<span><p>Large Transformer-based language models such as BERT have led to broad
performance improvements on many NLP tasks. Domain-specific variants of these
models have demonstrated excellent performance on a variety of specialised
tasks. In legal NLP, BERT-based models have led to new state-of-the-art results
on multiple tasks. The exploration of these models has demonstrated the
importance of capturing the specificity of the legal language and its
vocabulary. However, such approaches suffer from high computational costs,
leading to a higher ecological impact and lower accessibility. Our findings,
focusing on English language legal text, show that lightweight LSTM-based
Language Models are able to capture enough information from a small legal text
pretraining corpus and achieve excellent performance on short legal text
classification tasks. This is achieved with a significantly reduced
computational overhead compared to BERT-based models. However, our method also
shows degraded performance on a more complex task, multi-label classification
of longer documents, highlighting the limitations of this lightweight approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TravelBERT: Pre-training Language Model Incorporating Domain-specific Heterogeneous Knowledge into A Unified Representation. (arXiv:2109.01048v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01048">
<div class="article-summary-box-inner">
<span><p>Existing technologies expand BERT from different perspectives, e.g. designing
different pre-training tasks, different semantic granularities and different
model architectures. Few models consider expanding BERT from different text
formats. In this paper, we propose a heterogeneous knowledge language model
(HKLM), a unified pre-trained language model (PLM) for all forms of text,
including unstructured text, semi-structured text and well-structured text. To
capture the corresponding relations among these multi-format knowledge, our
approach uses masked language model objective to learn word knowledge, uses
triple classification objective and title matching objective to learn entity
knowledge and topic knowledge respectively. To obtain the aforementioned
multi-format text, we construct a corpus in the tourism domain and conduct
experiments on 5 tourism NLP datasets. The results show that our approach
outperforms the pre-training of plain text using only 1/4 of the data. The
code, datasets, corpus and knowledge graph will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skim-Attention: Learning to Focus via Document Layout. (arXiv:2109.01078v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01078">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-training techniques of text and layout have proven
effective in a number of document understanding tasks. Despite this success,
multimodal pre-training models suffer from very high computational and memory
costs. Motivated by human reading strategies, this paper presents
Skim-Attention, a new attention mechanism that takes advantage of the structure
of the document and its layout. Skim-Attention only attends to the
2-dimensional position of the words in a document. Our experiments show that
Skim-Attention obtains a lower perplexity than prior works, while being more
computationally efficient. Skim-Attention can be further combined with
long-range Transformers to efficiently process long documents. We also show how
Skim-Attention can be used off-the-shelf as a mask for any Pre-trained Language
Model, allowing to improve their performance while restricting attention.
Finally, we show the emergence of a document structure representation in
Skim-Attention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Suitable Are Subword Segmentation Strategies for Translating Non-Concatenative Morphology?. (arXiv:2109.01100v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01100">
<div class="article-summary-box-inner">
<span><p>Data-driven subword segmentation has become the default strategy for
open-vocabulary machine translation and other NLP tasks, but may not be
sufficiently generic for optimal learning of non-concatenative morphology. We
design a test suite to evaluate segmentation strategies on different types of
morphological phenomena in a controlled, semi-synthetic setting. In our
experiments, we compare how well machine translation models trained on subword-
and character-level can translate these morphological phenomena. We find that
learning to analyse and generate morphologically complex surface
representations is still challenging, especially for non-concatenative
morphological phenomena like reduplication or vowel harmony and for rare word
stems. Based on our results, we recommend that novel text representation
strategies be tested on a range of typologically diverse languages to minimise
the risk of adopting a strategy that inadvertently disadvantages certain
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence-to-Sequence Learning with Latent Neural Grammars. (arXiv:2109.01135v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01135">
<div class="article-summary-box-inner">
<span><p>Sequence-to-sequence learning with neural networks has become the de facto
standard for sequence prediction tasks. This approach typically models the
local distribution over the next word with a powerful neural network that can
condition on arbitrary context. While flexible and performant, these models
often require large datasets for training and can fail spectacularly on
benchmarks designed to test for compositional generalization. This work
explores an alternative, hierarchical approach to sequence-to-sequence learning
with quasi-synchronous grammars, where each node in the target tree is
transduced by a node in the source tree. Both the source and target trees are
treated as latent and induced during training. We develop a neural
parameterization of the grammar which enables parameter sharing over the
combinatorial space of derivation rules without the need for manual feature
engineering. We apply this latent neural grammar to various domains -- a
diagnostic language navigation task designed to test for compositional
generalization (SCAN), style transfer, and small-scale machine translation --
and find that it performs respectably compared to standard baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Iterative Multi-Knowledge Transfer Network for Aspect-Based Sentiment Analysis. (arXiv:2004.01935v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.01935">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis (ABSA) mainly involves three subtasks: aspect
term extraction, opinion term extraction, and aspect-level sentiment
classification, which are typically handled in a separate or joint manner.
However, previous approaches do not well exploit the interactive relations
among three subtasks and do not pertinently leverage the easily available
document-level labeled domain/sentiment knowledge, which restricts their
performances. To address these issues, we propose a novel Iterative
Multi-Knowledge Transfer Network (IMKTN) for end-to-end ABSA. For one thing,
through the interactive correlations between the ABSA subtasks, our IMKTN
transfers the task-specific knowledge from any two of the three subtasks to
another one at the token level by utilizing a well-designed routing algorithm,
that is, any two of the three subtasks will help the third one. For another,
our IMKTN pertinently transfers the document-level knowledge, i.e.,
domain-specific and sentiment-related knowledge, to the aspect-level subtasks
to further enhance the corresponding performance. Experimental results on three
benchmark datasets demonstrate the effectiveness and superiority of our
approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerating Real-Time Question Answering via Question Generation. (arXiv:2009.05167v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05167">
<div class="article-summary-box-inner">
<span><p>Although deep neural networks have achieved tremendous success for question
answering (QA), they are still suffering from heavy computational and energy
cost for real product deployment. Further, existing QA systems are bottlenecked
by the encoding time of real-time questions with neural networks, thus
suffering from detectable latency in deployment for large-volume traffic. To
reduce the computational cost and accelerate real-time question answering
(RTQA) for practical usage, we propose to remove all the neural networks from
online QA systems, and present Ocean-Q (an Ocean of Questions), which
introduces a new question generation (QG) model to generate a large pool of QA
pairs offline, then in real time matches an input question with the candidate
QA pool to predict the answer without question encoding. Ocean-Q can be readily
deployed in existing distributed database systems or search engine for
large-scale query usage, and much greener with no additional cost for
maintaining large neural networks. Experiments on SQuAD(-open) and HotpotQA
benchmarks demonstrate that Ocean-Q is able to accelerate the fastest
state-of-the-art RTQA system by 4X times, with only a 3+% accuracy drop.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GMH: A General Multi-hop Reasoning Model for KG Completion. (arXiv:2010.07620v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07620">
<div class="article-summary-box-inner">
<span><p>Knowledge graphs are essential for numerous downstream natural language
processing applications, but are typically incomplete with many facts missing.
This results in research efforts on multi-hop reasoning task, which can be
formulated as a search process and current models typically perform short
distance reasoning. However, the long-distance reasoning is also vital with the
ability to connect the superficially unrelated entities. To the best of our
knowledge, there lacks a general framework that approaches multi-hop reasoning
in mixed long-short distance reasoning scenarios. We argue that there are two
key issues for a general multi-hop reasoning model: i) where to go, and ii)
when to stop. Therefore, we propose a general model which resolves the issues
with three modules: 1) the local-global knowledge module to estimate the
possible paths, 2) the differentiated action dropout module to explore a
diverse set of paths, and 3) the adaptive stopping search module to avoid over
searching. The comprehensive results on three datasets demonstrate the
superiority of our model with significant improvements against baselines in
both short and long distance reasoning scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual Transfer of Abstractive Summarizer to Less-resource Language. (arXiv:2012.04307v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04307">
<div class="article-summary-box-inner">
<span><p>Automatic text summarization extracts important information from texts and
presents the information in the form of a summary. Abstractive summarization
approaches progressed significantly by switching to deep neural networks, but
results are not yet satisfactory, especially for languages where large training
sets do not exist. In several natural language processing tasks, a
cross-lingual model transfer is successfully applied in less-resource
languages. For summarization, the cross-lingual model transfer was not
attempted due to a non-reusable decoder side of neural models that cannot
correct target language generation. In our work, we use a pre-trained English
summarization model based on deep neural networks and sequence-to-sequence
architecture to summarize Slovene news articles. We address the problem of
inadequate decoder by using an additional language model for the evaluation of
the generated text in target language. We test several cross-lingual
summarization models with different amounts of target data for fine-tuning. We
assess the models with automatic evaluation measures and conduct a small-scale
human evaluation. Automatic evaluation shows that the summaries of our best
cross-lingual model are useful and of quality similar to the model trained only
in the target language. Human evaluation shows that our best model generates
summaries with high accuracy and acceptable readability. However, similar to
other abstractive models, our models are not perfect and may occasionally
produce misleading or absurd content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Topic Coverage Approach to Evaluation of Topic Models. (arXiv:2012.06274v3 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06274">
<div class="article-summary-box-inner">
<span><p>Topic models are widely used unsupervised models capable of learning topics -
weighted lists of words and documents - from large collections of text
documents. When topic models are used for discovery of topics in text
collections, a question that arises naturally is how well the model-induced
topics correspond to topics of interest to the analyst. In this paper we
revisit and extend a so far neglected approach to topic model evaluation based
on measuring topic coverage - computationally matching model topics with a set
of reference topics that models are expected to uncover. The approach is well
suited for analyzing models' performance in topic discovery and for large-scale
analysis of both topic models and measures of model quality. We propose new
measures of coverage and evaluate, in a series of experiments, different types
of topic models on two distinct text domains for which interest for topic
discovery exists. The experiments include evaluation of model quality, analysis
of coverage of distinct topic categories, and the analysis of the relationship
between coverage and other methods of topic model evaluation. The paper
contributes a new supervised measure of coverage, and the first unsupervised
measure of coverage. The supervised measure achieves topic matching accuracy
close to human agreement. The unsupervised measure correlates highly with the
supervised one (Spearman's $\rho \geq 0.95$). Other contributions include
insights into both topic models and different methods of model evaluation, and
the datasets and code for facilitating future research on topic coverage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NewsBERT: Distilling Pre-trained Language Model for Intelligent News Application. (arXiv:2102.04887v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04887">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) like BERT have made great progress in NLP.
News articles usually contain rich textual information, and PLMs have the
potentials to enhance news text modeling for various intelligent news
applications like news recommendation and retrieval. However, most existing
PLMs are in huge size with hundreds of millions of parameters. Many online news
applications need to serve millions of users with low latency tolerance, which
poses huge challenges to incorporating PLMs in these scenarios. Knowledge
distillation techniques can compress a large PLM into a much smaller one and
meanwhile keeps good performance. However, existing language models are
pre-trained and distilled on general corpus like Wikipedia, which has some gaps
with the news domain and may be suboptimal for news intelligence. In this
paper, we propose NewsBERT, which can distill PLMs for efficient and effective
news intelligence. In our approach, we design a teacher-student joint learning
and distillation framework to collaboratively learn both teacher and student
models, where the student model can learn from the learning experience of the
teacher model. In addition, we propose a momentum distillation method by
incorporating the gradients of teacher model into the update of student model
to better transfer useful knowledge learned by the teacher model. Extensive
experiments on two real-world datasets with three tasks show that NewsBERT can
effectively improve the model performance in various intelligent news
applications with much smaller models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Data-Centric Framework for Composable NLP Workflows. (arXiv:2103.01834v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01834">
<div class="article-summary-box-inner">
<span><p>Empirical natural language processing (NLP) systems in application domains
(e.g., healthcare, finance, education) involve interoperation among multiple
components, ranging from data ingestion, human annotation, to text retrieval,
analysis, generation, and visualization. We establish a unified open-source
framework to support fast development of such sophisticated NLP workflows in a
composable manner. The framework introduces a uniform data representation to
encode heterogeneous results by a wide range of NLP tasks. It offers a large
repository of processors for NLP tasks, visualization, and annotation, which
can be easily assembled with full interoperability under the unified
representation. The highly extensible framework allows plugging in custom
processors from external off-the-shelf NLP and deep learning libraries. The
whole framework is delivered through two modularized yet integratable
open-source projects, namely Forte (for workflow infrastructure and NLP
function processors) and Stave (for user interaction, visualization, and
annotation).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradual Fine-Tuning for Low-Resource Domain Adaptation. (arXiv:2103.02205v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02205">
<div class="article-summary-box-inner">
<span><p>Fine-tuning is known to improve NLP models by adapting an initial model
trained on more plentiful but less domain-salient examples to data in a target
domain. Such domain adaptation is typically done using one stage of
fine-tuning. We demonstrate that gradually fine-tuning in a multi-stage process
can yield substantial further gains and can be applied without modifying the
model or learning objective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conceptual similarity and communicative need shape colexification: an experimental study. (arXiv:2103.11024v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11024">
<div class="article-summary-box-inner">
<span><p>Colexification refers to the phenomenon of multiple meanings sharing one word
in a language. Cross-linguistic lexification patterns have been shown to be
largely predictable, as similar concepts are often colexified. We test a recent
claim that, beyond this general tendency, communicative needs play an important
role in shaping colexification patterns. We approach this question by means of
a series of human experiments, using an artificial language communication game
paradigm. Our results across four experiments match the previous
cross-linguistic findings: all other things being equal, speakers do prefer to
colexify similar concepts. However, we also find evidence supporting the
communicative need hypothesis: when faced with a frequent need to distinguish
similar pairs of meanings, speakers adjust their colexification preferences to
maintain communicative efficiency, and avoid colexifying those similar meanings
which need to be distinguished in communication. This research provides further
evidence to support the argument that languages are shaped by the needs and
preferences of their speakers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking. (arXiv:2104.04466v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04466">
<div class="article-summary-box-inner">
<span><p>Dialogue State Tracking is central to multi-domain task-oriented dialogue
systems, responsible for extracting information from user utterances. We
present a novel hybrid architecture that augments GPT-2 with representations
derived from Graph Attention Networks in such a way to allow causal, sequential
prediction of slot values. The model architecture captures inter-slot
relationships and dependencies across domains that otherwise can be lost in
sequential prediction. We report improvements in state tracking performance in
MultiWOZ 2.0 against a strong GPT-2 baseline and investigate a simplified
sparse training scenario in which DST models are trained only on session-level
annotations but evaluated at the turn level. We further report detailed
analyses to demonstrate the effectiveness of graph models in DST by showing
that the proposed graph modules capture inter-slot dependencies and improve the
predictions of values that are common to multiple domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Power of Scale for Parameter-Efficient Prompt Tuning. (arXiv:2104.08691v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08691">
<div class="article-summary-box-inner">
<span><p>In this work, we explore "prompt tuning", a simple yet effective mechanism
for learning "soft prompts" to condition frozen language models to perform
specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft
prompts are learned through backpropagation and can be tuned to incorporate
signal from any number of labeled examples. Our end-to-end learned approach
outperforms GPT-3's "few-shot" learning by a large margin. More remarkably,
through ablations on model size using T5, we show that prompt tuning becomes
more competitive with scale: as models exceed billions of parameters, our
method "closes the gap" and matches the strong performance of model tuning
(where all model weights are tuned). This finding is especially relevant in
that large models are costly to share and serve, and the ability to reuse one
frozen model for multiple downstream tasks can ease this burden. Our method can
be seen as a simplification of the recently proposed "prefix tuning" of Li and
Liang (2021), and we provide a comparison to this and other similar approaches.
Finally, we show that conditioning a frozen model with soft prompts confers
benefits in robustness to domain transfer, as compared to full model tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing Commonsense Explanation in Dialogue Response Generation. (arXiv:2104.09574v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09574">
<div class="article-summary-box-inner">
<span><p>Humans use commonsense reasoning (CSR) implicitly to produce natural and
coherent responses in conversations. Aiming to close the gap between current
response generation (RG) models and human communication abilities, we want to
understand why RG models respond as they do by probing RG model's understanding
of commonsense reasoning that elicits proper responses. We formalize the
problem by framing commonsense as a latent variable in the RG task and using
explanations for responses as textual form of commonsense. We collect 6k
annotated explanations justifying responses from four dialogue datasets and ask
humans to verify them and propose two probing settings to evaluate RG models'
CSR capabilities. Probing results show that models fail to capture the logical
relations between commonsense explanations and responses and fine-tuning on
in-domain data and increasing model sizes do not lead to understanding of CSR
for RG. We hope our study motivates more research in making RG models emulate
the human reasoning process in pursuit of smooth human-AI communication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AMMU : A Survey of Transformer-based Biomedical Pretrained Language Models. (arXiv:2105.00827v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00827">
<div class="article-summary-box-inner">
<span><p>Transformer-based pretrained language models (PLMs) have started a new era in
modern natural language processing (NLP). These models combine the power of
transformers, transfer learning, and self-supervised learning (SSL). Following
the success of these models in the general domain, the biomedical research
community has developed various in-domain PLMs starting from BioBERT to the
latest BioELECTRA and BioALBERT models. We strongly believe there is a need for
a survey paper that can provide a comprehensive survey of various
transformer-based biomedical pretrained language models (BPLMs). In this
survey, we start with a brief overview of foundational concepts like
self-supervised learning, embedding layer and transformer encoder layers. We
discuss core concepts of transformer-based PLMs like pretraining methods,
pretraining tasks, fine-tuning methods, and various embedding types specific to
biomedical domain. We introduce a taxonomy for transformer-based BPLMs and then
discuss all the models. We discuss various challenges and present possible
solutions. We conclude by highlighting some of the open issues which will drive
the research community to further improve transformer-based BPLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fastformer: Additive Attention Can Be All You Need. (arXiv:2108.09084v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09084">
<div class="article-summary-box-inner">
<span><p>Transformer is a powerful model for text understanding. However, it is
inefficient due to its quadratic complexity to input sequence length. Although
there are many methods on Transformer acceleration, they are still either
inefficient on long sequences or not effective enough. In this paper, we
propose Fastformer, which is an efficient Transformer model based on additive
attention. In Fastformer, instead of modeling the pair-wise interactions
between tokens, we first use additive attention mechanism to model global
contexts, and then further transform each token representation based on its
interaction with global context representations. In this way, Fastformer can
achieve effective context modeling with linear complexity. Extensive
experiments on five datasets show that Fastformer is much more efficient than
many existing Transformer models and can meanwhile achieve comparable or even
better long text modeling performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smart Bird: Learnable Sparse Attention for Efficient and Effective Transformer. (arXiv:2108.09193v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09193">
<div class="article-summary-box-inner">
<span><p>Transformer has achieved great success in NLP. However, the quadratic
complexity of the self-attention mechanism in Transformer makes it inefficient
in handling long sequences. Many existing works explore to accelerate
Transformers by computing sparse self-attention instead of a dense one, which
usually attends to tokens at certain positions or randomly selected tokens.
However, manually selected or random tokens may be uninformative for context
modeling. In this paper, we propose Smart Bird, which is an efficient and
effective Transformer with learnable sparse attention. In Smart Bird, we first
compute a sketched attention matrix with a single-head low-dimensional
Transformer, which aims to find potential important interactions between
tokens. We then sample token pairs based on their probability scores derived
from the sketched attention matrix to generate different sparse attention index
matrices for different attention heads. Finally, we select token embeddings
according to the index matrices to form the input of sparse attention networks.
Extensive experiments on six benchmark datasets for different tasks validate
the efficiency and effectiveness of Smart Bird in text modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Chatbot Per Person: Creating Personalized Chatbots based on Implicit User Profiles. (arXiv:2108.09355v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09355">
<div class="article-summary-box-inner">
<span><p>Personalized chatbots focus on endowing chatbots with a consistent
personality to behave like real users, give more informative responses, and
further act as personal assistants. Existing personalized approaches tried to
incorporate several text descriptions as explicit user profiles. However, the
acquisition of such explicit profiles is expensive and time-consuming, thus
being impractical for large-scale real-world applications. Moreover, the
restricted predefined profile neglects the language behavior of a real user and
cannot be automatically updated together with the change of user interests. In
this paper, we propose to learn implicit user profiles automatically from
large-scale user dialogue history for building personalized chatbots.
Specifically, leveraging the benefits of Transformer on language understanding,
we train a personalized language model to construct a general user profile from
the user's historical responses. To highlight the relevant historical responses
to the input post, we further establish a key-value memory network of
historical post-response pairs, and build a dynamic post-aware user profile.
The dynamic profile mainly describes what and how the user has responded to
similar posts in history. To explicitly utilize users' frequently used words,
we design a personalized decoder to fuse two decoding strategies, including
generating a word from the generic vocabulary and copying one word from the
user's personalized vocabulary. Experiments on two real-world datasets show the
significant improvement of our model compared with existing methods. Our code
is available at https://github.com/zhengyima/DHAP
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12202">
<div class="article-summary-box-inner">
<span><p>In joint entity and relation extraction, existing work either sequentially
encode task-specific features, leading to an imbalance in inter-task feature
interaction where features extracted later have no direct contact with those
that come first. Or they encode entity features and relation features in a
parallel manner, meaning that feature representation learning for each task is
largely independent of each other except for input sharing. We propose a
partition filter network to model two-way interaction between tasks properly,
where feature encoding is decomposed into two steps: partition and filter. In
our encoder, we leverage two gates: entity and relation gate, to segment
neurons into two task partitions and one shared partition. The shared partition
represents inter-task information valuable to both tasks and is evenly shared
across two tasks to ensure proper two-way interaction. The task partitions
represent intra-task information and are formed through concerted efforts of
both gates, making sure that encoding of task-specific features is dependent
upon each other. Experiment results on five public datasets show that our model
performs significantly better than previous approaches. In addition, contrary
to what previous work claims, our auxiliary experiments suggest that relation
prediction is contributory to named entity prediction in a non-negligible way.
The source code can be found at https://github.com/Coopercoppers/PFN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tree Decomposition Attention for AMR-to-Text Generation. (arXiv:2108.12300v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12300">
<div class="article-summary-box-inner">
<span><p>Text generation from AMR requires mapping a semantic graph to a string that
it annotates. Transformer-based graph encoders, however, poorly capture vertex
dependencies that may benefit sequence prediction. To impose order on an
encoder, we locally constrain vertex self-attention using a graph's tree
decomposition. Instead of forming a full query-key bipartite graph, we restrict
attention to vertices in parent, subtree, and same-depth bags of a vertex. This
hierarchical context lends both sparsity and structure to vertex state updates.
We apply dynamic programming to derive a forest of tree decompositions,
choosing the most structurally similar tree to the AMR. Our system outperforms
a self-attentive baseline by 1.6 BLEU and 1.8 chrF++.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Latent Tree Decomposition Parsers for AMR-to-Text Generation. (arXiv:2108.12304v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12304">
<div class="article-summary-box-inner">
<span><p>Graph encoders in AMR-to-text generation models often rely on neighborhood
convolutions or global vertex attention. While these approaches apply to
general graphs, AMRs may be amenable to encoders that target their tree-like
structure. By clustering edges into a hierarchy, a tree decomposition
summarizes graph structure. Our model encodes a derivation forest of tree
decompositions and extracts an expected tree. From tree node embeddings, it
builds graph edge features used in vertex attention of the graph encoder.
Encoding TD forests instead of shortest-pairwise paths in a self-attentive
baseline raises BLEU by 0.7 and chrF++ by 0.3. The forest encoder also
surpasses a convolutional baseline for molecular property prediction by 1.92%
ROC-AUC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smoothing Dialogue States for Open Conversational Machine Reading. (arXiv:2108.12599v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12599">
<div class="article-summary-box-inner">
<span><p>Conversational machine reading (CMR) requires machines to communicate with
humans through multi-turn interactions between two salient dialogue states of
decision making and question generation processes. In open CMR settings, as the
more realistic scenario, the retrieved background knowledge would be noisy,
which results in severe challenges in the information transmission. Existing
studies commonly train independent or pipeline systems for the two subtasks.
However, those methods are trivial by using hard-label decisions to activate
question generation, which eventually hinders the model performance. In this
work, we propose an effective gating strategy by smoothing the two dialogue
states in only one decoder and bridge decision making and question generation
to provide a richer dialogue state reference. Experiments on the OR-ShARC
dataset show the effectiveness of our method, which achieves new
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional Extreme Value Theory for Open Set Video Domain Adaptation. (arXiv:2109.00522v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00522">
<div class="article-summary-box-inner">
<span><p>With the advent of media streaming, video action recognition has become
progressively important for various applications, yet at the high expense of
requiring large-scale data labelling. To overcome the problem of expensive data
labelling, domain adaptation techniques have been proposed that transfers
knowledge from fully labelled data (i.e., source domain) to unlabelled data
(i.e., target domain). The majority of video domain adaptation algorithms are
proposed for closed-set scenarios in which all the classes are shared among the
domains. In this work, we propose an open-set video domain adaptation approach
to mitigate the domain discrepancy between the source and target data, allowing
the target data to contain additional classes that do not belong to the source
domain. Different from previous works, which only focus on improving accuracy
for shared classes, we aim to jointly enhance the alignment of shared classes
and recognition of unknown samples. Towards this goal, class-conditional
extreme value theory is applied to enhance the unknown recognition.
Specifically, the entropy values of target samples are modelled as generalised
extreme value distributions, which allows separating unknown samples lying in
the tail of the distribution. To alleviate the negative transfer issue, weights
computed by the distance from the sample entropy to the threshold are leveraged
in adversarial learning in the sense that confident source and target samples
are aligned, and unconfident samples are pushed away. The proposed method has
been thoroughly evaluated on both small-scale and large-scale cross-domain
video datasets and achieved the state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Limits of Pseudo Ground Truth in Visual Camera Re-localisation. (arXiv:2109.00524v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00524">
<div class="article-summary-box-inner">
<span><p>Benchmark datasets that measure camera pose accuracy have driven progress in
visual re-localisation research. To obtain poses for thousands of images, it is
common to use a reference algorithm to generate pseudo ground truth. Popular
choices include Structure-from-Motion (SfM) and
Simultaneous-Localisation-and-Mapping (SLAM) using additional sensors like
depth cameras if available. Re-localisation benchmarks thus measure how well
each method replicates the results of the reference algorithm. This begs the
question whether the choice of the reference algorithm favours a certain family
of re-localisation methods. This paper analyzes two widely used re-localisation
datasets and shows that evaluation outcomes indeed vary with the choice of the
reference algorithm. We thus question common beliefs in the re-localisation
literature, namely that learning-based scene coordinate regression outperforms
classical feature-based methods, and that RGB-D-based methods outperform
RGB-based methods. We argue that any claims on ranking re-localisation methods
should take the type of the reference algorithm, and the similarity of the
methods to the reference algorithm, into account.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransforMesh: A Transformer Network for Longitudinal modeling of Anatomical Meshes. (arXiv:2109.00532v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00532">
<div class="article-summary-box-inner">
<span><p>The longitudinal modeling of neuroanatomical changes related to Alzheimer's
disease (AD) is crucial for studying the progression of the disease. To this
end, we introduce TransforMesh, a spatio-temporal network based on transformers
that models longitudinal shape changes on 3D anatomical meshes. While
transformer and mesh networks have recently shown impressive performances in
natural language processing and computer vision, their application to medical
image analysis has been very limited. To the best of our knowledge, this is the
first work that combines transformer and mesh networks. Our results show that
TransforMesh can model shape trajectories better than other baseline
architectures that do not capture temporal dependencies. Moreover, we also
explore the capabilities of TransforMesh in detecting structural anomalies of
the hippocampus in patients developing AD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fair Representation: Guaranteeing Approximate Multiple Group Fairness for Unknown Tasks. (arXiv:2109.00545v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00545">
<div class="article-summary-box-inner">
<span><p>Motivated by scenarios where data is used for diverse prediction tasks, we
study whether fair representation can be used to guarantee fairness for unknown
tasks and for multiple fairness notions simultaneously. We consider seven group
fairness notions that cover the concepts of independence, separation, and
calibration. Against the backdrop of the fairness impossibility results, we
explore approximate fairness. We prove that, although fair representation might
not guarantee fairness for all prediction tasks, it does guarantee fairness for
an important subset of tasks -- the tasks for which the representation is
discriminative. Specifically, all seven group fairness notions are linearly
controlled by fairness and discriminativeness of the representation. When an
incompatibility exists between different fairness notions, fair and
discriminative representation hits the sweet spot that approximately satisfies
all notions. Motivated by our theoretical findings, we propose to learn both
fair and discriminative representations using pretext loss which
self-supervises learning, and Maximum Mean Discrepancy as a fair regularizer.
Experiments on tabular, image, and face datasets show that using the learned
representation, downstream predictions that we are unaware of when learning the
representation indeed become fairer for seven group fairness notions, and the
fairness guarantees computed from our theoretical results are all valid.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pulmonary Disease Classification Using Globally Correlated Maximum Likelihood: an Auxiliary Attention mechanism for Convolutional Neural Networks. (arXiv:2109.00573v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00573">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNN) are now being widely used for classifying
and detecting pulmonary abnormalities in chest radiographs. Two complementary
generalization properties of CNNs, translation invariance and equivariance, are
particularly useful in detecting manifested abnormalities associated with
pulmonary disease, regardless of their spatial locations within the image.
However, these properties also come with the loss of exact spatial information
and global relative positions of abnormalities detected in local regions.
Global relative positions of such abnormalities may help distinguish similar
conditions, such as COVID-19 and viral pneumonia. In such instances, a global
attention mechanism is needed, which CNNs do not support in their traditional
architectures that aim for generalization afforded by translation invariance
and equivariance. Vision Transformers provide a global attention mechanism, but
lack translation invariance and equivariance, requiring significantly more
training data samples to match generalization of CNNs. To address the loss of
spatial information and global relations between features, while preserving the
inductive biases of CNNs, we present a novel technique that serves as an
auxiliary attention mechanism to existing CNN architectures, in order to
extract global correlations between salient features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active label cleaning: Improving dataset quality under resource constraints. (arXiv:2109.00574v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00574">
<div class="article-summary-box-inner">
<span><p>Imperfections in data annotation, known as label noise, are detrimental to
the training of machine learning models and have an often-overlooked
confounding effect on the assessment of model performance. Nevertheless,
employing experts to remove label noise by fully re-annotating large datasets
is infeasible in resource-constrained settings, such as healthcare. This work
advocates for a data-driven approach to prioritising samples for re-annotation
- which we term "active label cleaning". We propose to rank instances according
to estimated label correctness and labelling difficulty of each sample, and
introduce a simulation framework to evaluate relabelling efficacy. Our
experiments on natural images and on a new medical imaging benchmark show that
cleaning noisy labels mitigates their negative impact on model training,
evaluation, and selection. Crucially, the proposed active label cleaning
enables correcting labels up to 4 times more effectively than typical random
selection in realistic conditions, making better use of experts' valuable time
for improving dataset quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebQA: Multihop and Multimodal QA. (arXiv:2109.00590v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00590">
<div class="article-summary-box-inner">
<span><p>Web search is fundamentally multimodal and multihop. Often, even before
asking a question we choose to go directly to image search to find our answers.
Further, rarely do we find an answer from a single source but aggregate
information and reason through implications. Despite the frequency of this
everyday occurrence, at present, there is no unified question answering
benchmark that requires a single model to answer long-form natural language
questions from text and open-ended visual sources -- akin to a human's
experience. We propose to bridge this gap between the natural language and
computer vision communities with WebQA. We show that A. our multihop text
queries are difficult for a large-scale transformer model, and B. existing
multi-modal transformers and visual representations do not perform well on
open-domain visual queries. Our challenge for the community is to create a
unified multimodal reasoning model that seamlessly transitions and reasons
regardless of the source modality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An End-to-End learnable Flow Regularized Model for Brain Tumor Segmentation. (arXiv:2109.00622v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00622">
<div class="article-summary-box-inner">
<span><p>Many segmentation tasks for biomedical images can be modeled as the
minimization of an energy function and solved by a class of max-flow and
min-cut optimization algorithms. However, the segmentation accuracy is
sensitive to the contrasting of semantic features of different segmenting
objects, as the traditional energy function usually uses hand-crafted features
in their energy functions. To address these limitations, we propose to
incorporate end-to-end trainable neural network features into the energy
functions. Our deep neural network features are extracted from the
down-sampling and up-sampling layers with skip-connections of a U-net. In the
inference stage, the learned features are fed into the energy functions. And
the segmentations are solved in a primal-dual form by ADMM solvers. In the
training stage, we train our neural networks by optimizing the energy function
in the primal form with regularizations on the min-cut and flow-conservation
functions, which are derived from the optimal conditions in the dual form. We
evaluate our methods, both qualitatively and quantitatively, in a brain tumor
segmentation task. As the energy minimization model achieves a balance on
sensitivity and smooth boundaries, we would show how our segmentation contours
evolve actively through iterations as ensemble references for doctor diagnosis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Field-Based Plot Extraction Using UAV RGB Images. (arXiv:2109.00632v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00632">
<div class="article-summary-box-inner">
<span><p>Unmanned Aerial Vehicles (UAVs) have become popular for use in plant
phenotyping of field based crops, such as maize and sorghum, due to their
ability to acquire high resolution data over field trials. Field experiments,
which may comprise thousands of plants, are planted according to experimental
designs to evaluate varieties or management practices. For many types of
phenotyping analysis, we examine smaller groups of plants known as "plots." In
this paper, we propose a new plot extraction method that will segment a UAV
image into plots. We will demonstrate that our method achieves higher plot
extraction accuracy than existing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for Efficient Multi-Stage Vision Transformers. (arXiv:2109.00642v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00642">
<div class="article-summary-box-inner">
<span><p>Vision Transformer (ViT) demonstrates that Transformer for natural language
processing can be applied to computer vision tasks and result in comparable
performance to convolutional neural networks (CNN), which have been studied and
adopted in computer vision for years. This naturally raises the question of how
the performance of ViT can be advanced with design techniques of CNN. To this
end, we propose to incorporate two techniques and present ViT-ResNAS, an
efficient multi-stage ViT architecture designed with neural architecture search
(NAS). First, we propose residual spatial reduction to decrease sequence
lengths for deeper layers and utilize a multi-stage architecture. When reducing
lengths, we add skip connections to improve performance and stabilize training
deeper networks. Second, we propose weight-sharing NAS with multi-architectural
sampling. We enlarge a network and utilize its sub-networks to define a search
space. A super-network covering all sub-networks is then trained for fast
evaluation of their performance. To efficiently train the super-network, we
propose to sample and train multiple sub-networks with one forward-backward
pass. After that, evolutionary search is performed to discover high-performance
network architectures. Experiments on ImageNet demonstrate that ViT-ResNAS
achieves better accuracy-MACs and accuracy-throughput trade-offs than the
original DeiT and other strong baselines of ViT. Code is available at
https://github.com/yilunliao/vit-search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dash: Semi-Supervised Learning with Dynamic Thresholding. (arXiv:2109.00650v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00650">
<div class="article-summary-box-inner">
<span><p>While semi-supervised learning (SSL) has received tremendous attentions in
many machine learning tasks due to its successful use of unlabeled data,
existing SSL algorithms use either all unlabeled examples or the unlabeled
examples with a fixed high-confidence prediction during the training progress.
However, it is possible that too many correct/wrong pseudo labeled examples are
eliminated/selected. In this work we develop a simple yet powerful framework,
whose key idea is to select a subset of training examples from the unlabeled
data when performing existing SSL methods so that only the unlabeled examples
with pseudo labels related to the labeled data will be used to train models.
The selection is performed at each updating iteration by only keeping the
examples whose losses are smaller than a given threshold that is dynamically
adjusted through the iteration. Our proposed approach, Dash, enjoys its
adaptivity in terms of unlabeled data selection and its theoretical guarantee.
Specifically, we theoretically establish the convergence rate of Dash from the
view of non-convex optimization. Finally, we empirically demonstrate the
effectiveness of the proposed method in comparison with state-of-the-art over
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variable Augmented Network for Invertible Modality Synthesis-Fusion. (arXiv:2109.00670v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00670">
<div class="article-summary-box-inner">
<span><p>As an effective way to integrate the information contained in multiple
medical images under different modalities, medical image synthesis and fusion
have emerged in various clinical applications such as disease diagnosis and
treatment planning. In this paper, an invertible and variable augmented network
(iVAN) is proposed for medical image synthesis and fusion. In iVAN, the channel
number of the network input and output is the same through variable
augmentation technology, and data relevance is enhanced, which is conducive to
the generation of characterization information. Meanwhile, the invertible
network is used to achieve the bidirectional inference processes. Due to the
invertible and variable augmentation schemes, iVAN can not only be applied to
the mappings of multi-input to one-output and multi-input to multi-output, but
also be applied to one-input to multi-output. Experimental results demonstrated
that the proposed method can obtain competitive or superior performance in
comparison to representative medical image synthesis and fusion methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regional Adversarial Training for Better Robust Generalization. (arXiv:2109.00678v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00678">
<div class="article-summary-box-inner">
<span><p>Adversarial training (AT) has been demonstrated as one of the most promising
defense methods against various adversarial attacks. To our knowledge, existing
AT-based methods usually train with the locally most adversarial perturbed
points and treat all the perturbed points equally, which may lead to
considerably weaker adversarial robust generalization on test data. In this
work, we introduce a new adversarial training framework that considers the
diversity as well as characteristics of the perturbed points in the vicinity of
benign samples. To realize the framework, we propose a Regional Adversarial
Training (RAT) defense method that first utilizes the attack path generated by
the typical iterative attack method of projected gradient descent (PGD), and
constructs an adversarial region based on the attack path. Then, RAT samples
diverse perturbed training points efficiently inside this region, and utilizes
a distance-aware label smoothing mechanism to capture our intuition that
perturbed points at different locations should have different impact on the
model performance. Extensive experiments on several benchmark datasets show
that RAT consistently makes significant improvement on standard adversarial
training (SAT), and exhibits better robust generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Face Video Inpainting via UV Mapping. (arXiv:2109.00681v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00681">
<div class="article-summary-box-inner">
<span><p>This paper addresses the problem of face video inpainting. Existing video
inpainting methods target primarily at natural scenes with repetitive patterns.
They do not make use of any prior knowledge of the face to help retrieve
correspondences for the corrupted face. They therefore only achieve sub-optimal
results, particularly for faces under large pose and expression variations
where face components appear very differently across frames. In this paper, we
propose a two-stage deep learning method for face video inpainting. We employ
3DMM as our 3D face prior to transform a face between the image space and the
UV (texture) space. In Stage I, we perform face inpainting in the UV space.
This helps to largely remove the influence of face poses and expressions and
makes the learning task much easier with well aligned face features. We
introduce a frame-wise attention module to fully exploit correspondences in
neighboring frames to assist the inpainting task. In Stage II, we transform the
inpainted face regions back to the image space and perform face video
refinement that inpaints any background regions not covered in Stage I and also
refines the inpainted face regions. Extensive experiments have been carried out
which show our method can significantly outperform methods based merely on 2D
information, especially for faces under large pose and expression variations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AnANet: Modeling Association and Alignment for Cross-modal Correlation Classification. (arXiv:2109.00693v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00693">
<div class="article-summary-box-inner">
<span><p>The explosive increase of multimodal data makes a great demand in many
cross-modal applications that follow the strict prior related assumption. Thus
researchers study the definition of cross-modal correlation category and
construct various classification systems and predictive models. However, those
systems pay more attention to the fine-grained relevant types of cross-modal
correlation, ignoring lots of implicit relevant data which are often divided
into irrelevant types. What's worse is that none of previous predictive models
manifest the essence of cross-modal correlation according to their definition
at the modeling stage. In this paper, we present a comprehensive analysis of
the image-text correlation and redefine a new classification system based on
implicit association and explicit alignment. To predict the type of image-text
correlation, we propose the Association and Alignment Network according to our
proposed definition (namely AnANet) which implicitly represents the global
discrepancy and commonality between image and text and explicitly captures the
cross-modal local relevance. The experimental results on our constructed new
image-text correlation dataset show the effectiveness of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FBSNet: A Fast Bilateral Symmetrical Network for Real-Time Semantic Segmentation. (arXiv:2109.00699v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00699">
<div class="article-summary-box-inner">
<span><p>Real-time semantic segmentation, which can be visually understood as the
pixel-level classification task on the input image, currently has broad
application prospects, especially in the fast-developing fields of autonomous
driving and drone navigation. However, the huge burden of calculation together
with redundant parameters are still the obstacles to its technological
development. In this paper, we propose a Fast Bilateral Symmetrical Network
(FBSNet) to alleviate the above challenges. Specifically, FBSNet employs a
symmetrical encoder-decoder structure with two branches, semantic information
branch, and spatial detail branch. The semantic information branch is the main
branch with deep network architecture to acquire the contextual information of
the input image and meanwhile acquire sufficient receptive field. While spatial
detail branch is a shallow and simple network used to establish local
dependencies of each pixel for preserving details, which is essential for
restoring the original resolution during the decoding phase. Meanwhile, a
feature aggregation module (FAM) is designed to effectively combine the output
features of the two branches. The experimental results of Cityscapes and CamVid
show that the proposed FBSNet can strike a good balance between accuracy and
efficiency. Specifically, it obtains 70.9\% and 68.9\% mIoU along with the
inference speed of 90 fps and 120 fps on these two test datasets, respectively,
with only 0.62 million parameters on a single RTX 2080Ti GPU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning 3D Mineral Prospectivity from 3D Geological Models with Convolutional Neural Networks: Application to a Structure-controlled Hydrothermal Gold Deposit. (arXiv:2109.00756v1 [physics.geo-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00756">
<div class="article-summary-box-inner">
<span><p>The three-dimensional (3D) geological models are the typical and key data
source in the 3D mineral prospecitivity modeling. Identifying
prospectivity-informative predictor variables from the 3D geological models is
a challenging and tedious task. Motivated by the ability of convolutional
neural networks (CNNs) to learn the intrinsic features, in this paper, we
present a novel method that leverages CNNs to learn 3D mineral prospectivity
from the 3D geological models. By exploiting the learning ability of CNNs, the
presented method allows for disentangling complex correlation to the
mineralization and thus opens a door to circumvent the tedious work for
designing the predictor variables. Specifically, to explore the unstructured 3D
geological models with the CNNs whose input should be structured, we develop a
2D CNN framework in which the geometry of geological boundary is compiled and
reorganized into multi-channel images and fed into the CNN. This ensures an
effective and efficient training of CNNs while allowing the prospective model
to approximate the ore-forming process. The presented method is applied to a
typical structure-controlled hydrothermal deposit, the Dayingezhuang gold
deposit, eastern China, in which the presented method was compared with the
prospectivity modeling methods using hand-designed predictor variables. The
results demonstrate the presented method capacitates a performance boost of the
3D prospectivity modeling and empowers us to decrease work-load and prospecting
risk in prediction of deep-seated orebodies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Direct PET Image Reconstruction Incorporating Deep Image Prior and a Forward Projection Model. (arXiv:2109.00768v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00768">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) have recently achieved remarkable
performance in positron emission tomography (PET) image reconstruction. In
particular, CNN-based direct PET image reconstruction, which directly generates
the reconstructed image from the sinogram, has potential applicability to PET
image enhancements because it does not require image reconstruction algorithms,
which often produce some artifacts. However, these deep learning-based, direct
PET image reconstruction algorithms have the disadvantage that they require a
large number of high-quality training datasets. In this study, we propose an
unsupervised direct PET image reconstruction method that incorporates a deep
image prior framework. Our proposed method incorporates a forward projection
model with a loss function to achieve unsupervised direct PET image
reconstruction from sinograms. To compare our proposed direct reconstruction
method with the filtered back projection (FBP) and maximum likelihood
expectation maximization (ML-EM) algorithms, we evaluated using Monte Carlo
simulation data of brain [$^{18}$F]FDG PET scans. The results demonstrate that
our proposed direct reconstruction quantitatively and qualitatively outperforms
the FBP and ML-EM algorithms with respect to peak signal-to-noise ratio and
structural similarity index.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Better Self-training for Image Classification through Self-supervision. (arXiv:2109.00778v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00778">
<div class="article-summary-box-inner">
<span><p>Self-training is a simple semi-supervised learning approach: Unlabelled
examples that attract high-confidence predictions are labelled with their
predictions and added to the training set, with this process being repeated
multiple times. Recently, self-supervision -- learning without manual
supervision by solving an automatically-generated pretext task -- has gained
prominence in deep learning. This paper investigates three different ways of
incorporating self-supervision into self-training to improve accuracy in image
classification: self-supervision as pretraining only, self-supervision
performed exclusively in the first iteration of self-training, and
self-supervision added to every iteration of self-training. Empirical results
on the SVHN, CIFAR-10, and PlantVillage datasets, using both training from
scratch, and Imagenet-pretrained weights, show that applying self-supervision
only in the first iteration of self-training can greatly improve accuracy, for
a modest increase in computation time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-Photorealistic Rendering of Layered Materials: A Multispectral Approach. (arXiv:2109.00780v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00780">
<div class="article-summary-box-inner">
<span><p>We present multispectral rendering techniques for visualizing layered
materials found in biological specimens. We are the first to use acquired data
from the near-infrared and ultraviolet spectra for non-photorealistic rendering
(NPR). Several plant and animal species are more comprehensively understood by
multispectral analysis. However, traditional NPR techniques ignore unique
information outside the visible spectrum. We introduce algorithms and
principles for processing wavelength dependent surface normals and reflectance.
Our registration and feature detection methods are used to formulate
stylization effects not considered by current NPR methods including: Spectral
Band Shading which isolates and emphasizes shape features at specific
wavelengths at multiple scales. Experts in our user study demonstrate the
effectiveness of our system for applications in the biological sciences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transfer of Pretrained Model Weights Substantially Improves Semi-Supervised Image Classification. (arXiv:2109.00788v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00788">
<div class="article-summary-box-inner">
<span><p>Deep neural networks produce state-of-the-art results when trained on a large
number of labeled examples but tend to overfit when small amounts of labeled
examples are used for training. Creating a large number of labeled examples
requires considerable resources, time, and effort. If labeling new data is not
feasible, so-called semi-supervised learning can achieve better generalisation
than purely supervised learning by employing unlabeled instances as well as
labeled ones. The work presented in this paper is motivated by the observation
that transfer learning provides the opportunity to potentially further improve
performance by exploiting models pretrained on a similar domain. More
specifically, we explore the use of transfer learning when performing
semi-supervised learning using self-learning. The main contribution is an
empirical evaluation of transfer learning using different combinations of
similarity metric learning methods and label propagation algorithms in
semi-supervised learning. We find that transfer learning always substantially
improves the model's accuracy when few labeled examples are available,
regardless of the type of loss used for training the neural network. This
finding is obtained by performing extensive experiments on the SVHN, CIFAR10,
and Plant Village image classification datasets and applying pretrained weights
from Imagenet for transfer learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-Supervised Learning using Siamese Networks. (arXiv:2109.00794v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00794">
<div class="article-summary-box-inner">
<span><p>Neural networks have been successfully used as classification models yielding
state-of-the-art results when trained on a large number of labeled samples.
These models, however, are more difficult to train successfully for
semi-supervised problems where small amounts of labeled instances are available
along with a large number of unlabeled instances. This work explores a new
training method for semi-supervised learning that is based on similarity
function learning using a Siamese network to obtain a suitable embedding. The
learned representations are discriminative in Euclidean space, and hence can be
used for labeling unlabeled instances using a nearest-neighbor classifier.
Confident predictions of unlabeled instances are used as true labels for
retraining the Siamese network on the expanded training set. This process is
applied iteratively. We perform an empirical study of this iterative
self-training algorithm. For improving unlabeled predictions, local learning
with global consistency [22] is also evaluated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Modal Zero-Shot Sign Language Recognition. (arXiv:2109.00796v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00796">
<div class="article-summary-box-inner">
<span><p>Zero-Shot Learning (ZSL) has rapidly advanced in recent years. Towards
overcoming the annotation bottleneck in the Sign Language Recognition (SLR), we
explore the idea of Zero-Shot Sign Language Recognition (ZS-SLR) with no
annotated visual examples, by leveraging their textual descriptions. In this
way, we propose a multi-modal Zero-Shot Sign Language Recognition (ZS-SLR)
model harnessing from the complementary capabilities of deep features fused
with the skeleton-based ones. A Transformer-based model along with a C3D model
is used for hand detection and deep features extraction, respectively. To make
a trade-off between the dimensionality of the skeletonbased and deep features,
we use an Auto-Encoder (AE) on top of the Long Short Term Memory (LSTM)
network. Finally, a semantic space is used to map the visual features to the
lingual embedding of the class labels, achieved via the Bidirectional Encoder
Representations from Transformers (BERT) model. Results on four large-scale
datasets, RKS-PERSIANSIGN, First-Person, ASLVID, and isoGD, show the
superiority of the proposed model compared to state-of-the-art alternatives in
ZS-SLR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anatomical-Guided Attention Enhances Unsupervised PET Image Denoising Performance. (arXiv:2109.00802v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00802">
<div class="article-summary-box-inner">
<span><p>Although supervised convolutional neural networks (CNNs) often outperform
conventional alternatives for denoising positron emission tomography (PET)
images, they require many low- and high-quality reference PET image pairs.
Herein, we propose an unsupervised 3D PET image denoising method based on
anatomical information-guided attention mechanism. Our proposed magnetic
resonance-guided deep decoder (MR-GDD) utilizes the spatial details and
semantic features of MR-guidance image more effectively by introducing
encoder-decoder and deep decoder subnetworks. Moreover, the specific shapes and
patterns of the guidance image do not affect the denoised PET image, because
the guidance image is input to the network through an attention gate. Monte
Carlo simulation using the [$^{18}$F]fluoro-2-deoxy-D-glucose (FDG) shows that
the proposed method outperforms other denoising algorithms in terms of the
highest peak signal-to-noise ratio and structural similarity (28.33 dB/0.886).
Furthermore, we experimentally visualized the behavior of the optimization
process, which is often unknown in unsupervised CNN-based restoration problems.
For preclinical (using [$^{18}$F]FDG and [$^{11}$C]raclopride) and clinical
(using [$^{18}$F]florbetapir) studies, the proposed method demonstrates
state-of-the-art denoising performance while retaining spatial resolution and
quantitative accuracy, despite using only a single architecture for various
noisy PET images with 1/10th of the full counts. These results suggest that the
proposed MR-GDD can reduce PET scan times and PET tracer doses considerably
without impacting patients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Single-Shot MultiBox Detector and YOLO Deep Learning Models for the Detection of Tomatoes in a Greenhouse. (arXiv:2109.00810v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00810">
<div class="article-summary-box-inner">
<span><p>The development of robotic solutions for agriculture requires advanced
perception capabilities that can work reliably in any crop stage. For example,
to automatise the tomato harvesting process in greenhouses, the visual
perception system needs to detect the tomato in any life cycle stage (flower to
the ripe tomato). The state-of-the-art for visual tomato detection focuses
mainly on ripe tomato, which has a distinctive colour from the background. This
paper contributes with an annotated visual dataset of green and reddish
tomatoes. This kind of dataset is uncommon and not available for research
purposes. This will enable further developments in edge artificial intelligence
for in situ and in real-time visual tomato detection required for the
development of harvesting robots. Considering this dataset, five deep learning
models were selected, trained and benchmarked to detect green and reddish
tomatoes grown in greenhouses. Considering our robotic platform specifications,
only the Single-Shot MultiBox Detector (SSD) and YOLO architectures were
considered. The results proved that the system can detect green and reddish
tomatoes, even those occluded by leaves. SSD MobileNet v2 had the best
performance when compared against SSD Inception v2, SSD ResNet 50, SSD ResNet
101 and YOLOv4 Tiny, reaching an F1-score of 66.15%, an mAP of 51.46% and an
inference time of 16.44 ms with the NVIDIA Turing Architecture platform, an
NVIDIA Tesla T4, with 12 GB. YOLOv4 Tiny also had impressive results, mainly
concerning inferring times of about 5 ms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Built Year Prediction from Buddha Face with Heterogeneous Labels. (arXiv:2109.00812v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00812">
<div class="article-summary-box-inner">
<span><p>Buddha statues are a part of human culture, especially of the Asia area, and
they have been alongside human civilisation for more than 2,000 years. As
history goes by, due to wars, natural disasters, and other reasons, the records
that show the built years of Buddha statues went missing, which makes it an
immense work for historians to estimate the built years. In this paper, we
pursue the idea of building a neural network model that automatically estimates
the built years of Buddha statues based only on their face images. Our model
uses a loss function that consists of three terms: an MSE loss that provides
the basis for built year estimation; a KL divergence-based loss that handles
the samples with both an exact built year and a possible range of built years
(e.g., dynasty or centuries) estimated by historians; finally a regularisation
that utilises both labelled and unlabelled samples based on manifold
assumption. By combining those three terms in the training process, we show
that our method is able to estimate built years for given images with 37.5
years of a mean absolute error on the test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning-based mitosis detection in breast cancer histologic samples. (arXiv:2109.00816v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00816">
<div class="article-summary-box-inner">
<span><p>This is the submission for mitosis detection in the context of the MIDOG 2021
challenge. It is based on the two-stage objection model Faster RCNN as well as
DenseNet as a backbone for the neural network architecture. It achieves a
F1-score of 0.6645 on the Preliminary Test Phase Leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rotation Invariance and Extensive Data Augmentation: a strategy for the Mitosis Domain Generalization (MIDOG) Challenge. (arXiv:2109.00823v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00823">
<div class="article-summary-box-inner">
<span><p>Automated detection of mitotic figures in histopathology images is a
challenging task: here, we present the different steps that describe the
strategy we applied to participate in the MIDOG 2021 competition. The purpose
of the competition was to evaluate the generalization of solutions to images
acquired with unseen target scanners (hidden for the participants) under the
constraint of using training data from a limited set of four independent source
scanners. Given this goal and constraints, we joined the challenge by proposing
a straight-forward solution based on a combination of state-of-the-art deep
learning methods with the aim of yielding robustness to possible
scanner-related distributional shifts at inference time. Our solution combines
methods that were previously shown to be efficient for mitosis detection: hard
negative mining, extensive data augmentation, rotation-invariant convolutional
networks.
</p>
<p>We trained five models with different splits of the provided dataset. The
subsequent classifiers produced F1-scores with a mean and standard deviation of
0.747+/-0.032 on the test splits. The resulting ensemble constitutes our
candidate algorithm: its automated evaluation on the preliminary test set of
the challenge returned a F1-score of 0.6828.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SlowFast Rolling-Unrolling LSTMs for Action Anticipation in Egocentric Videos. (arXiv:2109.00829v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00829">
<div class="article-summary-box-inner">
<span><p>Action anticipation in egocentric videos is a difficult task due to the
inherently multi-modal nature of human actions. Additionally, some actions
happen faster or slower than others depending on the actor or surrounding
context which could vary each time and lead to different predictions. Based on
this idea, we build upon RULSTM architecture, which is specifically designed
for anticipating human actions, and propose a novel attention-based technique
to evaluate, simultaneously, slow and fast features extracted from three
different modalities, namely RGB, optical flow, and extracted objects. Two
branches process information at different time scales, i.e., frame-rates, and
several fusion schemes are considered to improve prediction accuracy. We
perform extensive experiments on EpicKitchens-55 and EGTEA Gaze+ datasets, and
demonstrate that our technique systematically improves the results of RULSTM
architecture for Top-5 accuracy metric at different anticipation times.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stain-Robust Mitotic Figure Detection for the Mitosis Domain Generalization Challenge. (arXiv:2109.00853v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00853">
<div class="article-summary-box-inner">
<span><p>The detection of mitotic figures from different scanners/sites remains an
important topic of research, owing to its potential in assisting clinicians
with tumour grading. The MItosis DOmain Generalization (MIDOG) challenge aims
to test the robustness of detection models on unseen data from multiple
scanners for this task. We present a short summary of the approach employed by
the TIA Centre team to address this challenge. Our approach is based on a
hybrid detection model, where mitotic candidates are segmented on stain
normalised images, before being refined by a deep learning classifier.
Cross-validation on the training images achieved the F1-score of 0.786 and
0.765 on the preliminary test set, demonstrating the generalizability of our
model to unseen data from new scanners.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Models for Multi-Illumination Color Constancy. (arXiv:2109.00863v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00863">
<div class="article-summary-box-inner">
<span><p>In this paper, the aim is multi-illumination color constancy. However, most
of the existing color constancy methods are designed for single light sources.
Furthermore, datasets for learning multiple illumination color constancy are
largely missing. We propose a seed (physics driven) based multi-illumination
color constancy method. GANs are exploited to model the illumination estimation
problem as an image-to-image domain translation problem. Additionally, a novel
multi-illumination data augmentation method is proposed. Experiments on single
and multi-illumination datasets show that our methods outperform sota methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real World Robustness from Systematic Noise. (arXiv:2109.00864v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00864">
<div class="article-summary-box-inner">
<span><p>Systematic error, which is not determined by chance, often refers to the
inaccuracy (involving either the observation or measurement process) inherent
to a system. In this paper, we exhibit some long-neglected but
frequent-happening adversarial examples caused by systematic error. More
specifically, we find the trained neural network classifier can be fooled by
inconsistent implementations of image decoding and resize. This tiny difference
between these implementations often causes an accuracy drop from training to
deployment. To benchmark these real-world adversarial examples, we propose
ImageNet-S dataset, which enables researchers to measure a classifier's
robustness to systematic error. For example, we find a normal ResNet-50 trained
on ImageNet can have 1%-5% accuracy difference due to the systematic error.
Together our evaluation and dataset may aid future work toward real-world
robustness and practical generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing domain adaptation techniques for mitosis detection in multi-scanner breast cancer histopathology images. (arXiv:2109.00869v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00869">
<div class="article-summary-box-inner">
<span><p>Breast cancer is the most prevalent cancer worldwide and over two million new
cases are diagnosed each year. As part of the tumour grading process,
histopathologists manually count how many cells are dividing, in a biological
process called mitosis. Artificial intelligence (AI) methods have been
developed to automatically detect mitotic figures, however these methods often
perform poorly when applied to data from outside of the original (training)
domain, i.e. they do not generalise well to histology images created using
varied staining protocols or digitised using different scanners. Style
transfer, a form of domain adaptation, provides the means to transform images
from different domains to a shared visual appearance and have been adopted in
various applications to mitigate the issue of domain shift. In this paper we
train two mitosis detection models and two style transfer methods and evaluate
the usefulness of the latter for improving mitosis detection performance in
images digitised using different scanners. We found that the best of these
models, U-Net without style transfer, achieved an F1-score of 0.693 on the
MIDOG 2021 preliminary test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DVM-CAR: A large-scale automotive dataset for visual marketing research and applications. (arXiv:2109.00881v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00881">
<div class="article-summary-box-inner">
<span><p>The automotive industry is being transformed by technologies, applications
and services ranging from sensors to big data analytics and to artificial
intelligence. In this paper, we present our multidisciplinary initiative of
creating a publicly available dataset to facilitate the visual-related
marketing research and applications in automotive industry such as automotive
exterior design, consumer analytics and sales modelling. We are motivated by
the fact that there is growing interest in product aesthetics but there is no
large-scale dataset available that covers a wide range of variables and
information. We summarise the common issues faced by marketing researchers and
computer scientists through a user survey study, and design our dataset to
alleviate these issues. Our dataset contains 1.4 million images from 899 car
models as well as their corresponding car model specification and sales
information over more than ten years in the UK market. To the best of our
knowledge, this is the very first large-scale automotive dataset which contains
images, text and sales information from multiple sources over a long period of
time. We describe the detailed data structure and the preparation steps, which
we believe has the methodological contribution to the multi-source data fusion
and sharing. In addition, we discuss three dataset application examples to
illustrate the value of our dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MOON: Multi-Hash Codes Joint Learning for Cross-Media Retrieval. (arXiv:2109.00883v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00883">
<div class="article-summary-box-inner">
<span><p>In recent years, cross-media hashing technique has attracted increasing
attention for its high computation efficiency and low storage cost. However,
the existing approaches still have some limitations, which need to be explored.
1) A fixed hash length (e.g., 16bits or 32bits) is predefined before learning
the binary codes. Therefore, these models need to be retrained when the hash
length changes, that consumes additional computation power, reducing the
scalability in practical applications. 2) Existing cross-modal approaches only
explore the information in the original multimedia data to perform the hash
learning, without exploiting the semantic information contained in the learned
hash codes. To this end, we develop a novel Multiple hash cOdes jOint learNing
method (MOON) for cross-media retrieval. Specifically, the developed MOON
synchronously learns the hash codes with multiple lengths in a unified
framework. Besides, to enhance the underlying discrimination, we combine the
clues from the multimodal data, semantic labels and learned hash codes for hash
learning. As far as we know, the proposed MOON is the first work to
simultaneously learn different length hash codes without retraining in
cross-media retrieval. Experiments on several databases show that our MOON can
achieve promising performance, outperforming some recent competitive shallow
and deep methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tracking Hand Hygiene Gestures with Leap Motion Controller. (arXiv:2109.00884v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00884">
<div class="article-summary-box-inner">
<span><p>The process of hand washing, according to the WHO, is divided into stages
with clearly defined two handed dynamic gestures. In this paper, videos of hand
washing experts are segmented and analyzed with the goal of extracting their
corresponding features. These features can be further processed in software to
classify particular hand movements, determine whether the stages have been
successfully completed by the user and also assess the quality of washing.
Having identified the important features, a 3D gesture tracker, the Leap Motion
Controller (LEAP), was used to track and detect the hand features associated
with these stages. With the help of sequential programming and threshold
values, the hand features were combined together to detect the initiation and
completion of a sample WHO Stage 2 (Rub hands Palm to Palm). The LEAP provides
accurate raw positional data for tracking single hand gestures and two hands in
separation but suffers from occlusion when hands are in contact. Other than
hand hygiene the approaches shown here can be applied in other biomedical
applications requiring close hand gesture analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Learning for Target Tracking and Background Subtraction in Satellite Imagery. (arXiv:2109.00885v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00885">
<div class="article-summary-box-inner">
<span><p>This paper describes an unsupervised machine learning methodology capable of
target tracking and background suppression via a novel dual-model approach.
``Jekyll`` produces a video bit-mask describing an estimate of the locations of
moving objects, and ``Hyde`` outputs a pseudo-background frame to subtract from
the original input image sequence. These models were trained with a
custom-modified version of Cross Entropy Loss.
</p>
<p>Simulated data were used to compare the performance of Jekyll and Hyde
against a more traditional supervised Machine Learning approach. The results
from these comparisons show that the unsupervised methods developed are
competitive in output quality with supervised techniques, without the
associated cost of acquiring labeled training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrast Limited Adaptive Histogram Equalization (CLAHE) Approach for Enhancement of the Microstructures of Friction Stir Welded Joints. (arXiv:2109.00886v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00886">
<div class="article-summary-box-inner">
<span><p>Image processing algorithms are finding various applications in manufacturing
and materials industries such as identification of cracks in the fabricated
samples, calculating the geometrical properties of the given microstructure,
presence of surface defects, etc. The present work deals with the application
of Contrast Limited Adaptive Histogram Equalization (CLAHE) algorithm for
improving the quality of the microstructure images of the Friction Stir Welded
joints. The obtained results showed that the obtained value of quantitative
metric features such as Entropy value and RMS Contrast value were high which
resulted in enhanced microstructure images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dealing with Distribution Mismatch in Semi-supervised Deep Learning for Covid-19 Detection Using Chest X-ray Images: A Novel Approach Using Feature Densities. (arXiv:2109.00889v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00889">
<div class="article-summary-box-inner">
<span><p>In the context of the global coronavirus pandemic, different deep learning
solutions for infected subject detection using chest X-ray images have been
proposed. However, deep learning models usually need large labelled datasets to
be effective. Semi-supervised deep learning is an attractive alternative, where
unlabelled data is leveraged to improve the overall model's accuracy. However,
in real-world usage settings, an unlabelled dataset might present a different
distribution than the labelled dataset (i.e. the labelled dataset was sampled
from a target clinic and the unlabelled dataset from a source clinic). This
results in a distribution mismatch between the unlabelled and labelled
datasets. In this work, we assess the impact of the distribution mismatch
between the labelled and the unlabelled datasets, for a semi-supervised model
trained with chest X-ray images, for COVID-19 detection. Under strong
distribution mismatch conditions, we found an accuracy hit of almost 30\%,
suggesting that the unlabelled dataset distribution has a strong influence in
the behaviour of the model. Therefore, we propose a straightforward approach to
diminish the impact of such distribution mismatch. Our proposed method uses a
density approximation of the feature space. It is built upon the target dataset
to filter out the observations in the source unlabelled dataset that might harm
the accuracy of the semi-supervised model. It assumes that a small labelled
source dataset is available together with a larger source unlabelled dataset.
Our proposed method does not require any model training, it is simple and
computationally cheap. We compare our proposed method against two popular state
of the art out-of-distribution data detectors, which are also cheap and simple
to implement. In our tests, our method yielded accuracy gains of up to 32\%,
when compared to the previous state of the art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-World Application of Various Trajectory Planning Algorithms on MIT RACECAR. (arXiv:2109.00890v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00890">
<div class="article-summary-box-inner">
<span><p>In the project, the vehicle was first controlled with ROS. For this purpose,
the necessary nodes were prepared to be controlled with a joystick. Afterwards,
DWA(Dynamic Window Approach), TEB(Timed-Elastic Band) and APF(Artificial
Potential Field) path planning algorithms were applied to MIT RACECAR,
respectively. These algorithms have advantages and disadvantages against each
other on different issues. For this reason, a scenario was created to compare
algorithms. On a curved double lane road created according to this scenario,
MIT RACECAR has to follow the lanes and when it encounters an obstacle, it has
to change lanes without leaving the road and pass without hitting the obstacle.
In addition, an image processing algorithm was developed to obtain the position
information of the lanes needed to implement this scenario. This algorithm
detects the target point by processing the image taken from the ZED camera and
gives the target point information to the path planning algorithm.
</p>
<p>After the necessary tools were created, the algorithms were tested against
the scenario. In these tests, measurements such as how many obstacles the
algorithm successfully passed, how simple routes it chose, and computational
costs they have. According to these results, although it was not the algorithm
that successfully passed the most obstacles, APF was chosen due to its low
processing load and simple working logic. It was believed that with its
uncomplicated structure, APF would also provide advantages in the future stages
of the project.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Fine-grained Image Classification with Generative Adversarial Networks and Facial Landmark Detection. (arXiv:2109.00891v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00891">
<div class="article-summary-box-inner">
<span><p>Fine-grained classification remains a challenging task because distinguishing
categories needs learning complex and local differences. Diversity in the pose,
scale, and position of objects in an image makes the problem even more
difficult. Although the recent Vision Transformer models achieve high
performance, they need an extensive volume of input data. To encounter this
problem, we made the best use of GAN-based data augmentation to generate extra
dataset instances. Oxford-IIIT Pets was our dataset of choice for this
experiment. It consists of 37 breeds of cats and dogs with variations in scale,
poses, and lighting, which intensifies the difficulty of the classification
task. Furthermore, we enhanced the performance of the recent Generative
Adversarial Network (GAN), StyleGAN2-ADA model to generate more realistic
images while preventing overfitting to the training set. We did this by
training a customized version of MobileNetV2 to predict animal facial
landmarks; then, we cropped images accordingly. Lastly, we combined the
synthetic images with the original dataset and compared our proposed method
with standard GANs augmentation and no augmentation with different subsets of
training data. We validated our work by evaluating the accuracy of fine-grained
image classification on the recent Vision Transformer (ViT) Model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KITTI-CARLA: a KITTI-like dataset generated by CARLA Simulator. (arXiv:2109.00892v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00892">
<div class="article-summary-box-inner">
<span><p>KITTI-CARLA is a dataset built from the CARLA v0.9.10 simulator using a
vehicle with sensors identical to the KITTI dataset. The vehicle thus has a
Velodyne HDL64 LiDAR positioned in the middle of the roof and two color cameras
similar to Point Grey Flea 2. The positions of the LiDAR and cameras are the
same as the setup used in KITTI. The objective of this dataset is to test
approaches of semantic segmentation LiDAR and/or images, odometry LiDAR and/or
image in synthetic data and to compare with the results obtained on real data
like KITTI. This dataset thus makes it possible to improve transfer learning
methods from a synthetic dataset to a real dataset. We created 7 sequences with
5000 frames in each sequence in the 7 maps of CARLA providing different
environments (city, suburban area, mountain, rural area, highway...). The
dataset is available at: <a href="http://npm3d.fr">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Open Set Recognition. (arXiv:2109.00893v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00893">
<div class="article-summary-box-inner">
<span><p>Open Set Recognition (OSR) is about dealing with unknown situations that were
not learned by the models during training. In this paper, we provide a survey
of existing works about OSR and distinguish their respective advantages and
disadvantages to help out new researchers interested in the subject. The
categorization of OSR models is provided along with an extensive summary of
recent progress. Additionally, the relationships between OSR and its related
tasks including multi-class classification and novelty detection are analyzed.
It is concluded that OSR can appropriately deal with unknown instances in the
real-world where capturing all possible classes in the training data is not
practical. Lastly, applications of OSR are highlighted and some new directions
for future research topics are suggested.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Wind Power Curve Modeling Via Machine Vision: A Self-learning Deep Convolutional Network Based Method. (arXiv:2109.00894v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00894">
<div class="article-summary-box-inner">
<span><p>This paper develops a novel self-training U-net (STU-net) based method for
the automated WPC model generation without requiring data pre-processing. The
self-training (ST) process of STU-net has two steps. First, different from
traditional studies regarding the WPC modeling as a curve fitting problem, in
this paper, we renovate the WPC modeling formulation from a machine vision
aspect. To develop sufficiently diversified training samples, we synthesize
supervisory control and data acquisition (SCADA) data based on a set of S-shape
functions depicting WPCs. These synthesized SCADA data and WPC functions are
visualized as images and paired as training samples(I_x, I_wpc). A U-net is
then developed to approximate the model recovering I_wpc from I_x. The
developed U-net is applied into observed SCADA data and can successfully
generate the I_wpc. Moreover, we develop a pixel mapping and correction process
to derive a mathematical form f_wpc representing I_wpcgenerated previously. The
proposed STU-net only needs to train once and does not require any data
preprocessing in applications. Numerical experiments based on 76 WTs are
conducted to validate the superiority of the proposed method by benchmarking
against classical WPC modeling methods. To demonstrate the repeatability of the
presented research, we release our code at https://github.com/IkeYang/STU-net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Perceived Multi-modal Pretraining in E-commerce. (arXiv:2109.00895v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00895">
<div class="article-summary-box-inner">
<span><p>In this paper, we address multi-modal pretraining of product data in the
field of E-commerce. Current multi-modal pretraining methods proposed for image
and text modalities lack robustness in the face of modality-missing and
modality-noise, which are two pervasive problems of multi-modal product data in
real E-commerce scenarios. To this end, we propose a novel method, K3M, which
introduces knowledge modality in multi-modal pretraining to correct the noise
and supplement the missing of image and text modalities. The modal-encoding
layer extracts the features of each modality. The modal-interaction layer is
capable of effectively modeling the interaction of multiple modalities, where
an initial-interactive feature fusion model is designed to maintain the
independence of image modality and text modality, and a structure aggregation
module is designed to fuse the information of image, text, and knowledge
modalities. We pretrain K3M with three pretraining tasks, including masked
object modeling (MOM), masked language modeling (MLM), and link prediction
modeling (LPM). Experimental results on a real-world E-commerce dataset and a
series of product-based downstream tasks demonstrate that K3M achieves
significant improvements in performances than the baseline and state-of-the-art
methods when modality-noise or modality-missing exists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Solution of an Elastic Net Regularization for Dementia Knowledge Discovery using Deep Learning. (arXiv:2109.00896v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00896">
<div class="article-summary-box-inner">
<span><p>Background and Aim: Accurate classification of Magnetic Resonance Images
(MRI) is essential to accurately predict Mild Cognitive Impairment (MCI) to
Alzheimer's Disease (AD) conversion. Meanwhile, deep learning has been
successfully implemented to classify and predict dementia disease. However, the
accuracy of MRI image classification is low. This paper aims to increase the
accuracy and reduce the processing time of classification through Deep Learning
Architecture by using Elastic Net Regularization in Feature Selection.
Methodology: The proposed system consists of Convolutional Neural Network (CNN)
to enhance the accuracy of classification and prediction by using Elastic Net
Regularization. Initially, the MRI images are fed into CNN for features
extraction through convolutional layers alternate with pooling layers, and then
through a fully connected layer. After that, the features extracted are
subjected to Principle Component Analysis (PCA) and Elastic Net Regularization
for feature selection. Finally, the selected features are used as an input to
Extreme Machine Learning (EML) for the classification of MRI images. Results:
The result shows that the accuracy of the proposed solution is better than the
current system. In addition to that, the proposed method has improved the
classification accuracy by 5% on average and reduced the processing time by 30
~ 40 seconds on average. Conclusion: The proposed system is focused on
improving the accuracy and processing time of MCI converters/non-converters
classification. It consists of features extraction, feature selection, and
classification using CNN, FreeSurfer, PCA, Elastic Net, Extreme Machine
Learning. Finally, this study enhances the accuracy and the processing time by
using Elastic Net Regularization, which provides important selected features
for classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CE-Dedup: Cost-Effective Convolutional Neural Nets Training based on Image Deduplication. (arXiv:2109.00899v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00899">
<div class="article-summary-box-inner">
<span><p>Attributed to the ever-increasing large image datasets, Convolutional Neural
Networks (CNNs) have become popular for vision-based tasks. It is generally
admirable to have larger-sized datasets for higher network training accuracies.
However, the impact of dataset quality has not to be involved. It is reasonable
to assume the near-duplicate images exist in the datasets. For instance, the
Street View House Numbers (SVHN) dataset having cropped house plate digits from
0 to 9 are likely to have repetitive digits from the same/similar house plates.
Redundant images may take up a certain portion of the dataset without
consciousness. While contributing little to no accuracy improvement for the
CNNs training, these duplicated images unnecessarily pose extra resource and
computation consumption. To this end, this paper proposes a framework to assess
the impact of the near-duplicate images on CNN training performance, called
CE-Dedup. Specifically, CE-Dedup associates a hashing-based image deduplication
approach with downstream CNNs-based image classification tasks. CE-Dedup
balances the tradeoff between a large deduplication ratio and a stable accuracy
by adjusting the deduplication threshold. The effectiveness of CE-Dedup is
validated through extensive experiments on well-known CNN benchmarks. On one
hand, while maintaining the same validation accuracy, CE-Dedup can reduce the
dataset size by 23%. On the other hand, when allowing a small validation
accuracy drop (by 5%), CE-Dedup can trim the dataset size by 75%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatio-temporal-spectral-angular observation model that integrates observations from UAV and mobile mapping vehicle for better urban mapping. (arXiv:2109.00900v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00900">
<div class="article-summary-box-inner">
<span><p>In a complex urban scene, observation from a single sensor unavoidably leads
to voids in observations, failing to describe urban objects in a comprehensive
manner. In this paper, we propose a spatio-temporal-spectral-angular
observation model to integrate observations from UAV and mobile mapping vehicle
platform, realizing a joint, coordinated observation operation from both air
and ground. We develop a multi-source remote sensing data acquisition system to
effectively acquire multi-angle data of complex urban scenes. Multi-source data
fusion solves the missing data problem caused by occlusion and achieves
accurate, rapid, and complete collection of holographic spatial and temporal
information in complex urban scenes. We carried out an experiment on Baisha
Town, Chongqing, China and obtained multi-sensor, multi-angle data from UAV and
mobile mapping vehicle. We first extracted the point cloud from UAV and then
integrated the UAV and mobile mapping vehicle point cloud. The integrated
results combined both the characteristic of UAV and mobile mapping vehicle
point cloud, confirming the practicability of the proposed joint data
acquisition platform and the effectiveness of spatio-temporal-spectral-angular
observation model. Compared with the observation from UAV or mobile mapping
vehicle alone, the integrated system provides an effective data acquisition
solution towards comprehensive urban monitoring.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effect of the output activation function on the probabilities and errors in medical image segmentation. (arXiv:2109.00903v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00903">
<div class="article-summary-box-inner">
<span><p>The sigmoid activation is the standard output activation function in binary
classification and segmentation with neural networks. Still, there exist a
variety of other potential output activation functions, which may lead to
improved results in medical image segmentation. In this work, we consider how
the asymptotic behavior of different output activation and loss functions
affects the prediction probabilities and the corresponding segmentation errors.
For cross entropy, we show that a faster rate of change of the activation
function correlates with better predictions, while a slower rate of change can
improve the calibration of probabilities. For dice loss, we found that the
arctangent activation function is superior to the sigmoid function.
Furthermore, we provide a test space for arbitrary output activation functions
in the area of medical image segmentation. We tested seven activation functions
in combination with three loss functions on four different medical image
segmentation tasks to provide a classification of which function is best suited
in this application scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Automated Approach for the Recognition of Bengali License Plates. (arXiv:2109.00906v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00906">
<div class="article-summary-box-inner">
<span><p>Automatic Number Plate Recognition (ALPR) is a system for automatically
identifying the license plates of any vehicle. This process is important for
tracking, ticketing, and any billing system, among other things. With the use
of information and communication technology (ICT), all systems are being
automated, including the vehicle tracking system. This study proposes a hybrid
method for detecting license plates using characters from them. Our captured
image information was used for the recognition procedure in Bangladeshi
vehicles, which is the topic of this study. Here, for license plate detection,
the YOLO model was used where 81% was correctly predicted. And then, for
license plate segmentation, Otsu's Thresholding was used and eventually, for
character recognition, the CNN model was applied. This model will allow the
vehicle's automated license plate detection system to avoid any misuse.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FA-GAN: Feature-Aware GAN for Text to Image Synthesis. (arXiv:2109.00907v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00907">
<div class="article-summary-box-inner">
<span><p>Text-to-image synthesis aims to generate a photo-realistic image from a given
natural language description. Previous works have made significant progress
with Generative Adversarial Networks (GANs). Nonetheless, it is still hard to
generate intact objects or clear textures (Fig 1). To address this issue, we
propose Feature-Aware Generative Adversarial Network (FA-GAN) to synthesize a
high-quality image by integrating two techniques: a self-supervised
discriminator and a feature-aware loss. First, we design a self-supervised
discriminator with an auxiliary decoder so that the discriminator can extract
better representation. Secondly, we introduce a feature-aware loss to provide
the generator more direct supervision by employing the feature representation
from the self-supervised discriminator. Experiments on the MS-COCO dataset show
that our proposed method significantly advances the state-of-the-art FID score
from 28.92 to 24.58.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BiHPF: Bilateral High-Pass Filters for Robust Deepfake Detection. (arXiv:2109.00911v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00911">
<div class="article-summary-box-inner">
<span><p>The advancement in numerous generative models has a two-fold effect: a simple
and easy generation of realistic synthesized images, but also an increased risk
of malicious abuse of those images. Thus, it is important to develop a
generalized detector for synthesized images of any GAN model or object
category, including those unseen during the training phase. However, the
conventional methods heavily depend on the training settings, which cause a
dramatic decline in performance when tested with unknown domains. To resolve
the issue and obtain a generalized detection ability, we propose Bilateral
High-Pass Filters (BiHPF), which amplify the effect of the frequency-level
artifacts that are known to be found in the synthesized images of generative
models. Numerous experimental results validate that our method outperforms
other state-of-the-art methods, even when tested with unseen domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-task learning from fixed-wing UAV images for 2D/3D city modeling. (arXiv:2109.00918v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00918">
<div class="article-summary-box-inner">
<span><p>Single-task learning in artificial neural networks will be able to learn the
model very well, and the benefits brought by transferring knowledge thus become
limited. In this regard, when the number of tasks increases (e.g., semantic
segmentation, panoptic segmentation, monocular depth estimation, and 3D point
cloud), duplicate information may exist across tasks, and the improvement
becomes less significant. Multi-task learning has emerged as a solution to
knowledge-transfer issues and is an approach to scene understanding which
involves multiple related tasks each with potentially limited training data.
Multi-task learning improves generalization by leveraging the domain-specific
information contained in the training data of related tasks. In urban
management applications such as infrastructure development, traffic monitoring,
smart 3D cities, and change detection, automated multi-task data analysis for
scene understanding based on the semantic, instance, and panoptic annotation,
as well as monocular depth estimation, is required to generate precise urban
models. In this study, a common framework for the performance assessment of
multi-task learning methods from fixed-wing UAV images for 2D/3D city modeling
is presented.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reiterative Domain Aware Multi-target Adaptation. (arXiv:2109.00919v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00919">
<div class="article-summary-box-inner">
<span><p>Most domain adaptation methods focus on single-source-single-target
adaptation setting. Multi-target domain adaptation is a powerful extension in
which a single classifier is learned for multiple unlabeled target domains. To
build a multi-target classifier, it is crucial to effectively aggregate
features from the labeled source and different unlabeled target domains.
Towards this, recently introduced Domain-aware Curriculum Graph Co-Teaching
(D-CGCT) exploits dual classifier head, one of which is based on the graph
neural network. D-CGCT uses a sequential adaptation strategy that adapts one
domain at a time starting from the target domains that are more similar to the
source, assuming that the network finds it easier to adapt to such target
domains. However, we argue that there is no easier domain or difficult domain
in absolute sense and each domain can have samples showing different
characteristics. Following this cue, we propose Reiterative D-CGCT (RD-CGCT)
that obtains better adaptation performance by reiterating multiple times over
each target domain, while keeping the total number of iterations as same.
RD-CGCT further improves the adaptation performance by considering more source
samples than training samples in the training minibatch. Proposed RD-CGCT
significantly improves the performance over D-CGCT for Office-Home and Office31
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classifying Organisms and Artefacts By Their Shapes. (arXiv:2109.00920v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00920">
<div class="article-summary-box-inner">
<span><p>We often wish to classify objects by their shapes. Indeed, the study of
shapes is an important part of many scientific fields such as evolutionary
biology, structural biology, image processing, and archaeology. The most
widely-used method of shape analysis, Geometric Morphometrics, assumes that
that the mathematical space in which shapes are represented is linear. However,
it has long been known that shape space is, in fact, rather more complicated,
and certainly non-linear. Diffeomorphic methods that take this non-linearity
into account, and so give more accurate estimates of the distances among
shapes, exist but have rarely been applied to real-world problems. Using a
machine classifier, we tested the ability of several of these methods to
describe and classify the shapes of a variety of organic and man-made objects.
We find that one method, the Square-Root Velocity Function (SRVF), is superior
to all others, including a standard Geometric Morphometric method
(eigenshapes). We also show that computational shape classifiers outperform
human experts, and that the SRVF shortest-path between shapes can be used to
estimate the shapes of intermediate steps in evolutionary series. Diffeomorphic
shape analysis methods, we conclude, now provide practical and effective
solutions to many shape description and classification problems in the natural
and human sciences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ideals and Virtual Realities. (arXiv:2109.00926v1 [physics.ed-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00926">
<div class="article-summary-box-inner">
<span><p>A main step for world progress is to keep sharing ever-present Ideals for
science and education within today Virtual Realities. On-line education is
transforming human society to new levels in the way people teach and learn
during the ongoing SARS-CoV-2 pandemic. There is an increasing interest in
having more and more reliable, fast and simple apps to communicate and also to
record, assemble and distribute videos and lectures in the fields of Physics &amp;
Maths still using traditional didactic methods. We describe here how to
accurately reproduce chalkboard classes for the popular YouTube video platform
using OpenEyA-YT. The audience can thus be expanded over continents to help
mitigate the effects of physical isolation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Autonomous Curiosity for Real-Time Training Onboard Robotic Agents. (arXiv:2109.00927v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00927">
<div class="article-summary-box-inner">
<span><p>Learning requires both study and curiosity. A good learner is not only good
at extracting information from the data given to it, but also skilled at
finding the right new information to learn from. This is especially true when a
human operator is required to provide the ground truth - such a source should
only be queried sparingly. In this work, we address the problem of curiosity as
it relates to online, real-time, human-in-the-loop training of an object
detection algorithm onboard a robotic platform, one where motion produces new
views of the subject. We propose a deep reinforcement learning approach that
decides when to ask the human user for ground truth, and when to move. Through
a series of experiments, we demonstrate that our agent learns a movement and
request policy that is at least 3x more effective at using human user
interactions to train an object detector than untrained approaches, and is
generalizable to a variety of subjects and environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Impact of Attention on Adversarial Robustness of Image Classification Models. (arXiv:2109.00936v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00936">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks against deep learning models have gained significant
attention and recent works have proposed explanations for the existence of
adversarial examples and techniques to defend the models against these attacks.
Attention in computer vision has been used to incorporate focused learning of
important features and has led to improved accuracy. Recently, models with
attention mechanisms have been proposed to enhance adversarial robustness.
Following this context, this work aims at a general understanding of the impact
of attention on adversarial robustness. This work presents a comparative study
of adversarial robustness of non-attention and attention based image
classification models trained on CIFAR-10, CIFAR-100 and Fashion MNIST datasets
under the popular white box and black box attacks. The experimental results
show that the robustness of attention based models may be dependent on the
datasets used i.e. the number of classes involved in the classification. In
contrast to the datasets with less number of classes, attention based models
are observed to show better robustness towards classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SetMargin Loss applied to Deep Keystroke Biometrics with Circle Packing Interpretation. (arXiv:2109.00938v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00938">
<div class="article-summary-box-inner">
<span><p>This work presents a new deep learning approach for keystroke biometrics
based on a novel Distance Metric Learning method (DML). DML maps input data
into a learned representation space that reveals a "semantic" structure based
on distances. In this work, we propose a novel DML method specifically designed
to address the challenges associated to free-text keystroke identification
where the classes used in learning and inference are disjoint. The proposed
SetMargin Loss (SM-L) extends traditional DML approaches with a learning
process guided by pairs of sets instead of pairs of samples, as done
traditionally. The proposed learning strategy allows to enlarge inter-class
distances while maintaining the intra-class structure of keystroke dynamics. We
analyze the resulting representation space using the mathematical problem known
as Circle Packing, which provides neighbourhood structures with a theoretical
maximum inter-class distance. We finally prove experimentally the effectiveness
of the proposed approach on a challenging task: keystroke biometric
identification over a large set of 78,000 subjects. Our method achieves
state-of-the-art accuracy on a comparison performed with the best existing
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Robustness for Unsupervised Domain Adaptation. (arXiv:2109.00946v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00946">
<div class="article-summary-box-inner">
<span><p>Extensive Unsupervised Domain Adaptation (UDA) studies have shown great
success in practice by learning transferable representations across a labeled
source domain and an unlabeled target domain with deep models. However,
previous works focus on improving the generalization ability of UDA models on
clean examples without considering the adversarial robustness, which is crucial
in real-world applications. Conventional adversarial training methods are not
suitable for the adversarial robustness on the unlabeled target domain of UDA
since they train models with adversarial examples generated by the supervised
loss function. In this work, we leverage intermediate representations learned
by multiple robust ImageNet models to improve the robustness of UDA models. Our
method works by aligning the features of the UDA model with the robust features
learned by ImageNet pre-trained models along with domain adaptation training.
It utilizes both labeled and unlabeled domains and instills robustness without
any adversarial intervention or label requirement during domain adaptation
training. Experimental results show that our method significantly improves
adversarial robustness compared to the baseline while keeping clean accuracy on
various UDA benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAM: Explainable Visual Similarity and Classification via Gradient Activation Maps. (arXiv:2109.00951v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00951">
<div class="article-summary-box-inner">
<span><p>We present Gradient Activation Maps (GAM) - a machinery for explaining
predictions made by visual similarity and classification models. By gleaning
localized gradient and activation information from multiple network layers, GAM
offers improved visual explanations, when compared to existing alternatives.
The algorithmic advantages of GAM are explained in detail, and validated
empirically, where it is shown that GAM outperforms its alternatives across
various tasks and datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TrouSPI-Net: Spatio-temporal attention on parallel atrous convolutions and U-GRUs for skeletal pedestrian crossing prediction. (arXiv:2109.00953v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00953">
<div class="article-summary-box-inner">
<span><p>Understanding the behaviors and intentions of pedestrians is still one of the
main challenges for vehicle autonomy, as accurate predictions of their
intentions can guarantee their safety and driving comfort of vehicles. In this
paper, we address pedestrian crossing prediction in urban traffic environments
by linking the dynamics of a pedestrian's skeleton to a binary crossing
intention. We introduce TrouSPI-Net: a context-free, lightweight, multi-branch
predictor. TrouSPI-Net extracts spatio-temporal features for different time
resolutions by encoding pseudo-images sequences of skeletal joints' positions
and processes them with parallel attention modules and atrous convolutions. The
proposed approach is then enhanced by processing features such as relative
distances of skeletal joints, bounding box positions, or ego-vehicle speed with
U-GRUs. Using the newly proposed evaluation procedures for two large public
naturalistic data sets for studying pedestrian behavior in traffic: JAAD and
PIE, we evaluate TrouSPI-Net and analyze its performance. Experimental results
show that TrouSPI-Net achieved 0.76 F1 score on JAAD and 0.80 F1 score on PIE,
therefore outperforming current state-of-the-art while being lightweight and
context-free.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sk-Unet Model with Fourier Domain for Mitosis Detection. (arXiv:2109.00957v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00957">
<div class="article-summary-box-inner">
<span><p>Mitotic count is the most important morphological feature of breast cancer
grading. Many deep learning-based methods have been proposed but suffer from
domain shift. In this work, we construct a Fourier-based segmentation model for
mitosis detection to address the problem. Swapping the low-frequency spectrum
of source and target images is shown effective to alleviate the discrepancy
between different scanners. Our Fourier-based segmentation method can achieve
F1 with 0.7456 on the preliminary test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Infrared Image Super-Resolution via Heterogeneous Convolutional WGAN. (arXiv:2109.00960v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00960">
<div class="article-summary-box-inner">
<span><p>Image super-resolution is important in many fields, such as surveillance and
remote sensing. However, infrared (IR) images normally have low resolution
since the optical equipment is relatively expensive. Recently, deep learning
methods have dominated image super-resolution and achieved remarkable
performance on visible images; however, IR images have received less attention.
IR images have fewer patterns, and hence, it is difficult for deep neural
networks (DNNs) to learn diverse features from IR images. In this paper, we
present a framework that employs heterogeneous convolution and adversarial
training, namely, heterogeneous kernel-based super-resolution Wasserstein GAN
(HetSRWGAN), for IR image super-resolution. The HetSRWGAN algorithm is a
lightweight GAN architecture that applies a plug-and-play heterogeneous
kernel-based residual block. Moreover, a novel loss function that employs image
gradients is adopted, which can be applied to an arbitrary model. The proposed
HetSRWGAN achieves consistently better performance in both qualitative and
quantitative evaluations. According to the experimental results, the whole
training process is more stable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptive Cascade R-CNN for MItosis DOmain Generalization (MIDOG) Challenge. (arXiv:2109.00965v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00965">
<div class="article-summary-box-inner">
<span><p>We present a summary of the domain adaptive cascade R-CNN method for mitosis
detection of digital histopathology images. By comprehensive data augmentation
and adapting existing popular detection architecture, our proposed method has
achieved an F1 score of 0.7500 on the preliminary test set in MItosis DOmain
Generalization (MIDOG) Challenge at MICCAI2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate shape and phase averaging of time series through Dynamic Time Warping. (arXiv:2109.00978v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00978">
<div class="article-summary-box-inner">
<span><p>We propose a novel time series averaging method based on Dynamic Time Warping
(DTW). In contrast to previous methods, our algorithm preserves durational
information and the distinctive durational features of the sequences due to a
simple conversion of the output of DTW into a time sequence and an innovative
iterative averaging process. We show that it accurately estimates the ground
truth mean sequences and mean temporal location of landmarks in synthetic and
real-world datasets and outperforms state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Scene Novel View Synthesis via Deferred Spatio-temporal Consistency. (arXiv:2109.01018v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01018">
<div class="article-summary-box-inner">
<span><p>Structure from motion (SfM) enables us to reconstruct a scene via casual
capture from cameras at different viewpoints, and novel view synthesis (NVS)
allows us to render a captured scene from a new viewpoint. Both are hard with
casual capture and dynamic scenes: SfM produces noisy and spatio-temporally
sparse reconstructed point clouds, resulting in NVS with spatio-temporally
inconsistent effects. We consider SfM and NVS parts together to ease the
challenge. First, for SfM, we recover stable camera poses, then we defer the
requirement for temporally-consistent points across the scene and reconstruct
only a sparse point cloud per timestep that is noisy in space-time. Second, for
NVS, we present a variational diffusion formulation on depths and colors that
lets us robustly cope with the noise by enforcing spatio-temporal consistency
via per-pixel reprojection weights derived from the input views. Together, this
deferred approach generates novel views for dynamic scenes without requiring
challenging spatio-temporally consistent reconstructions nor training complex
models on large datasets. We demonstrate our algorithm on real-world dynamic
scenes against classic and more recent learning-based baseline approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extended Object Tracking Using Sets Of Trajectories with a PHD Filter. (arXiv:2109.01019v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01019">
<div class="article-summary-box-inner">
<span><p>PHD filtering is a common and effective multiple object tracking (MOT)
algorithm used in scenarios where the number of objects and their states are
unknown. In scenarios where each object can generate multiple measurements per
scan, some PHD filters can estimate the extent of the objects as well as their
kinematic properties. Most of these approaches are, however, not able to
inherently estimate trajectories and rely on ad-hoc methods, such as different
labeling schemes, to build trajectories from the state estimates. This paper
presents a Gamma Gaussian inverse Wishart mixture PHD filter that can directly
estimate sets of trajectories of extended targets by expanding previous
research on tracking sets of trajectories for point source objects to handle
extended objects. The new filter is compared to an existing extended PHD filter
that uses a labeling scheme to build trajectories, and it is shown that the new
filter can estimate object trajectories more reliably.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scene Text recognition with Full Normalization. (arXiv:2109.01034v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01034">
<div class="article-summary-box-inner">
<span><p>Scene text recognition has made significant progress in recent years and has
become an important part of the work-flow. The widespread use of mobile devices
opens up wide possibilities for using OCR technologies in everyday life.
However, lack of training data for new research in this area remains relevant.
In this article, we present a new dataset consisting of real shots on
smartphones and demonstrate the effectiveness of profile normalization in this
task. In addition, the influence of various augmentations during the training
of models for analyzing document images on smartphones is studied in detail.
Our dataset is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shot boundary detection method based on a new extensive dataset and mixed features. (arXiv:2109.01057v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01057">
<div class="article-summary-box-inner">
<span><p>Shot boundary detection in video is one of the key stages of video data
processing. A new method for shot boundary detection based on several video
features, such as color histograms and object boundaries, has been proposed.
The developed algorithm was tested on the open BBC Planet Earth [1] and RAI [2]
datasets, and the MSU CC datasets, based on videos used in the video codec
comparison conducted at MSU, as well as videos from the IBM set, were also
plotted. The total dataset for algorithm development and testing exceeded the
known TRECVID datasets. Based on the test results, the proposed algorithm for
scene change detection outperformed its counterparts with a final F-score of
0.9794.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">4D-Net for Learned Multi-Modal Alignment. (arXiv:2109.01066v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01066">
<div class="article-summary-box-inner">
<span><p>We present 4D-Net, a 3D object detection approach, which utilizes 3D Point
Cloud and RGB sensing information, both in time. We are able to incorporate the
4D information by performing a novel dynamic connection learning across various
feature representations and levels of abstraction, as well as by observing
geometric constraints. Our approach outperforms the state-of-the-art and strong
baselines on the Waymo Open Dataset. 4D-Net is better able to use motion cues
and dense image information to detect distant objects more successfully.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SLIDE: Single Image 3D Photography with Soft Layering and Depth-aware Inpainting. (arXiv:2109.01068v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01068">
<div class="article-summary-box-inner">
<span><p>Single image 3D photography enables viewers to view a still image from novel
viewpoints. Recent approaches combine monocular depth networks with inpainting
networks to achieve compelling results. A drawback of these techniques is the
use of hard depth layering, making them unable to model intricate appearance
details such as thin hair-like structures. We present SLIDE, a modular and
unified system for single image 3D photography that uses a simple yet effective
soft layering strategy to better preserve appearance details in novel views. In
addition, we propose a novel depth-aware training strategy for our inpainting
module, better suited for the 3D photography task. The resulting SLIDE approach
is modular, enabling the use of other components such as segmentation and
matting for improved layering. At the same time, SLIDE uses an efficient
layered depth formulation that only requires a single forward pass through the
component networks to produce high quality 3D photos. Extensive experimental
analysis on three view-synthesis datasets, in combination with user studies on
in-the-wild image collections, demonstrate superior performance of our
technique in comparison to existing strong baselines while being conceptually
much simpler. Project page: https://varunjampani.github.io/slide
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards disease-aware image editing of chest X-rays. (arXiv:2109.01071v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01071">
<div class="article-summary-box-inner">
<span><p>Disease-aware image editing by means of generative adversarial networks
(GANs) constitutes a promising avenue for advancing the use of AI in the
healthcare sector. Here, we present a proof of concept of this idea. While
GAN-based techniques have been successful in generating and manipulating
natural images, their application to the medical domain, however, is still in
its infancy. Working with the CheXpert data set, we show that StyleGAN can be
trained to generate realistic chest X-rays. Inspired by the Cyclic Reverse
Generator (CRG) framework, we train an encoder that allows for faithfully
inverting the generator on synthetic X-rays and provides organ-level
reconstructions of real ones. Employing a guided manipulation of latent codes,
we confer the medical condition of cardiomegaly (increased heart size) onto
real X-rays from healthy patients. This work was presented in the Medical
Imaging meets Neurips Workshop 2020, which was held as part of the 34th
Conference on Neural Information Processing Systems (NeurIPS 2020) in
Vancouver, Canada
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cascade RCNN for MIDOG Challenge. (arXiv:2109.01085v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01085">
<div class="article-summary-box-inner">
<span><p>Mitotic counts are one of the key indicators of breast cancer prognosis.
However, accurate mitotic cell counting is still a difficult problem and is
labourious. Automated methods have been proposed for this task, but are usually
dependent on the training images and show poor performance on unseen domains.
In this work, we present a multi-stage mitosis detection method based on a
Cascade RCNN developed to be sequentially more selective against false
positives. On the preliminary test set, the algorithm scores an F1-score of
0.7492.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On-target Adaptation. (arXiv:2109.01087v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01087">
<div class="article-summary-box-inner">
<span><p>Domain adaptation seeks to mitigate the shift between training on the
\emph{source} domain and testing on the \emph{target} domain. Most adaptation
methods rely on the source data by joint optimization over source data and
target data. Source-free methods replace the source data with a source model by
fine-tuning it on target. Either way, the majority of the parameter updates for
the model representation and the classifier are derived from the source, and
not the target. However, target accuracy is the goal, and so we argue for
optimizing as much as possible on the target data. We show significant
improvement by on-target adaptation, which learns the representation purely
from target data while taking only the source predictions for supervision. In
the long-tailed classification setting, we show further improvement by
on-target class distribution learning, which learns the (im)balance of classes
from target data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Functional Correspondence Problem. (arXiv:2109.01097v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01097">
<div class="article-summary-box-inner">
<span><p>The ability to find correspondences in visual data is the essence of most
computer vision tasks. But what are the right correspondences? The task of
visual correspondence is well defined for two different images of same object
instance. In case of two images of objects belonging to same category, visual
correspondence is reasonably well-defined in most cases. But what about
correspondence between two objects of completely different category -- e.g., a
shoe and a bottle? Does there exist any correspondence? Inspired by humans'
ability to: (a) generalize beyond semantic categories and; (b) infer functional
affordances, we introduce the problem of functional correspondences in this
paper. Given images of two objects, we ask a simple question: what is the set
of correspondences between these two images for a given task? For example, what
are the correspondences between a bottle and shoe for the task of pounding or
the task of pouring. We introduce a new dataset: FunKPoint that has ground
truth correspondences for 10 tasks and 20 object categories. We also introduce
a modular task-driven representation for attacking this problem and demonstrate
that our learned representation is effective for this task. But most
importantly, because our supervision signal is not bound by semantics, we show
that our learned representation can generalize better on few-shot
classification problem. We hope this paper will inspire our community to think
beyond semantics and focus more on cross-category generalization and learning
representations for robotics tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking the Robustness of Instance Segmentation Models. (arXiv:2109.01123v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01123">
<div class="article-summary-box-inner">
<span><p>This paper presents a comprehensive evaluation of instance segmentation
models with respect to real-world image corruptions and out-of-domain image
collections, e.g. datasets collected with different set-ups than the training
datasets the models learned from. The out-of-domain image evaluation shows the
generalization capability of models, an essential aspect of real-world
applications, and an extensively studied topic of domain adaptation. These
presented robustness and generalization evaluations are important when
designing instance segmentation models for real-world applications and picking
an off-the-shelf pretrained model to directly use for the task at hand.
Specifically, this benchmark study includes state-of-the-art network
architectures, network backbones, normalization layers, models trained starting
from scratch or ImageNet pretrained networks, and the effect of multi-task
training on robustness and generalization. Through this study, we gain several
insights e.g. we find that normalization layers play an essential role in
robustness, ImageNet pretraining does not help the robustness and the
generalization of models, excluding JPEG corruption, and network backbones and
copy-paste augmentations affect robustness significantly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-Robust Mitotic Figure Detection with StyleGAN. (arXiv:2109.01124v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01124">
<div class="article-summary-box-inner">
<span><p>We propose a new training scheme for domain generalization in mitotic figure
detection. By considering the image variance due to different scanner types as
different image styles, we have trained our detection network to be robust on
scanner types. To expand the image variance, domain of training image is
transferred into arbitrary domain. The proposed style transfer module generates
different styled images from an input image with random code, eventually
generating variously styled images. Our model with the proposed training scheme
shows good performance on MIDOG Preliminary Test-Set containing scanners never
seen before.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-view Stereo. (arXiv:2109.01129v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01129">
<div class="article-summary-box-inner">
<span><p>In this work, we present a new multi-view depth estimation method that
utilizes both conventional SfM reconstruction and learning-based priors over
the recently proposed neural radiance fields (NeRF). Unlike existing neural
network based optimization method that relies on estimated correspondences, our
method directly optimizes over implicit volumes, eliminating the challenging
step of matching pixels in indoor scenes. The key to our approach is to utilize
the learning-based priors to guide the optimization process of NeRF. Our system
firstly adapts a monocular depth network over the target scene by finetuning on
its sparse SfM reconstruction. Then, we show that the shape-radiance ambiguity
of NeRF still exists in indoor environments and propose to address the issue by
employing the adapted depth priors to monitor the sampling process of volume
rendering. Finally, a per-pixel confidence map acquired by error computation on
the rendered image can be used to further improve the depth quality.
Experiments show that our proposed framework significantly outperforms
state-of-the-art methods on indoor scenes, with surprising findings presented
on the effectiveness of correspondence-based optimization and NeRF-based
optimization over the adapted depth priors. In addition, we show that the
guided optimization scheme does not sacrifice the original synthesis capability
of neural radiance fields, improving the rendering quality on both seen and
novel views. Code is available at https://github.com/weiyithu/NerfingMVS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Semi-Automated Algorithm for Volumetric Segmentation of the Left Ventricle in Temporal 3D Echocardiography Sequences. (arXiv:2109.01132v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01132">
<div class="article-summary-box-inner">
<span><p>Purpose: Echocardiography is commonly used as a non-invasive imaging tool in
clinical practice for the assessment of cardiac function. However, delineation
of the left ventricle is challenging due to the inherent properties of
ultrasound imaging, such as the presence of speckle noise and the low
signal-to-noise ratio. Methods: We propose a semi-automated segmentation
algorithm for the delineation of the left ventricle in temporal 3D
echocardiography sequences. The method requires minimal user interaction and
relies on a diffeomorphic registration approach. Advantages of the method
include no dependence on prior geometrical information, training data, or
registration from an atlas. Results: The method was evaluated using
three-dimensional ultrasound scan sequences from 18 patients from the
Mazankowski Alberta Heart Institute, Edmonton, Canada, and compared to manual
delineations provided by an expert cardiologist and four other registration
algorithms. The segmentation approach yielded the following results over the
cardiac cycle: a mean absolute difference of 1.01 (0.21) mm, a Hausdorff
distance of 4.41 (1.43) mm, and a Dice overlap score of 0.93 (0.02).
Conclusions: The method performed well compared to the four other registration
algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01134">
<div class="article-summary-box-inner">
<span><p>Vision-language pre-training has recently emerged as a promising alternative
for representation learning. It shifts from the tradition of using images and
discrete labels for learning a fixed set of weights, seen as visual concepts,
to aligning images and raw text for two separate encoders. Such a paradigm
benefits from a broader source of supervision and allows zero-shot transfer to
downstream tasks since visual concepts can be diametrically generated from
natural language, known as prompt. In this paper, we identify that a major
challenge of deploying such models in practice is prompt engineering. This is
because designing a proper prompt, especially for context words surrounding a
class name, requires domain expertise and typically takes a significant amount
of time for words tuning since a slight change in wording could have a huge
impact on performance. Moreover, different downstream tasks require specific
designs, further hampering the efficiency of deployment. To overcome this
challenge, we propose a novel approach named context optimization (CoOp). The
main idea is to model context in prompts using continuous representations and
perform end-to-end learning from data while keeping the pre-trained parameters
fixed. In this way, the design of task-relevant prompts can be fully automated.
Experiments on 11 datasets show that CoOp effectively turns pre-trained
vision-language models into data-efficient visual learners, requiring as few as
one or two shots to beat hand-crafted prompts with a decent margin and able to
gain significant improvements when using more shots (e.g., at 16 shots the
average gain is around 17% with the highest reaching over 50%). CoOp also
exhibits strong robustness to distribution shift.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Power of Points for Modeling Humans in Clothing. (arXiv:2109.01137v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01137">
<div class="article-summary-box-inner">
<span><p>Currently it requires an artist to create 3D human avatars with realistic
clothing that can move naturally. Despite progress on 3D scanning and modeling
of human bodies, there is still no technology that can easily turn a static
scan into an animatable avatar. Automating the creation of such avatars would
enable many applications in games, social networking, animation, and AR/VR to
name a few. The key problem is one of representation. Standard 3D meshes are
widely used in modeling the minimally-clothed body but do not readily capture
the complex topology of clothing. Recent interest has shifted to implicit
surface models for this task but they are computationally heavy and lack
compatibility with existing 3D tools. What is needed is a 3D representation
that can capture varied topology at high resolution and that can be learned
from data. We argue that this representation has been with us all along -- the
point cloud. Point clouds have properties of both implicit and explicit
representations that we exploit to model 3D garment geometry on a human body.
We train a neural network with a novel local clothing geometric feature to
represent the shape of different outfits. The network is trained from 3D point
clouds of many types of clothing, on many bodies, in many poses, and learns to
model pose-dependent clothing deformations. The geometry feature can be
optimized to fit a previously unseen scan of a person in clothing, enabling the
scan to be reposed realistically. Our model demonstrates superior quantitative
and qualitative results in both multi-outfit modeling and unseen outfit
animation. The code is available for research purposes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Integrated Gradients with SmoothTaylor for Deep Neural Network Attribution. (arXiv:2004.10484v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.10484">
<div class="article-summary-box-inner">
<span><p>Integrated Gradients as an attribution method for deep neural network models
offers simple implementability. However, it suffers from noisiness of
explanations which affects the ease of interpretability. The SmoothGrad
technique is proposed to solve the noisiness issue and smoothen the attribution
maps of any gradient-based attribution method. In this paper, we present
SmoothTaylor as a novel theoretical concept bridging Integrated Gradients and
SmoothGrad, from the Taylor's theorem perspective. We apply the methods to the
image classification problem, using the ILSVRC2012 ImageNet object recognition
dataset, and a couple of pretrained image models to generate attribution maps.
These attribution maps are empirically evaluated using quantitative measures
for sensitivity and noise level. We further propose adaptive noising to
optimize for the noise scale hyperparameter value. From our experiments, we
find that the SmoothTaylor approach together with adaptive noising is able to
generate better quality saliency maps with lesser noise and higher sensitivity
to the relevant points in the input space as compared to Integrated Gradients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Manifold Alignment for Semantically Aligned Style Transfer. (arXiv:2005.10777v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.10777">
<div class="article-summary-box-inner">
<span><p>Most existing style transfer methods follow the assumption that styles can be
represented with global statistics (e.g., Gram matrices or covariance
matrices), and thus address the problem by forcing the output and style images
to have similar global statistics. An alternative is the assumption of local
style patterns, where algorithms are designed to swap similar local features of
content and style images. However, the limitation of these existing methods is
that they neglect the semantic structure of the content image which may lead to
corrupted content structure in the output. In this paper, we make a new
assumption that image features from the same semantic region form a manifold
and an image with multiple semantic regions follows a multi-manifold
distribution. Based on this assumption, the style transfer problem is
formulated as aligning two multi-manifold distributions and a Manifold
Alignment based Style Transfer (MAST) framework is proposed. The proposed
framework allows semantically similar regions between the output and the style
image share similar style patterns. Moreover, the proposed manifold alignment
method is flexible to allow user editing or using semantic segmentation maps as
guidance for style transfer. To allow the method to be applicable to
photorealistic style transfer, we propose a new adaptive weight skip connection
network structure to preserve the content details. Extensive experiments verify
the effectiveness of the proposed framework for both artistic and
photorealistic style transfer. Code is available at
https://github.com/NJUHuoJing/MAST.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Reconstruction of Novel Object Shapes from Single Images. (arXiv:2006.07752v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07752">
<div class="article-summary-box-inner">
<span><p>Accurately predicting the 3D shape of any arbitrary object in any pose from a
single image is a key goal of computer vision research. This is challenging as
it requires a model to learn a representation that can infer both the visible
and occluded portions of any object using a limited training set. A training
set that covers all possible object shapes is inherently infeasible. Such
learning-based approaches are inherently vulnerable to overfitting, and
successfully implementing them is a function of both the architecture design
and the training approach. We present an extensive investigation of factors
specific to architecture design, training, experiment design, and evaluation
that influence reconstruction performance and measurement. We show that our
proposed SDFNet achieves state-of-the-art performance on seen and unseen shapes
relative to existing methods GenRe and OccNet. We provide the first large-scale
evaluation of single image shape reconstruction to unseen objects. The source
code, data and trained models can be found on
https://github.com/rehg-lab/3DShapeGen.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Bayesian Evaluation Framework for Subjectively Annotated Visual Recognition Tasks. (arXiv:2007.06711v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06711">
<div class="article-summary-box-inner">
<span><p>An interesting development in automatic visual recognition has been the
emergence of tasks where it is not possible to assign objective labels to
images, yet still feasible to collect annotations that reflect human judgements
about them. Machine learning-based predictors for these tasks rely on
supervised training that models the behavior of the annotators, i.e., what
would the average person's judgement be for an image? A key open question for
this type of work, especially for applications where inconsistency with human
behavior can lead to ethical lapses, is how to evaluate the epistemic
uncertainty of trained predictors, i.e., the uncertainty that comes from the
predictor's model. We propose a Bayesian framework for evaluating black box
predictors in this regime, agnostic to the predictor's internal structure. The
framework specifies how to estimate the epistemic uncertainty that comes from
the predictor with respect to human labels by approximating a conditional
distribution and producing a credible interval for the predictions and their
measures of performance. The framework is successfully applied to four image
classification tasks that use subjective human judgements: facial beauty
assessment, social attribute assignment, apparent age estimation, and ambiguous
scene labeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable-by-design Semi-Supervised Representation Learning for COVID-19 Diagnosis from CT Imaging. (arXiv:2011.11719v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11719">
<div class="article-summary-box-inner">
<span><p>Our motivating application is a real-world problem: COVID-19 classification
from CT imaging, for which we present an explainable Deep Learning approach
based on a semi-supervised classification pipeline that employs variational
autoencoders to extract efficient feature embedding. We have optimized the
architecture of two different networks for CT images: (i) a novel conditional
variational autoencoder (CVAE) with a specific architecture that integrates the
class labels inside the encoder layers and uses side information with shared
attention layers for the encoder, which make the most of the contextual clues
for representation learning, and (ii) a downstream convolutional neural network
for supervised classification using the encoder structure of the CVAE. With the
explainable classification results, the proposed diagnosis system is very
effective for COVID-19 classification. Based on the promising results obtained
qualitatively and quantitatively, we envisage a wide deployment of our
developed technique in large-scale clinical studies.Code is available at
https://git.etrovub.be/AVSP/ct-based-covid-19-diagnostic-tool.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">USCL: Pretraining Deep Ultrasound Image Diagnosis Model through Video Contrastive Representation Learning. (arXiv:2011.13066v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13066">
<div class="article-summary-box-inner">
<span><p>Most deep neural networks (DNNs) based ultrasound (US) medical image analysis
models use pretrained backbones (e.g., ImageNet) for better model
generalization. However, the domain gap between natural and medical images
causes an inevitable performance bottleneck. To alleviate this problem, an US
dataset named US-4 is constructed for direct pretraining on the same domain. It
contains over 23,000 images from four US video sub-datasets. To learn robust
features from US-4, we propose an US semi-supervised contrastive learning
method, named USCL, for pretraining. In order to avoid high similarities
between negative pairs as well as mine abundant visual features from limited US
videos, USCL adopts a sample pair generation method to enrich the feature
involved in a single step of contrastive optimization. Extensive experiments on
several downstream tasks show the superiority of USCL pretraining against
ImageNet pretraining and other state-of-the-art (SOTA) pretraining approaches.
In particular, USCL pretrained backbone achieves fine-tuning accuracy of over
94% on POCUS dataset, which is 10% higher than 84% of the ImageNet pretrained
model. The source codes of this work are available at
https://github.<a href="/abs/com/9836328">com/9836328</a>47/USCL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Siamese Basis Function Networks for Data-efficient Defect Classification in Technical Domains. (arXiv:2012.01338v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01338">
<div class="article-summary-box-inner">
<span><p>Training deep learning models in technical domains is often accompanied by
the challenge that although the task is clear, insufficient data for training
is available. In this work, we propose a novel approach based on the
combination of Siamese networks and radial basis function networks to perform
data-efficient classification without pretraining by measuring the distance
between images in semantic space in a data-efficient manner. We develop the
models using three technical datasets, the NEU dataset, the BSD dataset, and
the TEX dataset. In addition to the technical domain, we show the general
applicability to classical datasets (cifar10 and MNIST) as well. The approach
is tested against state-of-the-art models (Resnet50 and Resnet101) by stepwise
reduction of the number of samples available for training. The authors show
that the proposed approach outperforms the state-of-the-art models in the low
data regime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factorizing Perception and Policy for Interactive Instruction Following. (arXiv:2012.03208v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03208">
<div class="article-summary-box-inner">
<span><p>Performing simple household tasks based on language directives is very
natural to humans, yet it remains an open challenge for AI agents. The
'interactive instruction following' task attempts to make progress towards
building agents that jointly navigate, interact, and reason in the environment
at every step. To address the multifaceted problem, we propose a model that
factorizes the task into interactive perception and action policy streams with
enhanced components and name it as MOCA, a Modular Object-Centric Approach. We
empirically validate that MOCA outperforms prior arts by significant margins on
the ALFRED benchmark with improved generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effect of the regularization hyperparameter on deep learning-based segmentation in LGE-MRI. (arXiv:2012.05661v5 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05661">
<div class="article-summary-box-inner">
<span><p>The extent to which the arbitrarily selected L2 regularization hyperparameter
value affects the outcome of semantic segmentation with deep learning is
demonstrated. Demonstrations rely on training U-net on small LGE-MRI datasets
using the arbitrarily selected L2 regularization values. The remaining
hyperparameters are to be manually adjusted or tuned only when 10 % of all
epochs are reached before the training validation accuracy reaches 90%.
Semantic segmentation with deep learning outcomes are objectively and
subjectively evaluated against the manual ground truth segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of deep learning-based myocardial infarction quantification using Segment CMR software. (arXiv:2012.09070v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09070">
<div class="article-summary-box-inner">
<span><p>This work evaluates deep learning-based myocardial infarction (MI)
quantification using Segment cardiovascular magnetic resonance (CMR) software.
Segment CMR software incorporates the expectation-maximization, weighted
intensity, a priori information (EWA) algorithm used to generate the infarct
scar volume, infarct scar percentage, and microvascular obstruction percentage.
Here, Segment CMR software segmentation algorithm is updated with semantic
segmentation with U-net to achieve and evaluate fully automated or deep
learning-based MI quantification. The direct observation of graphs and the
number of infarcted and contoured myocardium are two options used to estimate
the relationship between deep learning-based MI quantification and medical
expert-based results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Opti-Enc: On the Path to the Optimal Encoder-Decoder for Thermal Image Colorization for Cross Domain Colorized Images. (arXiv:2101.06910v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06910">
<div class="article-summary-box-inner">
<span><p>Thermal images can be obtained as either grayscale images or pseudo colored
images based on the thermal profile of the object being captured. In this work,
we explore what an optimal encoder decoder might look like for creating a
thermal-optical fused domain image. We compare the results from several
different encoder-decoder structures with different networks to answer this
question. This output images obtained from our method provides information of
both domains jointly in a colorized image. We call this a cross domain
colorized image. We also present a robust registration method for thermal and
optical pairs, which can work despite changes in resolution and the make of the
thermal imager. Lastly, we present a unique public dataset with registered
thermal-visual image pairs containing around 1800 images as a part of this
work, collected over a period of 2 years. We compare our results with prior
literature, show how our results are different and discuss on some future work
that can be explored further in this domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TLRM: Task-level Relation Module for GNN-based Few-Shot Learning. (arXiv:2101.09840v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09840">
<div class="article-summary-box-inner">
<span><p>Recently, graph neural networks (GNNs) have shown powerful ability to handle
few-shot classification problem, which aims at classifying unseen samples when
trained with limited labeled samples per class. GNN-based few-shot learning
architectures mostly replace traditional metric with a learnable GNN. In the
GNN, the nodes are set as the samples embedding, and the relationship between
two connected nodes can be obtained by a network, the input of which is the
difference of their embedding features. We consider this method of measuring
relation of samples only models the sample-to-sample relation, while neglects
the specificity of different tasks. That is, this method of measuring relation
does not take the task-level information into account. To this end, we propose
a new relation measure method, namely the task-level relation module (TLRM), to
explicitly model the task-level relation of one sample to all the others. The
proposed module captures the relation representations between nodes by
considering the sample-to-task instead of sample-to-sample embedding features.
We conducted extensive experiments on four benchmark datasets: mini-ImageNet,
tiered-ImageNet, CUB-$200$-$2011$, and CIFAR-FS. Experimental results
demonstrate that the proposed module is effective for GNN-based few-shot
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Combat Noisy Labels via Classification Margins. (arXiv:2102.00751v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00751">
<div class="article-summary-box-inner">
<span><p>A deep neural network trained on noisy labels is known to quickly lose its
power to discriminate clean instances from noisy ones. After the early learning
phase has ended, the network memorizes the noisy instances, which leads to a
significant degradation in its generalization performance. To resolve this
issue, we propose MARVEL (MARgins Via Early Learning), a new robust learning
method where the memorization of the noisy instances is curbed. We propose a
new test statistic that tracks the goodness of "fit" of every instance based on
the epoch-history of its classification margins. If its classification margin
is small in a sequence of consecutive learning epochs, that instance is
declared noisy and the network abandons learning on it. Consequently, the
network first flags a possibly noisy instance, and then waits to see if
learning on that instance can be improved and if not, the network learns with
confidence that this instance can be safely abandoned. We also propose MARVEL+,
where arduous instances can be upweighted, enabling the network to focus and
improve its learning on them and consequently its generalization. Experimental
results on benchmark datasets with synthetic label noise and real-world
datasets show that MARVEL outperforms other baselines consistently across
different noise levels, with a significantly larger margin under asymmetric
noise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Real-World Adversarial Patches through 3D Modeling of Complex Target Scenes. (arXiv:2102.05334v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05334">
<div class="article-summary-box-inner">
<span><p>Adversarial examples have proven to be a concerning threat to deep learning
models, particularly in the image domain. However, while many studies have
examined adversarial examples in the real world, most of them relied on 2D
photos of the attack scene. As a result, the attacks proposed may have limited
effectiveness when implemented in realistic environments with 3D objects or
varied conditions. There are few studies on adversarial learning that use 3D
objects, and in many cases, other researchers are unable to replicate the
real-world evaluation process. In this study, we present a framework that uses
3D modeling to craft adversarial patches for an existing real-world scene. Our
approach uses a 3D digital approximation of the scene as a simulation of the
real world. With the ability to add and manipulate any element in the digital
scene, our framework enables the attacker to improve the adversarial patch's
impact in real-world settings. We use the framework to create a patch for an
everyday scene and evaluate its performance using a novel evaluation process
that ensures that our results are reproducible in both the digital space and
the real world. Our evaluation results show that the framework can generate
adversarial patches that are robust to different settings in the real world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">White Box Methods for Explanations of Convolutional Neural Networks in Image Classification Tasks. (arXiv:2104.02548v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02548">
<div class="article-summary-box-inner">
<span><p>In recent years, deep learning has become prevalent to solve applications
from multiple domains. Convolutional Neural Networks (CNNs) particularly have
demonstrated state of the art performance for the task of image classification.
However, the decisions made by these networks are not transparent and cannot be
directly interpreted by a human. Several approaches have been proposed to
explain to understand the reasoning behind a prediction made by a network. In
this paper, we propose a topology of grouping these methods based on their
assumptions and implementations. We focus primarily on white box methods that
leverage the information of the internal architecture of a network to explain
its decision. Given the task of image classification and a trained CNN, this
work aims to provide a comprehensive and detailed overview of a set of methods
that can be used to create explanation maps for a particular image, that assign
an importance score to each pixel of the image based on its contribution to the
decision of the network. We also propose a further classification of the white
box methods based on their implementations to enable better comparisons and
help researchers find methods best suited for different scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anomaly Detection with Prototype-Guided Discriminative Latent Embeddings. (arXiv:2104.14945v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14945">
<div class="article-summary-box-inner">
<span><p>Recent efforts towards video anomaly detection (VAD) try to learn a deep
autoencoder to describe normal event patterns with small reconstruction errors.
The video inputs with large reconstruction errors are regarded as anomalies at
the test time. However, these methods sometimes reconstruct abnormal inputs
well because of the powerful generalization ability of deep autoencoder. To
address this problem, we present a novel approach for anomaly detection, which
utilizes discriminative prototypes of normal data to reconstruct video frames.
In this way, the model will favor the reconstruction of normal events and
distort the reconstruction of abnormal events. Specifically, we use a
prototype-guided memory module to perform discriminative latent embedding. We
introduce a new discriminative criterion for the memory module, as well as a
loss function correspondingly, which can encourage memory items to record the
representative embeddings of normal data, i.e. prototypes. Besides, we design a
novel two-branch autoencoder, which is composed of a future frame prediction
network and an RGB difference generation network that share the same encoder.
The stacked RGB difference contains motion information just like optical flow,
so our model can learn temporal regularity. We evaluate the effectiveness of
our method on three benchmark datasets and experimental results demonstrate the
proposed method outperforms the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmenter: Transformer for Semantic Segmentation. (arXiv:2105.05633v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05633">
<div class="article-summary-box-inner">
<span><p>Image segmentation is often ambiguous at the level of individual image
patches and requires contextual information to reach label consensus. In this
paper we introduce Segmenter, a transformer model for semantic segmentation. In
contrast to convolution-based methods, our approach allows to model global
context already at the first layer and throughout the network. We build on the
recent Vision Transformer (ViT) and extend it to semantic segmentation. To do
so, we rely on the output embeddings corresponding to image patches and obtain
class labels from these embeddings with a point-wise linear decoder or a mask
transformer decoder. We leverage models pre-trained for image classification
and show that we can fine-tune them on moderate sized datasets available for
semantic segmentation. The linear decoder allows to obtain excellent results
already, but the performance can be further improved by a mask transformer
generating class masks. We conduct an extensive ablation study to show the
impact of the different parameters, in particular the performance is better for
large models and small patch sizes. Segmenter attains excellent results for
semantic segmentation. It outperforms the state of the art on both ADE20K and
Pascal Context datasets and is competitive on Cityscapes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FCCDN: Feature Constraint Network for VHR Image Change Detection. (arXiv:2105.10860v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10860">
<div class="article-summary-box-inner">
<span><p>Change detection is the process of identifying pixelwise differences in
bitemporal co-registered images. It is of great significance to Earth
observations. Recently, with the emergence of deep learning (DL), the power and
feasibility of deep convolutional neural network (CNN)-based methods have been
shown in the field of change detection. However, there is still a lack of
effective supervision for change feature learning. In this work, a feature
constraint change detection network (FCCDN) is proposed. We constrain features
both in bitemporal feature extraction and feature fusion. More specifically, we
propose a dual encoder-decoder network backbone for the change detection task.
At the center of the backbone, we design a nonlocal feature pyramid network to
extract and fuse multiscale features. To fuse bitemporal features in a robust
way, we build a dense connection-based feature fusion module. Moreover, a
self-supervised learning-based strategy is proposed to constrain feature
learning. Based on FCCDN, we achieve state-of-the-art performance on two
building change detection datasets (LEVIR-CD and WHU). On the LEVIR-CD dataset,
we achieve an IoU of 0.8569 and an F1 score of 0.9229. On the WHU dataset, we
achieve an IoU of 0.8820 and an F1 score of 0.9373. Moreover, for the first
time, the acquisition of accurate bitemporal semantic segmentation results is
achieved without using semantic segmentation labels. This is vital for the
application of change detection because it saves the cost of labeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridge the Gap Between Model-based and Model-free Human Reconstruction. (arXiv:2106.06313v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06313">
<div class="article-summary-box-inner">
<span><p>It is challenging to directly estimate the geometry of human from a single
image due to the high diversity and complexity of body shapes with the various
clothing styles. Most of model-based approaches are limited to predict the
shape and pose of a minimally clothed body with over-smoothing surface.
Although capturing the fine detailed geometries, the model-free methods are
lack of the fixed mesh topology. To address these issues, we propose a novel
topology-preserved human reconstruction approach by bridging the gap between
model-based and model-free human reconstruction. We present an end-to-end
neural network that simultaneously predicts the pixel-aligned implicit surface
and the explicit mesh model built by graph convolutional neural network.
Moreover, an extra graph convolutional neural network is employed to estimate
the vertex offsets between the implicit surface and parametric mesh model.
Finally, we suggest an efficient implicit registration method to refine the
neural network output in implicit space. Experiments on DeepHuman dataset
showed that our approach is effective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Advances in adversarial attacks and defenses in computer vision: A survey. (arXiv:2108.00401v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00401">
<div class="article-summary-box-inner">
<span><p>Deep Learning (DL) is the most widely used tool in the contemporary field of
computer vision. Its ability to accurately solve complex problems is employed
in vision research to learn deep neural models for a variety of tasks,
including security critical applications. However, it is now known that DL is
vulnerable to adversarial attacks that can manipulate its predictions by
introducing visually imperceptible perturbations in images and videos. Since
the discovery of this phenomenon in 2013~[1], it has attracted significant
attention of researchers from multiple sub-fields of machine intelligence. In
[2], we reviewed the contributions made by the computer vision community in
adversarial attacks on deep learning (and their defenses) until the advent of
year 2018. Many of those contributions have inspired new directions in this
area, which has matured significantly since witnessing the first generation
methods. Hence, as a legacy sequel of [2], this literature review focuses on
the advances in this area since 2018. To ensure authenticity, we mainly
consider peer-reviewed contributions published in the prestigious sources of
computer vision and machine learning research. Besides a comprehensive
literature review, the article also provides concise definitions of technical
terminologies for non-experts in this domain. Finally, this article discusses
challenges and future outlook of this direction based on the literature
reviewed herein and [2].
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leaf Recognition Using Convolutional Neural Networks Based Features. (arXiv:2108.01808v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01808">
<div class="article-summary-box-inner">
<span><p>There is a warning light for the loss of plant habitats worldwide that
entails concerted efforts to conserve plant biodiversity. Thus, plant species
classification is of crucial importance to address this environmental
challenge. In recent years, there is a considerable increase in the number of
studies related to plant taxonomy. While some researchers try to improve their
recognition performance using novel approaches, others concentrate on
computational optimization for their framework. In addition, a few studies are
diving into feature extraction to gain significantly in terms of accuracy. In
this paper, we propose an effective method for the leaf recognition problem. In
our proposed approach, a leaf goes through some pre-processing to extract its
refined color image, vein image, xy-projection histogram, handcrafted shape,
texture features, and Fourier descriptors. These attributes are then
transformed into a better representation by neural network-based encoders
before a support vector machine (SVM) model is utilized to classify different
leaves. Overall, our approach performs a state-of-the-art result on the Flavia
leaf dataset, achieving the accuracy of 99.58\% on test sets under random
10-fold cross-validation and bypassing the previous methods. We also release
our codes (Scripts are available at
https://github.com/dinhvietcuong1996/LeafRecognition) for contributing to the
research community in the leaf classification problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Efficient Dual-reference Training Data Acquisition Method for CNN-Based Image Super-Resolution. (arXiv:2108.02348v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02348">
<div class="article-summary-box-inner">
<span><p>For deep learning methods of image super-resolution, the most critical issue
is whether the paired low and high resolution images for training accurately
reflect the sampling process of real cameras. Low and high resolution
(LR$\sim$HR) image pairs synthesized by existing degradation models (e.g.
bicubic downsampling) deviate from those in reality; thus the super-resolution
CNN trained by these synthesized LR$\sim$HR image pairs does not perform well
when being applied to real images. In this paper, we propose a novel method to
capture a large set of realistic LR$\sim$HR image pairs using real cameras. The
data acquisition is carried out under controllable lab conditions with minimum
human intervention and at high throughput (about 500 image pairs per hour). The
high level of automation makes it easy to produce a set of real LR$\sim$HR
training image pairs for each camera.Our innovation is to shoot images
displayed on an ultra-high quality screen at different resolutions. There are
three distinctive advantages of our method for image super-resolution. First,
as the LR and HR images are taken of a 3D planar surface (the screen) the
registration problem fits exactly to a homography model and we can display
specially designed markers on the image to improve the registration precision.
Second, the displayed digital image file can be exploited as a reference to
optimize the high frequency content of the restored image. Third, this
high-efficiency data collection method makes it possible to collect a
customized dataset for each camera sensor, for which one can train a specific
model for the intended camera sensor. Experimental results show that training a
super-resolution CNN by our LR$\sim$HR dataset has superior restoration
performance than training it by existing datasets on real world images at the
inference stage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Imperceptible Adversarial Examples by Spatial Chroma-Shift. (arXiv:2108.02502v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02502">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks have been shown to be vulnerable to various kinds of
adversarial perturbations. In addition to widely studied additive noise based
perturbations, adversarial examples can also be created by applying a per pixel
spatial drift on input images. While spatial transformation based adversarial
examples look more natural to human observers due to absence of additive noise,
they still possess visible distortions caused by spatial transformations. Since
the human vision is more sensitive to the distortions in the luminance compared
to those in chrominance channels, which is one of the main ideas behind the
lossy visual multimedia compression standards, we propose a spatial
transformation based perturbation method to create adversarial examples by only
modifying the color components of an input image. While having competitive
fooling rates on CIFAR-10 and NIPS2017 Adversarial Learning Challenge datasets,
examples created with the proposed method have better scores with regards to
various perceptual quality metrics. Human visual perception studies validate
that the examples are more natural looking and often indistinguishable from
their original counterparts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangled High Quality Salient Object Detection. (arXiv:2108.03551v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03551">
<div class="article-summary-box-inner">
<span><p>Aiming at discovering and locating most distinctive objects from visual
scenes, salient object detection (SOD) plays an essential role in various
computer vision systems. Coming to the era of high resolution, SOD methods are
facing new challenges. The major limitation of previous methods is that they
try to identify the salient regions and estimate the accurate objects
boundaries simultaneously with a single regression task at low-resolution. This
practice ignores the inherent difference between the two difficult problems,
resulting in poor detection quality. In this paper, we propose a novel deep
learning framework for high-resolution SOD task, which disentangles the task
into a low-resolution saliency classification network (LRSCN) and a
high-resolution refinement network (HRRN). As a pixel-wise classification task,
LRSCN is designed to capture sufficient semantics at low-resolution to identify
the definite salient, background and uncertain image regions. HRRN is a
regression task, which aims at accurately refining the saliency value of pixels
in the uncertain region to preserve a clear object boundary at high-resolution
with limited GPU memory. It is worth noting that by introducing uncertainty
into the training process, our HRRN can well address the high-resolution
refinement task without using any high-resolution training data. Extensive
experiments on high-resolution saliency datasets as well as some widely used
saliency benchmarks show that the proposed method achieves superior performance
compared to the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Creating synthetic meteorology satellite visible light images during night based on GAN method. (arXiv:2108.04330v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04330">
<div class="article-summary-box-inner">
<span><p>Meteorology satellite visible light images is critical for meteorology
support and forecast. However, there is no such kind of data during night time.
To overcome this, we propose a method based on deep learning to create
synthetic satellite visible light images during night. Specifically, to produce
more realistic products, we train a Generative Adversarial Networks (GAN) model
to generate visible light images given the corresponding satellite infrared
images and numerical weather prediction(NWP) products. To better model the
nonlinear relationship from infrared data and NWP products to visible light
images, we propose to use the channel-wise attention mechanics, e.g., SEBlock
to quantitative weight the input channels. The experiments based on the ECMWF
NWP products and FY-4A meteorology satellite visible light and infrared
channels date show that the proposed methods can be effective to create
realistic synthetic satellite visible light images during night.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Calibrating Neural Radiance Fields. (arXiv:2108.13826v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13826">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a camera self-calibration algorithm for generic
cameras with arbitrary non-linear distortions. We jointly learn the geometry of
the scene and the accurate camera parameters without any calibration objects.
Our camera model consists of a pinhole model, a fourth order radial distortion,
and a generic noise model that can learn arbitrary non-linear camera
distortions. While traditional self-calibration algorithms mostly rely on
geometric constraints, we additionally incorporate photometric consistency.
This requires learning the geometry of the scene, and we use Neural Radiance
Fields (NeRF). We also propose a new geometric loss function, viz., projected
ray distance loss, to incorporate geometric consistency for complex non-linear
camera models. We validate our approach on standard real image datasets and
demonstrate that our model can learn the camera intrinsics and extrinsics
(pose) from scratch without COLMAP initialization. Also, we show that learning
accurate camera models in a differentiable manner allows us to improve PSNR
over baselines. Our module is an easy-to-use plugin that can be applied to NeRF
variants to improve performance. The code and data are currently available at
https://github.com/POSTECH-CVLab/SCNeRF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perceptually Optimized Deep High-Dynamic-Range Image Tone Mapping. (arXiv:2109.00180v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00180">
<div class="article-summary-box-inner">
<span><p>We describe a deep high-dynamic-range (HDR) image tone mapping operator that
is computationally efficient and perceptually optimized. We first decompose an
HDR image into a normalized Laplacian pyramid, and use two deep neural networks
(DNNs) to estimate the Laplacian pyramid of the desired tone-mapped image from
the normalized representation. We then end-to-end optimize the entire method
over a database of HDR images by minimizing the normalized Laplacian pyramid
distance (NLPD), a recently proposed perceptual metric. Qualitative and
quantitative experiments demonstrate that our method produces images with
better visual quality, and runs the fastest among existing local tone mapping
algorithms.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-04 23:02:06.779350610 UTC">2021-09-04 23:02:06 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>