<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-04-12T01:30:00Z">04-12</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">BioRED: A Comprehensive Biomedical Relation Extraction Dataset. (arXiv:2204.04263v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04263">
<div class="article-summary-box-inner">
<span><p>Automated relation extraction (RE) from biomedical literature is critical for
many downstream text mining applications in both research and real-world
settings. However, most existing benchmarking datasets for bio-medical RE only
focus on relations of a single type (e.g., protein-protein interactions) at the
sentence level, greatly limiting the development of RE systems in biomedicine.
In this work, we first review commonly used named entity recognition (NER) and
RE datasets. Then we present BioRED, a first-of-its-kind biomedical RE corpus
with multiple entity types (e.g., gene/protein, disease, chemical) and relation
pairs (e.g., gene-disease; chemical-chemical), on a set of 600 PubMed articles.
Further, we label each relation as describing either a novel finding or
previously known background knowledge, enabling automated algorithms to
differentiate between novel and background information. We assess the utility
of BioRED by benchmarking several existing state-of-the-art methods, including
BERT-based models, on the NER and RE tasks. Our results show that while
existing approaches can reach high performance on the NER task (F-score of
89.3%), there is much room for improvement for the RE task, especially when
extracting novel relations (F-score of 47.7%). Our experiments also demonstrate
that such a comprehensive dataset can successfully facilitate the development
of more accurate, efficient, and robust RE systems for biomedicine.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of Natural Language Processing Techniques for Requirements Engineering. (arXiv:2204.04282v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04282">
<div class="article-summary-box-inner">
<span><p>Research in applying natural language processing (NLP) techniques to
requirements engineering (RE) tasks spans more than 40 years, from initial
efforts carried out in the 1980s to more recent attempts with machine learning
(ML) and deep learning (DL) techniques. However, in spite of the progress, our
recent survey shows that there is still a lack of systematic understanding and
organization of commonly used NLP techniques in RE. We believe one hurdle
facing the industry is lack of shared knowledge of NLP techniques and their
usage in RE tasks. In this paper, we present our effort to synthesize and
organize 57 most frequently used NLP techniques in RE. We classify these NLP
techniques in two ways: first, by their NLP tasks in typical pipelines and
second, by their linguist analysis levels. We believe these two ways of
classification are complementary, contributing to a better understanding of the
NLP techniques in RE and such understanding is crucial to the development of
better NLP tools for RE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Understanding Large-Scale Discourse Structures in Pre-Trained and Fine-Tuned Language Models. (arXiv:2204.04289v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04289">
<div class="article-summary-box-inner">
<span><p>With a growing number of BERTology work analyzing different components of
pre-trained language models, we extend this line of research through an
in-depth analysis of discourse information in pre-trained and fine-tuned
language models. We move beyond prior work along three dimensions: First, we
describe a novel approach to infer discourse structures from arbitrarily long
documents. Second, we propose a new type of analysis to explore where and how
accurately intrinsic discourse is captured in the BERT and BART models.
Finally, we assess how similar the generated structures are to a variety of
baselines as well as their distribution within and between models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MMTAfrica: Multilingual Machine Translation for African Languages. (arXiv:2204.04306v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04306">
<div class="article-summary-box-inner">
<span><p>In this paper, we focus on the task of multilingual machine translation for
African languages and describe our contribution in the 2021 WMT Shared Task:
Large-Scale Multilingual Machine Translation. We introduce MMTAfrica, the first
many-to-many multilingual translation system for six African languages: Fon
(fon), Igbo (ibo), Kinyarwanda (kin), Swahili/Kiswahili (swa), Xhosa (xho), and
Yoruba (yor) and two non-African languages: English (eng) and French (fra). For
multilingual translation concerning African languages, we introduce a novel
backtranslation and reconstruction objective, BT\&amp;REC, inspired by the random
online back translation and T5 modeling framework respectively, to effectively
leverage monolingual data. Additionally, we report improvements from MMTAfrica
over the FLORES 101 benchmarks (spBLEU gains ranging from $+0.58$ in Swahili to
French to $+19.46$ in French to Xhosa). We release our dataset and code source
at https://github.com/edaiofficial/mmtafrica.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grounding Hindsight Instructions in Multi-Goal Reinforcement Learning for Robotics. (arXiv:2204.04308v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04308">
<div class="article-summary-box-inner">
<span><p>This paper focuses on robotic reinforcement learning with sparse rewards for
natural language goal representations. An open problem is the
sample-inefficiency that stems from the compositionality of natural language,
and from the grounding of language in sensory data and actions. We address
these issues with three contributions. We first present a mechanism for
hindsight instruction replay utilizing expert feedback. Second, we propose a
seq2seq model to generate linguistic hindsight instructions. Finally, we
present a novel class of language-focused learning tasks. We show that
hindsight instructions improve the learning performance, as expected. In
addition, we also provide an unexpected result: We show that the learning
performance of our agent can be improved by one third if, in a sense, the agent
learns to talk to itself in a self-supervised manner. We achieve this by
learning to generate linguistic instructions that would have been appropriate
as a natural language goal for an originally unintended behavior. Our results
indicate that the performance gain increases with the task-complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Show, Don't Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue. (arXiv:2204.04327v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04327">
<div class="article-summary-box-inner">
<span><p>Building universal dialogue systems that can seamlessly operate across
multiple domains/APIs and generalize to new ones with minimal supervision and
maintenance is a critical challenge. Recent works have leveraged natural
language descriptions for schema elements to enable such systems; however,
descriptions can only indirectly convey schema semantics. In this work, we
propose Show, Don't Tell, a prompt format for seq2seq modeling which uses a
short labeled example dialogue to show the semantics of schema elements rather
than tell the model via descriptions. While requiring similar effort from
service developers, we show that using short examples as schema representations
with large language models results in stronger performance and better
generalization on two popular dialogue state tracking benchmarks: the
Schema-Guided Dialogue dataset and the MultiWoZ leave-one-out benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Better Chinese-centric Neural Machine Translation for Low-resource Languages. (arXiv:2204.04344v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04344">
<div class="article-summary-box-inner">
<span><p>The last decade has witnessed enormous improvements in science and
technology, stimulating the growing demand for economic and cultural exchanges
in various countries. Building a neural machine translation (NMT) system has
become an urgent trend, especially in the low-resource setting. However, recent
work tends to study NMT systems for low-resource languages centered on English,
while few works focus on low-resource NMT systems centered on other languages
such as Chinese. To achieve this, the low-resource multilingual translation
challenge of the 2021 iFLYTEK AI Developer Competition provides the
Chinese-centric multilingual low-resource NMT tasks, where participants are
required to build NMT systems based on the provided low-resource samples. In
this paper, we present the winner competition system that leverages monolingual
word embeddings data enhancement, bilingual curriculum learning, and
contrastive re-ranking. In addition, a new Incomplete-Trust (In-trust) loss
function is proposed to replace the traditional cross-entropy loss when
training. The experimental results demonstrate that the implementation of these
ideas leads better performance than other state-of-the-art methods. All the
experimental codes are released at:
https://github.com/WENGSYX/Low-resource-text-translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Importance of Karaka Framework in Multi-modal Grounding. (arXiv:2204.04347v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04347">
<div class="article-summary-box-inner">
<span><p>Computational Paninian Grammar model helps in decoding a natural language
expression as a series of modifier-modified relations and therefore facilitates
in identifying dependency relations closer to language (context) semantics
compared to the usual Stanford dependency relations. However, the importance of
this CPG dependency scheme has not been studied in the context of multi-modal
vision and language applications. At IIIT Hyderabad, we plan to perform a novel
study to explore the potential advantages and disadvantages of CPG framework in
a vision-language navigation task setting, a popular and challenging
multi-modal grounding task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Should we tweet this? Generative response modeling for predicting reception of public health messaging on Twitter. (arXiv:2204.04353v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04353">
<div class="article-summary-box-inner">
<span><p>The way people respond to messaging from public health organizations on
social media can provide insight into public perceptions on critical health
issues, especially during a global crisis such as COVID-19. It could be
valuable for high-impact organizations such as the US Centers for Disease
Control and Prevention (CDC) or the World Health Organization (WHO) to
understand how these perceptions impact reception of messaging on health policy
recommendations. We collect two datasets of public health messages and their
responses from Twitter relating to COVID-19 and Vaccines, and introduce a
predictive method which can be used to explore the potential reception of such
messages. Specifically, we harness a generative model (GPT-2) to directly
predict probable future responses and demonstrate how it can be used to
optimize expected reception of important health guidance. Finally, we introduce
a novel evaluation scheme with extensive statistical testing which allows us to
conclude that our models capture the semantics and sentiment found in actual
public health responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-Oriented Prefix-Tuning: Towards Efficient and Generalizable Fine-tuning for Zero-Shot Dialogue Summarization. (arXiv:2204.04362v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04362">
<div class="article-summary-box-inner">
<span><p>The most advanced abstractive dialogue summarizers lack generalization
ability on new domains and the existing researches for domain adaptation in
summarization generally rely on large-scale pre-trainings. To explore the
lightweight fine-tuning methods for domain adaptation of dialogue
summarization, in this paper, we propose an efficient and generalizable
Domain-Oriented Prefix-tuning model, which utilizes a domain word initialized
prefix module to alleviate domain entanglement and adopts discrete prompts to
guide the model to focus on key contents of dialogues and enhance model
generalization. We conduct zero-shot experiments and build domain adaptation
benchmarks on two multi-domain dialogue summarization datasets, TODSum and
QMSum. Adequate experiments and qualitative analysis prove the effectiveness of
our methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective. (arXiv:2204.04391v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04391">
<div class="article-summary-box-inner">
<span><p>NER model has achieved promising performance on standard NER benchmarks.
However, recent studies show that previous approaches may over-rely on entity
mention information, resulting in poor performance on out-of-vocabulary (OOV)
entity recognition. In this work, we propose MINER, a novel NER learning
framework, to remedy this issue from an information-theoretic perspective. The
proposed approach contains two mutual information-based training objectives: i)
generalizing information maximization, which enhances representation via deep
understanding of context and entity surface forms; ii) superfluous information
minimization, which discourages representation from rote memorizing entity
names or exploiting biased cues in data. Experiments on various settings and
datasets demonstrate that it achieves better performance in predicting OOV
entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Demonstration Tuning for Pre-trained Language Models. (arXiv:2204.04392v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04392">
<div class="article-summary-box-inner">
<span><p>Pretrained language models can be effectively stimulated by textual prompts
or demonstrations, especially in low-data scenarios. Recent works have focused
on automatically searching discrete or continuous prompts or optimized
verbalizers, yet studies for the demonstration are still limited. Concretely,
the demonstration examples are crucial for an excellent final performance of
prompt-tuning. In this paper, we propose a novel pluggable, extensible, and
efficient approach named contrastive demonstration tuning, which is free of
demonstration sampling. Furthermore, the proposed approach can be: (i) Plugged
to any previous prompt-tuning approaches; (ii) Extended to widespread
classification tasks with a large number of categories. Experimental results on
16 datasets illustrate that our method integrated with previous approaches
LM-BFF and P-tuning can yield better performance. Code is available in
https://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Denoising Neural Network for News Recommendation with Positive and Negative Implicit Feedback. (arXiv:2204.04397v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04397">
<div class="article-summary-box-inner">
<span><p>News recommendation is different from movie or e-commercial recommendation as
people usually do not grade the news. Therefore, user feedback for news is
always implicit (click behavior, reading time, etc). Inevitably, there are
noises in implicit feedback. On one hand, the user may exit immediately after
clicking the news as he dislikes the news content, leaving the noise in his
positive implicit feedback; on the other hand, the user may be recommended
multiple interesting news at the same time and only click one of them,
producing the noise in his negative implicit feedback. Opposite implicit
feedback could construct more integrated user preferences and help each other
to minimize the noise influence. Previous works on news recommendation only
used positive implicit feedback and suffered from the noise impact. In this
paper, we propose a denoising neural network for news recommendation with
positive and negative implicit feedback, named DRPN. DRPN utilizes both
feedback for recommendation with a module to denoise both positive and negative
implicit feedback to further enhance the performance. Experiments on the
real-world large-scale dataset demonstrate the state-of-the-art performance of
DRPN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PSP: Pre-trained Soft Prompts for Few-Shot Abstractive Summarization. (arXiv:2204.04413v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04413">
<div class="article-summary-box-inner">
<span><p>Few-shot abstractive summarization has become a challenging task in natural
language generation. To support it, we designed a novel soft prompts
architecture coupled with a prompt pre-training plus fine-tuning paradigm that
is effective and tunes only extremely light parameters. The soft prompts
include continuous input embeddings across an encoder and a decoder to fit the
structure of the generation models. Importantly, a novel inner-prompt placed in
the text is introduced to capture document-level information. The aim is to
devote attention to understanding the document that better prompts the model to
generate document-related content. The first step in the summarization
procedure is to conduct prompt pre-training with self-supervised pseudo-data.
This teaches the model basic summarizing capabilities. The model is then
fine-tuned with few-shot examples. Experimental results on the CNN/DailyMail
and XSum datasets show that our method, with only 0.1% of the parameters,
outperforms full-model tuning where all model parameters are tuned. It also
surpasses Prompt Tuning by a large margin and delivers competitive results
against Prefix-Tuning with 3% of the parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Multi-Granularity Hierarchical Features for Relation Extraction. (arXiv:2204.04437v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04437">
<div class="article-summary-box-inner">
<span><p>Relation extraction is a key task in Natural Language Processing (NLP), which
aims to extract relations between entity pairs from given texts. Recently,
relation extraction (RE) has achieved remarkable progress with the development
of deep neural networks. Most existing research focuses on constructing
explicit structured features using external knowledge such as knowledge graph
and dependency tree. In this paper, we propose a novel method to extract
multi-granularity features based solely on the original input sentences. We
show that effective structured features can be attained even without external
knowledge. Three kinds of features based on the input sentences are fully
exploited, which are in entity mention level, segment level, and sentence
level. All the three are jointly and hierarchically modeled. We evaluate our
method on three public benchmarks: SemEval 2010 Task 8, Tacred, and Tacred
Revisited. To verify the effectiveness, we apply our method to different
encoders such as LSTM and BERT. Experimental results show that our method
significantly outperforms existing state-of-the-art models that even use
external knowledge. Extensive analyses demonstrate that the performance of our
model is contributed by the capture of multi-granularity features and the model
of their hierarchical structure. Code and data are available at
\url{https://github.com/xnliang98/sms}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding, Detecting, and Separating Out-of-Distribution Samples and Adversarial Samples in Text Classification. (arXiv:2204.04458v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04458">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the differences and commonalities between
statistically out-of-distribution (OOD) samples and adversarial (Adv) samples,
both of which hurting a text classification model's performance. We conduct
analyses to compare the two types of anomalies (OOD and Adv samples) with the
in-distribution (ID) ones from three aspects: the input features, the hidden
representations in each layer of the model, and the output probability
distributions of the classifier. We find that OOD samples expose their
aberration starting from the first layer, while the abnormalities of Adv
samples do not emerge until the deeper layers of the model. We also illustrate
that the models' output probabilities for Adv samples tend to be more
unconfident. Based on our observations, we propose a simple method to separate
ID, OOD, and Adv samples using the hidden representations and output
probabilities of the model. On multiple combinations of ID, OOD datasets, and
Adv attacks, our proposed method shows exceptional results on distinguishing
ID, OOD, and Adv samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FoundationLayerNorm: Scaling BERT and GPT to 1,000 Layers. (arXiv:2204.04477v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04477">
<div class="article-summary-box-inner">
<span><p>The mainstream BERT/GPT model contains only 10 to 20 layers, and there is
little literature to discuss the training of deep BERT/GPT. This paper proposes
a simple yet effective method to stabilize BERT and GPT training. We
successfully scale up BERT and GPT to 1,000 layers, which is an order of
magnitude deeper than previous BERT and GPT. The proposed method
FoundationLayerNormalization enables efficient training of deep neural networks
and is validated at the 1000-layer scale.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KUCST@LT-EDI-ACL2022: Detecting Signs of Depression from Social Media Text. (arXiv:2204.04481v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04481">
<div class="article-summary-box-inner">
<span><p>In this paper we present our approach for detecting signs of depression from
social media text. Our model relies on word unigrams, part-of-speech tags,
readabilitiy measures and the use of first, second or third person and the
number of words. Our best model obtained a macro F1-score of 0.439 and ranked
25th, out of 31 teams. We further take advantage of the interpretability of the
Logistic Regression model and we make an attempt to interpret the model
coefficients with the hope that these will be useful for further research on
the topic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uninformative Input Features and Counterfactual Invariance: Two Perspectives on Spurious Correlations in Natural Language. (arXiv:2204.04487v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04487">
<div class="article-summary-box-inner">
<span><p>Spurious correlations are a threat to the trustworthiness of natural language
processing systems, motivating research into methods for identifying and
eliminating them. Gardner et al (2021) argue that the compositional nature of
language implies that \emph{all} correlations between labels and individual
input features are spurious. This paper analyzes this proposal in the context
of a toy example, demonstrating three distinct conditions that can give rise to
feature-label correlations in a simple PCFG. Linking the toy example to a
structured causal model shows that (1) feature-label correlations can arise
even when the label is invariant to interventions on the feature, and (2)
feature-label correlations may be absent even when the label is sensitive to
interventions on the feature. Because input features will be individually
correlated with labels in all but very rare circumstances, domain knowledge
must be applied to identify spurious correlations that pose genuine robustness
threats.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IDPG: An Instance-Dependent Prompt Generation Method. (arXiv:2204.04497v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04497">
<div class="article-summary-box-inner">
<span><p>Prompt tuning is a new, efficient NLP transfer learning paradigm that adds a
task-specific prompt in each input instance during the model training stage. It
freezes the pre-trained language model and only optimizes a few task-specific
prompts. In this paper, we propose a conditional prompt generation method to
generate prompts for each input instance, referred to as the Instance-Dependent
Prompt Generation (IDPG). Unlike traditional prompt tuning methods that use a
fixed prompt, IDPG introduces a lightweight and trainable component to generate
prompts based on each input sentence. Extensive experiments on ten natural
language understanding (NLU) tasks show that the proposed strategy consistently
outperforms various prompt tuning baselines and is on par with other efficient
transfer learning methods such as Compacter while tuning far fewer model
parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TANet: Thread-Aware Pretraining for Abstractive Conversational Summarization. (arXiv:2204.04504v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04504">
<div class="article-summary-box-inner">
<span><p>Although pre-trained language models (PLMs) have achieved great success and
become a milestone in NLP, abstractive conversational summarization remains a
challenging but less studied task. The difficulty lies in two aspects. One is
the lack of large-scale conversational summary data. Another is that applying
the existing pre-trained models to this task is tricky because of the
structural dependence within the conversation and its informal expression, etc.
In this work, we first build a large-scale (11M) pretraining dataset called
RCS, based on the multi-person discussions in the Reddit community. We then
present TANet, a thread-aware Transformer-based network. Unlike the existing
pre-trained models that treat a conversation as a sequence of sentences, we
argue that the inherent contextual dependency among the utterances plays an
essential role in understanding the entire conversation and thus propose two
new techniques to incorporate the structural information into our model. The
first is thread-aware attention which is computed by taking into account the
contextual dependency within utterances. Second, we apply thread prediction
loss to predict the relations between utterances. We evaluate our model on four
datasets of real conversations, covering types of meeting transcripts,
customer-service records, and forum threads. Experimental results demonstrate
that TANET achieves a new state-of-the-art in terms of both automatic
evaluation and human judgment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking for Public Health Surveillance tasks on Social Media with a Domain-Specific Pretrained Language Model. (arXiv:2204.04521v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04521">
<div class="article-summary-box-inner">
<span><p>A user-generated text on social media enables health workers to keep track of
information, identify possible outbreaks, forecast disease trends, monitor
emergency cases, and ascertain disease awareness and response to official
health correspondence. This exchange of health information on social media has
been regarded as an attempt to enhance public health surveillance (PHS).
Despite its potential, the technology is still in its early stages and is not
ready for widespread application. Advancements in pretrained language models
(PLMs) have facilitated the development of several domain-specific PLMs and a
variety of downstream applications. However, there are no PLMs for social media
tasks involving PHS. We present and release PHS-BERT, a transformer-based PLM,
to identify tasks related to public health surveillance on social media. We
compared and benchmarked the performance of PHS-BERT on 25 datasets from
different social medial platforms related to 7 different PHS tasks. Compared
with existing PLMs that are mainly evaluated on limited tasks, PHS-BERT
achieved state-of-the-art performance on all 25 tested datasets, showing that
our PLM is robust and generalizable in the common PHS tasks. By making PHS-BERT
available, we aim to facilitate the community to reduce the computational cost
and introduce new baselines for future works across various PHS-related tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extending the Scope of Out-of-Domain: Examining QA models in multiple subdomains. (arXiv:2204.04534v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04534">
<div class="article-summary-box-inner">
<span><p>Past works that investigate out-of-domain performance of QA systems have
mainly focused on general domains (e.g. news domain, wikipedia domain),
underestimating the importance of subdomains defined by the internal
characteristics of QA datasets. In this paper, we extend the scope of
"out-of-domain" by splitting QA examples into different subdomains according to
their several internal characteristics including question type, text length,
answer position. We then examine the performance of QA systems trained on the
data from different subdomains. Experimental results show that the performance
of QA systems can be significantly reduced when the train data and test data
come from different subdomains. These results question the generalizability of
current QA systems in multiple subdomains, suggesting the need to combat the
bias introduced by the internal characteristics of QA datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KOBEST: Korean Balanced Evaluation of Significant Tasks. (arXiv:2204.04541v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04541">
<div class="article-summary-box-inner">
<span><p>A well-formulated benchmark plays a critical role in spurring advancements in
the natural language processing (NLP) field, as it allows objective and precise
evaluation of diverse models. As modern language models (LMs) have become more
elaborate and sophisticated, more difficult benchmarks that require linguistic
knowledge and reasoning have been proposed. However, most of these benchmarks
only support English, and great effort is necessary to construct benchmarks for
other low resource languages. To this end, we propose a new benchmark named
Korean balanced evaluation of significant tasks (KoBEST), which consists of
five Korean-language downstream tasks. Professional Korean linguists designed
the tasks that require advanced Korean linguistic knowledge. Moreover, our data
is purely annotated by humans and thoroughly reviewed to guarantee high data
quality. We also provide baseline models and human performance results. Our
dataset is available on the Huggingface.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Extraction of Pathologies from C-Spine Radiology Reports using Multi-Task Learning. (arXiv:2204.04544v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04544">
<div class="article-summary-box-inner">
<span><p>Pretrained Transformer based models finetuned on domain specific corpora have
changed the landscape of NLP. Generally, if one has multiple tasks on a given
dataset, one may finetune different models or use task specific adapters. In
this work, we show that a multi-task model can beat or achieve the performance
of multiple BERT-based models finetuned on various tasks and various task
specific adapter augmented BERT-based models. We validate our method on our
internal radiologist's report dataset on cervical spine. We hypothesize that
the tasks are semantically close and related and thus multitask learners are
powerful classifiers. Our work opens the scope of using our method to
radiologist's reports on various body parts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Re-Examining Human Annotations for Interpretable NLP. (arXiv:2204.04580v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04580">
<div class="article-summary-box-inner">
<span><p>Explanation methods in Interpretable NLP often explain the model's decision
by extracting evidence (rationale) from the input texts supporting the
decision. Benchmark datasets for rationales have been released to evaluate how
good the rationale is. The ground truth rationales in these datasets are often
human annotations obtained via crowd-sourced websites. Valuable as these
datasets are, the details on how those human annotations are obtained are often
not clearly specified. We conduct comprehensive controlled experiments using
crowd-sourced websites on two widely used datasets in Interpretable NLP to
understand how those unsaid details can affect the annotation results.
Specifically, we compare the annotation results obtained from recruiting
workers satisfying different levels of qualification. We also provide
high-quality workers with different instructions for completing the same
underlying tasks. Our results reveal that the annotation quality is highly
subject to the workers' qualification, and workers can be guided to provide
certain annotations by the instructions. We further show that specific
explanation methods perform better when evaluated using the ground truth
rationales obtained by particular instructions. Based on these observations, we
highlight the importance of providing complete details of the annotation
process and call for careful interpretation of any experiment results obtained
using those annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering. (arXiv:2204.04581v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04581">
<div class="article-summary-box-inner">
<span><p>Retrieval augmented language models have recently become the standard for
knowledge intensive tasks. Rather than relying purely on latent semantics
within the parameters of large neural models, these methods enlist a
semi-parametric memory to encode an index of knowledge for the model to
retrieve over. Most prior work has employed text passages as the unit of
knowledge, which has high coverage at the cost of interpretability,
controllability, and efficiency. The opposite properties arise in other methods
which have instead relied on knowledge base (KB) facts. At the same time, more
recent work has demonstrated the effectiveness of storing and retrieving from
an index of Q-A pairs derived from text \citep{lewis2021paq}. This approach
yields a high coverage knowledge representation that maintains KB-like
properties due to its representations being more atomic units of information.
In this work we push this line of research further by proposing a
question-answer augmented encoder-decoder model and accompanying pretraining
strategy. This yields an end-to-end system that not only outperforms prior QA
retrieval methods on single-hop QA tasks but also enables compositional
reasoning, as demonstrated by strong performance on two multi-hop QA datasets.
Together, these methods improve the ability to interpret and control the model
while narrowing the performance gap with passage retrieval systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained Language Models For Classification Tasks. (arXiv:2204.04596v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04596">
<div class="article-summary-box-inner">
<span><p>Parameter-efficient tuning aims to distill knowledge for downstream tasks by
optimizing a few introduced parameters while freezing the pretrained language
models (PLMs). Continuous prompt tuning which prepends a few trainable vectors
to the embeddings of input is one of these methods and has drawn much attention
due to its effectiveness and efficiency. This family of methods can be
illustrated as exerting nonlinear transformations of hidden states inside PLMs.
However, a natural question is ignored: can the hidden states be directly used
for classification without changing them? In this paper, we aim to answer this
question by proposing a simple tuning method which only introduces three
trainable vectors. Firstly, we integrate all layers hidden states using the
introduced vectors. And then, we input the integrated hidden state(s) to a
task-specific linear classifier to predict categories. This scheme is similar
to the way ELMo utilises hidden states except that they feed the hidden states
to LSTM-based models. Although our proposed tuning scheme is simple, it
achieves comparable performance with prompt tuning methods like P-tuning and
P-tuning v2, verifying that original hidden states do contain useful
information for classification tasks. Moreover, our method has an advantage
over prompt tuning in terms of time and the number of parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decay No More: A Persistent Twitter Dataset for Learning Social Meaning. (arXiv:2204.04611v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04611">
<div class="article-summary-box-inner">
<span><p>With the proliferation of social media, many studies resort to social media
to construct datasets for developing social meaning understanding systems. For
the popular case of Twitter, most researchers distribute tweet IDs without the
actual text contents due to the data distribution policy of the platform. One
issue is that the posts become increasingly inaccessible over time, which leads
to unfair comparisons and a temporal bias in social media research. To
alleviate this challenge of data decay, we leverage a paraphrase model to
propose a new persistent English Twitter dataset for social meaning (PTSM).
PTSM consists of $17$ social meaning datasets in $10$ categories of tasks. We
experiment with two SOTA pre-trained language models and show that our PTSM can
substitute the actual tweets with paraphrases with marginal performance loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ME-GCN: Multi-dimensional Edge-Embedded Graph Convolutional Networks for Semi-supervised Text Classification. (arXiv:2204.04618v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04618">
<div class="article-summary-box-inner">
<span><p>Compared to sequential learning models, graph-based neural networks exhibit
excellent ability in capturing global information and have been used for
semi-supervised learning tasks. Most Graph Convolutional Networks are designed
with the single-dimensional edge feature and failed to utilise the rich edge
information about graphs. This paper introduces the ME-GCN (Multi-dimensional
Edge-enhanced Graph Convolutional Networks) for semi-supervised text
classification. A text graph for an entire corpus is firstly constructed to
describe the undirected and multi-dimensional relationship of word-to-word,
document-document, and word-to-document. The graph is initialised with
corpus-trained multi-dimensional word and document node representation, and the
relations are represented according to the distance of those words/documents
nodes. Then, the generated graph is trained with ME-GCN, which considers the
edge features as multi-stream signals, and each stream performs a separate
graph convolutional operation. Our ME-GCN can integrate a rich source of graph
edge information of the entire text corpus. The results have demonstrated that
our proposed model has significantly outperformed the state-of-the-art methods
across eight benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Framework for Fast Automated Phonological Reconstruction Using Trimmed Alignments and Sound Correspondence Patterns. (arXiv:2204.04619v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04619">
<div class="article-summary-box-inner">
<span><p>Computational approaches in historical linguistics have been increasingly
applied during the past decade and many new methods that implement parts of the
traditional comparative method have been proposed. Despite these increased
efforts, there are not many easy-to-use and fast approaches for the task of
phonological reconstruction. Here we present a new framework that combines
state-of-the-art techniques for automated sequence comparison with novel
techniques for phonetic alignment analysis and sound correspondence pattern
detection to allow for the supervised reconstruction of word forms in ancestral
languages. We test the method on a new dataset covering six groups from three
different language families. The results show that our method yields promising
results while at the same time being not only fast but also easy to apply and
expand.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pushing on Personality Detection from Verbal Behavior: A Transformer Meets Text Contours of Psycholinguistic Features. (arXiv:2204.04629v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04629">
<div class="article-summary-box-inner">
<span><p>Research at the intersection of personality psychology, computer science, and
linguistics has recently focused increasingly on modeling and predicting
personality from language use. We report two major improvements in predicting
personality traits from text data: (1) to our knowledge, the most comprehensive
set of theory-based psycholinguistic features and (2) hybrid models that
integrate a pre-trained Transformer Language Model BERT and Bidirectional Long
Short-Term Memory (BLSTM) networks trained on within-text distributions ('text
contours') of psycholinguistic features. We experiment with BLSTM models (with
and without Attention) and with two techniques for applying pre-trained
language representations from the transformer model - 'feature-based' and
'fine-tuning'. We evaluate the performance of the models we built on two
benchmark datasets that target the two dominant theoretical models of
personality: the Big Five Essay dataset and the MBTI Kaggle dataset. Our
results are encouraging as our models outperform existing work on the same
datasets. More specifically, our models achieve improvement in classification
accuracy by 2.9% on the Essay dataset and 8.28% on the Kaggle MBTI dataset. In
addition, we perform ablation experiments to quantify the impact of different
categories of psycholinguistic features in the respective personality
prediction models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"That Is a Suspicious Reaction!": Interpreting Logits Variation to Detect NLP Adversarial Attacks. (arXiv:2204.04636v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04636">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks are a major challenge faced by current machine learning
research. These purposely crafted inputs fool even the most advanced models,
precluding their deployment in safety-critical applications. Extensive research
in computer vision has been carried to develop reliable defense strategies.
However, the same issue remains less explored in natural language processing.
Our work presents a model-agnostic detector of adversarial text examples. The
approach identifies patterns in the logits of the target classifier when
perturbing the input text. The proposed detector improves the current
state-of-the-art performance in recognizing adversarial inputs and exhibits
strong generalization capabilities across different NLP models, datasets, and
word-level attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniDU: Towards A Unified Generative Dialogue Understanding Framework. (arXiv:2204.04637v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04637">
<div class="article-summary-box-inner">
<span><p>With the development of pre-trained language models, remarkable success has
been witnessed in dialogue understanding (DU) direction. However, the current
DU approaches just employ an individual model for each DU task, independently,
without considering the shared knowledge across different DU tasks. In this
paper, we investigate a unified generative dialogue understanding framework,
namely UniDU, to achieve information exchange among DU tasks. Specifically, we
reformulate the DU tasks into unified generative paradigm. In addition, to
consider different training data for each task, we further introduce
model-agnostic training strategy to optimize unified model in a balanced
manner. We conduct the experiments on ten dialogue understanding datasets,
which span five fundamental tasks: dialogue summary, dialogue completion, slot
filling, intent detection and dialogue state tracking. The proposed UniDU
framework outperforms task-specific well-designed methods on all 5 tasks. We
further conduct comprehensive analysis experiments to study the effect factors.
The experimental results also show that the proposed method obtains promising
performance on unseen dialogue domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linear Complexity Randomized Self-attention Mechanism. (arXiv:2204.04667v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04667">
<div class="article-summary-box-inner">
<span><p>Recently, random feature attentions (RFAs) are proposed to approximate the
softmax attention in linear time and space complexity by linearizing the
exponential kernel. In this paper, we first propose a novel perspective to
understand the bias in such approximation by recasting RFAs as self-normalized
importance samplers. This perspective further sheds light on an \emph{unbiased}
estimator for the whole softmax attention, called randomized attention (RA). RA
constructs positive random features via query-specific distributions and enjoys
greatly improved approximation fidelity, albeit exhibiting quadratic
complexity. By combining the expressiveness in RA and the efficiency in RFA, we
develop a novel linear complexity self-attention mechanism called linear
randomized attention (LARA). Extensive experiments across various domains
demonstrate that RA and LARA significantly improve the performance of RFAs by a
substantial margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation for Biomedical Factoid Question Answering. (arXiv:2204.04711v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04711">
<div class="article-summary-box-inner">
<span><p>We study the effect of seven data augmentation (da) methods in factoid
question answering, focusing on the biomedical domain, where obtaining training
instances is particularly difficult. We experiment with data from the BioASQ
challenge, which we augment with training instances obtained from an artificial
biomedical machine reading comprehension dataset, or via back-translation,
information retrieval, word substitution based on word2vec embeddings, or
masked language modeling, question generation, or extending the given passage
with additional context. We show that da can lead to very significant
performance gains, even when using large pre-trained Transformers, contributing
to a broader discussion of if/when da benefits large pre-trained models. One of
the simplest da methods, word2vec-based word substitution, performed best and
is recommended. We release our artificial training instances and code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing Model Jitter: Stable Re-training of Semantic Parsers in Production Environments. (arXiv:2204.04735v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04735">
<div class="article-summary-box-inner">
<span><p>Retraining modern deep learning systems can lead to variations in model
performance even when trained using the same data and hyper-parameters by
simply using different random seeds. We call this phenomenon model jitter. This
issue is often exacerbated in production settings, where models are retrained
on noisy data. In this work we tackle the problem of stable retraining with a
focus on conversational semantic parsers. We first quantify the model jitter
problem by introducing the model agreement metric and showing the variation
with dataset noise and model sizes. We then demonstrate the effectiveness of
various jitter reduction techniques such as ensembling and distillation.
Lastly, we discuss practical trade-offs between such techniques and show that
co-distillation provides a sweet spot in terms of jitter reduction for semantic
parsing systems with only a modest increase in resource usage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breaking Character: Are Subwords Good Enough for MRLs After All?. (arXiv:2204.04748v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04748">
<div class="article-summary-box-inner">
<span><p>Large pretrained language models (PLMs) typically tokenize the input string
into contiguous subwords before any pretraining or inference. However, previous
studies have claimed that this form of subword tokenization is inadequate for
processing morphologically-rich languages (MRLs). We revisit this hypothesis by
pretraining a BERT-style masked language model over character sequences instead
of word-pieces. We compare the resulting model, dubbed TavBERT, against
contemporary PLMs based on subwords for three highly complex and ambiguous MRLs
(Hebrew, Turkish, and Arabic), testing them on both morphological and semantic
tasks. Our results show, for all tested languages, that while TavBERT obtains
mild improvements on surface-level tasks \`a la POS tagging and full
morphological disambiguation, subword-based PLMs achieve significantly higher
performance on semantic tasks, such as named entity recognition and extractive
question answering. These results showcase and (re)confirm the potential of
subword tokenization as a reasonable modeling assumption for many languages,
including MRLs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Cross-lingual Transfer for Coarse-grained De-identification of Code-Mixed Clinical Texts. (arXiv:2204.04775v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04775">
<div class="article-summary-box-inner">
<span><p>Despite the advances in digital healthcare systems offering curated
structured knowledge, much of the critical information still lies in large
volumes of unlabeled and unstructured clinical texts. These texts, which often
contain protected health information (PHI), are exposed to information
extraction tools for downstream applications, risking patient identification.
Existing works in de-identification rely on using large-scale annotated corpora
in English, which often are not suitable in real-world multilingual settings.
Pre-trained language models (LM) have shown great potential for cross-lingual
transfer in low-resource settings. In this work, we empirically show the
few-shot cross-lingual transfer property of LMs for named entity recognition
(NER) and apply it to solve a low-resource and real-world challenge of
code-mixed (Spanish-Catalan) clinical notes de-identification in the stroke
domain. We annotate a gold evaluation dataset to assess few-shot setting
performance where we only use a few hundred labeled examples for training. Our
model improves the zero-shot F1-score from 73.7% to 91.2% on the gold
evaluation set when adapting Multilingual BERT (mBERT) (Devlin et al., 2019)
from the MEDDOCAN (Marimon et al., 2019) corpus with our few-shot cross-lingual
target corpus. When generalized to an out-of-sample test set, the best model
achieves a human-evaluation F1-score of 97.2%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MedDistant19: A Challenging Benchmark for Distantly Supervised Biomedical Relation Extraction. (arXiv:2204.04779v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04779">
<div class="article-summary-box-inner">
<span><p>Relation Extraction in the biomedical domain is challenging due to the lack
of labeled data and high annotation costs, needing domain experts. Distant
supervision is commonly used as a way to tackle the scarcity of annotated data
by automatically pairing knowledge graph relationships with raw texts.
Distantly Supervised Biomedical Relation Extraction (Bio-DSRE) models can
seemingly produce very accurate results in several benchmarks. However, given
the challenging nature of the task, we set out to investigate the validity of
such impressive results. We probed the datasets used by Amin et al. (2020) and
Hogan et al. (2021) and found a significant overlap between training and
evaluation relationships that, once resolved, reduced the accuracy of the
models by up to 71%. Furthermore, we noticed several inconsistencies with the
data construction process, such as creating negative samples and improper
handling of redundant relationships. We mitigate these issues and present
MedDistant19, a new benchmark dataset obtained by aligning the MEDLINE
abstracts with the widely used SNOMED Clinical Terms (SNOMED CT) knowledge
base. We experimented with several state-of-the-art models achieving an AUC of
55.4% and 49.8% at sentence- and bag-level, showing that there is still plenty
of room for improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fake news detection using parallel BERT deep neural networks. (arXiv:2204.04793v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04793">
<div class="article-summary-box-inner">
<span><p>Fake news is a growing challenge for social networks and media. Detection of
fake news always has been a problem for many years, but after the evolution of
social networks and increasing speed of news dissemination in recent years has
been considered again. There are several approaches to solving this problem,
one of which is to detect fake news based on its text style using deep neural
networks. In recent years, one of the most used forms of deep neural networks
for natural language processing is transfer learning with transformers. BERT is
one of the most promising transformers who outperforms other models in many NLP
benchmarks. This article, we introduce MWPBert, which uses two parallel BERT
networks to perform veracity detection on full-text news articles. One of the
BERT networks encodes news headline, and another encodes news body. Since the
input length of the BERT network is limited and constant and the news body is
usually a long text, we cannot fed the whole news text into the BERT.
Therefore, using the MaxWorth algorithm, we selected the part of the news text
that is more valuable for fact-checking, and fed it into the BERT network.
Finally, we encode the output of the two BERT networks to an output network to
classify the news. The experiment results showed that the proposed model
outperformed previous models in terms of accuracy and other performance
measures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explanation Graph Generation via Pre-trained Language Models: An Empirical Study with Contrastive Learning. (arXiv:2204.04813v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04813">
<div class="article-summary-box-inner">
<span><p>Pre-trained sequence-to-sequence language models have led to widespread
success in many natural language generation tasks. However, there has been
relatively less work on analyzing their ability to generate structured outputs
such as graphs. Unlike natural language, graphs have distinct structural and
semantic properties in the context of a downstream NLP task, e.g., generating a
graph that is connected and acyclic can be attributed to its structural
constraints, while the semantics of a graph can refer to how meaningfully an
edge represents the relation between two node concepts. In this work, we study
pre-trained language models that generate explanation graphs in an end-to-end
manner and analyze their ability to learn the structural constraints and
semantics of such graphs. We first show that with limited supervision,
pre-trained language models often generate graphs that either violate these
constraints or are semantically incoherent. Since curating large amount of
human-annotated graphs is expensive and tedious, we propose simple yet
effective ways of graph perturbations via node and edge edit operations that
lead to structurally and semantically positive and negative graphs. Next, we
leverage these graphs in different contrastive learning models with Max-Margin
and InfoNCE losses. Our methods lead to significant improvements in both
structural and semantic accuracy of explanation graphs and also generalize to
other similar graph generation tasks. Lastly, we show that human errors are the
best negatives for contrastive learning and also that automatically generating
more such human-like negative graphs can lead to further improvements. Our code
and models are publicly available at https://github.com/swarnaHub/ExplagraphGen
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Represent Programs with Heterogeneous Graphs. (arXiv:2012.04188v2 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04188">
<div class="article-summary-box-inner">
<span><p>Program source code contains complex structure information, which can be
represented in structured data forms like trees or graphs. To acquire the
structural information in source code, most existing researches use abstract
syntax trees (AST). A group of works add additional edges to ASTs to convert
source code into graphs and use graph neural networks to learn representations
for program graphs. Although these works provide additional control or data
flow information to ASTs for downstream tasks, they neglect an important aspect
of structure information in AST itself: the different types of nodes and edges.
In ASTs, different nodes contain different kinds of information like variables
or control flow, and the relation between a node and all its children can also
be different.
</p>
<p>To address the information of node and edge types, we bring the idea of
heterogeneous graphs to learning on source code and present a new formula of
building heterogeneous program graphs from ASTs with additional type
information for nodes and edges. We use the ASDL grammar of programming
language to define the node and edge types of program graphs. Then we use
heterogeneous graph neural networks to learn on these graphs. We evaluate our
approach on two tasks: code comment generation and method naming. Both tasks
require reasoning on the semantics of complete code snippets. Experiment
results show that our approach outperforms baseline models, including
homogeneous graph-based models, showing that leveraging the type information of
nodes and edges in program graphs can help in learning program semantics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curriculum Learning: A Survey. (arXiv:2101.10382v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10382">
<div class="article-summary-box-inner">
<span><p>Training machine learning models in a meaningful order, from the easy samples
to the hard ones, using curriculum learning can provide performance
improvements over the standard training approach based on random data
shuffling, without any additional computational costs. Curriculum learning
strategies have been successfully employed in all areas of machine learning, in
a wide range of tasks. However, the necessity of finding a way to rank the
samples from easy to hard, as well as the right pacing function for introducing
more difficult data can limit the usage of the curriculum approaches. In this
survey, we show how these limits have been tackled in the literature, and we
present different curriculum learning instantiations for various tasks in
machine learning. We construct a multi-perspective taxonomy of curriculum
learning approaches by hand, considering various classification criteria. We
further build a hierarchical tree of curriculum learning methods using an
agglomerative clustering algorithm, linking the discovered clusters with our
taxonomy. At the end, we provide some interesting directions for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters. (arXiv:2105.06232v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06232">
<div class="article-summary-box-inner">
<span><p>To diversify and enrich generated dialogue responses, knowledge-grounded
dialogue has been investigated in recent years. The existing methods tackle the
knowledge grounding challenge by retrieving the relevant sentences over a large
corpus and augmenting the dialogues with explicit extra information. Despite
their success, however, the existing works have drawbacks on the inference
efficiency. This paper proposes KnowExpert, an end-to-end framework to bypass
the explicit retrieval process and inject knowledge into the pre-trained
language models with lightweight adapters and adapt to the knowledge-grounded
dialogue task. To the best of our knowledge, this is the first attempt to
tackle this challenge without retrieval in this task under an open-domain
chit-chat scenario. The experimental results show that KknowExpert performs
comparably with some retrieval-based baselines while being time-efficient in
inference, demonstrating the potential of our proposed direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bangla Natural Language Processing: A Comprehensive Analysis of Classical, Machine Learning, and Deep Learning Based Methods. (arXiv:2105.14875v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14875">
<div class="article-summary-box-inner">
<span><p>The Bangla language is the seventh most spoken language, with 265 million
native and non-native speakers worldwide. However, English is the predominant
language for online resources and technical knowledge, journals, and
documentation. Consequently, many Bangla-speaking people, who have limited
command of English, face hurdles to utilize English resources. To bridge the
gap between limited support and increasing demand, researchers conducted many
experiments and developed valuable tools and techniques to create and process
Bangla language materials. Many efforts are also ongoing to make it easy to use
the Bangla language in the online and technical domains. There are some review
papers to understand the past, previous, and future Bangla Natural Language
Processing (BNLP) trends. The studies are mainly concentrated on the specific
domains of BNLP, such as sentiment analysis, speech recognition, optical
character recognition, and text summarization. There is an apparent scarcity of
resources that contain a comprehensive review of the recent BNLP tools and
methods. Therefore, in this paper, we present a thorough analysis of 75 BNLP
research papers and categorize them into 11 categories, namely Information
Extraction, Machine Translation, Named Entity Recognition, Parsing, Parts of
Speech Tagging, Question Answering System, Sentiment Analysis, Spam and Fake
Detection, Text Summarization, Word Sense Disambiguation, and Speech Processing
and Recognition. We study articles published between 1999 to 2021, and 50% of
the papers were published after 2015. Furthermore, we discuss Classical,
Machine Learning and Deep Learning approaches with different datasets while
addressing the limitations and current and future trends of the BNLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Saturated Transformers are Constant-Depth Threshold Circuits. (arXiv:2106.16213v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16213">
<div class="article-summary-box-inner">
<span><p>Transformers have become a standard neural network architecture for many NLP
problems, motivating theoretical analysis of their power in terms of formal
languages. Recent work has shown that transformers with hard attention are
quite limited in power (Hahn, 2020), as they can be simulated by constant-depth
AND/OR circuits (Hao et al. 2021). However, hard attention is a strong
assumption, which may complicate the relevance of these results in practice. In
this work, we analyze the circuit complexity of transformers with saturated
attention: a generalization of hard attention that more closely captures the
attention patterns learnable in practical transformers. We first show that
saturated transformers transcend the known limitations of hard-attention
transformers. We then prove saturated transformers with floating-point values
can be simulated by constant-depth threshold circuits, giving the class
$\mathsf{TC}^0$ as an upper bound on the formal languages they recognize.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Social Meaning Detection with Pragmatic Masking and Surrogate Fine-Tuning. (arXiv:2108.00356v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00356">
<div class="article-summary-box-inner">
<span><p>Masked language models (MLMs) are pre-trained with a denoising objective that
is in a mismatch with the objective of downstream fine-tuning. We propose
pragmatic masking and surrogate fine-tuning as two complementing strategies
that exploit social cues to drive pre-trained representations toward a broad
set of concepts useful for a wide class of social meaning tasks. We test our
models on $15$ different Twitter datasets for social meaning detection. Our
methods achieve $2.34\%$ $F_1$ over a competitive baseline, while outperforming
domain-specific language models pre-trained on large datasets. Our methods also
excel in few-shot learning: with only $5\%$ of training data (severely
few-shot), our methods enable an impressive $68.54\%$ average $F_1$. The
methods are also language agnostic, as we show in a zero-shot setting involving
six datasets from three different languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MMChat: Multi-Modal Chat Dataset on Social Media. (arXiv:2108.07154v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07154">
<div class="article-summary-box-inner">
<span><p>Incorporating multi-modal contexts in conversation is an important step for
developing more engaging dialogue systems. In this work, we explore this
direction by introducing MMChat: a large scale Chinese multi-modal dialogue
corpus (32.4M raw dialogues and 120.84K filtered dialogues). Unlike previous
corpora that are crowd-sourced or collected from fictitious movies, MMChat
contains image-grounded dialogues collected from real conversations on social
media, in which the sparsity issue is observed. Specifically, image-initiated
dialogues in common communications may deviate to some non-image-grounded
topics as the conversation proceeds. To better investigate this issue, we
manually annotate 100K dialogues from MMChat and further filter the corpus
accordingly, which yields MMChat-hf. We develop a benchmark model to address
the sparsity issue in dialogue generation tasks by adapting the attention
routing mechanism on image features. Experiments demonstrate the usefulness of
incorporating image features and the effectiveness in handling the sparsity of
image features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation. (arXiv:2108.11626v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11626">
<div class="article-summary-box-inner">
<span><p>As the use of interactive machines grow, the task of Emotion Recognition in
Conversation (ERC) became more important. If the machine-generated sentences
reflect emotion, more human-like sympathetic conversations are possible. Since
emotion recognition in conversation is inaccurate if the previous utterances
are not taken into account, many studies reflect the dialogue context to
improve the performances. Many recent approaches show performance improvement
by combining knowledge into modules learned from external structured data.
However, structured data is difficult to access in non-English languages,
making it difficult to extend to other languages. Therefore, we extract the
pre-trained memory using the pre-trained language model as an extractor of
external knowledge. We introduce CoMPM, which combines the speaker's
pre-trained memory with the context model, and find that the pre-trained memory
significantly improves the performance of the context model. CoMPM achieves the
first or second performance on all data and is state-of-the-art among systems
that do not leverage structured data. In addition, our method shows that it can
be extended to other languages because structured knowledge is not required,
unlike previous methods. Our code is available on
github~\footnote{https://github.com/rungjoo/CoMPM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Pursuit of Designing Multi-modal Transformer for Video Grounding. (arXiv:2109.06085v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06085">
<div class="article-summary-box-inner">
<span><p>Video grounding aims to localize the temporal segment corresponding to a
sentence query from an untrimmed video. Almost all existing video grounding
methods fall into two frameworks: 1) Top-down model: It predefines a set of
segment candidates and then conducts segment classification and regression. 2)
Bottom-up model: It directly predicts frame-wise probabilities of the
referential segment boundaries. However, all these methods are not end-to-end,
i.e., they always rely on some time-consuming post-processing steps to refine
predictions. To this end, we reformulate video grounding as a set prediction
task and propose a novel end-to-end multi-modal Transformer model, dubbed as
GTR. Specifically, GTR has two encoders for video and language encoding, and a
cross-modal decoder for grounding prediction. To facilitate the end-to-end
training, we use a Cubic Embedding layer to transform the raw videos into a set
of visual tokens. To better fuse these two modalities in the decoder, we design
a new Multi-head Cross-Modal Attention. The whole GTR is optimized via a
Many-to-One matching loss. Furthermore, we conduct comprehensive studies to
investigate different model design choices. Extensive results on three
benchmarks have validated the superiority of GTR. All three typical GTR
variants achieve record-breaking performance on all datasets and metrics, with
several times faster inference speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Slot Filling for Biomedical Information Extraction. (arXiv:2109.08564v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08564">
<div class="article-summary-box-inner">
<span><p>Information Extraction (IE) from text refers to the task of extracting
structured knowledge from unstructured text. The task typically consists of a
series of sub-tasks such as Named Entity Recognition and Relation Extraction.
Sourcing entity and relation type specific training data is a major bottleneck
in domains with limited resources such as biomedicine. In this work we present
a slot filling approach to the task of biomedical IE, effectively replacing the
need for entity and relation-specific training data, allowing us to deal with
zero-shot settings. We follow the recently proposed paradigm of coupling a
Tranformer-based bi-encoder, Dense Passage Retrieval, with a Transformer-based
reading comprehension model to extract relations from biomedical text. We
assemble a biomedical slot filling dataset for both retrieval and reading
comprehension and conduct a series of experiments demonstrating that our
approach outperforms a number of simpler baselines. We also evaluate our
approach end-to-end for standard as well as zero-shot settings. Our work
provides a fresh perspective on how to solve biomedical IE tasks, in the
absence of relevant training data. Our code, models and datasets are available
at https://github.com/ypapanik/biomedical-slot-filling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-based NP Enrichment. (arXiv:2109.12085v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12085">
<div class="article-summary-box-inner">
<span><p>Understanding the relations between entities denoted by NPs in a text is a
critical part of human-like natural language understanding. However, only a
fraction of such relations is covered by standard NLP tasks and benchmarks
nowadays. In this work, we propose a novel task termed text-based NP enrichment
(TNE), in which we aim to enrich each NP in a text with all the
preposition-mediated relations -- either explicit or implicit -- that hold
between it and other NPs in the text. The relations are represented as
triplets, each denoted by two NPs related via a preposition. Humans recover
such relations seamlessly, while current state-of-the-art models struggle with
them due to the implicit nature of the problem. We build the first large-scale
dataset for the problem, provide the formal framing and scope of annotation,
analyze the data, and report the results of fine-tuned language models on the
task, demonstrating the challenge it poses to current technology. A webpage
with a data-exploration UI, a demo, and links to the code, models, and
leaderboard, to foster further research into this challenging problem can be
found at: yanaiela.github.io/TNE/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Model Supervised by Understanding Map. (arXiv:2110.06043v9 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06043">
<div class="article-summary-box-inner">
<span><p>Inspired by the notion of Center of Mass in physics, an extension called
Semantic Center of Mass (SCOM) is proposed, and used to discover the abstract
"topic" of a document. The notion is under a framework model called
Understanding Map Supervised Topic Model (UM-S-TM). The devise aim of UM-S-TM
is to let both the document content and a semantic network -- specifically,
Understanding Map -- play a role, in interpreting the meaning of a document.
Based on different justifications, three possible methods are devised to
discover the SCOM of a document. Some experiments on artificial documents and
Understanding Maps are conducted to test their outcomes. In addition, its
ability of vectorization of documents and capturing sequential information are
tested. We also compared UM-S-TM with probabilistic topic models like Latent
Dirichlet Allocation (LDA) and probabilistic Latent Semantic Analysis (pLSA).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Efficient NLP: A Standard Evaluation and A Strong Baseline. (arXiv:2110.07038v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07038">
<div class="article-summary-box-inner">
<span><p>Supersized pre-trained language models have pushed the accuracy of various
natural language processing (NLP) tasks to a new state-of-the-art (SOTA).
Rather than pursuing the reachless SOTA accuracy, more and more researchers
start paying attention on model efficiency and usability. Different from
accuracy, the metric for efficiency varies across different studies, making
them hard to be fairly compared. To that end, this work presents ELUE
(Efficient Language Understanding Evaluation), a standard evaluation, and a
public leaderboard for efficient NLP models. ELUE is dedicated to depict the
Pareto Frontier for various language understanding tasks, such that it can tell
whether and how much a method achieves Pareto improvement. Along with the
benchmark, we also release a strong baseline, ElasticBERT, which allows BERT to
exit at any layer in both static and dynamic ways. We demonstrate the
ElasticBERT, despite its simplicity, outperforms or performs on par with SOTA
compressed and early exiting models. With ElasticBERT, the proposed ELUE has a
strong Pareto Frontier and makes a better evaluation for efficient NLP models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MReD: A Meta-Review Dataset for Structure-Controllable Text Generation. (arXiv:2110.07474v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07474">
<div class="article-summary-box-inner">
<span><p>When directly using existing text generation datasets for controllable
generation, we are facing the problem of not having the domain knowledge and
thus the aspects that could be controlled are limited. A typical example is
when using CNN/Daily Mail dataset for controllable text summarization, there is
no guided information on the emphasis of summary sentences. A more useful text
generator should leverage both the input text and the control signal to guide
the generation, which can only be built with a deep understanding of the domain
knowledge. Motivated by this vision, our paper introduces a new text generation
dataset, named MReD. Our new dataset consists of 7,089 meta-reviews and all its
45k meta-review sentences are manually annotated with one of the 9 carefully
defined categories, including abstract, strength, decision, etc. We present
experimental results on start-of-the-art summarization models, and propose
methods for structure-controlled generation with both extractive and
abstractive models using our annotated data. By exploring various settings and
analyzing the model behavior with respect to the control signal, we demonstrate
the challenges of our proposed task and the values of our dataset MReD.
Meanwhile, MReD also allows us to have a better understanding of the
meta-review domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Compositional Generalization with Self-Training for Data-to-Text Generation. (arXiv:2110.08467v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08467">
<div class="article-summary-box-inner">
<span><p>Data-to-text generation focuses on generating fluent natural language
responses from structured meaning representations (MRs). Such representations
are compositional and it is costly to collect responses for all possible
combinations of atomic meaning schemata, thereby necessitating few-shot
generalization to novel MRs. In this work, we systematically study the
compositional generalization of the state-of-the-art T5 models in few-shot
data-to-text tasks. We show that T5 models fail to generalize to unseen MRs,
and we propose a template-based input representation that considerably improves
the model's generalization capability. To further improve the model's
performance, we propose an approach based on self-training using fine-tuned
BLEURT for pseudo response selection. On the commonly-used SGD and Weather
benchmarks, the proposed self-training approach improves tree accuracy by 46%+
and reduces the slot error rates by 73%+ over the strong T5 baselines in
few-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FPM: A Collection of Large-scale Foundation Pre-trained Language Models. (arXiv:2111.04909v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.04909">
<div class="article-summary-box-inner">
<span><p>Large-scale Transformer models have significantly promoted the recent
development of natural language processing applications. However, little effort
has been made to unify the effective models. In this paper, driven by providing
a new set of baseline models in the future, we adopt various novel transformer
architectures and launch a model set with the help of recent mainstream
technologies. We focus the discussions on optimizing the depth of the networks
based on the existing powerful encode-decoder structures. We show that by
properly avoiding training defects such as non-convergence and degradation,
scaling up off-the-shelf transformer architectures consistently delivers better
performance. To stimulate future research on large-scale language model
pretraining, we present extensive results and detailed discussions on network
performance improvements with respect to the network depth and confirm the
existence of the optimal number of layers under specific tasks. To the best of
our knowledge, we provide the largest Chinese generative model and the largest
Chinese encoding model. The BERT language models we trained on English datasets
deliver a 14.45% higher F1 score than the Turing-NLR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Enactivist account of Mind Reading in Natural Language Understanding. (arXiv:2111.06179v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.06179">
<div class="article-summary-box-inner">
<span><p>In this paper we apply our understanding of the radical enactivist agenda to
the classic AI-hard problem of Natural Language Understanding. When Turing
devised his famous test the assumption was that a computer could use language
and the challenge would be to mimic human intelligence. It turned out playing
chess and formal logic were easy compared to understanding what people say. The
techniques of good old-fashioned AI (GOFAI) assume symbolic representation is
the core of reasoning and by that paradigm human communication consists of
transferring representations from one mind to another. However, one finds that
representations appear in another's mind, without appearing in the intermediary
language. People communicate by mind reading it seems. Systems with speech
interfaces such as Alexa and Siri are of course common, but they are limited.
Rather than adding mind reading skills, we introduced a "cheat" that enabled
our systems to fake it. The cheat is simple and only slightly interesting to
computer scientists and not at all interesting to philosophers. However,
reading about the enactivist idea that we "directly perceive" the intentions of
others, our cheat took on a new light and in this paper look again at how
natural language understanding might actually work between humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Vector Models with Textual Guidance for Fine-Grained Scientific Document Similarity. (arXiv:2111.08366v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08366">
<div class="article-summary-box-inner">
<span><p>We present a new scientific document similarity model based on matching
fine-grained aspects of texts. To train our model, we exploit a
naturally-occurring source of supervision: sentences in the full-text of papers
that cite multiple papers together (co-citations). Such co-citations not only
reflect close paper relatedness, but also provide textual descriptions of how
the co-cited papers are related. This novel form of textual supervision is used
for learning to match aspects across papers. We develop multi-vector
representations where vectors correspond to sentence-level aspects of
documents, and present two methods for aspect matching: (1) A fast method that
only matches single aspects, and (2) a method that makes sparse multiple
matches with an Optimal Transport mechanism that computes an Earth Mover's
Distance between aspects. Our approach improves performance on document
similarity tasks in four datasets. Further, our fast single-match method
achieves competitive results, paving the way for applying fine-grained
similarity to large scientific corpora. Code, data, and models to be at:
https://github.com/allenai/aspire
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-driven Model Generalizability in Crosslinguistic Low-resource Morphological Segmentation. (arXiv:2201.01845v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01845">
<div class="article-summary-box-inner">
<span><p>Common designs of model evaluation typically focus on monolingual settings,
where different models are compared according to their performance on a single
data set that is assumed to be representative of all possible data for the task
at hand. While this may be reasonable for a large data set, this assumption is
difficult to maintain in low-resource scenarios, where artifacts of the data
collection can yield data sets that are outliers, potentially making
conclusions about model performance coincidental. To address these concerns, we
investigate model generalizability in crosslinguistic low-resource scenarios.
Using morphological segmentation as the test case, we compare three broad
classes of models with different parameterizations, taking data from 11
languages across 6 language families. In each experimental setting, we evaluate
all models on a first data set, then examine their performance consistency when
introducing new randomly sampled data sets with the same size and when applying
the trained models to unseen test sets of varying sizes. The results
demonstrate that the extent of model generalization depends on the
characteristics of the data set, and does not necessarily rely heavily on the
data set size. Among the characteristics that we studied, the ratio of morpheme
overlap and that of the average number of morphemes per word between the
training and test sets are the two most prominent factors. Our findings suggest
that future work should adopt random sampling to construct data sets with
different sizes in order to make more responsible claims about model
evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Resources in the Tamasheq Language. (arXiv:2201.05051v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05051">
<div class="article-summary-box-inner">
<span><p>In this paper we present two datasets for Tamasheq, a developing language
mainly spoken in Mali and Niger. These two datasets were made available for the
IWSLT 2022 low-resource speech translation track, and they consist of
collections of radio recordings from daily broadcast news in Niger (Studio
Kalangou) and Mali (Studio Tamani). We share (i) a massive amount of unlabeled
audio data (671 hours) in five languages: French from Niger, Fulfulde, Hausa,
Tamasheq and Zarma, and (ii) a smaller 17 hours parallel corpus of audio
recordings in Tamasheq, with utterance-level translations in the French
language. All this data is shared under the Creative Commons BY-NC-ND 3.0
license. We hope these resources will inspire the speech community to develop
and benchmark models using the Tamasheq language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grounding Answers for Visual Questions Asked by Visually Impaired People. (arXiv:2202.01993v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01993">
<div class="article-summary-box-inner">
<span><p>Visual question answering is the task of answering questions about images. We
introduce the VizWiz-VQA-Grounding dataset, the first dataset that visually
grounds answers to visual questions asked by people with visual impairments. We
analyze our dataset and compare it with five VQA-Grounding datasets to
demonstrate what makes it similar and different. We then evaluate the SOTA VQA
and VQA-Grounding models and demonstrate that current SOTA algorithms often
fail to identify the correct visual evidence where the answer is located. These
models regularly struggle when the visual evidence occupies a small fraction of
the image, for images that are higher quality, as well as for visual questions
that require skills in text recognition. The dataset, evaluation server, and
leaderboard all can be found at the following link:
https://vizwiz.org/tasks-and-datasets/answer-grounding-for-vqa/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Logic Analogy Learning. (arXiv:2202.02436v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02436">
<div class="article-summary-box-inner">
<span><p>Letter-string analogy is an important analogy learning task which seems to be
easy for humans but very challenging for machines. The main idea behind current
approaches to solving letter-string analogies is to design heuristic rules for
extracting analogy structures and constructing analogy mappings. However, one
key problem is that it is difficult to build a comprehensive and exhaustive set
of analogy structures which can fully describe the subtlety of analogies. This
problem makes current approaches unable to handle complicated letter-string
analogy problems. In this paper, we propose Neural logic analogy learning
(Noan), which is a dynamic neural architecture driven by differentiable logic
reasoning to solve analogy problems. Each analogy problem is converted into
logical expressions consisting of logical variables and basic logical
operations (AND, OR, and NOT). More specifically, Noan learns the logical
variables as vector embeddings and learns each logical operation as a neural
module. In this way, the model builds computational graph integrating neural
network with logical reasoning to capture the internal logical structure of the
input letter strings. The analogy learning problem then becomes a True/False
evaluation problem of the logical expressions. Experiments show that our
machine learning-based Noan approach outperforms state-of-the-art approaches on
standard letter-string analogy benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for Low-Resource Language Translation?. (arXiv:2203.08850v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08850">
<div class="article-summary-box-inner">
<span><p>What can pre-trained multilingual sequence-to-sequence models like mBART
contribute to translating low-resource languages? We conduct a thorough
empirical experiment in 10 languages to ascertain this, considering five
factors: (1) the amount of fine-tuning data, (2) the noise in the fine-tuning
data, (3) the amount of pre-training data in the model, (4) the impact of
domain mismatch, and (5) language typology. In addition to yielding several
heuristics, the experiments form a framework for evaluating the data
sensitivities of machine translation systems. While mBART is robust to domain
differences, its translations for unseen and typologically distant languages
remain below 3.0 BLEU. In answer to our title's question, mBART is not a
low-resource panacea; we therefore encourage shifting the emphasis from new
models to new data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation. (arXiv:2203.09553v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09553">
<div class="article-summary-box-inner">
<span><p>Federated Learning (FL) on knowledge graphs (KGs) has yet to be as well
studied as other domains, such as computer vision and natural language
processing. A recent study FedE first proposes an FL framework that shares
entity embeddings of KGs across all clients. However, compared with model
sharing in vanilla FL, entity embedding sharing from FedE would incur severe
privacy leakage. Specifically, the known entity embedding can be used to infer
whether a specific relation between two entities exists in a private client. In
this paper, we first develop a novel attack that aims to recover the original
data based on embedding information, which is further used to evaluate the
vulnerabilities of FedE. Furthermore, we propose a Federated learning paradigm
with privacy-preserving Relation embedding aggregation (FedR) to tackle the
privacy issue in FedE. Compared to entity embedding sharing, relation embedding
sharing policy can significantly reduce the communication cost due to its
smaller size of queries. We conduct extensive experiments to evaluate FedR with
five different embedding learning models and three benchmark KG datasets.
Compared to FedE, FedR achieves similar utility and significant (nearly 2X)
improvements in both privacy and efficiency on link prediction task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">x-enVENT: A Corpus of Event Descriptions with Experiencer-specific Emotion and Appraisal Annotations. (arXiv:2203.10909v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.10909">
<div class="article-summary-box-inner">
<span><p>Emotion classification is often formulated as the task to categorize texts
into a predefined set of emotion classes. So far, this task has been the
recognition of the emotion of writers and readers, as well as that of entities
mentioned in the text. We argue that a classification setup for emotion
analysis should be performed in an integrated manner, including the different
semantic roles that participate in an emotion episode. Based on appraisal
theories in psychology, which treat emotions as reactions to events, we compile
an English corpus of written event descriptions. The descriptions depict
emotion-eliciting circumstances, and they contain mentions of people who
responded emotionally. We annotate all experiencers, including the original
author, with the emotions they likely felt. In addition, we link them to the
event they found salient (which can be different for different experiencers in
a text) by annotating event properties, or appraisals (e.g., the perceived
event undesirability, the uncertainty of its outcome). Our analysis reveals
patterns in the co-occurrence of people's emotions in interaction. Hence, this
richly-annotated resource provides useful data to study emotions and event
evaluations from the perspective of different roles, and it enables the
development of experiencer-specific emotion and appraisal classification
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer based ensemble for emotion detection. (arXiv:2203.11899v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.11899">
<div class="article-summary-box-inner">
<span><p>Detecting emotions in languages is important to accomplish a complete
interaction between humans and machines. This paper describes our contribution
to the WASSA 2022 shared task which handles this crucial task of emotion
detection. We have to identify the following emotions: sadness, surprise,
neutral, anger, fear, disgust, joy based on a given essay text. We are using an
ensemble of ELECTRA and BERT models to tackle this problem achieving an F1
score of $62.76\%$. Our codebase (https://bit.ly/WASSA_shared_task) and our
WandB project (https://wandb.ai/acl_wassa_pictxmanipal/acl_wassa) is publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">bitsa_nlp@LT-EDI-ACL2022: Leveraging Pretrained Language Models for Detecting Homophobia and Transphobia in Social Media Comments. (arXiv:2203.14267v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.14267">
<div class="article-summary-box-inner">
<span><p>Online social networks are ubiquitous and user-friendly. Nevertheless, it is
vital to detect and moderate offensive content to maintain decency and empathy.
However, mining social media texts is a complex task since users don't adhere
to any fixed patterns. Comments can be written in any combination of languages
and many of them may be low-resource.
</p>
<p>In this paper, we present our system for the LT-EDI shared task on detecting
homophobia and transphobia in social media comments. We experiment with a
number of monolingual and multilingual transformer based models such as mBERT
along with a data augmentation technique for tackling class imbalance. Such
pretrained large models have recently shown tremendous success on a variety of
benchmark tasks in natural language processing. We observe their performance on
a carefully annotated, real life dataset of YouTube comments in English as well
as Tamil.
</p>
<p>Our submission achieved ranks 9, 6 and 3 with a macro-averaged F1-score of
0.42, 0.64 and 0.58 in the English, Tamil and Tamil-English subtasks
respectively. The code for the system has been open sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A sequence-to-sequence approach for document-level relation extraction. (arXiv:2204.01098v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.01098">
<div class="article-summary-box-inner">
<span><p>Motivated by the fact that many relations cross the sentence boundary, there
has been increasing interest in document-level relation extraction (DocRE).
DocRE requires integrating information within and across sentences, capturing
complex interactions between mentions of entities. Most existing methods are
pipeline-based, requiring entities as input. However, jointly learning to
extract entities and relations can improve performance and be more efficient
due to shared parameters and training steps. In this paper, we develop a
sequence-to-sequence approach, seq2rel, that can learn the subtasks of DocRE
(entity extraction, coreference resolution and relation extraction) end-to-end,
replacing a pipeline of task-specific components. Using a simple strategy we
call entity hinting, we compare our approach to existing pipeline-based methods
on several popular biomedical datasets, in some cases exceeding their
performance. We also report the first end-to-end results on these datasets for
future comparison. Finally, we demonstrate that, under our model, an end-to-end
approach outperforms a pipeline-based approach. Our code, data and trained
models are available at {\url{https://github.com/johngiorgi/seq2rel}}. An
online demo is available at
{\url{https://share.streamlit.io/johngiorgi/seq2rel/main/demo.py}}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FashionCLIP: Connecting Language and Images for Product Representations. (arXiv:2204.03972v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03972">
<div class="article-summary-box-inner">
<span><p>The steady rise of online shopping goes hand in hand with the development of
increasingly complex ML and NLP models. While most use cases are cast as
specialized supervised learning problems, we argue that practitioners would
greatly benefit from more transferable representations of products. In this
work, we build on recent developments in contrastive learning to train
FashionCLIP, a CLIP-like model for the fashion industry. We showcase its
capabilities for retrieval, classification and grounding, and release our model
and code to the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Template-free Prompt Tuning for Few-shot NER. (arXiv:2109.13532v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13532">
<div class="article-summary-box-inner">
<span><p>Prompt-based methods have been successfully applied in sentence-level
few-shot learning tasks, mostly owing to the sophisticated design of templates
and label words. However, when applied to token-level labeling tasks such as
NER, it would be time-consuming to enumerate the template queries over all
potential entity spans. In this work, we propose a more elegant method to
reformulate NER tasks as LM problems without any templates. Specifically, we
discard the template construction process while maintaining the word prediction
paradigm of pre-training models to predict a class-related pivot word (or label
word) at the entity position. Meanwhile, we also explore principled ways to
automatically search for appropriate label words that the pre-trained models
can easily adapt to. While avoiding complicated template-based process, the
proposed LM objective also reduces the gap between different objectives used in
pre-training and fine-tuning, thus it can better benefit the few-shot
performance. Experimental results demonstrate the effectiveness of the proposed
method over bert-tagger and template-based method under few-shot setting.
Moreover, the decoding speed of the proposed method is up to 1930.12 times
faster than the template-based method.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Intelligent Sight and Sound: A Chronic Cancer Pain Dataset. (arXiv:2204.04214v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04214">
<div class="article-summary-box-inner">
<span><p>Cancer patients experience high rates of chronic pain throughout the
treatment process. Assessing pain for this patient population is a vital
component of psychological and functional well-being, as it can cause a rapid
deterioration of quality of life. Existing work in facial pain detection often
have deficiencies in labeling or methodology that prevent them from being
clinically relevant. This paper introduces the first chronic cancer pain
dataset, collected as part of the Intelligent Sight and Sound (ISS) clinical
trial, guided by clinicians to help ensure that model findings yield clinically
relevant results. The data collected to date consists of 29 patients, 509
smartphone videos, 189,999 frames, and self-reported affective and activity
pain scores adopted from the Brief Pain Inventory (BPI). Using static images
and multi-modal data to predict self-reported pain levels, early models show
significant gaps between current methods available to predict pain today, with
room for improvement. Due to the especially sensitive nature of the inherent
Personally Identifiable Information (PII) of facial images, the dataset will be
released under the guidance and control of the National Institutes of Health
(NIH).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization. (arXiv:2204.04215v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04215">
<div class="article-summary-box-inner">
<span><p>Data-free quantization is a task that compresses the neural network to low
bit-width without access to original training data. Most existing data-free
quantization methods cause severe performance degradation due to inaccurate
activation clipping range and quantization error, especially for low bit-width.
In this paper, we present a simple yet effective data-free quantization method
with accurate activation clipping and adaptive batch normalization. Accurate
activation clipping (AAC) improves the model accuracy by exploiting accurate
activation information from the full-precision model. Adaptive batch
normalization firstly proposes to address the quantization error from
distribution changes by updating the batch normalization layer adaptively.
Extensive experiments demonstrate that the proposed data-free quantization
method can yield surprisingly performance, achieving 64.33% top-1 accuracy of
ResNet18 on ImageNet dataset, with 3.7% absolute improvement outperforming the
existing state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Trajectory-Aware Transformer for Video Super-Resolution. (arXiv:2204.04216v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04216">
<div class="article-summary-box-inner">
<span><p>Video super-resolution (VSR) aims to restore a sequence of high-resolution
(HR) frames from their low-resolution (LR) counterparts. Although some progress
has been made, there are grand challenges to effectively utilize temporal
dependency in entire video sequences. Existing approaches usually align and
aggregate video frames from limited adjacent frames (e.g., 5 or 7 frames),
which prevents these approaches from satisfactory results. In this paper, we
take one step further to enable effective spatio-temporal learning in videos.
We propose a novel Trajectory-aware Transformer for Video Super-Resolution
(TTVSR). In particular, we formulate video frames into several pre-aligned
trajectories which consist of continuous visual tokens. For a query token,
self-attention is only learned on relevant visual tokens along spatio-temporal
trajectories. Compared with vanilla vision Transformers, such a design
significantly reduces the computational cost and enables Transformers to model
long-range features. We further propose a cross-scale feature tokenization
module to overcome scale-changing problems that often occur in long-range
videos. Experimental results demonstrate the superiority of the proposed TTVSR
over state-of-the-art models, by extensive quantitative and qualitative
evaluations in four widely-used video super-resolution benchmarks. Both code
and pre-trained models can be downloaded at
https://github.com/researchmm/TTVSR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature-enhanced Adversarial Semi-supervised Semantic Segmentation Network for Pulmonary Embolism Annotation. (arXiv:2204.04217v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04217">
<div class="article-summary-box-inner">
<span><p>This study established a feature-enhanced adversarial semi-supervised
semantic segmentation model to automatically annotate pulmonary embolism lesion
areas in computed tomography pulmonary angiogram (CTPA) images. In current
studies, all of the PE CTPA image segmentation methods are trained by
supervised learning. However, the supervised learning models need to be
retrained and the images need to be relabeled when the CTPA images come from
different hospitals. This study proposed a semi-supervised learning method to
make the model applicable to different datasets by adding a small amount of
unlabeled images. By training the model with both labeled and unlabeled images,
the accuracy of unlabeled images can be improved and the labeling cost can be
reduced. Our semi-supervised segmentation model includes a segmentation network
and a discriminator network. We added feature information generated from the
encoder of segmentation network to the discriminator so that it can learn the
similarity between predicted mask and ground truth mask. This HRNet-based
architecture can maintain a higher resolution for convolutional operations so
the prediction of small PE lesion areas can be improved. We used the labeled
open-source dataset and the unlabeled National Cheng Kung University Hospital
(NCKUH) (IRB number: B-ER-108-380) dataset to train the semi-supervised
learning model, and the resulting mean intersection over union (mIOU), dice
score, and sensitivity achieved 0.3510, 0.4854, and 0.4253, respectively on the
NCKUH dataset. Then, we fine-tuned and tested the model with a small amount of
unlabeled PE CTPA images from China Medical University Hospital (CMUH) (IRB
number: CMUH110-REC3-173) dataset. Comparing the results of our semi-supervised
model with the supervised model, the mIOU, dice score, and sensitivity improved
from 0.2344, 0.3325, and 0.3151 to 0.3721, 0.5113, and 0.4967, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes for Medical Image Super-Resolution. (arXiv:2204.04218v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04218">
<div class="article-summary-box-inner">
<span><p>Super-resolving medical images can help physicians in providing more accurate
diagnostics. In many situations, computed tomography (CT) or magnetic resonance
imaging (MRI) techniques output several scans (modes) during a single
investigation, which can jointly be used (in a multimodal fashion) to further
boost the quality of super-resolution results. To this end, we propose a novel
multimodal multi-head convolutional attention module to super-resolve CT and
MRI scans. Our attention module uses the convolution operation to perform joint
spatial-channel attention on multiple concatenated input tensors, where the
kernel (receptive field) size controls the reduction rate of the spatial
attention and the number of convolutional filters controls the reduction rate
of the channel attention, respectively. We introduce multiple attention heads,
each head having a distinct receptive field size corresponding to a particular
reduction rate for the spatial attention. We integrate our multimodal
multi-head convolutional attention (MMHCA) into two deep neural architectures
for super-resolution and conduct experiments on three data sets. Our empirical
results show the superiority of our attention module over the state-of-the-art
attention mechanisms used in super-resolution. Moreover, we conduct an ablation
study to assess the impact of the components involved in our attention module,
e.g. the number of inputs or the number of heads.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Reliable and Explainable AI Model for Solid Pulmonary Nodule Diagnosis. (arXiv:2204.04219v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04219">
<div class="article-summary-box-inner">
<span><p>Lung cancer has the highest mortality rate of deadly cancers in the world.
Early detection is essential to treatment of lung cancer. However, detection
and accurate diagnosis of pulmonary nodules depend heavily on the experiences
of radiologists and can be a heavy workload for them. Computer-aided diagnosis
(CAD) systems have been developed to assist radiologists in nodule detection
and diagnosis, greatly easing the workload while increasing diagnosis accuracy.
Recent development of deep learning, greatly improved the performance of CAD
systems. However, lack of model reliability and interpretability remains a
major obstacle for its large-scale clinical application. In this work, we
proposed a multi-task explainable deep-learning model for pulmonary nodule
diagnosis. Our neural model can not only predict lesion malignancy but also
identify relevant manifestations. Further, the location of each manifestation
can also be visualized for visual interpretability. Our proposed neural model
achieved a test AUC of 0.992 on LIDC public dataset and a test AUC of 0.923 on
our in-house dataset. Moreover, our experimental results proved that by
incorporating manifestation identification tasks into the multi-task model, the
accuracy of the malignancy classification can also be improved. This multi-task
explainable model may provide a scheme for better interaction with the
radiologists in a clinical environment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision-Based American Sign Language Classification Approach via Deep Learning. (arXiv:2204.04235v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04235">
<div class="article-summary-box-inner">
<span><p>Hearing-impaired is the disability of partial or total hearing loss that
causes a significant problem for communication with other people in society.
American Sign Language (ASL) is one of the sign languages that most commonly
used language used by Hearing impaired communities to communicate with each
other. In this paper, we proposed a simple deep learning model that aims to
classify the American Sign Language letters as a step in a path for removing
communication barriers that are related to disabilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChildCI Framework: Analysis of Motor and Cognitive Development in Children-Computer Interaction for Age Detection. (arXiv:2204.04236v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04236">
<div class="article-summary-box-inner">
<span><p>This article presents a comprehensive analysis of the different tests
proposed in the recent ChildCI framework, proving its potential for generating
a better understanding of children's neuromotor and cognitive development along
time, as well as their possible application in other research areas such as
e-Health and e-Learning. In particular, we propose a set of over 100 global
features related to motor and cognitive aspects of the children interaction
with mobile devices, some of them collected and adapted from the literature.
Furthermore, we analyse the robustness and discriminative power of the proposed
feature set including experimental results for the task of children age group
detection based on their motor and cognitive behaviors. Two different scenarios
are considered in this study: i) single-test scenario, and ii) multiple-test
scenario. Results over 93% accuracy are achieved using the publicly available
ChildCIdb_v1 database (over 400 children from 18 months to 8 years old),
proving the high correlation of children's age with the way they interact with
mobile devices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Elastic shape analysis of surfaces with second-order Sobolev metrics: a comprehensive numerical framework. (arXiv:2204.04238v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04238">
<div class="article-summary-box-inner">
<span><p>This paper introduces a set of numerical methods for Riemannian shape
analysis of 3D surfaces within the setting of invariant (elastic) second-order
Sobolev metrics. More specifically, we address the computation of geodesics and
geodesic distances between parametrized or unparametrized immersed surfaces
represented as 3D meshes. Building on this, we develop tools for the
statistical shape analysis of sets of surfaces, including methods for
estimating Karcher means and performing tangent PCA on shape populations, and
for computing parallel transport along paths of surfaces. Our proposed approach
fundamentally relies on a relaxed variational formulation for the geodesic
matching problem via the use of varifold fidelity terms, which enable us to
enforce reparametrization independence when computing geodesics between
unparametrized surfaces, while also yielding versatile algorithms that allow us
to compare surfaces with varying sampling or mesh structures. Importantly, we
demonstrate how our relaxed variational framework can be extended to tackle
partially observed data. The different benefits of our numerical pipeline are
illustrated over various examples, synthetic and real.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding the Influence of Receptive Field and Network Complexity in Neural-Network-Guided TEM Image Analysis. (arXiv:2204.04250v1 [cond-mat.mtrl-sci])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04250">
<div class="article-summary-box-inner">
<span><p>Trained neural networks are promising tools to analyze the ever-increasing
amount of scientific image data, but it is unclear how to best customize these
networks for the unique features in transmission electron micrographs. Here, we
systematically examine how neural network architecture choices affect how
neural networks segment, or pixel-wise separate, crystalline nanoparticles from
amorphous background in transmission electron microscopy (TEM) images. We focus
on decoupling the influence of receptive field, or the area of the input image
that contributes to the output decision, from network complexity, which
dictates the number of trainable parameters. We find that for low-resolution
TEM images which rely on amplitude contrast to distinguish nanoparticles from
background, the receptive field does not significantly influence segmentation
performance. On the other hand, for high-resolution TEM images which rely on a
combination of amplitude and phase contrast changes to identify nanoparticles,
receptive field is a key parameter for increased performance, especially in
images with minimal amplitude contrast. Our results provide insight and
guidance as to how to adapt neural networks for applications with TEM datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Improving Cross-dataset Generalization of Deepfake Detectors. (arXiv:2204.04285v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04285">
<div class="article-summary-box-inner">
<span><p>Facial manipulation by deep fake has caused major security risks and raised
severe societal concerns. As a countermeasure, a number of deep fake detection
methods have been proposed recently. Most of them model deep fake detection as
a binary classification problem using a backbone convolutional neural network
(CNN) architecture pretrained for the task. These CNN-based methods have
demonstrated very high efficacy in deep fake detection with the Area under the
Curve (AUC) as high as 0.99. However, the performance of these methods degrades
significantly when evaluated across datasets. In this paper, we formulate deep
fake detection as a hybrid combination of supervised and reinforcement learning
(RL) to improve its cross-dataset generalization performance. The proposed
method chooses the top-k augmentations for each test sample by an RL agent in
an image-specific manner. The classification scores, obtained using CNN, of all
the augmentations of each test image are averaged together for final real or
fake classification. Through extensive experimental validation, we demonstrate
the superiority of our method over existing published research in cross-dataset
generalization of deep fake detectors, thus obtaining state-of-the-art
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to modulate random weights can induce task-specific contexts for economical meta and continual learning. (arXiv:2204.04297v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04297">
<div class="article-summary-box-inner">
<span><p>Neural networks are vulnerable to catastrophic forgetting when data
distributions are non-stationary during continual online learning; learning of
a later task often leads to forgetting of an earlier task. One solution
approach is model-agnostic continual meta-learning, whereby both task-specific
and meta parameters are trained. Here, we depart from this view and introduce a
novel neural-network architecture inspired by neuromodulation in biological
nervous systems. Neuromodulation is the biological mechanism that dynamically
controls and fine-tunes synaptic dynamics to complement the behavioral context
in real-time, which has received limited attention in machine learning. We
introduce a single-hidden-layer network that learns only a relatively small
context vector per task (task-specific parameters) that neuromodulates
unchanging, randomized weights (meta parameters) that transform the input. We
show that when task boundaries are available, this approach can eliminate
catastrophic forgetting entirely while also drastically reducing the number of
learnable parameters relative to other context-vector-based approaches.
Furthermore, by combining this model with a simple meta-learning approach for
inferring task identity, we demonstrate that the model can be generalized into
a framework to perform continual learning without knowledge of task boundaries.
Finally, we showcase the framework in a supervised continual online learning
scenario and discuss the implications of the proposed formalism.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmenting across places: The need for fair transfer learning with satellite imagery. (arXiv:2204.04358v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04358">
<div class="article-summary-box-inner">
<span><p>The increasing availability of high-resolution satellite imagery has enabled
the use of machine learning to support land-cover measurement and inform
policy-making. However, labelling satellite images is expensive and is
available for only some locations. This prompts the use of transfer learning to
adapt models from data-rich locations to others. Given the potential for
high-impact applications of satellite imagery across geographies, a systematic
assessment of transfer learning implications is warranted. In this work, we
consider the task of land-cover segmentation and study the fairness
implications of transferring models across locations. We leverage a large
satellite image segmentation benchmark with 5987 images from 18 districts (9
urban and 9 rural). Via fairness metrics we quantify disparities in model
performance along two axes -- across urban-rural locations and across
land-cover classes. Findings show that state-of-the-art models have better
overall accuracy in rural areas compared to urban areas, through unsupervised
domain adaptation methods transfer learning better to urban versus rural areas
and enlarge fairness gaps. In analysis of reasons for these findings, we show
that raw satellite images are overall more dissimilar between source and target
districts for rural than for urban locations. This work highlights the need to
conduct fairness analysis for satellite imagery segmentation models and
motivates the development of methods for fair transfer learning in order not to
introduce disparities between places, particularly urban and rural locations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention guided global enhancement and local refinement network for semantic segmentation. (arXiv:2204.04363v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04363">
<div class="article-summary-box-inner">
<span><p>The encoder-decoder architecture is widely used as a lightweight semantic
segmentation network. However, it struggles with a limited performance compared
to a well-designed Dilated-FCN model for two major problems. First, commonly
used upsampling methods in the decoder such as interpolation and deconvolution
suffer from a local receptive field, unable to encode global contexts. Second,
low-level features may bring noises to the network decoder through skip
connections for the inadequacy of semantic concepts in early encoder layers. To
tackle these challenges, a Global Enhancement Method is proposed to aggregate
global information from high-level feature maps and adaptively distribute them
to different decoder layers, alleviating the shortage of global contexts in the
upsampling process. Besides, a Local Refinement Module is developed by
utilizing the decoder features as the semantic guidance to refine the noisy
encoder features before the fusion of these two (the decoder features and the
encoder features). Then, the two methods are integrated into a Context Fusion
Block, and based on that, a novel Attention guided Global enhancement and Local
refinement Network (AGLN) is elaborately designed. Extensive experiments on
PASCAL Context, ADE20K, and PASCAL VOC 2012 datasets have demonstrated the
effectiveness of the proposed approach. In particular, with a vanilla
ResNet-101 backbone, AGLN achieves the state-of-the-art result (56.23% mean
IoU) on the PASCAL Context dataset. The code is available at
https://github.com/zhasen1996/AGLN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Channel Pruning In Quantization-aware Training: An Adaptive Projection-gradient Descent-shrinkage-splitting Method. (arXiv:2204.04375v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04375">
<div class="article-summary-box-inner">
<span><p>We propose an adaptive projection-gradient descent-shrinkage-splitting method
(APGDSSM) to integrate penalty based channel pruning into quantization-aware
training (QAT). APGDSSM concurrently searches weights in both the quantized
subspace and the sparse subspace. APGDSSM uses shrinkage operator and a
splitting technique to create sparse weights, as well as the Group Lasso
penalty to push the weight sparsity into channel sparsity. In addition, we
propose a novel complementary transformed l1 penalty to stabilize the training
for extreme compression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robotic Surgery Remote Mentoring via AR with 3D Scene Streaming and Hand Interaction. (arXiv:2204.04377v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04377">
<div class="article-summary-box-inner">
<span><p>With the growing popularity of robotic surgery, education becomes
increasingly important and urgently needed for the sake of patient safety.
However, experienced surgeons have limited accessibility due to their busy
clinical schedule or working in a distant city, thus can hardly provide
sufficient education resources for novices. Remote mentoring, as an effective
way, can help solve this problem, but traditional methods are limited to plain
text, audio, or 2D video, which are not intuitive nor vivid. Augmented reality
(AR), a thriving technique being widely used for various education scenarios,
is promising to offer new possibilities of visual experience and interactive
teaching. In this paper, we propose a novel AR-based robotic surgery remote
mentoring system with efficient 3D scene visualization and natural 3D hand
interaction. Using a head-mounted display (i.e., HoloLens), the mentor can
remotely monitor the procedure streamed from the trainee's operation side. The
mentor can also provide feedback directly with hand gestures, which is in-turn
transmitted to the trainee and viewed in surgical console as guidance. We
comprehensively validate the system on both real surgery stereo videos and
ex-vivo scenarios of common robotic training tasks (i.e., peg-transfer and
suturing). Promising results are demonstrated regarding the fidelity of
streamed scene visualization, the accuracy of feedback with hand interaction,
and the low-latency of each component in the entire remote mentoring system.
This work showcases the feasibility of leveraging AR technology for reliable,
flexible and low-cost solutions to robotic surgical education, and holds great
potential for clinical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond 3DMM: Learning to Capture High-fidelity 3D Face Shape. (arXiv:2204.04379v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04379">
<div class="article-summary-box-inner">
<span><p>3D Morphable Model (3DMM) fitting has widely benefited face analysis due to
its strong 3D priori. However, previous reconstructed 3D faces suffer from
degraded visual verisimilitude due to the loss of fine-grained geometry, which
is attributed to insufficient ground-truth 3D shapes, unreliable training
strategies and limited representation power of 3DMM. To alleviate this issue,
this paper proposes a complete solution to capture the personalized shape so
that the reconstructed shape looks identical to the corresponding person.
Specifically, given a 2D image as the input, we virtually render the image in
several calibrated views to normalize pose variations while preserving the
original image geometry. A many-to-one hourglass network serves as the
encode-decoder to fuse multiview features and generate vertex displacements as
the fine-grained geometry. Besides, the neural network is trained by directly
optimizing the visual effect, where two 3D shapes are compared by measuring the
similarity between the multiview images rendered from the shapes. Finally, we
propose to generate the ground-truth 3D shapes by registering RGB-D images
followed by pose and shape augmentation, providing sufficient data for network
training. Experiments on several challenging protocols demonstrate the superior
reconstruction accuracy of our proposal on the face shape.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A dataset of ant colonies motion trajectories in indoor and outdoor scenes for social cluster behavior study. (arXiv:2204.04380v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04380">
<div class="article-summary-box-inner">
<span><p>Motion and interaction of social insects (such as ants) have been studied by
many researchers to understand the clustering mechanism. Most studies in the
field of ant behavior have only focused on indoor environments, while outdoor
environments are still underexplored. In this paper, we collect 10 videos of
ant colonies from different indoor and outdoor scenes. And we develop an image
sequence marking software named VisualMarkData, which enables us to provide
annotations of ants in the video. In all 5354 frames, the location information
and the identification number of each ant are recorded for a total of 712 ants
and 114112 annotations. Moreover, we provide visual analysis tools to assess
and validate the technical quality and reproducibility of our data. It is hoped
that this dataset will contribute to a deeper exploration on the behavior of
the ant colony.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Federated Unsupervised Domain Adaptation for Face Recognition. (arXiv:2204.04382v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04382">
<div class="article-summary-box-inner">
<span><p>Given labeled data in a source domain, unsupervised domain adaptation has
been widely adopted to generalize models for unlabeled data in a target domain,
whose data distributions are different. However, existing works are
inapplicable to face recognition under privacy constraints because they require
sharing of sensitive face images between domains. To address this problem, we
propose federated unsupervised domain adaptation for face recognition, FedFR.
FedFR jointly optimizes clustering-based domain adaptation and federated
learning to elevate performance on the target domain. Specifically, for
unlabeled data in the target domain, we enhance a clustering algorithm with
distance constrain to improve the quality of predicted pseudo labels. Besides,
we propose a new domain constraint loss (DCL) to regularize source domain
training in federated learning. Extensive experiments on a newly constructed
benchmark demonstrate that FedFR outperforms the baseline and classic methods
on the target domain by 3% to 14% on different evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Two Dimensions of Worst-case Training and the Integrated Effect for Out-of-domain Generalization. (arXiv:2204.04384v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04384">
<div class="article-summary-box-inner">
<span><p>Training with an emphasis on "hard-to-learn" components of the data has been
proven as an effective method to improve the generalization of machine learning
models, especially in the settings where robustness (e.g., generalization
across distributions) is valued. Existing literature discussing this
"hard-to-learn" concept are mainly expanded either along the dimension of the
samples or the dimension of the features. In this paper, we aim to introduce a
simple view merging these two dimensions, leading to a new, simple yet
effective, heuristic to train machine learning models by emphasizing the
worst-cases on both the sample and the feature dimensions. We name our method
W2D following the concept of "Worst-case along Two Dimensions". We validate the
idea and demonstrate its empirical strength over standard benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Divergence-aware Federated Self-Supervised Learning. (arXiv:2204.04385v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04385">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) is capable of learning remarkable
representations from centrally available data. Recent works further implement
federated learning with SSL to learn from rapidly growing decentralized
unlabeled images (e.g., from cameras and phones), often resulted from privacy
constraints. Extensive attention has been paid to SSL approaches based on
Siamese networks. However, such an effort has not yet revealed deep insights
into various fundamental building blocks for the federated self-supervised
learning (FedSSL) architecture. We aim to fill in this gap via in-depth
empirical study and propose a new method to tackle the non-independently and
identically distributed (non-IID) data problem of decentralized data. Firstly,
we introduce a generalized FedSSL framework that embraces existing SSL methods
based on Siamese networks and presents flexibility catering to future methods.
In this framework, a server coordinates multiple clients to conduct SSL
training and periodically updates local models of clients with the aggregated
global model. Using the framework, our study uncovers unique insights of
FedSSL: 1) stop-gradient operation, previously reported to be essential, is not
always necessary in FedSSL; 2) retaining local knowledge of clients in FedSSL
is particularly beneficial for non-IID data. Inspired by the insights, we then
propose a new approach for model update, Federated Divergence-aware Exponential
Moving Average update (FedEMA). FedEMA updates local models of clients
adaptively using EMA of the global model, where the decay rate is dynamically
measured by model divergence. Extensive experiments demonstrate that FedEMA
outperforms existing methods by 3-4% on linear evaluation. We hope that this
work will provide useful insights for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual-Stage Approach Toward Hyperspectral Image Super-Resolution. (arXiv:2204.04387v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04387">
<div class="article-summary-box-inner">
<span><p>Hyperspectral image produces high spectral resolution at the sacrifice of
spatial resolution. Without reducing the spectral resolution, improving the
resolution in the spatial domain is a very challenging problem. Motivated by
the discovery that hyperspectral image exhibits high similarity between
adjacent bands in a large spectral range, in this paper, we explore a new
structure for hyperspectral image super-resolution (DualSR), leading to a
dual-stage design, i.e., coarse stage and fine stage. In coarse stage, five
bands with high similarity in a certain spectral range are divided into three
groups, and the current band is guided to study the potential knowledge. Under
the action of alternative spectral fusion mechanism, the coarse SR image is
super-resolved in band-by-band. In order to build model from a global
perspective, an enhanced back-projection method via spectral angle constraint
is developed in fine stage to learn the content of spatial-spectral
consistency, dramatically improving the performance gain. Extensive experiments
demonstrate the effectiveness of the proposed coarse stage and fine stage.
Besides, our network produces state-of-the-art results against existing works
in terms of spatial reconstruction and spectral fidelity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">E^2TAD: An Energy-Efficient Tracking-based Action Detector. (arXiv:2204.04416v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04416">
<div class="article-summary-box-inner">
<span><p>Video action detection (spatio-temporal action localization) is usually the
starting point for human-centric intelligent analysis of videos nowadays. It
has high practical impacts for many applications across robotics, security,
healthcare, etc. The two-stage paradigm of Faster R-CNN inspires a standard
paradigm of video action detection in object detection, i.e., firstly
generating person proposals and then classifying their actions. However, none
of the existing solutions could provide fine-grained action detection to the
"who-when-where-what" level. This paper presents a tracking-based solution to
accurately and efficiently localize predefined key actions spatially (by
predicting the associated target IDs and locations) and temporally (by
predicting the time in exact frame indices). This solution won first place in
the UAV-Video Track of 2021 Low-Power Computer Vision Challenge (LPCVC).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mapping Temporary Slums from Satellite Imagery using a Semi-Supervised Approach. (arXiv:2204.04419v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04419">
<div class="article-summary-box-inner">
<span><p>One billion people worldwide are estimated to be living in slums, and
documenting and analyzing these regions is a challenging task. As compared to
regular slums; the small, scattered and temporary nature of temporary slums
makes data collection and labeling tedious and time-consuming. To tackle this
challenging problem of temporary slums detection, we present a semi-supervised
deep learning segmentation-based approach; with the strategy to detect initial
seed images in the zero-labeled data settings. A small set of seed samples (32
in our case) are automatically discovered by analyzing the temporal changes,
which are manually labeled to train a segmentation and representation learning
module. The segmentation module gathers high dimensional image representations,
and the representation learning module transforms image representations into
embedding vectors. After that, a scoring module uses the embedding vectors to
sample images from a large pool of unlabeled images and generates pseudo-labels
for the sampled images. These sampled images with their pseudo-labels are added
to the training set to update the segmentation and representation learning
modules iteratively. To analyze the effectiveness of our technique, we
construct a large geographically marked dataset of temporary slums. This
dataset constitutes more than 200 potential temporary slum locations (2.28
square kilometers) found by sieving sixty-eight thousand images from 12
metropolitan cities of Pakistan covering 8000 square kilometers. Furthermore,
our proposed method outperforms several competitive semi-supervised semantic
segmentation baselines on a similar setting. The code and the dataset will be
made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unbiased Directed Object Attention Graph for Object Navigation. (arXiv:2204.04421v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04421">
<div class="article-summary-box-inner">
<span><p>Object navigation tasks require agents to locate specific objects in unknown
environments based on visual information. Previously, graph convolutions were
used to implicitly explore the relationships between objects. However, due to
differences in visibility among objects, it is easy to generate biases in
object attention. Thus, in this paper, we propose a directed object attention
(DOA) graph to guide the agent in explicitly learning the attention
relationships between objects, thereby reducing the object attention bias. In
particular, we use the DOA graph to perform unbiased adaptive object attention
(UAOA) on the object features and unbiased adaptive image attention (UAIA) on
the raw images, respectively. To distinguish features in different branches, a
concise adaptive branch energy distribution (ABED) method is proposed. We
assess our methods on the AI2-Thor dataset. Compared with the state-of-the-art
(SOTA) method, our method reports 7.4%, 8.1% and 17.6% increase in success rate
(SR), success weighted by path length (SPL) and success weighted by action
efficiency (SAE), respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Differential Filters for Fast and Communication-Efficient Federated Learning. (arXiv:2204.04424v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04424">
<div class="article-summary-box-inner">
<span><p>Federated learning (FL) scenarios inherently generate a large communication
overhead by frequently transmitting neural network updates between clients and
server. To minimize the communication cost, introducing sparsity in conjunction
with differential updates is a commonly used technique. However, sparse model
updates can slow down convergence speed or unintentionally skip certain update
aspects, e.g., learned features, if error accumulation is not properly
addressed. In this work, we propose a new scaling method operating at the
granularity of convolutional filters which 1) compensates for highly sparse
updates in FL processes, 2) adapts the local models to new data domains by
enhancing some features in the filter space while diminishing others and 3)
motivates extra sparsity in updates and thus achieves higher compression
ratios, i.e., savings in the overall data transfer. Compared to unscaled
updates and previous work, experimental results on different computer vision
tasks (Pascal VOC, CIFAR10, Chest X-Ray) and neural networks (ResNets,
MobileNets, VGGs) in uni-, bidirectional and partial update FL settings show
that the proposed method improves the performance of the central server model
while converging faster and reducing the total amount of transmitted data by up
to 377 times.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ManiTrans: Entity-Level Text-Guided Image Manipulation via Token-wise Semantic Alignment and Generation. (arXiv:2204.04428v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04428">
<div class="article-summary-box-inner">
<span><p>Existing text-guided image manipulation methods aim to modify the appearance
of the image or to edit a few objects in a virtual or simple scenario, which is
far from practical application. In this work, we study a novel task on
text-guided image manipulation on the entity level in the real world. The task
imposes three basic requirements, (1) to edit the entity consistent with the
text descriptions, (2) to preserve the text-irrelevant regions, and (3) to
merge the manipulated entity into the image naturally. To this end, we propose
a new transformer-based framework based on the two-stage image synthesis
method, namely \textbf{ManiTrans}, which can not only edit the appearance of
entities but also generate new entities corresponding to the text guidance. Our
framework incorporates a semantic alignment module to locate the image regions
to be manipulated, and a semantic loss to help align the relationship between
the vision and language. We conduct extensive experiments on the real datasets,
CUB, Oxford, and COCO datasets to verify that our method can distinguish the
relevant and irrelevant regions and achieve more precise and flexible
manipulation compared with baseline methods. The project homepage is
\url{https://jawang19.github.io/manitrans}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HSTR-Net: High Spatio-Temporal Resolution Video Generation For Wide Area Surveillance. (arXiv:2204.04435v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04435">
<div class="article-summary-box-inner">
<span><p>Wide area surveillance has many applications and tracking of objects under
observation is an important task, which often needs high spatio-temporal
resolution (HSTR) video for better precision. This paper presents the usage of
multiple video feeds for the generation of HSTR video as an extension of
reference based super resolution (RefSR). One feed captures video at high
spatial resolution with low frame rate (HSLF) while the other captures low
spatial resolution and high frame rate (LSHF) video simultaneously for the same
scene. The main purpose is to create an HSTR video from the fusion of HSLF and
LSHF videos. In this paper we propose an end-to-end trainable deep network that
performs optical flow estimation and frame reconstruction by combining inputs
from both video feeds. The proposed architecture provides significant
improvement over existing video frame interpolation and RefSR techniques in
terms of objective PSNR and SSIM metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guided deep learning by subaperture decomposition: ocean patterns from SAR imagery. (arXiv:2204.04438v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04438">
<div class="article-summary-box-inner">
<span><p>Spaceborne synthetic aperture radar can provide meters scale images of the
ocean surface roughness day or night in nearly all weather conditions. This
makes it a unique asset for many geophysical applications. Sentinel 1 SAR wave
mode vignettes have made possible to capture many important oceanic and
atmospheric phenomena since 2014. However, considering the amount of data
provided, expanding applications requires a strategy to automatically process
and extract geophysical parameters. In this study, we propose to apply
subaperture decomposition as a preprocessing stage for SAR deep learning
models. Our data centring approach surpassed the baseline by 0.7, obtaining
state of the art on the TenGeoPSARwv data set. In addition, we empirically
showed that subaperture decomposition could bring additional information over
the original vignette, by rising the number of clusters for an unsupervised
segmentation method. Overall, we encourage the development of data centring
approaches, showing that, data preprocessing could bring significant
performance improvements over existing deep learning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Noise-based Enhancement for Foveated Rendering. (arXiv:2204.04455v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04455">
<div class="article-summary-box-inner">
<span><p>Human visual sensitivity to spatial details declines towards the periphery.
Novel image synthesis techniques, so-called foveated rendering, exploit this
observation and reduce the spatial resolution of synthesized images for the
periphery, avoiding the synthesis of high-spatial-frequency details that are
costly to generate but not perceived by a viewer. However, contemporary
techniques do not make a clear distinction between the range of spatial
frequencies that must be reproduced and those that can be omitted. For a given
eccentricity, there is a range of frequencies that are detectable but not
resolvable. While the accurate reproduction of these frequencies is not
required, an observer can detect their absence if completely omitted. We use
this observation to improve the performance of existing foveated rendering
techniques. We demonstrate that this specific range of frequencies can be
efficiently replaced with procedural noise whose parameters are carefully tuned
to image content and human perception. Consequently, these frequencies do not
have to be synthesized during rendering, allowing more aggressive foveation,
and they can be replaced by noise generated in a less expensive post-processing
step, leading to improved performance of the rendering system. Our main
contribution is a perceptually-inspired technique for deriving the parameters
of the noise required for the enhancement and its calibration. The method
operates on rendering output and runs at rates exceeding 200FPS at 4K
resolution, making it suitable for integration with real-time foveated
rendering systems for VR and AR devices. We validate our results and compare
them to the existing contrast enhancement technique in user experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Refining time-space traffic diagrams: A multiple linear regression model. (arXiv:2204.04457v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04457">
<div class="article-summary-box-inner">
<span><p>A time-space traffic (TS) diagram that presents traffic states in time-space
cells with colors is one of the most important traffic analysis and
visualization tools. Despite its importance for transportation research and
engineering, most TS diagrams that have already existed or are being produced
are too coarse to exhibit detailed traffic dynamics due to the limitation of
the current information technology and traffic infrastructure investment. To
increase the resolution of a TS diagram and make it present more traffic
details, this paper introduces a TS diagram refinement problem and proposes a
multiple linear regression-based model to solve the problem. Two tests, which
attempt to increase the resolution of a TS diagram for 4 and 16 times,
respectively, are carried out to evaluate the performance of the proposed
model. The data collected from different time, different location and even
different country is involved to thoroughly evaluate the accuracy and
transferability of the proposed model. The strict tests with diverse data show
that the proposed model, although it is simple in form, is able to refine a TS
diagram with a promising accuracy and reliable transferability. The proposed
refinement model will "save" those widely-existing TS diagrams from their
blurry "faces" and make it possible to learn more traffic details from those TS
diagrams.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A3CLNN: Spatial, Spectral and Multiscale Attention ConvLSTM Neural Network for Multisource Remote Sensing Data Classification. (arXiv:2204.04462v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04462">
<div class="article-summary-box-inner">
<span><p>The problem of effectively exploiting the information multiple data sources
has become a relevant but challenging research topic in remote sensing. In this
paper, we propose a new approach to exploit the complementarity of two data
sources: hyperspectral images (HSIs) and light detection and ranging (LiDAR)
data. Specifically, we develop a new dual-channel spatial, spectral and
multiscale attention convolutional long short-term memory neural network
(called dual-channel A3CLNN) for feature extraction and classification of
multisource remote sensing data. Spatial, spectral and multiscale attention
mechanisms are first designed for HSI and LiDAR data in order to learn
spectral- and spatial-enhanced feature representations, and to represent
multiscale information for different classes. In the designed fusion network, a
novel composite attention learning mechanism (combined with a three-level
fusion strategy) is used to fully integrate the features in these two data
sources. Finally, inspired by the idea of transfer learning, a novel stepwise
training strategy is designed to yield a final classification result. Our
experimental results, conducted on several multisource remote sensing data
sets, demonstrate that the newly proposed dual-channel A3CLNN exhibits better
feature representation ability (leading to more competitive classification
performance) than other state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ultrasound Signal Processing: From Models to Deep Learning. (arXiv:2204.04466v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04466">
<div class="article-summary-box-inner">
<span><p>Medical ultrasound imaging relies heavily on high-quality signal processing
algorithms to provide reliable and interpretable image reconstructions.
Hand-crafted reconstruction methods, often based on approximations of the
underlying measurement model, are useful in practice, but notoriously fall
behind in terms of image quality. More sophisticated solutions, based on
statistical modelling, careful parameter tuning, or through increased model
complexity, can be sensitive to different environments. Recently, deep learning
based methods have gained popularity, which are optimized in a data-driven
fashion. These model-agnostic methods often rely on generic model structures,
and require vast training data to converge to a robust solution. A relatively
new paradigm combines the power of the two: leveraging data-driven deep
learning, as well as exploiting domain knowledge. These model-based solutions
yield high robustness, and require less trainable parameters and training data
than conventional neural networks. In this work we provide an overview of these
methods from the recent literature, and discuss a wide variety of ultrasound
applications. We aim to inspire the reader to further research in this area,
and to address the opportunities within the field of ultrasound signal
processing. We conclude with a future perspective on these model-based deep
learning techniques for medical ultrasound applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">S4OD: Semi-Supervised learning for Single-Stage Object Detection. (arXiv:2204.04492v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04492">
<div class="article-summary-box-inner">
<span><p>Single-stage detectors suffer from extreme foreground-background class
imbalance, while two-stage detectors do not. Therefore, in semi-supervised
object detection, two-stage detectors can deliver remarkable performance by
only selecting high-quality pseudo labels based on classification scores.
However, directly applying this strategy to single-stage detectors would
aggravate the class imbalance with fewer positive samples. Thus, single-stage
detectors have to consider both quality and quantity of pseudo labels
simultaneously. In this paper, we design a dynamic self-adaptive threshold
(DSAT) strategy in classification branch, which can automatically select pseudo
labels to achieve an optimal trade-off between quality and quantity. Besides,
to assess the regression quality of pseudo labels in single-stage detectors, we
propose a module to compute the regression uncertainty of boxes based on
Non-Maximum Suppression. By leveraging only 10% labeled data from COCO, our
method achieves 35.0% AP on anchor-free detector (FCOS) and 32.9% on
anchor-based detector (RetinaNet).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides. (arXiv:2204.04494v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04494">
<div class="article-summary-box-inner">
<span><p>In the clinic, resected tissue samples are stained with Hematoxylin-and-Eosin
(H&amp;E) and/or Immunhistochemistry (IHC) stains and presented to the pathologists
on glass slides or as digital scans for diagnosis and assessment of disease
progression. Cell-level quantification, e.g. in IHC protein expression scoring,
can be extremely inefficient and subjective. We present DeepLIIF
(https://deepliif.org), a first free online platform for efficient and
reproducible IHC scoring. DeepLIIF outperforms current state-of-the-art
approaches (relying on manual error-prone annotations) by virtually restaining
clinical IHC slides with more informative multiplex immunofluorescence
staining. Our DeepLIIF cloud-native platform supports (1) more than 150
proprietary/non-proprietary input formats via the Bio-Formats standard, (2)
interactive adjustment, visualization, and downloading of the IHC
quantification results and the accompanying restained images, (3) consumption
of an exposed workflow API programmatically or through interactive plugins for
open source whole slide image viewers such as QuPath/ImageJ, and (4) auto
scaling to efficiently scale GPU resources based on user demand.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Exploitation of Deepfake Model Recognition. (arXiv:2204.04513v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04513">
<div class="article-summary-box-inner">
<span><p>Despite recent advances in Generative Adversarial Networks (GANs), with
special focus to the Deepfake phenomenon there is no a clear understanding
neither in terms of explainability nor of recognition of the involved models.
In particular, the recognition of a specific GAN model that generated the
deepfake image compared to many other possible models created by the same
generative architecture (e.g. StyleGAN) is a task not yet completely addressed
in the state-of-the-art. In this work, a robust processing pipeline to evaluate
the possibility to point-out analytic fingerprints for Deepfake model
recognition is presented. After exploiting the latent space of 50 slightly
different models through an in-depth analysis on the generated images, a proper
encoder was trained to discriminate among these models obtaining a
classification accuracy of over 96%. Once demonstrated the possibility to
discriminate extremely similar images, a dedicated metric exploiting the
insights discovered in the latent space was introduced. By achieving a final
accuracy of more than 94% for the Model Recognition task on images generated by
models not employed in the training phase, this study takes an important step
in countering the Deepfake phenomenon introducing a sort of signature in some
sense similar to those employed in the multimedia forensics field (e.g. for
camera source identification task, image ballistics task, etc).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Informed Deep Learning Models Enable High-Confidence Predictions for Digital Histopathology. (arXiv:2204.04516v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04516">
<div class="article-summary-box-inner">
<span><p>A model's ability to express its own predictive uncertainty is an essential
attribute for maintaining clinical user confidence as computational biomarkers
are deployed into real-world medical settings. In the domain of cancer digital
histopathology, we describe a novel, clinically-oriented approach to
uncertainty quantification (UQ) for whole-slide images, estimating uncertainty
using dropout and calculating thresholds on training data to establish cutoffs
for low- and high-confidence predictions. We train models to identify lung
adenocarcinoma vs. squamous cell carcinoma and show that high-confidence
predictions outperform predictions without UQ, in both cross-validation and
testing on two large external datasets spanning multiple institutions. Our
testing strategy closely approximates real-world application, with predictions
generated on unsupervised, unannotated slides using predetermined thresholds.
Furthermore, we show that UQ thresholding remains reliable in the setting of
domain shift, with accurate high-confidence predictions of adenocarcinoma vs.
squamous cell carcinoma for out-of-distribution, non-lung cancer cohorts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Free Black-Box Watermark and Ownership Proof for Image Classification Neural Networks. (arXiv:2204.04522v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04522">
<div class="article-summary-box-inner">
<span><p>Watermarking has become a plausible candidate for ownership verification and
intellectual property protection of deep neural networks. Regarding image
classification neural networks, current watermarking schemes uniformly resort
to backdoor triggers. However, injecting a backdoor into a neural network
requires knowledge of the training dataset, which is usually unavailable in the
real-world commercialization. Meanwhile, established watermarking schemes
oversight the potential damage of exposed evidence during ownership
verification and the watermarking algorithms themselves. Those concerns decline
current watermarking schemes from industrial applications. To confront these
challenges, we propose a knowledge-free black-box watermarking scheme for image
classification neural networks. The image generator obtained from a data-free
distillation process is leveraged to stabilize the network's performance during
the backdoor injection. A delicate encoding and verification protocol is
designed to ensure the scheme's security against knowledgable adversaries. We
also give a pioneering analysis of the capacity of the watermarking scheme.
Experiment results proved the functionality-preserving capability and security
of the proposed watermarking scheme.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Labeling Refinement for Robust Representation Learning with Bootstrap Your Own Latent. (arXiv:2204.04545v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04545">
<div class="article-summary-box-inner">
<span><p>In this work, we have worked towards two major goals. Firstly, we have
investigated the importance of Batch Normalisation (BN) layers in a
non-contrastive representation learning framework called Bootstrap Your Own
Latent (BYOL). We conducted several experiments to conclude that BN layers are
not necessary for representation learning in BYOL. Moreover, BYOL only learns
from the positive pairs of images but ignores other semantically similar images
in the same input batch. For the second goal, we have introduced two new loss
functions to determine the semantically similar pairs in the same input batch
of images and reduce the distance between their representations. These loss
functions are Cross-Cosine Similarity Loss (CCSL) and Cross-Sigmoid Similarity
Loss (CSSL). Using the proposed loss functions, we are able to surpass the
performance of Vanilla BYOL (71.04%) by training the BYOL framework using CCSL
loss (76.87%) on the STL10 dataset. BYOL trained using CSSL loss performs
comparably with Vanilla BYOL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive search area for fast motion estimation. (arXiv:2204.04546v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04546">
<div class="article-summary-box-inner">
<span><p>This paper suggests a new method for determining the search area for a motion
estimation algorithm based on block matching. The search area is adaptively
found in the proposed method for each frame block. This search area is similar
to that of the full search (FS) algorithm but smaller for most blocks of a
frame. Therefore, the proposed algorithm is analogous to FS in terms of
regularity but has much less computational complexity. The temporal and spatial
correlations among the motion vectors of blocks are used to find the search
area. The matched block is chosen from a rectangular area that the prediction
vectors set out. Simulation results indicate that the speed of the proposed
algorithm is at least seven times better than the FS algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Transformer for Nursing Activity Recognition. (arXiv:2204.04564v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04564">
<div class="article-summary-box-inner">
<span><p>In an aging population, elderly patient safety is a primary concern at
hospitals and nursing homes, which demands for increased nurse care. By
performing nurse activity recognition, we can not only make sure that all
patients get an equal desired care, but it can also free nurses from manual
documentation of activities they perform, leading to a fair and safe place of
care for the elderly. In this work, we present a multimodal transformer-based
network, which extracts features from skeletal joints and acceleration data,
and fuses them to perform nurse activity recognition. Our method achieves
state-of-the-art performance of 81.8% accuracy on the benchmark dataset
available for nurse activity recognition from the Nurse Care Activity
Recognition Challenge. We perform ablation studies to show that our fusion
model is better than single modality transformer variants (using only
acceleration or skeleton joints data). Our solution also outperforms
state-of-the-art ST-GCN, GRU and other classical hand-crafted-feature-based
classifier solutions by a margin of 1.6%, on the NCRC dataset. Code is
available at \url{https://github.com/Momilijaz96/MMT_for_NCRC}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification. (arXiv:2204.04567v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04567">
<div class="article-summary-box-inner">
<span><p>Few-shot classification is a challenging problem as only very few training
examples are given for each new task. One of the effective research lines to
address this challenge focuses on learning deep representations driven by a
similarity measure between a query image and few support images of some class.
Statistically, this amounts to measure the dependency of image features, viewed
as random vectors in a high-dimensional embedding space. Previous methods
either only use marginal distributions without considering joint distributions,
suffering from limited representation capability, or are computationally
expensive though harnessing joint distributions. In this paper, we propose a
deep Brownian Distance Covariance (DeepBDC) method for few-shot classification.
The central idea of DeepBDC is to learn image representations by measuring the
discrepancy between joint characteristic functions of embedded features and
product of the marginals. As the BDC metric is decoupled, we formulate it as a
highly modular and efficient layer. Furthermore, we instantiate DeepBDC in two
different few-shot classification frameworks. We make experiments on six
standard few-shot image benchmarks, covering general object recognition,
fine-grained categorization and cross-domain classification. Extensive
evaluations show our DeepBDC significantly outperforms the counterparts, while
establishing new state-of-the-art results. The source code is available at
<a href="http://www.peihuali.org/DeepBDC">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Cross-Modal Representation Learning with Progressive Self-Distillation. (arXiv:2204.04588v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04588">
<div class="article-summary-box-inner">
<span><p>The learning objective of vision-language approach of CLIP does not
effectively account for the noisy many-to-many correspondences found in
web-harvested image captioning datasets, which contributes to its compute and
data inefficiency. To address this challenge, we introduce a novel training
framework based on cross-modal contrastive learning that uses progressive
self-distillation and soft image-text alignments to more efficiently learn
robust representations from noisy data. Our model distills its own knowledge to
dynamically generate soft-alignment targets for a subset of images and captions
in every minibatch, which are then used to update its parameters. Extensive
evaluation across 14 benchmark datasets shows that our method consistently
outperforms its CLIP counterpart in multiple settings, including: (a) zero-shot
classification, (b) linear probe transfer, and (c) image-text retrieval,
without incurring added computational cost. Analysis using an ImageNet-based
robustness test-bed reveals that our method offers better effective robustness
to natural distribution shifts compared to both ImageNet-trained models and
CLIP itself. Lastly, pretraining with datasets spanning two orders of magnitude
in size shows that our improvements over CLIP tend to scale with number of
training examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention. (arXiv:2204.04601v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04601">
<div class="article-summary-box-inner">
<span><p>Interpretability is an important property for visual models as it helps
researchers and users understand the internal mechanism of a complex model.
However, generating semantic explanations about the learned representation is
challenging without direct supervision to produce such explanations. We propose
a general framework, Latent Visual Semantic Explainer (LaViSE), to teach any
existing convolutional neural network to generate text descriptions about its
own latent representations at the filter level. Our method constructs a mapping
between the visual and semantic spaces using generic image datasets, using
images and category names. It then transfers the mapping to the target domain
which does not have semantic labels. The proposed framework employs a modular
structure and enables to analyze any trained network whether or not its
original training data is available. We show that our method can generate novel
descriptions for learned filters beyond the set of categories defined in the
training dataset and perform an extensive evaluation on multiple datasets. We
also demonstrate a novel application of our method for unsupervised dataset
bias analysis which allows us to automatically discover hidden biases in
datasets or compare different subsets without using additional labels. The
dataset and code are made public to facilitate further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Video Representation Learning with Motion-Contrastive Perception. (arXiv:2204.04607v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04607">
<div class="article-summary-box-inner">
<span><p>Visual-only self-supervised learning has achieved significant improvement in
video representation learning. Existing related methods encourage models to
learn video representations by utilizing contrastive learning or designing
specific pretext tasks. However, some models are likely to focus on the
background, which is unimportant for learning video representations. To
alleviate this problem, we propose a new view called long-range residual frame
to obtain more motion-specific information. Based on this, we propose the
Motion-Contrastive Perception Network (MCPNet), which consists of two branches,
namely, Motion Information Perception (MIP) and Contrastive Instance Perception
(CIP), to learn generic video representations by focusing on the changing areas
in videos. Specifically, the MIP branch aims to learn fine-grained motion
features, and the CIP branch performs contrastive learning to learn overall
semantics information for each instance. Experiments on two benchmark datasets
UCF-101 and HMDB-51 show that our method outperforms current state-of-the-art
visual-only self-supervised approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Pixel-Level Distinctions for Video Highlight Detection. (arXiv:2204.04615v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04615">
<div class="article-summary-box-inner">
<span><p>The goal of video highlight detection is to select the most attractive
segments from a long video to depict the most interesting parts of the video.
Existing methods typically focus on modeling relationship between different
video segments in order to learning a model that can assign highlight scores to
these segments; however, these approaches do not explicitly consider the
contextual dependency within individual segments. To this end, we propose to
learn pixel-level distinctions to improve the video highlight detection. This
pixel-level distinction indicates whether or not each pixel in one video
belongs to an interesting section. The advantages of modeling such fine-level
distinctions are two-fold. First, it allows us to exploit the temporal and
spatial relations of the content in one video, since the distinction of a pixel
in one frame is highly dependent on both the content before this frame and the
content around this pixel in this frame. Second, learning the pixel-level
distinction also gives a good explanation to the video highlight task regarding
what contents in a highlight segment will be attractive to people. We design an
encoder-decoder network to estimate the pixel-level distinction, in which we
leverage the 3D convolutional neural networks to exploit the temporal context
information, and further take advantage of the visual saliency to model the
spatial distinction. State-of-the-art performance on three public benchmarks
clearly validates the effectiveness of our framework for video highlight
detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Principal Curve-Based Classifiers and Similarity-Based Selective Sampling in Time-Series. (arXiv:2204.04620v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04620">
<div class="article-summary-box-inner">
<span><p>Considering the concept of time-dilation, there exist some major issues with
recurrent neural Architectures. Any variation in time spans between input data
points causes performance attenuation in recurrent neural network
architectures. Principal curve-based classifiers have the ability of handling
any kind of variation in time spans. In other words, principal curve-based
classifiers preserve the relativity of time while neural network architecture
violates this property of time. On the other hand, considering the labeling
costs and problems in online monitoring devices, there should be an algorithm
that finds the data points which knowing their labels will cause in better
performance of the classifier. Current selective sampling algorithms have lack
of reliability due to the randomness of the proposed algorithms. This paper
proposes a classifier and also a deterministic selective sampling algorithm
with the same computational steps, both by use of principal curve as their
building block in model definition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Manga Character Re-identification via Face-body and Spatial-temporal Associated Clustering. (arXiv:2204.04621v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04621">
<div class="article-summary-box-inner">
<span><p>In the past few years, there has been a dramatic growth in e-manga
(electronic Japanese-style comics). Faced with the booming demand for manga
research and the large amount of unlabeled manga data, we raised a new task,
called unsupervised manga character re-identification. However, the artistic
expression and stylistic limitations of manga pose many challenges to the
re-identification problem. Inspired by the idea that some content-related
features may help clustering, we propose a Face-body and Spatial-temporal
Associated Clustering method (FSAC). In the face-body combination module, a
face-body graph is constructed to solve problems such as exaggeration and
deformation in artistic creation by using the integrity of the image. In the
spatial-temporal relationship correction module, we analyze the appearance
features of characters and design a temporal-spatial-related triplet loss to
fine-tune the clustering. Extensive experiments on a manga book dataset with
109 volumes validate the superiority of our method in unsupervised manga
character re-identification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stripformer: Strip Transformer for Fast Image Deblurring. (arXiv:2204.04627v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04627">
<div class="article-summary-box-inner">
<span><p>Images taken in dynamic scenes may contain unwanted motion blur, which
significantly degrades visual quality. Such blur causes short- and long-range
region-specific smoothing artifacts that are often directional and non-uniform,
which is difficult to be removed. Inspired by the current success of
transformers on computer vision and image processing tasks, we develop,
Stripformer, a transformer-based architecture that constructs intra- and
inter-strip tokens to reweight image features in the horizontal and vertical
directions to catch blurred patterns with different orientations. It stacks
interlaced intra-strip and inter-strip attention layers to reveal blur
magnitudes. In addition to detecting region-specific blurred patterns of
various orientations and magnitudes, Stripformer is also a token-efficient and
parameter-efficient transformer model, demanding much less memory usage and
computation cost than the vanilla transformer but works better without relying
on tremendous training data. Experimental results show that Stripformer
performs favorably against state-of-the-art models in dynamic scene deblurring.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intersection Prediction from Single 360{\deg} Image via Deep Detection of Possible Direction of Travel. (arXiv:2204.04634v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04634">
<div class="article-summary-box-inner">
<span><p>Movie-Map, an interactive first-person-view map that engages the user in a
simulated walking experience, comprises short 360{\deg} video segments
separated by traffic intersections that are seamlessly connected according to
the viewer's direction of travel. However, in wide urban-scale areas with
numerous intersecting roads, manual intersection segmentation requires
significant human effort. Therefore, automatic identification of intersections
from 360{\deg} videos is an important problem for scaling up Movie-Map. In this
paper, we propose a novel method that identifies an intersection from
individual frames in 360{\deg} videos. Instead of formulating the intersection
identification as a standard binary classification task with a 360{\deg} image
as input, we identify an intersection based on the number of the possible
directions of travel (PDoT) in perspective images projected in eight directions
from a single 360{\deg} image detected by the neural network for handling
various types of intersections. We constructed a large-scale 360{\deg} Image
Intersection Identification (iii360) dataset for training and evaluation where
360{\deg} videos were collected from various areas such as school campus,
downtown, suburb, and china town and demonstrate that our PDoT-based method
achieves 88\% accuracy, which is significantly better than that achieved by the
direct naive binary classification based method. The source codes and a partial
dataset will be shared in the community after the paper is published.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConsInstancy: Learning Instance Representations for Semi-Supervised Panoptic Segmentation of Concrete Aggregate Particles. (arXiv:2204.04635v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04635">
<div class="article-summary-box-inner">
<span><p>We present a semi-supervised method for panoptic segmentation based on
ConsInstancy regularisation, a novel strategy for semi-supervised learning. It
leverages completely unlabelled data by enforcing consistency between predicted
instance representations and semantic segmentations during training in order to
improve the segmentation performance. To this end, we also propose new types of
instance representations that can be predicted by one simple forward path
through a fully convolutional network (FCN), delivering a convenient and
simple-to-train framework for panoptic segmentation. More specifically, we
propose the prediction of a three-dimensional instance orientation map as
intermediate representation and two complementary distance transform maps as
final representation, providing unique instance representations for a panoptic
segmentation. We test our method on two challenging data sets of both, hardened
and fresh concrete, the latter being proposed by the authors in this paper
demonstrating the effectiveness of our approach, outperforming the results
achieved by state-of-the-art methods for semi-supervised segmentation. In
particular, we are able to show that by leveraging completely unlabeled data in
our semi-supervised approach the achieved overall accuracy (OA) is increased by
up to 5% compared to an entirely supervised training using only labeled data.
Furthermore, we exceed the OA achieved by state-of-the-art semi-supervised
methods by up to 1.5%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spectral Unmixing of Hyperspectral Images Based on Block Sparse Structure. (arXiv:2204.04638v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04638">
<div class="article-summary-box-inner">
<span><p>Spectral unmixing (SU) of hyperspectral images (HSIs) is one of the important
areas in remote sensing (RS) that needs to be carefully addressed in different
RS applications. Despite the high spectral resolution of the hyperspectral
data, the relatively low spatial resolution of the sensors may lead to mixture
of different pure materials within the image pixels. In this case, the spectrum
of a given pixel recorded by the sensor can be a combination of multiple
spectra each belonging to a unique material in that pixel. Spectral unmixing is
then used as a technique to extract the spectral characteristics of the
different materials within the mixed pixels and to recover the spectrum of each
pure spectral signature, called endmember. Block-sparsity exists in
hyperspectral images as a result of spectral similarity between neighboring
pixels. In block-sparse signals, the nonzero samples occur in clusters and the
pattern of the clusters is often supposed to be unavailable as prior
information. This paper presents an innovative spectral unmixing approach for
HSIs based on block-sparse structure and sparse Bayesian learning (SBL)
strategy. To evaluate the performance of the proposed SU algorithm, it is
tested on both synthetic and real hyperspectral data and the quantitative
results are compared to those of other state-of-the-art methods in terms of
abundance angel distance (AAD) and mean square error (MSE). The achieved
results show the superiority of the proposed algorithm over the other competing
methods by a significant margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counting in the 2020s: Binned Representations and Inclusive Performance Measures for Deep Crowd Counting Approaches. (arXiv:2204.04653v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04653">
<div class="article-summary-box-inner">
<span><p>The data distribution in popular crowd counting datasets is typically heavy
tailed and discontinuous. This skew affects all stages within the pipelines of
deep crowd counting approaches. Specifically, the approaches exhibit
unacceptably large standard deviation wrt statistical measures (MSE, MAE). To
address such concerns in a holistic manner, we make two fundamental
contributions. Firstly, we modify the training pipeline to accommodate the
knowledge of dataset skew. To enable principled and balanced minibatch
sampling, we propose a novel smoothed Bayesian binning approach. More
specifically, we propose a novel cost function which can be readily
incorporated into existing crowd counting deep networks to encourage bin-aware
optimization. As the second contribution, we introduce additional performance
measures which are more inclusive and throw light on various comparative
performance aspects of the deep networks. We also show that our binning-based
modifications retain their superiority wrt the newly proposed performance
measures. Overall, our contributions enable a practically useful and
detail-oriented characterization of performance for crowd counting approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fashionformer: A simple, Effective and Unified Baseline for Human Fashion Segmentation and Recognition. (arXiv:2204.04654v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04654">
<div class="article-summary-box-inner">
<span><p>Human fashion understanding is one important computer vision task since it
has the comprehensive information that can be used for real-world applications.
In this work, we focus on joint human fashion segmentation and attribute
recognition. Contrary to the previous works that separately model each task as
a multi-head prediction problem, our insight is to bridge these two tasks with
one unified model via vision transformer modeling to benefit each task. In
particular, we introduce the object query for segmentation and the attribute
query for attribute prediction. Both queries and their corresponding features
can be linked via mask prediction. Then we adopt a two-stream query learning
framework to learn the decoupled query representations. For attribute stream,
we design a novel Multi-Layer Rendering module to explore more fine-grained
features. The decoder design shares the same spirits with DETR, thus we name
the proposed method Fahsionformer. Extensive experiments on three human fashion
datasets including Fashionpedia, ModaNet and Deepfashion illustrate the
effectiveness of our approach. In particular, our method with the same backbone
achieve relative 10% improvements than previous works in case of \textit{a
joint metric ( AP$^{\text{mask}}_{\text{IoU+F}_1}$) for both segmentation and
attribute recognition}. To the best of our knowledge, we are the first unified
end-to-end vision transformer framework for human fashion analysis. We hope
this simple yet effective method can serve as a new flexible baseline for
fashion analysis. Code will be available at
https://github.com/xushilin1/FashionFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Panoptic-PartFormer: Learning a Unified Model for Panoptic Part Segmentation. (arXiv:2204.04655v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04655">
<div class="article-summary-box-inner">
<span><p>Panoptic Part Segmentation (PPS) aims to unify panoptic segmentation and part
segmentation into one task. Previous work mainly utilizes separated approaches
to handle thing, stuff, and part predictions individually without performing
any shared computation and task association. In this work, we aim to unify
these tasks at the architectural level, designing the first end-to-end unified
method named Panoptic-PartFormer. In particular, motivated by the recent
progress in Vision Transformer, we model things, stuff, and part as object
queries and directly learn to optimize the all three predictions as unified
mask prediction and classification problem. We design a decoupled decoder to
generate part feature and thing/stuff feature respectively. Then we propose to
utilize all the queries and corresponding features to perform reasoning jointly
and iteratively. The final mask can be obtained via inner product between
queries and the corresponding features. The extensive ablation studies and
analysis prove the effectiveness of our framework. Our Panoptic-PartFormer
achieves the new state-of-the-art results on both Cityscapes PPS and Pascal
Context PPS datasets with at least 70% GFlops and 50% parameters decrease. In
particular, we get 3.4% relative improvements with ResNet50 backbone and 10%
improvements after adopting Swin Transformer on Pascal Context PPS dataset. To
the best of our knowledge, we are the first to solve the PPS problem via
\textit{a unified and end-to-end transformer model. Given its effectiveness and
conceptual simplicity, we hope our Panoptic-PartFormer can serve as a good
baseline and aid future unified research for PPS. Our code and models will be
available at https://github.com/lxtGH/Panoptic-PartFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation. (arXiv:2204.04656v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04656">
<div class="article-summary-box-inner">
<span><p>This paper presents Video K-Net, a simple, strong, and unified framework for
fully end-to-end video panoptic segmentation. The method is built upon K-Net, a
method that unifies image segmentation via a group of learnable kernels. We
observe that these learnable kernels from K-Net, which encode object
appearances and contexts, can naturally associate identical instances across
video frames. Motivated by this observation, Video K-Net learns to
simultaneously segment and track "things" and "stuff" in a video with simple
kernel-based appearance modeling and cross-temporal kernel interaction. Despite
the simplicity, it achieves state-of-the-art video panoptic segmentation
results on Citscapes-VPS and KITTI-STEP without bells and whistles. In
particular on KITTI-STEP, the simple method can boost almost 12\% relative
improvements over previous methods. We also validate its generalization on
video semantic segmentation, where we boost various baselines by 2\% on the
VSPW dataset. Moreover, we extend K-Net into clip-level video framework for
video instance segmentation where we obtain 40.5\% for ResNet50 backbone and
51.5\% mAP for Swin-base on YouTube-2019 validation set. We hope this simple
yet effective method can serve as a new flexible baseline in video
segmentation. Both code and models are released at
https://github.com/lxtGH/Video-K-Net
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FOSTER: Feature Boosting and Compression for Class-Incremental Learning. (arXiv:2204.04662v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04662">
<div class="article-summary-box-inner">
<span><p>The ability to learn new concepts continually is necessary in this
ever-changing world. However, deep neural networks suffer from catastrophic
forgetting when learning new categories. Many works have been proposed to
alleviate this phenomenon, whereas most of them either fall into the
stability-plasticity dilemma or take too much computation or storage overhead.
Inspired by the gradient boosting algorithm to gradually fit the residuals
between the target and the current approximation function, we propose a novel
two-stage learning paradigm FOSTER, empowering the model to learn new
categories adaptively. Specifically, we first dynamically expand new modules to
fit the residuals of the target and the original model. Next, we remove
redundant parameters and feature dimensions through an effective distillation
strategy to maintain the single backbone model. We validate our method FOSTER
on CIFAR-100, ImageNet-100/1000 under different settings. Experimental results
show that our method achieves state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effective Out-of-Distribution Detection in Classifier Based on PEDCC-Loss. (arXiv:2204.04665v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04665">
<div class="article-summary-box-inner">
<span><p>Deep neural networks suffer from the overconfidence issue in the open world,
meaning that classifiers could yield confident, incorrect predictions for
out-of-distribution (OOD) samples. Thus, it is an urgent and challenging task
to detect these samples drawn far away from training distribution based on the
security considerations of artificial intelligence. Many current methods based
on neural networks mainly rely on complex processing strategies, such as
temperature scaling and input preprocessing, to obtain satisfactory results. In
this paper, we propose an effective algorithm for detecting out-of-distribution
examples utilizing PEDCC-Loss. We mathematically analyze the nature of the
confidence score output by the PEDCC (Predefined Evenly-Distribution Class
Centroids) classifier, and then construct a more effective scoring function to
distinguish in-distribution (ID) and out-of-distribution. In this method, there
is no need to preprocess the input samples and the computational burden of the
algorithm is reduced. Experiments demonstrate that our method can achieve
better OOD detection performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linear Complexity Randomized Self-attention Mechanism. (arXiv:2204.04667v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04667">
<div class="article-summary-box-inner">
<span><p>Recently, random feature attentions (RFAs) are proposed to approximate the
softmax attention in linear time and space complexity by linearizing the
exponential kernel. In this paper, we first propose a novel perspective to
understand the bias in such approximation by recasting RFAs as self-normalized
importance samplers. This perspective further sheds light on an \emph{unbiased}
estimator for the whole softmax attention, called randomized attention (RA). RA
constructs positive random features via query-specific distributions and enjoys
greatly improved approximation fidelity, albeit exhibiting quadratic
complexity. By combining the expressiveness in RA and the efficiency in RFA, we
develop a novel linear complexity self-attention mechanism called linear
randomized attention (LARA). Extensive experiments across various domains
demonstrate that RA and LARA significantly improve the performance of RFAs by a
substantial margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NAN: Noise-Aware NeRFs for Burst-Denoising. (arXiv:2204.04668v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04668">
<div class="article-summary-box-inner">
<span><p>Burst denoising is now more relevant than ever, as computational photography
helps overcome sensitivity issues inherent in mobile phones and small cameras.
A major challenge in burst-denoising is in coping with pixel misalignment,
which was so far handled with rather simplistic assumptions of simple motion,
or the ability to align in pre-processing. Such assumptions are not realistic
in the presence of large motion and high levels of noise. We show that Neural
Radiance Fields (NeRFs), originally suggested for physics-based novel-view
rendering, can serve as a powerful framework for burst denoising. NeRFs have an
inherent capability of handling noise as they integrate information from
multiple images, but they are limited in doing so, mainly since they build on
pixel-wise operations which are suitable to ideal imaging conditions. Our
approach, termed NAN, leverages inter-view and spatial information in NeRFs to
better deal with noise. It achieves state-of-the-art results in burst denoising
and is especially successful in coping with large movement and occlusions,
under very high levels of noise. With the rapid advances in accelerating NeRFs,
it could provide a powerful platform for denoising in challenging environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is my Driver Observation Model Overconfident? Input-guided Calibration Networks for Reliable and Interpretable Confidence Estimates. (arXiv:2204.04674v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04674">
<div class="article-summary-box-inner">
<span><p>Driver observation models are rarely deployed under perfect conditions. In
practice, illumination, camera placement and type differ from the ones present
during training and unforeseen behaviours may occur at any time. While
observing the human behind the steering wheel leads to more intuitive
human-vehicle-interaction and safer driving, it requires recognition algorithms
which do not only predict the correct driver state, but also determine their
prediction quality through realistic and interpretable confidence measures.
Reliable uncertainty estimates are crucial for building trust and are a serious
obstacle for deploying activity recognition networks in real driving systems.
In this work, we for the first time examine how well the confidence values of
modern driver observation models indeed match the probability of the correct
outcome and show that raw neural network-based approaches tend to significantly
overestimate their prediction quality. To correct this misalignment between the
confidence values and the actual uncertainty, we consider two strategies.
First, we enhance two activity recognition models often used for driver
observation with temperature scaling-an off-the-shelf method for confidence
calibration in image classification. Then, we introduce Calibrated Action
Recognition with Input Guidance (CARING)-a novel approach leveraging an
additional neural network to learn scaling the confidences depending on the
video representation. Extensive experiments on the Drive&amp;Act dataset
demonstrate that both strategies drastically improve the quality of model
confidences, while our CARING model out-performs both, the original
architectures and their temperature scaling enhancement, leading to best
uncertainty estimates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple Baselines for Image Restoration. (arXiv:2204.04676v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04676">
<div class="article-summary-box-inner">
<span><p>Although there have been significant advances in the field of image
restoration recently, the system complexity of the state-of-the-art (SOTA)
methods is increasing as well, which may hinder the convenient analysis and
comparison of methods. In this paper, we propose a simple baseline that exceeds
the SOTA methods and is computationally efficient. To further simplify the
baseline, we reveal that the nonlinear activation functions, e.g. Sigmoid,
ReLU, GELU, Softmax, etc. are not necessary: they could be replaced by
multiplication or removed. Thus, we derive a Nonlinear Activation Free Network,
namely NAFNet, from the baseline. SOTA results are achieved on various
challenging benchmarks, e.g. 33.69 dB PSNR on GoPro (for image deblurring),
exceeding the previous SOTA 0.38 dB with only 8.4% of its computational costs;
40.30 dB PSNR on SIDD (for image denoising), exceeding the previous SOTA 0.28
dB with less than half of its computational costs. The code and the pretrained
models will be released at https://github.com/megvii-research/NAFNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FedCorr: Multi-Stage Federated Learning for Label Noise Correction. (arXiv:2204.04677v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04677">
<div class="article-summary-box-inner">
<span><p>Federated learning (FL) is a privacy-preserving distributed learning paradigm
that enables clients to jointly train a global model. In real-world FL
implementations, client data could have label noise, and different clients
could have vastly different label noise levels. Although there exist methods in
centralized learning for tackling label noise, such methods do not perform well
on heterogeneous label noise in FL settings, due to the typically smaller sizes
of client datasets and data privacy requirements in FL. In this paper, we
propose $\texttt{FedCorr}$, a general multi-stage framework to tackle
heterogeneous label noise in FL, without making any assumptions on the noise
models of local clients, while still maintaining client data privacy. In
particular, (1) $\texttt{FedCorr}$ dynamically identifies noisy clients by
exploiting the dimensionalities of the model prediction subspaces independently
measured on all clients, and then identifies incorrect labels on noisy clients
based on per-sample losses. To deal with data heterogeneity and to increase
training stability, we propose an adaptive local proximal regularization term
that is based on estimated local noise levels. (2) We further finetune the
global model on identified clean clients and correct the noisy labels for the
remaining noisy clients after finetuning. (3) Finally, we apply the usual
training on all clients to make full use of all local data. Experiments
conducted on CIFAR-10/100 with federated synthetic label noise, and on a
real-world noisy dataset, Clothing1M, demonstrate that $\texttt{FedCorr}$ is
robust to label noise and substantially outperforms the state-of-the-art
methods at multiple noise levels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scale Invariant Semantic Segmentation with RGB-D Fusion. (arXiv:2204.04679v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04679">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a neural network architecture for scale-invariant
semantic segmentation using RGB-D images. We utilize depth information as an
additional modality apart from color images only. Especially in an outdoor
scene which consists of different scale objects due to the distance of the
objects from the camera. The near distance objects consist of significantly
more pixels than the far ones. We propose to incorporate depth information to
the RGB data for pixel-wise semantic segmentation to address the different
scale objects in an outdoor scene. We adapt to a well-known
DeepLab-v2(ResNet-101) model as our RGB baseline. Depth images are passed
separately as an additional input with a distinct branch. The intermediate
feature maps of both color and depth image branch are fused using a novel
fusion block. Our model is compact and can be easily applied to the other RGB
model. We perform extensive qualitative and quantitative evaluation on a
challenging dataset Cityscapes. The results obtained are comparable to the
state-of-the-art. Additionally, we evaluated our model on a self-recorded real
dataset. For the shake of extended evaluation of a driving scene with ground
truth we generated a synthetic dataset using popular vehicle simulation project
CARLA. The results obtained from the real and synthetic dataset shows the
effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning with Multi-Structure Commonsense Knowledge in Visual Dialog. (arXiv:2204.04680v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04680">
<div class="article-summary-box-inner">
<span><p>Visual Dialog requires an agent to engage in a conversation with humans
grounded in an image. Many studies on Visual Dialog focus on the understanding
of the dialog history or the content of an image, while a considerable amount
of commonsense-required questions are ignored. Handling these scenarios depends
on logical reasoning that requires commonsense priors. How to capture relevant
commonsense knowledge complementary to the history and the image remains a key
challenge. In this paper, we propose a novel model by Reasoning with
Multi-structure Commonsense Knowledge (RMK). In our model, the external
knowledge is represented with sentence-level facts and graph-level facts, to
properly suit the scenario of the composite of dialog history and image. On top
of these multi-structure representations, our model can capture relevant
knowledge and incorporate them into the vision and semantic features, via
graph-based interaction and transformer-based fusion. Experimental results and
analysis on VisDial v1.0 and VisDialCK datasets show that our proposed model
effectively outperforms comparative methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing the Robustness, Efficiency, and Diversity of Differentiable Architecture Search. (arXiv:2204.04681v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04681">
<div class="article-summary-box-inner">
<span><p>Differentiable architecture search (DARTS) has attracted much attention due
to its simplicity and significant improvement in efficiency. However, the
excessive accumulation of the skip connection makes it suffer from long-term
weak stability and low robustness. Many works attempt to restrict the
accumulation of skip connections by indicators or manual design, however, these
methods are susceptible to thresholds and human priors. In this work, we
suggest a more subtle and direct approach that removes skip connections from
the operation space. Then, by introducing an adaptive channel allocation
strategy, we redesign the DARTS framework to automatically refill the skip
connections in the evaluation stage, resolving the performance degradation
caused by the absence of skip connections. Our method, dubbed
Adaptive-Channel-Allocation-DARTS (ACA-DRATS), could eliminate the
inconsistency in operation strength and significantly expand the architecture
diversity. We continue to explore smaller search space under our framework, and
offer a direct search on the entire ImageNet dataset. Experiments show that
ACA-DRATS improves the search stability and significantly speeds up DARTS by
more than ten times while yielding higher accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coreset of Hyperspectral Images on Small Quantum Computer. (arXiv:2204.04691v1 [quant-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04691">
<div class="article-summary-box-inner">
<span><p>Machine Learning (ML) techniques are employed to analyze and process big
Remote Sensing (RS) data, and one well-known ML technique is a Support Vector
Machine (SVM). An SVM is a quadratic programming (QP) problem, and a D-Wave
quantum annealer (D-Wave QA) promises to solve this QP problem more efficiently
than a conventional computer. However, the D-Wave QA cannot solve directly the
SVM due to its very few input qubits. Hence, we use a coreset ("core of a
dataset") of given EO data for training an SVM on this small D-Wave QA. The
coreset is a small, representative weighted subset of an original dataset, and
any training models generate competitive classes by using the coreset in
contrast to by using its original dataset. We measured the closeness between an
original dataset and its coreset by employing a Kullback-Leibler (KL)
divergence measure. Moreover, we trained the SVM on the coreset data by using
both a D-Wave QA and a conventional method. We conclude that the coreset
characterizes the original dataset with very small KL divergence measure. In
addition, we present our KL divergence results for demonstrating the closeness
between our original data and its coreset. As practical RS data, we use
Hyperspectral Image (HSI) of Indian Pine, USA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Efficient Pattern Mining Convolution Neural Network (CNN) algorithm with Grey Wolf Optimization (GWO). (arXiv:2204.04704v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04704">
<div class="article-summary-box-inner">
<span><p>Automation of feature analysis in the dynamic image frame dataset deals with
complexity of intensity mapping with normal and abnormal class. The
threshold-based data clustering and feature analysis requires iterative model
to learn the component of image frame in multi-pattern for different image
frame data type. This paper proposed a novel model of feature analysis method
with the CNN based on Convoluted Pattern of Wavelet Transform (CPWT) feature
vectors that are optimized by Grey Wolf Optimization (GWO) algorithm.
Initially, the image frame gets normalized by applying median filter to the
image frame that reduce the noise and apply smoothening on it. From that, the
edge information represents the boundary region of bright spot in the image
frame. Neural network-based image frame classification performs repeated
learning of the feature with minimum training of dataset to cluster the image
frame pixels. Features of the filtered image frame was analyzed in different
pattern of feature extraction model based on the convoluted model of wavelet
transformation method. These features represent the different class of image
frame in spatial and textural pattern of it. Convolutional Neural Network (CNN)
classifier supports to analyze the features and classify the action label for
the image frame dataset. This process enhances the classification with minimum
number of training dataset. The performance of this proposed method can be
validated by comparing with traditional state-of-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Adversarial Networks for Image Augmentation in Agriculture: A Systematic Review. (arXiv:2204.04707v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04707">
<div class="article-summary-box-inner">
<span><p>In agricultural image analysis, optimal model performance is keenly pursued
for better fulfilling visual recognition tasks (e.g., image classification,
segmentation, object detection and localization), in the presence of challenges
with biological variability and unstructured environments. Large-scale,
balanced and ground-truthed image datasets, however, are often difficult to
obtain to fuel the development of advanced, high-performance models. As
artificial intelligence through deep learning is impacting analysis and
modeling of agricultural images, data augmentation plays a crucial role in
boosting model performance while reducing manual efforts for data preparation,
by algorithmically expanding training datasets. Beyond traditional data
augmentation techniques, generative adversarial network (GAN) invented in 2014
in the computer vision community, provides a suite of novel approaches that can
learn good data representations and generate highly realistic samples. Since
2017, there has been a growth of research into GANs for image augmentation or
synthesis in agriculture for improved model performance. This paper presents an
overview of the evolution of GAN architectures followed by a systematic review
of their application to agriculture
(https://github.com/Derekabc/GANs-Agriculture), involving various vision tasks
for plant health, weeds, fruits, aquaculture, animal farming, plant phenotyping
as well as postharvest detection of fruit defects. Challenges and opportunities
of GANs are discussed for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Harmonization by Matching Regional References. (arXiv:2204.04715v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04715">
<div class="article-summary-box-inner">
<span><p>To achieve visual consistency in composite images, recent image harmonization
methods typically summarize the appearance pattern of global background and
apply it to the global foreground without location discrepancy. However, for a
real image, the appearances (illumination, color temperature, saturation, hue,
texture, etc) of different regions can vary significantly. So previous methods,
which transfer the appearance globally, are not optimal. Trying to solve this
issue, we firstly match the contents between the foreground and background and
then adaptively adjust every foreground location according to the appearance of
its content-related background regions. Further, we design a residual
reconstruction strategy, that uses the predicted residual to adjust the
appearance, and the composite foreground to reserve the image details.
Extensive experiments demonstrate the effectiveness of our method. The source
code will be available publicly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TOV: The Original Vision Model for Optical Remote Sensing Image Understanding via Self-supervised Learning. (arXiv:2204.04716v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04716">
<div class="article-summary-box-inner">
<span><p>Do we on the right way for remote sensing image understanding (RSIU) by
training models via supervised data-dependent and task-dependent way, instead
of human vision in a label-free and task-independent way? We argue that a more
desirable RSIU model should be trained with intrinsic structure from data
rather that extrinsic human labels to realize generalizability across a wide
range of RSIU tasks. According to this hypothesis, we proposed \textbf{T}he
\textbf{O}riginal \textbf{V}ision model (TOV) in remote sensing filed. Trained
by massive unlabeled optical data along a human-like self-supervised learning
(SSL) path that is from general knowledge to specialized knowledge, TOV model
can be easily adapted to various RSIU tasks, including scene classification,
object detection, and semantic segmentation, and outperforms dominant ImageNet
supervised pretrained method as well as two recently proposed SSL pretrained
methods on majority of 12 publicly available benchmarks. Moreover, we analyze
the influences of two key factors on the performance of building TOV model for
RSIU, including the influence of using different data sampling methods and the
selection of learning paths during self-supervised optimization. We believe
that a general model which is trained by a label-free and task-independent way
may be the next paradigm for RSIU and hope the insights distilled from this
study can help to foster the development of an original vision model for RSIU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Non-rigid Structure-from-Motion: A Sequence-to-Sequence Translation Perspective. (arXiv:2204.04730v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04730">
<div class="article-summary-box-inner">
<span><p>Directly regressing the non-rigid shape and camera pose from the individual
2D frame is ill-suited to the Non-Rigid Structure-from-Motion (NRSfM) problem.
This frame-by-frame 3D reconstruction pipeline overlooks the inherent
spatial-temporal nature of NRSfM, i.e., reconstructing the whole 3D sequence
from the input 2D sequence. In this paper, we propose to model deep NRSfM from
a sequence-to-sequence translation perspective, where the input 2D frame
sequence is taken as a whole to reconstruct the deforming 3D non-rigid shape
sequence. First, we apply a shape-motion predictor to estimate the initial
non-rigid shape and camera motion from a single frame. Then we propose a
context modeling module to model camera motions and complex non-rigid shapes.
To tackle the difficulty in enforcing the global structure constraint within
the deep framework, we propose to impose the union-of-subspace structure by
replacing the self-expressiveness layer with multi-head attention and delayed
regularizers, which enables end-to-end batch-wise training. Experimental
results across different datasets such as Human3.6M, CMU Mocap and InterHand
prove the superiority of our framework. The code will be made publicly
available
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Analysis of Decision-Level Fusion for Multimodal Driver Behaviour Understanding. (arXiv:2204.04734v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04734">
<div class="article-summary-box-inner">
<span><p>Visual recognition inside the vehicle cabin leads to safer driving and more
intuitive human-vehicle interaction but such systems face substantial obstacles
as they need to capture different granularities of driver behaviour while
dealing with highly limited body visibility and changing illumination.
Multimodal recognition mitigates a number of such issues: prediction outcomes
of different sensors complement each other due to different modality-specific
strengths and weaknesses. While several late fusion methods have been
considered in previously published frameworks, they constantly feature
different architecture backbones and building blocks making it very hard to
isolate the role of the chosen late fusion strategy itself. This paper presents
an empirical evaluation of different paradigms for decision-level late fusion
in video-based driver observation. We compare seven different mechanisms for
joining the results of single-modal classifiers which have been both popular,
(e.g. score averaging) and not yet considered (e.g. rank-level fusion) in the
context of driver observation evaluating them based on different criteria and
benchmark settings. This is the first systematic study of strategies for fusing
outcomes of multimodal predictors inside the vehicles, conducted with the goal
to provide guidance for fusion scheme selection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CholecTriplet2021: A benchmark challenge for surgical action triplet recognition. (arXiv:2204.04746v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04746">
<div class="article-summary-box-inner">
<span><p>Context-aware decision support in the operating room can foster surgical
safety and efficiency by leveraging real-time feedback from surgical workflow
analysis. Most existing works recognize surgical activities at a coarse-grained
level, such as phases, steps or events, leaving out fine-grained interaction
details about the surgical activity; yet those are needed for more helpful AI
assistance in the operating room. Recognizing surgical actions as triplets of
&lt;instrument, verb, target&gt; combination delivers comprehensive details about the
activities taking place in surgical videos. This paper presents
CholecTriplet2021: an endoscopic vision challenge organized at MICCAI 2021 for
the recognition of surgical action triplets in laparoscopic videos. The
challenge granted private access to the large-scale CholecT50 dataset, which is
annotated with action triplet information. In this paper, we present the
challenge setup and assessment of the state-of-the-art deep learning methods
proposed by the participants during the challenge. A total of 4 baseline
methods from the challenge organizers and 19 new deep learning algorithms by
competing teams are presented to recognize surgical action triplets directly
from surgical videos, achieving mean average precision (mAP) ranging from 4.2%
to 38.1%. This study also analyzes the significance of the results obtained by
the presented approaches, performs a thorough methodological comparison between
them, in-depth result analysis, and proposes a novel ensemble method for
enhanced recognition. Our analysis shows that surgical workflow analysis is not
yet solved, and also highlights interesting directions for future research on
fine-grained surgical activity recognition which is of utmost importance for
the development of AI in surgery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Cross-view Image Retrieval: Highly Accurate Vehicle Localization Using Satellite Image. (arXiv:2204.04752v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04752">
<div class="article-summary-box-inner">
<span><p>This paper addresses the problem of vehicle-mounted camera localization by
matching a ground-level image with an overhead-view satellite map. Existing
methods often treat this problem as cross-view image retrieval, and use learned
deep features to match the ground-level query image to a partition (eg, a small
patch) of the satellite map. By these methods, the localization accuracy is
limited by the partitioning density of the satellite map (often in the order of
tens meters). Departing from the conventional wisdom of image retrieval, this
paper presents a novel solution that can achieve highly-accurate localization.
The key idea is to formulate the task as pose estimation and solve it by
neural-net based optimization. Specifically, we design a two-branch {CNN} to
extract robust features from the ground and satellite images, respectively. To
bridge the vast cross-view domain gap, we resort to a Geometry Projection
module that projects features from the satellite map to the ground-view, based
on a relative camera pose. Aiming to minimize the differences between the
projected features and the observed features, we employ a differentiable
Levenberg-Marquardt ({LM}) module to search for the optimal camera pose
iteratively. The entire pipeline is differentiable and runs end-to-end.
Extensive experiments on standard autonomous vehicle localization datasets have
confirmed the superiority of the proposed method. Notably, e.g., starting from
a coarse estimate of camera location within a wide region of 40m x 40m, with an
80% likelihood our method quickly reduces the lateral location error to be
within 5m on a new KITTI cross-view dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DILEMMA: Self-Supervised Shape and Texture Learning with Transformers. (arXiv:2204.04788v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04788">
<div class="article-summary-box-inner">
<span><p>There is a growing belief that deep neural networks with a shape bias may
exhibit better generalization capabilities than models with a texture bias,
because shape is a more reliable indicator of the object category. However, we
show experimentally that existing measures of shape bias are not stable
predictors of generalization and argue that shape discrimination should not
come at the expense of texture discrimination. Thus, we propose a pseudo-task
to explicitly boost both shape and texture discriminability in models trained
via self-supervised learning. For this purpose, we train a ViT to detect which
input token has been combined with an incorrect positional embedding. To retain
texture discrimination, the ViT is also trained as in MoCo with a
student-teacher architecture and a contrastive loss over an extra learnable
class token. We call our method DILEMMA, which stands for Detection of
Incorrect Location EMbeddings with MAsked inputs. We evaluate our method
through fine-tuning on several datasets and show that it outperforms MoCoV3 and
DINO. Moreover, we show that when downstream tasks are strongly reliant on
shape (such as in the YOGA-82 pose dataset), our pre-trained features yield a
significant gain over prior work. Code will be released upon publication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric Action Recognition. (arXiv:2204.04796v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04796">
<div class="article-summary-box-inner">
<span><p>Learning an egocentric action recognition model from video data is
challenging due to distractors (e.g., irrelevant objects) in the background.
Further integrating object information into an action model is hence
beneficial. Existing methods often leverage a generic object detector to
identify and represent the objects in the scene. However, several important
issues remain. Object class annotations of good quality for the target domain
(dataset) are still required for learning good object representation. Besides,
previous methods deeply couple the existing action models and need to retrain
them jointly with object representation, leading to costly and inflexible
integration. To overcome both limitations, we introduce Self-Supervised
Learning Over Sets (SOS), an approach to pre-train a generic Objects In Contact
(OIC) representation model from video object regions detected by an
off-the-shelf hand-object contact detector. Instead of augmenting object
regions individually as in conventional self-supervised learning, we view the
action process as a means of natural data transformations with unique
spatio-temporal continuity and exploit the inherent relationships among
per-video object sets. Extensive experiments on two datasets, EPIC-KITCHENS-100
and EGTEA, show that our OIC significantly boosts the performance of multiple
state-of-the-art video classification models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning. (arXiv:2204.04799v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04799">
<div class="article-summary-box-inner">
<span><p>Continual learning aims to enable a single model to learn a sequence of tasks
without catastrophic forgetting. Top-performing methods usually require a
rehearsal buffer to store past pristine examples for experience replay, which,
however, limits their practical value due to privacy and memory constraints. In
this work, we present a simple yet effective framework, DualPrompt, which
learns a tiny set of parameters, called prompts, to properly instruct a
pre-trained model to learn tasks arriving sequentially without buffering past
examples. DualPrompt presents a novel approach to attach complementary prompts
to the pre-trained backbone, and then formulates the objective as learning
task-invariant and task-specific "instructions". With extensive experimental
validation, DualPrompt consistently sets state-of-the-art performance under the
challenging class-incremental setting. In particular, DualPrompt outperforms
recent advanced continual learning methods with relatively large buffer sizes.
We also introduce a more challenging benchmark, Split ImageNet-R, to help
generalize rehearsal-free continual learning research. Source code is available
at https://github.com/google-research/l2p.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OutfitTransformer: Learning Outfit Representations for Fashion Recommendation. (arXiv:2204.04812v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04812">
<div class="article-summary-box-inner">
<span><p>Learning an effective outfit-level representation is critical for predicting
the compatibility of items in an outfit, and retrieving complementary items for
a partial outfit. We present a framework, OutfitTransformer, that uses the
proposed task-specific tokens and leverages the self-attention mechanism to
learn effective outfit-level representations encoding the compatibility
relationships between all items in the entire outfit for addressing both
compatibility prediction and complementary item retrieval tasks. For
compatibility prediction, we design an outfit token to capture a global outfit
representation and train the framework using a classification loss. For
complementary item retrieval, we design a target item token that additionally
takes the target item specification (in the form of a category or text
description) into consideration. We train our framework using a proposed
set-wise outfit ranking loss to generate a target item embedding given an
outfit, and a target item specification as inputs. The generated target item
embedding is then used to retrieve compatible items that match the rest of the
outfit. Additionally, we adopt a pre-training approach and a curriculum
learning strategy to improve retrieval performance. Since our framework learns
at an outfit-level, it allows us to learn a single embedding capturing
higher-order relations among multiple items in the outfit more effectively than
pairwise methods. Experiments demonstrate that our approach outperforms
state-of-the-art methods on compatibility prediction, fill-in-the-blank, and
complementary item retrieval tasks. We further validate the quality of our
retrieval results with a user study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial-Spectral Feature Extraction via Deep ConvLSTM Neural Networks for Hyperspectral Image Classification. (arXiv:1905.03577v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.03577">
<div class="article-summary-box-inner">
<span><p>In recent years, deep learning has presented a great advance in hyperspectral
image (HSI) classification. Particularly, long short-term memory (LSTM), as a
special deep learning structure, has shown great ability in modeling long-term
dependencies in the time dimension of video or the spectral dimension of HSIs.
However, the loss of spatial information makes it quite difficult to obtain the
better performance. In order to address this problem, two novel deep models are
proposed to extract more discriminative spatial-spectral features by exploiting
the Convolutional LSTM (ConvLSTM). By taking the data patch in a local sliding
window as the input of each memory cell band by band, the 2-D extended
architecture of LSTM is considered for building the spatial-spectral ConvLSTM
2-D Neural Network (SSCL2DNN) to model long-range dependencies in the spectral
domain. To better preserve the intrinsic structure information of the
hyperspectral data, the spatial-spectral ConvLSTM 3-D Neural Network (SSCL3DNN)
is proposed by extending LSTM to 3-D version for further improving the
classification performance. The experiments, conducted on three commonly used
HSI data sets, demonstrate that the proposed deep models have certain
competitive advantages and can provide better classification performance than
other state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Harmonic Convolutional Networks based on Discrete Cosine Transform. (arXiv:2001.06570v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.06570">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) learn filters in order to capture local
correlation patterns in feature space. We propose to learn these filters as
combinations of preset spectral filters defined by the Discrete Cosine
Transform (DCT). Our proposed DCT-based harmonic blocks replace conventional
convolutional layers to produce partially or fully harmonic versions of new or
existing CNN architectures. Using DCT energy compaction properties, we
demonstrate how the harmonic networks can be efficiently compressed by
truncating high-frequency information in harmonic blocks thanks to the
redundancies in the spectral domain. We report extensive experimental
validation demonstrating benefits of the introduction of harmonic blocks into
state-of-the-art CNN models in image classification, object detection and
semantic segmentation applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Affect Transfer Learning for Behavior Prediction in an Intelligent Tutoring System. (arXiv:2002.05242v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05242">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a video-based transfer learning approach for
predicting problem outcomes of students working with an intelligent tutoring
system (ITS). By analyzing a student's face and gestures, our method predicts
the outcome of a student answering a problem in an ITS from a video feed. Our
work is motivated by the reasoning that the ability to predict such outcomes
enables tutoring systems to adjust interventions, such as hints and
encouragement, and to ultimately yield improved student learning. We collected
a large labeled dataset of student interactions with an intelligent online math
tutor consisting of 68 sessions, where 54 individual students solved 2,749
problems. The dataset is public and available at
https://www.cs.bu.edu/faculty/betke/research/learning/ . Working with this
dataset, our transfer-learning challenge was to design a representation in the
source domain of pictures obtained "in the wild" for the task of facial
expression analysis, and transferring this learned representation to the task
of human behavior prediction in the domain of webcam videos of students in a
classroom environment. We developed a novel facial affect representation and a
user-personalized training scheme that unlocks the potential of this
representation. We designed several variants of a recurrent neural network that
models the temporal structure of video sequences of students solving math
problems. Our final model, named ATL-BP for Affect Transfer Learning for
Behavior Prediction, achieves a relative increase in mean F-score of 50% over
the state-of-the-art method on this new dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Robustness of Deep Sensor Fusion Models. (arXiv:2006.13192v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.13192">
<div class="article-summary-box-inner">
<span><p>We experimentally study the robustness of deep camera-LiDAR fusion
architectures for 2D object detection in autonomous driving. First, we find
that the fusion model is usually both more accurate, and more robust against
single-source attacks than single-sensor deep neural networks. Furthermore, we
show that without adversarial training, early fusion is more robust than late
fusion, whereas the two perform similarly after adversarial training. However,
we note that single-channel adversarial training of deep fusion is often
detrimental even to robustness. Moreover, we observe cross-channel
externalities, where single-channel adversarial training reduces robustness to
attacks on the other channel. Additionally, we observe that the choice of
adversarial model in adversarial training is critical: using attacks restricted
to cars' bounding boxes is more effective in adversarial training and exhibits
less significant cross-channel externalities. Finally, we find that
joint-channel adversarial training helps mitigate many of the issues above, but
does not significantly boost adversarial robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural networks with late-phase weights. (arXiv:2007.12927v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12927">
<div class="article-summary-box-inner">
<span><p>The largely successful method of training neural networks is to learn their
weights using some variant of stochastic gradient descent (SGD). Here, we show
that the solutions found by SGD can be further improved by ensembling a subset
of the weights in late stages of learning. At the end of learning, we obtain
back a single model by taking a spatial average in weight space. To avoid
incurring increased computational costs, we investigate a family of
low-dimensional late-phase weight models which interact multiplicatively with
the remaining parameters. Our results show that augmenting standard models with
late-phase weights improves generalization in established benchmarks such as
CIFAR-10/100, ImageNet and enwik8. These findings are complemented with a
theoretical analysis of a noisy quadratic problem which provides a simplified
picture of the late phases of neural network learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regularizing Attention Networks for Anomaly Detection in Visual Question Answering. (arXiv:2009.10054v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10054">
<div class="article-summary-box-inner">
<span><p>For stability and reliability of real-world applications, the robustness of
DNNs in unimodal tasks has been evaluated. However, few studies consider
abnormal situations that a visual question answering (VQA) model might
encounter at test time after deployment in the real-world. In this study, we
evaluate the robustness of state-of-the-art VQA models to five different
anomalies, including worst-case scenarios, the most frequent scenarios, and the
current limitation of VQA models. Different from the results in unimodal tasks,
the maximum confidence of answers in VQA models cannot detect anomalous inputs,
and post-training of the outputs, such as outlier exposure, is ineffective for
VQA models. Thus, we propose an attention-based method, which uses confidence
of reasoning between input images and questions and shows much more promising
results than the previous methods in unimodal tasks. In addition, we show that
a maximum entropy regularization of attention networks can significantly
improve the attention-based anomaly detection of the VQA models. Thanks to the
simplicity, attention-based anomaly detection and the regularization are
model-agnostic methods, which can be used for various cross-modal attentions in
the state-of-the-art VQA models. The results imply that cross-modal attention
in VQA is important to improve not only VQA accuracy, but also the robustness
to various anomalies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classification Problems. (arXiv:2011.12945v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12945">
<div class="article-summary-box-inner">
<span><p>In real-world classification tasks, each class often comprises multiple
finer-grained "subclasses." As the subclass labels are frequently unavailable,
models trained using only the coarser-grained class labels often exhibit highly
variable performance across different subclasses. This phenomenon, known as
hidden stratification, has important consequences for models deployed in
safety-critical applications such as medicine. We propose GEORGE, a method to
both measure and mitigate hidden stratification even when subclass labels are
unknown. We first observe that unlabeled subclasses are often separable in the
feature space of deep neural networks, and exploit this fact to estimate
subclass labels for the training data via clustering techniques. We then use
these approximate subclass labels as a form of noisy supervision in a
distributionally robust optimization objective. We theoretically characterize
the performance of GEORGE in terms of the worst-case generalization error
across any subclass. We empirically validate GEORGE on a mix of real-world and
benchmark image classification datasets, and show that our approach boosts
worst-case subclass accuracy by up to 22 percentage points compared to standard
training techniques, without requiring any prior information about the
subclasses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curriculum Learning: A Survey. (arXiv:2101.10382v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10382">
<div class="article-summary-box-inner">
<span><p>Training machine learning models in a meaningful order, from the easy samples
to the hard ones, using curriculum learning can provide performance
improvements over the standard training approach based on random data
shuffling, without any additional computational costs. Curriculum learning
strategies have been successfully employed in all areas of machine learning, in
a wide range of tasks. However, the necessity of finding a way to rank the
samples from easy to hard, as well as the right pacing function for introducing
more difficult data can limit the usage of the curriculum approaches. In this
survey, we show how these limits have been tackled in the literature, and we
present different curriculum learning instantiations for various tasks in
machine learning. We construct a multi-perspective taxonomy of curriculum
learning approaches by hand, considering various classification criteria. We
further build a hierarchical tree of curriculum learning methods using an
agglomerative clustering algorithm, linking the discovered clusters with our
taxonomy. At the end, we provide some interesting directions for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The MSR-Video to Text Dataset with Clean Annotations. (arXiv:2102.06448v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06448">
<div class="article-summary-box-inner">
<span><p>Video captioning automatically generates short descriptions of the video
content, usually in form of a single sentence. Many methods have been proposed
for solving this task. A large dataset called MSR Video to Text (MSR-VTT) is
often used as the benchmark dataset for testing the performance of the methods.
However, we found that the human annotations, i.e., the descriptions of video
contents in the dataset are quite noisy, e.g., there are many duplicate
captions and many captions contain grammatical problems. These problems may
pose difficulties to video captioning models for learning underlying patterns.
We cleaned the MSR-VTT annotations by removing these problems, then tested
several typical video captioning models on the cleaned dataset. Experimental
results showed that data cleaning boosted the performances of the models
measured by popular quantitative metrics. We recruited subjects to evaluate the
results of a model trained on the original and cleaned datasets. The human
behavior experiment demonstrated that trained on the cleaned dataset, the model
generated captions that were more coherent and more relevant to the contents of
the video clips.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VAE Approximation Error: ELBO and Exponential Families. (arXiv:2102.09310v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09310">
<div class="article-summary-box-inner">
<span><p>The importance of Variational Autoencoders reaches far beyond standalone
generative models -- the approach is also used for learning latent
representations and can be generalized to semi-supervised learning. This
requires a thorough analysis of their commonly known shortcomings: posterior
collapse and approximation errors. This paper analyzes VAE approximation errors
caused by the combination of the ELBO objective and encoder models from
conditional exponential families, including, but not limited to, commonly used
conditionally independent discrete and continuous models. We characterize
subclasses of generative models consistent with these encoder families. We show
that the ELBO optimizer is pulled away from the likelihood optimizer towards
the consistent subset and study this effect experimentally. Importantly, this
subset can not be enlarged, and the respective error cannot be decreased, by
considering deeper encoder/decoder networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deeply Unsupervised Patch Re-Identification for Pre-training Object Detectors. (arXiv:2103.04814v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04814">
<div class="article-summary-box-inner">
<span><p>Unsupervised pre-training aims at learning transferable features that are
beneficial for downstream tasks. However, most state-of-the-art unsupervised
methods concentrate on learning global representations for image-level
classification tasks instead of discriminative local region representations,
which limits their transferability to region-level downstream tasks, such as
object detection. To improve the transferability of pre-trained features to
object detection, we present Deeply Unsupervised Patch Re-ID (DUPR), a simple
yet effective method for unsupervised visual representation learning. The patch
Re-ID task treats individual patch as a pseudo-identity and contrastively
learns its correspondence in two views, enabling us to obtain discriminative
local features for object detection. Then the proposed patch Re-ID is performed
in a deeply unsupervised manner, appealing to object detection, which usually
requires multilevel feature maps. Extensive experiments demonstrate that DUPR
outperforms state-of-the-art unsupervised pre-trainings and even the ImageNet
supervised pre-training on various downstream tasks related to object
detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Believe The HiPe: Hierarchical Perturbation for Fast, Robust, and Model-Agnostic Saliency Mapping. (arXiv:2103.05108v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05108">
<div class="article-summary-box-inner">
<span><p>Understanding the predictions made by Artificial Intelligence (AI) systems is
becoming more and more important as deep learning models are used for
increasingly complex and high-stakes tasks. Saliency mapping -- a popular
visual attribution method -- is one important tool for this, but existing
formulations are limited by either computational cost or architectural
constraints. We therefore propose Hierarchical Perturbation, a very fast and
completely model-agnostic method for interpreting model predictions with robust
saliency maps. Using standard benchmarks and datasets, we show that our
saliency maps are of competitive or superior quality to those generated by
existing model-agnostic methods -- and are over 20 times faster to compute.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PredRNN: A Recurrent Neural Network for Spatiotemporal Predictive Learning. (arXiv:2103.09504v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09504">
<div class="article-summary-box-inner">
<span><p>The predictive learning of spatiotemporal sequences aims to generate future
images by learning from the historical context, where the visual dynamics are
believed to have modular structures that can be learned with compositional
subsystems. This paper models these structures by presenting PredRNN, a new
recurrent network, in which a pair of memory cells are explicitly decoupled,
operate in nearly independent transition manners, and finally form unified
representations of the complex environment. Concretely, besides the original
memory cell of LSTM, this network is featured by a zigzag memory flow that
propagates in both bottom-up and top-down directions across all layers,
enabling the learned visual dynamics at different levels of RNNs to
communicate. It also leverages a memory decoupling loss to keep the memory
cells from learning redundant features. We further propose a new curriculum
learning strategy to force PredRNN to learn long-term dynamics from context
frames, which can be generalized to most sequence-to-sequence models. We
provide detailed ablation studies to verify the effectiveness of each
component. Our approach is shown to obtain highly competitive results on five
datasets for both action-free and action-conditioned predictive learning
scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistency-based Active Learning for Object Detection. (arXiv:2103.10374v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10374">
<div class="article-summary-box-inner">
<span><p>Active learning aims to improve the performance of task model by selecting
the most informative samples with a limited budget. Unlike most recent works
that focused on applying active learning for image classification, we propose
an effective Consistency-based Active Learning method for object Detection
(CALD), which fully explores the consistency between original and augmented
data. CALD has three appealing benefits. (i) CALD is systematically designed by
investigating the weaknesses of existing active learning methods, which do not
take the unique challenges of object detection into account. (ii) CALD unifies
box regression and classification with a single metric, which is not concerned
by active learning methods for classification. CALD also focuses on the most
informative local region rather than the whole image, which is beneficial for
object detection. (iii) CALD not only gauges individual information for sample
selection, but also leverages mutual information to encourage a balanced data
distribution. Extensive experiments show that CALD significantly outperforms
existing state-of-the-art task-agnostic and detection-specific active learning
methods on general object detection datasets. Based on the Faster R-CNN
detector, CALD consistently surpasses the baseline method (random selection) by
2.9/2.8/0.8 mAP on average on PASCAL VOC 2007, PASCAL VOC 2012, and MS COCO.
Code is available at \url{https://github.com/we1pingyu/CALD}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A State-of-the-art Survey of Object Detection Techniques in Microorganism Image Analysis: From Classical Methods to Deep Learning Approaches. (arXiv:2105.03148v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03148">
<div class="article-summary-box-inner">
<span><p>Microorganisms play a vital role in human life. Therefore, microorganism
detection is of great significance to human beings. However, the traditional
manual microscopic detection methods have the disadvantages of long detection
cycle, low detection accuracy in large orders, and great difficulty in
detecting uncommon microorganisms. Therefore, it is meaningful to apply
computer image analysis technology to the field of microorganism detection.
Computer image analysis can realize high-precision and high-efficiency
detection of microorganisms. In this review, first,we analyse the existing
microorganism detection methods in chronological order, from traditional image
processing and traditional machine learning to deep learning methods. Then, we
analyze and summarize these existing methods and introduce some potential
methods, including visual transformers. In the end, the future development
direction and challenges of microorganism detection are discussed. In general,
we have summarized 142 related technical papers from 1985 to the present. This
review will help researchers have a more comprehensive understanding of the
development process, research status, and future trends in the field of
microorganism detection and provide a reference for researchers in other
fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recent advances and clinical applications of deep learning in medical image analysis. (arXiv:2105.13381v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13381">
<div class="article-summary-box-inner">
<span><p>Deep learning has received extensive research interest in developing new
medical image processing algorithms, and deep learning based models have been
remarkably successful in a variety of medical imaging tasks to support disease
detection and diagnosis. Despite the success, the further improvement of deep
learning models in medical image analysis is majorly bottlenecked by the lack
of large-sized and well-annotated datasets. In the past five years, many
studies have focused on addressing this challenge. In this paper, we reviewed
and summarized these recent studies to provide a comprehensive overview of
applying deep learning methods in various medical image analysis tasks.
Especially, we emphasize the latest progress and contributions of
state-of-the-art unsupervised and semi-supervised deep learning in medical
image analysis, which are summarized based on different application scenarios,
including classification, segmentation, detection, and image registration. We
also discuss the major technical challenges and suggest the possible solutions
in future research efforts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Guided Segmentation Framework for Semi-supervised Video Instance Segmentation. (arXiv:2106.03330v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03330">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose Contextual Guided Segmentation (CGS) framework for
video instance segmentation in three passes. In the first pass, i.e., preview
segmentation, we propose Instance Re-Identification Flow to estimate main
properties of each instance (i.e., human/non-human, rigid/deformable,
known/unknown category) by propagating its preview mask to other frames. In the
second pass, i.e., contextual segmentation, we introduce multiple contextual
segmentation schemes. For human instance, we develop skeleton-guided
segmentation in a frame along with object flow to correct and refine the result
across frames. For non-human instance, if the instance has a wide variation in
appearance and belongs to known categories (which can be inferred from the
initial mask), we adopt instance segmentation. If the non-human instance is
nearly rigid, we train FCNs on synthesized images from the first frame of a
video sequence. In the final pass, i.e., guided segmentation, we develop a
novel fined-grained segmentation method on non-rectangular regions of interest
(ROIs). The natural-shaped ROI is generated by applying guided attention from
the neighbor frames of the current one to reduce the ambiguity in the
segmentation of different overlapping instances. Forward mask propagation is
followed by backward mask propagation to further restore missing instance
fragments due to re-appeared instances, fast motion, occlusion, or heavy
deformation. Finally, instances in each frame are merged based on their depth
values, together with human and non-human object interaction and rare instance
priority. Experiments conducted on the DAVIS Test-Challenge dataset demonstrate
the effectiveness of our proposed framework. We achieved the 3rd consistently
in the DAVIS Challenges 2017-2019 with 75.4%, 72.4%, and 78.4% in terms of
global score, region similarity, and contour accuracy, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04569">
<div class="article-summary-box-inner">
<span><p>Most machine learning models are validated and tested on fixed datasets. This
can give an incomplete picture of the capabilities and weaknesses of the model.
Such weaknesses can be revealed at test time in the real world. The risks
involved in such failures can be loss of profits, loss of time or even loss of
life in certain critical applications. In order to alleviate this issue,
simulators can be controlled in a fine-grained manner using interpretable
parameters to explore the semantic image manifold. In this work, we propose a
framework for learning how to test machine learning algorithms using simulators
in an adversarial manner in order to find weaknesses in the model before
deploying it in critical scenarios. We apply this method in a face recognition
setup. We show that certain weaknesses of models trained on real data can be
discovered using simulated samples. Using our proposed method, we can find
adversarial synthetic faces that fool contemporary face recognition models.
This demonstrates the fact that these models have weaknesses that are not
measured by commonly used validation datasets. We hypothesize that this type of
adversarial examples are not isolated, but usually lie in connected spaces in
the latent space of the simulator. We present a method to find these
adversarial regions as opposed to the typical adversarial points found in the
adversarial example literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective. (arXiv:2106.07115v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07115">
<div class="article-summary-box-inner">
<span><p>Multiple views of data, both naturally acquired (e.g., image and audio) and
artificially produced (e.g., via adding different noise to data samples), have
proven useful in enhancing representation learning. Natural views are often
handled by multiview analysis tools, e.g., (deep) canonical correlation
analysis [(D)CCA], while the artificial ones are frequently used in
self-supervised learning (SSL) paradigms, e.g., BYOL and Barlow Twins. Both
types of approaches often involve learning neural feature extractors such that
the embeddings of data exhibit high cross-view correlations. Although
intuitive, the effectiveness of correlation-based neural embedding is mostly
empirically validated.
</p>
<p>This work aims to understand latent correlation maximization-based deep
multiview learning from a latent component identification viewpoint. An
intuitive generative model of multiview data is adopted, where the views are
different nonlinear mixtures of shared and private components. Since the shared
components are view/distortion-invariant, representing the data using such
components is believed to reveal the identity of the samples effectively and
robustly. Under this model, latent correlation maximization is shown to
guarantee the extraction of the shared components across views (up to certain
ambiguities). In addition, it is further shown that the private information in
each view can be provably disentangled from the shared using proper
regularization design. A finite sample analysis, which has been rare in
nonlinear mixture identifiability study, is also presented. The theoretical
results and newly designed regularization are tested on a series of tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SAR-Net: Shape Alignment and Recovery Network for Category-level 6D Object Pose and Size Estimation. (arXiv:2106.14193v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14193">
<div class="article-summary-box-inner">
<span><p>Given a single scene image, this paper proposes a method of Category-level 6D
Object Pose and Size Estimation (COPSE) from the point cloud of the target
object, without external real pose-annotated training data. Specifically,
beyond the visual cues in RGB images, we rely on the shape information
predominately from the depth (D) channel. The key idea is to explore the shape
alignment of each instance against its corresponding category-level template
shape, and the symmetric correspondence of each object category for estimating
a coarse 3D object shape. Our framework deforms the point cloud of the
category-level template shape to align the observed instance point cloud for
implicitly representing its 3D rotation. Then we model the symmetric
correspondence by predicting symmetric point cloud from the partially observed
point cloud. The concatenation of the observed point cloud and symmetric one
reconstructs a coarse object shape, thus facilitating object center (3D
translation) and 3D size estimation. Extensive experiments on the
category-level NOCS benchmark demonstrate that our lightweight model still
competes with state-of-the-art approaches that require labeled real-world
images. We also deploy our approach to a physical Baxter robot to perform
grasping tasks on unseen but category-known instances, and the results further
validate the efficacy of our proposed model. Code and pre-trained models are
available on the project webpage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Dynamics of Nonlinear Representation Learning and Its Application. (arXiv:2106.14836v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14836">
<div class="article-summary-box-inner">
<span><p>Representations of the world environment play a crucial role in artificial
intelligence. It is often inefficient to conduct reasoning and inference
directly in the space of raw sensory representations, such as pixel values of
images. Representation learning allows us to automatically discover suitable
representations from raw sensory data. For example, given raw sensory data, a
deep neural network learns nonlinear representations at its hidden layers,
which are subsequently used for classification (or regression) at its output
layer. This happens implicitly during training through minimizing a supervised
or unsupervised loss in common practical regimes of deep learning, unlike the
neural tangent kernel (NTK) regime. In this paper, we study the dynamics of
such implicit nonlinear representation learning, which is beyond the NTK
regime. We identify a pair of a new assumption and a novel condition, called
the common model structure assumption and the data-architecture alignment
condition. Under the common model structure assumption, the data-architecture
alignment condition is shown to be sufficient for the global convergence and
necessary for the global optimality. Moreover, our theory explains how and when
increasing the network size does and does not improve the training behaviors in
the practical regime. Our results provide practical guidance for designing a
model structure: e.g., the common model structure assumption can be used as a
justification for using a particular model structure instead of others. We also
derive a new training framework based on the theory. The proposed framework is
empirically shown to maintain competitive (practical) test performances while
providing global convergence guarantees for deep residual neural networks with
convolutions, skip connections, and batch normalization with standard benchmark
datasets, including CIFAR-10, CIFAR-100, and SVHN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is attention to bounding boxes all you need for pedestrian action prediction?. (arXiv:2107.08031v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08031">
<div class="article-summary-box-inner">
<span><p>The human driver is no longer the only one concerned with the complexity of
the driving scenarios. Autonomous vehicles (AV) are similarly becoming involved
in the process. Nowadays, the development of AVs in urban places raises
essential safety concerns for vulnerable road users (VRUs) such as pedestrians.
Therefore, to make the roads safer, it is critical to classify and predict the
pedestrians' future behavior. In this paper, we present a framework based on
multiple variations of the Transformer models able to infer predict the
pedestrian street-crossing decision-making based on the dynamics of its
initiated trajectory. We showed that using solely bounding boxes as input
features can outperform the previous state-of-the-art results by reaching a
prediction accuracy of 91\% and an F1-score of 0.83 on the PIE dataset. In
addition, we introduced a large-size simulated dataset (CP2A) using CARLA for
action prediction. Our model has similarly reached high accuracy (91\%) and
F1-score (0.91) on this dataset. Interestingly, we showed that pre-training our
Transformer model on the CP2A dataset and then fine-tuning it on the PIE
dataset is beneficial for the action prediction task. Finally, our model's
results are successfully supported by the "human attention to bounding boxes"
experiment which we created to test humans ability for pedestrian action
prediction without the need for environmental context. The code for the dataset
and the models is available at:
https://github.com/linaashaji/Action_Anticipation
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging Gap between Image Pixels and Semantics via Supervision: A Survey. (arXiv:2107.13757v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13757">
<div class="article-summary-box-inner">
<span><p>The fact that there exists a gap between low-level features and semantic
meanings of images, called the semantic gap, is known for decades. Resolution
of the semantic gap is a long standing problem. The semantic gap problem is
reviewed and a survey on recent efforts in bridging the gap is made in this
work. Most importantly, we claim that the semantic gap is primarily bridged
through supervised learning today. Experiences are drawn from two application
domains to illustrate this point: 1) object detection and 2) metric learning
for content-based image retrieval (CBIR). To begin with, this paper offers a
historical retrospective on supervision, makes a gradual transition to the
modern data-driven methodology and introduces commonly used datasets. Then, it
summarizes various supervision methods to bridge the semantic gap in the
context of object detection and metric learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SphereFace2: Binary Classification is All You Need for Deep Face Recognition. (arXiv:2108.01513v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01513">
<div class="article-summary-box-inner">
<span><p>State-of-the-art deep face recognition methods are mostly trained with a
softmax-based multi-class classification framework. Despite being popular and
effective, these methods still have a few shortcomings that limit empirical
performance. In this paper, we start by identifying the discrepancy between
training and evaluation in the existing multi-class classification framework
and then discuss the potential limitations caused by the "competitive" nature
of softmax normalization. Motivated by these limitations, we propose a novel
binary classification training framework, termed SphereFace2. In contrast to
existing methods, SphereFace2 circumvents the softmax normalization, as well as
the corresponding closed-set assumption. This effectively bridges the gap
between training and evaluation, enabling the representations to be improved
individually by each binary classification task. Besides designing a specific
well-performing loss function, we summarize a few general principles for this
"one-vs-all" binary classification framework so that it can outperform current
competitive methods. Our experiments on popular benchmarks demonstrate that
SphereFace2 can consistently outperform state-of-the-art deep face recognition
methods. The code has been made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NODEO: A Neural Ordinary Differential Equation Based Optimization Framework for Deformable Image Registration. (arXiv:2108.03443v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03443">
<div class="article-summary-box-inner">
<span><p>Deformable image registration (DIR), aiming to find spatial correspondence
between images, is one of the most critical problems in the domain of medical
image analysis. In this paper, we present a novel, generic, and accurate
diffeomorphic image registration framework that utilizes neural ordinary
differential equations (NODEs). We model each voxel as a moving particle and
consider the set of all voxels in a 3D image as a high-dimensional dynamical
system whose trajectory determines the targeted deformation field. Our method
leverages deep neural networks for their expressive power in modeling dynamical
systems, and simultaneously optimizes for a dynamical system between the image
pairs and the corresponding transformation. Our formulation allows various
constraints to be imposed along the transformation to maintain desired
regularities. Our experiment results show that our method outperforms the
benchmarks under various metrics. Additionally, we demonstrate the feasibility
to expand our framework to register multiple image sets using a unified form of
transformation,which could possibly serve a wider range of applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Self-Distillation Embedded Supervised Affinity Attention Model for Few-Shot Segmentation. (arXiv:2108.06600v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06600">
<div class="article-summary-box-inner">
<span><p>Few-shot semantic segmentation is a challenging task of predicting object
categories in pixel-wise with only few annotated samples. However, existing
approaches still face two main challenges. First, huge feature distinction
between support and query images causes knowledge transferring barrier, which
harms the segmentation performance. Second, few support samples cause
unrepresentative of support features, hardly to guide high-quality query
segmentation. To deal with the above two issues, we propose self-distillation
embedded supervised affinity attention model (SD-AANet) to improve the
performance of few-shot segmentation task. Specifically, the self-distillation
guided prototype module (SDPM) extracts intrinsic prototype by
self-distillation between support and query to capture representative features.
The supervised affinity attention module (SAAM) adopts support ground truth to
guide the production of high quality query attention map, which can learn
affinity information to focus on whole area of query target. Extensive
experiments prove that our SD-AANet significantly improves the performance
comparing with existing methods. Comprehensive ablation experiments and
visualization studies also show the significant effect of SDPM and SAAM for
few-shot segmentation task. On benchmark datasets, PASCAL-5i and COCO-20i, our
proposed SD-AANet both achieve state-of-the-art results. Our code is available
on https://github.com/cv516Buaa/SD-AANet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MMChat: Multi-Modal Chat Dataset on Social Media. (arXiv:2108.07154v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07154">
<div class="article-summary-box-inner">
<span><p>Incorporating multi-modal contexts in conversation is an important step for
developing more engaging dialogue systems. In this work, we explore this
direction by introducing MMChat: a large scale Chinese multi-modal dialogue
corpus (32.4M raw dialogues and 120.84K filtered dialogues). Unlike previous
corpora that are crowd-sourced or collected from fictitious movies, MMChat
contains image-grounded dialogues collected from real conversations on social
media, in which the sparsity issue is observed. Specifically, image-initiated
dialogues in common communications may deviate to some non-image-grounded
topics as the conversation proceeds. To better investigate this issue, we
manually annotate 100K dialogues from MMChat and further filter the corpus
accordingly, which yields MMChat-hf. We develop a benchmark model to address
the sparsity issue in dialogue generation tasks by adapting the attention
routing mechanism on image features. Experiments demonstrate the usefulness of
incorporating image features and the effectiveness in handling the sparsity of
image features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier. (arXiv:2108.09135v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09135">
<div class="article-summary-box-inner">
<span><p>The adversarial patch attack against image classification models aims to
inject adversarially crafted pixels within a restricted image region (i.e., a
patch) for inducing model misclassification. This attack can be realized in the
physical world by printing and attaching the patch to the victim object; thus,
it imposes a real-world threat to computer vision systems. To counter this
threat, we design PatchCleanser as a certifiably robust defense against
adversarial patches. In PatchCleanser, we perform two rounds of pixel masking
on the input image to neutralize the effect of the adversarial patch. This
image-space operation makes PatchCleanser compatible with any state-of-the-art
image classifier for achieving high accuracy. Furthermore, we can prove that
PatchCleanser will always predict the correct class labels on certain images
against any adaptive white-box attacker within our threat model, achieving
certified robustness. We extensively evaluate PatchCleanser on the ImageNet,
ImageNette, CIFAR-10, CIFAR-100, SVHN, and Flowers-102 datasets and demonstrate
that our defense achieves similar clean accuracy as state-of-the-art
classification models and also significantly improves certified robustness from
prior works. Remarkably, PatchCleanser achieves 83.9% top-1 clean accuracy and
62.1% top-1 certified robust accuracy against a 2%-pixel square patch anywhere
on the image for the 1000-class ImageNet dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking the Misalignment Problem in Dense Object Detection. (arXiv:2108.12176v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12176">
<div class="article-summary-box-inner">
<span><p>Object detection aims to localize and classify the objects in a given image,
and these two tasks are sensitive to different object regions. Therefore, some
locations predict high-quality bounding boxes but low classification scores,
and some locations are quite the opposite. A misalignment exists between the
two tasks, and their features are spatially entangled. In order to solve the
misalignment problem, we propose a plug-in Spatial-disentangled and
Task-aligned operator (SALT). By predicting two task-aware point sets that are
located in each task's sensitive regions, SALT can reassign features from those
regions and align them to the corresponding anchor point. Therefore, features
for the two tasks are spatially aligned and disentangled. To minimize the
difference between the two regression stages, we propose a Self-distillation
regression (SDR) loss that can transfer knowledge from the refined regression
results to the coarse regression results. On the basis of SALT and SDR loss, we
propose SALT-Net, which explicitly exploits task-aligned point-set features for
accurate detection results. Extensive experiments on the MS-COCO dataset show
that our proposed methods can consistently boost different state-of-the-art
dense detectors by $\sim$2 AP. Notably, SALT-Net with Res2Net-101-DCN backbone
achieves 53.8 AP on the MS-COCO test-dev.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Pursuit of Designing Multi-modal Transformer for Video Grounding. (arXiv:2109.06085v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06085">
<div class="article-summary-box-inner">
<span><p>Video grounding aims to localize the temporal segment corresponding to a
sentence query from an untrimmed video. Almost all existing video grounding
methods fall into two frameworks: 1) Top-down model: It predefines a set of
segment candidates and then conducts segment classification and regression. 2)
Bottom-up model: It directly predicts frame-wise probabilities of the
referential segment boundaries. However, all these methods are not end-to-end,
i.e., they always rely on some time-consuming post-processing steps to refine
predictions. To this end, we reformulate video grounding as a set prediction
task and propose a novel end-to-end multi-modal Transformer model, dubbed as
GTR. Specifically, GTR has two encoders for video and language encoding, and a
cross-modal decoder for grounding prediction. To facilitate the end-to-end
training, we use a Cubic Embedding layer to transform the raw videos into a set
of visual tokens. To better fuse these two modalities in the decoder, we design
a new Multi-head Cross-Modal Attention. The whole GTR is optimized via a
Many-to-One matching loss. Furthermore, we conduct comprehensive studies to
investigate different model design choices. Extensive results on three
benchmarks have validated the superiority of GTR. All three typical GTR
variants achieve record-breaking performance on all datasets and metrics, with
several times faster inference speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design. (arXiv:2110.03659v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03659">
<div class="article-summary-box-inner">
<span><p>An agent's functionality is largely determined by its design, i.e., skeletal
structure and joint attributes (e.g., length, size, strength). However, finding
the optimal agent design for a given function is extremely challenging since
the problem is inherently combinatorial and the design space is prohibitively
large. Additionally, it can be costly to evaluate each candidate design which
requires solving for its optimal controller. To tackle these problems, our key
idea is to incorporate the design procedure of an agent into its
decision-making process. Specifically, we learn a conditional policy that, in
an episode, first applies a sequence of transform actions to modify an agent's
skeletal structure and joint attributes, and then applies control actions under
the new design. To handle a variable number of joints across designs, we use a
graph-based policy where each graph node represents a joint and uses message
passing with its neighbors to output joint-specific actions. Using policy
gradient methods, our approach enables joint optimization of agent design and
control as well as experience sharing across different designs, which improves
sample efficiency substantially. Experiments show that our approach,
Transform2Act, outperforms prior methods significantly in terms of convergence
speed and final performance. Notably, Transform2Act can automatically discover
plausible designs similar to giraffes, squids, and spiders. Code and videos are
available at https://sites.google.com/view/transform2act.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Arch-Net: Model Distillation for Architecture Agnostic Model Deployment. (arXiv:2111.01135v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01135">
<div class="article-summary-box-inner">
<span><p>Vast requirement of computation power of Deep Neural Networks is a major
hurdle to their real world applications. Many recent Application Specific
Integrated Circuit (ASIC) chips feature dedicated hardware support for Neural
Network Acceleration. However, as ASICs take multiple years to develop, they
are inevitably out-paced by the latest development in Neural Architecture
Research. For example, Transformer Networks do not have native support on many
popular chips, and hence are difficult to deploy. In this paper, we propose
Arch-Net, a family of Neural Networks made up of only operators efficiently
supported across most architectures of ASICs. When a Arch-Net is produced, less
common network constructs, like Layer Normalization and Embedding Layers, are
eliminated in a progressive manner through label-free Blockwise Model
Distillation, while performing sub-eight bit quantization at the same time to
maximize performance. Empirical results on machine translation and image
classification tasks confirm that we can transform latest developed Neural
Architectures into fast running and as-accurate Arch-Net, ready for deployment
on multiple mass-produced ASIC chips. The code will be available at
https://github.com/megvii-research/Arch-Net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LTD: Low Temperature Distillation for Robust Adversarial Training. (arXiv:2111.02331v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02331">
<div class="article-summary-box-inner">
<span><p>Adversarial training has been widely used to enhance the robustness of the
neural network models against adversarial attacks. However, there still a
notable gap between the nature accuracy and the robust accuracy. We found one
of the reasons is the commonly used labels, one-hot vectors, hinder the
learning process for image recognition. In this paper, we proposed a method,
called Low Temperature Distillation (LTD), which is based on the knowledge
distillation framework to generate the desired soft labels. Unlike the previous
work, LTD uses relatively low temperature in the teacher model, and employs
different, but fixed, temperatures for the teacher model and the student model.
Moreover, we have investigated the methods to synergize the use of nature data
and adversarial ones in LTD. Experimental results show that without extra
unlabeled data, the proposed method combined with the previous work can achieve
57.72\% and 30.36\% robust accuracy on CIFAR-10 and CIFAR-100 dataset
respectively, which is about 1.21\% improvement of the state-of-the-art methods
in average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMU: smooth activation function for deep networks using smoothing maximum technique. (arXiv:2111.04682v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.04682">
<div class="article-summary-box-inner">
<span><p>Deep learning researchers have a keen interest in proposing two new novel
activation functions which can boost network performance. A good choice of
activation function can have significant consequences in improving network
performance. A handcrafted activation is the most common choice in neural
network models. ReLU is the most common choice in the deep learning community
due to its simplicity though ReLU has some serious drawbacks. In this paper, we
have proposed a new novel activation function based on approximation of known
activation functions like Leaky ReLU, and we call this function Smooth Maximum
Unit (SMU). Replacing ReLU by SMU, we have got 6.22% improvement in the
CIFAR100 dataset with the ShuffleNet V2 model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FabricFlowNet: Bimanual Cloth Manipulation with a Flow-based Policy. (arXiv:2111.05623v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.05623">
<div class="article-summary-box-inner">
<span><p>We address the problem of goal-directed cloth manipulation, a challenging
task due to the deformability of cloth. Our insight is that optical flow, a
technique normally used for motion estimation in video, can also provide an
effective representation for corresponding cloth poses across observation and
goal images. We introduce FabricFlowNet (FFN), a cloth manipulation policy that
leverages flow as both an input and as an action representation to improve
performance. FabricFlowNet also elegantly switches between bimanual and
single-arm actions based on the desired goal. We show that FabricFlowNet
significantly outperforms state-of-the-art model-free and model-based cloth
manipulation policies that take image input. We also present real-world
experiments on a bimanual system, demonstrating effective sim-to-real transfer.
Finally, we show that our method generalizes when trained on a single square
cloth to other cloth shapes, such as T-shirts and rectangular cloths. Video and
other supplementary materials are available at:
https://sites.google.com/view/fabricflownet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Swin Transformer V2: Scaling Up Capacity and Resolution. (arXiv:2111.09883v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09883">
<div class="article-summary-box-inner">
<span><p>Large-scale NLP models have been shown to significantly improve the
performance on language tasks with no signs of saturation. They also
demonstrate amazing few-shot capabilities like that of human beings. This paper
aims to explore large-scale models in computer vision. We tackle three major
issues in training and application of large vision models, including training
instability, resolution gaps between pre-training and fine-tuning, and hunger
on labelled data. Three main techniques are proposed: 1) a residual-post-norm
method combined with cosine attention to improve training stability; 2) A
log-spaced continuous position bias method to effectively transfer models
pre-trained using low-resolution images to downstream tasks with
high-resolution inputs; 3) A self-supervised pre-training method, SimMIM, to
reduce the needs of vast labeled images. Through these techniques, this paper
successfully trained a 3 billion-parameter Swin Transformer V2 model, which is
the largest dense vision model to date, and makes it capable of training with
images of up to 1,536$\times$1,536 resolution. It set new performance records
on 4 representative vision tasks, including ImageNet-V2 image classification,
COCO object detection, ADE20K semantic segmentation, and Kinetics-400 video
action classification. Also note our training is much more efficient than that
in Google's billion-level visual models, which consumes 40 times less labelled
data and 40 times less training time. Code is available at
\url{https://github.com/microsoft/Swin-Transformer}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transferability Estimation using Bhattacharyya Class Separability. (arXiv:2111.12780v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12780">
<div class="article-summary-box-inner">
<span><p>Transfer learning has become a popular method for leveraging pre-trained
models in computer vision. However, without performing computationally
expensive fine-tuning, it is difficult to quantify which pre-trained source
models are suitable for a specific target task, or, conversely, to which tasks
a pre-trained source model can be easily adapted to. In this work, we propose
Gaussian Bhattacharyya Coefficient (GBC), a novel method for quantifying
transferability between a source model and a target dataset. In a first step we
embed all target images in the feature space defined by the source model, and
represent them with per-class Gaussians. Then, we estimate their pairwise class
separability using the Bhattacharyya coefficient, yielding a simple and
effective measure of how well the source model transfers to the target task. We
evaluate GBC on image classification tasks in the context of dataset and
architecture selection. Further, we also perform experiments on the more
complex semantic segmentation transferability estimation task. We demonstrate
that GBC outperforms state-of-the-art transferability metrics on most
evaluation criteria in the semantic segmentation settings, matches the
performance of top methods for dataset transferability in image classification,
and performs best on architecture selection problems for image classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Low-Cost and Efficient Malaria Detection. (arXiv:2111.13656v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13656">
<div class="article-summary-box-inner">
<span><p>Malaria, a fatal but curable disease claims hundreds of thousands of lives
every year. Early and correct diagnosis is vital to avoid health complexities,
however, it depends upon the availability of costly microscopes and trained
experts to analyze blood-smear slides. Deep learning-based methods have the
potential to not only decrease the burden of experts but also improve
diagnostic accuracy on low-cost microscopes. However, this is hampered by the
absence of a reasonable size dataset. One of the most challenging aspects is
the reluctance of the experts to annotate the dataset at low magnification on
low-cost microscopes. We present a dataset to further the research on malaria
microscopy over the low-cost microscopes at low magnification. Our large-scale
dataset consists of images of blood-smear slides from several malaria-infected
patients, collected through microscopes at two different cost spectrums and
multiple magnifications. Malarial cells are annotated for the localization and
life-stage classification task on the images collected through the high-cost
microscope at high magnification. We design a mechanism to transfer these
annotations from the high-cost microscope at high magnification to the low-cost
microscope, at multiple magnifications. Multiple object detectors and domain
adaptation methods are presented as the baselines. Furthermore, a partially
supervised domain adaptation method is introduced to adapt the object-detector
to work on the images collected from the low-cost microscope. The dataset will
be made publicly available after publication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">n-CPS: Generalising Cross Pseudo Supervision to n Networks for Semi-Supervised Semantic Segmentation. (arXiv:2112.07528v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07528">
<div class="article-summary-box-inner">
<span><p>We present n-CPS - a generalisation of the recent state-of-the-art cross
pseudo supervision (CPS) approach for the task of semi-supervised semantic
segmentation. In n-CPS, there are n simultaneously trained subnetworks that
learn from each other through one-hot encoding perturbation and consistency
regularisation. We also show that ensembling techniques applied to subnetworks
outputs can significantly improve the performance. To the best of our
knowledge, n-CPS paired with CutMix outperforms CPS and sets the new
state-of-the-art for Pascal VOC 2012 with (1/16, 1/8, 1/4, and 1/2 supervised
regimes) and Cityscapes (1/16 supervised).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial Distribution Patterns and Stress Potential Signs of Clownfish in Recirculating Aquaculture Systems. (arXiv:2112.14513v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.14513">
<div class="article-summary-box-inner">
<span><p>Monitoring and detecting fish behaviors provide essential information on fish
welfare and contribute to achieving intelligent production in global
aquaculture. This work proposes an efficient approach to analyze the spatial
distribution status and motion patterns of juvenile clownfish
\textit{(Amphiprion bicinctus)} maintained in aquaria at three stocking
densities (1, 5, and 10 individuals/aquarium). The estimated displacement is
the key factor in assessing the dispersion and velocity to express the
clownfish's spatial distribution and movement behavior in a recirculating
aquaculture system. Indeed, we aim at computing the velocity, magnitude, and
turning angle using an optical flow method to assist aquaculturists in
efficiently monitoring and identifying fish behavior. We test the system design
on a database containing two days of video streams of juvenile clownfish
maintained in aquaria. The proposed displacement estimation reveals good
performance in measuring clownfish's motion and dispersion characteristics
leading to assess the potential signs of stress behaviors. Furthermore, we
demonstrate the effectiveness of the proposed technique for quantifying
variation in clownfish activity levels between recordings taken in the morning
and afternoon at different stocking densities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering. (arXiv:2112.15399v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.15399">
<div class="article-summary-box-inner">
<span><p>We present an information-theoretic regularization technique for few-shot
novel view synthesis based on neural implicit representation. The proposed
approach minimizes potential reconstruction inconsistency that happens due to
insufficient viewpoints by imposing the entropy constraint of the density in
each ray. In addition, to alleviate the potential degenerate issue when all
training images are acquired from almost redundant viewpoints, we further
incorporate the spatially smoothness constraint into the estimated images by
restricting information gains from a pair of rays with slightly different
viewpoints. The main idea of our algorithm is to make reconstructed scenes
compact along individual rays and consistent across rays in the neighborhood.
The proposed regularizers can be plugged into most of existing neural volume
rendering techniques based on NeRF in a straightforward way. Despite its
simplicity, we achieve consistently improved performance compared to existing
neural view synthesis methods by large margins on multiple standard benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantically Grounded Visual Embeddings for Zero-Shot Learning. (arXiv:2201.00577v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.00577">
<div class="article-summary-box-inner">
<span><p>Zero-shot learning methods rely on fixed visual and semantic embeddings,
extracted from independent vision and language models, both pre-trained for
other large-scale tasks. This is a weakness of current zero-shot learning
frameworks as such disjoint embeddings fail to adequately associate visual and
textual information to their shared semantic content. Therefore, we propose to
learn semantically grounded and enriched visual information by computing a
joint image and text model with a two-stream network on a proxy task. To
improve this alignment between image and textual representations, provided by
attributes, we leverage ancillary captions to provide grounded semantic
information. Our method, dubbed joint embeddings for zero-shot learning is
evaluated on several benchmark datasets, improving the performance of existing
state-of-the-art methods in both standard ($+1.6$\% on aPY, $+2.6\%$ on FLO)
and generalized ($+2.1\%$ on AWA$2$, $+2.2\%$ on CUB) zero-shot recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An unambiguous cloudiness index for nonwovens. (arXiv:2201.02011v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02011">
<div class="article-summary-box-inner">
<span><p>Cloudiness or formation is a concept routinely used in industry to address
deviations from homogeneity in nonwovens and papers. Measuring a cloudiness
index based on image data is a common task in industrial quality assurance. The
two most popular ways of quantifying cloudiness are based on power spectrum or
correlation function on the one hand or the Laplacian pyramid on the other
hand. Here, we recall the mathematical basis of the first approach
comprehensively, derive a cloudiness index, and demonstrate its practical
estimation. We prove that the Laplacian pyramid as well as other quantities
characterizing cloudiness like the range of interaction and the intensity of
small-angle scattering are very closely related to the power spectrum. Finally,
we show that the power spectrum is easy to be measured image analytically and
carries more information than the alternatives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Swin Transformer for Fast MRI. (arXiv:2201.03230v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03230">
<div class="article-summary-box-inner">
<span><p>Magnetic resonance imaging (MRI) is an important non-invasive clinical tool
that can produce high-resolution and reproducible images. However, a long
scanning time is required for high-quality MR images, which leads to exhaustion
and discomfort of patients, inducing more artefacts due to voluntary movements
of the patients and involuntary physiological movements. To accelerate the
scanning process, methods by k-space undersampling and deep learning based
reconstruction have been popularised. This work introduced SwinMR, a novel Swin
transformer based method for fast MRI reconstruction. The whole network
consisted of an input module (IM), a feature extraction module (FEM) and an
output module (OM). The IM and OM were 2D convolutional layers and the FEM was
composed of a cascaded of residual Swin transformer blocks (RSTBs) and 2D
convolutional layers. The RSTB consisted of a series of Swin transformer layers
(STLs). The shifted windows multi-head self-attention (W-MSA/SW-MSA) of STL was
performed in shifted windows rather than the multi-head self-attention (MSA) of
the original transformer in the whole image space. A novel multi-channel loss
was proposed by using the sensitivity maps, which was proved to reserve more
textures and details. We performed a series of comparative studies and ablation
studies in the Calgary-Campinas public brain MR dataset and conducted a
downstream segmentation experiment in the Multi-modal Brain Tumour Segmentation
Challenge 2017 dataset. The results demonstrate our SwinMR achieved
high-quality reconstruction compared with other benchmark methods, and it shows
great robustness with different undersampling masks, under noise interruption
and on different datasets. The code is publicly available at
https://github.com/ayanglab/SwinMR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection. (arXiv:2201.07131v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.07131">
<div class="article-summary-box-inner">
<span><p>One of the most pressing challenges for the detection of face-manipulated
videos is generalising to forgery methods not seen during training while
remaining effective under common corruptions such as compression. In this
paper, we examine whether we can tackle this issue by harnessing videos of real
talking faces, which contain rich information on natural facial appearance and
behaviour and are readily available in large quantities online. Our method,
termed RealForensics, consists of two stages. First, we exploit the natural
correspondence between the visual and auditory modalities in real videos to
learn, in a self-supervised cross-modal manner, temporally dense video
representations that capture factors such as facial movements, expression, and
identity. Second, we use these learned representations as targets to be
predicted by our forgery detector along with the usual binary forgery
classification task; this encourages it to base its real/fake decision on said
factors. We show that our method achieves state-of-the-art performance on
cross-manipulation generalisation and robustness experiments, and examine the
factors that contribute to its performance. Our results suggest that leveraging
natural and unlabelled videos is a promising direction for the development of
more robust face forgery detectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">POTHER: Patch-Voted Deep Learning-based Chest X-ray Bias Analysis for COVID-19 Detection. (arXiv:2201.09360v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09360">
<div class="article-summary-box-inner">
<span><p>A critical step in the fight against COVID-19, which continues to have a
catastrophic impact on peoples lives, is the effective screening of patients
presented in the clinics with severe COVID-19 symptoms. Chest radiography is
one of the promising screening approaches. Many studies reported detecting
COVID-19 in chest X-rays accurately using deep learning. A serious limitation
of many published approaches is insufficient attention paid to explaining
decisions made by deep learning models. Using explainable artificial
intelligence methods, we demonstrate that model decisions may rely on
confounding factors rather than medical pathology. After an analysis of
potential confounding factors found on chest X-ray images, we propose a novel
method to minimise their negative impact. We show that our proposed method is
more robust than previous attempts to counter confounding factors such as ECG
leads in chest X-rays that often influence model classification decisions. In
addition to being robust, our method achieves results comparable to the
state-of-the-art. The source code and pre-trained weights are publicly
available at (https://github.com/tomek1911/POTHER).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERTHA: Video Captioning Evaluation Via Transfer-Learned Human Assessment. (arXiv:2201.10243v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10243">
<div class="article-summary-box-inner">
<span><p>Evaluating video captioning systems is a challenging task as there are
multiple factors to consider; for instance: the fluency of the caption,
multiple actions happening in a single scene, and the human bias of what is
considered important. Most metrics try to measure how similar the system
generated captions are to a single or a set of human-annotated captions. This
paper presents a new method based on a deep learning model to evaluate these
systems. The model is based on BERT, which is a language model that has been
shown to work well in multiple NLP tasks. The aim is for the model to learn to
perform an evaluation similar to that of a human. To do so, we use a dataset
that contains human evaluations of system generated captions. The dataset
consists of the human judgments of the captions produce by the system
participating in various years of the TRECVid video to text task. These
annotations will be made publicly available. BERTHA obtain favourable results,
outperforming the commonly used metrics in some setups.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Contrastive Learning is Provably (almost) Principal Component Analysis. (arXiv:2201.12680v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12680">
<div class="article-summary-box-inner">
<span><p>We show that Contrastive Learning (CL) under a family of loss functions
(including InfoNCE) has a game-theoretical formulation, where the \emph{max
player} finds representation to maximize contrastiveness, and the \emph{min
player} puts weights on pairs of samples with similar representation. We show
that the max player who does \emph{representation learning} reduces to
Principal Component Analysis for deep linear network, and almost all local
minima are global, recovering optimal PCA solutions. Experiments show that the
formulation yields comparable (or better) performance on CIFAR10 and STL-10
when extending beyond InfoNCE, yielding novel contrastive losses. Furthermore,
we extend our theoretical analysis to 2-layer ReLU networks, showing its
difference from linear ones, and proving that feature composition is preferred
over picking single dominant feature under strong augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grounding Answers for Visual Questions Asked by Visually Impaired People. (arXiv:2202.01993v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01993">
<div class="article-summary-box-inner">
<span><p>Visual question answering is the task of answering questions about images. We
introduce the VizWiz-VQA-Grounding dataset, the first dataset that visually
grounds answers to visual questions asked by people with visual impairments. We
analyze our dataset and compare it with five VQA-Grounding datasets to
demonstrate what makes it similar and different. We then evaluate the SOTA VQA
and VQA-Grounding models and demonstrate that current SOTA algorithms often
fail to identify the correct visual evidence where the answer is located. These
models regularly struggle when the visual evidence occupies a small fraction of
the image, for images that are higher quality, as well as for visual questions
that require skills in text recognition. The dataset, evaluation server, and
leaderboard all can be found at the following link:
https://vizwiz.org/tasks-and-datasets/answer-grounding-for-vqa/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SSHA: Video Violence Recognition and Localization Using a Semi-Supervised Hard Attention Model. (arXiv:2202.02212v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02212">
<div class="article-summary-box-inner">
<span><p>Current human-based surveillance systems are prone to inadequate availability
and reliability. Artificial intelligence-based solutions are compelling,
considering their reliability and precision in the face of an increasing
adaption of surveillance systems. Exceedingly efficient and precise machine
learning models are required to effectively utilize the extensive volume of
high-definition surveillance imagery. This study focuses on improving the
accuracy of the methods and models used in automated surveillance systems to
recognize and localize human violence in video footage. The proposed model uses
an I3D backbone pretrained on the Kinetics dataset and has achieved
state-of-the-art accuracy of 90.4% and 98.7% on RWF and Hockey datasets,
respectively. The semi-supervised hard attention mechanism has enabled the
proposed method to fully capture the available information in a high-resolution
video by processing the necessary video regions in great detail.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Wilderness Using Explainable Machine Learning in Satellite Imagery. (arXiv:2203.00379v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.00379">
<div class="article-summary-box-inner">
<span><p>Wilderness areas offer important ecological and social benefits and therefore
warrant monitoring and preservation. Yet, the characteristics of wilderness are
little known, making the detection and monitoring of wilderness areas via
remote sensing techniques a challenging task. We explore the appearance and
characteristics of the vague concept of wilderness via multispectral satellite
imagery. For this, we apply a novel explainable machine learning technique to a
dataset consisting of wild and anthropogenic areas in Fennoscandia. With our
technique, we predict continuous, detailed, and high-resolution sensitivity
maps of unseen remote sensing data for wild and anthropogenic characteristics.
Our neural network provides an interpretable activation space in which regions
are semantically arranged regarding these characteristics and certain land
cover classes. Interpretability increases confidence in the method and allows
for new explanations of the investigated concept. Our model advances
explainable machine learning for remote sensing, offers opportunities for
comprehensive analyses of existing wilderness, and has practical relevance for
conservation efforts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SingleSketch2Mesh : Generating 3D Mesh model from Sketch. (arXiv:2203.03157v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03157">
<div class="article-summary-box-inner">
<span><p>Sketching is an important activity in any design process. Designers and
stakeholders share their ideas through hand-drawn sketches. These sketches are
further used to create 3D models. Current methods to generate 3D models from
sketches are either manual or tightly coupled with 3D modeling platforms.
Therefore, it requires users to have an experience of sketching on such
platform. Moreover, most of the existing approaches are based on geometric
manipulation and thus cannot be generalized. We propose a novel AI based
ensemble approach, SingleSketch2Mesh, for generating 3D models from hand-drawn
sketches. Our approach is based on Generative Networks and Encoder-Decoder
Architecture to generate 3D mesh model from a hand-drawn sketch. We evaluate
our solution with existing solutions. Our approach outperforms existing
approaches on both - quantitative and qualitative evaluation criteria.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Open-Set Text Recognition via Label-to-Prototype Learning. (arXiv:2203.05179v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.05179">
<div class="article-summary-box-inner">
<span><p>Scene text recognition is a popular topic and extensively used in the
industry. Although many methods have achieved satisfactory performance for the
close-set text recognition challenges, these methods lose feasibility in
open-set scenarios, where collecting data or retraining models for novel
characters is too expensive. E.g., annotating samples for foreign languages can
be expensive, whereas retraining the model each time a "novel" character is
discovered from historical documents also costs time and resources. In this
paper, we introduce and formulate a new task, i.e., the open-set text
recognition task, which demands the capability to spot and cognize novel
characters without retraining. Here, we propose a label-to-prototype learning
framework that fulfills the new requirements in the proposed task.
Specifically, novel characters are mapped to their corresponding prototypes
with a Label-to-Prototype Learning module. The module is trained on seen labels
and holds generalization capability for generating class centers for novel
characters without retraining. The framework also implements rejection
capability over out-of-set characters, which allows spotting unknown characters
during the evaluation process. Extensive experiments show that our method
achieves promising performance on a variety of zero-shot, close-set, and
open-set text recognition datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DFTR: Depth-supervised Fusion Transformer for Salient Object Detection. (arXiv:2203.06429v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.06429">
<div class="article-summary-box-inner">
<span><p>Automated salient object detection (SOD) plays an increasingly crucial role
in many computer vision applications. By reformulating the depth information as
supervision rather than as input, depth-supervised convolutional neural
networks (CNN) have achieved promising results on both RGB and RGB-D SOD
scenarios with the merits of no requirements for extra depth networks and depth
inputs in the inference stage. This paper, for the first time, seeks to expand
the applicability of depth supervision to the Transformer architecture.
Specifically, we develop a Depth-supervised Fusion TRansformer (DFTR), to
further improve the accuracy of both RGB and RGB-D SOD. The proposed DFTR
involves three primary features: 1) DFTR, to the best of our knowledge, is the
first pure Transformer-based model for depth-supervised SOD; 2) A multi-scale
feature aggregation (MFA) module is proposed to fully exploit the multi-scale
features encoded by the Swin Transformer in a coarse-to-fine manner; 3) To
enable bidirectional information flow across different streams of features, a
novel multi-stage feature fusion (MFF) module is further integrated into our
DFTR with the emphasis on salient regions at different network learning stages.
We extensively evaluate the proposed DFTR on ten benchmarking datasets.
Experimental results show that our DFTR consistently outperforms the existing
state-of-the-art methods for both RGB and RGB-D SOD tasks. The code and model
will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Energy-Latency Attacks via Sponge Poisoning. (arXiv:2203.08147v2 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08147">
<div class="article-summary-box-inner">
<span><p>Sponge examples are test-time inputs carefully-optimized to increase energy
consumption and latency of neural networks when deployed on hardware
accelerators. In this work, we demonstrate that sponge attacks can also be
implanted at training time, when model training is outsourced to a third party,
via an attack that we call sponge poisoning. This attack allows one to increase
the energy consumption and latency of machine-learning models indiscriminately
on each test-time input. We present a novel formalization for sponge poisoning,
overcoming the limitations related to the optimization of test-time sponge
examples, and show that this attack is possible even if the attacker only
controls a few poisoning samples and model updates. Our extensive experimental
analysis, involving two deep learning architectures and three datasets, shows
that sponge poisoning can almost completely vanish the effect of such hardware
accelerators. Finally, we analyze activations of the resulting sponge models,
identifying the module components that are more sensitive to this
vulnerability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI. (arXiv:2203.09268v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09268">
<div class="article-summary-box-inner">
<span><p>We present PROSUB: PROgressive SUBsampling, a deep learning based, automated
methodology that subsamples an oversampled data set (e.g. multi-channeled 3D
images) with minimal loss of information. We build upon a recent dual-network
approach that won the MICCAI MUlti-DIffusion (MUDI) quantitative MRI
measurement sampling-reconstruction challenge, but suffers from deep learning
training instability, by subsampling with a hard decision boundary. PROSUB uses
the paradigm of recursive feature elimination (RFE) and progressively
subsamples measurements during deep learning training, improving optimization
stability. PROSUB also integrates a neural architecture search (NAS) paradigm,
allowing the network architecture hyperparameters to respond to the subsampling
process. We show PROSUB outperforms the winner of the MUDI MICCAI challenge,
producing large improvements &gt;18% MSE on the MUDI challenge sub-tasks and
qualitative improvements on downstream processes useful for clinical
applications. We also show the benefits of incorporating NAS and analyze the
effect of PROSUB's components. As our method generalizes to other problems
beyond MRI measurement selection-reconstruction, our code is
https://github.com/sbb-gh/PROSUB
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization. (arXiv:2203.12870v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12870">
<div class="article-summary-box-inner">
<span><p>6-DoF object pose estimation from a monocular image is challenging, and a
post-refinement procedure is generally needed for high-precision estimation. In
this paper, we propose a framework based on a recurrent neural network (RNN)
for object pose refinement, which is robust to erroneous initial poses and
occlusions. During the recurrent iterations, object pose refinement is
formulated as a non-linear least squares problem based on the estimated
correspondence field (between a rendered image and the observed image). The
problem is then solved by a differentiable Levenberg-Marquardt (LM) algorithm
enabling end-to-end training. The correspondence field estimation and pose
refinement are conducted alternatively in each iteration to recover the object
poses. Furthermore, to improve the robustness to occlusion, we introduce a
consistency-check mechanism based on the learned descriptors of the 3D model
and observed 2D images, which downweights the unreliable correspondences during
pose optimization. Extensive experiments on LINEMOD, Occlusion-LINEMOD, and
YCB-Video datasets validate the effectiveness of our method and demonstrate
state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction. (arXiv:2203.12997v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12997">
<div class="article-summary-box-inner">
<span><p>Dimensionality reduction is crucial both for visualization and preprocessing
high dimensional data for machine learning. We introduce a novel method based
on a hierarchy built on 1-nearest neighbor graphs in the original space which
is used to preserve the grouping properties of the data distribution on
multiple levels. The core of the proposal is an optimization-free projection
that is competitive with the latest versions of t-SNE and UMAP in performance
and visualization quality while being an order of magnitude faster in run-time.
Furthermore, its interpretable mechanics, the ability to project new data, and
the natural separation of data clusters in visualizations make it a general
purpose unsupervised dimension reduction technique. In the paper, we argue
about the soundness of the proposed method and evaluate it on a diverse
collection of datasets with sizes varying from 1K to 11M samples and dimensions
from 28 to 16K. We perform comparisons with other state-of-the-art methods on
multiple metrics and target dimensions highlighting its efficiency and
performance. Code is available at https://github.com/koulakis/h-nne
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Playing Lottery Tickets in Style Transfer Models. (arXiv:2203.13802v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.13802">
<div class="article-summary-box-inner">
<span><p>Style transfer has achieved great success and attracted a wide range of
attention from both academic and industrial communities due to its flexible
application scenarios. However, the dependence on a pretty large VGG-based
autoencoder leads to existing style transfer models having high parameter
complexities, which limits their applications on resource-constrained devices.
Compared with many other tasks, the compression of style transfer models has
been less explored. Recently, the lottery ticket hypothesis (LTH) has shown
great potential in finding extremely sparse matching subnetworks which can
achieve on par or even better performance than the original full networks when
trained in isolation. In this work, we for the first time perform an empirical
study to verify whether such trainable matching subnetworks also exist in style
transfer models. Specifically, we take two most popular style transfer models,
i.e., AdaIN and SANet, as the main testbeds, which represent global and local
transformation based style transfer methods respectively. We carry out
extensive experiments and comprehensive analysis, and draw the following
conclusions. (1) Compared with fixing the VGG encoder, style transfer models
can benefit more from training the whole network together. (2) Using iterative
magnitude pruning, we find the matching subnetworks at 89.2% sparsity in AdaIN
and 73.7% sparsity in SANet, which demonstrates that style transfer models can
play lottery tickets too. (3) The feature transformation module should also be
pruned to obtain a much sparser model without affecting the existence and
quality of the matching subnetworks. (4) Besides AdaIN and SANet, other models
such as LST, MANet, AdaAttN and MCCNet can also play lottery tickets, which
shows that LTH can be generalized to various style transfer models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PAEDID: Patch Autoencoder Based Deep Image Decomposition For Pixel-level Defective Region Segmentation. (arXiv:2203.14457v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.14457">
<div class="article-summary-box-inner">
<span><p>Unsupervised pixel-level defective region segmentation is an important task
in image-based anomaly detection for various industrial applications. The
state-of-the-art methods have their own advantages and limitations:
matrix-decomposition-based methods are robust to noise but lack complex
background image modeling capability; representation-based methods are good at
defective region localization but lack accuracy in defective region shape
contour extraction; reconstruction-based methods detected defective region
match well with the ground truth defective region shape contour but are noisy.
To combine the best of both worlds, we present an unsupervised patch
autoencoder based deep image decomposition (PAEDID) method for defective region
segmentation. In the training stage, we learn the common background as a deep
image prior by a patch autoencoder (PAE) network. In the inference stage, we
formulate anomaly detection as an image decomposition problem with the deep
image prior and domain-specific regularizations. By adopting the proposed
approach, the defective regions in the image can be accurately extracted in an
unsupervised fashion. We demonstrate the effectiveness of the PAEDID method in
simulation studies and an industrial dataset in the case study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Driven, Soft Alignment of Functional Data Using Shapes and Landmarks. (arXiv:2203.14810v2 [stat.ME] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.14810">
<div class="article-summary-box-inner">
<span><p>Alignment or registration of functions is a fundamental problem in
statistical analysis of functions and shapes. While there are several
approaches available, a more recent approach based on Fisher-Rao metric and
square-root velocity functions (SRVFs) has been shown to have good performance.
However, this SRVF method has two limitations: (1) it is susceptible to over
alignment, i.e., alignment of noise as well as the signal, and (2) in case
there is additional information in form of landmarks, the original formulation
does not prescribe a way to incorporate that information. In this paper we
propose an extension that allows for incorporation of landmark information to
seek a compromise between matching curves and landmarks. This results in a soft
landmark alignment that pushes landmarks closer, without requiring their exact
overlays to finds a compromise between contributions from functions and
landmarks. The proposed method is demonstrated to be superior in certain
practical scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A systematic review and meta-analysis of Digital Elevation Model (DEM) fusion: pre-processing, methods and applications. (arXiv:2203.15026v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.15026">
<div class="article-summary-box-inner">
<span><p>The remote sensing community has identified data fusion as one of the key
challenging topics of the 21st century. The subject of image fusion in
two-dimensional (2D) space has been covered in several published reviews.
However, the special case of 2.5D/3D Digital Elevation Model (DEM) fusion has
not been addressed till date. DEM fusion is a key application of data fusion in
remote sensing. It takes advantage of the complementary characteristics of
multi-source DEMs to deliver a more complete, accurate and reliable elevation
dataset. Although several methods for fusing DEMs have been developed, the
absence of a well-rounded review has limited their proliferation among
researchers and end-users. It is often required to combine knowledge from
multiple studies to inform a holistic perspective and guide further research.
In response, this paper provides a systematic review of DEM fusion: the
pre-processing workflow, methods and applications, enhanced with a
meta-analysis. Through the discussion and comparative analysis, unresolved
challenges and open issues were identified, and future directions for research
were proposed. This review is a timely solution and an invaluable source of
information for researchers within the fields of remote sensing and spatial
information science, and the data fusion community at large.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In-N-Out Generative Learning for Dense Unsupervised Video Segmentation. (arXiv:2203.15312v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.15312">
<div class="article-summary-box-inner">
<span><p>In this paper, we focus on the unsupervised learning for Video Object
Segmentation (VOS) which learns visual correspondence (i.e., similarity between
pixel-level features) from unlabeled videos. Previous methods are mainly based
on the contrastive learning paradigm, which optimize either in image level or
pixel level. Image-level optimization (e.g., the spatially pooled feature of
ResNet) learns robust high-level semantics but is sub-optimal since the
pixel-level features are optimized implicitly. By contrast, pixel-level
optimization is more explicit, however, it is sensitive to the visual quality
of training data and is not robust to object deformation. To complementarily
perform these two levels of optimization in a unified framework, we propose the
In-aNd-Out (INO) generative learning from a purely generative perspective with
the help of naturally designed class tokens and patch tokens in Vision
Transformer (ViT). Specifically, for image-level optimization, we force the
out-view imagination from local to global views on class tokens, which helps
capturing high-level semantics, and we name it as out-generative learning. As
to pixel-level optimization, we perform in-view masked image modeling on patch
tokens, which recovers the corrupted parts of an image via inferring its
fine-grained structure, and we term it as in-generative learning. To better
discover the temporal information, we additionally force the inter-frame
consistency from both feature level and affinity matrix level. Extensive
experiments on DAVIS-2017 val and YouTube-VOS 2018 val show that our INO
outperforms previous state-of-the-art methods by significant margins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters. (arXiv:2203.15331v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.15331">
<div class="article-summary-box-inner">
<span><p>Currently, many theoretical as well as practically relevant questions towards
the transferability and robustness of Convolutional Neural Networks (CNNs)
remain unsolved. While ongoing research efforts are engaging these problems
from various angles, in most computer vision related cases these approaches can
be generalized to investigations of the effects of distribution shifts in image
data. In this context, we propose to study the shifts in the learned weights of
trained CNN models. Here we focus on the properties of the distributions of
dominantly used 3x3 convolution filter kernels. We collected and publicly
provide a dataset with over 1.4 billion filters from hundreds of trained CNNs,
using a wide range of datasets, architectures, and vision tasks. In a first use
case of the proposed dataset, we can show highly relevant properties of many
publicly available pre-trained models for practical applications: I) We analyze
distribution shifts (or the lack thereof) between trained filters along
different axes of meta-parameters, like visual category of the dataset, task,
architecture, or layer depth. Based on these results, we conclude that model
pre-training can succeed on arbitrary datasets if they meet size and variance
conditions. II) We show that many pre-trained models contain degenerated
filters which make them less robust and less suitable for fine-tuning on target
applications.
</p>
<p>Data &amp; Project website: https://github.com/paulgavrikov/cnn-filter-db
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mc-BEiT: Multi-choice Discretization for Image BERT Pre-training. (arXiv:2203.15371v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.15371">
<div class="article-summary-box-inner">
<span><p>Image BERT pre-training with masked image modeling (MIM) becomes a popular
practice to cope with self-supervised representation learning. A seminal work,
BEiT, casts MIM as a classification task with a visual vocabulary, tokenizing
the continuous visual signals into discrete vision tokens using a pre-learned
dVAE. Despite a feasible solution, the improper discretization hinders further
improvements of image pre-training. Since image discretization has no
ground-truth answers, we believe that the masked patch should not be assigned
with a unique token id even if a better tokenizer can be obtained. In this
work, we introduce an improved BERT-style image pre-training method, namely
mc-BEiT, which performs MIM proxy tasks towards eased and refined multi-choice
training objectives. Specifically, the multi-choice supervision for the masked
image patches is formed by the soft probability vectors of the discrete token
ids, which are predicted by the off-the-shelf image tokenizer and further
refined by high-level inter-patch perceptions resorting to the observation that
similar patches should share their choices. Extensive experiments on
classification, segmentation, and detection tasks demonstrate the superiority
of our method, e.g., the pre-trained ViT-B achieves 84.1% top-1 fine-tuning
accuracy on ImageNet-1K classification, 50.8% mIOU on ADE20K semantic
segmentation, 51.2% AP^b and 44.3% AP^m of object detection and instance
segmentation on COCO, outperforming the competitive counterparts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smooth Robust Tensor Completion for Background/Foreground Separation with Missing Pixels: Novel Algorithm with Convergence Guarantee. (arXiv:2203.16328v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16328">
<div class="article-summary-box-inner">
<span><p>The objective of this study is to address the problem of
background/foreground separation with missing pixels by combining the video
acquisition, video recovery, background/foreground separation into a single
framework. To achieve this, a smooth robust tensor completion (SRTC) model is
proposed to recover the data and decompose it into the static background and
smooth foreground, respectively. Specifically, the static background is modeled
by the low-rank tucker decomposition and the smooth foreground (moving objects)
is modeled by the spatiotemporal continuity, which is enforced by the total
variation regularization. An efficient algorithm based on tensor proximal
alternating minimization (tenPAM) is implemented to solve the proposed model
with global convergence guarantee under very mild conditions. Extensive
experiments on real data demonstrate that the proposed method significantly
outperforms the state-of-the-art approaches for background/foreground
separation with missing pixels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GEB+: A benchmark for generic event boundary captioning, grounding and text-based retrieval. (arXiv:2204.00486v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.00486">
<div class="article-summary-box-inner">
<span><p>Cognitive science has shown that humans perceive videos in terms of events
separated by state changes of dominant subjects. State changes trigger new
events and are one of the most useful among the large amount of redundant
information perceived. However, previous research focuses on the overall
understanding of segments without evaluating the fine-grained status changes
inside. In this paper, we introduce a new dataset called Kinetic-GEBC (Generic
Event Boundary Captioning). The dataset consists of over 170k boundaries
associated with captions describing status changes in the generic events in 12K
videos. Upon this new dataset, we propose three tasks supporting the
development of a more fine-grained, robust, and human-like understanding of
videos through status changes. We evaluate many representative baselines in our
dataset, where we also design a new TPD (Temporal-based Pairwise Difference)
Modeling method for current state-of-the-art backbones and achieve significant
performance improvements. Besides, the results show there are still formidable
challenges for current methods in the utilization of different granularities,
representation of visual difference, and the accurate localization of status
changes. Further analysis shows that our dataset can drive developing more
powerful methods to understand status changes and thus improve video level
comprehension.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How stable are Transferability Metrics evaluations?. (arXiv:2204.01403v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.01403">
<div class="article-summary-box-inner">
<span><p>Transferability metrics is a maturing field with increasing interest, which
aims at providing heuristics for selecting the most suitable source models to
transfer to a given target dataset, without fine-tuning them all. However,
existing works rely on custom experimental setups which differ across papers,
leading to inconsistent conclusions about which transferability metrics work
best. In this paper we conduct a large-scale study by systematically
constructing a broad range of 715k experimental setup variations. We discover
that even small variations to an experimental setup lead to different
conclusions about the superiority of a transferability metric over another.
Then we propose better evaluations by aggregating across many experiments,
enabling to reach more stable conclusions. As a result, we reveal the
superiority of LogME at selecting good source datasets to transfer from in a
semantic segmentation scenario, NLEEP at selecting good source architectures in
an image classification scenario, and GBC at determining which target task
benefits most from a given source model. Yet, no single transferability metric
works best in all scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors. (arXiv:2204.03039v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03039">
<div class="article-summary-box-inner">
<span><p>Camera-based 3D object detectors are welcome due to their wider deployment
and lower price than LiDAR sensors. We revisit the prior stereo modeling DSGN
about the stereo volume constructions for representing both 3D geometry and
semantics. We polish the stereo modeling and propose our approach, DSGN++,
aiming for improving information flow throughout the 2D-to-3D pipeline in the
following three main aspects. First, to effectively lift the 2D information to
stereo volume, we propose depth-wise plane sweeping (DPS) that allows denser
connections and extracts depth-guided features. Second, for better grasping
differently spaced features, we present a novel stereo volume -- Dual-view
Stereo Volume (DSV) that integrates front-view and top-view features and
reconstructs sub-voxel depth in the camera frustum. Third, as the foreground
region becomes less dominant in 3D space, we firstly propose a multi-modal data
editing strategy -- Stereo-LiDAR Copy-Paste, which ensures cross-modal
alignment and improves data efficiency. Without bells and whistles, extensive
experiments in various modality setups on the popular KITTI benchmark show that
our method consistently outperforms other camera-based 3D detectors for all
categories. Code will be released at https://github.com/chenyilun95/DSGN2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental Prototype Prompt-tuning with Pre-trained Representation for Class Incremental Learning. (arXiv:2204.03410v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03410">
<div class="article-summary-box-inner">
<span><p>Class incremental learning has attracted much attention, but most existing
works still continually fine-tune the representation model, resulting in much
catastrophic forgetting. Instead of struggling to fight against such forgetting
by replaying or distillation like most of the existing methods, we take the
pre-train-and-prompt-tuning paradigm to sequentially learn new visual concepts
based on a fixed semantic rich pre-trained representation model by incremental
prototype prompt-tuning (IPP), which substantially reduces the catastrophic
forgetting. In addition, an example prototype classification is proposed to
compensate for semantic drift, the problem caused by learning bias at different
phases. Extensive experiments conducted on the three incremental learning
benchmarks demonstrate that our method consistently outperforms other
state-of-the-art methods with a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Effects of Regularization and Data Augmentation are Class Dependent. (arXiv:2204.03632v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03632">
<div class="article-summary-box-inner">
<span><p>Regularization is a fundamental technique to prevent over-fitting and to
improve generalization performances by constraining a model's complexity.
Current Deep Networks heavily rely on regularizers such as Data-Augmentation
(DA) or weight-decay, and employ structural risk minimization, i.e.
cross-validation, to select the optimal regularization hyper-parameters. In
this study, we demonstrate that techniques such as DA or weight decay produce a
model with a reduced complexity that is unfair across classes. The optimal
amount of DA or weight decay found from cross-validation leads to disastrous
model performances on some classes e.g. on Imagenet with a resnet50, the "barn
spider" classification test accuracy falls from $68\%$ to $46\%$ only by
introducing random crop DA during training. Even more surprising, such
performance drop also appears when introducing uninformative regularization
techniques such as weight decay. Those results demonstrate that our search for
ever increasing generalization performance -- averaged over all classes and
samples -- has left us with models and regularizers that silently sacrifice
performances on some classes. This scenario can become dangerous when deploying
a model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on
INaturalist sees its performances fall from $70\%$ to $30\%$ on class \#8889
when introducing random crop DA during the Imagenet pre-training phase. Those
results demonstrate that designing novel regularizers without class-dependent
bias remains an open research question.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DAD-3DHeads: A Large-scale Dense, Accurate and Diverse Dataset for 3D Head Alignment from a Single Image. (arXiv:2204.03688v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03688">
<div class="article-summary-box-inner">
<span><p>We present DAD-3DHeads, a dense and diverse large-scale dataset, and a robust
model for 3D Dense Head Alignment in the wild. It contains annotations of over
3.5K landmarks that accurately represent 3D head shape compared to the
ground-truth scans. The data-driven model, DAD-3DNet, trained on our dataset,
learns shape, expression, and pose parameters, and performs 3D reconstruction
of a FLAME mesh. The model also incorporates a landmark prediction branch to
take advantage of rich supervision and co-training of multiple related tasks.
Experimentally, DAD-3DNet outperforms or is comparable to the state-of-the-art
models in (i) 3D Head Pose Estimation on AFLW2000-3D and BIWI, (ii) 3D Face
Shape Reconstruction on NoW and Feng, and (iii) 3D Dense Head Alignment and 3D
Landmarks Estimation on DAD-3DHeads dataset. Finally, the diversity of
DAD-3DHeads in camera angles, facial expressions, and occlusions enables a
benchmark to study in-the-wild generalization and robustness to distribution
shifts. The dataset webpage is https://p.farm/research/dad-3dheads.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-04-12 23:08:15.612069244 UTC">2022-04-12 23:08:15 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>