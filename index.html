<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-05-16T01:30:00Z">05-16</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Natural Sentences for Understanding Biases in Language Models. (arXiv:2205.06303v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06303">
<div class="article-summary-box-inner">
<span><p>Evaluation of biases in language models is often limited to synthetically
generated datasets. This dependence traces back to the need for a prompt-style
dataset to trigger specific behaviors of language models. In this paper, we
address this gap by creating a prompt dataset with respect to occupations
collected from real-world natural sentences present in Wikipedia. We aim to
understand the differences between using template-based prompts and natural
sentence prompts when studying gender-occupation biases in language models. We
find bias evaluations are very sensitive to the design choices of template
prompts, and we propose using natural sentence prompts for systematic
evaluations to step away from design choices that could introduce bias in the
observations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Noun2Verb: Probabilistic frame semantics for word class conversion. (arXiv:2205.06321v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06321">
<div class="article-summary-box-inner">
<span><p>Humans can flexibly extend word usages across different grammatical classes,
a phenomenon known as word class conversion. Noun-to-verb conversion, or
denominal verb (e.g., to Google a cheap flight), is one of the most prevalent
forms of word class conversion. However, existing natural language processing
systems are impoverished in interpreting and generating novel denominal verb
usages. Previous work has suggested that novel denominal verb usages are
comprehensible if the listener can compute the intended meaning based on shared
knowledge with the speaker. Here we explore a computational formalism for this
proposal couched in frame semantics. We present a formal framework, Noun2Verb,
that simulates the production and comprehension of novel denominal verb usages
by modeling shared knowledge of speaker and listener in semantic frames. We
evaluate an incremental set of probabilistic models that learn to interpret and
generate novel denominal verb usages via paraphrasing. We show that a model
where the speaker and listener cooperatively learn the joint distribution over
semantic frame elements better explains the empirical denominal verb usages
than state-of-the-art language models, evaluated against data from 1)
contemporary English in both adult and child speech, 2) contemporary Mandarin
Chinese, and 3) the historical development of English. Our work grounds word
class conversion in probabilistic frame semantics and bridges the gap between
natural language processing systems and humans in lexical creativity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Economics of Multilingual Few-shot Learning: Modeling the Cost-Performance Trade-offs of Machine Translated and Manual Data. (arXiv:2205.06350v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06350">
<div class="article-summary-box-inner">
<span><p>Borrowing ideas from {\em Production functions} in micro-economics, in this
paper we introduce a framework to systematically evaluate the performance and
cost trade-offs between machine-translated and manually-created labelled data
for task-specific fine-tuning of massively multilingual language models. We
illustrate the effectiveness of our framework through a case-study on the
TyDIQA-GoldP dataset. One of the interesting conclusions of the study is that
if the cost of machine translation is greater than zero, the optimal
performance at least cost is always achieved with at least some or only
manually-created data. To our knowledge, this is the first attempt towards
extending the concept of production functions to study data collection
strategies for training multilingual models, and can serve as a valuable tool
for other similar cost vs data trade-offs in NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Static Models and Test Sets: Benchmarking the Potential of Pre-trained Models Across Tasks and Languages. (arXiv:2205.06356v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06356">
<div class="article-summary-box-inner">
<span><p>Although recent Massively Multilingual Language Models (MMLMs) like mBERT and
XLMR support around 100 languages, most existing multilingual NLP benchmarks
provide evaluation data in only a handful of these languages with little
linguistic diversity. We argue that this makes the existing practices in
multilingual evaluation unreliable and does not provide a full picture of the
performance of MMLMs across the linguistic landscape. We propose that the
recent work done in Performance Prediction for NLP tasks can serve as a
potential solution in fixing benchmarking in Multilingual NLP by utilizing
features related to data and language typology to estimate the performance of
an MMLM on different languages. We compare performance prediction with
translating test data with a case study on four different multilingual
datasets, and observe that these methods can provide reliable estimates of the
performance that are often on-par with the translation based approaches,
without the need for any additional translation as well as evaluation costs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Design and Implementation of a Quantum Kernel for Natural Language Processing. (arXiv:2205.06409v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06409">
<div class="article-summary-box-inner">
<span><p>Natural language processing (NLP) is the field that attempts to make human
language accessible to computers, and it relies on applying a mathematical
model to express the meaning of symbolic language. One such model, DisCoCat,
defines how to express both the meaning of individual words as well as their
compositional nature. This model can be naturally implemented on quantum
computers, leading to the field quantum NLP (QNLP). Recent experimental work
used quantum machine learning techniques to map from text to class label using
the expectation value of the quantum encoded sentence. Theoretical work has
been done on computing the similarity of sentences but relies on an unrealized
quantum memory store. The main goal of this thesis is to leverage the DisCoCat
model to design a quantum-based kernel function that can be used by a support
vector machine (SVM) for NLP tasks. Two similarity measures were studied: (i)
the transition amplitude approach and (ii) the SWAP test. A simple NLP meaning
classification task from previous work was used to train the word embeddings
and evaluate the performance of both models. The Python module lambeq and its
related software stack was used for implementation. The explicit model from
previous work was used to train word embeddings and achieved a testing accuracy
of $93.09 \pm 0.01$%. It was shown that both the SVM variants achieved a higher
testing accuracy of $95.72 \pm 0.01$% for approach (i) and $97.14 \pm 0.01$%
for (ii). The SWAP test was then simulated under a noise model defined by the
real quantum device, ibmq_guadalupe. The explicit model achieved an accuracy of
$91.94 \pm 0.01$% while the SWAP test SVM achieved 96.7% on the testing
dataset, suggesting that the kernelized classifiers are resilient to noise.
These are encouraging results and motivate further investigations of our
proposed kernelized QNLP paradigm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TIE: Topological Information Enhanced Structural Reading Comprehension on Web Pages. (arXiv:2205.06435v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06435">
<div class="article-summary-box-inner">
<span><p>Recently, the structural reading comprehension (SRC) task on web pages has
attracted increasing research interests. Although previous SRC work has
leveraged extra information such as HTML tags or XPaths, the informative
topology of web pages is not effectively exploited. In this work, we propose a
Topological Information Enhanced model (TIE), which transforms the token-level
task into a tag-level task by introducing a two-stage process (i.e. node
locating and answer refining). Based on that, TIE integrates Graph Attention
Network (GAT) and Pre-trained Language Model (PLM) to leverage the topological
information of both logical structures and spatial structures. Experimental
results demonstrate that our model outperforms strong baselines and achieves
state-of-the-art performances on the web-based SRC benchmark WebSRC at the time
of writing. The code of TIE will be publicly available at
https://github.com/X-LANCE/TIE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Low-Cost, Controllable and Interpretable Task-Oriented Chatbot: With Real-World After-Sale Services as Example. (arXiv:2205.06436v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06436">
<div class="article-summary-box-inner">
<span><p>Though widely used in industry, traditional task-oriented dialogue systems
suffer from three bottlenecks: (i) difficult ontology construction (e.g.,
intents and slots); (ii) poor controllability and interpretability; (iii)
annotation-hungry. In this paper, we propose to represent utterance with a
simpler concept named Dialogue Action, upon which we construct a
tree-structured TaskFlow and further build task-oriented chatbot with TaskFlow
as core component. A framework is presented to automatically construct TaskFlow
from large-scale dialogues and deploy online. Our experiments on real-world
after-sale customer services show TaskFlow can satisfy the major needs, as well
as reduce the developer burden effectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AEON: A Method for Automatic Evaluation of NLP Test Cases. (arXiv:2205.06439v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06439">
<div class="article-summary-box-inner">
<span><p>Due to the labor-intensive nature of manual test oracle construction, various
automated testing techniques have been proposed to enhance the reliability of
Natural Language Processing (NLP) software. In theory, these techniques mutate
an existing test case (e.g., a sentence with its label) and assume the
generated one preserves an equivalent or similar semantic meaning and thus, the
same label. However, in practice, many of the generated test cases fail to
preserve similar semantic meaning and are unnatural (e.g., grammar errors),
which leads to a high false alarm rate and unnatural test cases. Our evaluation
study finds that 44% of the test cases generated by the state-of-the-art (SOTA)
approaches are false alarms. These test cases require extensive manual checking
effort, and instead of improving NLP software, they can even degrade NLP
software when utilized in model training. To address this problem, we propose
AEON for Automatic Evaluation Of NLP test cases. For each generated test case,
it outputs scores based on semantic similarity and language naturalness. We
employ AEON to evaluate test cases generated by four popular testing techniques
on five datasets across three typical NLP tasks. The results show that AEON
aligns the best with human judgment. In particular, AEON achieves the best
average precision in detecting semantic inconsistent test cases, outperforming
the best baseline metric by 10%. In addition, AEON also has the highest average
precision of finding unnatural test cases, surpassing the baselines by more
than 15%. Moreover, model training with test cases prioritized by AEON leads to
models that are more accurate and robust, demonstrating AEON's potential in
improving NLP software.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple and Effective Relation-based Embedding Propagation for Knowledge Representation Learning. (arXiv:2205.06456v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06456">
<div class="article-summary-box-inner">
<span><p>Relational graph neural networks have garnered particular attention to encode
graph context in knowledge graphs (KGs). Although they achieved competitive
performance on small KGs, how to efficiently and effectively utilize graph
context for large KGs remains an open problem. To this end, we propose the
Relation-based Embedding Propagation (REP) method. It is a post-processing
technique to adapt pre-trained KG embeddings with graph context. As relations
in KGs are directional, we model the incoming head context and the outgoing
tail context separately. Accordingly, we design relational context functions
with no external parameters. Besides, we use averaging to aggregate context
information, making REP more computation-efficient. We theoretically prove that
such designs can avoid information distortion during propagation. Extensive
experiments also demonstrate that REP has significant scalability while
improving or maintaining prediction quality. Notably, it averagely brings about
10% relative improvement to triplet-based embedding methods on OGBL-WikiKG2 and
takes 5%-83% time to achieve comparable results as the state-of-the-art GC-OTE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViT5: Pretrained Text-to-Text Transformer for Vietnamese Language Generation. (arXiv:2205.06457v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06457">
<div class="article-summary-box-inner">
<span><p>We present ViT5, a pretrained Transformer-based encoder-decoder model for the
Vietnamese language. With T5-style self-supervised pretraining, ViT5 is trained
on a large corpus of high-quality and diverse Vietnamese texts. We benchmark
ViT5 on two downstream text generation tasks, Abstractive Text Summarization
and Named Entity Recognition. Although Abstractive Text Summarization has been
widely studied for the English language thanks to its rich and large source of
data, there has been minimal research into the same task in Vietnamese, a much
lower resource language. In this work, we perform exhaustive experiments on
both Vietnamese Abstractive Summarization and Named Entity Recognition,
validating the performance of ViT5 against many other pretrained
Transformer-based encoder-decoder models. Our experiments show that ViT5
significantly outperforms existing models and achieves state-of-the-art results
on Vietnamese Text Summarization. On the task of Named Entity Recognition, ViT5
is competitive against previous best results from pretrained encoder-based
Transformer models. Further analysis shows the importance of context length
during the self-supervised pretraining on downstream performance across
different settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Generation of Captions and Subtitles with Dual Decoding. (arXiv:2205.06522v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06522">
<div class="article-summary-box-inner">
<span><p>As the amount of audio-visual content increases, the need to develop
automatic captioning and subtitling solutions to match the expectations of a
growing international audience appears as the only viable way to boost
throughput and lower the related post-production costs. Automatic captioning
and subtitling often need to be tightly intertwined to achieve an appropriate
level of consistency and synchronization with each other and with the video
signal. In this work, we assess a dual decoding scheme to achieve a strong
coupling between these two tasks and show how adequacy and consistency are
increased, with virtually no additional cost in terms of model size and
training complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Productivity Assessment of Neural Code Completion. (arXiv:2205.06537v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06537">
<div class="article-summary-box-inner">
<span><p>Neural code synthesis has reached a point where snippet generation is
accurate enough to be considered for integration into human software
development workflows. Commercial products aim to increase programmers'
productivity, without being able to measure it directly. In this case study, we
asked users of GitHub Copilot about its impact on their productivity, and
sought to find a reflection of their perception in directly measurable user
data. We find that the rate with which shown suggestions are accepted, rather
than more specific metrics regarding the persistence of completions in the code
over time, drives developers' perception of productivity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graph Question Answering Datasets and Their Generalizability: Are They Enough for Future Research?. (arXiv:2205.06573v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06573">
<div class="article-summary-box-inner">
<span><p>Existing approaches on Question Answering over Knowledge Graphs (KGQA) have
weak generalizability. That is often due to the standard i.i.d. assumption on
the underlying dataset. Recently, three levels of generalization for KGQA were
defined, namely i.i.d., compositional, zero-shot. We analyze 25 well-known KGQA
datasets for 5 different Knowledge Graphs (KGs). We show that according to this
definition many existing and online available KGQA datasets are either not
suited to train a generalizable KGQA system or that the datasets are based on
discontinued and out-dated KGs. Generating new datasets is a costly process
and, thus, is not an alternative to smaller research groups and companies. In
this work, we propose a mitigation method for re-splitting available KGQA
datasets to enable their applicability to evaluate generalization, without any
cost and manual effort. We test our hypothesis on three KGQA datasets, i.e.,
LC-QuAD, LC-QuAD 2.0 and QALD-9). Experiments on re-splitted KGQA datasets
demonstrate its effectiveness towards generalizability. The code and a unified
way to access 18 available datasets is online at
https://github.com/semantic-systems/KGQA-datasets as well as
https://github.com/semantic-systems/KGQA-datasets-generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Contextual Representation with Gloss Regularized Pre-training. (arXiv:2205.06603v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06603">
<div class="article-summary-box-inner">
<span><p>Though achieving impressive results on many NLP tasks, the BERT-like masked
language models (MLM) encounter the discrepancy between pre-training and
inference. In light of this gap, we investigate the contextual representation
of pre-training and inference from the perspective of word probability
distribution. We discover that BERT risks neglecting the contextual word
similarity in pre-training. To tackle this issue, we propose an auxiliary gloss
regularizer module to BERT pre-training (GR-BERT), to enhance word semantic
similarity. By predicting masked words and aligning contextual embeddings to
corresponding glosses simultaneously, the word similarity can be explicitly
modeled. We design two architectures for GR-BERT and evaluate our model in
downstream tasks. Experimental results show that the gloss regularizer benefits
BERT in word-level and sentence-level semantic representation. The GR-BERT
achieves new state-of-the-art in lexical substitution task and greatly promotes
BERT sentence representation in both unsupervised and supervised STS tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Text Classification using Supervision Signals from a Language Model. (arXiv:2205.06604v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06604">
<div class="article-summary-box-inner">
<span><p>Solving text classification in a weakly supervised manner is important for
real-world applications where human annotations are scarce. In this paper, we
propose to query a masked language model with cloze style prompts to obtain
supervision signals. We design a prompt which combines the document itself and
"this article is talking about [MASK]." A masked language model can generate
words for the [MASK] token. The generated words which summarize the content of
a document can be utilized as supervision signals. We propose a latent variable
model to learn a word distribution learner which associates generated words to
pre-defined categories and a document classifier simultaneously without using
any annotated data. Evaluation on three datasets, AGNews, 20Newsgroups, and
UCINews, shows that our method can outperform baselines by 2%, 4%, and 3%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Devil is in the Details: On the Pitfalls of Vocabulary Selection in Neural Machine Translation. (arXiv:2205.06618v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06618">
<div class="article-summary-box-inner">
<span><p>Vocabulary selection, or lexical shortlisting, is a well-known technique to
improve latency of Neural Machine Translation models by constraining the set of
allowed output words during inference. The chosen set is typically determined
by separately trained alignment model parameters, independent of the
source-sentence context at inference time. While vocabulary selection appears
competitive with respect to automatic quality metrics in prior work, we show
that it can fail to select the right set of output words, particularly for
semantically non-compositional linguistic phenomena such as idiomatic
expressions, leading to reduced translation quality as perceived by humans.
Trading off latency for quality by increasing the size of the allowed set is
often not an option in real-world scenarios. We propose a model of vocabulary
selection, integrated into the neural translation model, that predicts the set
of allowed output words from contextualized encoder representations. This
restores translation quality of an unconstrained system, as measured by human
evaluations on WMT newstest2020 and idiomatic expressions, at an inference
latency competitive with alignment-based selection using aggressive thresholds,
thereby removing the dependency on separately trained alignment models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing Hate Speech Data along Racial, Gender and Intersectional Axes. (arXiv:2205.06621v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06621">
<div class="article-summary-box-inner">
<span><p>To tackle the rising phenomenon of hate speech, efforts have been made
towards data curation and analysis. When it comes to analysis of bias, previous
work has focused predominantly on race. In our work, we further investigate
bias in hate speech datasets along racial, gender and intersectional axes. We
identify strong bias against African American English (AAE), masculine and
AAE+Masculine tweets, which are annotated as disproportionately more hateful
and offensive than from other demographics. We provide evidence that BERT-based
models propagate this bias and show that balancing the training data for these
protected attributes can lead to fairer models with regards to gender, but not
race.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlling Translation Formality Using Pre-trained Multilingual Language Models. (arXiv:2205.06644v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06644">
<div class="article-summary-box-inner">
<span><p>This paper describes the University of Maryland's submission to the Special
Task on Formality Control for Spoken Language Translation at \iwslt, which
evaluates translation from English into 6 languages with diverse grammatical
formality markers. We investigate to what extent this problem can be addressed
with a \textit{single multilingual model}, simultaneously controlling its
output for target language and formality. Results show that this strategy can
approach the translation quality and formality control achieved by dedicated
translation models. However, the nature of the underlying pre-trained language
model and of the finetuning samples greatly impact results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Modeling of Multi-Domain Multi-Device ASR Systems. (arXiv:2205.06655v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06655">
<div class="article-summary-box-inner">
<span><p>Modern Automatic Speech Recognition (ASR) systems often use a portfolio of
domain-specific models in order to get high accuracy for distinct user
utterance types across different devices. In this paper, we propose an
innovative approach that integrates the different per-domain per-device models
into a unified model, using a combination of domain embedding, domain experts,
mixture of experts and adversarial training. We run careful ablation studies to
show the benefit of each of these innovations in contributing to the accuracy
of the overall unified model. Experiments show that our proposed unified
modeling approach actually outperforms the carefully tuned per-domain models,
giving relative gains of up to 10% over a baseline model with negligible
increase in the number of parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Case for a Legal Compliance API for the Enforcement of the EU's Digital Services Act on Social Media Platforms. (arXiv:2205.06666v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06666">
<div class="article-summary-box-inner">
<span><p>In the course of under a year, the European Commission has launched some of
the most important regulatory proposals to date on platform governance. The
Commission's goals behind cross-sectoral regulation of this sort include the
protection of markets and democracies alike. While all these acts propose
sophisticated rules for setting up new enforcement institutions and procedures,
one aspect remains highly unclear: how digital enforcement will actually take
place in practice. Focusing on the Digital Services Act (DSA), this discussion
paper critically addresses issues around social media data access for the
purpose of digital enforcement and proposes the use of a legal compliance
application programming interface (API) as a means to facilitate compliance
with the DSA and complementary European and national regulation. To
contextualize this discussion, the paper pursues two scenarios that exemplify
the harms arising out of content monetization affecting a particularly
vulnerable category of social media users: children. The two scenarios are used
to further reflect upon essential issues surrounding data access and legal
compliance with the DSA and further applicable legal standards in the field of
labour and consumer law.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LSCDiscovery: A shared task on semantic change discovery and detection in Spanish. (arXiv:2205.06691v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06691">
<div class="article-summary-box-inner">
<span><p>We present the first shared task on semantic change discovery and detection
in Spanish and create the first dataset of Spanish words manually annotated for
semantic change using the DURel framework (Schlechtweg et al., 2018). The task
is divided in two phases: 1) Graded Change Discovery, and 2) Binary Change
Detection. In addition to introducing a new language the main novelty with
respect to the previous tasks consists in predicting and evaluating changes for
all vocabulary words in the corpus. Six teams participated in phase 1 and seven
teams in phase 2 of the shared task, and the best system obtained a Spearman
rank correlation of 0.735 for phase 1 and an F1 score of 0.716 for phase 2. We
describe the systems developed by the competing teams, highlighting the
techniques that were particularly useful and discuss the limits of these
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MuCPAD: A Multi-Domain Chinese Predicate-Argument Dataset. (arXiv:2205.06703v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06703">
<div class="article-summary-box-inner">
<span><p>During the past decade, neural network models have made tremendous progress
on in-domain semantic role labeling (SRL). However, performance drops
dramatically under the out-of-domain setting. In order to facilitate research
on cross-domain SRL, this paper presents MuCPAD, a multi-domain Chinese
predicate-argument dataset, which consists of 30,897 sentences and 92,051
predicates from six different domains. MuCPAD exhibits three important
features. 1) Based on a frame-free annotation methodology, we avoid writing
complex frames for new predicates. 2) We explicitly annotate omitted core
arguments to recover more complete semantic structure, considering that
omission of content words is ubiquitous in multi-domain Chinese texts. 3) We
compile 53 pages of annotation guidelines and adopt strict double annotation
for improving data quality. This paper describes in detail the annotation
methodology and annotation process of MuCPAD, and presents in-depth data
analysis. We also give benchmark results on cross-domain SRL based on MuCPAD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving the Numerical Reasoning Skills of Pretrained Language Models. (arXiv:2205.06733v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06733">
<div class="article-summary-box-inner">
<span><p>State-of-the-art pretrained language models tend to perform below their
capabilities when applied out-of-the-box on tasks that require reasoning over
numbers. Recent work sees two main reasons for this: (1) popular tokenisation
algorithms are optimized for common words, and therefore have limited
expressiveness for numbers, and (2) common pretraining objectives do not target
numerical reasoning or understanding numbers at all. Recent approaches usually
address them separately and mostly by proposing architectural changes or
pretraining models from scratch. In this paper, we propose a new extended
pretraining approach called reasoning-aware pretraining to jointly address both
shortcomings without requiring architectural changes or pretraining from
scratch. Using contrastive learning, our approach incorporates an alternative
number representation into an already pretrained model, while improving its
numerical reasoning skills by training on a novel pretraining objective called
inferable number prediction task. We evaluate our approach on three different
tasks that require numerical reasoning, including (a) reading comprehension in
the DROP dataset, (b) inference-on-tables in the InfoTabs dataset, and (c)
table-to-text generation in WikiBio and SciGen datasets. Our results on DROP
and InfoTabs show that our approach improves the accuracy by 9.6 and 33.9
points on these datasets, respectively. Our human evaluation on SciGen and
WikiBio shows that our approach improves the factual correctness on all
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An empirical study of CTC based models for OCR of Indian languages. (arXiv:2205.06740v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06740">
<div class="article-summary-box-inner">
<span><p>Recognition of text on word or line images, without the need for sub-word
segmentation has become the mainstream of research and development of text
recognition for Indian languages. Modelling unsegmented sequences using
Connectionist Temporal Classification (CTC) is the most commonly used approach
for segmentation-free OCR. In this work we present a comprehensive empirical
study of various neural network models that uses CTC for transcribing step-wise
predictions in the neural network output to a Unicode sequence. The study is
conducted for 13 Indian languages, using an internal dataset that has around
1000 pages per language. We study the choice of line vs word as the recognition
unit, and use of synthetic data to train the models. We compare our models with
popular publicly available OCR tools for end-to-end document image recognition.
Our end-to-end pipeline that employ our recognition models and existing text
segmentation tools outperform these public OCR tools for 8 out of the 13
languages. We also introduce a new public dataset called Mozhi for word and
line recognition in Indian language. The dataset contains more than 1.2 million
annotated word images (120 thousand text lines) across 13 Indian languages. Our
code, trained models and the Mozhi dataset will be made available at
<a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Who Are We Talking About? Handling Person Names in Speech Translation. (arXiv:2205.06755v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06755">
<div class="article-summary-box-inner">
<span><p>Recent work has shown that systems for speech translation (ST) -- similarly
to automatic speech recognition (ASR) -- poorly handle person names. This
shortcoming does not only lead to errors that can seriously distort the meaning
of the input, but also hinders the adoption of such systems in application
scenarios (like computer-assisted interpreting) where the translation of named
entities, like person names, is crucial. In this paper, we first analyse the
outputs of ASR/ST systems to identify the reasons of failures in person name
transcription/translation. Besides the frequency in the training data, we
pinpoint the nationality of the referred person as a key factor. We then
mitigate the problem by creating multilingual models, and further improve our
ST systems by forcing them to jointly generate transcripts and translations,
prioritising the former over the latter. Overall, our solutions result in a
relative improvement in token-level person name accuracy by 47.8% on average
for three language pairs (en-&gt;es,fr,it).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interlock-Free Multi-Aspect Rationalization for Text Classification. (arXiv:2205.06756v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06756">
<div class="article-summary-box-inner">
<span><p>Explanation is important for text classification tasks. One prevalent type of
explanation is rationales, which are text snippets of input text that suffice
to yield the prediction and are meaningful to humans. A lot of research on
rationalization has been based on the selective rationalization framework,
which has recently been shown to be problematic due to the interlocking
dynamics. In this paper, we show that we address the interlocking problem in
the multi-aspect setting, where we aim to generate multiple rationales for
multiple outputs. More specifically, we propose a multi-stage training method
incorporating an additional self-supervised contrastive loss that helps to
generate more semantically diverse rationales. Empirical results on the beer
review dataset show that our method improves significantly the rationalization
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Twitter-Based Gender Recognition Using Transformers. (arXiv:2205.06801v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06801">
<div class="article-summary-box-inner">
<span><p>Social media contains useful information about people and the society that
could help advance research in many different areas (e.g. by applying opinion
mining, emotion/sentiment analysis, and statistical analysis) such as business
and finance, health, socio-economic inequality and gender vulnerability. User
demographics provide rich information that could help study the subject
further. However, user demographics such as gender are considered private and
are not freely available. In this study, we propose a model based on
transformers to predict the user's gender from their images and tweets. We
fine-tune a model based on Vision Transformers (ViT) to stratify female and
male images. Next, we fine-tune another model based on Bidirectional Encoders
Representations from Transformers (BERT) to recognize the user's gender by
their tweets. This is highly beneficial, because not all users provide an image
that indicates their gender. The gender of such users could be detected form
their tweets. The combination model improves the accuracy of image and text
classification models by 6.98% and 4.43%, respectively. This shows that the
image and text classification models are capable of complementing each other by
providing additional information to one another. We apply our method to the
PAN-2018 dataset, and obtain an accuracy of 85.52%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Word Embeddings and Validity Indexes in Fuzzy Clustering. (arXiv:2205.06802v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06802">
<div class="article-summary-box-inner">
<span><p>In the new era of internet systems and applications, a concept of detecting
distinguished topics from huge amounts of text has gained a lot of attention.
These methods use representation of text in a numerical format -- called
embeddings -- to imitate human-based semantic similarity between words. In this
study, we perform a fuzzy-based analysis of various vector representations of
words, i.e., word embeddings. Also we introduce new methods of fuzzy clustering
based on hybrid implementation of fuzzy clustering methods with an evolutionary
algorithm named Forest Optimization. We use two popular fuzzy clustering
algorithms on count-based word embeddings, with different methods and
dimensionality. Words about covid from Kaggle dataset gathered and calculated
into vectors and clustered. The results indicate that fuzzy clustering
algorithms are very sensitive to high-dimensional data, and parameter tuning
can dramatically change their performance. We evaluate results of experiments
with various clustering validity indexes to compare different algorithm
variation with different embeddings accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PaCo: Preconditions Attributed to Commonsense Knowledge. (arXiv:2104.08712v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08712">
<div class="article-summary-box-inner">
<span><p>Humans can seamlessly reason with circumstantial preconditions of commonsense
knowledge. We understand that a glass is used for drinking water, unless the
glass is broken or the water is toxic. Despite state-of-the-art (SOTA) language
models' (LMs) impressive performance on inferring commonsense knowledge, it is
unclear whether they understand the circumstantial preconditions. To address
this gap, we propose a novel challenge of reasoning with circumstantial
preconditions. We collect a dataset, called PaCo, consisting of 12.4 thousand
preconditions of commonsense statements expressed in natural language. Based on
this dataset, we create three canonical evaluation tasks and use them to
examine the capability of existing LMs to understand situational preconditions.
Our results reveal a 10-30% gap between machine and human performance on our
tasks, which shows that reasoning with preconditions is an open challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-train or Annotate? Domain Adaptation with a Constrained Budget. (arXiv:2109.04711v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04711">
<div class="article-summary-box-inner">
<span><p>Recent work has demonstrated that pre-training in-domain language models can
boost performance when adapting to a new domain. However, the costs associated
with pre-training raise an important question: given a fixed budget, what steps
should an NLP practitioner take to maximize performance? In this paper, we view
domain adaptation with a constrained budget as a consumer choice problem, where
the goal is to select an optimal combination of data annotation and
pre-training. We measure annotation costs of three procedural text datasets,
along with the pre-training costs of several in-domain language models. The
utility of different combinations of pre-training and data annotation are
evaluated under varying budget constraints to assess which combination strategy
works best. We find that for small budgets, spending all funds on annotation
leads to the best performance; once the budget becomes large enough, however, a
combination of data annotation and in-domain pre-training yields better
performance. Our experiments suggest task-specific data annotation should be
part of an economical strategy when adapting an NLP model to a new domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PoKE: A Prompt-based Knowledge Eliciting Approach for Event Argument Extraction. (arXiv:2109.05190v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05190">
<div class="article-summary-box-inner">
<span><p>Eliciting knowledge from pre-trained language models via prompt-based
learning has shown great potential in many natural language processing tasks.
Whereas, the applications for more complex tasks such as event extraction are
less studied since the design of prompt is not straightforward for the
structured event containing various triggers and arguments. % Meanwhile,
current conditional generation methods employ large encoder-decoder models,
which are costly to train and serve. In this paper, we present a novel
prompt-based approach, which elicits both the independent and joint knowledge
about different events for event argument extraction. The experimental results
on the benchmark ACE2005 dataset show the great advantages of our proposed
approach. In particular, our approach is superior to the recent advanced
methods in both fully-supervised and low-resource scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lifelong Pretraining: Continually Adapting Language Models to Emerging Corpora. (arXiv:2110.08534v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08534">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (PTLMs) are typically learned over a large, static
corpus and further fine-tuned for various downstream tasks. However, when
deployed in the real world, a PTLM-based model must deal with data
distributions that deviate from what the PTLM was initially trained on. In this
paper, we study a lifelong language model pretraining challenge where a PTLM is
continually updated so as to adapt to emerging data. Over a domain-incremental
research paper stream and a chronologically-ordered tweet stream, we
incrementally pretrain a PTLM with different continual learning algorithms, and
keep track of the downstream task performance (after fine-tuning). We evaluate
PTLM's ability to adapt to new corpora while retaining learned knowledge in
earlier corpora. Our experiments show distillation-based approaches to be most
effective in retaining downstream performance in earlier domains. The
algorithms also improve knowledge transfer, allowing models to achieve better
downstream performance over the latest data, and improve temporal
generalization when distribution gaps exist between training and evaluation
because of time. We believe our problem formulation, methods, and analysis will
inspire future studies towards continual pretraining of language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reinforced Abstractive Summarization with Adaptive Length Controlling. (arXiv:2112.07534v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07534">
<div class="article-summary-box-inner">
<span><p>Document summarization, as a fundamental task in natural language generation,
aims to generate a short and coherent summary for a given document.
Controllable summarization, especially of the length, is an important issue for
some practical applications, especially how to trade-off the length constraint
and information integrity. In this paper, we propose an \textbf{A}daptive
\textbf{L}ength \textbf{C}ontrolling \textbf{O}ptimization (\textbf{ALCO})
method to leverage two-stage abstractive summarization model via reinforcement
learning. ALCO incorporates length constraint into the stage of sentence
extraction to penalize the overlength extracted sentences. Meanwhile, a
saliency estimation mechanism is designed to preserve the salient information
in the generated sentences. A series of experiments have been conducted on a
wildly-used benchmark dataset \textit{CNN/Daily Mail}. The results have shown
that ALCO performs better than the popular baselines in terms of length
controllability and content preservation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02639">
<div class="article-summary-box-inner">
<span><p>As humans, we navigate a multimodal world, building a holistic understanding
from all our senses. We introduce MERLOT Reserve, a model that represents
videos jointly over time -- through a new training objective that learns from
audio, subtitles, and video frames. Given a video, we replace snippets of text
and audio with a MASK token; the model learns by choosing the correct
masked-out snippet. Our objective learns faster than alternatives, and performs
well at scale: we pretrain on 20 million YouTube videos.
</p>
<p>Empirical results show that MERLOT Reserve learns strong multimodal
representations. When finetuned, it sets state-of-the-art on Visual Commonsense
Reasoning (VCR), TVQA, and Kinetics-600; outperforming prior work by 5%, 7%,
and 1.5% respectively. Ablations show that these tasks benefit from audio
pretraining -- even VCR, a QA task centered around images (without sound).
Moreover, our objective enables out-of-the-box prediction, revealing strong
multimodal commonsense understanding. In a fully zero-shot setting, our model
obtains competitive results on four video tasks, even outperforming supervised
approaches on the recently proposed Situated Reasoning (STAR) benchmark.
</p>
<p>We analyze why audio enables better vision-language representations,
suggesting significant opportunities for future research. We conclude by
discussing ethical and societal implications of multimodal pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion Intensity and its Control for Emotional Voice Conversion. (arXiv:2201.03967v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03967">
<div class="article-summary-box-inner">
<span><p>Emotional voice conversion (EVC) seeks to convert the emotional state of an
utterance while preserving the linguistic content and speaker identity. In EVC,
emotions are usually treated as discrete categories overlooking the fact that
speech also conveys emotions with various intensity levels that the listener
can perceive. In this paper, we aim to explicitly characterize and control the
intensity of emotion. We propose to disentangle the speaker style from
linguistic content and encode the speaker style into a style embedding in a
continuous space that forms the prototype of emotion embedding. We further
learn the actual emotion encoder from an emotion-labelled database and study
the use of relative attributes to represent fine-grained emotion intensity. To
ensure emotional intelligibility, we incorporate emotion classification loss
and emotion embedding similarity loss into the training of the EVC network. As
desired, the proposed network controls the fine-grained emotion intensity in
the output speech. Through both objective and subjective evaluations, we
validate the effectiveness of the proposed network for emotional expressiveness
and emotion intensity control.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Should we tweet this? Generative response modeling for predicting reception of public health messaging on Twitter. (arXiv:2204.04353v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04353">
<div class="article-summary-box-inner">
<span><p>The way people respond to messaging from public health organizations on
social media can provide insight into public perceptions on critical health
issues, especially during a global crisis such as COVID-19. It could be
valuable for high-impact organizations such as the US Centers for Disease
Control and Prevention (CDC) or the World Health Organization (WHO) to
understand how these perceptions impact reception of messaging on health policy
recommendations. We collect two datasets of public health messages and their
responses from Twitter relating to COVID-19 and Vaccines, and introduce a
predictive method which can be used to explore the potential reception of such
messages. Specifically, we harness a generative model (GPT-2) to directly
predict probable future responses and demonstrate how it can be used to
optimize expected reception of important health guidance. Finally, we introduce
a novel evaluation scheme with extensive statistical testing which allows us to
conclude that our models capture the semantics and sentiment found in actual
public health responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Retrieve Videos by Asking Questions. (arXiv:2205.05739v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05739">
<div class="article-summary-box-inner">
<span><p>The majority of traditional text-to-video retrieval systems operate in static
environments, i.e., there is no interaction between the user and the agent
beyond the initial textual query provided by the user. This can be suboptimal
if the initial query has ambiguities, which would lead to many falsely
retrieved videos. To overcome this limitation, we propose a novel framework for
Video Retrieval using Dialog (ViReD), which enables the user to interact with
an AI agent via multiple rounds of dialog. The key contribution of our
framework is a novel multimodal question generator that learns to ask questions
that maximize the subsequent video retrieval performance. Our multimodal
question generator uses (i) the video candidates retrieved during the last
round of interaction with the user and (ii) the text-based dialog history
documenting all previous interactions, to generate questions that incorporate
both visual and linguistic cues relevant to video retrieval. Furthermore, to
generate maximally informative questions, we propose an Information-Guided
Supervision (IGS), which guides the question generator to ask questions that
would boost subsequent video retrieval accuracy. We validate the effectiveness
of our interactive ViReD framework on the AVSD dataset, showing that our
interactive method performs significantly better than traditional
non-interactive video retrieval systems. Furthermore, we also demonstrate that
our proposed approach also generalizes to the real-world settings that involve
interactions with real humans, thus, demonstrating the robustness and
generality of our framework
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Re-thinking Knowledge Graph Completion Evaluation from an Information Retrieval Perspective. (arXiv:2205.04105v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.04105">
<div class="article-summary-box-inner">
<span><p>Knowledge graph completion (KGC) aims to infer missing knowledge triples
based on known facts in a knowledge graph. Current KGC research mostly follows
an entity ranking protocol, wherein the effectiveness is measured by the
predicted rank of a masked entity in a test triple. The overall performance is
then given by a micro(-average) metric over all individual answer entities. Due
to the incomplete nature of the large-scale knowledge bases, such an entity
ranking setting is likely affected by unlabelled top-ranked positive examples,
raising questions on whether the current evaluation protocol is sufficient to
guarantee a fair comparison of KGC systems. To this end, this paper presents a
systematic study on whether and how the label sparsity affects the current KGC
evaluation with the popular micro metrics. Specifically, inspired by the TREC
paradigm for large-scale information retrieval (IR) experimentation, we create
a relatively "complete" judgment set based on a sample from the popular
FB15k-237 dataset following the TREC pooling method. According to our analysis,
it comes as a surprise that switching from the original labels to our
"complete" labels results in a drastic change of system ranking of a variety of
13 popular KGC models in terms of micro metrics. Further investigation
indicates that the IR-like macro(-average) metrics are more stable and
discriminative under different settings, meanwhile, less affected by label
sparsity. Thus, for KGC evaluation, we recommend conducting TREC-style pooling
to balance between human efforts and label completeness, and reporting also the
IR-like macro metrics to reflect the ranking nature of the KGC task.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Overparameterization Improves StyleGAN Inversion. (arXiv:2205.06304v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06304">
<div class="article-summary-box-inner">
<span><p>Deep generative models like StyleGAN hold the promise of semantic image
editing: modifying images by their content, rather than their pixel values.
Unfortunately, working with arbitrary images requires inverting the StyleGAN
generator, which has remained challenging so far. Existing inversion approaches
obtain promising yet imperfect results, having to trade-off between
reconstruction quality and downstream editability. To improve quality, these
approaches must resort to various techniques that extend the model latent space
after training. Taking a step back, we observe that these methods essentially
all propose, in one way or another, to increase the number of free parameters.
This suggests that inversion might be difficult because it is underconstrained.
In this work, we address this directly and dramatically overparameterize the
latent space, before training, with simple changes to the original StyleGAN
architecture. Our overparameterization increases the available degrees of
freedom, which in turn facilitates inversion. We show that this allows us to
obtain near-perfect image reconstruction without the need for encoders nor for
altering the latent space after training. Our approach also retains
editability, which we demonstrate by realistically interpolating between
images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-time Virtual-Try-On from a Single Example Image through Deep Inverse Graphics and Learned Differentiable Renderers. (arXiv:2205.06305v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06305">
<div class="article-summary-box-inner">
<span><p>Augmented reality applications have rapidly spread across online platforms,
allowing consumers to virtually try-on a variety of products, such as makeup,
hair dying, or shoes. However, parametrizing a renderer to synthesize realistic
images of a given product remains a challenging task that requires expert
knowledge. While recent work has introduced neural rendering methods for
virtual try-on from example images, current approaches are based on large
generative models that cannot be used in real-time on mobile devices. This
calls for a hybrid method that combines the advantages of computer graphics and
neural rendering approaches. In this paper we propose a novel framework based
on deep learning to build a real-time inverse graphics encoder that learns to
map a single example image into the parameter space of a given augmented
reality rendering engine. Our method leverages self-supervised learning and
does not require labeled training data which makes it extendable to many
virtual try-on applications. Furthermore, most augmented reality renderers are
not differentiable in practice due to algorithmic choices or implementation
constraints to reach real-time on portable devices. To relax the need for a
graphics-based differentiable renderer in inverse graphics problems, we
introduce a trainable imitator module. Our imitator is a generative network
that learns to accurately reproduce the behavior of a given non-differentiable
renderer. We propose a novel rendering sensitivity loss to train the imitator,
which ensures that the network learns an accurate and continuous representation
for each rendering parameter. Our framework enables novel applications where
consumers can virtually try-on a novel unknown product from an inspirational
reference image on social media. It can also be used by graphics artists to
automatically create realistic rendering from a reference product image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visuomotor Control in Multi-Object Scenes Using Object-Aware Representations. (arXiv:2205.06333v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06333">
<div class="article-summary-box-inner">
<span><p>Perceptual understanding of the scene and the relationship between its
different components is important for successful completion of robotic tasks.
Representation learning has been shown to be a powerful technique for this, but
most of the current methodologies learn task specific representations that do
not necessarily transfer well to other tasks. Furthermore, representations
learned by supervised methods require large labeled datasets for each task that
are expensive to collect in the real world. Using self-supervised learning to
obtain representations from unlabeled data can mitigate this problem. However,
current self-supervised representation learning methods are mostly object
agnostic, and we demonstrate that the resulting representations are
insufficient for general purpose robotics tasks as they fail to capture the
complexity of scenes with many components. In this paper, we explore the
effectiveness of using object-aware representation learning techniques for
robotic tasks. Our self-supervised representations are learned by observing the
agent freely interacting with different parts of the environment and is queried
in two different settings: (i) policy learning and (ii) object location
prediction. We show that our model learns control policies in a
sample-efficient manner and outperforms state-of-the-art object agnostic
techniques as well as methods trained on raw RGB images. Our results show a 20
percent increase in performance in low data regimes (1000 trajectories) in
policy training using implicit behavioral cloning (IBC). Furthermore, our
method outperforms the baselines for the task of object localization in
multi-object scenes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LANTERN-RD: Enabling Deep Learning for Mitigation of the Invasive Spotted Lanternfly. (arXiv:2205.06397v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06397">
<div class="article-summary-box-inner">
<span><p>The Spotted Lanternfly (SLF) is an invasive planthopper that threatens the
local biodiversity and agricultural economy of regions such as the Northeastern
United States and Japan. As researchers scramble to study the insect, there is
a great potential for computer vision tasks such as detection, pose estimation,
and accurate identification to have important downstream implications in
containing the SLF. However, there is currently no publicly available dataset
for training such AI models. To enable computer vision applications and
motivate advancements to challenge the invasive SLF problem, we propose
LANTERN-RD, the first curated image dataset of the spotted lanternfly and its
look-alikes, featuring images with varied lighting conditions, diverse
backgrounds, and subjects in assorted poses. A VGG16-based baseline CNN
validates the potential of this dataset for stimulating fresh computer vision
applications to accelerate invasive SLF research. Additionally, we implement
the trained model in a simple mobile classification application in order to
directly empower responsible public mitigation efforts. The overarching mission
of this work is to introduce a novel SLF image dataset and release a
classification framework that enables computer vision applications, boosting
studies surrounding the invasive SLF and assisting in minimizing its
agricultural and economic damage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning. (arXiv:2205.06401v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06401">
<div class="article-summary-box-inner">
<span><p>Contrastive learning pre-trains an image encoder using a large amount of
unlabeled data such that the image encoder can be used as a general-purpose
feature extractor for various downstream tasks. In this work, we propose
PoisonedEncoder, a data poisoning attack to contrastive learning. In
particular, an attacker injects carefully crafted poisoning inputs into the
unlabeled pre-training data, such that the downstream classifiers built based
on the poisoned encoder for multiple target downstream tasks simultaneously
classify attacker-chosen, arbitrary clean inputs as attacker-chosen, arbitrary
classes. We formulate our data poisoning attack as a bilevel optimization
problem, whose solution is the set of poisoning inputs; and we propose a
contrastive-learning-tailored method to approximately solve it. Our evaluation
on multiple datasets shows that PoisonedEncoder achieves high attack success
rates while maintaining the testing accuracy of the downstream classifiers
built upon the poisoned encoder for non-attacker-chosen inputs. We also
evaluate five defenses against PoisonedEncoder, including one pre-processing,
three in-processing, and one post-processing defenses. Our results show that
these defenses can decrease the attack success rate of PoisonedEncoder, but
they also sacrifice the utility of the encoder or require a large clean
pre-training dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tensor Decompositions for Hyperspectral Data Processing in Remote Sensing: A Comprehensive Review. (arXiv:2205.06407v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06407">
<div class="article-summary-box-inner">
<span><p>Owing to the rapid development of sensor technology, hyperspectral (HS)
remote sensing (RS) imaging has provided a significant amount of spatial and
spectral information for the observation and analysis of the Earth's surface at
a distance of data acquisition devices, such as aircraft, spacecraft, and
satellite. The recent advancement and even revolution of the HS RS technique
offer opportunities to realize the full potential of various applications,
while confronting new challenges for efficiently processing and analyzing the
enormous HS acquisition data. Due to the maintenance of the 3-D HS inherent
structure, tensor decomposition has aroused widespread concern and research in
HS data processing tasks over the past decades. In this article, we aim at
presenting a comprehensive overview of tensor decomposition, specifically
contextualizing the five broad topics in HS data processing, and they are HS
restoration, compressed sensing, anomaly detection, super-resolution, and
spectral unmixing. For each topic, we elaborate on the remarkable achievements
of tensor decomposition models for HS RS with a pivotal description of the
existing methodologies and a representative exhibition on the experimental
results. As a result, the remaining challenges of the follow-up research
directions are outlined and discussed from the perspective of the real HS RS
practices and tensor decomposition merged with advanced priors and even with
deep neural networks. This article summarizes different tensor
decomposition-based HS data processing methods and categorizes them into
different classes from simple adoptions to complex combinations with other
priors for the algorithm beginners. We also expect this survey can provide new
investigations and development trends for the experienced researchers who
understand tensor decomposition and HS RS to some extent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video-based assessment of intraoperative surgical skill. (arXiv:2205.06416v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06416">
<div class="article-summary-box-inner">
<span><p>Purpose: The objective of this investigation is to provide a comprehensive
analysis of state-of-the-art methods for video-based assessment of surgical
skill in the operating room. Methods: Using a data set of 99 videos of
capsulorhexis, a critical step in cataract surgery, we evaluate feature based
methods previously developed for surgical skill assessment mostly under
benchtop settings. In addition, we present and validate two deep learning
methods that directly assess skill using RGB videos. In the first method, we
predict instrument tips as keypoints, and learn surgical skill using temporal
convolutional neural networks. In the second method, we propose a novel
architecture for surgical skill assessment that includes a frame-wise encoder
(2D convolutional neural network) followed by a temporal model (recurrent
neural network), both of which are augmented by visual attention mechanisms. We
report the area under the receiver operating characteristic curve, sensitivity,
specificity, and predictive values with each method through 5-fold
cross-validation. Results: For the task of binary skill classification (expert
vs. novice), deep neural network based methods exhibit higher AUC than the
classical spatiotemporal interest point based methods. The neural network
approach using attention mechanisms also showed high sensitivity and
specificity. Conclusion: Deep learning methods are necessary for video-based
assessment of surgical skill in the operating room. Our findings of internal
validity of a network using attention mechanisms to assess skill directly using
RGB videos should be evaluated for external validity in other data sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Talking Face Generation with Multilingual TTS. (arXiv:2205.06421v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06421">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a joint system combining a talking face generation
system with a text-to-speech system that can generate multilingual talking face
videos from only the text input. Our system can synthesize natural multilingual
speeches while maintaining the vocal identity of the speaker, as well as lip
movements synchronized to the synthesized speech. We demonstrate the
generalization capabilities of our system by selecting four languages (Korean,
English, Japanese, and Chinese) each from a different language family. We also
compare the outputs of our talking face generation model to outputs of a prior
work that claims multilingual support. For our demo, we add a translation API
to the preprocessing stage and present it in the form of a neural dubber so
that users can utilize the multilingual property of our system more easily.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Test-time Fourier Style Calibration for Domain Generalization. (arXiv:2205.06427v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06427">
<div class="article-summary-box-inner">
<span><p>The topic of generalizing machine learning models learned on a collection of
source domains to unknown target domains is challenging. While many domain
generalization (DG) methods have achieved promising results, they primarily
rely on the source domains at train-time without manipulating the target
domains at test-time. Thus, it is still possible that those methods can overfit
to source domains and perform poorly on target domains. Driven by the
observation that domains are strongly related to styles, we argue that reducing
the gap between source and target styles can boost models' generalizability. To
solve the dilemma of having no access to the target domain during training, we
introduce Test-time Fourier Style Calibration (TF-Cal) for calibrating the
target domain style on the fly during testing. To access styles, we utilize
Fourier transformation to decompose features into amplitude (style) features
and phase (semantic) features. Furthermore, we present an effective technique
to Augment Amplitude Features (AAF) to complement TF-Cal. Extensive experiments
on several popular DG benchmarks and a segmentation dataset for medical images
demonstrate that our method outperforms state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FRIH: Fine-grained Region-aware Image Harmonization. (arXiv:2205.06448v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06448">
<div class="article-summary-box-inner">
<span><p>Image harmonization aims to generate a more realistic appearance of
foreground and background for a composite image. Existing methods perform the
same harmonization process for the whole foreground. However, the implanted
foreground always contains different appearance patterns. All the existing
solutions ignore the difference of each color block and losing some specific
details. Therefore, we propose a novel global-local two stages framework for
Fine-grained Region-aware Image Harmonization (FRIH), which is trained
end-to-end. In the first stage, the whole input foreground mask is used to make
a global coarse-grained harmonization. In the second stage, we adaptively
cluster the input foreground mask into several submasks by the corresponding
pixel RGB values in the composite image. Each submask and the coarsely adjusted
image are concatenated respectively and fed into a lightweight cascaded module,
adjusting the global harmonization performance according to the region-aware
local feature. Moreover, we further designed a fusion prediction module by
fusing features from all the cascaded decoder layers together to generate the
final result, which could utilize the different degrees of harmonization
results comprehensively. Without bells and whistles, our FRIH algorithm
achieves the best performance on iHarmony4 dataset (PSNR is 38.19 dB) with a
lightweight model. The parameters for our model are only 11.98 M, far below the
existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A microstructure estimation Transformer inspired by sparse representation for diffusion MRI. (arXiv:2205.06450v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06450">
<div class="article-summary-box-inner">
<span><p>Diffusion magnetic resonance imaging (dMRI) is an important tool in
characterizing tissue microstructure based on biophysical models, which are
complex and highly non-linear. Resolving microstructures with optimization
techniques is prone to estimation errors and requires dense sampling in the
q-space. Deep learning based approaches have been proposed to overcome these
limitations. Motivated by the superior performance of the Transformer, in this
work, we present a learning-based framework based on Transformer, namely, a
Microstructure Estimation Transformer with Sparse Coding (METSC) for dMRI-based
microstructure estimation with downsampled q-space data. To take advantage of
the Transformer while addressing its limitation in large training data
requirements, we explicitly introduce an inductive bias - model bias into the
Transformer using a sparse coding technique to facilitate the training process.
Thus, the METSC is composed with three stages, an embedding stage, a sparse
representation stage, and a mapping stage. The embedding stage is a
Transformer-based structure that encodes the signal to ensure the voxel is
represented effectively. In the sparse representation stage, a dictionary is
constructed by solving a sparse reconstruction problem that unfolds the
Iterative Hard Thresholding (IHT) process. The mapping stage is essentially a
decoder that computes the microstructural parameters from the output of the
second stage, based on the weighted sum of normalized dictionary coefficients
where the weights are also learned. We tested our framework on two dMRI models
with downsampled q-space data, including the intravoxel incoherent motion
(IVIM) model and the neurite orientation dispersion and density imaging (NODDI)
model. The proposed method achieved up to 11.25 folds of acceleration in scan
time and outperformed the other state-of-the-art learning-based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Monocular Human Digitization via Implicit Re-projection Networks. (arXiv:2205.06468v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06468">
<div class="article-summary-box-inner">
<span><p>We present an approach to generating 3D human models from images. The key to
our framework is that we predict double-sided orthographic depth maps and color
images from a single perspective projected image. Our framework consists of
three networks. The first network predicts normal maps to recover geometric
details such as wrinkles in the clothes and facial regions. The second network
predicts shade-removed images for the front and back views by utilizing the
predicted normal maps. The last multi-headed network takes both normal maps and
shade-free images and predicts depth maps while selectively fusing photometric
and geometric information through multi-headed attention gates. Experimental
results demonstrate that our method shows visually plausible results and
competitive performance in terms of various evaluation metrics over
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Left Atrial Appendage Segmentation and Analysis in 3D and 4D Medical Images. (arXiv:2205.06486v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06486">
<div class="article-summary-box-inner">
<span><p>Atrial fibrillation (AF) is a cardiovascular disease identified as one of the
main risk factors for stroke. The majority of strokes due to AF are caused by
clots originating in the left atrial appendage (LAA). LAA occlusion is an
effective procedure for reducing stroke risk. Planning the procedure using
pre-procedural imaging and analysis has shown benefits. The analysis is
commonly done by manually segmenting the appendage on 2D slices. Automatic LAA
segmentation methods could save an expert's time and provide insightful 3D
visualizations and accurate automatic measurements to aid in medical
procedures. Several semi- and fully-automatic methods for segmenting the
appendage have been proposed. This paper provides a review of automatic LAA
segmentation methods on 3D and 4D medical images, including CT, MRI, and
echocardiogram images. We classify methods into heuristic and model-based
methods, as well as into semi- and fully-automatic methods. We summarize and
compare the proposed methods, evaluate their effectiveness, and present current
challenges in the field and approaches to overcome them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RTMaps-based Local Dynamic Map for multi-ADAS data fusion. (arXiv:2205.06497v1 [cs.DB])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06497">
<div class="article-summary-box-inner">
<span><p>Work on Local Dynamic Maps (LDM) implementation is still in its early stages,
as the LDM standards only define how information shall be structured in
databases, while the mechanism to fuse or link information across different
layers is left undefined. A working LDM component, as a real-time database
inside the vehicle is an attractive solution to multi-ADAS systems, which may
feed a real-time LDM database that serves as a central point of information
inside the vehicle, exposing fused and structured information to other
components (e.g., decision-making systems). In this paper we describe our
approach implementing a real-time LDM component using the RTMaps middleware, as
a database deployed in a vehicle, but also at road-side units (RSU), making use
of the three pillars that guide a successful fusion strategy: utilisation of
standards (with conversions between domains), middlewares to unify multiple
ADAS sources, and linkage of data via semantic concepts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FontNet: Closing the gap to font designer performance in font synthesis. (arXiv:2205.06512v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06512">
<div class="article-summary-box-inner">
<span><p>Font synthesis has been a very active topic in recent years because manual
font design requires domain expertise and is a labor-intensive and
time-consuming job. While remarkably successful, existing methods for font
synthesis have major shortcomings; they require finetuning for unobserved font
style with large reference images, the recent few-shot font synthesis methods
are either designed for specific language systems or they operate on
low-resolution images which limits their use. In this paper, we tackle this
font synthesis problem by learning the font style in the embedding space. To
this end, we propose a model, called FontNet, that simultaneously learns to
separate font styles in the embedding space where distances directly correspond
to a measure of font similarity, and translates input images into the given
observed or unobserved font style. Additionally, we design the network
architecture and training procedure that can be adopted for any language system
and can produce high-resolution font images. Thanks to this approach, our
proposed method outperforms the existing state-of-the-art font generation
methods on both qualitative and quantitative experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Semantic Composition with Syntactic Hypergraph for Video Question Answering. (arXiv:2205.06530v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06530">
<div class="article-summary-box-inner">
<span><p>A key challenge in video question answering is how to realize the cross-modal
semantic alignment between textual concepts and corresponding visual objects.
Existing methods mostly seek to align the word representations with the video
regions. However, word representations are often not able to convey a complete
description of textual concepts, which are in general described by the
compositions of certain words. To address this issue, we propose to first build
a syntactic dependency tree for each question with an off-the-shelf tool and
use it to guide the extraction of meaningful word compositions. Based on the
extracted compositions, a hypergraph is further built by viewing the words as
nodes and the compositions as hyperedges. Hypergraph convolutional networks
(HCN) are then employed to learn the initial representations of word
compositions. Afterwards, an optimal transport based method is proposed to
perform cross-modal semantic alignment for the textual and visual semantic
space. To reflect the cross-modal influences, the cross-modal information is
incorporated into the initial representations, leading to a model named
cross-modality-aware syntactic HCN. Experimental results on three benchmarks
show that our method outperforms all strong baselines. Further analyses
demonstrate the effectiveness of each component, and show that our model is
good at modeling different levels of semantic compositions and filtering out
irrelevant information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparison of attention models and post-hoc explanation methods for embryo stage identification: a case study. (arXiv:2205.06546v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06546">
<div class="article-summary-box-inner">
<span><p>An important limitation to the development of AI-based solutions for In Vitro
Fertilization (IVF) is the black-box nature of most state-of-the-art models,
due to the complexity of deep learning architectures, which raises potential
bias and fairness issues. The need for interpretable AI has risen not only in
the IVF field but also in the deep learning community in general. This has
started a trend in literature where authors focus on designing objective
metrics to evaluate generic explanation methods. In this paper, we study the
behavior of recently proposed objective faithfulness metrics applied to the
problem of embryo stage identification. We benchmark attention models and
post-hoc methods using metrics and further show empirically that (1) the
metrics produce low overall agreement on the model ranking and (2) depending on
the metric approach, either post-hoc methods or attention models are favored.
We conclude with general remarks about the difficulty of defining faithfulness
and the necessity of understanding its relationship with the type of approach
that is favored.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta Balanced Network for Fair Face Recognition. (arXiv:2205.06548v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06548">
<div class="article-summary-box-inner">
<span><p>Although deep face recognition has achieved impressive progress in recent
years, controversy has arisen regarding discrimination based on skin tone,
questioning their deployment into real-world scenarios. In this paper, we aim
to systematically and scientifically study this bias from both data and
algorithm aspects. First, using the dermatologist approved Fitzpatrick Skin
Type classification system and Individual Typology Angle, we contribute a
benchmark called Identity Shades (IDS) database, which effectively quantifies
the degree of the bias with respect to skin tone in existing face recognition
algorithms and commercial APIs. Further, we provide two skin-tone aware
training datasets, called BUPT-Globalface dataset and BUPT-Balancedface
dataset, to remove bias in training data. Finally, to mitigate the algorithmic
bias, we propose a novel meta-learning algorithm, called Meta Balanced Network
(MBN), which learns adaptive margins in large margin loss such that the model
optimized by this loss can perform fairly across people with different skin
tones. To determine the margins, our method optimizes a meta skewness loss on a
clean and unbiased meta set and utilizes backward-on-backward automatic
differentiation to perform a second order gradient descent step on the current
margins. Extensive experiments show that MBN successfully mitigates bias and
learns more balanced performance for people with different skin tones in face
recognition. The proposed datasets are available at
<a href="http://www.whdeng.cn/RFW/index.html.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Structure-Texture Separation Network for Oracle Character Recognition. (arXiv:2205.06549v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06549">
<div class="article-summary-box-inner">
<span><p>Oracle bone script is the earliest-known Chinese writing system of the Shang
dynasty and is precious to archeology and philology. However, real-world
scanned oracle data are rare and few experts are available for annotation which
make the automatic recognition of scanned oracle characters become a
challenging task. Therefore, we aim to explore unsupervised domain adaptation
to transfer knowledge from handprinted oracle data, which are easy to acquire,
to scanned domain. We propose a structure-texture separation network (STSN),
which is an end-to-end learning framework for joint disentanglement,
transformation, adaptation and recognition. First, STSN disentangles features
into structure (glyph) and texture (noise) components by generative models, and
then aligns handprinted and scanned data in structure feature space such that
the negative influence caused by serious noises can be avoided when adapting.
Second, transformation is achieved via swapping the learned textures across
domains and a classifier for final classification is trained to predict the
labels of the transformed scanned characters. This not only guarantees the
absolute separation, but also enhances the discriminative ability of the
learned features. Extensive experiments on Oracle-241 dataset show that STSN
outperforms other adaptation methods and successfully improves recognition
performance on scanned data even when they are contaminated by long burial and
careless excavation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Domain Disentanglement for Generalizable Medical Image Segmentation. (arXiv:2205.06551v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06551">
<div class="article-summary-box-inner">
<span><p>Efficiently utilizing discriminative features is crucial for convolutional
neural networks to achieve remarkable performance in medical image segmentation
and is also important for model generalization across multiple domains, where
letting model recognize domain-specific and domain-invariant information among
multi-site datasets is a reasonable strategy for domain generalization.
Unfortunately, most of the recent disentangle networks are not directly
adaptable to unseen-domain datasets because of the limitations of offered data
distribution. To tackle this deficiency, we propose Contrastive Domain
Disentangle (CDD) network for generalizable medical image segmentation. We
first introduce a disentangle network to decompose medical images into an
anatomical representation factor and a modality representation factor. Then, a
style contrastive loss is proposed to encourage the modality representations
from the same domain to distribute as close as possible while different domains
are estranged from each other. Finally, we propose a domain augmentation
strategy that can randomly generate new domains for model generalization
training. Experimental results on multi-site fundus image datasets for optic
cup and disc segmentation show that the CDD has good model generalization. Our
proposed CDD outperforms several state-of-the-art methods in domain
generalizable segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Virtual passengers for real car solutions: synthetic datasets. (arXiv:2205.06556v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06556">
<div class="article-summary-box-inner">
<span><p>Strategies that include the generation of synthetic data are beginning to be
viable as obtaining real data can be logistically complicated, very expensive
or slow. Not only the capture of the data can lead to complications, but also
its annotation. To achieve high-fidelity data for training intelligent systems,
we have built a 3D scenario and set-up to resemble reality as closely as
possible. With our approach, it is possible to configure and vary parameters to
add randomness to the scene and, in this way, allow variation in data, which is
so important in the construction of a dataset. Besides, the annotation task is
already included in the data generation exercise, rather than being a
post-capture task, which can save a lot of resources. We present the process
and concept of synthetic data generation in an automotive context, specifically
for driver and passenger monitoring purposes, as an alternative to real data
capturing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Masking for Unsupervised Anomaly Detection and Localization. (arXiv:2205.06568v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06568">
<div class="article-summary-box-inner">
<span><p>Recently, anomaly detection and localization in multimedia data have received
significant attention among the machine learning community. In real-world
applications such as medical diagnosis and industrial defect detection,
anomalies only present in a fraction of the images. To extend the
reconstruction-based anomaly detection architecture to the localized anomalies,
we propose a self-supervised learning approach through random masking and then
restoring, named Self-Supervised Masking (SSM) for unsupervised anomaly
detection and localization. SSM not only enhances the training of the
inpainting network but also leads to great improvement in the efficiency of
mask prediction at inference. Through random masking, each image is augmented
into a diverse set of training triplets, thus enabling the autoencoder to learn
to reconstruct with masks of various sizes and shapes during training. To
improve the efficiency and effectiveness of anomaly detection and localization
at inference, we propose a novel progressive mask refinement approach that
progressively uncovers the normal regions and finally locates the anomalous
regions. The proposed SSM method outperforms several state-of-the-arts for both
anomaly detection and anomaly localization, achieving 98.3% AUC on Retinal-OCT
and 93.9% AUC on MVTec AD, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Blind Image Inpainting with Sparse Directional Filter Dictionaries for Lightweight CNNs. (arXiv:2205.06597v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06597">
<div class="article-summary-box-inner">
<span><p>Blind inpainting algorithms based on deep learning architectures have shown a
remarkable performance in recent years, typically outperforming model-based
methods both in terms of image quality and run time. However, neural network
strategies typically lack a theoretical explanation, which contrasts with the
well-understood theory underlying model-based methods. In this work, we
leverage the advantages of both approaches by integrating theoretically founded
concepts from transform domain methods and sparse approximations into a
CNN-based approach for blind image inpainting. To this end, we present a novel
strategy to learn convolutional kernels that applies a specifically designed
filter dictionary whose elements are linearly combined with trainable weights.
Numerical experiments demonstrate the competitiveness of this approach. Our
results show not only an improved inpainting quality compared to conventional
CNNs but also significantly faster network convergence within a lightweight
network design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StyLandGAN: A StyleGAN based Landscape Image Synthesis using Depth-map. (arXiv:2205.06611v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06611">
<div class="article-summary-box-inner">
<span><p>Despite recent success in conditional image synthesis, prevalent input
conditions such as semantics and edges are not clear enough to express `Linear
(Ridges)' and `Planar (Scale)' representations. To address this problem, we
propose a novel framework StyLandGAN, which synthesizes desired landscape
images using a depth map which has higher expressive power. Our StyleLandGAN is
extended from the unconditional generation model to accept input conditions. We
also propose a '2-phase inference' pipeline which generates diverse depth maps
and shifts local parts so that it can easily reflect user's intend. As a
comparison, we modified the existing semantic image synthesis models to accept
a depth map as well. Experimental results show that our method is superior to
existing methods in quality, diversity, and depth-accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Local Attention Graph-based Transformer for Multi-target Genetic Alteration Prediction. (arXiv:2205.06672v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06672">
<div class="article-summary-box-inner">
<span><p>Classical multiple instance learning (MIL) methods are often based on the
identical and independent distributed assumption between instances, hence
neglecting the potentially rich contextual information beyond individual
entities. On the other hand, Transformers with global self-attention modules
have been proposed to model the interdependencies among all instances. However,
in this paper we question: Is global relation modeling using self-attention
necessary, or can we appropriately restrict self-attention calculations to
local regimes in large-scale whole slide images (WSIs)? We propose a
general-purpose local attention graph-based Transformer for MIL (LA-MIL),
introducing an inductive bias by explicitly contextualizing instances in
adaptive local regimes of arbitrary size. Additionally, an efficiently adapted
loss function enables our approach to learn expressive WSI embeddings for the
joint analysis of multiple biomarkers. We demonstrate that LA-MIL achieves
state-of-the-art results in mutation prediction for gastrointestinal cancer,
outperforming existing models on important biomarkers such as microsatellite
instability for colorectal cancer. This suggests that local self-attention
sufficiently models dependencies on par with global modules. Our implementation
will be published.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VesNet-RL: Simulation-based Reinforcement Learning for Real-World US Probe Navigation. (arXiv:2205.06676v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06676">
<div class="article-summary-box-inner">
<span><p>Ultrasound (US) is one of the most common medical imaging modalities since it
is radiation-free, low-cost, and real-time. In freehand US examinations,
sonographers often navigate a US probe to visualize standard examination planes
with rich diagnostic information. However, reproducibility and stability of the
resulting images often suffer from intra- and inter-operator variation.
Reinforcement learning (RL), as an interaction-based learning method, has
demonstrated its effectiveness in visual navigating tasks; however, RL is
limited in terms of generalization. To address this challenge, we propose a
simulation-based RL framework for real-world navigation of US probes towards
the standard longitudinal views of vessels. A UNet is used to provide binary
masks from US images; thereby, the RL agent trained on simulated binary vessel
images can be applied in real scenarios without further training. To accurately
characterize actual states, a multi-modality state representation structure is
introduced to facilitate the understanding of environments. Moreover,
considering the characteristics of vessels, a novel standard view recognition
approach based on the minimum bounding rectangle is proposed to terminate the
searching process. To evaluate the effectiveness of the proposed method, the
trained policy is validated virtually on 3D volumes of a volunteer's in-vivo
carotid artery, and physically on custom-designed gel phantoms using robotic
US. The results demonstrate that proposed approach can effectively and
accurately navigate the probe towards the longitudinal view of vessels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-Eye: An Open Platform to Study Human Performance on Identifying AI-Synthesized Faces. (arXiv:2205.06680v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06680">
<div class="article-summary-box-inner">
<span><p>AI-synthesized faces are visually challenging to discern from real ones. They
have been used as profile images for fake social media accounts, which leads to
high negative social impacts. Although progress has been made in developing
automatic methods to detect AI-synthesized faces, there is no open platform to
study the human performance of AI-synthesized faces detection. In this work, we
develop an online platform called Open-eye to study the human performance of
AI-synthesized face detection. We describe the design and workflow of the
Open-eye in this paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Effectiveness of Temporal Dependency in Deepfake Video Detection. (arXiv:2205.06684v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06684">
<div class="article-summary-box-inner">
<span><p>Deepfakes are a form of synthetic image generation used to generate fake
videos of individuals for malicious purposes. The resulting videos may be used
to spread misinformation, reduce trust in media, or as a form of blackmail.
These threats necessitate automated methods of deepfake video detection. This
paper investigates whether temporal information can improve the deepfake
detection performance of deep learning models.
</p>
<p>To investigate this, we propose a framework that classifies new and existing
approaches by their defining characteristics. These are the types of feature
extraction: automatic or manual, and the temporal relationship between frames:
dependent or independent. We apply this framework to investigate the effect of
temporal dependency on a model's deepfake detection performance.
</p>
<p>We find that temporal dependency produces a statistically significant (p &lt;
0.05) increase in performance in classifying real images for the model using
automatic feature selection, demonstrating that spatio-temporal information can
increase the performance of deepfake video detection models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Framework for Implicit Sinkhorn Differentiation. (arXiv:2205.06688v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06688">
<div class="article-summary-box-inner">
<span><p>The Sinkhorn operator has recently experienced a surge of popularity in
computer vision and related fields. One major reason is its ease of integration
into deep learning frameworks. To allow for an efficient training of respective
neural networks, we propose an algorithm that obtains analytical gradients of a
Sinkhorn layer via implicit differentiation. In comparison to prior work, our
framework is based on the most general formulation of the Sinkhorn operator. It
allows for any type of loss function, while both the target capacities and cost
matrices are differentiated jointly. We further construct error bounds of the
resulting algorithm for approximate inputs. Finally, we demonstrate that for a
number of applications, simply replacing automatic differentiation with our
algorithm directly improves the stability and accuracy of the obtained
gradients. Moreover, we show that it is computationally more efficient,
particularly when resources like GPU memory are scarce.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Distillation Meets Open-Set Semi-Supervised Learning. (arXiv:2205.06701v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06701">
<div class="article-summary-box-inner">
<span><p>Existing knowledge distillation methods mostly focus on distillation of
teacher's prediction and intermediate activation. However, the structured
representation, which arguably is one of the most critical ingredients of deep
models, is largely overlooked. In this work, we propose a novel {\em
\modelname{}} ({\bf\em \shortname{})} method dedicated for distilling
representational knowledge semantically from a pretrained teacher to a target
student. The key idea is that we leverage the teacher's classifier as a
semantic critic for evaluating the representations of both teacher and student
and distilling the semantic knowledge with high-order structured information
over all feature dimensions. This is accomplished by introducing a notion of
cross-network logit computed through passing student's representation into
teacher's classifier. Further, considering the set of seen classes as a basis
for the semantic space in a combinatorial perspective, we scale \shortname{} to
unseen classes for enabling effective exploitation of largely available,
arbitrary unlabeled training data. At the problem level, this establishes an
interesting connection between knowledge distillation with open-set
semi-supervised learning (SSL). Extensive experiments show that our
\shortname{} outperforms significantly previous state-of-the-art knowledge
distillation methods on both coarse object classification and fine face
recognition tasks, as well as less studied yet practically crucial binary
network distillation. Under more realistic open-set SSL settings we introduce,
we reveal that knowledge distillation is generally more effective than existing
Out-Of-Distribution (OOD) sample detection, and our proposed \shortname{} is
superior over both previous distillation and SSL competitors. The source code
is available at \url{https://github.com/jingyang2017/SRD\_ossl}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-encoder Network for Parameter Reduction of a Kernel-based Interpolation Architecture. (arXiv:2205.06723v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06723">
<div class="article-summary-box-inner">
<span><p>Video frame interpolation involves the synthesis of new frames from existing
ones. Convolutional neural networks (CNNs) have been at the forefront of the
recent advances in this field. One popular CNN-based approach involves the
application of generated kernels to the input frames to obtain an interpolated
frame. Despite all the benefits interpolation methods offer, many of these
networks require a lot of parameters, with more parameters meaning a heavier
computational burden. Reducing the size of the model typically impacts
performance negatively. This paper presents a method for parameter reduction
for a popular flow-less kernel-based network (Adaptive Collaboration of Flows).
Through our technique of removing the layers that require the most parameters
and replacing them with smaller encoders, we reduce the number of parameters of
the network and even achieve better performance compared to the original
method. This is achieved by deploying rotation to force each individual encoder
to learn different features from the input images. Ablations are conducted to
justify design choices and an evaluation on how our method performs on
full-length videos is presented.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An empirical study of CTC based models for OCR of Indian languages. (arXiv:2205.06740v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06740">
<div class="article-summary-box-inner">
<span><p>Recognition of text on word or line images, without the need for sub-word
segmentation has become the mainstream of research and development of text
recognition for Indian languages. Modelling unsegmented sequences using
Connectionist Temporal Classification (CTC) is the most commonly used approach
for segmentation-free OCR. In this work we present a comprehensive empirical
study of various neural network models that uses CTC for transcribing step-wise
predictions in the neural network output to a Unicode sequence. The study is
conducted for 13 Indian languages, using an internal dataset that has around
1000 pages per language. We study the choice of line vs word as the recognition
unit, and use of synthetic data to train the models. We compare our models with
popular publicly available OCR tools for end-to-end document image recognition.
Our end-to-end pipeline that employ our recognition models and existing text
segmentation tools outperform these public OCR tools for 8 out of the 13
languages. We also introduce a new public dataset called Mozhi for word and
line recognition in Indian language. The dataset contains more than 1.2 million
annotated word images (120 thousand text lines) across 13 Indian languages. Our
code, trained models and the Mozhi dataset will be made available at
<a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Slimmable Video Codec. (arXiv:2205.06754v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06754">
<div class="article-summary-box-inner">
<span><p>Neural video compression has emerged as a novel paradigm combining trainable
multilayer neural networks and machine learning, achieving competitive
rate-distortion (RD) performances, but still remaining impractical due to heavy
neural architectures, with large memory and computational demands. In addition,
models are usually optimized for a single RD tradeoff. Recent slimmable image
codecs can dynamically adjust their model capacity to gracefully reduce the
memory and computation requirements, without harming RD performance. In this
paper we propose a slimmable video codec (SlimVC), by integrating a slimmable
temporal entropy model in a slimmable autoencoder. Despite a significantly more
complex architecture, we show that slimming remains a powerful mechanism to
control rate, memory footprint, computational cost and latency, all being
important requirements for practical video compression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scribble2D5: Weakly-Supervised Volumetric Image Segmentation via Scribble Annotations. (arXiv:2205.06779v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06779">
<div class="article-summary-box-inner">
<span><p>Recently, weakly-supervised image segmentation using weak annotations like
scribbles has gained great attention, since such annotations are much easier to
obtain compared to time-consuming and label-intensive labeling at the
pixel/voxel level. However, because scribbles lack structure information of
region of interest (ROI), existing scribble-based methods suffer from poor
boundary localization. Furthermore, most current methods are designed for 2D
image segmentation, which do not fully leverage the volumetric information if
directly applied to image slices. In this paper, we propose a scribble-based
volumetric image segmentation, Scribble2D5, which tackles 3D anisotropic image
segmentation and improves boundary prediction. To achieve this, we augment a
2.5D attention UNet with a proposed label propagation module to extend semantic
information from scribbles and a combination of static and active boundary
prediction to learn ROI's boundary and regularize its shape. Extensive
experiments on three public datasets demonstrate Scribble2D5 significantly
outperforms current scribble-based methods and approaches the performance of
fully-supervised ones. Our code is available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KG-SP: Knowledge Guided Simple Primitives for Open World Compositional Zero-Shot Learning. (arXiv:2205.06784v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06784">
<div class="article-summary-box-inner">
<span><p>The goal of open-world compositional zero-shot learning (OW-CZSL) is to
recognize compositions of state and objects in images, given only a subset of
them during training and no prior on the unseen compositions. In this setting,
models operate on a huge output space, containing all possible state-object
compositions. While previous works tackle the problem by learning embeddings
for the compositions jointly, here we revisit a simple CZSL baseline and
predict the primitives, i.e. states and objects, independently. To ensure that
the model develops primitive-specific features, we equip the state and object
classifiers with separate, non-linear feature extractors. Moreover, we estimate
the feasibility of each composition through external knowledge, using this
prior to remove unfeasible compositions from the output space. Finally, we
propose a new setting, i.e. CZSL under partial supervision (pCZSL), where
either only objects or state labels are available during training, and we can
use our prior to estimate the missing labels. Our model, Knowledge-Guided
Simple Primitives (KG-SP), achieves state of the art in both OW-CZSL and pCZSL,
surpassing most recent competitors even when coupled with semi-supervised
learning techniques. Code available at: https://github.com/ExplainableML/KG-SP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VQFR: Blind Face Restoration with Vector-Quantized Dictionary and Parallel Decoder. (arXiv:2205.06803v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06803">
<div class="article-summary-box-inner">
<span><p>Although generative facial prior and geometric prior have recently
demonstrated high-quality results for blind face restoration, producing
fine-grained facial details faithful to inputs remains a challenging problem.
Motivated by the classical dictionary-based methods and the recent vector
quantization (VQ) technique, we propose a VQ-based face restoration method --
VQFR. VQFR takes advantage of high-quality low-level feature banks extracted
from high-quality faces and can thus help recover realistic facial details.
However, the simple application of the VQ codebook cannot achieve good results
with faithful details and identity preservation. Therefore, we further
introduce two special network designs. 1). We first investigate the compression
patch size in the VQ codebook and find that the VQ codebook designed with a
proper compression patch size is crucial to balance the quality and fidelity.
2). To further fuse low-level features from inputs while not "contaminating"
the realistic details generated from the VQ codebook, we proposed a parallel
decoder consisting of a texture decoder and a main decoder. Those two decoders
then interact with a texture warping module with deformable convolution.
Equipped with the VQ codebook as a facial detail dictionary and the parallel
decoder design, the proposed VQFR can largely enhance the restored quality of
facial details while keeping the fidelity to previous methods. Codes will be
available at https://github.com/TencentARC/VQFR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">secml: A Python Library for Secure and Explainable Machine Learning. (arXiv:1912.10013v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.10013">
<div class="article-summary-box-inner">
<span><p>We present \texttt{secml}, an open-source Python library for secure and
explainable machine learning. It implements the most popular attacks against
machine learning, including test-time evasion attacks to generate adversarial
examples against deep neural networks and training-time poisoning attacks
against support vector machines and many other algorithms. These attacks enable
evaluating the security of learning algorithms and the corresponding defenses
under both white-box and black-box threat models. To this end, \texttt{secml}
provides built-in functions to compute security evaluation curves, showing how
quickly classification performance decreases against increasing adversarial
perturbations of the input data. \texttt{secml} also includes explainability
methods to help understand why adversarial attacks succeed against a given
model, by visualizing the most influential features and training prototypes
contributing to each decision. It is distributed under the Apache License 2.0
and hosted at \url{https://github.com/pralab/secml}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning for Domain Adaptation on Point-Clouds. (arXiv:2003.12641v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.12641">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) is a technique for learning useful
representations from unlabeled data. It has been applied effectively to domain
adaptation (DA) on images and videos. It is still unknown if and how it can be
leveraged for domain adaptation in 3D perception problems. Here we describe the
first study of SSL for DA on point clouds. We introduce a new family of pretext
tasks, Deformation Reconstruction, inspired by the deformations encountered in
sim-to-real transformations. In addition, we propose a novel training procedure
for labeled point cloud data motivated by the MixUp method called Point cloud
Mixup (PCM). Evaluations on domain adaptations datasets for classification and
segmentation, demonstrate a large improvement over existing and baseline
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distance Guided Channel Weighting for Semantic Segmentation. (arXiv:2004.12679v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.12679">
<div class="article-summary-box-inner">
<span><p>Recent works have achieved great success in improving the performance of
multiple computer vision tasks by capturing features with a high channel number
utilizing deep neural networks. However, many channels of extracted features
are not discriminative and contain a lot of redundant information. In this
paper, we address above issue by introducing the Distance Guided Channel
Weighting (DGCW) Module. The DGCW module is constructed in a pixel-wise context
extraction manner, which enhances the discriminativeness of features by
weighting different channels of each pixel's feature vector when modeling its
relationship with other pixels. It can make full use of the high-discriminative
information while ignore the low-discriminative information containing in
feature maps, as well as capture the long-range dependencies. Furthermore, by
incorporating the DGCW module with a baseline segmentation network, we propose
the Distance Guided Channel Weighting Network (DGCWNet). We conduct extensive
experiments to demonstrate the effectiveness of DGCWNet. In particular, it
achieves 81.6% mIoU on Cityscapes with only fine annotated data for training,
and also gains satisfactory performance on another two semantic segmentation
datasets, i.e. Pascal Context and ADE20K. Code will be available soon at
https://github.com/LanyunZhu/DGCWNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Super-Resolution Domain Adaptation Networks for Semantic Segmentation via Pixel and Output Level Aligning. (arXiv:2005.06382v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.06382">
<div class="article-summary-box-inner">
<span><p>Recently, Unsupervised Domain Adaptation (UDA) has attracted increasing
attention to address the domain shift problem in the semantic segmentation
task. Although previous UDA methods have achieved promising performance, they
still suffer from the distribution gaps between source and target domains,
especially the resolution discrepany in the remote sensing images. To address
this problem, this paper designs a novel end-to-end semantic segmentation
network, namely Super-Resolution Domain Adaptation Network (SRDA-Net). SRDA-Net
can simultaneously achieve the super-resolution task and the domain adaptation
task, thus satisfying the requirement of semantic segmentation for remote
sensing images which usually involve various resolution images. The proposed
SRDA-Net includes three parts: a Super-Resolution and Segmentation (SRS) model
which focuses on recovering high-resolution image and predicting segmentation
map, a Pixel-level Domain Classifier (PDC) for determining which domain the
pixel belongs to, and an Output-space Domain Classifier (ODC) for
distinguishing which domain the pixel contribution is from. By jointly
optimizing SRS with two classifiers, the proposed method can not only
eliminates the resolution difference between source and target domains, but
also improve the performance of the semantic segmentation task. Experimental
results on two remote sensing datasets with different resolutions demonstrate
that SRDA-Net performs favorably against some state-of-the-art methods in terms
of accuracy and visual quality. Code and models are available at
https://github.com/tangzhenjie/SRDA-Net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Sampling for Neural Point Cloud Consolidation. (arXiv:2008.06471v3 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.06471">
<div class="article-summary-box-inner">
<span><p>We introduce a novel technique for neural point cloud consolidation which
learns from only the input point cloud. Unlike other point upsampling methods
which analyze shapes via local patches, in this work, we learn from global
subsets. We repeatedly self-sample the input point cloud with global subsets
that are used to train a deep neural network. Specifically, we define source
and target subsets according to the desired consolidation criteria (e.g.,
generating sharp points or points in sparse regions). The network learns a
mapping from source to target subsets, and implicitly learns to consolidate the
point cloud. During inference, the network is fed with random subsets of points
from the input, which it displaces to synthesize a consolidated point set. We
leverage the inductive bias of neural networks to eliminate noise and outliers,
a notoriously difficult problem in point cloud consolidation. The shared
weights of the network are optimized over the entire shape, learning non-local
statistics and exploiting the recurrence of local-scale geometries.
Specifically, the network encodes the distribution of the underlying shape
surface within a fixed set of local kernels, which results in the best
explanation of the underlying shape surface. We demonstrate the ability to
consolidate point sets from a variety of shapes, while eliminating outliers and
noise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-Local Robust Quaternion Matrix Completion for Color Images and Videos Inpainting. (arXiv:2011.08675v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08675">
<div class="article-summary-box-inner">
<span><p>The image nonlocal self-similarity (NSS) prior refers to the fact that a
local patch often has many nonlocal similar patches to it across the image and
has been widely applied in many recently proposed machining learning algorithms
for image processing. However, there is no theoretical analysis on its working
principle in the literature. In this paper, we discover a potential causality
between NSS and low-rank property of color images, which is also available to
grey images. A new patch group based NSS prior scheme is proposed to learn
explicit NSS models of natural color images. The numerical low-rank property of
patched matrices is also rigorously proved. The NSS-based QMC algorithm
computes an optimal low-rank approximation to the high-rank color image,
resulting in high PSNR and SSIM measures and particularly the better visual
quality. A new tensor NSS-based QMC method is also presented to solve the color
video inpainting problem based on quaternion tensor representation. The
numerical experiments on color images and videos indicate the advantages of
NSS-based QMC over the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Image Generation via Sparse Modeling. (arXiv:2104.00464v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00464">
<div class="article-summary-box-inner">
<span><p>The interest of the deep learning community in image synthesis has grown
massively in recent years. Nowadays, deep generative methods, and especially
Generative Adversarial Networks (GANs), are leading to state-of-the-art
performance, capable of synthesizing images that appear realistic. While the
efforts for improving the quality of the generated images are extensive, most
attempts still consider the generator part as an uncorroborated "black-box". In
this paper, we aim to provide a better understanding and design of the image
generation process. We interpret existing generators as implicitly relying on
sparsity-inspired models. More specifically, we show that generators can be
viewed as manifestations of the Convolutional Sparse Coding (CSC) and its
Multi-Layered version (ML-CSC) synthesis processes. We leverage this
observation by explicitly enforcing a sparsifying regularization on
appropriately chosen activation layers in the generator, and demonstrate that
this leads to improved image synthesis. Furthermore, we show that the same
rationale and benefits apply to generators serving inverse problems,
demonstrated on the Deep Image Prior (DIP) method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval. (arXiv:2104.00650v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00650">
<div class="article-summary-box-inner">
<span><p>Our objective in this work is video-text retrieval - in particular a joint
embedding that enables efficient text-to-video retrieval. The challenges in
this area include the design of the visual architecture and the nature of the
training data, in that the available large scale video-text training datasets,
such as HowTo100M, are noisy and hence competitive performance is achieved only
at scale through large amounts of compute. We address both these challenges in
this paper. We propose an end-to-end trainable model that is designed to take
advantage of both large-scale image and video captioning datasets. Our model is
an adaptation and extension of the recent ViT and Timesformer architectures,
and consists of attention in both space and time. The model is flexible and can
be trained on both image and video text datasets, either independently or in
conjunction. It is trained with a curriculum learning schedule that begins by
treating images as 'frozen' snapshots of video, and then gradually learns to
attend to increasing temporal context when trained on video datasets. We also
provide a new video-text pretraining dataset WebVid-2M, comprised of over two
million videos with weak captions scraped from the internet. Despite training
on datasets that are an order of magnitude smaller, we show that this approach
yields state-of-the-art results on standard downstream video-retrieval
benchmarks including MSR-VTT, MSVD, DiDeMo and LSMDC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional Hyper-Network for Blind Super-Resolution with Multiple Degradations. (arXiv:2104.03926v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03926">
<div class="article-summary-box-inner">
<span><p>Although single-image super-resolution (SISR) methods have achieved great
success on single degradation, they still suffer performance drop with multiple
degrading effects in real scenarios. Recently, some blind and non-blind models
for multiple degradations have been explored. However, those methods usually
degrade significantly for distribution shifts between the training and test
data. Towards this end, we propose a conditional meta-network framework (named
CMDSR) for the first time, which helps SR framework learn how to adapt to
changes in input distribution. We extract degradation prior at task-level with
the proposed ConditionNet, which will be used to adapt the parameters of the
basic SR network (BaseNet). Specifically, the ConditionNet of our framework
first learns the degradation prior from a support set, which is composed of a
series of degraded image patches from the same task. Then the adaptive BaseNet
rapidly shifts its parameters according to the conditional features. Moreover,
in order to better extract degradation prior, we propose a task contrastive
loss to decrease the inner-task distance and increase the cross-task distance
between task-level features. Without predefining degradation maps, our blind
framework can conduct one single parameter update to yield considerable SR
results. Extensive experiments demonstrate the effectiveness of CMDSR over
various blind, even non-blind methods. The flexible BaseNet structure also
reveals that CMDSR can be a general framework for large series of SISR models.
Our code is available at \url{https://github.com/guanghaoyin/CMDSR}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning general and distinctive 3D local deep descriptors for point cloud registration. (arXiv:2105.10382v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10382">
<div class="article-summary-box-inner">
<span><p>An effective 3D descriptor should be invariant to different geometric
transformations, such as scale and rotation, robust to occlusions and clutter,
and capable of generalising to different application domains. We present a
simple yet effective method to learn general and distinctive 3D local
descriptors that can be used to register point clouds that are captured in
different domains. Point cloud patches are extracted, canonicalised with
respect to their local reference frame, and encoded into scale and
rotation-invariant compact descriptors by a deep neural network that is
invariant to permutations of the input points. This design is what enables our
descriptors to generalise across domains. We evaluate and compare our
descriptors with alternative handcrafted and deep learning-based descriptors on
several indoor and outdoor datasets that are reconstructed by using both RGBD
sensors and laser scanners. Our descriptors outperform most recent descriptors
by a large margin in terms of generalisation, and also become the state of the
art in benchmarks where training and testing are performed in the same domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Coupling of Depth and Egomotion Networks for Self-Supervised Structure from Motion. (arXiv:2106.04007v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04007">
<div class="article-summary-box-inner">
<span><p>Structure from motion (SfM) has recently been formulated as a self-supervised
learning problem, where neural network models of depth and egomotion are
learned jointly through view synthesis. Herein, we address the open problem of
how to best couple, or link, the depth and egomotion network components, so
that information such as a common scale factor can be shared between the
networks. Towards this end, we introduce several notions of coupling,
categorize existing approaches, and present a novel tightly-coupled approach
that leverages the interdependence of depth and egomotion at training time and
at test time. Our approach uses iterative view synthesis to recursively update
the egomotion network input, permitting contextual information to be passed
between the components. We demonstrate through substantial experiments that our
approach promotes consistency between the depth and egomotion predictions at
test time, improves generalization, and leads to state-of-the-art accuracy on
indoor and outdoor depth and egomotion evaluation benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal and frequency-weighted tensor nuclear norm for hyperspectral image denoising. (arXiv:2106.12489v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12489">
<div class="article-summary-box-inner">
<span><p>Low-rankness is important in the hyperspectral image (HSI) denoising tasks.
The tensor nuclear norm (TNN), defined based on the tensor singular value
decomposition, is a state-of-the-art method to describe the low-rankness of
HSI. However, TNN ignores some physical meanings of HSI in tackling denoising
tasks, leading to suboptimal denoising performance. In this paper, we propose
the multi-modal and frequency-weighted tensor nuclear norm (MFWTNN) and the
non-convex MFWTNN for HSI denoising tasks. Firstly, we investigate the physical
meaning of frequency components and reconsider their weights to improve the
low-rank representation ability of TNN. Secondly, we consider the correlation
among two spatial dimensions and the spectral dimension of HSI and combine the
above improvements to TNN to propose MFWTNN. Thirdly, we use non-convex
functions to approximate the rank function of the frequency tensor and propose
the NonMFWTNN to relax the MFWTNN better. Besides, we adaptively choose bigger
weights for slices mainly containing noise information and smaller weights for
slices containing profile information. Finally, we develop the efficient
alternating direction method of multiplier (ADMM) based algorithm to solve the
proposed models, and the effectiveness of our models are substantiated in
simulated and real HSI datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FaDIV-Syn: Fast Depth-Independent View Synthesis using Soft Masks and Implicit Blending. (arXiv:2106.13139v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13139">
<div class="article-summary-box-inner">
<span><p>Novel view synthesis is required in many robotic applications, such as VR
teleoperation and scene reconstruction. Existing methods are often too slow for
these contexts, cannot handle dynamic scenes, and are limited by their explicit
depth estimation stage, where incorrect depth predictions can lead to large
projection errors. Our proposed method runs in real time on live streaming data
and avoids explicit depth estimation by efficiently warping input images into
the target frame for a range of assumed depth planes. The resulting plane sweep
volume (PSV) is directly fed into our network, which first estimates soft PSV
masks in a self-supervised manner, and then directly produces the novel output
view. This improves efficiency and performance on transparent, reflective,
thin, and feature-less scene parts. FaDIV-Syn can perform both interpolation
and extrapolation tasks at 540p in real-time and outperforms state-of-the-art
extrapolation methods on the large-scale RealEstate10k dataset. We thoroughly
evaluate ablations, such as removing the Soft-Masking network, training from
fewer examples as well as generalization to higher resolutions and stronger
depth discretization. Our implementation is available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertify: Attacks Against Neural Network Certification. (arXiv:2108.11299v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11299">
<div class="article-summary-box-inner">
<span><p>A key concept towards reliable, robust, and safe AI systems is the idea to
implement fallback strategies when predictions of the AI cannot be trusted.
Certifiers for neural networks have made great progress towards provable
robustness guarantees against evasion attacks using adversarial examples. These
methods guarantee for some predictions that a certain class of manipulations or
attacks could not have changed the outcome. For the remaining predictions
without guarantees, the method abstains from making a prediction and a fallback
strategy needs to be invoked, which is typically more costly, less accurate, or
even involves a human operator. While this is a key concept towards safe and
secure AI, we show for the first time that this strategy comes with its own
security risks, as such fallback strategies can be deliberately triggered by an
adversary. In particular, we conduct the first systematic analysis of
training-time attacks against certifiers in practical application pipelines,
identifying new threat vectors that can be exploited to degrade the overall
system. Using these insights, we design two backdoor attacks against network
certifiers, which can drastically reduce certified robustness. For example,
adding 1% poisoned data during training is sufficient to reduce certified
robustness by up to 95 percentage points, effectively rendering the certifier
useless. We analyze how such novel attacks can compromise the overall system's
integrity or availability. Our extensive experiments across multiple datasets,
model architectures, and certifiers demonstrate the wide applicability of these
attacks. A first investigation into potential defenses shows that current
approaches are insufficient to mitigate the issue, highlighting the need for
new, more specific solutions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Authentication Attacks on Projection-based Cancelable Biometric Schemes (long version). (arXiv:2110.15163v5 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15163">
<div class="article-summary-box-inner">
<span><p>Cancelable biometric schemes aim at generating secure biometric templates by
combining user specific tokens, such as password, stored secret or salt, along
with biometric data. This type of transformation is constructed as a
composition of a biometric transformation with a feature extraction algorithm.
The security requirements of cancelable biometric schemes concern the
irreversibility, unlinkability and revocability of templates, without losing in
accuracy of comparison. While several schemes were recently attacked regarding
these requirements, full reversibility of such a composition in order to
produce colliding biometric characteristics, and specifically presentation
attacks, were never demonstrated to the best of our knowledge. In this paper,
we formalize these attacks for a traditional cancelable scheme with the help of
integer linear programming (ILP) and quadratically constrained quadratic
programming (QCQP). Solving these optimization problems allows an adversary to
slightly alter its fingerprint image in order to impersonate any individual.
Moreover, in an even more severe scenario, it is possible to simultaneously
impersonate several individuals.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeltaConv: Anisotropic Operators for Geometric Deep Learning on Point Clouds. (arXiv:2111.08799v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08799">
<div class="article-summary-box-inner">
<span><p>Learning from 3D point-cloud data has rapidly gained momentum, motivated by
the success of deep learning on images and the increased availability of
3D~data. In this paper, we aim to construct anisotropic convolution layers that
work directly on the surface derived from a point cloud. This is challenging
because of the lack of a global coordinate system for tangential directions on
surfaces. We introduce DeltaConv, a convolution layer that combines geometric
operators from vector calculus to enable the construction of anisotropic
filters on point clouds. Because these operators are defined on scalar- and
vector-fields, we separate the network into a scalar- and a vector-stream,
which are connected by the operators. The vector stream enables the network to
explicitly represent, evaluate, and process directional information. Our
convolutions are robust and simple to implement and match or improve on
state-of-the-art approaches on several benchmarks, while also speeding up
training and inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SeCGAN: Parallel Conditional Generative Adversarial Networks for Face Editing via Semantic Consistency. (arXiv:2111.09298v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09298">
<div class="article-summary-box-inner">
<span><p>Semantically guided conditional Generative Adversarial Networks (cGANs) have
become a popular approach for face editing in recent years. However, most
existing methods introduce semantic masks as direct conditional inputs to the
generator and often require the target masks to perform the corresponding
translation in the RGB space. We propose SeCGAN, a novel label-guided cGAN for
editing face images utilising semantic information without the need to specify
target semantic masks. During training, SeCGAN has two branches of generators
and discriminators operating in parallel, with one trained to translate RGB
images and the other for semantic masks. To bridge the two branches in a
mutually beneficial manner, we introduce a semantic consistency loss which
constrains both branches to have consistent semantic outputs. Whilst both
branches are required during training, the RGB branch is our primary network
and the semantic branch is not needed for inference. Our results on CelebA and
CelebA-HQ demonstrate that our approach is able to generate facial images with
more accurate attributes, outperforming competitive baselines in terms of
Target Attribute Recognition Rate whilst maintaining quality metrics such as
self-supervised Fr\'{e}chet Inception Distance and Inception Score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Anomaly Detection Using Self-Supervised Multi-Cue Tasks. (arXiv:2111.12379v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12379">
<div class="article-summary-box-inner">
<span><p>Anomaly detection is important in many real-life applications. Recently,
self-supervised learning has greatly helped deep anomaly detection by
recognizing several geometric transformations. However these methods lack finer
features, usually highly depend on the anomaly type, and do not perform well on
fine-grained problems. To address these issues, we first introduce in this work
three novel and efficient discriminative and generative tasks which have
complementary strength: (i) a piece-wise jigsaw puzzle task focuses on
structure cues; (ii) a tint rotation recognition is used within each piece,
taking into account the colorimetry information; (iii) and a partial
re-colorization task considers the image texture. In order to make the
re-colorization task more object-oriented than background-oriented, we propose
to include the contextual color information of the image border via an
attention mechanism. We then present a new out-of-distribution detection
function and highlight its better stability compared to existing methods. Along
with it, we also experiment different score fusion functions. Finally, we
evaluate our method on an extensive protocol composed of various anomaly types,
from object anomalies, style anomalies with fine-grained classification to
local anomalies with face anti-spoofing datasets. Our model significantly
outperforms state-of-the-art with up to 36% relative error improvement on
object anomalies and 40% on face anti-spoofing problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02639">
<div class="article-summary-box-inner">
<span><p>As humans, we navigate a multimodal world, building a holistic understanding
from all our senses. We introduce MERLOT Reserve, a model that represents
videos jointly over time -- through a new training objective that learns from
audio, subtitles, and video frames. Given a video, we replace snippets of text
and audio with a MASK token; the model learns by choosing the correct
masked-out snippet. Our objective learns faster than alternatives, and performs
well at scale: we pretrain on 20 million YouTube videos.
</p>
<p>Empirical results show that MERLOT Reserve learns strong multimodal
representations. When finetuned, it sets state-of-the-art on Visual Commonsense
Reasoning (VCR), TVQA, and Kinetics-600; outperforming prior work by 5%, 7%,
and 1.5% respectively. Ablations show that these tasks benefit from audio
pretraining -- even VCR, a QA task centered around images (without sound).
Moreover, our objective enables out-of-the-box prediction, revealing strong
multimodal commonsense understanding. In a fully zero-shot setting, our model
obtains competitive results on four video tasks, even outperforming supervised
approaches on the recently proposed Situated Reasoning (STAR) benchmark.
</p>
<p>We analyze why audio enables better vision-language representations,
suggesting significant opportunities for future research. We conclude by
discussing ethical and societal implications of multimodal pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M\"obius Convolutions for Spherical CNNs. (arXiv:2201.12212v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12212">
<div class="article-summary-box-inner">
<span><p>M\"obius transformations play an important role in both geometry and
spherical image processing - they are the group of conformal automorphisms of
2D surfaces and the spherical equivalent of homographies. Here we present a
novel, M\"obius-equivariant spherical convolution operator which we call
M\"obius convolution, and with it, develop the foundations for
M\"obius-equivariant spherical CNNs. Our approach is based on a simple
observation: to achieve equivariance, we only need to consider the
lower-dimensional subgroup which transforms the positions of points as seen in
the frames of their neighbors. To efficiently compute M\"obius convolutions at
scale we derive an approximation of the action of the transformations on
spherical filters, allowing us to compute our convolutions in the spectral
domain with the fast Spherical Harmonic Transform. The resulting framework is
both flexible and descriptive, and we demonstrate its utility by achieving
promising results in both shape classification and image segmentation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computing Multiple Image Reconstructions with a Single Hypernetwork. (arXiv:2202.11009v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11009">
<div class="article-summary-box-inner">
<span><p>Deep learning based techniques achieve state-of-the-art results in a wide
range of image reconstruction tasks like compressed sensing. These methods
almost always have hyperparameters, such as the weight coefficients that
balance the different terms in the optimized loss function. The typical
approach is to train the model for a hyperparameter setting determined with
some empirical or theoretical justification. Thus, at inference time, the model
can only compute reconstructions corresponding to the pre-determined
hyperparameter values. In this work, we present a hypernetwork-based approach,
called HyperRecon, to train reconstruction models that are agnostic to
hyperparameter settings. At inference time, HyperRecon can efficiently produce
diverse reconstructions, which would each correspond to different
hyperparameter values. In this framework, the user is empowered to select the
most useful output(s) based on their own judgement. We demonstrate our method
in compressed sensing, super-resolution and denoising tasks, using two
large-scale and publicly-available MRI datasets. Our code is available at
https://github.com/alanqrwang/hyperrecon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards deep learning-powered IVF: A large public benchmark for morphokinetic parameter prediction. (arXiv:2203.00531v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.00531">
<div class="article-summary-box-inner">
<span><p>An important limitation to the development of Artificial Intelligence
(AI)-based solutions for In Vitro Fertilization (IVF) is the absence of a
public reference benchmark to train and evaluate deep learning (DL) models. In
this work, we describe a fully annotated dataset of 704 videos of developing
embryos, for a total of 337k images. We applied ResNet, LSTM, and ResNet-3D
architectures to our dataset and demonstrate that they overperform algorithmic
approaches to automatically annotate stage development phases. Altogether, we
propose the first public benchmark that will allow the community to evaluate
morphokinetic models. This is the first step towards deep learning-powered IVF.
Of note, we propose highly detailed annotations with 16 different development
phases, including early cell division phases, but also late cell divisions,
phases after morulation, and very early phases, which have never been used
before. We postulate that this original approach will help improve the overall
performance of deep learning approaches on time-lapse videos of embryo
development, ultimately benefiting infertile patients with improved clinical
success rates (Code and data are available at
https://gitlab.univ-nantes.fr/E144069X/bench_mk_pred.git).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Vision Transformers for Joint SAR-optical Representation Learning. (arXiv:2204.05381v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05381">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) has attracted much interest in remote sensing
and earth observation due to its ability to learn task-agnostic representations
without human annotation. While most of the existing SSL works in remote
sensing utilize ConvNet backbones and focus on a single modality, we explore
the potential of vision transformers (ViTs) for joint SAR-optical
representation learning. Based on DINO, a state-of-the-art SSL algorithm that
distills knowledge from two augmented views of an input image, we combine SAR
and optical imagery by concatenating all channels to a unified input.
Subsequently, we randomly mask out channels of one modality as a data
augmentation strategy. While training, the model gets fed optical-only,
SAR-only, and SAR-optical image pairs learning both inner- and intra-modality
representations. Experimental results employing the BigEarthNet-MM dataset
demonstrate the benefits of both, the ViT backbones and the proposed multimodal
SSL algorithm DINO-MM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A9-Dataset: Multi-Sensor Infrastructure-Based Dataset for Mobility Research. (arXiv:2204.06527v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.06527">
<div class="article-summary-box-inner">
<span><p>Data-intensive machine learning based techniques increasingly play a
prominent role in the development of future mobility solutions - from driver
assistance and automation functions in vehicles, to real-time traffic
management systems realized through dedicated infrastructure. The availability
of high quality real-world data is often an important prerequisite for the
development and reliable deployment of such systems in large scale. Towards
this endeavour, we present the A9-Dataset based on roadside sensor
infrastructure from the 3 km long Providentia++ test field near Munich in
Germany. The dataset includes anonymized and precision-timestamped multi-modal
sensor and object data in high resolution, covering a variety of traffic
situations. As part of the first set of data, which we describe in this paper,
we provide camera and LiDAR frames from two overhead gantry bridges on the A9
autobahn with the corresponding objects labeled with 3D bounding boxes. The
first set includes in total more than 1000 sensor frames and 14000 traffic
objects. The dataset is available for download at https://a9-dataset.com.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Overview of Recent Work in Media Forensics: Methods and Threats. (arXiv:2204.12067v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12067">
<div class="article-summary-box-inner">
<span><p>In this paper, we review recent work in media forensics for digital images,
video, audio (specifically speech), and documents. For each data modality, we
discuss synthesis and manipulation techniques that can be used to create and
modify digital media. We then review technological advancements for detecting
and quantifying such manipulations. Finally, we consider open issues and
suggest directions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smart City Intersections: Intelligence Nodes for Future Metropolises. (arXiv:2205.01686v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01686">
<div class="article-summary-box-inner">
<span><p>Traffic intersections are the most suitable locations for the deployment of
computing, communications, and intelligence services for smart cities of the
future. The abundance of data to be collected and processed, in combination
with privacy and security concerns, motivates the use of the edge-computing
paradigm which aligns well with physical intersections in metropolises. This
paper focuses on high-bandwidth, low-latency applications, and in that context
it describes: (i) system design considerations for smart city intersection
intelligence nodes; (ii) key technological components including sensors,
networking, edge computing, low latency design, and AI-based intelligence; and
(iii) applications such as privacy preservation, cloud-connected vehicles, a
real-time "radar-screen", traffic management, and monitoring of pedestrian
behavior during pandemics. The results of the experimental studies performed on
the COSMOS testbed located in New York City are illustrated. Future challenges
in designing human-centered smart city intersections are summarized.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scene Clustering Based Pseudo-labeling Strategy for Multi-modal Aerial View Object Classification. (arXiv:2205.01920v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01920">
<div class="article-summary-box-inner">
<span><p>Multi-modal aerial view object classification (MAVOC) in Automatic target
recognition (ATR), although an important and challenging problem, has been
under studied. This paper firstly finds that fine-grained data, class imbalance
and various shooting conditions preclude the representational ability of
general image classification. Moreover, the MAVOC dataset has scene aggregation
characteristics. By exploiting these properties, we propose Scene Clustering
Based Pseudo-labeling Strategy (SCP-Label), a simple yet effective method to
employ in post-processing. The SCP-Label brings greater accuracy by assigning
the same label to objects within the same scene while also mitigating bias and
confusion with model ensembles. Its performance surpasses the official baseline
by a large margin of +20.57% Accuracy on Track 1 (SAR), and +31.86% Accuracy on
Track 2 (SAR+EO), demonstrating the potential of SCP-Label as post-processing.
Finally, we win the championship both on Track1 and Track2 in the CVPR 2022
Perception Beyond the Visible Spectrum (PBVS) Workshop MAVOC Challenge. Our
code is available at https://github.com/HowieChangchn/SCP-Label.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Arrhythmia Classifier using Binarized Convolutional Neural Network for Resource-Constrained Devices. (arXiv:2205.03661v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03661">
<div class="article-summary-box-inner">
<span><p>Monitoring electrocardiogram signals is of great significance for the
diagnosis of arrhythmias. In recent years, deep learning and convolutional
neural networks have been widely used in the classification of cardiac
arrhythmias. However, the existing neural network applied to ECG signal
detection usually requires a lot of computing resources, which is not friendlyF
to resource-constrained equipment, and it is difficult to realize real-time
monitoring. In this paper, a binarized convolutional neural network suitable
for ECG monitoring is proposed, which is hardware-friendly and more suitable
for use in resource-constrained wearable devices. Targeting the MIT-BIH
arrhythmia database, the classifier based on this network reached an accuracy
of 95.67% in the five-class test. Compared with the proposed baseline
full-precision network with an accuracy of 96.45%, it is only 0.78% lower.
Importantly, it achieves 12.65 times the computing speedup, 24.8 times the
storage compression ratio, and only requires a quarter of the memory overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Retrieve Videos by Asking Questions. (arXiv:2205.05739v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05739">
<div class="article-summary-box-inner">
<span><p>The majority of traditional text-to-video retrieval systems operate in static
environments, i.e., there is no interaction between the user and the agent
beyond the initial textual query provided by the user. This can be suboptimal
if the initial query has ambiguities, which would lead to many falsely
retrieved videos. To overcome this limitation, we propose a novel framework for
Video Retrieval using Dialog (ViReD), which enables the user to interact with
an AI agent via multiple rounds of dialog. The key contribution of our
framework is a novel multimodal question generator that learns to ask questions
that maximize the subsequent video retrieval performance. Our multimodal
question generator uses (i) the video candidates retrieved during the last
round of interaction with the user and (ii) the text-based dialog history
documenting all previous interactions, to generate questions that incorporate
both visual and linguistic cues relevant to video retrieval. Furthermore, to
generate maximally informative questions, we propose an Information-Guided
Supervision (IGS), which guides the question generator to ask questions that
would boost subsequent video retrieval accuracy. We validate the effectiveness
of our interactive ViReD framework on the AVSD dataset, showing that our
interactive method performs significantly better than traditional
non-interactive video retrieval systems. Furthermore, we also demonstrate that
our proposed approach also generalizes to the real-world settings that involve
interactions with real humans, thus, demonstrating the robustness and
generality of our framework
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Surface Representation for Point Clouds. (arXiv:2205.05740v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05740">
<div class="article-summary-box-inner">
<span><p>Most prior work represents the shapes of point clouds by coordinates.
However, it is insufficient to describe the local geometry directly. In this
paper, we present \textbf{RepSurf} (representative surfaces), a novel
representation of point clouds to \textbf{explicitly} depict the very local
structure. We explore two variants of RepSurf, Triangular RepSurf and Umbrella
RepSurf inspired by triangle meshes and umbrella curvature in computer
graphics. We compute the representations of RepSurf by predefined geometric
priors after surface reconstruction. RepSurf can be a plug-and-play module for
most point cloud models thanks to its free collaboration with irregular points.
Based on a simple baseline of PointNet++ (SSG version), Umbrella RepSurf
surpasses the previous state-of-the-art by a large margin for classification,
segmentation and detection on various benchmarks in terms of performance and
efficiency. With an increase of around \textbf{0.008M} number of parameters,
\textbf{0.04G} FLOPs, and \textbf{1.12ms} inference time, our method achieves
\textbf{94.7\%} (+0.5\%) on ModelNet40, and \textbf{84.6\%} (+1.8\%) on
ScanObjectNN for classification, while \textbf{74.3\%} (+0.8\%) mIoU on S3DIS
6-fold, and \textbf{70.0\%} (+1.6\%) mIoU on ScanNet for segmentation. For
detection, previous state-of-the-art detector with our RepSurf obtains
\textbf{71.2\%} (+2.1\%) mAP$\mathit{_{25}}$, \textbf{54.8\%} (+2.0\%)
mAP$\mathit{_{50}}$ on ScanNetV2, and \textbf{64.9\%} (+1.9\%)
mAP$\mathit{_{25}}$, \textbf{47.7\%} (+2.5\%) mAP$\mathit{_{50}}$ on SUN RGB-D.
Our lightweight Triangular RepSurf performs its excellence on these benchmarks
as well. The code is publicly available at
\url{https://github.com/hancyran/RepSurf}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MEWS: Real-time Social Media Manipulation Detection and Analysis. (arXiv:2205.05783v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05783">
<div class="article-summary-box-inner">
<span><p>This article presents a beta-version of MEWS (Misinformation Early Warning
System). It describes the various aspects of the ingestion, manipulation
detection, and graphing algorithms employed to determine--in near
real-time--the relationships between social media images as they emerge and
spread on social media platforms. By combining these various technologies into
a single processing pipeline, MEWS can identify manipulated media items as they
arise and identify when these particular items begin trending on individual
social media platforms or even across multiple platforms. The emergence of a
novel manipulation followed by rapid diffusion of the manipulated content
suggests a disinformation campaign.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">F3A-GAN: Facial Flow for Face Animation with Generative Adversarial Networks. (arXiv:2205.06204v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06204">
<div class="article-summary-box-inner">
<span><p>Formulated as a conditional generation problem, face animation aims at
synthesizing continuous face images from a single source image driven by a set
of conditional face motion. Previous works mainly model the face motion as
conditions with 1D or 2D representation (e.g., action units, emotion codes,
landmark), which often leads to low-quality results in some complicated
scenarios such as continuous generation and largepose transformation. To tackle
this problem, the conditions are supposed to meet two requirements, i.e.,
motion information preserving and geometric continuity. To this end, we propose
a novel representation based on a 3D geometric flow, termed facial flow, to
represent the natural motion of the human face at any pose. Compared with other
previous conditions, the proposed facial flow well controls the continuous
changes to the face. After that, in order to utilize the facial flow for face
editing, we build a synthesis framework generating continuous images with
conditional facial flows. To fully take advantage of the motion information of
facial flows, a hierarchical conditional framework is designed to combine the
extracted multi-scale appearance features from images and motion features from
flows in a hierarchical manner. The framework then decodes multiple fused
features back to images progressively. Experimental results demonstrate the
effectiveness of our method compared to other state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-05-16 23:08:48.097285752 UTC">2022-05-16 23:08:48 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>