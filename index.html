<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-12-28T01:30:00Z">12-28</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring Attribution in Natural Language Generation Models. (arXiv:2112.12870v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12870">
<div class="article-summary-box-inner">
<span><p>With recent improvements in natural language generation (NLG) models for
various applications, it has become imperative to have the means to identify
and evaluate whether NLG output is only sharing verifiable information about
the external world. In this work, we present a new evaluation framework
entitled Attributable to Identified Sources (AIS) for assessing the output of
natural language generation models, when such output pertains to the external
world. We first define AIS and introduce a two-stage annotation pipeline for
allowing annotators to appropriately evaluate model output according to AIS
guidelines. We empirically validate this approach on three generation datasets
(two in the conversational QA domain and one in summarization) via human
evaluation studies that suggest that AIS could serve as a common framework for
measuring whether model-generated statements are supported by underlying
sources. We release guidelines for the human evaluation studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spoiler in a Textstack: How Much Can Transformers Help?. (arXiv:2112.12913v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12913">
<div class="article-summary-box-inner">
<span><p>This paper presents our research regarding spoiler detection in reviews. In
this use case, we describe the method of fine-tuning and organizing the
available text-based model tasks with the latest deep learning achievements and
techniques to interpret the models' results.
</p>
<p>Until now, spoiler research has been rarely described in the literature. We
tested the transfer learning approach and different latest transformer
architectures on two open datasets with annotated spoilers (ROC AUC above 81\%
on TV Tropes Movies dataset, and Goodreads dataset above 88\%). We also
collected data and assembled a new dataset with fine-grained annotations. To
that end, we employed interpretability techniques and measures to assess the
models' reliability and explain their results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Memorization in Neural Language Models. (arXiv:2112.12938v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12938">
<div class="article-summary-box-inner">
<span><p>Modern neural language models widely used in tasks across NLP risk memorizing
sensitive information from their training data. As models continue to scale up
in parameters, training data, and compute, understanding memorization in
language models is both important from a learning-theoretical point of view,
and is practically crucial in real world applications. An open question in
previous studies of memorization in language models is how to filter out
"common" memorization. In fact, most memorization criteria strongly correlate
with the number of occurrences in the training set, capturing "common"
memorization such as familiar phrases, public knowledge or templated texts. In
this paper, we provide a principled perspective inspired by a taxonomy of human
memory in Psychology. From this perspective, we formulate a notion of
counterfactual memorization, which characterizes how a model's predictions
change if a particular document is omitted during training. We identify and
study counterfactually-memorized training examples in standard text datasets.
We further estimate the influence of each training example on the validation
set and on generated texts, and show that this can provide direct evidence of
the source of memorization at test time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing Scientific Publications using Domain-Specific Word Embedding and Topic Modelling. (arXiv:2112.12940v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12940">
<div class="article-summary-box-inner">
<span><p>The scientific world is changing at a rapid pace, with new technology being
developed and new trends being set at an increasing frequency. This paper
presents a framework for conducting scientific analyses of academic
publications, which is crucial to monitor research trends and identify
potential innovations. This framework adopts and combines various techniques of
Natural Language Processing, such as word embedding and topic modelling. Word
embedding is used to capture semantic meanings of domain-specific words. We
propose two novel scientific publication embedding, i.e., PUB-G and PUB-W,
which are capable of learning semantic meanings of general as well as
domain-specific words in various research fields. Thereafter, topic modelling
is used to identify clusters of research topics within these larger research
fields. We curated a publication dataset consisting of two conferences and two
journals from 1995 to 2020 from two research domains. Experimental results show
that our PUB-G and PUB-W embeddings are superior in comparison to other
baseline embeddings by a margin of ~0.18-1.03 based on topic coherence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distinguishing Transformative from Incremental Clinical Evidence: A Classifier of Clinical Research using Textual features from Abstracts and Citing Sentences. (arXiv:2112.12996v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12996">
<div class="article-summary-box-inner">
<span><p>In clinical research and clinical decision-making, it is important to know if
a study changes or only supports the current standards of care for specific
disease management. We define such a change as transformative and a support as
incremental research. It usually requires a huge amount of domain expertise and
time for humans to finish such tasks. Faculty Opinions provides us with a
well-annotated corpus on whether a research challenges or only confirms
established research. In this study, a machine learning approach is proposed to
distinguishing transformative from incremental clinical evidence. The texts
from both abstract and a 2-year window of citing sentences are collected for a
training set of clinical studies recommended and labeled by Faculty Opinions
experts. We achieve the best performance with an average AUC of 0.755
(0.705-0.875) using Random Forest as the classifier and citing sentences as the
feature. The results showed that transformative research has typical language
patterns in citing sentences unlike abstract sentences. We provide an efficient
tool for identifying those clinical evidence challenging or only confirming
established claims for clinicians and researchers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining Improvements for Exploiting Dependency Trees in Neural Semantic Parsing. (arXiv:2112.13179v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13179">
<div class="article-summary-box-inner">
<span><p>The dependency tree of a natural language sentence can capture the
interactions between semantics and words. However, it is unclear whether those
methods which exploit such dependency information for semantic parsing can be
combined to achieve further improvement and the relationship of those methods
when they combine. In this paper, we examine three methods to incorporate such
dependency information in a Transformer based semantic parser and empirically
study their combinations. We first replace standard self-attention heads in the
encoder with parent-scaled self-attention (PASCAL) heads, i.e., the ones that
can attend to the dependency parent of each token. Then we concatenate
syntax-aware word representations (SAWRs), i.e., the intermediate hidden
representations of a neural dependency parser, with ordinary word embedding to
enhance the encoder. Later, we insert the constituent attention (CA) module to
the encoder, which adds an extra constraint to attention heads that can better
capture the inherent dependency structure of input sentences. Transductive
ensemble learning (TEL) is used for model aggregation, and an ablation study is
conducted to show the contribution of each method. Our experiments show that CA
is complementary to PASCAL or SAWRs, and PASCAL + CA provides state-of-the-art
performance among neural approaches on ATIS, GEO, and JOBS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CABACE: Injecting Character Sequence Information and Domain Knowledge for Enhanced Acronym and Long-Form Extraction. (arXiv:2112.13237v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13237">
<div class="article-summary-box-inner">
<span><p>Acronyms and long-forms are commonly found in research documents, more so in
documents from scientific and legal domains. Many acronyms used in such
documents are domain-specific and are very rarely found in normal text corpora.
Owing to this, transformer-based NLP models often detect OOV (Out of
Vocabulary) for acronym tokens, especially for non-English languages, and their
performance suffers while linking acronyms to their long forms during
extraction. Moreover, pretrained transformer models like BERT are not
specialized to handle scientific and legal documents. With these points being
the overarching motivation behind this work, we propose a novel framework
CABACE: Character-Aware BERT for ACronym Extraction, which takes into account
character sequences in text and is adapted to scientific and legal domains by
masked language modelling. We further use an objective with an augmented loss
function, adding the max loss and mask loss terms to the standard cross-entropy
loss for training CABACE. We further leverage pseudo labelling and adversarial
data generation to improve the generalizability of the framework. Experimental
results prove the superiority of the proposed framework in comparison to
various baselines. Additionally, we show that the proposed framework is better
suited than baseline models for zero-shot generalization to non-English
languages, thus reinforcing the effectiveness of our approach. Our team
BacKGProp secured the highest scores on the French dataset, second-highest on
Danish and Vietnamese, and third-highest in the English-Legal dataset on the
global leaderboard for the acronym extraction (AE) shared task at SDU AAAI-22.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PerCQA: Persian Community Question Answering Dataset. (arXiv:2112.13238v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13238">
<div class="article-summary-box-inner">
<span><p>Community Question Answering (CQA) forums provide answers for many real-life
questions. Thanks to the large size, these forums are very popular among
machine learning researchers. Automatic answer selection, answer ranking,
question retrieval, expert finding, and fact-checking are example learning
tasks performed using CQA data. In this paper, we present PerCQA, the first
Persian dataset for CQA. This dataset contains the questions and answers
crawled from the most well-known Persian forum. After data acquisition, we
provide rigorous annotation guidelines in an iterative process, and then the
annotation of question-answer pairs in SemEvalCQA format. PerCQA contains 989
questions and 21,915 annotated answers. We make PerCQA publicly available to
encourage more research in Persian CQA. We also build strong benchmarks for the
task of answer selection in PerCQA by using mono- and multi-lingual pre-trained
language models
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Preliminary Study for Literary Rhyme Generation based on Neuronal Representation, Semantics and Shallow Parsing. (arXiv:2112.13241v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13241">
<div class="article-summary-box-inner">
<span><p>In recent years, researchers in the area of Computational Creativity have
studied the human creative process proposing different approaches to reproduce
it with a formal procedure. In this paper, we introduce a model for the
generation of literary rhymes in Spanish, combining structures of language and
neural network models %(\textit{Word2vec}).%, into a structure for semantic
assimilation. The results obtained with a manual evaluation of the texts
generated by our algorithm are encouraging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deeper Clinical Document Understanding Using Relation Extraction. (arXiv:2112.13259v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13259">
<div class="article-summary-box-inner">
<span><p>The surging amount of biomedical literature &amp; digital clinical records
presents a growing need for text mining techniques that can not only identify
but also semantically relate entities in unstructured data. In this paper we
propose a text mining framework comprising of Named Entity Recognition (NER)
and Relation Extraction (RE) models, which expands on previous work in three
main ways. First, we introduce two new RE model architectures -- an
accuracy-optimized one based on BioBERT and a speed-optimized one utilizing
crafted features over a Fully Connected Neural Network (FCNN). Second, we
evaluate both models on public benchmark datasets and obtain new
state-of-the-art F1 scores on the 2012 i2b2 Clinical Temporal Relations
challenge (F1 of 73.6, +1.2% over the previous SOTA), the 2010 i2b2 Clinical
Relations challenge (F1 of 69.1, +1.2%), the 2019 Phenotype-Gene Relations
dataset (F1 of 87.9, +8.5%), the 2012 Adverse Drug Events Drug-Reaction dataset
(F1 of 90.0, +6.3%), and the 2018 n2c2 Posology Relations dataset (F1 of 96.7,
+0.6%). Third, we show two practical applications of this framework -- for
building a biomedical knowledge graph and for improving the accuracy of mapping
entities to clinical codes. The system is built using the Spark NLP library
which provides a production-grade, natively scalable, hardware-optimized,
trainable &amp; tunable NLP framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stance Quantification: Definition of the Problem. (arXiv:2112.13288v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13288">
<div class="article-summary-box-inner">
<span><p>Stance detection is commonly defined as the automatic process of determining
the positions of text producers, towards a target. In this paper, we define a
research problem closely related to stance detection, namely, stance
quantification, for the first time. We define stance quantification on a pair
including (1) a set of natural language text items and (2) a target. At the end
of the stance quantification process, a triple is obtained which consists of
the percentages of the number of text items classified as Favor, Against,
Neither, respectively, towards the target in the input pair. Also defined in
the current paper is a significant subproblem of the stance quantification
problem, namely, multi-target stance quantification. We believe that stance
quantification at the aggregate level can lead to fruitful results in many
application settings, and furthermore, stance quantification might be the sole
stance related analysis alternative in settings where privacy concerns prevent
researchers from applying generic stance detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantum Algorithm for the Shortest Superstring Problem. (arXiv:2112.13319v1 [quant-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13319">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider the ``Shortest Superstring Problem''(SSP) or the
``Shortest Common Superstring Problem''(SCS). The problem is as follows. For a
positive integer $n$, a sequence of n strings $S=(s^1,\dots,s^n)$ is given. We
should construct the shortest string $t$ (we call it superstring) that contains
each string from the given sequence as a substring. The problem is connected
with the sequence assembly method for reconstructing a long DNA sequence from
small fragments. We present a quantum algorithm with running time
$O^*(1.728^n)$. Here $O^*$ notation does not consider polynomials of $n$ and
the length of $t$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Budget Sensitive Reannotation of Noisy Relation Classification Data Using Label Hierarchy. (arXiv:2112.13320v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13320">
<div class="article-summary-box-inner">
<span><p>Large crowd-sourced datasets are often noisy and relation classification (RC)
datasets are no exception. Reannotating the entire dataset is one probable
solution however it is not always viable due to time and budget constraints.
This paper addresses the problem of efficient reannotation of a large noisy
dataset for the RC. Our goal is to catch more annotation errors in the dataset
while reannotating fewer instances. Existing work on RC dataset reannotation
lacks the flexibility about how much data to reannotate. We introduce the
concept of a reannotation budget to overcome this limitation. The immediate
follow-up problem is: Given a specific reannotation budget, which subset of the
data should we reannotate? To address this problem, we present two strategies
to selectively reannotate RC datasets. Our strategies utilize the taxonomic
hierarchy of relation labels. The intuition of our work is to rely on the graph
distance between actual and predicted relation labels in the label hierarchy
graph. We evaluate our reannotation strategies on the well-known TACRED
dataset. We design our experiments to answer three specific research questions.
First, does our strategy select novel candidates for reannotation? Second, for
a given reannotation budget is our reannotation strategy more efficient at
catching annotation errors? Third, what is the impact of data reannotation on
RC model performance measurement? Experimental results show that our both
reannotation strategies are novel and efficient. Our analysis indicates that
the current reported performance of RC models on noisy TACRED data is inflated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Interdisciplinary Approach for the Automated Detection and Visualization of Media Bias in News Articles. (arXiv:2112.13352v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13352">
<div class="article-summary-box-inner">
<span><p>Media coverage has a substantial effect on the public perception of events.
Nevertheless, media outlets are often biased. One way to bias news articles is
by altering the word choice. The automatic identification of bias by word
choice is challenging, primarily due to the lack of gold-standard data sets and
high context dependencies. In this research project, I aim to devise data sets
and methods to identify media bias. To achieve this, I plan to research methods
using natural language processing and deep learning while employing models and
using analysis concepts from psychology and linguistics. The first results
indicate the effectiveness of an interdisciplinary research approach. My vision
is to devise a system that helps news readers become aware of media coverage
differences caused by bias. So far, my best performing BERT-based model is
pre-trained on a larger corpus consisting of distant labels, indicating that
distant supervision has the potential to become a solution for the difficult
task of bias detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Delivery Issues Identification from Customer Feedback Data. (arXiv:2112.13372v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13372">
<div class="article-summary-box-inner">
<span><p>Millions of packages are delivered successfully by online and local retail
stores across the world every day. The proper delivery of packages is needed to
ensure high customer satisfaction and repeat purchases. These deliveries suffer
various problems despite the best efforts from the stores. These issues happen
not only due to the large volume and high demand for low turnaround time but
also due to mechanical operations and natural factors. These issues range from
receiving wrong items in the package to delayed shipment to damaged packages
because of mishandling during transportation. Finding solutions to various
delivery issues faced by both sending and receiving parties plays a vital role
in increasing the efficiency of the entire process. This paper shows how to
find these issues using customer feedback from the text comments and uploaded
images. We used transfer learning for both Text and Image models to minimize
the demand for thousands of labeled examples. The results show that the model
can find different issues. Furthermore, it can also be used for tasks like
bottleneck identification, process improvement, automating refunds, etc.
Compared with the existing process, the ensemble of text and image models
proposed in this paper ensures the identification of several types of delivery
issues, which is more suitable for the real-life scenarios of delivery of items
in retail businesses. This method can supply a new idea of issue detection for
the delivery of packages in similar industries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArT: All-round Thinker for Unsupervised Commonsense Question-Answering. (arXiv:2112.13428v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13428">
<div class="article-summary-box-inner">
<span><p>Without labeled question-answer pairs for necessary training, unsupervised
commonsense question-answering (QA) appears to be extremely challenging due to
its indispensable unique prerequisite on commonsense source like knowledge
bases (KBs), which are usually highly resource consuming in construction.
Recently pre-trained language models (PrLMs) show effectiveness as an
alternative for commonsense clues when they play a role of knowledge generator.
However, existing work simply generates hundreds of pseudo-answers, or roughly
performs knowledge generation according to templates once for all, which may
result in much noise and thus hinders the quality of generated knowledge.
Motivated by human thinking experience, we propose an approach of All-round
Thinker (ArT) by fully taking association during knowledge generating. In
detail, our model first focuses on key parts in the given context, and then
generates highly related knowledge on such a basis in an association way like
human thinking. Besides, for casual reasoning, a reverse thinking mechanism is
proposed to conduct bidirectional inferring between cause and effect. ArT is
totally unsupervised and KBs-free. We evaluate it on three commonsense QA
benchmarks: COPA, SocialIQA and SCT. On all scales of PrLM backbones, ArT shows
its brilliant performance and outperforms previous advanced unsupervised
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">New Methods & Metrics for LFQA tasks. (arXiv:2112.13432v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13432">
<div class="article-summary-box-inner">
<span><p>Long-form question answering (LFQA) tasks require retrieving the documents
pertinent to a query, using them to form a paragraph-length answer. Despite
considerable progress in LFQA modeling, fundamental issues impede its progress:
i) train/validation/test dataset overlap, ii) absence of automatic metrics and
iii) generated answers not being "grounded" in retrieved documents. This work
addresses every one these critical bottlenecks, contributing natural language
inference/generation (NLI/NLG) methods and metrics that make significant
strides to their alleviation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event-based clinical findings extraction from radiology reports with pre-trained language model. (arXiv:2112.13512v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13512">
<div class="article-summary-box-inner">
<span><p>Radiology reports contain a diverse and rich set of clinical abnormalities
documented by radiologists during their interpretation of the images.
Comprehensive semantic representations of radiological findings would enable a
wide range of secondary use applications to support diagnosis, triage, outcomes
prediction, and clinical research. In this paper, we present a new corpus of
radiology reports annotated with clinical findings. Our annotation schema
captures detailed representations of pathologic findings that are observable on
imaging ("lesions") and other types of clinical problems ("medical problems").
The schema used an event-based representation to capture fine-grained details,
including assertion, anatomy, characteristics, size, count, etc. Our gold
standard corpus contained a total of 500 annotated computed tomography (CT)
reports. We extracted triggers and argument entities using two state-of-the-art
deep learning architectures, including BERT. We then predicted the linkages
between trigger and argument entities (referred to as argument roles) using a
BERT-based relation extraction model. We achieved the best extraction
performance using a BERT model pre-trained on 3 million radiology reports from
our institution: 90.9%-93.4% F1 for finding triggers 72.0%-85.6% F1 for
arguments roles. To assess model generalizability, we used an external
validation set randomly sampled from the MIMIC Chest X-ray (MIMIC-CXR)
database. The extraction performance on this validation set was 95.6% for
finding triggers and 79.1%-89.7% for argument roles, demonstrating that the
model generalized well to the cross-institutional data with a different imaging
modality. We extracted the finding events from all the radiology reports in the
MIMIC-CXR database and provided the extractions to the research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Personalized Answer Generation in E-Commerce via Multi-Perspective Preference Modeling. (arXiv:2112.13556v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13556">
<div class="article-summary-box-inner">
<span><p>Recently, Product Question Answering (PQA) on E-Commerce platforms has
attracted increasing attention as it can act as an intelligent online shopping
assistant and improve the customer shopping experience. Its key function,
automatic answer generation for product-related questions, has been studied by
aiming to generate content-preserving while question-related answers. However,
an important characteristic of PQA, i.e., personalization, is neglected by
existing methods. It is insufficient to provide the same "completely
summarized" answer to all customers, since many customers are more willing to
see personalized answers with customized information only for themselves, by
taking into consideration their own preferences towards product aspects or
information needs. To tackle this challenge, we propose a novel Personalized
Answer GEneration method (PAGE) with multi-perspective preference modeling,
which explores historical user-generated contents to model user preference for
generating personalized answers in PQA. Specifically, we first retrieve
question-related user history as external knowledge to model knowledge-level
user preference. Then we leverage Gaussian Softmax distribution model to
capture latent aspect-level user preference. Finally, we develop a
persona-aware pointer network to generate personalized answers in terms of both
content and style by utilizing personal user preference and dynamic user
vocabulary. Experimental results on real-world E-Commerce QA datasets
demonstrate that the proposed method outperforms existing methods by generating
informative and customized answers, and show that answer generation in
E-Commerce can benefit from personalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chinese Learners' Phonetic Transfer of /i/ from Mandarin Chinese to General American English: Evidence from Perception and Production Experiments. (arXiv:2112.13571v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13571">
<div class="article-summary-box-inner">
<span><p>Ever since the development of Contrastive Analysis (CA) in the 1950s, which
focuses on comparing and contrasting two language systems, linguists have
started to systematically explore the influence of the mother tongue on
acquiring a second language. This phenomenon is later defined as "language
transfer". The current paper concerns language transfer at the phonetic level
and concentrates on the transfer phenomenon existing in advanced-level Chinese
learners' acquisition of English vowels /i/ and its lax counterpart. By
determining whether advanced-level Chinese English-language learners (ELLs) can
accurately distinguish between /i/ and its lax counterpart, and pronounce them
in English words precisely, this paper serves as a reference for further
studying Chinese ELLs' language transfer. Two objectives were to be met:
firstly, learners' perceptual ability to distinguish between vowels /i/ and its
lax counterpart should be examined; and secondly, the effect of the phonetic
transfer should be determined. A perception test and a production test were
used to attain these two objectives. Both tests were completed by 12
advanced-level Chinese ELLs, six males and six females. Results indicate that
both male and female participants could consciously distinguish between /i/ and
its lax counterpart. All participants have signs of experiencing negative
phonetic transfer in their pronunciation, except that the current data do not
decisively reflect an impact of the phonetic transfer on female ELLs'
acquisition of the high front lax vowel in English words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Polite Emotional Dialogue Acts for Conversational Analysis in Dialy Dialog Data. (arXiv:2112.13572v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13572">
<div class="article-summary-box-inner">
<span><p>Many socio-linguistic cues are used in the conversational analysis, such as
emotion, sentiment, and dialogue acts. One of the fundamental social cues is
politeness, which linguistically possesses properties useful in conversational
analysis. This short article presents some of the brief findings of polite
emotional dialogue acts, where we can correlate the relational bonds between
these socio-linguistics cues. We found that the utterances with emotion classes
Anger and Disgust are more likely to be impolite while Happiness and Sadness to
be polite. Similar phenomenon occurs with dialogue acts, Inform and Commissive
contain many polite utterances than Question and Directive. Finally, we will
conclude on the future work of these findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal Attention Network for Stock Movements Prediction. (arXiv:2112.13593v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13593">
<div class="article-summary-box-inner">
<span><p>Stock prices move as piece-wise trending fluctuation rather than a purely
random walk. Traditionally, the prediction of future stock movements is based
on the historical trading record. Nowadays, with the development of social
media, many active participants in the market choose to publicize their
strategies, which provides a window to glimpse over the whole market's attitude
towards future movements by extracting the semantics behind social media.
However, social media contains conflicting information and cannot replace
historical records completely. In this work, we propose a multi-modality
attention network to reduce conflicts and integrate semantic and numeric
features to predict future stock movements comprehensively. Specifically, we
first extract semantic information from social media and estimate their
credibility based on posters' identity and public reputation. Then we
incorporate the semantic from online posts and numeric features from historical
records to make the trading strategy. Experimental results show that our
approach outperforms previous methods by a significant margin in both
prediction accuracy (61.20\%) and trading profits (9.13\%). It demonstrates
that our method improves the performance of stock movements prediction and
informs future research on multi-modality fusion towards stock prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HeteroQA: Learning towards Question-and-Answering through Multiple Information Sources via Heterogeneous Graph Modeling. (arXiv:2112.13597v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13597">
<div class="article-summary-box-inner">
<span><p>Community Question Answering (CQA) is a well-defined task that can be used in
many scenarios, such as E-Commerce and online user community for special
interests.
</p>
<p>In these communities, users can post articles, give comment, raise a question
and answer it.
</p>
<p>These data form the heterogeneous information sources where each information
source have their own special structure and context (comments attached to an
article or related question with answers).
</p>
<p>Most of the CQA methods only incorporate articles or Wikipedia to extract
knowledge and answer the user's question.
</p>
<p>However, various types of information sources in the community are not fully
explored by these CQA methods and these multiple information sources (MIS) can
provide more related knowledge to user's questions.
</p>
<p>Thus, we propose a question-aware heterogeneous graph transformer to
incorporate the MIS in the user community to automatically generate the answer.
</p>
<p>To evaluate our proposed method, we conduct the experiments on two datasets:
$\text{MSM}^{\text{plus}}$ the modified version of benchmark dataset MS-MARCO
and the AntQA dataset which is the first large-scale CQA dataset with four
types of MIS.
</p>
<p>Extensive experiments on two datasets show that our model outperforms all the
baselines in terms of all the metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CUGE: A Chinese Language Understanding and Generation Evaluation Benchmark. (arXiv:2112.13610v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13610">
<div class="article-summary-box-inner">
<span><p>Realizing general-purpose language intelligence has been a longstanding goal
for natural language processing, where standard evaluation benchmarks play a
fundamental and guiding role. We argue that for general-purpose language
intelligence evaluation, the benchmark itself needs to be comprehensive and
systematic. To this end, we propose CUGE, a Chinese Language Understanding and
Generation Evaluation benchmark with the following features: (1) Hierarchical
benchmark framework, where datasets are principally selected and organized with
a language capability-task-dataset hierarchy. (2) Multi-level scoring strategy,
where different levels of model performance are provided based on the
hierarchical framework. To facilitate CUGE, we provide a public leaderboard
that can be customized to support flexible model judging criteria. Evaluation
results on representative pre-trained language models indicate ample room for
improvement towards general-purpose language intelligence. CUGE is publicly
available at cuge.baai.ac.cn.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parameter Differentiation based Multilingual Neural Machine Translation. (arXiv:2112.13619v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13619">
<div class="article-summary-box-inner">
<span><p>Multilingual neural machine translation (MNMT) aims to translate multiple
languages with a single model and has been proved successful thanks to
effective knowledge transfer among different languages with shared parameters.
However, it is still an open question which parameters should be shared and
which ones need to be task-specific. Currently, the common practice is to
heuristically design or search language-specific modules, which is difficult to
find the optimal configuration. In this paper, we propose a novel parameter
differentiation based method that allows the model to determine which
parameters should be language-specific during training. Inspired by cellular
differentiation, each shared parameter in our method can dynamically
differentiate into more specialized types. We further define the
differentiation criterion as inter-task gradient similarity. Therefore,
parameters with conflicting inter-task gradients are more likely to be
language-specific. Extensive experiments on multilingual datasets have
demonstrated that our method significantly outperforms various strong baselines
with different parameter sharing configurations. Further analyses reveal that
the parameter sharing configuration obtained by our method correlates well with
the linguistic proximities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on non-English Question Answering Dataset. (arXiv:2112.13634v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13634">
<div class="article-summary-box-inner">
<span><p>Research in question answering datasets and models has gained a lot of
attention in the research community. Many of them release their own question
answering datasets as well as the models. There is tremendous progress that we
have seen in this area of research. The aim of this survey is to recognize,
summarize and analyze the existing datasets that have been released by many
researchers, especially in non-English datasets as well as resources such as
research code, and evaluation metrics. In this paper, we review question
answering datasets that are available in common languages other than English
such as French, German, Japanese, Chinese, Arabic, Russian, as well as the
multilingual and cross-lingual question-answering datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Empathetic Responses by Looking Ahead the User's Sentiment. (arXiv:1906.08487v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.08487">
<div class="article-summary-box-inner">
<span><p>An important aspect of human conversation difficult for machines is
conversing with empathy, which is to understand the user's emotion and respond
appropriately. Recent neural conversation models that attempted to generate
empathetic responses either focused on conditioning the output to a given
emotion, or incorporating the current user emotional state. However, these
approaches do not factor in how the user would feel towards the generated
response. Hence, in this paper, we propose Sentiment Look-ahead, which is a
novel perspective for empathy that models the future user emotional state. In
short, Sentiment Look-ahead is a reward function under a reinforcement learning
framework that provides a higher reward to the generative model when the
generated utterance improves the user's sentiment. We implement and evaluate
three different possible implementations of sentiment look-ahead and
empirically show that our proposed approach can generate significantly more
empathetic, relevant, and fluent responses than other competitive baselines
such as multitask learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controllable Data Synthesis Method for Grammatical Error Correction. (arXiv:1909.13302v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.13302">
<div class="article-summary-box-inner">
<span><p>Due to the lack of parallel data in current Grammatical Error Correction
(GEC) task, models based on Sequence to Sequence framework cannot be adequately
trained to obtain higher performance. We propose two data synthesis methods
which can control the error rate and the ratio of error types on synthetic
data. The first approach is to corrupt each word in the monolingual corpus with
a fixed probability, including replacement, insertion and deletion. Another
approach is to train error generation models and further filtering the decoding
results of the models. The experiments on different synthetic data show that
the error rate is 40% and the ratio of error types is the same can improve the
model performance better. Finally, we synthesize about 100 million data and
achieve comparable performance as the state of the art, which uses twice as
much data as we use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Higher Criticism for Discriminating Word-Frequency Tables and Testing Authorship. (arXiv:1911.01208v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.01208">
<div class="article-summary-box-inner">
<span><p>We adapt the Higher Criticism (HC) goodness-of-fit test to measure the
closeness between word-frequency tables. We apply this measure to authorship
attribution challenges, where the goal is to identify the author of a document
using other documents whose authorship is known. The method is simple yet
performs well without handcrafting and tuning; reporting accuracy at the state
of the art level in various current challenges. As an inherent side effect, the
HC calculation identifies a subset of discriminating words. In practice, the
identified words have low variance across documents belonging to a corpus of
homogeneous authorship. We conclude that in comparing the similarity of a new
document and a corpus of a single author, HC is mostly affected by words
characteristic of the author and is relatively unaffected by topic structure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Backpropagation through Signal Temporal Logic Specifications: Infusing Logical Structure into Gradient-Based Methods. (arXiv:2008.00097v3 [eess.SY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00097">
<div class="article-summary-box-inner">
<span><p>This paper presents a technique, named STLCG, to compute the quantitative
semantics of Signal Temporal Logic (STL) formulas using computation graphs.
STLCG provides a platform which enables the incorporation of logical
specifications into robotics problems that benefit from gradient-based
solutions. Specifically, STL is a powerful and expressive formal language that
can specify spatial and temporal properties of signals generated by both
continuous and hybrid systems. The quantitative semantics of STL provide a
robustness metric, i.e., how much a signal satisfies or violates an STL
specification. In this work, we devise a systematic methodology for translating
STL robustness formulas into computation graphs. With this representation, and
by leveraging off-the-shelf automatic differentiation tools, we are able to
efficiently backpropagate through STL robustness formulas and hence enable a
natural and easy-to-use integration of STL specifications with many
gradient-based approaches used in robotics. Through a number of examples
stemming from various robotics applications, we demonstrate that STLCG is
versatile, computationally efficient, and capable of incorporating human-domain
knowledge into the problem formulation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Optimality of Vagueness: "Around", "Between", and the Gricean Maxims. (arXiv:2008.11841v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11841">
<div class="article-summary-box-inner">
<span><p>Why is ordinary language vague? We argue that in contexts in which a
cooperative speaker is not perfectly informed about the world, the use of vague
expressions can offer an optimal tradeoff between truthfulness (Gricean
Quality) and informativeness (Gricean Quantity). Focusing on expressions of
approximation such as "around", which are semantically vague, we show that they
allow the speaker to convey indirect probabilistic information, in a way that
can give the listener a more accurate representation of the information
available to the speaker than any more precise expression would (intervals of
the form "between"). That is, vague sentences can be more informative than
their precise counterparts. We give a probabilistic treatment of the
interpretation of "around", and offer a model for the interpretation and use of
"around"-statements within the Rational Speech Act (RSA) framework. In our
account the shape of the speaker's distribution matters in ways not predicted
by the Lexical Uncertainty model standardly used in the RSA framework for vague
predicates. We use our approach to draw further lessons concerning the semantic
flexibility of vague expressions and their irreducibility to more precise
meanings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Robustness and Bias Analysis of BERT-based Relation Extraction. (arXiv:2009.06206v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06206">
<div class="article-summary-box-inner">
<span><p>Fine-tuning pre-trained models have achieved impressive performance on
standard natural language processing benchmarks. However, the resultant model
generalizability remains poorly understood. We do not know, for example, how
excellent performance can lead to the perfection of generalization models. In
this study, we analyze a fine-tuned BERT model from different perspectives
using relation extraction. We also characterize the differences in
generalization techniques according to our proposed improvements. From
empirical experimentation, we find that BERT suffers a bottleneck in terms of
robustness by way of randomizations, adversarial and counterfactual tests, and
biases (i.e., selection and semantic). These findings highlight opportunities
for future improvements. Our open-sourced testbed DiagnoseRE is available in
\url{https://github.com/zjunlp/DiagnoseRE}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reflective Decoding: Beyond Unidirectional Generation with Off-the-Shelf Language Models. (arXiv:2010.08566v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08566">
<div class="article-summary-box-inner">
<span><p>Publicly available, large pretrained LanguageModels (LMs) generate text with
remarkable quality, but only sequentially from left to right. As a result, they
are not immediately applicable to generation tasks that break the
unidirectional assumption, such as paraphrasing or text-infilling,
necessitating task-specific supervision.
</p>
<p>In this paper, we present Reflective Decoding, a novel unsupervised algorithm
that allows for direct application of unidirectional LMs to non-sequential
tasks. Our 2-step approach requires no supervision or even parallel corpora,
only two off-the-shelf pretrained LMs in opposite directions: forward and
backward. First, in the contextualization step, we use LMs to generate
ensembles of past and future contexts which collectively capture the input
(e.g. the source sentence for paraphrasing). Second, in the reflection step, we
condition on these "context ensembles", generating outputs that are compatible
with them. Comprehensive empirical results demonstrate that Reflective Decoding
outperforms strong unsupervised baselines on both paraphrasing and abductive
text infilling, significantly narrowing the gap between unsupervised and
supervised methods. Reflective Decoding surpasses multiple supervised baselines
on various metrics including human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WeNet: Production oriented Streaming and Non-streaming End-to-End Speech Recognition Toolkit. (arXiv:2102.01547v4 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01547">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose an open source, production first, and production
ready speech recognition toolkit called WeNet in which a new two-pass approach
is implemented to unify streaming and non-streaming end-to-end (E2E) speech
recognition in a single model. The main motivation of WeNet is to close the gap
between the research and the production of E2E speechrecognition models. WeNet
provides an efficient way to ship ASR applications in several real-world
scenarios, which is the main difference and advantage to other open source E2E
speech recognition toolkits. In our toolkit, a new two-pass method is
implemented. Our method propose a dynamic chunk-based attention strategy of the
the transformer layers to allow arbitrary right context length modifies in
hybrid CTC/attention architecture. The inference latency could be easily
controlled by only changing the chunk size. The CTC hypotheses are then
rescored by the attention decoder to get the final result. Our experiments on
the AISHELL-1 dataset using WeNet show that, our model achieves 5.03\% relative
character error rate (CER) reduction in non-streaming ASR compared to a
standard non-streaming transformer. After model quantification, our model
perform reasonable RTF and latency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Node Co-occurrence based Graph Neural Networks for Knowledge Graph Link Prediction. (arXiv:2104.07396v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07396">
<div class="article-summary-box-inner">
<span><p>We introduce a novel embedding model, named NoGE, which aims to integrate
co-occurrence among entities and relations into graph neural networks to
improve knowledge graph completion (i.e., link prediction). Given a knowledge
graph, NoGE constructs a single graph considering entities and relations as
individual nodes. NoGE then computes weights for edges among nodes based on the
co-occurrence of entities and relations. Next, NoGE proposes Dual Quaternion
Graph Neural Networks (DualQGNN) and utilizes DualQGNN to update vector
representations for entity and relation nodes. NoGE then adopts a score
function to produce the triple scores. Comprehensive experimental results show
that NoGE obtains state-of-the-art results on three new and difficult benchmark
datasets CoDEx for knowledge graph completion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter. (arXiv:2105.07148v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07148">
<div class="article-summary-box-inner">
<span><p>Lexicon information and pre-trained models, such as BERT, have been combined
to explore Chinese sequence labelling tasks due to their respective strengths.
However, existing methods solely fuse lexicon features via a shallow and random
initialized sequence layer and do not integrate them into the bottom layers of
BERT. In this paper, we propose Lexicon Enhanced BERT (LEBERT) for Chinese
sequence labelling, which integrates external lexicon knowledge into BERT
layers directly by a Lexicon Adapter layer. Compared with the existing methods,
our model facilitates deep lexicon knowledge fusion at the lower layers of
BERT. Experiments on ten Chinese datasets of three tasks including Named Entity
Recognition, Word Segmentation, and Part-of-Speech tagging, show that LEBERT
achieves the state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Killing One Bird with Two Stones: Model Extraction and Attribute Inference Attacks against BERT-based APIs. (arXiv:2105.10909v2 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10909">
<div class="article-summary-box-inner">
<span><p>The collection and availability of big data, combined with advances in
pre-trained models (e.g., BERT, XLNET, etc), have revolutionized the predictive
performance of modern natural language processing tasks, ranging from text
classification to text generation. This allows corporations to provide machine
learning as a service (MLaaS) by encapsulating fine-tuned BERT-based models as
APIs. However, BERT-based APIs have exhibited a series of security and privacy
vulnerabilities. For example, prior work has exploited the security issues of
the BERT-based APIs through the adversarial examples crafted by the extracted
model. However, the privacy leakage problems of the BERT-based APIs through the
extracted model have not been well studied. On the other hand, due to the high
capacity of BERT-based APIs, the fine-tuned model is easy to be overlearned,
but what kind of information can be leaked from the extracted model remains
unknown. In this work, we bridge this gap by first presenting an effective
model extraction attack, where the adversary can practically steal a BERT-based
API (the target/victim model) by only querying a limited number of queries. We
further develop an effective attribute inference attack which can infer the
sensitive attribute of the training data used by the BERT-based APIs. Our
extensive experiments on benchmark datasets under various realistic settings
validate the potential vulnerabilities of BERT-based APIs. Moreover, we
demonstrate that two promising defense methods become ineffective against our
attacks, which calls for more effective defense methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatically Detecting Cyberbullying Comments on Online Game Forums. (arXiv:2106.01598v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01598">
<div class="article-summary-box-inner">
<span><p>Online game forums are popular to most of game players. They use it to
communicate and discuss the strategy of the game, or even to make friends.
However, game forums also contain abusive and harassment speech, disturbing and
threatening players. Therefore, it is necessary to automatically detect and
remove cyberbullying comments to keep the game forum clean and friendly. We use
the Cyberbullying dataset collected from World of Warcraft (WoW) and League of
Legends (LoL) forums and train classification models to automatically detect
whether a comment of a player is abusive or not. The result obtains 82.69% of
macro F1-score for LoL forum and 83.86% of macro F1-score for WoW forum by the
Toxic-BERT model on the Cyberbullying dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mischievous Nominal Constructions in Universal Dependencies. (arXiv:2108.12928v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12928">
<div class="article-summary-box-inner">
<span><p>While the highly multilingual Universal Dependencies (UD) project provides
extensive guidelines for clausal structure as well as structure within
canonical nominal phrases, a standard treatment is lacking for many
"mischievous" nominal phenomena that break the mold. As a result, numerous
inconsistencies within and across corpora can be found, even in languages with
extensive UD treebanking work, such as English. This paper surveys the kinds of
mischievous nominal expressions attested in English UD corpora and proposes
solutions primarily with English in mind, but which may offer paths to
solutions for a variety of UD languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Language-specificity of Multilingual BERT and the Impact of Fine-tuning. (arXiv:2109.06935v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06935">
<div class="article-summary-box-inner">
<span><p>Recent work has shown evidence that the knowledge acquired by multilingual
BERT (mBERT) has two components: a language-specific and a language-neutral
one. This paper analyses the relationship between them, in the context of
fine-tuning on two tasks -- POS tagging and natural language inference -- which
require the model to bring to bear different degrees of language-specific
knowledge. Visualisations reveal that mBERT loses the ability to cluster
representations by language after fine-tuning, a result that is supported by
evidence from language identification experiments. However, further experiments
on 'unlearning' language-specific representations using gradient reversal and
iterative adversarial learning are shown not to add further improvement to the
language-independent component over and above the effect of fine-tuning. The
results presented here suggest that the process of fine-tuning causes a
reorganisation of the model's limited representational capacity, enhancing
language-independent representations at the expense of language-specific ones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FST Morphological Analyser and Generator for Mapud\"ungun. (arXiv:2109.09176v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09176">
<div class="article-summary-box-inner">
<span><p>Following the Mapuche grammar by Smeets, this article describes the main
morphophonological aspects of Mapud\"ungun, explaining what triggers them and
the contexts where they arise. We present a computational approach producing a
finite state morphological analyser (and generator) capable of classifying and
appropriately tagging all the components (roots and suffixes) that interact in
a Mapuche word form. The bulk of the article focuses on presenting details
about the morphology of Mapud\"ungun verb and its formalisation using FOMA. A
system evaluation process and its results are also present in this article.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XLM-K: Improving Cross-Lingual Language Model Pre-Training with Multilingual Knowledge. (arXiv:2109.12573v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12573">
<div class="article-summary-box-inner">
<span><p>Cross-lingual pre-training has achieved great successes using monolingual and
bilingual plain text corpora. However, most pre-trained models neglect
multilingual knowledge, which is language agnostic but comprises abundant
cross-lingual structure alignment. In this paper, we propose XLM-K, a
cross-lingual language model incorporating multilingual knowledge in
pre-training. XLM-K augments existing multilingual pre-training with two
knowledge tasks, namely Masked Entity Prediction Task and Object Entailment
Task. We evaluate XLM-K on MLQA, NER and XNLI. Experimental results clearly
demonstrate significant improvements over existing multilingual language
models. The results on MLQA and NER exhibit the superiority of XLM-K in
knowledge related tasks. The success in XNLI shows a better cross-lingual
transferability obtained in XLM-K. What is more, we provide a detailed probing
analysis to confirm the desired knowledge captured in our pre-training regimen.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsolved Problems in ML Safety. (arXiv:2109.13916v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13916">
<div class="article-summary-box-inner">
<span><p>Machine learning (ML) systems are rapidly increasing in size, are acquiring
new capabilities, and are increasingly deployed in high-stakes settings. As
with other powerful technologies, safety for ML should be a leading research
priority. In response to emerging safety challenges in ML, such as those
introduced by recent large-scale models, we provide a new roadmap for ML Safety
and refine the technical problems that the field needs to address. We present
four problems ready for research, namely withstanding hazards ("Robustness"),
identifying hazards ("Monitoring"), steering ML systems ("Alignment"), and
reducing deployment hazards ("External Safety"). Throughout, we clarify each
problem's motivation and provide concrete research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Model Supervised by Understanding Map. (arXiv:2110.06043v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06043">
<div class="article-summary-box-inner">
<span><p>Inspired by the notion of Center of Mass in physics, an extension called
Semantic Center of Mass (SCOM) is proposed, and used to discover the abstract
"topic" of a document. The notion is under a framework model called
Understanding Map Supervised Topic Model (UM-S-TM). The devise aim of UM-S-TM
is to let both the document content and a semantic network -- specifically,
Understanding Map -- play a role, in interpreting the meaning of a document.
Based on different justifications, three possible methods are devised to
discover the SCOM of a document. Some experiments on artificial documents and
Understanding Maps are conducted to test their outcomes. In addition, its
ability of vectorization of documents and capturing sequential information are
tested. We also compared UM-S-TM with probabilistic topic models like Latent
Dirichlet Allocation (LDA) and probabilistic Latent Semantic Analysis (pLSA).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Evaluation and Moderation of Open-domain Dialogue Systems. (arXiv:2111.02110v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02110">
<div class="article-summary-box-inner">
<span><p>The development of Open-Domain Dialogue Systems (ODS)is a trending topic due
to the large number of research challenges, large societal and business impact,
and advances in the underlying technology. However, the development of these
kinds of systems requires two important characteristics:1) automatic evaluation
mechanisms that show high correlations with human judgements across multiple
dialogue evaluation aspects (with explainable features for providing
constructive and explicit feedback on the quality of generative models'
responses for quick development and deployment)and 2) mechanisms that can help
to control chatbot responses,while avoiding toxicity and employing intelligent
ways to handle toxic user comments and keeping interaction flow and engagement.
This track at the 10th Dialogue System Technology Challenge (DSTC10) is part of
the ongoing effort to promote scalable and toxic-free ODS. This paper describes
the datasets and baselines provided to participants, as well as submission
evaluation results for each of the two proposed subtasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Profitable Trade-Off Between Memory and Performance In Multi-Domain Chatbot Architectures. (arXiv:2111.03963v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03963">
<div class="article-summary-box-inner">
<span><p>Text classification problem is a very broad field of study in the field of
natural language processing. In short, the text classification problem is to
determine which of the previously determined classes the given text belongs to.
Successful studies have been carried out in this field in the past studies. In
the study, Bidirectional Encoder Representations for Transformers (BERT), which
is a frequently preferred method for solving the classification problem in the
field of natural language processing, is used. By solving classification
problems through a single model to be used in a chatbot architecture, it is
aimed to alleviate the load on the server that will be created by more than one
model used for solving more than one classification problem. At this point,
with the masking method applied during the estimation of a single BERT model,
which was created for classification in more than one subject, the estimation
of the model was provided on a problem-based basis. Three separate data sets
covering different fields from each other are divided by various methods in
order to complicate the problem, and classification problems that are very
close to each other in terms of field are also included in this way. The
dataset used in this way consists of five classification problems with 154
classes. A BERT model containing all classification problems and other BERT
models trained specifically for the problems were compared with each other in
terms of performance and the space they occupied on the server.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-Supervised Learning and Explicit Policy Injection. (arXiv:2111.14592v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.14592">
<div class="article-summary-box-inner">
<span><p>Pre-trained models have proved to be powerful in enhancing task-oriented
dialog systems. However, current pre-training methods mainly focus on enhancing
dialog understanding and generation tasks while neglecting the exploitation of
dialog policy. In this paper, we propose GALAXY, a novel pre-trained dialog
model that explicitly learns dialog policy from limited labeled dialogs and
large-scale unlabeled dialog corpora via semi-supervised learning.
Specifically, we introduce a dialog act prediction task for policy optimization
during pre-training and employ a consistency regularization term to refine the
learned representation with the help of unlabeled dialogs. We also implement a
gating mechanism to weigh suitable unlabeled dialog samples. Empirical results
show that GALAXY substantially improves the performance of task-oriented dialog
systems, and achieves new state-of-the-art results on benchmark datasets:
In-Car, MultiWOZ2.0 and MultiWOZ2.1, improving their end-to-end combined scores
by 2.5, 5.3 and 5.5 points, respectively. We also show that GALAXY has a
stronger few-shot ability than existing models under various low-resource
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GKS: Graph-based Knowledge Selector for Task-oriented Dialog System. (arXiv:2112.03719v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03719">
<div class="article-summary-box-inner">
<span><p>In previous research, knowledge-selection tasks mostly rely on language
model-based methods or knowledge ranking. However, while approaches that rely
on the language models take all knowledge as sequential input, knowledge does
not contain sequential information in most circumstances. On the other hand,
the knowledge-ranking methods leverage dialog history and each given knowledge
snippet separately, but they do not consider information between knowledge
snippets. In the Tenth Dialog System Technology Challenges (DSTC10), we
participated in the second Knowledge-grounded Task-oriented Dialogue Modeling
on Spoken Conversations. To deal with the problems mentioned above, we modified
training methods based on state-of-the-art (SOTA) models for the first and
third sub-tasks. As for the second sub-task of knowledge selection, we proposed
Graph-Knowledge Selector (GKS), utilizing a graph-attention base model
incorporated with the language model. GKS makes knowledge-selection decisions
in the dialog by simultaneously considering each knowledge embedding generated
from the language model without sequential features. Moreover, GKS leverages
considerable knowledge in decision-making and takes relations across knowledge
as part of the selection process. As a result, GKS outperforms several SOTA
models proposed in the data-set on knowledge selection from the Ninth Dialog
System Technology Challenges (DSTC9).
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Attention Generative Adversarial Network for Iterative Reconstruction of CT Images. (arXiv:2112.12810v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12810">
<div class="article-summary-box-inner">
<span><p>Computed tomography (CT) uses X-ray measurements taken from sensors around
the body to generate tomographic images of the human body. Conventional
reconstruction algorithms can be used if the X-ray data are adequately sampled
and of high quality; however, concerns such as reducing dose to the patient, or
geometric limitations on data acquisition, may result in low quality or
incomplete data. Images reconstructed from these data using conventional
methods are of poor quality, due to noise and other artifacts. The aim of this
study is to train a single neural network to reconstruct high-quality CT images
from noisy or incomplete CT scan data, including low-dose, sparse-view, and
limited-angle scenarios. To accomplish this task, we train a generative
adversarial network (GAN) as a signal prior, to be used in conjunction with the
iterative simultaneous algebraic reconstruction technique (SART) for CT data.
The network includes a self-attention block to model long-range dependencies in
the data. We compare our Self-Attention GAN for CT image reconstruction with
several state-of-the-art approaches, including denoising cycle GAN, CIRCLE GAN,
and a total variation superiorized algorithm. Our approach is shown to have
comparable overall performance to CIRCLE GAN, while outperforming the other two
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MDN-VO: Estimating Visual Odometry with Confidence. (arXiv:2112.12812v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12812">
<div class="article-summary-box-inner">
<span><p>Visual Odometry (VO) is used in many applications including robotics and
autonomous systems. However, traditional approaches based on feature matching
are computationally expensive and do not directly address failure cases,
instead relying on heuristic methods to detect failure. In this work, we
propose a deep learning-based VO model to efficiently estimate 6-DoF poses, as
well as a confidence model for these estimates. We utilise a CNN - RNN hybrid
model to learn feature representations from image sequences. We then employ a
Mixture Density Network (MDN) which estimates camera motion as a mixture of
Gaussians, based on the extracted spatio-temporal representations. Our model
uses pose labels as a source of supervision, but derives uncertainties in an
unsupervised manner. We evaluate the proposed model on the KITTI and nuScenes
datasets and report extensive quantitative and qualitative results to analyse
the performance of both pose and uncertainty estimation. Our experiments show
that the proposed model exceeds state-of-the-art performance in addition to
detecting failure cases using the predicted pose uncertainty.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Camera Sensor Fusion for Visual Odometry using Deep Uncertainty Estimation. (arXiv:2112.12818v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12818">
<div class="article-summary-box-inner">
<span><p>Visual Odometry (VO) estimation is an important source of information for
vehicle state estimation and autonomous driving. Recently, deep learning based
approaches have begun to appear in the literature. However, in the context of
driving, single sensor based approaches are often prone to failure because of
degraded image quality due to environmental factors, camera placement, etc. To
address this issue, we propose a deep sensor fusion framework which estimates
vehicle motion using both pose and uncertainty estimations from multiple
on-board cameras. We extract spatio-temporal feature representations from a set
of consecutive images using a hybrid CNN - RNN model. We then utilise a Mixture
Density Network (MDN) to estimate the 6-DoF pose as a mixture of distributions
and a fusion module to estimate the final pose using MDN outputs from
multi-cameras. We evaluate our approach on the publicly available, large scale
autonomous vehicle dataset, nuScenes. The results show that the proposed fusion
approach surpasses the state-of-the-art, and provides robust estimates and
accurate trajectories compared to individual camera-based estimations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dense anomaly detection by robust learning on synthetic negative data. (arXiv:2112.12833v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12833">
<div class="article-summary-box-inner">
<span><p>Standard machine learning is unable to accommodate inputs which do not belong
to the training distribution. The resulting models often give rise to confident
incorrect predictions which may lead to devastating consequences. This problem
is especially demanding in the context of dense prediction since input images
may be partially anomalous. Previous work has addressed dense anomaly detection
by discriminative training on mixed-content images. We extend this approach
with synthetic negative patches which simultaneously achieve high inlier
likelihood and uniform discriminative prediction. We generate synthetic
negatives with normalizing flows due to their outstanding distribution coverage
and capability to generate samples at different resolutions. We also propose to
detect anomalies according to a principled information-theoretic criterion
which can be consistently applied through training and inference. The resulting
models set the new state of the art on standard benchmarks and datasets in
spite of minimal computational overhead and refraining from auxiliary negative
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Faster Deep Ensemble Averaging for Quantification of DNA Damage from Comet Assay Images With Uncertainty Estimates. (arXiv:2112.12839v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12839">
<div class="article-summary-box-inner">
<span><p>Several neurodegenerative diseases involve the accumulation of cellular DNA
damage. Comet assays are a popular way of estimating the extent of DNA damage.
Current literature on the use of deep learning to quantify DNA damage presents
an empirical approach to hyper-parameter optimization and does not include
uncertainty estimates. Deep ensemble averaging is a standard approach to
estimating uncertainty but it requires several iterations of network training,
which makes it time-consuming. Here we present an approach to quantify the
extent of DNA damage that combines deep learning with a rigorous and
comprehensive method to optimize the hyper-parameters with the help of
statistical tests. We also use an architecture that allows for a faster
computation of deep ensemble averaging and performs statistical tests
applicable to networks using transfer learning. We applied our approach to a
comet assay dataset with more than 1300 images and achieved an $R^2$ of 0.84,
where the output included the confidence interval for each prediction. The
proposed architecture is an improvement over the current approaches since it
speeds up the uncertainty estimation by 30X while being statistically more
rigorous.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding the impact of class imbalance on the performance of chest x-ray image classifiers. (arXiv:2112.12843v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12843">
<div class="article-summary-box-inner">
<span><p>This work aims to understand the impact of class imbalance on the performance
of chest x-ray classifiers, in light of the standard evaluation practices
adopted by researchers in terms of discrimination and calibration performance.
Firstly, we conducted a literature study to analyze common scientific practices
and confirmed that: (1) even when dealing with highly imbalanced datasets, the
community tends to use metrics that are dominated by the majority class; and
(2) it is still uncommon to include calibration studies for chest x-ray
classifiers, albeit its importance in the context of healthcare. Secondly, we
perform a systematic experiment on two major chest x-ray datasets to explore
the behavior of several performance metrics under different class ratios and
show that widely adopted metrics can conceal the performance in the minority
class. Finally, we propose the adoption of two alternative metrics, the
precision-recall curve and the Balanced Brier score, which better reflect the
performance of the system in such scenarios. Our results indicate that current
evaluation practices adopted by the research community for chest x-ray
classifiers may not reflect the performance of such systems for computer-aided
diagnosis in real clinical scenarios, and suggest alternatives to improve this
situation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HSPACE: Synthetic Parametric Humans Animated in Complex Environments. (arXiv:2112.12867v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12867">
<div class="article-summary-box-inner">
<span><p>Advances in the state of the art for 3d human sensing are currently limited
by the lack of visual datasets with 3d ground truth, including multiple people,
in motion, operating in real-world environments, with complex illumination or
occlusion, and potentially observed by a moving camera. Sophisticated scene
understanding would require estimating human pose and shape as well as
gestures, towards representations that ultimately combine useful metric and
behavioral signals with free-viewpoint photo-realistic visualisation
capabilities. To sustain progress, we build a large-scale photo-realistic
dataset, Human-SPACE (HSPACE), of animated humans placed in complex synthetic
indoor and outdoor environments. We combine a hundred diverse individuals of
varying ages, gender, proportions, and ethnicity, with hundreds of motions and
scenes, as well as parametric variations in body shape (for a total of 1,600
different humans), in order to generate an initial dataset of over 1 million
frames. Human animations are obtained by fitting an expressive human body
model, GHUM, to single scans of people, followed by novel re-targeting and
positioning procedures that support the realistic animation of dressed humans,
statistical variation of body proportions, and jointly consistent scene
placement of multiple moving people. Assets are generated automatically, at
scale, and are compatible with existing real time rendering and game engines.
The dataset with evaluation server will be made available for research. Our
large-scale analysis of the impact of synthetic data, in connection with real
data and weak supervision, underlines the considerable potential for continuing
quality improvements and limiting the sim-to-real gap, in this practical
setting, in connection with increased model capacity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A formal approach to good practices in Pseudo-Labeling for Unsupervised Domain Adaptive Re-Identification. (arXiv:2112.12887v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12887">
<div class="article-summary-box-inner">
<span><p>The use of pseudo-labels prevails in order to tackle Unsupervised Domain
Adaptive (UDA) Re-Identification (re-ID) with the best performance. Indeed,
this family of approaches has given rise to several UDA re-ID specific
frameworks, which are effective. In these works, research directions to improve
Pseudo-Labeling UDA re-ID performance are varied and mostly based on intuition
and experiments: refining pseudo-labels, reducing the impact of errors in
pseudo-labels... It can be hard to deduce from them general good practices,
which can be implemented in any Pseudo-Labeling method, to consistently improve
its performance. To address this key question, a new theoretical view on
Pseudo-Labeling UDA re-ID is proposed. The contributions are threefold: (i) A
novel theoretical framework for Pseudo-Labeling UDA re-ID, formalized through a
new general learning upper-bound on the UDA re-ID performance. (ii) General
good practices for Pseudo-Labeling, directly deduced from the interpretation of
the proposed theoretical framework, in order to improve the target re-ID
performance. (iii) Extensive experiments on challenging person and vehicle
cross-dataset re-ID tasks, showing consistent performance improvements for
various state-of-the-art methods and various proposed implementations of good
practices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cluster-guided Image Synthesis with Unconditional Models. (arXiv:2112.12911v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12911">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GANs) are the driving force behind the
state-of-the-art in image generation. Despite their ability to synthesize
high-resolution photo-realistic images, generating content with on-demand
conditioning of different granularity remains a challenge. This challenge is
usually tackled by annotating massive datasets with the attributes of interest,
a laborious task that is not always a viable option. Therefore, it is vital to
introduce control into the generation process of unsupervised generative
models. In this work, we focus on controllable image generation by leveraging
GANs that are well-trained in an unsupervised fashion. To this end, we discover
that the representation space of intermediate layers of the generator forms a
number of clusters that separate the data according to semantically meaningful
attributes (e.g., hair color and pose). By conditioning on the cluster
assignments, the proposed method is able to control the semantic class of the
generated image. Our approach enables sampling from each cluster by Implicit
Maximum Likelihood Estimation (IMLE). We showcase the efficacy of our approach
on faces (CelebA-HQ and FFHQ), animals (Imagenet) and objects (LSUN) using
different pre-trained generative models. The results highlight the ability of
our approach to condition image generation on attributes like gender, pose and
hair style on faces, as well as a variety of features on different object
classes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Semantics Allow for Textual Reasoning Better in Scene Text Recognition. (arXiv:2112.12916v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12916">
<div class="article-summary-box-inner">
<span><p>Existing Scene Text Recognition (STR) methods typically use a language model
to optimize the joint probability of the 1D character sequence predicted by a
visual recognition (VR) model, which ignore the 2D spatial context of visual
semantics within and between character instances, making them not generalize
well to arbitrary shape scene text. To address this issue, we make the first
attempt to perform textual reasoning based on visual semantics in this paper.
Technically, given the character segmentation maps predicted by a VR model, we
construct a subgraph for each instance, where nodes represent the pixels in it
and edges are added between nodes based on their spatial similarity. Then,
these subgraphs are sequentially connected by their root nodes and merged into
a complete graph. Based on this graph, we devise a graph convolutional network
for textual reasoning (GTR) by supervising it with a cross-entropy loss. GTR
can be easily plugged in representative STR models to improve their performance
owing to better textual reasoning. Specifically, we construct our model, namely
S-GTR, by paralleling GTR to the language model in a segmentation-based STR
baseline, which can effectively exploit the visual-linguistic complementarity
via mutual learning. S-GTR sets new state-of-the-art on six challenging STR
benchmarks and generalizes well to multi-linguistic datasets. Code is available
at https://github.com/adeline-cs/GTR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-initialization Optimization Network for Accurate 3D Human Pose and Shape Estimation. (arXiv:2112.12917v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12917">
<div class="article-summary-box-inner">
<span><p>3D human pose and shape recovery from a monocular RGB image is a challenging
task. Existing learning based methods highly depend on weak supervision
signals, e.g. 2D and 3D joint location, due to the lack of in-the-wild paired
3D supervision. However, considering the 2D-to-3D ambiguities existed in these
weak supervision labels, the network is easy to get stuck in local optima when
trained with such labels. In this paper, we reduce the ambituity by optimizing
multiple initializations. Specifically, we propose a three-stage framework
named Multi-Initialization Optimization Network (MION). In the first stage, we
strategically select different coarse 3D reconstruction candidates which are
compatible with the 2D keypoints of input sample. Each coarse reconstruction
can be regarded as an initialization leads to one optimization branch. In the
second stage, we design a mesh refinement transformer (MRT) to respectively
refine each coarse reconstruction result via a self-attention mechanism.
Finally, a Consistency Estimation Network (CEN) is proposed to find the best
result from mutiple candidates by evaluating if the visual evidence in RGB
image matches a given 3D reconstruction. Experiments demonstrate that our
Multi-Initialization Optimization Network outperforms existing 3D mesh based
methods on multiple public benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Not All Voxels Are Equal: Semantic Scene Completion from the Point-Voxel Perspective. (arXiv:2112.12925v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12925">
<div class="article-summary-box-inner">
<span><p>We revisit Semantic Scene Completion (SSC), a useful task to predict the
semantic and occupancy representation of 3D scenes, in this paper. A number of
methods for this task are always based on voxelized scene representations for
keeping local scene structure. However, due to the existence of visible empty
voxels, these methods always suffer from heavy computation redundancy when the
network goes deeper, and thus limit the completion quality. To address this
dilemma, we propose our novel point-voxel aggregation network for this task.
Firstly, we transfer the voxelized scenes to point clouds by removing these
visible empty voxels and adopt a deep point stream to capture semantic
information from the scene efficiently. Meanwhile, a light-weight voxel stream
containing only two 3D convolution layers preserves local structures of the
voxelized scenes. Furthermore, we design an anisotropic voxel aggregation
operator to fuse the structure details from the voxel stream into the point
stream, and a semantic-aware propagation module to enhance the up-sampling
process in the point stream by semantic labels. We demonstrate that our model
surpasses state-of-the-arts on two benchmarks by a large margin, with only
depth images as the input.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Aligned Cross-Modal Representation for Generalized Zero-Shot Classification. (arXiv:2112.12927v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12927">
<div class="article-summary-box-inner">
<span><p>Learning a common latent embedding by aligning the latent spaces of
cross-modal autoencoders is an effective strategy for Generalized Zero-Shot
Classification (GZSC). However, due to the lack of fine-grained instance-wise
annotations, it still easily suffer from the domain shift problem for the
discrepancy between the visual representation of diversified images and the
semantic representation of fixed attributes. In this paper, we propose an
innovative autoencoder network by learning Aligned Cross-Modal Representations
(dubbed ACMR) for GZSC. Specifically, we propose a novel Vision-Semantic
Alignment (VSA) method to strengthen the alignment of cross-modal latent
features on the latent subspaces guided by a learned classifier. In addition,
we propose a novel Information Enhancement Module (IEM) to reduce the
possibility of latent variables collapse meanwhile encouraging the
discriminative ability of latent variables. Extensive experiments on publicly
available datasets demonstrate the state-of-the-art performance of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Realtime Global Attention Network for Semantic Segmentation. (arXiv:2112.12939v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12939">
<div class="article-summary-box-inner">
<span><p>In this paper, we proposed an end-to-end realtime global attention neural
network (RGANet) for the challenging task of semantic segmentation. Different
from the encoding strategy deployed by self-attention paradigms, the proposed
global attention module encodes global attention via depth-wise convolution and
affine transformations. The integration of these global attention modules into
a hierarchy architecture maintains high inferential performance. In addition,
an improved evaluation metric, namely MGRID, is proposed to alleviate the
negative effect of non-convex, widely scattered ground-truth areas. Results
from extensive experiments on state-of-the-art architectures for semantic
segmentation manifest the leading performance of proposed approaches for
robotic monocular visual perception.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep ensembles in bioimage segmentation. (arXiv:2112.12955v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12955">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation consists in classifying each pixel of an image by
assigning it to a specific label chosen from a set of all the available ones.
During the last few years, a lot of attention shifted to this kind of task.
Many computer vision researchers tried to apply autoencoder structures to
develop models that can learn the semantics of the image as well as a low-level
representation of it. In an autoencoder architecture, given an input, an
encoder computes a low dimensional representation of the input that is then
used by a decoder to reconstruct the original data. In this work, we propose an
ensemble of convolutional neural networks (CNNs). In ensemble methods, many
different models are trained and then used for classification, the ensemble
aggregates the outputs of the single classifiers. The approach leverages on
differences of various classifiers to improve the performance of the whole
system. Diversity among the single classifiers is enforced by using different
loss functions. In particular, we present a new loss function that results from
the combination of Dice and Structural Similarity Index. The proposed ensemble
is implemented by combining different backbone networks using the DeepLabV3+
and HarDNet environment. The proposal is evaluated through an extensive
empirical evaluation on two real-world scenarios: polyp and skin segmentation.
All the code is available online at https://github.com/LorisNanni.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SGTR: End-to-end Scene Graph Generation with Transformer. (arXiv:2112.12970v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12970">
<div class="article-summary-box-inner">
<span><p>Scene Graph Generation (SGG) remains a challenging visual understanding task
due to its complex compositional property. Most previous works adopt a
bottom-up two-stage or a point-based one-stage approach, which often suffers
from overhead time complexity or sub-optimal design assumption. In this work,
we propose a novel SGG method to address the aforementioned issues, which
formulates the task as a bipartite graph construction problem. To solve the
problem, we develop a transformer-based end-to-end framework that first
generates the entity and predicate proposal set, followed by inferring directed
edges to form the relation triplets. In particular, we develop a new
entity-aware predicate representation based on a structural predicate generator
to leverage the compositional property of relationships. Moreover, we design a
graph assembling module to infer the connectivity of the bipartite scene graph
based on our entity-aware structure, enabling us to generate the scene graph in
an end-to-end manner. Extensive experimental results show that our design is
able to achieve the state-of-the-art or comparable performance on two
challenging benchmarks, surpassing most of the existing approaches and enjoying
higher efficiency in inference. We hope our model can serve as a strong
baseline for the Transformer-based scene graph generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Doppler velocity-based algorithm for Clustering and Velocity Estimation of moving objects. (arXiv:2112.12984v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12984">
<div class="article-summary-box-inner">
<span><p>We propose a Doppler velocity-based cluster and velocity estimation algorithm
based on the characteristics of FMCW LiDAR which achieves highly accurate,
single-scan, and real-time motion state detection and velocity estimation. We
prove the continuity of the Doppler velocity on the same object. Based on this
principle, we achieve the distinction between moving objects and stationary
background via region growing clustering algorithm. The obtained stationary
background will be used to estimate the velocity of the FMCW LiDAR by the
least-squares method. Then we estimate the velocity of the moving objects using
the estimated LiDAR velocity and the Doppler velocity of moving objects
obtained by clustering. To ensure real-time processing, we set the appropriate
least-squares parameters. Meanwhile, to verify the effectiveness of the
algorithm, we create the FMCW LiDAR model on the autonomous driving simulation
platform CARLA for spawning data. The results show that our algorithm can
process at least a 4.5million points and estimate the velocity of 150 moving
objects per second under the arithmetic power of the Ryzen 3600x CPU, with a
motion state detection accuracy of over 99% and estimated velocity accuracy of
0.1 m/s.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">iSeg3D: An Interactive 3D Shape Segmentation Tool. (arXiv:2112.12988v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12988">
<div class="article-summary-box-inner">
<span><p>A large-scale dataset is essential for learning good features in 3D shape
understanding, but there are only a few datasets that can satisfy deep learning
training. One of the major reasons is that current tools for annotating
per-point semantic labels using polygons or scribbles are tedious and
inefficient. To facilitate segmentation annotations in 3D shapes, we propose an
effective annotation tool, named iSeg for 3D shape. It can obtain a satisfied
segmentation result with minimal human clicks (&lt; 10). Under our observation,
most objects can be considered as the composition of finite primitive shapes,
and we train iSeg3D model on our built primitive-composed shape data to learn
the geometric prior knowledge in a self-supervised manner. Given human
interactions, the learned knowledge can be used to segment parts on arbitrary
shapes, in which positive clicks help associate the primitives into the
semantic parts and negative clicks can avoid over-segmentation. Besides, We
also provide an online human-in-loop fine-tuning module that enables the model
perform better segmentation with less clicks. Experiments demonstrate the
effectiveness of iSeg3D on PartNet shape segmentation. Data and codes will be
made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-Aware Continual Zero-Shot Learning. (arXiv:2112.12989v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12989">
<div class="article-summary-box-inner">
<span><p>We introduce Domain Aware Continual Zero-Shot Learning (DACZSL), the task of
visually recognizing images of unseen categories in unseen domains
sequentially. We created DACZSL on top of the DomainNet dataset by dividing it
into a sequence of tasks, where classes are incrementally provided on seen
domains during training and evaluation is conducted on unseen domains for both
seen and unseen classes. We also proposed a novel Domain-Invariant CZSL Network
(DIN), which outperforms state-of-the-art baseline models that we adapted to
DACZSL setting. We adopt a structure-based approach to alleviate forgetting
knowledge from previous tasks with a small per-task private network in addition
to a global shared network. To encourage the private network to capture the
domain and task-specific representation, we train our model with a novel
adversarial knowledge disentanglement setting to make our global network
task-invariant and domain-invariant over all the tasks. Our method also learns
a class-wise learnable prompt to obtain better class-level text representation,
which is used to represent side information to enable zero-shot prediction of
future unseen classes. Our code and benchmarks will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">US-GAN: On the importance of Ultimate Skip Connection for Facial Expression Synthesis. (arXiv:2112.13002v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13002">
<div class="article-summary-box-inner">
<span><p>Recent studies have shown impressive results in multi-domain image-to-image
translation for facial expression synthesis. While effective, these methods
require a large number of labelled samples for plausible results. Their
performance significantly degrades when we train them on smaller datasets. To
address this limitation, in this work, we present US-GAN, a smaller and
effective method for synthesizing plausible expressions by employing notably
smaller datasets. The proposed method comprises of encoding layers, single
residual block, decoding layers and an ultimate skip connection that links the
input image to an output image. It has three times lesser parameters as
compared to state-of-the-art facial expression synthesis methods. Experimental
results demonstrate the quantitative and qualitative effectiveness of our
proposed method. In addition, we also show that an ultimate skip connection is
sufficient for recovering rich facial and overall color details of the input
face image that a larger state-of-the-art model fails to recover.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuous Spectral Reconstruction from RGB Images via Implicit Neural Representation. (arXiv:2112.13003v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13003">
<div class="article-summary-box-inner">
<span><p>Existing methods for spectral reconstruction usually learn a discrete mapping
from RGB images to a number of spectral bands. However, this modeling strategy
ignores the continuous nature of spectral signature. In this paper, we propose
Neural Spectral Reconstruction (NeSR) to lift this limitation, by introducing a
novel continuous spectral representation. To this end, we embrace the concept
of implicit function and implement a parameterized embodiment with a neural
network. Specifically, we first adopt a backbone network to extract spatial
features of RGB inputs. Based on it, we devise Spectral Profile Interpolation
(SPI) module and Neural Attention Mapping (NAM) module to enrich deep features,
where the spatial-spectral correlation is involved for a better representation.
Then, we view the number of sampled spectral bands as the coordinate of
continuous implicit function, so as to learn the projection from deep features
to spectral intensities. Extensive experiments demonstrate the distinct
advantage of NeSR in reconstruction accuracy over baseline methods. Moreover,
NeSR extends the flexibility of spectral reconstruction by enabling an
arbitrary number of spectral bands as the target output.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking Pedestrian Odometry: The Brown Pedestrian Odometry Dataset (BPOD). (arXiv:2112.13018v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13018">
<div class="article-summary-box-inner">
<span><p>We present the Brown Pedestrian Odometry Dataset (BPOD) for benchmarking
visual odometry algorithms in head-mounted pedestrian settings. This dataset
was captured using synchronized global and rolling shutter stereo cameras in 12
diverse indoor and outdoor locations on Brown University's campus. Compared to
existing datasets, BPOD contains more image blur and self-rotation, which are
common in pedestrian odometry but rare elsewhere. Ground-truth trajectories are
generated from stick-on markers placed along the pedestrian's path, and the
pedestrian's position is documented using a third-person video. We evaluate the
performance of representative direct, feature-based, and learning-based VO
methods on BPOD. Our results show that significant development is needed to
successfully capture pedestrian trajectories. The link to the dataset is here:
\url{https://doi.org/10.26300/c1n7-7p93
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grounding Linguistic Commands to Navigable Regions. (arXiv:2112.13031v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13031">
<div class="article-summary-box-inner">
<span><p>Humans have a natural ability to effortlessly comprehend linguistic commands
such as "park next to the yellow sedan" and instinctively know which region of
the road the vehicle should navigate. Extending this ability to autonomous
vehicles is the next step towards creating fully autonomous agents that respond
and act according to human commands. To this end, we propose the novel task of
Referring Navigable Regions (RNR), i.e., grounding regions of interest for
navigation based on the linguistic command. RNR is different from Referring
Image Segmentation (RIS), which focuses on grounding an object referred to by
the natural language expression instead of grounding a navigable region. For
example, for a command "park next to the yellow sedan," RIS will aim to segment
the referred sedan, and RNR aims to segment the suggested parking region on the
road. We introduce a new dataset, Talk2Car-RegSeg, which extends the existing
Talk2car dataset with segmentation masks for the regions described by the
linguistic commands. A separate test split with concise manoeuvre-oriented
commands is provided to assess the practicality of our dataset. We benchmark
the proposed dataset using a novel transformer-based architecture. We present
extensive ablations and show superior performance over baselines on multiple
evaluation metrics. A downstream path planner generating trajectories based on
RNR outputs confirms the efficacy of the proposed framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Channel-Wise Attention-Based Network for Self-Supervised Monocular Depth Estimation. (arXiv:2112.13047v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13047">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning has shown very promising results for monocular depth
estimation. Scene structure and local details both are significant clues for
high-quality depth estimation. Recent works suffer from the lack of explicit
modeling of scene structure and proper handling of details information, which
leads to a performance bottleneck and blurry artefacts in predicted results. In
this paper, we propose the Channel-wise Attention-based Depth Estimation
Network (CADepth-Net) with two effective contributions: 1) The structure
perception module employs the self-attention mechanism to capture long-range
dependencies and aggregates discriminative features in channel dimensions,
explicitly enhances the perception of scene structure, obtains the better scene
understanding and rich feature representation. 2) The detail emphasis module
re-calibrates channel-wise feature maps and selectively emphasizes the
informative features, aiming to highlight crucial local details information and
fuse different level features more efficiently, resulting in more precise and
sharper depth prediction. Furthermore, the extensive experiments validate the
effectiveness of our method and show that our model achieves the
state-of-the-art results on the KITTI benchmark and Make3D datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Gated Memory Recurrent Network for Efficient Scalable HDR Deghosting. (arXiv:2112.13050v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13050">
<div class="article-summary-box-inner">
<span><p>We propose a novel recurrent network-based HDR deghosting method for fusing
arbitrary length dynamic sequences. The proposed method uses convolutional and
recurrent architectures to generate visually pleasing, ghosting-free HDR
images. We introduce a new recurrent cell architecture, namely Self-Gated
Memory (SGM) cell, that outperforms the standard LSTM cell while containing
fewer parameters and having faster running times. In the SGM cell, the
information flow through a gate is controlled by multiplying the gate's output
by a function of itself. Additionally, we use two SGM cells in a bidirectional
setting to improve output quality. The proposed approach achieves
state-of-the-art performance compared to existing HDR deghosting methods
quantitatively across three publicly available datasets while simultaneously
achieving scalability to fuse variable-length input sequence without
necessitating re-training. Through extensive ablations, we demonstrate the
importance of individual components in our proposed approach. The code is
available at https://val.cds.iisc.ac.in/HDR/HDRRNN/index.html.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Wasserstein Dice Loss, Test-time Augmentation, and Transformers for the BraTS 2021 challenge. (arXiv:2112.13054v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13054">
<div class="article-summary-box-inner">
<span><p>Brain tumor segmentation from multiple Magnetic Resonance Imaging (MRI)
modalities is a challenging task in medical image computation. The main
challenges lie in the generalizability to a variety of scanners and imaging
protocols. In this paper, we explore strategies to increase model robustness
without increasing inference time. Towards this aim, we explore finding a
robust ensemble from models trained using different losses, optimizers, and
train-validation data split. Importantly, we explore the inclusion of a
transformer in the bottleneck of the U-Net architecture. While we find
transformer in the bottleneck performs slightly worse than the baseline U-Net
in average, the generalized Wasserstein Dice loss consistently produces
superior results. Further, we adopt an efficient test time augmentation
strategy for faster and robust inference. Our final ensemble of seven 3D U-Nets
with test-time augmentation produces an average dice score of 89.4% and an
average Hausdorff 95% distance of 10.0 mm when evaluated on the BraTS 2021
testing dataset. Our code and trained models are publicly available at
https://github.com/LucasFidon/TRABIT_BraTS2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NIP: Neuron-level Inverse Perturbation Against Adversarial Attacks. (arXiv:2112.13060v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13060">
<div class="article-summary-box-inner">
<span><p>Although deep learning models have achieved unprecedented success, their
vulnerabilities towards adversarial attacks have attracted increasing
attention, especially when deployed in security-critical domains. To address
the challenge, numerous defense strategies, including reactive and proactive
ones, have been proposed for robustness improvement. From the perspective of
image feature space, some of them cannot reach satisfying results due to the
shift of features. Besides, features learned by models are not directly related
to classification results. Different from them, We consider defense method
essentially from model inside and investigated the neuron behaviors before and
after attacks. We observed that attacks mislead the model by dramatically
changing the neurons that contribute most and least to the correct label.
Motivated by it, we introduce the concept of neuron influence and further
divide neurons into front, middle and tail part. Based on it, we propose
neuron-level inverse perturbation(NIP), the first neuron-level reactive defense
method against adversarial attacks. By strengthening front neurons and
weakening those in the tail part, NIP can eliminate nearly all adversarial
perturbations while still maintaining high benign accuracy. Besides, it can
cope with different sizes of perturbations via adaptivity, especially larger
ones. Comprehensive experiments conducted on three datasets and six models show
that NIP outperforms the state-of-the-art baselines against eleven adversarial
attacks. We further provide interpretable proofs via neuron activation and
visualization for better understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CatchBackdoor: Backdoor Testing by Critical Trojan Neural Path Identification via Differential Fuzzing. (arXiv:2112.13064v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13064">
<div class="article-summary-box-inner">
<span><p>The success of deep neural networks (DNNs) in real-world applications has
benefited from abundant pre-trained models. However, the backdoored pre-trained
models can pose a significant trojan threat to the deployment of downstream
DNNs. Existing DNN testing methods are mainly designed to find incorrect corner
case behaviors in adversarial settings but fail to discover the backdoors
crafted by strong trojan attacks. Observing the trojan network behaviors shows
that they are not just reflected by a single compromised neuron as proposed by
previous work but attributed to the critical neural paths in the activation
intensity and frequency of multiple neurons. This work formulates the DNN
backdoor testing and proposes the CatchBackdoor framework. Via differential
fuzzing of critical neurons from a small number of benign examples, we identify
the trojan paths and particularly the critical ones, and generate backdoor
testing examples by simulating the critical neurons in the identified paths.
Extensive experiments demonstrate the superiority of CatchBackdoor, with higher
detection performance than existing methods. CatchBackdoor works better on
detecting backdoors by stealthy blending and adaptive attacks, which existing
methods fail to detect. Moreover, our experiments show that CatchBackdoor may
reveal the potential backdoors of models in Model Zoo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Virtuoso: Video-based Intelligence for real-time tuning on SOCs. (arXiv:2112.13076v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13076">
<div class="article-summary-box-inner">
<span><p>Efficient and adaptive computer vision systems have been proposed to make
computer vision tasks, such as image classification and object detection,
optimized for embedded or mobile devices. These solutions, quite recent in
their origin, focus on optimizing the model (a deep neural network, DNN) or the
system by designing an adaptive system with approximation knobs. In spite of
several recent efforts, we show that existing solutions suffer from two major
drawbacks. First, the system does not consider energy consumption of the models
while making a decision on which model to run. Second, the evaluation does not
consider the practical scenario of contention on the device, due to other
co-resident workloads. In this work, we propose an efficient and adaptive video
object detection system, Virtuoso, which is jointly optimized for accuracy,
energy efficiency, and latency. Underlying Virtuoso is a multi-branch execution
kernel that is capable of running at different operating points in the
accuracy-energy-latency axes, and a lightweight runtime scheduler to select the
best fit execution branch to satisfy the user requirement. To fairly compare
with Virtuoso, we benchmark 15 state-of-the-art or widely used protocols,
including Faster R-CNN (FRCNN), YOLO v3, SSD, EfficientDet, SELSA, MEGA, REPP,
FastAdapt, and our in-house adaptive variants of FRCNN+, YOLO+, SSD+, and
EfficientDet+ (our variants have enhanced efficiency for mobiles). With this
comprehensive benchmark, Virtuoso has shown superiority to all the above
protocols, leading the accuracy frontier at every efficiency level on NVIDIA
Jetson mobile GPUs. Specifically, Virtuoso has achieved an accuracy of 63.9%,
which is more than 10% higher than some of the popular object detection models,
FRCNN at 51.1%, and YOLO at 49.5%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Scale Feature Fusion: Learning Better Semantic Segmentation for Road Pothole Detection. (arXiv:2112.13082v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13082">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel pothole detection approach based on single-modal
semantic segmentation. It first extracts visual features from input images
using a convolutional neural network. A channel attention module then reweighs
the channel features to enhance the consistency of different feature maps.
Subsequently, we employ an atrous spatial pyramid pooling module (comprising of
atrous convolutions in series, with progressive rates of dilation) to integrate
the spatial context information. This helps better distinguish between potholes
and undamaged road areas. Finally, the feature maps in the adjacent layers are
fused using our proposed multi-scale feature fusion module. This further
reduces the semantic gap between different feature channel layers. Extensive
experiments were carried out on the Pothole-600 dataset to demonstrate the
effectiveness of our proposed method. The quantitative comparisons suggest that
our method achieves the state-of-the-art (SoTA) performance on both RGB images
and transformed disparity images, outperforming three SoTA single-modal
semantic segmentation networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimViT: Exploring a Simple Vision Transformer with sliding windows. (arXiv:2112.13085v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13085">
<div class="article-summary-box-inner">
<span><p>Although vision Transformers have achieved excellent performance as backbone
models in many vision tasks, most of them intend to capture global relations of
all tokens in an image or a window, which disrupts the inherent spatial and
local correlations between patches in 2D structure. In this paper, we introduce
a simple vision Transformer named SimViT, to incorporate spatial structure and
local information into the vision Transformers. Specifically, we introduce
Multi-head Central Self-Attention(MCSA) instead of conventional Multi-head
Self-Attention to capture highly local relations. The introduction of sliding
windows facilitates the capture of spatial structure. Meanwhile, SimViT
extracts multi-scale hierarchical features from different layers for dense
prediction tasks. Extensive experiments show the SimViT is effective and
efficient as a general-purpose backbone model for various image processing
tasks. Especially, our SimViT-Micro only needs 3.3M parameters to achieve 71.1%
top-1 accuracy on ImageNet-1k dataset, which is the smallest size vision
Transformer model by now. Our code will be available in
https://github.com/ucasligang/SimViT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Invertible Network for Unpaired Low-light Image Enhancement. (arXiv:2112.13107v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13107">
<div class="article-summary-box-inner">
<span><p>Existing unpaired low-light image enhancement approaches prefer to employ the
two-way GAN framework, in which two CNN generators are deployed for enhancement
and degradation separately. However, such data-driven models ignore the
inherent characteristics of transformation between the low and normal light
images, leading to unstable training and artifacts. Here, we propose to
leverage the invertible network to enhance low-light image in forward process
and degrade the normal-light one inversely with unpaired learning. The
generated and real images are then fed into discriminators for adversarial
learning. In addition to the adversarial loss, we design various loss functions
to ensure the stability of training and preserve more image details.
Particularly, a reversibility loss is introduced to alleviate the over-exposure
problem. Moreover, we present a progressive self-guided enhancement process for
low-light images and achieve favorable performance against the SOTAs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ultrasound Speckle Suppression and Denoising using MRI-derived Normalizing Flow Priors. (arXiv:2112.13110v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13110">
<div class="article-summary-box-inner">
<span><p>Ultrasonography offers an inexpensive, widely-accessible and compact medical
imaging solution. However, compared to other imaging modalities such as CT and
MRI, ultrasound images notoriously suffer from strong speckle noise, which
originates from the random interference of sub-wavelength scattering. This
deteriorates ultrasound image quality and makes interpretation challenging. We
here propose a new unsupervised ultrasound speckle reduction and image
denoising method based on maximum-a-posteriori estimation with deep generative
priors that are learned from high-quality MRI images. To model the generative
tissue reflectivity prior, we exploit normalizing flows, which in recent years
have shown to be very powerful in modeling signal priors across a variety of
applications. To facilitate generaliation, we factorize the prior and train our
flow model on patches from the NYU fastMRI (fully-sampled) dataset. This prior
is then used for inference in an iterative denoising scheme. We first validate
the utility of our learned priors on noisy MRI data (no prior domain shift),
and then turn to evaluating performance on both simulated and in-vivo
ultrasound images from the PICMUS and CUBDL datasets. The results show that the
method outperforms other (unsupervised) ultrasound denoising methods (NLM and
OBNLM) both quantitatively and qualitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Curse of Zero Task Diversity: On the Failure of Transfer Learning to Outperform MAML and their Empirical Equivalence. (arXiv:2112.13121v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13121">
<div class="article-summary-box-inner">
<span><p>It has been recently observed that a transfer learning solution might be all
we needed to solve many few-shot learning benchmarks. This raises important
questions about when and how meta-learning algorithms should be deployed. In
this paper, we make a first step in clarifying these questions by first
formulating a computable metric for a few-shot learning benchmark that we
hypothesize is predictive of whether meta-learning solutions will succeed or
not. We name this metric the diversity coefficient of a few-shot learning
benchmark. Using the diversity coefficient, we show that the MiniImagenet
benchmark has zero diversity - according to twenty-four different ways to
compute the diversity. We proceed to show that when making a fair comparison
between MAML learned solutions to transfer learning, both have identical
meta-test accuracy. This suggests that transfer learning fails to outperform
MAML - contrary to what previous work suggests. Together, these two facts
provide the first test of whether diversity correlates with meta-learning
success and therefore show that a diversity coefficient of zero correlates with
a high similarity between transfer learning and MAML learned solutions -
especially at meta-test time. We therefore conjecture meta-learned solutions
have the same meta-test performance as transfer learning when the diversity
coefficient is zero.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does MAML Only Work via Feature Re-use? A Data Centric Perspective. (arXiv:2112.13137v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13137">
<div class="article-summary-box-inner">
<span><p>Recent work has suggested that a good embedding is all we need to solve many
few-shot learning benchmarks. Furthermore, other work has strongly suggested
that Model Agnostic Meta-Learning (MAML) also works via this same method - by
learning a good embedding. These observations highlight our lack of
understanding of what meta-learning algorithms are doing and when they work. In
this work, we provide empirical results that shed some light on how
meta-learned MAML representations function. In particular, we identify three
interesting properties: 1) In contrast to previous work, we show that it is
possible to define a family of synthetic benchmarks that result in a low degree
of feature re-use - suggesting that current few-shot learning benchmarks might
not have the properties needed for the success of meta-learning algorithms; 2)
meta-overfitting occurs when the number of classes (or concepts) are finite,
and this issue disappears once the task has an unbounded number of concepts
(e.g., online learning); 3) more adaptation at meta-test time with MAML does
not necessarily result in a significant representation change or even an
improvement in meta-test performance - even when training on our proposed
synthetic benchmarks. Finally, we suggest that to understand meta-learning
algorithms better, we must go beyond tracking only absolute performance and, in
addition, formally quantify the degree of meta-learning and track both metrics
together. Reporting results in future work this way will help us identify the
sources of meta-overfitting more accurately and help us design more flexible
meta-learning algorithms that learn beyond fixed feature re-use. Finally, we
conjecture the core challenge of re-thinking meta-learning is in the design of
few-shot learning data sets and benchmarks - rather than in the algorithms, as
suggested by previous work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reconstructing Compact Building Models from Point Clouds Using Deep Implicit Fields. (arXiv:2112.13142v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13142">
<div class="article-summary-box-inner">
<span><p>Three-dimensional (3D) building models play an increasingly pivotal role in
many real-world applications while obtaining a compact representation of
buildings remains an open problem. In this paper, we present a novel framework
for reconstructing compact, watertight, polygonal building models from point
clouds. Our framework comprises three components: (a) a cell complex is
generated via adaptive space partitioning that provides a polyhedral embedding
as the candidate set; (b) an implicit field is learned by a deep neural network
that facilitates building occupancy estimation; (c) a Markov random field is
formulated to extract the outer surface of a building via combinatorial
optimization. We evaluate and compare our method with state-of-the-art methods
in shape reconstruction, surface approximation, and geometry simplification.
Experiments on both synthetic and real-world point clouds have demonstrated
that, with our neural-guided strategy, high-quality building models can be
obtained with significant advantages in fidelity, compactness, and
computational efficiency. Our method shows robustness to noise and insufficient
measurements, and it can directly generalize from synthetic scans to real-world
measurements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast and Scalable Computation of the Forward and Inverse Discrete Periodic Radon Transform. (arXiv:2112.13149v1 [cs.AR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13149">
<div class="article-summary-box-inner">
<span><p>The Discrete Periodic Radon Transform (DPRT) has been extensively used in
applications that involve image reconstructions from projections. This
manuscript introduces a fast and scalable approach for computing the forward
and inverse DPRT that is based on the use of: (i) a parallel array of
fixed-point adder trees, (ii) circular shift registers to remove the need for
accessing external memory components when selecting the input data for the
adder trees, (iii) an image block-based approach to DPRT computation that can
fit the proposed architecture to available resources, and (iv) fast
transpositions that are computed in one or a few clock cycles that do not
depend on the size of the input image. As a result, for an $N\times N$ image
($N$ prime), the proposed approach can compute up to $N^{2}$ additions per
clock cycle. Compared to previous approaches, the scalable approach provides
the fastest known implementations for different amounts of computational
resources. For example, for a $251\times 251$ image, for approximately $25\%$
fewer flip-flops than required for a systolic implementation, we have that the
scalable DPRT is computed 36 times faster. For the fastest case, we introduce
optimized architectures that can compute the DPRT and its inverse in just
$2N+\left\lceil \log_{2}N\right\rceil+1$ and $2N+3\left\lceil
\log_{2}N\right\rceil+B+2$ cycles respectively, where $B$ is the number of bits
used to represent each input pixel. On the other hand, the scalable DPRT
approach requires more 1-bit additions than for the systolic implementation and
provides a trade-off between speed and additional 1-bit additions. All of the
proposed DPRT architectures were implemented in VHDL and validated using an
FPGA implementation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast 2D Convolutions and Cross-Correlations Using Scalable Architectures. (arXiv:2112.13150v1 [cs.AR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13150">
<div class="article-summary-box-inner">
<span><p>The manuscript describes fast and scalable architectures and associated
algorithms for computing convolutions and cross-correlations. The basic idea is
to map 2D convolutions and cross-correlations to a collection of 1D
convolutions and cross-correlations in the transform domain. This is
accomplished through the use of the Discrete Periodic Radon Transform (DPRT)
for general kernels and the use of SVD-LU decompositions for low-rank kernels.
The approach uses scalable architectures that can be fitted into modern FPGA
and Zynq-SOC devices. Based on different types of available resources, for
$P\times P$ blocks, 2D convolutions and cross-correlations can be computed in
just $O(P)$ clock cycles up to $O(P^2)$ clock cycles. Thus, there is a
trade-off between performance and required numbers and types of resources. We
provide implementations of the proposed architectures using modern programmable
devices (Virtex-7 and Zynq-SOC). Based on the amounts and types of required
resources, we show that the proposed approaches significantly outperform
current methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Clustering based Deduction Learning for Image Recognition and Classification. (arXiv:2112.13165v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13165">
<div class="article-summary-box-inner">
<span><p>The paper proposes a semantic clustering based deduction learning by
mimicking the learning and thinking process of human brains. Human beings can
make judgments based on experience and cognition, and as a result, no one would
recognize an unknown animal as a car. Inspired by this observation, we propose
to train deep learning models using the clustering prior that can guide the
models to learn with the ability of semantic deducing and summarizing from
classification attributes, such as a cat belonging to animals while a car
pertaining to vehicles. %Specifically, if an image is labeled as a cat, then
the model is trained to learn that "this image is totally not any random class
that is the outlier of animal". The proposed approach realizes the high-level
clustering in the semantic space, enabling the model to deduce the relations
among various classes during the learning process. In addition, the paper
introduces a semantic prior based random search for the opposite labels to
ensure the smooth distribution of the clustering and the robustness of the
classifiers. The proposed approach is supported theoretically and empirically
through extensive experiments. We compare the performance across
state-of-the-art classifiers on popular benchmarks, and the generalization
ability is verified by adding noisy labeling to the datasets. Experimental
results demonstrate the superiority of the proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DSRGAN: Detail Prior-Assisted Perceptual Single Image Super-Resolution via Generative Adversarial Networks. (arXiv:2112.13191v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13191">
<div class="article-summary-box-inner">
<span><p>The generative adversarial network (GAN) is successfully applied to study the
perceptual single image superresolution (SISR). However, the GAN often tends to
generate images with high frequency details being inconsistent with the real
ones. Inspired by conventional detail enhancement algorithms, we propose a
novel prior knowledge, the detail prior, to assist the GAN in alleviating this
problem and restoring more realistic details. The proposed method, named
DSRGAN, includes a well designed detail extraction algorithm to capture the
most important high frequency information from images. Then, two discriminators
are utilized for supervision on image-domain and detail-domain restorations,
respectively. The DSRGAN merges the restored detail into the final output via a
detail enhancement manner. The special design of DSRGAN takes advantages from
both the model-based conventional algorithm and the data-driven deep learning
network. Experimental results demonstrate that the DSRGAN outperforms the
state-of-the-art SISR methods on perceptual metrics and achieves comparable
results in terms of fidelity metrics simultaneously. Following the DSRGAN, it
is feasible to incorporate other conventional image processing algorithms into
a deep learning network to form a model-based deep SISR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Network-Aware 5G Edge Computing for Object Detection: Augmenting Wearables to "See'' More, Farther and Faster. (arXiv:2112.13194v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13194">
<div class="article-summary-box-inner">
<span><p>Advanced wearable devices are increasingly incorporating high-resolution
multi-camera systems. As state-of-the-art neural networks for processing the
resulting image data are computationally demanding, there has been growing
interest in leveraging fifth generation (5G) wireless connectivity and mobile
edge computing for offloading this processing to the cloud. To assess this
possibility, this paper presents a detailed simulation and evaluation of 5G
wireless offloading for object detection within a powerful, new smart wearable
called VIS4ION, for the Blind-and-Visually Impaired (BVI). The current VIS4ION
system is an instrumented book-bag with high-resolution cameras, vision
processing and haptic and audio feedback. The paper considers uploading the
camera data to a mobile edge cloud to perform real-time object detection and
transmitting the detection results back to the wearable. To determine the video
requirements, the paper evaluates the impact of video bit rate and resolution
on object detection accuracy and range. A new street scene dataset with labeled
objects relevant to BVI navigation is leveraged for analysis. The vision
evaluation is combined with a detailed full-stack wireless network simulation
to determine the distribution of throughputs and delays with real navigation
paths and ray-tracing from new high-resolution 3D models in an urban
environment. For comparison, the wireless simulation considers both a standard
4G-Long Term Evolution (LTE) carrier and high-rate 5G millimeter-wave (mmWave)
carrier. The work thus provides a thorough and realistic assessment of edge
computing with mmWave connectivity in an application with both high bandwidth
and low latency requirements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pseudocylindrical Convolutions for Learned Omnidirectional Image Compression. (arXiv:2112.13227v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13227">
<div class="article-summary-box-inner">
<span><p>Although equirectangular projection (ERP) is a convenient form to store
omnidirectional images (also known as 360-degree images), it is neither
equal-area nor conformal, thus not friendly to subsequent visual communication.
In the context of image compression, ERP will over-sample and deform things and
stuff near the poles, making it difficult for perceptually optimal bit
allocation. In conventional 360-degree image compression, techniques such as
region-wise packing and tiled representation are introduced to alleviate the
over-sampling problem, achieving limited success. In this paper, we make one of
the first attempts to learn deep neural networks for omnidirectional image
compression. We first describe parametric pseudocylindrical representation as a
generalization of common pseudocylindrical map projections. A computationally
tractable greedy method is presented to determine the (sub)-optimal
configuration of the pseudocylindrical representation in terms of a novel proxy
objective for rate-distortion performance. We then propose pseudocylindrical
convolutions for 360-degree image compression. Under reasonable constraints on
the parametric representation, the pseudocylindrical convolution can be
efficiently implemented by standard convolution with the so-called
pseudocylindrical padding. To demonstrate the feasibility of our idea, we
implement an end-to-end 360-degree image compression system, consisting of the
learned pseudocylindrical representation, an analysis transform, a non-uniform
quantizer, a synthesis transform, and an entropy model. Experimental results on
$19,790$ omnidirectional images show that our method achieves consistently
better rate-distortion performance than the competing methods. Moreover, the
visual quality by our method is significantly improved for all images at all
bitrates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evolutionary Generation of Visual Motion Illusions. (arXiv:2112.13243v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13243">
<div class="article-summary-box-inner">
<span><p>Why do we sometimes perceive static images as if they were moving? Visual
motion illusions enjoy a sustained popularity, yet there is no definitive
answer to the question of why they work. We present a generative model, the
Evolutionary Illusion GENerator (EIGen), that creates new visual motion
illusions. The structure of EIGen supports the hypothesis that illusory motion
might be the result of perceiving the brain's own predictions rather than
perceiving raw visual input from the eyes. The scientific motivation of this
paper is to demonstrate that the perception of illusory motion could be a side
effect of the predictive abilities of the brain. The philosophical motivation
of this paper is to call attention to the untapped potential of "motivated
failures", ways for artificial systems to fail as biological systems fail, as a
worthy outlet for Artificial Intelligence and Artificial Life research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Artifact Reduction in Fundus Imaging using Cycle Consistent Adversarial Neural Networks. (arXiv:2112.13264v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13264">
<div class="article-summary-box-inner">
<span><p>Fundus images are very useful in identifying various ophthalmic disorders.
However, due to the presence of artifacts, the visibility of the retina is
severely affected. This may result in misdiagnosis of the disorder which may
lead to more complicated problems. Since deep learning is a powerful tool to
extract patterns from data without much human intervention, they can be applied
to image-to-image translation problems. An attempt has been made in this paper
to automatically rectify such artifacts present in the images of the fundus. We
use a CycleGAN based model which consists of residual blocks to reduce the
artifacts in the images. Significant improvements are seen when compared to the
existing techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Clustering Active Learning for Person Re-identification. (arXiv:2112.13308v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13308">
<div class="article-summary-box-inner">
<span><p>Supervised person re-identification (re-id) approaches require a large amount
of pairwise manual labeled data, which is not applicable in most real-world
scenarios for re-id deployment. On the other hand, unsupervised re-id methods
rely on unlabeled data to train models but performs poorly compared with
supervised re-id methods. In this work, we aim to combine unsupervised re-id
learning with a small number of human annotations to achieve a competitive
performance. Towards this goal, we present a Unsupervised Clustering Active
Learning (UCAL) re-id deep learning approach. It is capable of incrementally
discovering the representative centroid-pairs and requiring human annotate
them. These few labeled representative pairwise data can improve the
unsupervised representation learning model with other large amounts of
unlabeled data. More importantly, because the representative centroid-pairs are
selected for annotation, UCAL can work with very low-cost human effort.
Extensive experiments demonstrate the superiority of the proposed model over
state-of-the-art active learning methods on three re-id benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Cross-Scale Prediction for Efficient Neural Video Compression. (arXiv:2112.13309v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13309">
<div class="article-summary-box-inner">
<span><p>In this paper, we present the first neural video codec that can compete with
the latest coding standard H.266/VVC in terms of sRGB PSNR on UVG dataset for
the low-latency mode. Existing neural hybrid video coding approaches rely on
optical flow or Gaussian-scale flow for prediction, which cannot support
fine-grained adaptation to diverse motion content. Towards more
content-adaptive prediction, we propose a novel cross-scale prediction module
that achieves more effective motion compensation. Specifically, on the one
hand, we produce a reference feature pyramid as prediction sources, then
transmit cross-scale flows that leverage the feature scale to control the
precision of prediction. On the other hand, we introduce the mechanism of
weighted prediction into the scenario of prediction with a single reference
frame, where cross-scale weight maps are transmitted to synthesize a fine
prediction result. In addition to the cross-scale prediction module, we further
propose a multi-stage quantization strategy, which improves the rate-distortion
performance with no extra computational penalty during inference. We show the
encouraging performance of our efficient neural video codec (ENVC) on several
common benchmark datasets and analyze in detail the effectiveness of every
important component.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Miti-DETR: Object Detection based on Transformers with Mitigatory Self-Attention Convergence. (arXiv:2112.13310v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13310">
<div class="article-summary-box-inner">
<span><p>Object Detection with Transformers (DETR) and related works reach or even
surpass the highly-optimized Faster-RCNN baseline with self-attention network
architectures. Inspired by the evidence that pure self-attention possesses a
strong inductive bias that leads to the transformer losing the expressive power
with respect to network depth, we propose a transformer architecture with a
mitigatory self-attention mechanism by applying possible direct mapping
connections in the transformer architecture to mitigate the rank collapse so as
to counteract feature expression loss and enhance the model performance. We
apply this proposal in object detection tasks and develop a model named
Miti-DETR. Miti-DETR reserves the inputs of each single attention layer to the
outputs of that layer so that the "non-attention" information has participated
in any attention propagation. The formed residual self-attention network
addresses two critical issues: (1) stop the self-attention networks from
degenerating to rank-1 to the maximized degree; and (2) further diversify the
path distribution of parameter update so that easier attention learning is
expected. Miti-DETR significantly enhances the average detection precision and
convergence speed towards existing DETR-based models on the challenging COCO
object detection dataset. Moreover, the proposed transformer with the residual
self-attention network can be easily generalized or plugged in other related
task models without specific customization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuous Offline Handwriting Recognition using Deep Learning Models. (arXiv:2112.13328v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13328">
<div class="article-summary-box-inner">
<span><p>Handwritten text recognition is an open problem of great interest in the area
of automatic document image analysis. The transcription of handwritten content
present in digitized documents is significant in analyzing historical archives
or digitizing information from handwritten documents, forms, and
communications. In the last years, great advances have been made in this area
due to applying deep learning techniques to its resolution. This Thesis
addresses the offline continuous handwritten text recognition (HTR) problem,
consisting of developing algorithms and models capable of transcribing the text
present in an image without the need for the text to be segmented into
characters. For this purpose, we have proposed a new recognition model based on
integrating two types of deep learning architectures: convolutional neural
networks (CNN) and sequence-to-sequence (seq2seq) models, respectively. The
convolutional component of the model is oriented to identify relevant features
present in characters, and the seq2seq component builds the transcription of
the text by modeling the sequential nature of the text. For the design of this
new model, an extensive analysis of the capabilities of different convolutional
architectures in the simplified problem of isolated character recognition has
been carried out in order to identify the most suitable ones to be integrated
into the continuous model. Additionally, extensive experimentation of the
proposed model for the continuous problem has been carried out to determine its
robustness to changes in parameterization. The generalization capacity of the
model has also been validated by evaluating it on three handwritten text
databases using different languages: IAM in English, RIMES in French, and
Osborne in Spanish, respectively. The new proposed model provides competitive
results with those obtained with other well-established methodologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">It\^{o}-Taylor Sampling Scheme for Denoising Diffusion Probabilistic Models using Ideal Derivatives. (arXiv:2112.13339v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13339">
<div class="article-summary-box-inner">
<span><p>Denoising Diffusion Probabilistic Models (DDPMs) have been attracting
attention recently as a new challenger to popular deep neural generative models
including GAN, VAE, etc. However, DDPMs have a disadvantage that they often
require a huge number of refinement steps during the synthesis. To address this
problem, this paper proposes a new DDPM sampler based on a second-order
numerical scheme for stochastic differential equations (SDEs), while the
conventional sampler is based on a first-order numerical scheme. In general, it
is not easy to compute the derivatives that are required in higher-order
numerical schemes. However, in the case of DDPM, this difficulty is alleviated
by the trick which the authors call "ideal derivative substitution". The newly
derived higher-order sampler was applied to both image and speech generation
tasks, and it is experimentally observed that the proposed sampler could
synthesize plausible images and audio signals in relatively smaller number of
refinement steps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AlertTrap: A study on object detection in remote insects trap monitoring system using on-the-edge deep learning platform. (arXiv:2112.13341v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13341">
<div class="article-summary-box-inner">
<span><p>Fruit flies are one of the most harmful insect species to fruit yields. In
AlertTrap, implementation of SSD architecture with different state-of-the-art
backbone feature extractors such as MobileNetV1 and MobileNetV2 appear to be
potential solutions for the real-time detection problem. SSD-MobileNetV1 and
SSD-MobileNetV2 perform well and result in AP@0.5 of 0.957 and 1.0
respectively. YOLOv4-tiny outperforms the SSD family with 1.0 in AP@0.5;
however, its throughput velocity is slightly slower.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Delivery Issues Identification from Customer Feedback Data. (arXiv:2112.13372v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13372">
<div class="article-summary-box-inner">
<span><p>Millions of packages are delivered successfully by online and local retail
stores across the world every day. The proper delivery of packages is needed to
ensure high customer satisfaction and repeat purchases. These deliveries suffer
various problems despite the best efforts from the stores. These issues happen
not only due to the large volume and high demand for low turnaround time but
also due to mechanical operations and natural factors. These issues range from
receiving wrong items in the package to delayed shipment to damaged packages
because of mishandling during transportation. Finding solutions to various
delivery issues faced by both sending and receiving parties plays a vital role
in increasing the efficiency of the entire process. This paper shows how to
find these issues using customer feedback from the text comments and uploaded
images. We used transfer learning for both Text and Image models to minimize
the demand for thousands of labeled examples. The results show that the model
can find different issues. Furthermore, it can also be used for tasks like
bottleneck identification, process improvement, automating refunds, etc.
Compared with the existing process, the ensemble of text and image models
proposed in this paper ensures the identification of several types of delivery
issues, which is more suitable for the real-life scenarios of delivery of items
in retail businesses. This method can supply a new idea of issue detection for
the delivery of packages in similar industries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sinogram upsampling using Primal-Dual UNet for undersampled CT and radial MRI reconstruction. (arXiv:2112.13443v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13443">
<div class="article-summary-box-inner">
<span><p>CT and MRI are two widely used clinical imaging modalities for non-invasive
diagnosis. However, both of these modalities come with certain problems. CT
uses harmful ionising radiation, and MRI suffers from slow acquisition speed.
Both problems can be tackled by undersampling, such as sparse sampling.
However, such undersampled data leads to lower resolution and introduces
artefacts. Several techniques, including deep learning based methods, have been
proposed to reconstruct such data. However, the undersampled reconstruction
problem for these two modalities was always considered as two different
problems and tackled separately by different research works. This paper
proposes a unified solution for both sparse CT and undersampled radial MRI
reconstruction, achieved by applying Fourier transform-based pre-processing on
the radial MRI and then reconstructing both modalities using sinogram
upsampling combined with filtered back-projection. The Primal-Dual network is a
deep learning based method for reconstructing sparsely-sampled CT data. This
paper introduces Primal-Dual UNet, which improves the Primal-Dual network in
terms of accuracy and reconstruction speed. The proposed method resulted in an
average SSIM of 0.932 while performing sparse CT reconstruction for fan-beam
geometry with a sparsity level of 16, achieving a statistically significant
improvement over the previous model, which resulted in 0.919. Furthermore, the
proposed model resulted in 0.903 and 0.957 average SSIM while reconstructing
undersampled brain and abdominal MRI data with an acceleration factor of 16 -
statistically significant improvements over the original model, which resulted
in 0.867 and 0.949. Finally, this paper shows that the proposed network not
only improves the overall image quality, but also improves the image quality
for the regions-of-interest; as well as generalises better in presence of a
needle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PreDisM: Pre-Disaster Modelling With CNN Ensembles for At-Risk Communities. (arXiv:2112.13465v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13465">
<div class="article-summary-box-inner">
<span><p>The machine learning community has recently had increased interest in the
climate and disaster damage domain due to a marked increased occurrences of
natural hazards (e.g., hurricanes, forest fires, floods, earthquakes). However,
not enough attention has been devoted to mitigating probable destruction from
impending natural hazards. We explore this crucial space by predicting
building-level damages on a before-the-fact basis that would allow state actors
and non-governmental organizations to be best equipped with resource
distribution to minimize or preempt losses. We introduce PreDisM that employs
an ensemble of ResNets and fully connected layers over decision trees to
capture image-level and meta-level information to accurately estimate weakness
of man-made structures to disaster-occurrences. Our model performs well and is
responsive to tuning across types of disasters and highlights the space of
preemptive hazard damage modelling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Joint Modelling Based on Hierarchical Transformer for Co-summarization. (arXiv:2112.13478v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13478">
<div class="article-summary-box-inner">
<span><p>Video summarization aims to automatically generate a summary (storyboard or
video skim) of a video, which can facilitate large-scale video retrieving and
browsing. Most of the existing methods perform video summarization on
individual videos, which neglects the correlations among similar videos. Such
correlations, however, are also informative for video understanding and video
summarization. To address this limitation, we propose Video Joint Modelling
based on Hierarchical Transformer (VJMHT) for co-summarization, which takes
into consideration the semantic dependencies across videos. Specifically, VJMHT
consists of two layers of Transformer: the first layer extracts semantic
representation from individual shots of similar videos, while the second layer
performs shot-level video joint modelling to aggregate cross-video semantic
information. By this means, complete cross-video high-level patterns are
explicitly modelled and learned for the summarization of individual videos.
Moreover, Transformer-based video representation reconstruction is introduced
to maximize the high-level similarity between the summary and the original
video. Extensive experiments are conducted to verify the effectiveness of the
proposed modules and the superiority of VJMHT in terms of F-measure and
rank-based evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Compact Neural Network-based Algorithm for Robust Image Watermarking. (arXiv:2112.13491v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13491">
<div class="article-summary-box-inner">
<span><p>Digital image watermarking seeks to protect the digital media information
from unauthorized access, where the message is embedded into the digital image
and extracted from it, even some noises or distortions are applied under
various data processing including lossy image compression and interactive
content editing. Traditional image watermarking solutions easily suffer from
robustness when specified with some prior constraints, while recent deep
learning-based watermarking methods could not tackle the information loss
problem well under various separate pipelines of feature encoder and decoder.
In this paper, we propose a novel digital image watermarking solution with a
compact neural network, named Invertible Watermarking Network (IWN). Our IWN
architecture is based on a single Invertible Neural Network (INN), this
bijective propagation framework enables us to effectively solve the challenge
of message embedding and extraction simultaneously, by taking them as a pair of
inverse problems for each other and learning a stable invertible mapping. In
order to enhance the robustness of our watermarking solution, we specifically
introduce a simple but effective bit message normalization module to condense
the bit message to be embedded, and a noise layer is designed to simulate
various practical attacks under our IWN framework. Extensive experiments
demonstrate the superiority of our solution under various distortions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Transformer for Small-Size Datasets. (arXiv:2112.13492v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13492">
<div class="article-summary-box-inner">
<span><p>Recently, the Vision Transformer (ViT), which applied the transformer
structure to the image classification task, has outperformed convolutional
neural networks. However, the high performance of the ViT results from
pre-training using a large-size dataset such as JFT-300M, and its dependence on
a large dataset is interpreted as due to low locality inductive bias. This
paper proposes Shifted Patch Tokenization (SPT) and Locality Self-Attention
(LSA), which effectively solve the lack of locality inductive bias and enable
it to learn from scratch even on small-size datasets. Moreover, SPT and LSA are
generic and effective add-on modules that are easily applicable to various
ViTs. Experimental results show that when both SPT and LSA were applied to the
ViTs, the performance improved by an average of 2.96% in Tiny-ImageNet, which
is a representative small-size dataset. Especially, Swin Transformer achieved
an overwhelming performance improvement of 4.08% thanks to the proposed SPT and
LSA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating Parameters of the Tree Root in Heterogeneous Soil Environments via Mask-Guided Multi-Polarimetric Integration Neural Network. (arXiv:2112.13494v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13494">
<div class="article-summary-box-inner">
<span><p>Ground-penetrating radar (GPR) has been used as a non-destructive tool for
tree root inspection. Estimating root-related parameters from GPR radargrams
greatly facilitates root health monitoring and imaging. However, the task of
estimating root-related parameters is challenging as the root reflection is a
complex function of multiple root parameters and root orientations. Existing
methods can only estimate a single root parameter at a time without considering
the influence of other parameters and root orientations, resulting in limited
estimation accuracy under different root conditions. In addition, soil
heterogeneity introduces clutter in GPR radargrams, making the data processing
and interpretation even harder. To address these issues, a novel neural network
architecture, called mask-guided multi-polarimetric integration neural network
(MMI-Net), is proposed to automatically and simultaneously estimate multiple
root-related parameters in heterogeneous soil environments. The MMI-Net
includes two sub-networks: a MaskNet that predicts a mask to highlight the root
reflection area to eliminate interfering environmental clutter, and a ParaNet
that uses the predicted mask as guidance to integrate, extract, and emphasize
informative features in multi-polarimetric radargrams for accurate estimation
of five key root-related parameters. The parameters include the root depth,
diameter, relative permittivity, horizontal and vertical orientation angles.
Experimental results demonstrate that the proposed MMI-Net achieves high
estimation accuracy in these root-related parameters. This is the first work
that takes the combined contributions of root parameters and spatial
orientations into account and simultaneously estimates multiple root-related
parameters. The data and code implemented in the paper can be found at
https://haihan-sun.github.io/GPR.html.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MSHT: Multi-stage Hybrid Transformer for the ROSE Image Analysis of Pancreatic Cancer. (arXiv:2112.13513v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13513">
<div class="article-summary-box-inner">
<span><p>Pancreatic cancer is one of the most malignant cancers in the world, which
deteriorates rapidly with very high mortality. The rapid on-site evaluation
(ROSE) technique innovates the workflow by immediately analyzing the fast
stained cytopathological images with on-site pathologists, which enables faster
diagnosis in this time-pressured process. However, the wider expansion of ROSE
diagnosis has been hindered by the lack of experienced pathologists. To
overcome this problem, we propose a hybrid high-performance deep learning model
to enable the automated workflow, thus freeing the occupation of the valuable
time of pathologists. By firstly introducing the Transformer block into this
field with our particular multi-stage hybrid design, the spatial features
generated by the convolutional neural network (CNN) significantly enhance the
Transformer global modeling. Turning multi-stage spatial features as global
attention guidance, this design combines the robustness from the inductive bias
of CNN with the sophisticated global modeling power of Transformer. A dataset
of 4240 ROSE images is collected to evaluate the method in this unexplored
field. The proposed multi-stage hybrid Transformer (MSHT) achieves 95.68% in
classification accuracy, which is distinctively higher than the
state-of-the-art models. Facing the need for interpretability, MSHT outperforms
its counterparts with more accurate attention regions. The results demonstrate
that the MSHT can distinguish cancer samples accurately at an unprecedented
image scale, laying the foundation for deploying automatic decision systems and
enabling the expansion of ROSE in clinical practice. The code and records are
available at: https://github.com/sagizty/Multi-Stage-Hybrid-Transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Contrastive Learning for General Face Forgery Detection. (arXiv:2112.13522v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13522">
<div class="article-summary-box-inner">
<span><p>With various facial manipulation techniques arising, face forgery detection
has drawn growing attention due to security concerns. Previous works always
formulate face forgery detection as a classification problem based on
cross-entropy loss, which emphasizes category-level differences rather than the
essential discrepancies between real and fake faces, limiting model
generalization in unseen domains. To address this issue, we propose a novel
face forgery detection framework, named Dual Contrastive Learning (DCL), which
specially constructs positive and negative paired data and performs designed
contrastive learning at different granularities to learn generalized feature
representation. Concretely, combined with the hard sample selection strategy,
Inter-Instance Contrastive Learning (Inter-ICL) is first proposed to promote
task-related discriminative features learning by especially constructing
instance pairs. Moreover, to further explore the essential discrepancies,
Intra-Instance Contrastive Learning (Intra-ICL) is introduced to focus on the
local content inconsistencies prevalent in the forged faces by constructing
local-region pairs inside instances. Extensive experiments and visualizations
on several datasets demonstrate the generalization of our method against the
state-of-the-art competitors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Generative Vision Transformer with Energy-Based Latent Space for Saliency Prediction. (arXiv:2112.13528v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13528">
<div class="article-summary-box-inner">
<span><p>Vision transformer networks have shown superiority in many computer vision
tasks. In this paper, we take a step further by proposing a novel generative
vision transformer with latent variables following an informative energy-based
prior for salient object detection. Both the vision transformer network and the
energy-based prior model are jointly trained via Markov chain Monte Carlo-based
maximum likelihood estimation, in which the sampling from the intractable
posterior and prior distributions of the latent variables are performed by
Langevin dynamics. Further, with the generative vision transformer, we can
easily obtain a pixel-wise uncertainty map from an image, which indicates the
model confidence in predicting saliency from the image. Different from the
existing generative models which define the prior distribution of the latent
variables as a simple isotropic Gaussian distribution, our model uses an
energy-based informative prior which can be more expressive to capture the
latent space of the data. We apply the proposed framework to both RGB and RGB-D
salient object detection tasks. Extensive experimental results show that our
framework can achieve not only accurate saliency predictions but also
meaningful uncertainty maps that are consistent with the human perception.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Attack for Asynchronous Event-based Data. (arXiv:2112.13534v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13534">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) are vulnerable to adversarial examples that are
carefully designed to cause the deep learning model to make mistakes.
Adversarial examples of 2D images and 3D point clouds have been extensively
studied, but studies on event-based data are limited. Event-based data can be
an alternative to a 2D image under high-speed movements, such as autonomous
driving. However, the given adversarial events make the current deep learning
model vulnerable to safety issues. In this work, we generate adversarial
examples and then train the robust models for event-based data, for the first
time. Our algorithm shifts the time of the original events and generates
additional adversarial events. Additional adversarial events are generated in
two stages. First, null events are added to the event-based data to generate
additional adversarial events. The perturbation size can be controlled with the
number of null events. Second, the location and time of additional adversarial
events are set to mislead DNNs in a gradient-based attack. Our algorithm
achieves an attack success rate of 97.95\% on the N-Caltech101 dataset.
Furthermore, the adversarial training model improves robustness on the
adversarial event data compared to the original model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Learned Feature Critics for Domain Generalized Semantic Segmentation. (arXiv:2112.13538v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13538">
<div class="article-summary-box-inner">
<span><p>How to handle domain shifts when recognizing or segmenting visual data across
domains has been studied by learning and vision communities. In this paper, we
address domain generalized semantic segmentation, in which the segmentation
model is trained on multiple source domains and is expected to generalize to
unseen data domains. We propose a novel meta-learning scheme with feature
disentanglement ability, which derives domain-invariant features for semantic
segmentation with domain generalization guarantees. In particular, we introduce
a class-specific feature critic module in our framework, enforcing the
disentangled visual features with domain generalization guarantees. Finally,
our quantitative results on benchmark datasets confirm the effectiveness and
robustness of our proposed model, performing favorably against state-of-the-art
domain adaptation and generalization methods in segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Classification in Unseen Domains by Episodic Meta-Learning Across Visual Domains. (arXiv:2112.13539v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13539">
<div class="article-summary-box-inner">
<span><p>Few-shot classification aims to carry out classification given only few
labeled examples for the categories of interest. Though several approaches have
been proposed, most existing few-shot learning (FSL) models assume that base
and novel classes are drawn from the same data domain. When it comes to
recognizing novel-class data in an unseen domain, this becomes an even more
challenging task of domain generalized few-shot classification. In this paper,
we present a unique learning framework for domain-generalized few-shot
classification, where base classes are from homogeneous multiple source
domains, while novel classes to be recognized are from target domains which are
not seen during training. By advancing meta-learning strategies, our learning
framework exploits data across multiple source domains to capture
domain-invariant features, with FSL ability introduced by metric-learning based
mechanisms across support and query data. We conduct extensive experiments to
verify the effectiveness of our proposed learning framework and show learning
from small yet homogeneous source data is able to perform preferably against
learning from large-scale one. Moreover, we provide insights into choices of
backbone models for domain-generalized few-shot classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Edge Restoring Filter. (arXiv:2112.13540v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13540">
<div class="article-summary-box-inner">
<span><p>In computer vision, image processing and computer graphics, image smoothing
filtering is a very basic and important task and to be expected possessing good
edge-preserving smoothing property. Here we address the problem that the
edge-preserving ability of many popular local smoothing filters needs to be
improved. In this paper, we propose the image Edge Restoring Filter (ERF) to
restore the blur edge pixels in the output of local smoothing filters to be
clear. The proposed filter can been implemented after many local smoothing
filter (such as Box filter, Gaussian filter, Bilateral Filter, Guided Filter
and so on). The combinations of "original local smoothing filters + ERF" have
better edge-preserving smoothing property than the original local smoothing
filters. Experiments on image smoothing, image denoising and image enhancement
demonstrate the excellent edges restoring ability of the proposed filter and
good edgepreserving smoothing property of the combination "original local
smoothing filters + ERF". The proposed filter would benefit a great variety of
applications given that smoothing filtering is a high frequently used and
fundamental operation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViR:the Vision Reservoir. (arXiv:2112.13545v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13545">
<div class="article-summary-box-inner">
<span><p>The most recent year has witnessed the success of applying the Vision
Transformer (ViT) for image classification. However, there are still evidences
indicating that ViT often suffers following two aspects, i) the high
computation and the memory burden from applying the multiple Transformer layers
for pre-training on a large-scale dataset, ii) the over-fitting when training
on small datasets from scratch. To address these problems, a novel method,
namely, Vision Reservoir computing (ViR), is proposed here for image
classification, as a parallel to ViT. By splitting each image into a sequence
of tokens with fixed length, the ViR constructs a pure reservoir with a nearly
fully connected topology to replace the Transformer module in ViT. Two kinds of
deep ViR models are subsequently proposed to enhance the network performance.
Comparative experiments between the ViR and the ViT are carried out on several
image classification benchmarks. Without any pre-training process, the ViR
outperforms the ViT in terms of both model and computational complexity.
Specifically, the number of parameters of the ViR is about 15% even 5% of the
ViT, and the memory footprint is about 20% to 40% of the ViT. The superiority
of the ViR performance is explained by Small-World characteristics, Lyapunov
exponents, and memory capacity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PRIME: A Few Primitives Can Boost Robustness to Common Corruptions. (arXiv:2112.13547v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13547">
<div class="article-summary-box-inner">
<span><p>Despite their impressive performance on image classification tasks, deep
networks have a hard time generalizing to many common corruptions of their
data. To fix this vulnerability, prior works have mostly focused on increasing
the complexity of their training pipelines, combining multiple methods, in the
name of diversity. However, in this work, we take a step back and follow a
principled approach to achieve robustness to common corruptions. We propose
PRIME, a general data augmentation scheme that consists of simple families of
max-entropy image transformations. We show that PRIME outperforms the prior art
for corruption robustness, while its simplicity and plug-and-play nature
enables it to be combined with other methods to further boost their robustness.
Furthermore, we analyze PRIME to shed light on the importance of the mixing
strategy on synthesizing corrupted images, and to reveal the
robustness-accuracy trade-offs arising in the context of common corruptions.
Finally, we show that the computational efficiency of our method allows it to
be easily used in both on-line and off-line data augmentation schemes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Responsive Listening Head Generation: A Benchmark Dataset and Baseline. (arXiv:2112.13548v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13548">
<div class="article-summary-box-inner">
<span><p>Responsive listening during face-to-face conversations is a critical element
of social interaction and is well established in psychological research.
Through non-verbal signals response to the speakers' words, intonations, or
behaviors in real-time, listeners show how they are engaged in dialogue. In
this work, we build the Responsive Listener Dataset (RLD), a conversation video
corpus collected from the public resources featuring 67 speakers, 76 listeners
with three different attitudes. We define the responsive listening head
generation task as the synthesis of a non-verbal head with motions and
expressions reacting to the multiple inputs, including the audio and visual
signal of the speaker. Unlike speech-driven gesture or talking head generation,
we introduce more modals in this task, hoping to benefit several research
fields, including human-to-human interaction, video-to-video translation,
cross-modal understanding, and generation. Furthermore, we release an attitude
conditioned listening head generation baseline. Project page:
\url{https://project.mhzhou.com/rld}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Robust and Lightweight Model through Separable Structured Transformations. (arXiv:2112.13551v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13551">
<div class="article-summary-box-inner">
<span><p>With the proliferation of mobile devices and the Internet of Things, deep
learning models are increasingly deployed on devices with limited computing
resources and memory, and are exposed to the threat of adversarial noise.
Learning deep models with both lightweight and robustness is necessary for
these equipments. However, current deep learning solutions are difficult to
learn a model that possesses these two properties without degrading one or the
other. As is well known, the fully-connected layers contribute most of the
parameters of convolutional neural networks. We perform a separable structural
transformation of the fully-connected layer to reduce the parameters, where the
large-scale weight matrix of the fully-connected layer is decoupled by the
tensor product of several separable small-sized matrices. Note that data, such
as images, no longer need to be flattened before being fed to the
fully-connected layer, retaining the valuable spatial geometric information of
the data. Moreover, in order to further enhance both lightweight and
robustness, we propose a joint constraint of sparsity and differentiable
condition number, which is imposed on these separable matrices. We evaluate the
proposed approach on MLP, VGG-16 and Vision Transformer. The experimental
results on datasets such as ImageNet, SVHN, CIFAR-100 and CIFAR10 show that we
successfully reduce the amount of network parameters by 90%, while the robust
accuracy loss is less than 1.5%, which is better than the SOTA methods based on
the original fully-connected layer. Interestingly, it can achieve an
overwhelming advantage even at a high compression rate, e.g., 200 times.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of Histopathology Images of Lung Cancer Using Convolutional Neural Network (CNN). (arXiv:2112.13553v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13553">
<div class="article-summary-box-inner">
<span><p>Cancer is the uncontrollable cell division of abnormal cells inside the human
body, which can spread to other body organs. It is one of the non-communicable
diseases (NCDs) and NCDs accounts for 71% of total deaths worldwide whereas
lung cancer is the second most diagnosed cancer after female breast cancer.
Cancer survival rate of lung cancer is only 19%. There are various methods for
the diagnosis of lung cancer, such as X-ray, CT scan, PET-CT scan, bronchoscopy
and biopsy. However, to know the subtype of lung cancer based on the tissue
type H and E staining is widely used, where the staining is done on the tissue
aspirated from a biopsy. Studies have reported that the type of histology is
associated with prognosis and treatment in lung cancer. Therefore, early and
accurate detection of lung cancer histology is an urgent need and as its
treatment is dependent on the type of histology, molecular profile and stage of
the disease, it is most essential to analyse the histopathology images of lung
cancer. Hence, to speed up the vital process of diagnosis of lung cancer and
reduce the burden on pathologists, Deep learning techniques are used. These
techniques have shown improved efficacy in the analysis of histopathology
slides of cancer. Several studies reported the importance of convolution neural
networks (CNN) in the classification of histopathological pictures of various
cancer types such as brain, skin, breast, lung, colorectal cancer. In this
study tri-category classification of lung cancer images (normal, adenocarcinoma
and squamous cell carcinoma) are carried out by using ResNet 50, VGG-19,
Inception_ResNet_V2 and DenseNet for the feature extraction and triplet loss to
guide the CNN such that it increases inter-cluster distance and reduces
intra-cluster distance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DAM-AL: Dilated Attention Mechanism with Attention Loss for 3D Infant Brain Image Segmentation. (arXiv:2112.13559v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13559">
<div class="article-summary-box-inner">
<span><p>While Magnetic Resonance Imaging (MRI) has played an essential role in infant
brain analysis, segmenting MRI into a number of tissues such as gray matter
(GM), white matter (WM), and cerebrospinal fluid (CSF) is crucial and complex
due to the extremely low intensity contrast between tissues at around 6-9
months of age as well as amplified noise, myelination, and incomplete volume.
In this paper, we tackle those limitations by developing a new deep learning
model, named DAM-AL, which contains two main contributions, i.e., dilated
attention mechanism and hard-case attention loss. Our DAM-AL network is
designed with skip block layers and atrous block convolution. It contains both
channel-wise attention at high-level context features and spatial attention at
low-level spatial structural features. Our attention loss consists of two terms
corresponding to region information and hard samples attention. Our proposed
DAM-AL has been evaluated on the infant brain iSeg 2017 dataset and the
experiments have been conducted on both validation and testing sets. We have
benchmarked DAM-AL on Dice coefficient and ASD metrics and compared it with
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hard Example Guided Hashing for Image Retrieval. (arXiv:2112.13565v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13565">
<div class="article-summary-box-inner">
<span><p>Compared with the traditional hashing methods, deep hashing methods generate
hash codes with rich semantic information and greatly improves the performances
in the image retrieval field. However, it is unsatisfied for current deep
hashing methods to predict the similarity of hard examples. It exists two main
factors affecting the ability of learning hard examples, which are weak key
features extraction and the shortage of hard examples. In this paper, we give a
novel end-to-end model to extract the key feature from hard examples and obtain
hash code with the accurate semantic information. In addition, we redesign a
hard pair-wise loss function to assess the hard degree and update penalty
weights of examples. It effectively alleviates the shortage problem in hard
examples. Experimental results on CIFAR-10 and NUS-WIDE demonstrate that our
model outperformances the mainstream hashing-based image retrieval methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vegetation Stratum Occupancy Prediction from Airborne LiDAR 3D Point Clouds. (arXiv:2112.13583v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13583">
<div class="article-summary-box-inner">
<span><p>We propose a new deep learning-based method for estimating the occupancy of
vegetation strata from 3D point clouds captured from an aerial platform. Our
model predicts rasterized occupancy maps for three vegetation strata: lower,
medium, and higher strata. Our training scheme allows our network to only being
supervized with values aggregated over cylindrical plots, which are easier to
produce than pixel-wise or point-wise annotations. Our method outperforms
handcrafted and deep learning baselines in terms of precision while
simultaneously providing visual and interpretable predictions. We provide an
open-source implementation of our method along along a dataset of 199
agricultural plots to train and evaluate occupancy regression algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Image Synthesis and Editing: A Survey. (arXiv:2112.13592v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13592">
<div class="article-summary-box-inner">
<span><p>As information exists in various modalities in real world, effective
interaction and fusion among multimodal information plays a key role for the
creation and perception of multimodal data in computer vision and deep learning
research. With superb power in modelling the interaction among multimodal
information, multimodal image synthesis and editing have become a hot research
topic in recent years. Different from traditional visual guidance which
provides explicit clues, multimodal guidance offers intuitive and flexible
means in image synthesis and editing. On the other hand, this field is also
facing several challenges in alignment of features with inherent modality gaps,
synthesis of high-resolution images, faithful evaluation metrics, etc. In this
survey, we comprehensively contextualize the advance of the recent multimodal
image synthesis \&amp; editing and formulate taxonomies according to data modality
and model architectures. We start with an introduction to different types of
guidance modalities in image synthesis and editing. We then describe multimodal
image synthesis and editing approaches extensively with detailed frameworks
including Generative Adversarial Networks (GANs), GAN Inversion, Transformers,
and other methods such as NeRF and Diffusion models. This is followed by a
comprehensive description of benchmark datasets and corresponding evaluation
metrics as widely adopted in multimodal image synthesis and editing, as well as
detailed comparisons of different synthesis methods with analysis of respective
advantages and limitations. Finally, we provide insights into the current
research challenges and possible future research directions. A project
associated with this survey is available at https://github.com/fnzhan/MISE
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Depth estimation of endoscopy using sim-to-real transfer. (arXiv:2112.13595v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13595">
<div class="article-summary-box-inner">
<span><p>In order to use the navigation system effectively, distance information
sensors such as depth sensors are essential. Since depth sensors are difficult
to use in endoscopy, many groups propose a method using convolutional neural
networks. In this paper, the ground truth of the depth image and the endoscopy
image is generated through endoscopy simulation using the colon model segmented
by CT colonography. Photo-realistic simulation images can be created using a
sim-to-real approach using cycleGAN for endoscopy images. By training the
generated dataset, we propose a quantitative endoscopy depth estimation
network. The proposed method represents a better-evaluated score than the
existing unsupervised training-based results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study of Adder Neural Networks for Object Detection. (arXiv:2112.13608v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13608">
<div class="article-summary-box-inner">
<span><p>Adder neural networks (AdderNets) have shown impressive performance on image
classification with only addition operations, which are more energy efficient
than traditional convolutional neural networks built with multiplications.
Compared with classification, there is a strong demand on reducing the energy
consumption of modern object detectors via AdderNets for real-world
applications such as autonomous driving and face detection. In this paper, we
present an empirical study of AdderNets for object detection. We first reveal
that the batch normalization statistics in the pre-trained adder backbone
should not be frozen, since the relatively large feature variance of AdderNets.
Moreover, we insert more shortcut connections in the neck part and design a new
feature fusion architecture for avoiding the sparse features of adder layers.
We present extensive ablation studies to explore several design choices of
adder detectors. Comparisons with state-of-the-arts are conducted on COCO and
PASCAL VOC benchmarks. Specifically, the proposed Adder FCOS achieves a 37.8\%
AP on the COCO val set, demonstrating comparable performance to that of the
convolutional counterpart with an about $1.4\times$ energy reduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generation of Synthetic Rat Brain MRI scans with a 3D Enhanced Alpha-GAN. (arXiv:2112.13626v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13626">
<div class="article-summary-box-inner">
<span><p>Translational brain research using Magnetic Resonance Imaging (MRI) is
becoming increasingly popular as animal models are an essential part of
scientific studies and ultra-high-field scanners become more available. Some
drawbacks of MRI are MRI scanner availability, and the time needed to perform a
full scanning session (it usually takes over 30 minutes). Data protection laws
and 3R ethical rule also make it difficult to create large data sets for
training Deep Learning models. Generative Adversarial Networks (GAN) have been
shown capable of performing data augmentation with higher quality than other
techniques. In this work, the alpha-GAN architecture is used to test its
ability to generate realistic 3D MRI scans of the rat brain. As far as the
authors are aware, this is the first time an approach based on GANs is used for
data augmentation in preclinical data. The generated scans are evaluated using
various qualitative and quantitative metrics. A Turing test performed by 4
experts has shown that the generated scans can trick almost any expert. The
generated scans were also used to evaluate their impact on the performance of
an existing deep learning model developed for rat brain segmentation of white
matter, grey matter, and cerebrospinal fluid. The models were compared using
the Dice score. The best results for the segmentation of whole brain and white
matter were achieved when 174 real scans and 348 synthetic ones were used, with
improvements of 0.0172 and 0.0129. The use of 174 real scans and 87 synthetic
ones led to improvements of 0.0038 and 0.0764 of grey matter and cerebrospinal
fluid segmentation. Thus, by using the proposed new normalisation layer and
loss functions, it was possible to improve the realism of the generated rat MRI
scans and it was demonstrated that using the data generated improved the
segmentation model more than using conventional data augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaptivePose: Human Parts as Adaptive Points. (arXiv:2112.13635v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13635">
<div class="article-summary-box-inner">
<span><p>Multi-person pose estimation methods generally follow top-down and bottom-up
paradigms, both of which can be considered as two-stage approaches thus leading
to the high computation cost and low efficiency. Towards a compact and
efficient pipeline for multi-person pose estimation task, in this paper, we
propose to represent the human parts as points and present a novel body
representation, which leverages an adaptive point set including the human
center and seven human-part related points to represent the human instance in a
more fine-grained manner. The novel representation is more capable of capturing
the various pose deformation and adaptively factorizes the long-range
center-to-joint displacement thus delivers a single-stage differentiable
network to more precisely regress multi-person pose, termed as AdaptivePose.
For inference, our proposed network eliminates the grouping as well as
refinements and only needs a single-step disentangling process to form
multi-person pose. Without any bells and whistles, we achieve the best
speed-accuracy trade-offs of 67.4% AP / 29.4 fps with DLA-34 and 71.3% AP / 9.1
fps with HRNet-W48 on COCO test-dev dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-normalized Classification of Parkinson's Disease DaTscan Images. (arXiv:2112.13637v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13637">
<div class="article-summary-box-inner">
<span><p>Classifying SPECT images requires a preprocessing step which normalizes the
images using a normalization region. The choice of the normalization region is
not standard, and using different normalization regions introduces
normalization region-dependent variability. This paper mathematically analyzes
the effect of the normalization region to show that normalized-classification
is exactly equivalent to a subspace separation of the half rays of the images
under multiplicative equivalence. Using this geometry, a new self-normalized
classification strategy is proposed. This strategy eliminates the normalizing
region altogether. The theory is used to classify DaTscan images of 365
Parkinson's disease (PD) subjects and 208 healthy control (HC) subjects from
the Parkinson's Progression Marker Initiative (PPMI). The theory is also used
to understand PD progression from baseline to year 4.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding the Perceived Quality of Video Predictions. (arXiv:2005.00356v5 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00356">
<div class="article-summary-box-inner">
<span><p>The study of video prediction models is believed to be a fundamental approach
to representation learning for videos. While a plethora of generative models
for predicting the future frame pixel values given the past few frames exist,
the quantitative evaluation of the predicted frames has been found to be
extremely challenging. In this context, we study the problem of quality
assessment of predicted videos. We create the Indian Institute of Science
Predicted Videos Quality Assessment (IISc PVQA) Database consisting of 300
videos, obtained by applying different prediction models on different datasets,
and accompanying human opinion scores. We collected subjective ratings of
quality from 50 human participants for these videos. Our subjective study
reveals that human observers were highly consistent in their judgments of
quality of predicted videos. We benchmark several popularly used measures for
evaluating video prediction and show that they do not adequately correlate with
these subjective scores. We introduce two new features to effectively capture
the quality of predicted videos, motion-compensated cosine similarities of deep
features of predicted frames with past frames, and deep features extracted from
rescaled frame differences. We show that our feature design leads to state of
the art quality prediction in accordance with human judgments on our IISc PVQA
Database. The database and code are publicly available on our project website:
https://nagabhushansn95.github.io/publications/2020/pvqa
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attentive WaveBlock: Complementarity-enhanced Mutual Networks for Unsupervised Domain Adaptation in Person Re-identification and Beyond. (arXiv:2006.06525v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06525">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation (UDA) for person re-identification is
challenging because of the huge gap between the source and target domain. A
typical self-training method is to use pseudo-labels generated by clustering
algorithms to iteratively optimize the model on the target domain. However, a
drawback to this is that noisy pseudo-labels generally cause trouble in
learning. To address this problem, a mutual learning method by dual networks
has been developed to produce reliable soft labels. However, as the two neural
networks gradually converge, their complementarity is weakened and they likely
become biased towards the same kind of noise. This paper proposes a novel
light-weight module, the Attentive WaveBlock (AWB), which can be integrated
into the dual networks of mutual learning to enhance the complementarity and
further depress noise in the pseudo-labels. Specifically, we first introduce a
parameter-free module, the WaveBlock, which creates a difference between
features learned by two networks by waving blocks of feature maps differently.
Then, an attention mechanism is leveraged to enlarge the difference created and
discover more complementary features. Furthermore, two kinds of combination
strategies, i.e. pre-attention and post-attention, are explored. Experiments
demonstrate that the proposed method achieves state-of-the-art performance with
significant improvements on multiple UDA person re-identification tasks. We
also prove the generality of the proposed method by applying it to vehicle
re-identification and image classification tasks. Our codes and models are
available at https://github.com/WangWenhao0716/Attentive-WaveBlock.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Elements of End-to-end Deep Face Recognition: A Survey of Recent Advances. (arXiv:2009.13290v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13290">
<div class="article-summary-box-inner">
<span><p>Face recognition is one of the most popular and long-standing topics in
computer vision. With the recent development of deep learning techniques and
large-scale datasets, deep face recognition has made remarkable progress and
been widely used in many real-world applications. Given a natural image or
video frame as input, an end-to-end deep face recognition system outputs the
face feature for recognition. To achieve this, a typical end-to-end system is
built with three key elements: face detection, face alignment, and face
representation. The face detection locates faces in the image or frame. Then,
the face alignment is proceeded to calibrate the faces to the canonical view
and crop them with a normalized pixel size. Finally, in the stage of face
representation, the discriminative features are extracted from the aligned face
for recognition. Nowadays, all of the three elements are fulfilled by the
technique of deep convolutional neural network. In this survey article, we
present a comprehensive review about the recent advance of each element. To
start with, we present an overview of the end-to-end deep face recognition.
Then, we review the advance of each element, respectively, covering many
aspects such as the to-date algorithm designs, evaluation metrics, datasets,
performance comparison, existing challenges, and promising directions for
future research. Also, we provide a detailed discussion about the effect of
each element on its subsequent elements and the holistic system. Through this
survey, we wish to bring contributions in two aspects: first, readers can
conveniently identify the methods which are quite strong-baseline style in the
subcategory for further exploration; second, one can also employ suitable
methods for establishing a state-of-the-art end-to-end face recognition system
from scratch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distributionally Robust Learning for Uncertainty Calibration under Domain Shift. (arXiv:2010.05784v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05784">
<div class="article-summary-box-inner">
<span><p>We propose a framework for learning calibrated uncertainties under domain
shifts. We consider the case where the source (training) distribution differs
from the target (test) distribution. We detect such domain shifts through the
use of a binary domain classifier and integrate it with the task network and
train them jointly end-to-end. The binary domain classifier yields a density
ratio that reflects the closeness of a target (test) sample to the source
(training) distribution. We employ it to adjust the uncertainty of prediction
in the task network. This idea of using the density ratio is based on the
distributionally robust learning (DRL) framework, which accounts for the domain
shift through adversarial risk minimization. We demonstrate that our method
generates calibrated uncertainties that benefit many downstream tasks, such as
unsupervised domain adaptation (UDA) and semi-supervised learning (SSL). In
these tasks, methods like self-training and FixMatch use uncertainties to
select confident pseudo-labels for re-training. Our experiments show that the
introduction of DRL leads to significant improvements in cross-domain
performance. We also demonstrate that the estimated density ratios show
agreement with the human selection frequencies, suggesting a positive
correlation with a proxy of human perceived uncertainties.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hand-Based Person Identification using Global and Part-Aware Deep Feature Representation Learning. (arXiv:2101.05260v7 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05260">
<div class="article-summary-box-inner">
<span><p>In cases of serious crime, including sexual abuse, often the only available
information with demonstrated potential for identification is images of the
hands. Since this evidence is captured in uncontrolled situations, it is
difficult to analyse. As global approaches to feature comparison are limited in
this case, it is important to extend to consider local information. In this
work, we propose hand-based person identification by learning both global and
local deep feature representation. Our proposed method, Global and Part-Aware
Network (GPA-Net), creates global and local branches on the conv-layer for
learning robust discriminative global and part-level features. For learning the
local (part-level) features, we perform uniform partitioning on the conv-layer
in both horizontal and vertical directions. We retrieve the parts by conducting
a soft partition without explicitly partitioning the images or requiring
external cues such as pose estimation. We make extensive evaluations on two
large multi-ethnic and publicly available hand datasets, demonstrating that our
proposed method significantly outperforms competing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Adaptive Training: Bridging Supervised and Self-Supervised Learning. (arXiv:2101.08732v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08732">
<div class="article-summary-box-inner">
<span><p>We propose self-adaptive training -- a unified training algorithm that
dynamically calibrates and enhances training processes by model predictions
without incurring an extra computational cost -- to advance both supervised and
self-supervised learning of deep neural networks. We analyze the training
dynamics of deep networks on training data that are corrupted by, e.g., random
noise and adversarial examples. Our analysis shows that model predictions are
able to magnify useful underlying information in data and this phenomenon
occurs broadly even in the absence of any label information, highlighting that
model predictions could substantially benefit the training processes:
self-adaptive training improves the generalization of deep networks under noise
and enhances the self-supervised representation learning. The analysis also
sheds light on understanding deep learning, e.g., a potential explanation of
the recently-discovered double-descent phenomenon in empirical risk
minimization and the collapsing issue of the state-of-the-art self-supervised
learning algorithms. Experiments on the CIFAR, STL, and ImageNet datasets
verify the effectiveness of our approach in three applications: classification
with label noise, selective classification, and linear evaluation. To
facilitate future research, the code has been made publicly available at
https://github.com/LayneH/self-adaptive-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anytime 3D Object Reconstruction using Multi-modal Variational Autoencoder. (arXiv:2101.10391v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10391">
<div class="article-summary-box-inner">
<span><p>For effective human-robot teaming, it is important for the robots to be able
to share their visual perception with the human operators. In a harsh remote
collaboration setting, data compression techniques such as autoencoder can be
utilized to obtain and transmit the data in terms of latent variables in a
compact form. In addition, to ensure real-time runtime performance even under
unstable environments, an anytime estimation approach is desired that can
reconstruct the full contents from incomplete information. In this context, we
propose a method for imputation of latent variables whose elements are
partially lost. To achieve the anytime property with only a few dimensions of
variables, exploiting prior information of the category-level is essential. A
prior distribution used in variational autoencoders is simply assumed to be
isotropic Gaussian regardless of the labels of each training datapoint. This
type of flattened prior makes it difficult to perform imputation from the
category-level distributions. We overcome this limitation by exploiting a
category-specific multi-modal prior distribution in the latent space. The
missing elements of the partially transferred data can be sampled, by finding a
specific modal according to the remaining elements. Since the method is
designed to use partial elements for anytime estimation, it can also be applied
for data over-compression. Based on the experiments on the ModelNet and
Pascal3D datasets, the proposed approach shows consistently superior
performance over autoencoder and variational autoencoder up to 70% data loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Aware Semi-Supervised Method Using Large Unlabeled and Limited Labeled COVID-19 Data. (arXiv:2102.06388v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06388">
<div class="article-summary-box-inner">
<span><p>The new coronavirus has caused more than one million deaths and continues to
spread rapidly. This virus targets the lungs, causing respiratory distress
which can be mild or severe. The X-ray or computed tomography (CT) images of
lungs can reveal whether the patient is infected with COVID-19 or not. Many
researchers are trying to improve COVID-19 detection using artificial
intelligence. Our motivation is to develop an automatic method that can cope
with scenarios in which preparing labeled data is time consuming or expensive.
In this article, we propose a Semi-supervised Classification using Limited
Labeled Data (SCLLD) relying on Sobel edge detection and Generative Adversarial
Networks (GANs) to automate the COVID-19 diagnosis. The GAN discriminator
output is a probabilistic value which is used for classification in this work.
The proposed system is trained using 10,000 CT scans collected from Omid
Hospital, whereas a public dataset is also used for validating our system. The
proposed method is compared with other state-of-the-art supervised methods such
as Gaussian processes. To the best of our knowledge, this is the first time a
semi-supervised method for COVID-19 detection is presented. Our system is
capable of learning from a mixture of limited labeled and unlabeled data where
supervised learners fail due to a lack of sufficient amount of labeled data.
Thus, our semi-supervised training method significantly outperforms the
supervised training of Convolutional Neural Network (CNN) when labeled training
data is scarce. The 95% confidence intervals for our method in terms of
accuracy, sensitivity, and specificity are 99.56 +- 0.20%, 99.88 +- 0.24%, and
99.40 +- 0.18%, respectively, whereas intervals for the CNN (trained
supervised) are 68.34 +- 4.11%, 91.2 +- 6.15%, and 46.40 +- 5.21%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reconstructing Recognizable 3D Face Shapes based on 3D Morphable Models. (arXiv:2104.03515v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03515">
<div class="article-summary-box-inner">
<span><p>Many recent works have reconstructed distinctive 3D face shapes by
aggregating shape parameters of the same identity and separating those of
different people based on parametric models (e.g., 3D morphable models
(3DMMs)). However, despite the high accuracy in the face recognition task using
these shape parameters, the visual discrimination of face shapes reconstructed
from those parameters is unsatisfactory. The following research question has
not been answered in previous works: Do discriminative shape parameters
guarantee visual discrimination in represented 3D face shapes? This paper
analyzes the relationship between shape parameters and reconstructed shape
geometry and proposes a novel shape identity-aware regularization(SIR) loss for
shape parameters, aiming at increasing discriminability in both the shape
parameter and shape geometry domains. Moreover, to cope with the lack of
training data containing both landmark and identity annotations, we propose a
network structure and an associated training strategy to leverage mixed data
containing either identity or landmark labels. We compare our method with
existing methods in terms of the reconstruction error, visual
distinguishability, and face recognition accuracy of the shape parameters.
Experimental results show that our method outperforms the state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skeleton-based Hand-Gesture Recognition with Lightweight Graph Convolutional Networks. (arXiv:2104.04255v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04255">
<div class="article-summary-box-inner">
<span><p>Graph convolutional networks (GCNs) aim at extending deep learning to
arbitrary irregular domains, namely graphs. Their success is highly dependent
on how the topology of input graphs is defined and most of the existing GCN
architectures rely on predefined or handcrafted graph structures. In this
paper, we introduce a novel method that learns the topology (or connectivity)
of input graphs as a part of GCN design. The main contribution of our method
resides in building an orthogonal connectivity basis that optimally aggregates
nodes, through their neighborhood, prior to achieve convolution. Our method
also considers a stochasticity criterion which acts as a regularizer that makes
the learned basis and the underlying GCNs lightweight while still being highly
effective. Experiments conducted on the challenging task of skeleton-based
hand-gesture recognition show the high effectiveness of the learned GCNs w.r.t.
the related work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from 2D: Contrastive Pixel-to-Point Knowledge Transfer for 3D Pretraining. (arXiv:2104.04687v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04687">
<div class="article-summary-box-inner">
<span><p>Most 3D neural networks are trained from scratch owing to the lack of
large-scale labeled 3D datasets. In this paper, we present a novel 3D
pretraining method by leveraging 2D networks learned from rich 2D datasets. We
propose the contrastive pixel-to-point knowledge transfer to effectively
utilize the 2D information by mapping the pixel-level and point-level features
into the same embedding space. Due to the heterogeneous nature between 2D and
3D networks, we introduce the back-projection function to align the features
between 2D and 3D to make the transfer possible. Additionally, we devise an
upsampling feature projection layer to increase the spatial resolution of
high-level 2D feature maps, which enables learning fine-grained 3D
representations. With a pretrained 2D network, the proposed pretraining process
requires no additional 2D or 3D labeled data, further alleviating the expensive
3D data annotation cost. To the best of our knowledge, we are the first to
exploit existing 2D trained weights to pretrain 3D deep neural networks. Our
intensive experiments show that the 3D models pretrained with 2D knowledge
boost the performances of 3D networks across various real-world 3D downstream
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Chebyshev Basis in Graph Convolutional Networks for Skeleton-based Action Recognition. (arXiv:2104.05482v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05482">
<div class="article-summary-box-inner">
<span><p>Spectral graph convolutional networks (GCNs) are particular deep models which
aim at extending neural networks to arbitrary irregular domains. The principle
of these networks consists in projecting graph signals using the
eigen-decomposition of their Laplacians, then achieving filtering in the
spectral domain prior to back-project the resulting filtered signals onto the
input graph domain. However, the success of these operations is highly
dependent on the relevance of the used Laplacians which are mostly handcrafted
and this makes GCNs clearly sub-optimal. In this paper, we introduce a novel
spectral GCN that learns not only the usual convolutional parameters but also
the Laplacian operators. The latter are designed "end-to-end" as a part of a
recursive Chebyshev decomposition with the particularity of conveying both the
differential and the non-differential properties of the learned representations
-- with increasing order and discrimination power -- without overparametrizing
the trained GCNs. Extensive experiments, conducted on the challenging task of
skeleton-based action recognition, show the generalization ability and the
outperformance of our proposed Laplacian design w.r.t. different baselines
(built upon handcrafted and other learned Laplacians) as well as the related
work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Time series forecasting of new cases and new deaths rate for COVID-19 using deep learning methods. (arXiv:2104.15007v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.15007">
<div class="article-summary-box-inner">
<span><p>The first known case of Coronavirus disease 2019 (COVID-19) was identified in
December 2019. It has spread worldwide, leading to an ongoing pandemic, imposed
restrictions and costs to many countries. Predicting the number of new cases
and deaths during this period can be a useful step in predicting the costs and
facilities required in the future. The purpose of this study is to predict new
cases and deaths rate one, three and seven-day ahead during the next 100 days.
The motivation for predicting every n days (instead of just every day) is the
investigation of the possibility of computational cost reduction and still
achieving reasonable performance. Such a scenario may be encountered in
real-time forecasting of time series. Six different deep learning methods are
examined on the data adopted from the WHO website. Three methods are LSTM,
Convolutional LSTM, and GRU. The bidirectional extension is then considered for
each method to forecast the rate of new cases and new deaths in Australia and
Iran countries.
</p>
<p>This study is novel as it carries out a comprehensive evaluation of the
aforementioned three deep learning methods and their bidirectional extensions
to perform prediction on COVID-19 new cases and new death rate time series. To
the best of our knowledge, this is the first time that Bi-GRU and Bi-Conv-LSTM
models are used for prediction on COVID-19 new cases and new deaths time
series. The evaluation of the methods is presented in the form of graphs and
Friedman statistical test. The results show that the bidirectional models have
lower errors than other models. A several error evaluation metrics are
presented to compare all models, and finally, the superiority of bidirectional
methods is determined. This research could be useful for organisations working
against COVID-19 and determining their long-term plans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-contact Pain Recognition from Video Sequences with Remote Physiological Measurements Prediction. (arXiv:2105.08822v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08822">
<div class="article-summary-box-inner">
<span><p>Automatic pain recognition is paramount for medical diagnosis and treatment.
The existing works fall into three categories: assessing facial appearance
changes, exploiting physiological cues, or fusing them in a multi-modal manner.
However, (1) appearance changes are easily affected by subjective factors which
impedes objective pain recognition. Besides, the appearance-based approaches
ignore long-range spatial-temporal dependencies that are important for modeling
expressions over time; (2) the physiological cues are obtained by attaching
sensors on human body, which is inconvenient and uncomfortable. In this paper,
we present a novel multi-task learning framework which encodes both appearance
changes and physiological cues in a non-contact manner for pain recognition.
The framework is able to capture both local and long-range dependencies via the
proposed attention mechanism for the learned appearance representations, which
are further enriched by temporally attended physiological cues (remote
photoplethysmography, rPPG) that are recovered from videos in the auxiliary
task. This framework is dubbed rPPG-enriched Spatio-Temporal Attention Network
(rSTAN) and allows us to establish the state-of-the-art performance of
non-contact pain recognition on publicly available pain databases. It
demonstrates that rPPG predictions can be used as an auxiliary task to
facilitate non-contact automatic pain recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Visual Representation Learning by Online Constrained K-Means. (arXiv:2105.11527v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11527">
<div class="article-summary-box-inner">
<span><p>Cluster discrimination is an effective pretext task for unsupervised
representation learning, which often consists of two phases: clustering and
discrimination. Clustering is to assign each instance a pseudo label that will
be used to learn representations in discrimination. The main challenge resides
in clustering since prevalent clustering methods (e.g., k-means) have to run in
a batch mode and there can be a trivial solution consisting of a dominating
cluster. To address these challenges, we first investigate the objective of
clustering-based representation learning. Based on this, we propose a novel
clustering-based pretext task with online Constrained K-means (CoKe). Compared
with the balanced clustering that each cluster has exactly the same size, we
only constrain the minimal size of each cluster to flexibly capture the
inherent data structure. More importantly, our online assignment method has a
theoretical guarantee to approach the global optimum. By decoupling clustering
and discrimination, CoKe can achieve competitive performance when optimizing
with only a single view from each instance. Extensive experiments on ImageNet
verify both the efficacy and efficiency of our proposal. Code will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Mutual Learning for Semi-supervised Semantic Segmentation. (arXiv:2106.00609v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00609">
<div class="article-summary-box-inner">
<span><p>Recent semi-supervised learning (SSL) methods are commonly based on pseudo
labeling. Since the SSL performance is greatly influenced by the quality of
pseudo labels, mutual learning has been proposed to effectively suppress the
noises in the pseudo supervision. In this work, we propose robust mutual
learning that improves the prior approach in two aspects. First, the vanilla
mutual learners suffer from the coupling issue that models may converge to
learn homogeneous knowledge. We resolve this issue by introducing mean teachers
to generate mutual supervisions so that there is no direct interaction between
the two students. We also show that strong data augmentations, model noises and
heterogeneous network architectures are essential to alleviate the model
coupling. Second, we notice that mutual learning fails to leverage the
network's own ability for pseudo label refinement. Therefore, we introduce
self-rectification that leverages the internal knowledge and explicitly
rectifies the pseudo labels before the mutual teaching. Such self-rectification
and mutual teaching collaboratively improve the pseudo label accuracy
throughout the learning. The proposed robust mutual learning demonstrates
state-of-the-art performance on semantic segmentation in low-data regime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias. (arXiv:2106.03348v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03348">
<div class="article-summary-box-inner">
<span><p>Transformers have shown great potential in various computer vision tasks
owing to their strong capability in modeling long-range dependency using the
self-attention mechanism. Nevertheless, vision transformers treat an image as
1D sequence of visual tokens, lacking an intrinsic inductive bias (IB) in
modeling local visual structures and dealing with scale variance.
Alternatively, they require large-scale training data and longer training
schedules to learn the IB implicitly. In this paper, we propose a novel Vision
Transformer Advanced by Exploring intrinsic IB from convolutions, ie, ViTAE.
Technically, ViTAE has several spatial pyramid reduction modules to downsample
and embed the input image into tokens with rich multi-scale context by using
multiple convolutions with different dilation rates. In this way, it acquires
an intrinsic scale invariance IB and is able to learn robust feature
representation for objects at various scales. Moreover, in each transformer
layer, ViTAE has a convolution block in parallel to the multi-head
self-attention module, whose features are fused and fed into the feed-forward
network. Consequently, it has the intrinsic locality IB and is able to learn
local features and global dependencies collaboratively. Experiments on ImageNet
as well as downstream tasks prove the superiority of ViTAE over the baseline
transformer and concurrent works. Source code and pretrained models will be
available at GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Transformer for High-Resolution GANs. (arXiv:2106.07631v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07631">
<div class="article-summary-box-inner">
<span><p>Attention-based models, exemplified by the Transformer, can effectively model
long range dependency, but suffer from the quadratic complexity of
self-attention operation, making them difficult to be adopted for
high-resolution image generation based on Generative Adversarial Networks
(GANs). In this paper, we introduce two key ingredients to Transformer to
address this challenge. First, in low-resolution stages of the generative
process, standard global self-attention is replaced with the proposed
multi-axis blocked self-attention which allows efficient mixing of local and
global attention. Second, in high-resolution stages, we drop self-attention
while only keeping multi-layer perceptrons reminiscent of the implicit neural
function. To further improve the performance, we introduce an additional
self-modulation component based on cross-attention. The resulting model,
denoted as HiT, has a nearly linear computational complexity with respect to
the image size and thus directly scales to synthesizing high definition images.
We show in the experiments that the proposed HiT achieves state-of-the-art FID
scores of 30.83 and 2.95 on unconditional ImageNet $128 \times 128$ and FFHQ
$256 \times 256$, respectively, with a reasonable throughput. We believe the
proposed HiT is an important milestone for generators in GANs which are
completely free of convolutions. Our code is made publicly available at
https://github.com/google-research/hit-gan
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Action Transformer: A Self-Attention Model for Short-Time Pose-Based Human Action Recognition. (arXiv:2107.00606v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00606">
<div class="article-summary-box-inner">
<span><p>Deep neural networks based purely on attention have been successful across
several domains, relying on minimal architectural priors from the designer. In
Human Action Recognition (HAR), attention mechanisms have been primarily
adopted on top of standard convolutional or recurrent layers, improving the
overall generalization capability. In this work, we introduce Action
Transformer (AcT), a simple, fully self-attentional architecture that
consistently outperforms more elaborated networks that mix convolutional,
recurrent and attentive layers. In order to limit computational and energy
requests, building on previous human action recognition research, the proposed
approach exploits 2D pose representations over small temporal windows,
providing a low latency solution for accurate and effective real-time
performance. Moreover, we open-source MPOSE2021, a new large-scale dataset, as
an attempt to build a formal training and evaluation benchmark for real-time,
short-time HAR. The proposed methodology was extensively tested on MPOSE2021
and compared to several state-of-the-art architectures, proving the
effectiveness of the AcT model and laying the foundations for future work on
HAR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CamTuner: Reinforcement-Learning based System for Camera Parameter Tuning to enhance Analytics. (arXiv:2107.03964v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03964">
<div class="article-summary-box-inner">
<span><p>Video analytics systems critically rely on video cameras, which capture
high-quality video frames, to achieve high analytics accuracy. Although modern
video cameras often expose tens of configurable parameter settings that can be
set by end-users, deployment of surveillance cameras today often uses a fixed
set of parameter settings because the end-users lack the skill or understanding
to reconfigure these parameters.
</p>
<p>In this paper, we first show that in a typical surveillance camera
deployment, environmental condition changes can significantly affect the
accuracy of analytics units such as person detection, face detection and face
recognition, and how such adverse impact can be mitigated by dynamically
adjusting camera settings. We then propose CAMTUNER, a framework that can be
easily applied to an existing video analytics pipeline (VAP) to enable
automatic and dynamic adaptation of complex camera settings to changing
environmental conditions, and autonomously optimize the accuracy of analytics
units (AUs) in the VAP. CAMTUNER is based on SARSA reinforcement learning (RL)
and it incorporates two novel components: a light-weight analytics quality
estimator and a virtual camera. CAMTUNER is implemented in a system with AXIS
surveillance cameras and several VAPs (with various AUs) that processed
day-long customer videos captured at airport entrances. Our evaluations show
that CAMTUNER can adapt quickly to changing environments. We compared CAMTUNER
with two alternative approaches where either static camera settings were used,
or a strawman approach where camera settings were manually changed every hour
(based on human perception of quality). We observed that for the face detection
and person detection AUs, CAMTUNER is able to achieve up to 13.8% and 9.2%
higher accuracy, respectively, compared to the best of the two approaches
(average improvement of 8% for both AUs).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">eGHWT: The Extended Generalized Haar-Walsh Transform. (arXiv:2107.05121v3 [eess.SP] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05121">
<div class="article-summary-box-inner">
<span><p>Extending computational harmonic analysis tools from the classical setting of
regular lattices to the more general setting of graphs and networks is very
important and much research has been done recently. The Generalized Haar-Walsh
Transform (GHWT) developed by Irion and Saito (2014) is a multiscale transform
for signals on graphs, which is a generalization of the classical Haar and
Walsh-Hadamard Transforms. We propose the extended Generalized Haar-Walsh
Transform (eGHWT), which is a generalization of the adapted time-frequency
tilings of Thiele and Villemoes (1996). The eGHWT examines not only the
efficiency of graph-domain partitions but also that of "sequency-domain"
partitions simultaneously. Consequently, the eGHWT and its associated
best-basis selection algorithm for graph signals significantly improve the
performance of the previous GHWT with the similar computational cost, $O(N \log
N)$, where $N$ is the number of nodes of an input graph. While the GHWT
best-basis algorithm seeks the most suitable orthonormal basis for a given task
among more than $(1.5)^N$ possible orthonormal bases in $\mathbb{R}^N$, the
eGHWT best-basis algorithm can find a better one by searching through more than
$0.618\cdot(1.84)^N$ possible orthonormal bases in $\mathbb{R}^N$. This article
describes the details of the eGHWT best-basis algorithm and demonstrates its
superiority using several examples including genuine graph signals as well as
conventional digital images viewed as graph signals. Furthermore, we also show
how the eGHWT can be extended to 2D signals and matrix-form data by viewing
them as a tensor product of graphs generated from their columns and rows and
demonstrate its effectiveness on applications such as image approximation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ENHANCE (ENriching Health data by ANnotations of Crowd and Experts): A case study for skin lesion classification. (arXiv:2107.12734v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12734">
<div class="article-summary-box-inner">
<span><p>We present ENHANCE, an open dataset with multiple annotations to complement
the existing ISIC and PH2 skin lesion classification datasets. This dataset
contains annotations of visual ABC (asymmetry, border, colour) features from
non-expert annotation sources: undergraduate students, crowd workers from
Amazon MTurk and classic image processing algorithms. In this paper we first
analyse the correlations between the annotations and the diagnostic label of
the lesion, as well as study the agreement between different annotation
sources. Overall we find weak correlations of non-expert annotations with the
diagnostic label, and low agreement between different annotation sources. We
then study multi-task learning (MTL) with the annotations as additional labels,
and show that non-expert annotations can improve (ensembles of)
state-of-the-art convolutional neural networks via MTL. We hope that our
dataset can be used in further research into multiple annotations and/or MTL.
All data and models are available on Github:
https://github.com/raumannsr/ENHANCE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discovering "Semantics" in Super-Resolution Networks. (arXiv:2108.00406v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00406">
<div class="article-summary-box-inner">
<span><p>Super-resolution (SR) is a fundamental and representative task of low-level
vision area. It is generally thought that the features extracted from the SR
network have no specific semantic information, and the network simply learns
complex non-linear mappings from input to output. Can we find any "semantics"
in SR networks? In this paper, we give affirmative answers to this question. By
analyzing the feature representations with dimensionality reduction and
visualization, we successfully discover the deep semantic representations in SR
networks, \textit{i.e.}, deep degradation representations (DDR), which relate
to the image degradation types and degrees. We also reveal the differences in
representation semantics between classification and SR networks. Through
extensive experiments and analysis, we draw a series of observations and
conclusions, which are of great significance for future work, such as
interpreting the intrinsic mechanisms of low-level CNN networks and developing
new evaluation approaches for blind SR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Branch with Attention Network for Hand-Based Person Recognition. (arXiv:2108.02234v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02234">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel hand-based person recognition method for
the purpose of criminal investigations since the hand image is often the only
available information in cases of serious crime such as sexual abuse. Our
proposed method, Multi-Branch with Attention Network (MBA-Net), incorporates
both channel and spatial attention modules in branches in addition to a global
(without attention) branch to capture global structural information for
discriminative feature learning. The attention modules focus on the relevant
features of the hand image while suppressing the irrelevant backgrounds. In
order to overcome the weakness of the attention mechanisms, equivariant to
pixel shuffling, we integrate relative positional encodings into the spatial
attention module to capture the spatial positions of pixels. Extensive
evaluations on two large multi-ethnic and publicly available hand datasets
demonstrate that our proposed method achieves state-of-the-art performance,
surpassing the existing hand-based identification methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Re-using Adversarial Mask Discriminators for Test-time Training under Distribution Shifts. (arXiv:2108.11926v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11926">
<div class="article-summary-box-inner">
<span><p>Thanks to their ability to learn flexible data-driven losses, Generative
Adversarial Networks (GANs) are an integral part of many semi- and
weakly-supervised methods for medical image segmentation. GANs jointly optimise
a generator and an adversarial discriminator on a set of training data. After
training is complete, the discriminator is usually discarded, and only the
generator is used for inference. But should we discard discriminators? In this
work, we argue that training stable discriminators produces expressive loss
functions that we can re-use at inference to detect and \textit{correct}
segmentation mistakes. First, we identify key challenges and suggest possible
solutions to make discriminators re-usable at inference. Then, we show that we
can combine discriminators with image reconstruction costs (via decoders) to
endow a causal perspective to test-time training and further improve the model.
Our method is simple and improves the test-time performance of pre-trained
GANs. Moreover, we show that it is compatible with standard post-processing
techniques and it has the potential to be used for Online Continual Learning.
With our work, we open new research avenues for re-using adversarial
discriminators at inference. Our code is available at
https://vios-s.github.io/adversarial-test-time-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Panoptic nuScenes: A Large-Scale Benchmark for LiDAR Panoptic Segmentation and Tracking. (arXiv:2109.03805v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03805">
<div class="article-summary-box-inner">
<span><p>Panoptic scene understanding and tracking of dynamic agents are essential for
robots and automated vehicles to navigate in urban environments. As LiDARs
provide accurate illumination-independent geometric depictions of the scene,
performing these tasks using LiDAR point clouds provides reliable predictions.
However, existing datasets lack diversity in the type of urban scenes and have
a limited number of dynamic object instances which hinders both learning of
these tasks as well as credible benchmarking of the developed methods. In this
paper, we introduce the large-scale Panoptic nuScenes benchmark dataset that
extends our popular nuScenes dataset with point-wise groundtruth annotations
for semantic segmentation, panoptic segmentation, and panoptic tracking tasks.
To facilitate comparison, we provide several strong baselines for each of these
tasks on our proposed dataset. Moreover, we analyze the drawbacks of the
existing metrics for panoptic tracking and propose the novel instance-centric
PAT metric that addresses the concerns. We present exhaustive experiments that
demonstrate the utility of Panoptic nuScenes compared to existing datasets and
make the online evaluation server available at nuScenes.org. We believe that
this extension will accelerate the research of novel methods for scene
understanding of dynamic urban environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IceNet for Interactive Contrast Enhancement. (arXiv:2109.05838v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05838">
<div class="article-summary-box-inner">
<span><p>A CNN-based interactive contrast enhancement algorithm, called IceNet, is
proposed in this work, which enables a user to adjust image contrast easily
according to his or her preference. Specifically, a user provides a parameter
for controlling the global brightness and two types of scribbles to darken or
brighten local regions in an image. Then, given these annotations, IceNet
estimates a gamma map for the pixel-wise gamma correction. Finally, through
color restoration, an enhanced image is obtained. The user may provide
annotations iteratively to obtain a satisfactory image. IceNet is also capable
of producing a personalized enhanced image automatically, which can serve as a
basis for further adjustment if so desired. Moreover, to train IceNet
effectively and reliably, we propose three differentiable losses. Extensive
experiments show that IceNet can provide users with satisfactorily enhanced
images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LGD: Label-guided Self-distillation for Object Detection. (arXiv:2109.11496v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11496">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose the first self-distillation framework for general
object detection, termed LGD (Label-Guided self-Distillation). Previous studies
rely on a strong pretrained teacher to provide instructive knowledge that could
be unavailable in real-world scenarios. Instead, we generate an instructive
knowledge by inter-and-intra relation modeling among objects, requiring only
student representations and regular labels. Concretely, our framework involves
sparse label-appearance encoding, inter-object relation adaptation and
intra-object knowledge mapping to obtain the instructive knowledge. They
jointly form an implicit teacher at training phase, dynamically dependent on
labels and evolving student representations. Modules in LGD are trained
end-to-end with student detector and are discarded in inference.
Experimentally, LGD obtains decent results on various detectors, datasets, and
extensive tasks like instance segmentation. For example in MS-COCO dataset, LGD
improves RetinaNet with ResNet-50 under 2x single-scale training from 36.2% to
39.0% mAP (+ 2.8%). It boosts much stronger detectors like FCOS with
ResNeXt-101 DCN v2 under 2x multi-scale training from 46.1% to 47.9% (+ 1.8%).
Compared with a classical teacher-based method FGFI, LGD not only performs
better without requiring pretrained teacher but also reduces 51% training cost
beyond inherent student learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Progressive and Coarse-to-fine Registration of Brain MRI via Deformation Field Integration and Non-Rigid Feature Fusion. (arXiv:2109.12384v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12384">
<div class="article-summary-box-inner">
<span><p>Registration of brain MRI images requires to solve a deformation field, which
is extremely difficult in aligning intricate brain tissues, e.g., subcortical
nuclei, etc. Existing efforts resort to decomposing the target deformation
field into intermediate sub-fields with either tiny motions, i.e., progressive
registration stage by stage, or lower resolutions, i.e., coarse-to-fine
estimation of the full-size deformation field. In this paper, we argue that
those efforts are not mutually exclusive, and propose a unified framework for
robust brain MRI registration in both progressive and coarse-to-fine manners
simultaneously. Specifically, building on a dual-encoder U-Net, the
fixed-moving MRI pair is encoded and decoded into multi-scale deformation
sub-fields from coarse to fine. Each decoding block contains two proposed novel
modules: i) in Deformation Field Integration (DFI), a single integrated
sub-field is calculated, warping by which is equivalent to warping
progressively by sub-fields from all previous decoding blocks, and ii) in
Non-rigid Feature Fusion (NFF), features of the fixed-moving pair are aligned
by DFI-integrated sub-field, and then fused to predict a finer sub-field.
Leveraging both DFI and NFF, the target deformation field is factorized into
multi-scale sub-fields, where the coarser fields alleviate the estimate of a
finer one and the finer field learns to make up those misalignments insolvable
by previous coarser ones. The extensive and comprehensive experimental results
on both private and public datasets demonstrate a superior registration
performance of brain MRI images over progressive registration only and
coarse-to-fine estimation only, with an increase by at most 8% in the average
Dice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsolved Problems in ML Safety. (arXiv:2109.13916v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13916">
<div class="article-summary-box-inner">
<span><p>Machine learning (ML) systems are rapidly increasing in size, are acquiring
new capabilities, and are increasingly deployed in high-stakes settings. As
with other powerful technologies, safety for ML should be a leading research
priority. In response to emerging safety challenges in ML, such as those
introduced by recent large-scale models, we provide a new roadmap for ML Safety
and refine the technical problems that the field needs to address. We present
four problems ready for research, namely withstanding hazards ("Robustness"),
identifying hazards ("Monitoring"), steering ML systems ("Alignment"), and
reducing deployment hazards ("External Safety"). Throughout, we clarify each
problem's motivation and provide concrete research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Pose Transfer with Correspondence Learning and Mesh Refinement. (arXiv:2109.15025v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.15025">
<div class="article-summary-box-inner">
<span><p>3D pose transfer is one of the most challenging 3D generation tasks. It aims
to transfer the pose of a source mesh to a target mesh and keep the identity
(e.g., body shape) of the target mesh. Some previous works require key point
annotations to build reliable correspondence between the source and target
meshes, while other methods do not consider any shape correspondence between
sources and targets, which leads to limited generation quality. In this work,
we propose a correspondence-refinement network to achieve the 3D pose transfer
for both human and animal meshes. The correspondence between source and target
meshes is first established by solving an optimal transport problem. Then, we
warp the source mesh according to the dense correspondence and obtain a coarse
warped mesh. The warped mesh will be better refined with our proposed Elastic
Instance Normalization, which is a conditional normalization layer and can help
to generate high-quality meshes. Extensive experimental results show that the
proposed architecture can effectively transfer the poses from source to target
meshes and produce better results with satisfied visual performance than
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-Specific Bias Filtering for Single Labeled Domain Generalization. (arXiv:2110.00726v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00726">
<div class="article-summary-box-inner">
<span><p>Domain generalization (DG) utilizes multiple labeled source datasets to train
a generalizable model for unseen target domains. However, due to expensive
annotation costs, the requirements of labeling all the source data are hard to
be met in real-world applications. In this paper, we investigate a Single
Labeled Domain Generalization (SLDG) task with only one source domain being
labeled, which is more practical and challenging than the Conventional Domain
Generalization (CDG). A major obstacle in the SLDG task is the
discriminability-generalization bias: discriminative information in the labeled
source dataset may contain domain-specific bias, constraining the
generalization of the trained model. To tackle this challenging task, we
propose a novel method called Domain-Specific Bias Filtering (DSBF), which
initializes a discriminative model with the labeled source data and then
filters out its domain-specific bias with the unlabeled source data for
generalization improvement. We divide the filtering process into (1) feature
extractor debiasing via k-means clustering-based semantic feature re-extraction
and (2) classifier calibrating through attention-guided semantic feature
projection. DSBF unifies the exploration of the labeled and the unlabeled
source data to enhance the discriminability and generalization of the trained
model, resulting in a highly generalizable model. We further provide
theoretical analysis to verify the proposed domain-specific bias filtering
process. Extensive experiments on multiple datasets show the superior
performance of DSBF in tackling both the challenging SLDG task and the CDG
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimized U-Net for Brain Tumor Segmentation. (arXiv:2110.03352v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03352">
<div class="article-summary-box-inner">
<span><p>We propose an optimized U-Net architecture for a brain tumor segmentation
task in the BraTS21 challenge. To find the optimal model architecture and the
learning schedule, we have run an extensive ablation study to test: deep
supervision loss, Focal loss, decoder attention, drop block, and residual
connections. Additionally, we have searched for the optimal depth of the U-Net
encoder, number of convolutional channels and post-processing strategy. Our
method won the validation phase and took third place in the test phase. We have
open-sourced the code to reproduce our BraTS21 submission at the NVIDIA Deep
Learning Examples GitHub Repository.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Foreground Extraction via Deep Region Competition. (arXiv:2110.15497v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15497">
<div class="article-summary-box-inner">
<span><p>We present Deep Region Competition (DRC), an algorithm designed to extract
foreground objects from images in a fully unsupervised manner. Foreground
extraction can be viewed as a special case of generic image segmentation that
focuses on identifying and disentangling objects from the background. In this
work, we rethink the foreground extraction by reconciling energy-based prior
with generative image modeling in the form of Mixture of Experts (MoE), where
we further introduce the learned pixel re-assignment as the essential inductive
bias to capture the regularities of background regions. With this modeling, the
foreground-background partition can be naturally found through
Expectation-Maximization (EM). We show that the proposed method effectively
exploits the interaction between the mixture components during the partitioning
process, which closely connects to region competition, a seminal approach for
generic image segmentation. Experiments demonstrate that DRC exhibits more
competitive performances on complex real-world data and challenging
multi-object scenes compared with prior methods. Moreover, we show empirically
that DRC can potentially generalize to novel foreground objects even from
categories unseen during training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Influential Prototypical Networks for Few Shot Learning: A Dermatological Case Study. (arXiv:2111.00698v5 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00698">
<div class="article-summary-box-inner">
<span><p>Prototypical network (PN) is a simple yet effective few shot learning
strategy. It is a metric-based meta-learning technique where classification is
performed by computing Euclidean distances to prototypical representations of
each class. Conventional PN attributes equal importance to all samples and
generates prototypes by simply averaging the support sample embeddings
belonging to each class. In this work, we propose a novel version of PN that
attributes weights to support samples corresponding to their influence on the
support sample distribution. Influence weights of samples are calculated based
on maximum mean discrepancy (MMD) between the mean embeddings of sample
distributions including and excluding the sample. Comprehensive evaluation of
our proposed influential PN (IPNet) is performed by comparing its performance
with other baseline PNs on three different benchmark dermatological datasets.
IPNet outperforms all baseline models with compelling results across all three
datasets and various N-way, K-shot classification tasks. Findings from
cross-domain adaptation experiments further establish the robustness and
generalizability of IPNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognizing Vector Graphics without Rasterization. (arXiv:2111.03281v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03281">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider a different data format for images: vector
graphics. In contrast to raster graphics which are widely used in image
recognition, vector graphics can be scaled up or down into any resolution
without aliasing or information loss, due to the analytic representation of the
primitives in the document. Furthermore, vector graphics are able to give extra
structural information on how low-level elements group together to form high
level shapes or structures. These merits of graphic vectors have not been fully
leveraged in existing methods. To explore this data format, we target on the
fundamental recognition tasks: object localization and classification. We
propose an efficient CNN-free pipeline that does not render the graphic into
pixels (i.e. rasterization), and takes textual document of the vector graphics
as input, called YOLaT (You Only Look at Text). YOLaT builds multi-graphs to
model the structural and spatial information in vector graphics, and a
dual-stream graph neural network is proposed to detect objects from the graph.
Our experiments show that by directly operating on vector graphics, YOLaT
out-performs raster-graphic based object detection baselines in terms of both
average precision and efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethink Dilated Convolution for Real-time Semantic Segmentation. (arXiv:2111.09957v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09957">
<div class="article-summary-box-inner">
<span><p>Recent advances in semantic segmentation generally adapt an ImageNet
pretrained backbone with a special context module after it to quickly increase
the field-of-view. Although successful, the backbone, in which most of the
computation lies, does not have a large enough field-of-view to make the best
decisions. Some recent advances tackle this problem by rapidly downsampling the
resolution in the backbone while also having one or more parallel branches with
higher resolutions. We take a different approach by designing a ResNeXt
inspired block structure that uses two parallel 3x3 convolutional layers with
different dilation rates to increase the field-of-view while also preserving
the local details. By repeating this block structure in the backbone, we do not
need to append any special context module after it. In addition, we propose a
lightweight decoder that restores local information better than common
alternatives. To demonstrate the effectiveness of our approach, our model
RegSeg achieves state-of-the-art results on real-time Cityscapes and CamVid
datasets. Using a T4 GPU with mixed precision, RegSeg achieves 78.3 mIOU on
Cityscapes test set at 30 FPS, and 80.9 mIOU on CamVid test set at 70 FPS, both
without ImageNet pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Denoised Internal Models: a Brain-Inspired Autoencoder against Adversarial Attacks. (arXiv:2111.10844v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.10844">
<div class="article-summary-box-inner">
<span><p>Despite its great success, deep learning severely suffers from robustness;
that is, deep neural networks are very vulnerable to adversarial attacks, even
the simplest ones. Inspired by recent advances in brain science, we propose the
Denoised Internal Models (DIM), a novel generative autoencoder-based model to
tackle this challenge. Simulating the pipeline in the human brain for visual
signal processing, DIM adopts a two-stage approach. In the first stage, DIM
uses a denoiser to reduce the noise and the dimensions of inputs, reflecting
the information pre-processing in the thalamus. Inspired from the sparse coding
of memory-related traces in the primary visual cortex, the second stage
produces a set of internal models, one for each category. We evaluate DIM over
42 adversarial attacks, showing that DIM effectively defenses against all the
attacks and outperforms the SOTA on the overall robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computer Vision User Entity Behavior Analytics. (arXiv:2111.13176v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13176">
<div class="article-summary-box-inner">
<span><p>Insider threats are costly, hard to detect, and unfortunately rising in
occurrence. Seeking to improve detection of such threats, we develop novel
techniques to enable us to extract powerful features, generate high quality
image encodings, and augment attack vectors for greater classification power.
Combined, they form Computer Vision User and Entity Behavior Analytics, a
detection system designed from the ground up to improve upon advancements in
academia and mitigate the issues that prevent the usage of advanced models in
industry. The proposed system beats state-of-art methods used in academia and
as well as in industry.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13445">
<div class="article-summary-box-inner">
<span><p>Transfer learning is a classic paradigm by which models pretrained on large
"upstream" datasets are adapted to yield good results on "downstream,"
specialized datasets. Generally, it is understood that more accurate models on
the "upstream" dataset will provide better transfer accuracy "downstream". In
this work, we perform an in-depth investigation of this phenomenon in the
context of convolutional neural networks (CNNs) trained on the ImageNet
dataset, which have been pruned - that is, compressed by sparsifiying their
connections. Specifically, we consider transfer using unstructured pruned
models obtained by applying several state-of-the-art pruning methods, including
magnitude-based, second-order, re-growth and regularization approaches, in the
context of twelve standard transfer tasks. In a nutshell, our study shows that
sparse models can match or even outperform the transfer performance of dense
models, even at high sparsities, and, while doing so, can lead to significant
inference and even training speedups. At the same time, we observe and analyze
significant differences in the behaviour of different pruning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High Quality Segmentation for Ultra High-resolution Images. (arXiv:2111.14482v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.14482">
<div class="article-summary-box-inner">
<span><p>To segment 4K or 6K ultra high-resolution images needs extra computation
consideration in image segmentation. Common strategies, such as down-sampling,
patch cropping, and cascade model, cannot address well the balance issue
between accuracy and computation cost. Motivated by the fact that humans
distinguish among objects continuously from coarse to precise levels, we
propose the Continuous Refinement Model~(CRM) for the ultra high-resolution
segmentation refinement task. CRM continuously aligns the feature map with the
refinement target and aggregates features to reconstruct these images' details.
Besides, our CRM shows its significant generalization ability to fill the
resolution gap between low-resolution training images and ultra high-resolution
testing ones. We present quantitative performance evaluation and visualization
to show that our proposed method is fast and effective on image segmentation
refinement. Code will be released at https://github.com/dvlab-research/Entity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label-Efficient Semantic Segmentation with Diffusion Models. (arXiv:2112.03126v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03126">
<div class="article-summary-box-inner">
<span><p>Denoising diffusion probabilistic models have recently received much research
attention since they outperform alternative approaches, such as GANs, and
currently provide state-of-the-art generative performance. The superior
performance of diffusion models has made them an appealing tool in several
applications, including inpainting, super-resolution, and semantic editing. In
this paper, we demonstrate that diffusion models can also serve as an
instrument for semantic segmentation, especially in the setup when labeled data
is scarce. In particular, for several pretrained diffusion models, we
investigate the intermediate activations from the networks that perform the
Markov step of the reverse diffusion process. We show that these activations
effectively capture the semantic information from an input image and appear to
be excellent pixel-level representations for the segmentation problem. Based on
these observations, we describe a simple segmentation method, which can work
even if only a few training images are provided. Our approach significantly
outperforms the existing alternatives on several datasets for the same amount
of human supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diffusion Models for Implicit Image Segmentation Ensembles. (arXiv:2112.03145v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03145">
<div class="article-summary-box-inner">
<span><p>Diffusion models have shown impressive performance for generative modelling
of images. In this paper, we present a novel semantic segmentation method based
on diffusion models. By modifying the training and sampling scheme, we show
that diffusion models can perform lesion segmentation of medical images. To
generate an image specific segmentation, we train the model on the ground truth
segmentation, and use the image as a prior during training and in every step
during the sampling process. With the given stochastic sampling process, we can
generate a distribution of segmentation masks. This property allows us to
compute pixel-wise uncertainty maps of the segmentation, and allows an implicit
ensemble of segmentations that increases the segmentation performance. We
evaluate our method on the BRATS2020 dataset for brain tumor segmentation.
Compared to state-of-the-art segmentation models, our approach yields good
segmentation results and, additionally, detailed uncertainty maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Top-Down Deep Clustering with Multi-generator GANs. (arXiv:2112.03398v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03398">
<div class="article-summary-box-inner">
<span><p>Deep clustering (DC) leverages the representation power of deep architectures
to learn embedding spaces that are optimal for cluster analysis. This approach
filters out low-level information irrelevant for clustering and has proven
remarkably successful for high dimensional data spaces. Some DC methods employ
Generative Adversarial Networks (GANs), motivated by the powerful latent
representations these models are able to learn implicitly. In this work, we
propose HC-MGAN, a new technique based on GANs with multiple generators
(MGANs), which have not been explored for clustering. Our method is inspired by
the observation that each generator of a MGAN tends to generate data that
correlates with a sub-region of the real data distribution. We use this
clustered generation to train a classifier for inferring from which generator a
given image came from, thus providing a semantically meaningful clustering for
the real distribution. Additionally, we design our method so that it is
performed in a top-down hierarchical clustering tree, thus proposing the first
hierarchical DC method, to the best of our knowledge. We conduct several
experiments to evaluate the proposed method against recent DC methods,
obtaining competitive results. Last, we perform an exploratory analysis of the
hierarchical clustering tree that highlights how accurately it organizes the
data in a hierarchy of semantically coherent patterns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Activation to Saliency: Forming High-Quality Labels for Completely Unsupervised Salient Object Detection. (arXiv:2112.03650v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03650">
<div class="article-summary-box-inner">
<span><p>Existing deep learning-based Unsupervised Salient Object Detection (USOD)
methods rely on supervised pre-trained deep models. Moreover, they generate
pseudo labels based on hand-crafted features, which lack high-level semantic
information. In order to overcome these shortcomings, we propose a new
two-stage Activation-to-Saliency (A2S) framework that effectively excavates
high-quality saliency cues to train a robust saliency detector. It is worth
noting that our method does not require any manual annotation, even in the
pre-training phase. In the first stage, we transform an unsupervisedly
pre-trained network to aggregate multi-level features to a single activation
map, where an Adaptive Decision Boundary (ADB) is proposed to assist the
training of the transformed network. Moreover, a new loss function is proposed
to facilitate the generation of high-quality pseudo labels. In the second
stage, a self-rectification learning paradigm strategy is developed to train a
saliency detector and refine the pseudo labels online. In addition, we
construct a lightweight saliency detector using two Residual Attention Modules
(RAMs) to largely reduce the risk of overfitting. Extensive experiments on
several SOD benchmarks prove that our framework reports significant performance
compared with existing USOD methods. Moreover, training our framework on 3,000
images consumes about 1 hour, which is over 30$\times$ faster than previous
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MinkLoc3D-SI: 3D LiDAR place recognition with sparse convolutions, spherical coordinates, and intensity. (arXiv:2112.06539v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06539">
<div class="article-summary-box-inner">
<span><p>The 3D LiDAR place recognition aims to estimate a coarse localization in a
previously seen environment based on a single scan from a rotating 3D LiDAR
sensor. The existing solutions to this problem include hand-crafted point cloud
descriptors (e.g., ScanContext, M2DP, LiDAR IRIS) and deep learning-based
solutions (e.g., PointNetVLAD, PCAN, LPDNet, DAGC, MinkLoc3D), which are often
only evaluated on accumulated 2D scans from the Oxford RobotCar dataset. We
introduce MinkLoc3D-SI, a sparse convolution-based solution that utilizes
spherical coordinates of 3D points and processes the intensity of 3D LiDAR
measurements, improving the performance when a single 3D LiDAR scan is used.
Our method integrates the improvements typical for hand-crafted descriptors
(like ScanContext) with the most efficient 3D sparse convolutions (MinkLoc3D).
Our experiments show improved results on single scans from 3D LiDARs (USyd
Campus dataset) and great generalization ability (KITTI dataset). Using
intensity information on accumulated 2D scans (RobotCar Intensity dataset)
improves the performance, even though spherical representation doesn't produce
a noticeable improvement. As a result, MinkLoc3D-SI is suited for single scans
obtained from a 3D LiDAR, making it applicable in autonomous vehicles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ensemble CNN Networks for GBM Tumors Segmentation using Multi-parametric MRI. (arXiv:2112.06554v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06554">
<div class="article-summary-box-inner">
<span><p>Glioblastomas are the most aggressive fast-growing primary brain cancer which
originate in the glial cells of the brain. Accurate identification of the
malignant brain tumor and its sub-regions is still one of the most challenging
problems in medical image segmentation. The Brain Tumor Segmentation Challenge
(BraTS) has been a popular benchmark for automatic brain glioblastomas
segmentation algorithms since its initiation. In this year, BraTS 2021
challenge provides the largest multi-parametric (mpMRI) dataset of 2,000
pre-operative patients. In this paper, we propose a new aggregation of two deep
learning frameworks namely, DeepSeg and nnU-Net for automatic glioblastoma
recognition in pre-operative mpMRI. Our ensemble method obtains Dice similarity
scores of 92.00, 87.33, and 84.10 and Hausdorff Distances of 3.81, 8.91, and
16.02 for the enhancing tumor, tumor core, and whole tumor regions,
respectively, on the BraTS 2021 validation set, ranking us among the top ten
teams. These experimental findings provide evidence that it can be readily
applied clinically and thereby aiding in the brain cancer prognosis, therapy
planning, and therapy response monitoring. A docker image for reproducing our
segmentation results is available online at
(https://hub.docker.com/r/razeineldin/deepseg21).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple and Robust Loss Design for Multi-Label Learning with Missing Labels. (arXiv:2112.07368v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07368">
<div class="article-summary-box-inner">
<span><p>Multi-label learning in the presence of missing labels (MLML) is a
challenging problem. Existing methods mainly focus on the design of network
structures or training schemes, which increase the complexity of
implementation. This work seeks to fulfill the potential of loss function in
MLML without increasing the procedure and complexity. Toward this end, we
propose two simple yet effective methods via robust loss design based on an
observation that a model can identify missing labels during training with a
high precision. The first is a novel robust loss for negatives, namely the Hill
loss, which re-weights negatives in the shape of a hill to alleviate the effect
of false negatives. The second is a self-paced loss correction (SPLC) method,
which uses a loss derived from the maximum likelihood criterion under an
approximate distribution of missing labels. Comprehensive experiments on a vast
range of multi-label image classification datasets demonstrate that our methods
can remarkably boost the performance of MLML and achieve new state-of-the-art
loss functions in MLML.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Homography Decomposition Networks for Planar Object Tracking. (arXiv:2112.07909v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07909">
<div class="article-summary-box-inner">
<span><p>Planar object tracking plays an important role in AI applications, such as
robotics, visual servoing, and visual SLAM. Although the previous planar
trackers work well in most scenarios, it is still a challenging task due to the
rapid motion and large transformation between two consecutive frames. The
essential reason behind this problem is that the condition number of such a
non-linear system changes unstably when the searching range of the homography
parameter space becomes larger. To this end, we propose a novel Homography
Decomposition Networks(HDN) approach that drastically reduces and stabilizes
the condition number by decomposing the homography transformation into two
groups. Specifically, a similarity transformation estimator is designed to
predict the first group robustly by a deep convolution equivariant network. By
taking advantage of the scale and rotation estimation with high confidence, a
residual transformation is estimated by a simple regression model. Furthermore,
the proposed end-to-end network is trained in a semi-supervised fashion.
Extensive experiments show that our proposed approach outperforms the
state-of-the-art planar tracking methods at a large margin on the challenging
POT, UCSB and POIC datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeePaste -- Inpainting for Pasting. (arXiv:2112.10600v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10600">
<div class="article-summary-box-inner">
<span><p>One of the challenges of supervised learning training is the need to procure
an substantial amount of tagged data. A well-known method of solving this
problem is to use synthetic data in a copy-paste fashion, so that we cut
objects and paste them onto relevant backgrounds. Pasting the objects naively
results in artifacts that cause models to give poor results on real data. We
present a new method for cleanly pasting objects on different backgrounds so
that the dataset created gives competitive performance on real data. The main
emphasis is on the treatment of the border of the pasted object using
inpainting. We show state-of-the-art results both on instance detection and
foreground segmentation
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MPViT: Multi-Path Vision Transformer for Dense Prediction. (arXiv:2112.11010v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11010">
<div class="article-summary-box-inner">
<span><p>Dense computer vision tasks such as object detection and segmentation require
effective multi-scale feature representation for detecting or classifying
objects or regions with varying sizes. While Convolutional Neural Networks
(CNNs) have been the dominant architectures for such tasks, recently introduced
Vision Transformers (ViTs) aim to replace them as a backbone. Similar to CNNs,
ViTs build a simple multi-stage structure (i.e., fine-to-coarse) for
multi-scale representation with single-scale patches. In this work, with a
different perspective from existing Transformers, we explore multi-scale patch
embedding and multi-path structure, constructing the Multi-Path Vision
Transformer (MPViT). MPViT embeds features of the same size~(i.e., sequence
length) with patches of different scales simultaneously by using overlapping
convolutional patch embedding. Tokens of different scales are then
independently fed into the Transformer encoders via multiple paths and the
resulting features are aggregated, enabling both fine and coarse feature
representations at the same feature level. Thanks to the diverse, multi-scale
feature representations, our MPViTs scaling from tiny~(5M) to base~(73M)
consistently achieve superior performance over state-of-the-art Vision
Transformers on ImageNet classification, object detection, instance
segmentation, and semantic segmentation. These extensive results demonstrate
that MPViT can serve as a versatile backbone network for various vision tasks.
Code will be made publicly available at \url{https://git.io/MPViT}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EPNet++: Cascade Bi-directional Fusion for Multi-Modal 3D Object Detection. (arXiv:2112.11088v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11088">
<div class="article-summary-box-inner">
<span><p>Recently, fusing the LiDAR point cloud and camera image to improve the
performance and robustness of 3D object detection has received more and more
attention, as these two modalities naturally possess strong complementarity. In
this paper, we propose EPNet++ for multi-modal 3D object detection by
introducing a novel Cascade Bi-directional Fusion~(CB-Fusion) module and a
Multi-Modal Consistency~(MC) loss. More concretely, the proposed CB-Fusion
module boosts the plentiful semantic information of point features with the
image features in a cascade bi-directional interaction fusion manner, leading
to more comprehensive and discriminative feature representations. The MC loss
explicitly guarantees the consistency between predicted scores from two
modalities to obtain more comprehensive and reliable confidence scores. The
experiment results on the KITTI, JRDB and SUN-RGBD datasets demonstrate the
superiority of EPNet++ over the state-of-the-art methods. Besides, we emphasize
a critical but easily overlooked problem, which is to explore the performance
and robustness of a 3D detector in a sparser scene. Extensive experiments
present that EPNet++ outperforms the existing SOTA methods with remarkable
margins in highly sparse point cloud cases, which might be an available
direction to reduce the expensive cost of LiDAR sensors. Code will be released
in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Registration of Forest Point Clouds by Global Matching of Relative Stem Positions. (arXiv:2112.11121v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11121">
<div class="article-summary-box-inner">
<span><p>Registering point clouds of forest environments is an essential prerequisite
for LiDAR applications in precision forestry. State-of-the-art methods for
forest point cloud registration require the extraction of individual tree
attributes, and they have an efficiency bottleneck when dealing with point
clouds of real-world forests with dense trees. We propose an automatic, robust,
and efficient method for the registration of forest point clouds. Our approach
first locates tree stems from raw point clouds and then matches the stems based
on their relative spatial relationship to determine the registration
transformation. In contrast to existing methods, our algorithm requires no
extra individual tree attributes and has linear complexity to the number of
trees in the environment, allowing it to align point clouds of large forest
environments. Extensive experiments have revealed that our method is superior
to the state-of-the-art methods regarding registration accuracy and robustness,
and it significantly outperforms existing techniques in terms of efficiency.
Besides, we introduce a new benchmark dataset that complements the very few
existing open datasets for the development and evaluation of registration
methods for forest point clouds. The source code of our method and the dataset
are available at https://github.com/zexinyang/AlignTree.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles. (arXiv:2112.11798v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11798">
<div class="article-summary-box-inner">
<span><p>As autonomous vehicles and autonomous racing rise in popularity, so does the
need for faster and more accurate detectors. While our naked eyes are able to
extract contextual information almost instantly, even from far away, image
resolution and computational resources limitations make detecting smaller
objects (that is, objects that occupy a small pixel area in the input image) a
genuinely challenging task for machines and a wide-open research field. This
study explores how the popular YOLOv5 object detector can be modified to
improve its performance in detecting smaller objects, with a particular
application in autonomous racing. To achieve this, we investigate how replacing
certain structural elements of the model (as well as their connections and
other parameters) can affect performance and inference time. In doing so, we
propose a series of models at different scales, which we name `YOLO-Z', and
which display an improvement of up to 6.9% in mAP when detecting smaller
objects at 50% IOU, at the cost of just a 3ms increase in inference time
compared to the original YOLOv5. Our objective is to inform future research on
the potential of adjusting a popular detector such as YOLOv5 to address
specific tasks and provide insights on how specific changes can impact small
object detection. Such findings, applied to the broader context of autonomous
vehicles, could increase the amount of contextual information available to such
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Discriminative Single-Shot Segmentation Network for Visual Object Tracking. (arXiv:2112.11846v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11846">
<div class="article-summary-box-inner">
<span><p>Template-based discriminative trackers are currently the dominant tracking
paradigm due to their robustness, but are restricted to bounding box tracking
and a limited range of transformation models, which reduces their localization
accuracy. We propose a discriminative single-shot segmentation tracker -- D3S2,
which narrows the gap between visual object tracking and video object
segmentation. A single-shot network applies two target models with
complementary geometric properties, one invariant to a broad range of
transformations, including non-rigid deformations, the other assuming a rigid
object to simultaneously achieve robust online target segmentation. The overall
tracking reliability is further increased by decoupling the object and feature
scale estimation. Without per-dataset finetuning, and trained only for
segmentation as the primary output, D3S2 outperforms all published trackers on
the recent short-term tracking benchmark VOT2020 and performs very close to the
state-of-the-art trackers on the GOT-10k, TrackingNet, OTB100 and LaSoT. D3S2
outperforms the leading segmentation tracker SiamMask on video object
segmentation benchmarks and performs on par with top video object segmentation
algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Path Structural Contrastive Embeddings for Learning Novel Objects. (arXiv:2112.12359v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12359">
<div class="article-summary-box-inner">
<span><p>Learning novel classes from a very few labeled samples has attracted
increasing attention in machine learning areas. Recent research on either
meta-learning based or transfer-learning based paradigm demonstrates that
gaining information on a good feature space can be an effective solution to
achieve favorable performance on few-shot tasks. In this paper, we propose a
simple but effective paradigm that decouples the tasks of learning feature
representations and classifiers and only learns the feature embedding
architecture from base classes via the typical transfer-learning training
strategy. To maintain both the generalization ability across base and novel
classes and discrimination ability within each class, we propose a dual path
feature learning scheme that effectively combines structural similarity with
contrastive feature construction. In this way, both inner-class alignment and
inter-class uniformity can be well balanced, and result in improved
performance. Experiments on three popular benchmarks show that when
incorporated with a simple prototype based classifier, our method can still
achieve promising results for both standard and generalized few-shot problems
in either an inductive or transductive inference setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LaTr: Layout-Aware Transformer for Scene-Text VQA. (arXiv:2112.12494v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12494">
<div class="article-summary-box-inner">
<span><p>We propose a novel multimodal architecture for Scene Text Visual Question
Answering (STVQA), named Layout-Aware Transformer (LaTr). The task of STVQA
requires models to reason over different modalities. Thus, we first investigate
the impact of each modality, and reveal the importance of the language module,
especially when enriched with layout information. Accounting for this, we
propose a single objective pre-training scheme that requires only text and
spatial cues. We show that applying this pre-training scheme on scanned
documents has certain advantages over using natural images, despite the domain
gap. Scanned documents are easy to procure, text-dense and have a variety of
layouts, helping the model learn various spatial cues (e.g. left-of, below
etc.) by tying together language and layout information. Compared to existing
approaches, our method performs vocabulary-free decoding and, as shown,
generalizes well beyond the training vocabulary. We further demonstrate that
LaTr improves robustness towards OCR errors, a common reason for failure cases
in STVQA. In addition, by leveraging a vision transformer, we eliminate the
need for an external object detector. LaTr outperforms state-of-the-art STVQA
methods on multiple datasets. In particular, +7.6% on TextVQA, +10.8% on ST-VQA
and +4.0% on OCR-VQA (all absolute accuracy numbers).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BANMo: Building Animatable 3D Neural Models from Many Casual Videos. (arXiv:2112.12761v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12761">
<div class="article-summary-box-inner">
<span><p>Prior work for articulated 3D shape reconstruction often relies on
specialized sensors (e.g., synchronized multi-camera systems), or pre-built 3D
deformable models (e.g., SMAL or SMPL). Such methods are not able to scale to
diverse sets of objects in the wild. We present BANMo, a method that requires
neither a specialized sensor nor a pre-defined template shape. BANMo builds
high-fidelity, articulated 3D models (including shape and animatable skinning
weights) from many monocular casual videos in a differentiable rendering
framework. While the use of many videos provides more coverage of camera views
and object articulations, they introduce significant challenges in establishing
correspondence across scenes with different backgrounds, illumination
conditions, etc. Our key insight is to merge three schools of thought; (1)
classic deformable shape models that make use of articulated bones and blend
skinning, (2) volumetric neural radiance fields (NeRFs) that are amenable to
gradient-based optimization, and (3) canonical embeddings that generate
correspondences between pixels and an articulated model. We introduce neural
blend skinning models that allow for differentiable and invertible articulated
deformations. When combined with canonical embeddings, such models allow us to
establish dense correspondences across videos that can be self-supervised with
cycle consistency. On real and synthetic datasets, BANMo shows higher-fidelity
3D reconstructions than prior works for humans and animals, with the ability to
render realistic images from novel viewpoints and poses. Project webpage:
banmo-www.github.io .
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-12-28 23:07:21.306564347 UTC">2021-12-28 23:07:21 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>