<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-06-13T01:30:00Z">06-13</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Defending Compositionality in Emergent Languages. (arXiv:2206.04751v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04751">
<div class="article-summary-box-inner">
<span><p>Compositionality has traditionally been understood as a major factor in
productivity of language and, more broadly, human cognition. Yet, recently,
some research started to question its status, showing that artificial neural
networks are good at generalization even without noticeable compositional
behavior. We argue that some of these conclusions are too strong and/or
incomplete. In the context of a two-agent communication game, we show that
compositionality indeed seems essential for successful generalization when the
evaluation is done on a proper dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Case for a Single Model that can Both Generate Continuations and Fill in the Blank. (arXiv:2206.04812v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04812">
<div class="article-summary-box-inner">
<span><p>The task of inserting text into a specified position in a passage, known as
fill in the blank (FitB), is useful for a variety of applications where writers
interact with a natural language generation (NLG) system to craft text. While
previous work has tackled this problem with models trained specifically to do
the fill-in-the-blank task, a more useful model is one that can effectively
perform _both_ FitB and continuation. In this work, we evaluate the feasibility
of using a single model to do both tasks. We show that models pre-trained with
a FitB-style objective are capable of both tasks, while models pre-trained for
continuation are not. Finally, we show how FitB models can be easily finetuned
to allow for fine-grained control over the length and word choice of the
generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ask to Know More: Generating Counterfactual Explanations for Fake Claims. (arXiv:2206.04869v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04869">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose elucidating fact checking predictions using
counterfactual explanations to help people understand why a specific piece of
news was identified as fake. In this work, generating counterfactual
explanations for fake news involves three steps: asking good questions, finding
contradictions, and reasoning appropriately. We frame this research question as
contradicted entailment reasoning through question answering (QA). We first ask
questions towards the false claim and retrieve potential answers from the
relevant evidence documents. Then, we identify the most contradictory answer to
the false claim by use of an entailment classifier. Finally, a counterfactual
explanation is created using a matched QA pair with three different
counterfactual explanation forms. Experiments are conducted on the FEVER
dataset for both system and human evaluations. Results suggest that the
proposed approach generates the most helpful explanations compared to
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Chinese Dialect TTS Frontend with Non-Autoregressive Neural Machine Translation. (arXiv:2206.04922v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04922">
<div class="article-summary-box-inner">
<span><p>Chinese dialect text-to-speech(TTS) system usually can only be utilized by
native linguists, because the written form of Chinese dialects has different
characters, idioms, grammar and usage from Mandarin, and even the local speaker
cannot input a correct sentence. For Mandarin text inputs, Chinese dialect TTS
can only generate partly-meaningful speech with relatively poor prosody and
naturalness. To lower the bar of use and make it more practical in commercial,
we propose a novel Chinese dialect TTS frontend with a translation module. It
helps to convert Mandarin text into idiomatic expressions with correct
orthography and grammar, so that the intelligibility and naturalness of the
synthesized speech can be improved. A non-autoregressive neural machine
translation model with a glancing sampling strategy is proposed for the
translation task. It is the first known work to incorporate translation with
TTS frontend. Our experiments on Cantonese approve that the proposed frontend
can help Cantonese TTS system achieve a 0.27 improvement in MOS with Mandarin
inputs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RuCoCo: a new Russian corpus with coreference annotation. (arXiv:2206.04925v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04925">
<div class="article-summary-box-inner">
<span><p>We present a new corpus with coreference annotation, Russian Coreference
Corpus (RuCoCo). The goal of RuCoCo is to obtain a large number of annotated
texts while maintaining high inter-annotator agreement. RuCoCo contains news
texts in Russian, part of which were annotated from scratch, and for the rest
the machine-generated annotations were refined by human annotators. The size of
our corpus is one million words and around 150,000 mentions. We make the corpus
publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sort by Structure: Language Model Ranking as Dependency Probing. (arXiv:2206.04935v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04935">
<div class="article-summary-box-inner">
<span><p>Making an informed choice of pre-trained language model (LM) is critical for
performance, yet environmentally costly, and as such widely underexplored. The
field of Computer Vision has begun to tackle encoder ranking, with promising
forays into Natural Language Processing, however they lack coverage of
linguistic tasks such as structured prediction. We propose probing to rank LMs,
specifically for parsing dependencies in a given language, by measuring the
degree to which labeled trees are recoverable from an LM's contextualized
embeddings. Across 46 typologically and architecturally diverse LM-language
pairs, our probing approach predicts the best LM choice 79% of the time using
orders of magnitude less compute than training a full parser. Within this
study, we identify and analyze one recently proposed decoupled LM - RemBERT -
and find it strikingly contains less inherent dependency information, but often
yields the best parser after full fine-tuning. Without this outlier our
approach identifies the best LM in 89% of cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generate, Evaluate, and Select: A Dialogue System with a Response Evaluator for Diversity-Aware Response Generation. (arXiv:2206.04937v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04937">
<div class="article-summary-box-inner">
<span><p>We aim to overcome the lack of diversity in responses of current dialogue
systems and to develop a dialogue system that is engaging as a conversational
partner. We propose a generator-evaluator model that evaluates multiple
responses generated by a response generator and selects the best response by an
evaluator. By generating multiple responses, we obtain diverse responses. We
conduct human evaluations to compare the output of the proposed system with
that of a baseline system. The results of the human evaluations showed that the
proposed system's responses were often judged to be better than the baseline
system's, and indicated the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Borrowing or Codeswitching? Annotating for Finer-Grained Distinctions in Language Mixing. (arXiv:2206.04973v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04973">
<div class="article-summary-box-inner">
<span><p>We present a new corpus of Twitter data annotated for codeswitching and
borrowing between Spanish and English. The corpus contains 9,500 tweets
annotated at the token level with codeswitches, borrowings, and named entities.
This corpus differs from prior corpora of codeswitching in that we attempt to
clearly define and annotate the boundary between codeswitching and borrowing
and do not treat common "internet-speak" ('lol', etc.) as codeswitching when
used in an otherwise monolingual context. The result is a corpus that enables
the study and modeling of Spanish-English borrowing and codeswitching on
Twitter in one dataset. We present baseline scores for modeling the labels of
this corpus using Transformer-based language models. The annotation itself is
released with a CC BY 4.0 license, while the text it applies to is distributed
in compliance with the Twitter terms of service.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised and Few-shot Parsing from Pretrained Language Models. (arXiv:2206.04980v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04980">
<div class="article-summary-box-inner">
<span><p>Pretrained language models are generally acknowledged to be able to encode
syntax [Tenney et al., 2019, Jawahar et al., 2019, Hewitt and Manning, 2019].
In this article, we propose UPOA, an Unsupervised constituent Parsing model
that calculates an Out Association score solely based on the self-attention
weight matrix learned in a pretrained language model as the syntactic distance
for span segmentation. We further propose an enhanced version, UPIO, which
exploits both inside association and outside association scores for estimating
the likelihood of a span. Experiments with UPOA and UPIO disclose that the
linear projection matrices for the query and key in the self-attention
mechanism play an important role in parsing. We therefore extend the
unsupervised models to few-shot parsing models (FPOA, FPIO) that use a few
annotated trees to learn better linear projection matrices for parsing.
Experiments on the Penn Treebank demonstrate that our unsupervised parsing
model UPIO achieves results comparable to the state of the art on short
sentences (length &lt;= 10). Our few-shot parsing model FPIO trained with only 20
annotated trees outperforms a previous few-shot parsing method trained with 50
annotated trees. Experiments on cross-lingual parsing show that both
unsupervised and few-shot parsing methods are better than previous methods on
most languages of SPMRL [Seddah et al., 2013].
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building an Icelandic Entity Linking Corpus. (arXiv:2206.05014v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05014">
<div class="article-summary-box-inner">
<span><p>In this paper, we present the first Entity Linking corpus for Icelandic. We
describe our approach of using a multilingual entity linking model (mGENRE) in
combination with Wikipedia API Search (WAPIS) to label our data and compare it
to an approach using WAPIS only. We find that our combined method reaches 53.9%
coverage on our corpus, compared to 30.9% using only WAPIS. We analyze our
results and explain the value of using a multilingual system when working with
Icelandic. Additionally, we analyze the data that remain unlabeled, identify
patterns and discuss why they may be more difficult to annotate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simple Yet Efficient Method for Adversarial Word-Substitute Attack. (arXiv:2206.05015v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05015">
<div class="article-summary-box-inner">
<span><p>NLP researchers propose different word-substitute black-box attacks that can
fool text classification models. In such attack, an adversary keeps sending
crafted adversarial queries to the target model until it can successfully
achieve the intended outcome. State-of-the-art attack methods usually require
hundreds or thousands of queries to find one adversarial example. In this
paper, we study whether a sophisticated adversary can attack the system with
much less queries. We propose a simple yet efficient method that can reduce the
average number of adversarial queries by 3-30 times and maintain the attack
effectiveness. This research highlights that an adversary can fool a deep NLP
model with much less cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Frictional Authors. (arXiv:2206.05016v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05016">
<div class="article-summary-box-inner">
<span><p>I present a method for text analysis based on an analogy with the dynamic
friction of sliding surfaces. One surface is an array of points with a
'friction coefficient' derived from the distribution frequency of a text's
alphabetic characters. The other surface is a test patch having points with
this friction coefficient equal to a median value. Examples are presented from
an analysis of a broad range of public domain texts, and comparison is made to
the Flesch Reading Ease. Source code for the analysis program is provided.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empathetic Conversational Systems: A Review of Current Advances, Gaps, and Opportunities. (arXiv:2206.05017v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05017">
<div class="article-summary-box-inner">
<span><p>The concept of empathy is vital in human-agent systems as it contributes to
mutual understanding, problem-solving and sustained relationships. Despite the
increasing adoption of conversational systems as one of the most significant
events in the recent decade, the emotional aspects require considerable
improvements, particularly in effectively displaying empathy. This paper
provides a critical review of this rapidly growing field by examining the
current advances in four dimensions: (i) conceptual empathy models and
frameworks, (ii) the adopted empathy-related concepts, (iii) the datasets and
algorithmic techniques developed, and (iv) the evaluation strategies. The
review findings show that the most studies centred on the use of the
EMPATHETICDIALOGUES dataset, and the text-based modality dominated research in
this field. Moreover, studies have focused mainly on extracting features from
the messages of both users and the conversational systems, with minimal
emphasis on user modelling and profiling. For implementation in variegated
real-world domain settings, we recommend that future studies address the gaps
in detecting and authenticating emotions at the entity level, handling
multimodal inputs, displaying more nuanced empathetic behaviours, and
encompassing additional dialogue system features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Going Beyond the Cookie Theft Picture Test: Detecting Cognitive Impairments using Acoustic Features. (arXiv:2206.05018v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05018">
<div class="article-summary-box-inner">
<span><p>Standardized tests play a crucial role in the detection of cognitive
impairment. Previous work demonstrated that automatic detection of cognitive
impairment is possible using audio data from a standardized picture description
task. The presented study goes beyond that, evaluating our methods on data
taken from two standardized neuropsychological tests, namely the German SKT and
a German version of the CERAD-NB, and a semi-structured clinical interview
between a patient and a psychologist. For the tests, we focus on speech
recordings of three sub-tests: reading numbers (SKT 3), interference (SKT 7),
and verbal fluency (CERAD-NB 1). We show that acoustic features from
standardized tests can be used to reliably discriminate cognitively impaired
individuals from non-impaired ones. Furthermore, we provide evidence that even
features extracted from random speech samples of the interview can be a
discriminator of cognitive impairment. In our baseline experiments, we use
OpenSMILE features and Support Vector Machine classifiers. In an improved
setup, we show that using wav2vec 2.0 features instead, we can achieve an
accuracy of up to 85%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solution of DeBERTaV3 on CommonsenseQA. (arXiv:2206.05033v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05033">
<div class="article-summary-box-inner">
<span><p>We report the performance of DeBERTaV3 on CommonsenseQA in this report. We
simply formalize the answer selection as a text classification for DeBERTaV3.
The strong natural language inference ability of DeBERTaV3 helps its single and
ensemble model set the new state-of-the-art on CommonsenseQA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Construction and Evaluation of the LEAFTOP Dataset of Automatically Extracted Nouns in 1480 Languages. (arXiv:2206.05034v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05034">
<div class="article-summary-box-inner">
<span><p>The LEAFTOP (language extracted automatically from thousands of passages)
dataset consists of nouns that appear in multiple places in the four gospels of
the New Testament. We use a naive approach -- probabilistic inference -- to
identify likely translations in 1480 other languages. We evaluate this process
and find that it provides lexiconaries with accuracy from 42% (Korafe) to 99%
(Runyankole), averaging 72% correct across evaluated languages. The process
translates up to 161 distinct lemmas from Koine Greek (average 159). We
identify nouns which appear to be easy and hard to translate, language families
where this technique works, and future possible improvements and extensions.
The claims to novelty are: the use of a Koine Greek New Testament as the source
language; using a fully-annotated manually-created grammatically parse of the
source text; a custom scraper for texts in the target languages; a new metric
for language similarity; a novel strategy for evaluation on low-resource
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentiment analysis on electricity twitter posts. (arXiv:2206.05042v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05042">
<div class="article-summary-box-inner">
<span><p>In today's world, everyone is expressive in some way, and the focus of this
project is on people's opinions about rising electricity prices in United
Kingdom and India using data from Twitter, a micro-blogging platform on which
people post messages, known as tweets. Because many people's incomes are not
good and they have to pay so many taxes and bills, maintaining a home has
become a disputed issue these days. Despite the fact that Government offered
subsidy schemes to compensate people electricity bills but it is not welcomed
by people. In this project, the aim is to perform sentiment analysis on
people's expressions and opinions expressed on Twitter. In order to grasp the
electricity prices opinion, it is necessary to carry out sentiment analysis for
the government and consumers in energy market. Furthermore, text present on
these medias are unstructured in nature, so to process them we firstly need to
pre-process the data. There are so many feature extraction techniques such as
Bag of Words, TF-IDF (Term Frequency-Inverse Document Frequency), word
embedding, NLP based features like word count. In this project, we analysed the
impact of feature TF-IDF word level on electricity bills dataset of sentiment
analysis. We found that by using TF-IDF word level performance of sentiment
analysis is 3-4 higher than using N-gram features. Analysis is done using four
classification algorithms including Naive Bayes, Decision Tree, Random Forest,
and Logistic Regression and considering F-Score, Accuracy, Precision, and
Recall performance parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">REKnow: Enhanced Knowledge for Joint Entity and Relation Extraction. (arXiv:2206.05123v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05123">
<div class="article-summary-box-inner">
<span><p>Relation extraction is an important but challenging task that aims to extract
all hidden relational facts from the text. With the development of deep
language models, relation extraction methods have achieved good performance on
various benchmarks. However, we observe two shortcomings of previous methods:
first, there is no unified framework that works well under various relation
extraction settings; second, effectively utilizing external knowledge as
background information is absent. In this work, we propose a knowledge-enhanced
generative model to mitigate these two issues. Our generative model is a
unified framework to sequentially generate relational triplets under various
relation extraction settings and explicitly utilizes relevant knowledge from
Knowledge Graph (KG) to resolve ambiguities. Our model achieves superior
performance on multiple benchmarks and settings, including WebNLG, NYT10, and
TACRED.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning. (arXiv:2206.05154v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05154">
<div class="article-summary-box-inner">
<span><p>One of the challenges of language teaching is how to organize the rules
regarding syntax, semantics, or phonology of the language in a meaningful
manner. This not only requires pedagogical skills, but also requires a deep
understanding of that language. While comprehensive materials to develop such
curricula are available in English and some broadly spoken languages, for many
other languages, teachers need to manually create them in response to their
students' needs. This process is challenging because i) it requires that such
experts be accessible and have the necessary resources, and ii) even if there
are such experts, describing all the intricacies of a language is
time-consuming and prone to omission. In this article, we present an automatic
framework that aims to facilitate this process by automatically discovering and
visualizing descriptions of different aspects of grammar. Specifically, we
extract descriptions from a natural text corpus that answer questions about
morphosyntax (learning of word order, agreement, case marking, or word
formation) and semantics (learning of vocabulary) and show illustrative
examples. We apply this method for teaching the Indian languages, Kannada and
Marathi, which, unlike English, do not have well-developed pedagogical
resources and, therefore, are likely to benefit from this exercise. To assess
the perceived utility of the extracted material, we enlist the help of language
educators from schools in North America who teach these languages to perform a
manual evaluation. Overall, teachers find the materials to be interesting as a
reference material for their own lesson preparation or even for learner
evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nominal Metaphor Generation with Multitask Learning. (arXiv:2206.05195v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05195">
<div class="article-summary-box-inner">
<span><p>Nominal metaphors are frequently used in human language and have been shown
to be effective in persuading, expressing emotion, and stimulating interest.
This paper tackles the problem of Chinese Nominal Metaphor (NM) generation. We
introduce a novel multitask framework, which jointly optimizes three tasks: NM
identification, NM component identification, and NM generation. The metaphor
identification module is able to perform a self-training procedure, which
discovers novel metaphors from a large-scale unlabeled corpus for NM
generation. The NM component identification module emphasizes components during
training and conditions the generation on these NM components for more coherent
results. To train the NM identification and component identification modules,
we construct an annotated corpus consisting of 6.3k sentences that contain
diverse metaphorical patterns. Automatic metrics show that our method can
produce diverse metaphors with good readability, where 92\% of them are novel
metaphorical comparisons. Human evaluation shows our model significantly
outperforms baselines on consistency and creativity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-Task Benchmark for Korean Legal Language Understanding and Judgement Prediction. (arXiv:2206.05224v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05224">
<div class="article-summary-box-inner">
<span><p>The recent advances of deep learning have dramatically changed how machine
learning, especially in the domain of natural language processing, can be
applied to legal domain. However, this shift to the data-driven approaches
calls for larger and more diverse datasets, which are nevertheless still small
in number, especially in non-English languages. Here we present the first
large-scale benchmark of Korean legal AI datasets, LBox Open, that consists of
one legal corpus, two classification tasks, two legal judgement prediction
(LJP) tasks, and one summarization task. The legal corpus consists of 150k
Korean precedents (264M tokens), of which 63k are sentenced in last 4 years and
96k are from the first and the second level courts in which factual issues are
reviewed. The two classification tasks are case names (10k) and statutes (3k)
prediction from the factual description of individual cases. The LJP tasks
consist of (1) 11k criminal examples where the model is asked to predict fine
amount, imprisonment with labor, and imprisonment without labor ranges for the
given facts, and (2) 5k civil examples where the inputs are facts and claim for
relief and outputs are the degrees of claim acceptance. The summarization task
consists of the Supreme Court precedents and the corresponding summaries. We
also release LCube, the first Korean legal language model trained on the legal
corpus from this study. Given the uniqueness of the Law of South Korea and the
diversity of the legal tasks covered in this work, we believe that LBox Open
contributes to the multilinguality of global legal research. LBox Open and
LCube will be publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dimensional Modeling of Emotions in Text with Appraisal Theories: Corpus Creation, Annotation Reliability, and Prediction. (arXiv:2206.05238v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05238">
<div class="article-summary-box-inner">
<span><p>The most prominent tasks in emotion analysis are to assign emotions to texts
and to understand how emotions manifest in language. An important observation
for natural language processing is that emotions can be communicated implicitly
by referring to events alone, appealing to an empathetic, intersubjective
understanding of events, even without explicitly mentioning an emotion name. In
psychology, the class of emotion theories known as appraisal theories aims at
explaining the link between events and emotions. Appraisals can be formalized
as variables that measure a cognitive evaluation by people living through an
event that they consider relevant. They include the assessment if an event is
novel, if the person considers themselves to be responsible, if it is in line
with the own goals, and many others. Such appraisals explain which emotions are
developed based on an event, e.g., that a novel situation can induce surprise
or one with uncertain consequences could evoke fear. We analyze the suitability
of appraisal theories for emotion analysis in text with the goal of
understanding if appraisal concepts can reliably be reconstructed by
annotators, if they can be predicted by text classifiers, and if appraisal
concepts help to identify emotion categories. To achieve that, we compile a
corpus by asking people to textually describe events that triggered particular
emotions and to disclose their appraisals. Then, we ask readers to reconstruct
emotions and appraisals from the text. This setup allows us to measure if
emotions and appraisals can be recovered purely from text and provides a human
baseline to judge model's performance measures. Our comparison of text
classification methods to human annotators shows that both can reliably detect
emotions and appraisals with similar performance. We further show that
appraisal concepts improve the categorization of emotions in text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoCon: A Self-Supervised Approach for Controlled Text Generation. (arXiv:2006.03535v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03535">
<div class="article-summary-box-inner">
<span><p>Pretrained Transformer-based language models (LMs) display remarkable natural
language generation capabilities. With their immense potential, controlling
text generation of such LMs is getting attention. While there are studies that
seek to control high-level attributes (such as sentiment and topic) of
generated text, there is still a lack of more precise control over its content
at the word- and phrase-level. Here, we propose Content-Conditioner (CoCon) to
control an LM's output text with a content input, at a fine-grained level. In
our self-supervised approach, the CoCon block learns to help the LM complete a
partially-observed text sequence by conditioning with content inputs that are
withheld from the LM. Through experiments, we show that CoCon can naturally
incorporate target content into generated texts and control high-level text
attributes in a zero-shot manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AxFormer: Accuracy-driven Approximation of Transformers for Faster, Smaller and more Accurate NLP Models. (arXiv:2010.03688v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03688">
<div class="article-summary-box-inner">
<span><p>Transformers have greatly advanced the state-of-the-art in Natural Language
Processing (NLP) in recent years, but present very large computation and
storage requirements. We observe that the design process of Transformers
(pre-train a foundation model on a large dataset in a self-supervised manner,
and subsequently fine-tune it for different downstream tasks) leads to
task-specific models that are highly over-parameterized, adversely impacting
both accuracy and inference efficiency. We propose AxFormer, a systematic
framework that applies accuracy-driven approximations to create optimized
transformer models for a given downstream task. AxFormer combines two key
optimizations -- accuracy-driven pruning and selective hard attention.
Accuracy-driven pruning identifies and removes parts of the fine-tuned
transformer that hinder performance on the given downstream task. Sparse
hard-attention optimizes attention blocks in selected layers by eliminating
irrelevant word aggregations, thereby helping the model focus only on the
relevant parts of the input. In effect, AxFormer leads to models that are more
accurate, while also being faster and smaller. Our experiments on GLUE and
SQUAD tasks show that AxFormer models are up to 4.5% more accurate, while also
being up to 2.5X faster and up to 3.2X smaller than conventional fine-tuned
models. In addition, we demonstrate that AxFormer can be combined with previous
efforts such as distillation or quantization to achieve further efficiency
gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MTG: A Benchmark Suite for Multilingual Text Generation. (arXiv:2108.07140v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07140">
<div class="article-summary-box-inner">
<span><p>We introduce MTG, a new benchmark suite for training and evaluating
multilingual text generation. It is the first-proposed multilingual multiway
text generation dataset with the largest human-annotated data (400k). It
includes four generation tasks (story generation, question generation, title
generation and text summarization) across five languages (English, German,
French, Spanish and Chinese). The multiway setup enables testing knowledge
transfer capabilities for a model across languages and tasks. Using MTG, we
train and analyze several popular multilingual generation models from different
aspects. Our benchmark suite fosters model performance enhancement with more
human-annotated parallel data. It provides comprehensive evaluations with
diverse generation scenarios. Code and data are available at
\url{https://github.com/zide05/MTG}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparison and Combination of Sentence Embeddings Derived from Different Supervision Signals. (arXiv:2202.02990v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02990">
<div class="article-summary-box-inner">
<span><p>There have been many successful applications of sentence embedding methods.
However, it has not been well understood what properties are captured in the
resulting sentence embeddings depending on the supervision signals. In this
paper, we focus on two types of sentence embedding methods with similar
architectures and tasks: one fine-tunes pre-trained language models on the
natural language inference task, and the other fine-tunes pre-trained language
models on word prediction task from its definition sentence, and investigate
their properties. Specifically, we compare their performances on semantic
textual similarity (STS) tasks using STS datasets partitioned from two
perspectives: 1) sentence source and 2) superficial similarity of the sentence
pairs, and compare their performances on the downstream and probing tasks.
Furthermore, we attempt to combine the two methods and demonstrate that
combining the two methods yields substantially better performance than the
respective methods on unsupervised STS tasks and downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Step at a Time: Long-Horizon Vision-and-Language Navigation with Milestones. (arXiv:2202.07028v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07028">
<div class="article-summary-box-inner">
<span><p>We study the problem of developing autonomous agents that can follow human
instructions to infer and perform a sequence of actions to complete the
underlying task. Significant progress has been made in recent years, especially
for tasks with short horizons. However, when it comes to long-horizon tasks
with extended sequences of actions, an agent can easily ignore some
instructions or get stuck in the middle of the long instructions and eventually
fail the task. To address this challenge, we propose a model-agnostic
milestone-based task tracker (M-TRACK) to guide the agent and monitor its
progress. Specifically, we propose a milestone builder that tags the
instructions with navigation and interaction milestones which the agent needs
to complete step by step, and a milestone checker that systemically checks the
agent's progress in its current milestone and determines when to proceed to the
next. On the challenging ALFRED dataset, our M-TRACK leads to a notable 33% and
52% relative improvement in unseen success rate over two competitive base
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ERNIE-GeoL: A Geography-and-Language Pre-trained Model and its Applications in Baidu Maps. (arXiv:2203.09127v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09127">
<div class="article-summary-box-inner">
<span><p>Pre-trained models (PTMs) have become a fundamental backbone for downstream
tasks in natural language processing and computer vision. Despite initial gains
that were obtained by applying generic PTMs to geo-related tasks at Baidu Maps,
a clear performance plateau over time was observed. One of the main reasons for
this plateau is the lack of readily available geographic knowledge in generic
PTMs. To address this problem, in this paper, we present ERNIE-GeoL, which is a
geography-and-language pre-trained model designed and developed for improving
the geo-related tasks at Baidu Maps. ERNIE-GeoL is elaborately designed to
learn a universal representation of geography-language by pre-training on
large-scale data generated from a heterogeneous graph that contains abundant
geographic knowledge. Extensive quantitative and qualitative experiments
conducted on large-scale real-world datasets demonstrate the superiority and
effectiveness of ERNIE-GeoL. ERNIE-GeoL has already been deployed in production
at Baidu Maps since April 2021, which significantly benefits the performance of
various downstream tasks. This demonstrates that ERNIE-GeoL can serve as a
fundamental backbone for a wide range of geo-related tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CompactIE: Compact Facts in Open Information Extraction. (arXiv:2205.02880v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02880">
<div class="article-summary-box-inner">
<span><p>A major drawback of modern neural OpenIE systems and benchmarks is that they
prioritize high coverage of information in extractions over compactness of
their constituents. This severely limits the usefulness of OpenIE extractions
in many downstream tasks. The utility of extractions can be improved if
extractions are compact and share constituents. To this end, we study the
problem of identifying compact extractions with neural-based methods. We
propose CompactIE, an OpenIE system that uses a novel pipelined approach to
produce compact extractions with overlapping constituents. It first detects
constituents of the extractions and then links them to build extractions. We
train our system on compact extractions obtained by processing existing
benchmarks. Our experiments on CaRB and Wire57 datasets indicate that CompactIE
finds 1.5x-2x more compact extractions than previous systems, with high
precision, establishing a new state-of-the-art performance in OpenIE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graph - Deep Learning: A Case Study in Question Answering in Aviation Safety Domain. (arXiv:2205.15952v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.15952">
<div class="article-summary-box-inner">
<span><p>In the commercial aviation domain, there are a large number of documents,
like, accident reports (NTSB, ASRS) and regulatory directives (ADs). There is a
need for a system to access these diverse repositories efficiently in order to
service needs in the aviation industry, like maintenance, compliance, and
safety. In this paper, we propose a Knowledge Graph (KG) guided Deep Learning
(DL) based Question Answering (QA) system for aviation safety. We construct a
Knowledge Graph from Aircraft Accident reports and contribute this resource to
the community of researchers. The efficacy of this resource is tested and
proved by the aforesaid QA system. Natural Language Queries constructed from
the documents mentioned above are converted into SPARQL (the interface language
of the RDF graph database) queries and answered. On the DL side, we have two
different QA models: (i) BERT QA which is a pipeline of Passage Retrieval
(Sentence-BERT based) and Question Answering (BERT based), and (ii) the
recently released GPT-3. We evaluate our system on a set of queries created
from the accident reports. Our combined QA system achieves 9.3% increase in
accuracy over GPT-3 and 40.3% increase over BERT QA. Thus, we infer that KG-DL
performs better than either singly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. (arXiv:2206.04615v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04615">
<div class="article-summary-box-inner">
<span><p>Language models demonstrate both quantitative improvement and new qualitative
capabilities with increasing scale. Despite their potentially transformative
impact, these new capabilities are as yet poorly characterized. In order to
inform future research, prepare for disruptive new model capabilities, and
ameliorate socially harmful effects, it is vital that we understand the present
and near-future capabilities and limitations of language models. To address
this challenge, we introduce the Beyond the Imitation Game benchmark
(BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442
authors across 132 institutions. Task topics are diverse, drawing problems from
linguistics, childhood development, math, common-sense reasoning, biology,
physics, social bias, software development, and beyond. BIG-bench focuses on
tasks that are believed to be beyond the capabilities of current language
models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense
transformer architectures, and Switch-style sparse transformers on BIG-bench,
across model sizes spanning millions to hundreds of billions of parameters. In
addition, a team of human expert raters performed all tasks in order to provide
a strong baseline. Findings include: model performance and calibration both
improve with scale, but are poor in absolute terms (and when compared with
rater performance); performance is remarkably similar across model classes,
though with benefits from sparsity; tasks that improve gradually and
predictably commonly involve a large knowledge or memorization component,
whereas tasks that exhibit "breakthrough" behavior at a critical scale often
involve multiple steps or components, or brittle metrics; social bias typically
increases with scale in settings with ambiguous context, but this can be
improved with prompting.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Extending Momentum Contrast with Cross Similarity Consistency Regularization. (arXiv:2206.04676v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04676">
<div class="article-summary-box-inner">
<span><p>Contrastive self-supervised representation learning methods maximize the
similarity between the positive pairs, and at the same time tend to minimize
the similarity between the negative pairs. However, in general the interplay
between the negative pairs is ignored as they do not put in place special
mechanisms to treat negative pairs differently according to their specific
differences and similarities. In this paper, we present Extended Momentum
Contrast (XMoCo), a self-supervised representation learning method founded upon
the legacy of the momentum-encoder unit proposed in the MoCo family
configurations. To this end, we introduce a cross consistency regularization
loss, with which we extend the transformation consistency to dissimilar images
(negative pairs). Under the cross consistency regularization rule, we argue
that semantic representations associated with any pair of images (positive or
negative) should preserve their cross-similarity under pretext transformations.
Moreover, we further regularize the training loss by enforcing a uniform
distribution of similarity over the negative pairs across a batch. The proposed
regularization can easily be added to existing self-supervised learning
algorithms in a plug-and-play fashion. Empirically, we report a competitive
performance on the standard Imagenet-1K linear head classification benchmark.
In addition, by transferring the learned representations to common downstream
tasks, we show that using XMoCo with the prevalently utilized augmentations can
lead to improvements in the performance of such tasks. We hope the findings of
this paper serve as a motivation for researchers to take into consideration the
important interplay among the negative examples in self-supervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Backdoor Attacks Survive Time-Varying Models?. (arXiv:2206.04677v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04677">
<div class="article-summary-box-inner">
<span><p>Backdoors are powerful attacks against deep neural networks (DNNs). By
poisoning training data, attackers can inject hidden rules (backdoors) into
DNNs, which only activate on inputs containing attack-specific triggers. While
existing work has studied backdoor attacks on a variety of DNN models, they
only consider static models, which remain unchanged after initial deployment.
</p>
<p>In this paper, we study the impact of backdoor attacks on a more realistic
scenario of time-varying DNN models, where model weights are updated
periodically to handle drifts in data distribution over time. Specifically, we
empirically quantify the "survivability" of a backdoor against model updates,
and examine how attack parameters, data drift behaviors, and model update
strategies affect backdoor survivability. Our results show that one-shot
backdoor attacks (i.e., only poisoning training data once) do not survive past
a few model updates, even when attackers aggressively increase trigger size and
poison ratio. To stay unaffected by model update, attackers must continuously
introduce corrupted data into the training pipeline. Together, these results
indicate that when models are updated to learn new data, they also "forget"
backdoors as hidden, malicious features. The larger the distribution shift
between old and new training data, the faster backdoors are forgotten.
Leveraging these insights, we apply a smart learning rate scheduler to further
accelerate backdoor forgetting during model updates, which prevents one-shot
backdoors from surviving past a single model update.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">POODLE: Improving Few-shot Learning via Penalizing Out-of-Distribution Samples. (arXiv:2206.04679v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04679">
<div class="article-summary-box-inner">
<span><p>In this work, we propose to use out-of-distribution samples, i.e., unlabeled
samples coming from outside the target classes, to improve few-shot learning.
Specifically, we exploit the easily available out-of-distribution samples to
drive the classifier to avoid irrelevant features by maximizing the distance
from prototypes to out-of-distribution samples while minimizing that of
in-distribution samples (i.e., support, query data). Our approach is simple to
implement, agnostic to feature extractors, lightweight without any additional
cost for pre-training, and applicable to both inductive and transductive
settings. Extensive experiments on various standard benchmarks demonstrate that
the proposed method consistently improves the performance of pretrained
networks with different architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gaussian Fourier Pyramid for Local Laplacian Filter. (arXiv:2206.04681v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04681">
<div class="article-summary-box-inner">
<span><p>Multi-scale processing is essential in image processing and computer
graphics. Halos are a central issue in multi-scale processing. Several
edge-preserving decompositions resolve halos, e.g., local Laplacian filtering
(LLF), by extending the Laplacian pyramid to have an edge-preserving property.
Its processing is costly; thus, an approximated acceleration of fast LLF was
proposed to linearly interpolate multiple Laplacian pyramids. This paper
further improves the accuracy by Fourier series expansion, named Fourier LLF.
Our results showed that Fourier LLF has a higher accuracy for the same number
of pyramids. Moreover, Fourier LLF exhibits parameter-adaptive property for
content-adaptive filtering. The code is available at:
https://norishigefukushima.github.io/GaussianFourierPyramid/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RT-DNAS: Real-time Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation. (arXiv:2206.04682v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04682">
<div class="article-summary-box-inner">
<span><p>Accurately segmenting temporal frames of cine magnetic resonance imaging
(MRI) is a crucial step in various real-time MRI guided cardiac interventions.
To achieve fast and accurate visual assistance, there are strict requirements
on the maximum latency and minimum throughput of the segmentation framework.
State-of-the-art neural networks on this task are mostly hand-crafted to
satisfy these constraints while achieving high accuracy. On the other hand,
while existing literature have demonstrated the power of neural architecture
search (NAS) in automatically identifying the best neural architectures for
various medical applications, they are mostly guided by accuracy, sometimes
with computation complexity, and the importance of real-time constraints are
overlooked. A major challenge is that such constraints are non-differentiable
and are thus not compatible with the widely used differentiable NAS frameworks.
In this paper, we present a strategy that directly handles real-time
constraints in a differentiable NAS framework named RT-DNAS. Experiments on
extended 2017 MICCAI ACDC dataset show that compared with state-of-the-art
manually and automatically designed architectures, RT-DNAS is able to identify
ones with better accuracy while satisfying the real-time constraints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structure-consistent Restoration Network for Cataract Fundus Image Enhancement. (arXiv:2206.04684v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04684">
<div class="article-summary-box-inner">
<span><p>Fundus photography is a routine examination in clinics to diagnose and
monitor ocular diseases. However, for cataract patients, the fundus image
always suffers quality degradation caused by the clouding lens. The degradation
prevents reliable diagnosis by ophthalmologists or computer-aided systems. To
improve the certainty in clinical diagnosis, restoration algorithms have been
proposed to enhance the quality of fundus images. Unfortunately, challenges
remain in the deployment of these algorithms, such as collecting sufficient
training data and preserving retinal structures. In this paper, to circumvent
the strict deployment requirement, a structure-consistent restoration network
(SCR-Net) for cataract fundus images is developed from synthesized data that
shares an identical structure. A cataract simulation model is firstly designed
to collect synthesized cataract sets (SCS) formed by cataract fundus images
sharing identical structures. Then high-frequency components (HFCs) are
extracted from the SCS to constrain structure consistency such that the
structure preservation in SCR-Net is enforced. The experiments demonstrate the
effectiveness of SCR-Net in the comparison with state-of-the-art methods and
the follow-up clinical applications. The code is available at
https://github.com/liamheng/ArcNet-Medical-Image-Enhancement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-based Clinical Assessment of Optic Nerve Head Robustness Superseding Biomechanical Testing. (arXiv:2206.04689v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04689">
<div class="article-summary-box-inner">
<span><p>$\mathbf{Purpose}$: To use artificial intelligence (AI) to: (1) exploit
biomechanical knowledge of the optic nerve head (ONH) from a relatively large
population; (2) assess ONH robustness from a single optical coherence
tomography (OCT) scan of the ONH; (3) identify what critical three-dimensional
(3D) structural features make a given ONH robust.
</p>
<p>$\mathbf{Design}$: Retrospective cross-sectional study.
</p>
<p>$\mathbf{Methods}$: 316 subjects had their ONHs imaged with OCT before and
after acute intraocular pressure (IOP) elevation through ophthalmo-dynamometry.
IOP-induced lamina-cribrosa deformations were then mapped in 3D and used to
classify ONHs. Those with LC deformations superior to 4% were considered
fragile, while those with deformations inferior to 4% robust. Learning from
these data, we compared three AI algorithms to predict ONH robustness strictly
from a baseline (undeformed) OCT volume: (1) a random forest classifier; (2) an
autoencoder; and (3) a dynamic graph CNN (DGCNN). The latter algorithm also
allowed us to identify what critical 3D structural features make a given ONH
robust.
</p>
<p>$\mathbf{Results}$: All 3 methods were able to predict ONH robustness from 3D
structural information alone and without the need to perform biomechanical
testing. The DGCNN (area under the receiver operating curve [AUC]: 0.76 $\pm$
0.08) outperformed the autoencoder (AUC: 0.70 $\pm$ 0.07) and the random forest
classifier (AUC: 0.69 $\pm$ 0.05). Interestingly, to assess ONH robustness, the
DGCNN mainly used information from the scleral canal and the LC insertion
sites.
</p>
<p>$\mathbf{Conclusions}$: We propose an AI-driven approach that can assess the
robustness of a given ONH solely from a single OCT scan of the ONH, and without
the need to perform biomechanical testing. Longitudinal studies should
establish whether ONH robustness could help us identify fast visual field loss
progressors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-MIA: COVID-19 Detection & Severity Analysis through Medical Imaging. (arXiv:2206.04732v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04732">
<div class="article-summary-box-inner">
<span><p>This paper presents the baseline approach for the organized 2nd Covid-19
Competition, occurring in the framework of the AIMIA Workshop in the European
Conference on Computer Vision (ECCV 2022). It presents the COV19-CT-DB database
which is annotated for COVID-19 detction, consisting of about 7,700 3-D CT
scans. Part of the database consisting of Covid-19 cases is further annotated
in terms of four Covid-19 severity conditions. We have split the database and
the latter part of it in training, validation and test datasets. The former two
datasets are used for training and validation of machine learning models, while
the latter will be used for evaluation of the developed models. The baseline
approach consists of a deep learning approach, based on a CNN-RNN network and
report its performance on the COVID19-CT-DB database.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study on Disentanglement of Negative-free Contrastive Learning. (arXiv:2206.04756v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04756">
<div class="article-summary-box-inner">
<span><p>Negative-free contrastive learning has attracted a lot of attention with
simplicity and impressive performance for large-scale pretraining. But its
disentanglement property remains unexplored. In this paper, we take different
negative-free contrastive learning methods to study the disentanglement
property of this genre of self-supervised methods empirically. We find the
existing disentanglement metrics fail to make meaningful measurements for the
high-dimensional representation model so we propose a new disentanglement
metric based on Mutual Information between representation and data factors.
With the proposed metric, we benchmark the disentanglement property of
negative-free contrastive learning for the first time, on both popular
synthetic datasets and a real-world dataset CelebA. Our study shows that the
investigated methods can learn a well-disentangled subset of representation. We
extend the study of the disentangled representation learning to
high-dimensional representation space and negative-free contrastive learning
for the first time. The implementation of the proposed metric is available at
\url{https://github.com/noahcao/disentanglement_lib_med}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What should AI see? Using the Public's Opinion to Determine the Perception of an AI. (arXiv:2206.04776v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04776">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNN) have made impressive progress in the
interpretation of image data, so that it is conceivable and to some degree
realistic to use them in safety critical applications like automated driving.
From an ethical standpoint, the AI algorithm should take into account the
vulnerability of objects or subjects on the street that ranges from "not at
all", e.g. the road itself, to "high vulnerability" of pedestrians. One way to
take this into account is to define the cost of confusion of one semantic
category with another and use cost-based decision rules for the interpretation
of probabilities, which are the output of DNNs. However, it is an open problem
how to define the cost structure, who should be in charge to do that, and
thereby define what AI-algorithms will actually "see". As one possible answer,
we follow a participatory approach and set up an online survey to ask the
public to define the cost structure. We present the survey design and the data
acquired along with an evaluation that also distinguishes between perspective
(car passenger vs. external traffic participant) and gender. Using simulation
based $F$-tests, we find highly significant differences between the groups.
These differences have consequences on the reliable detection of pedestrians in
a safety critical distance to the self-driving car. We discuss the ethical
problems that are related to this approach and also discuss the problems
emerging from human-machine interaction through the survey from a psychological
point of view. Finally, we include comments from industry leaders in the field
of AI safety on the applicability of survey based elements in the design of AI
functionalities in automated driving.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations. (arXiv:2206.04779v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04779">
<div class="article-summary-box-inner">
<span><p>Offline reinforcement learning has shown great promise in leveraging large
pre-collected datasets for policy learning, allowing agents to forgo
often-expensive online data collection. However, to date, offline reinforcement
learning from has been relatively under-explored, and there is a lack of
understanding of where the remaining challenges lie. In this paper, we seek to
establish simple baselines for continuous control in the visual domain. We show
that simple modifications to two state-of-the-art vision-based online
reinforcement learning algorithms, DreamerV2 and DrQ-v2, suffice to outperform
prior work and establish a competitive baseline. We rigorously evaluate these
algorithms on both existing offline datasets and a new testbed for offline
reinforcement learning from visual observations that better represents the data
distributions present in real-world offline reinforcement learning problems,
and open-source our code and data to facilitate progress in this important
domain. Finally, we present and analyze several key desiderata unique to
offline RL from visual observations, including visual distractions and visually
identifiable changes in dynamics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReFace: Real-time Adversarial Attacks on Face Recognition Systems. (arXiv:2206.04783v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04783">
<div class="article-summary-box-inner">
<span><p>Deep neural network based face recognition models have been shown to be
vulnerable to adversarial examples. However, many of the past attacks require
the adversary to solve an input-dependent optimization problem using gradient
descent which makes the attack impractical in real-time. These adversarial
examples are also tightly coupled to the attacked model and are not as
successful in transferring to different models. In this work, we propose
ReFace, a real-time, highly-transferable attack on face recognition models
based on Adversarial Transformation Networks (ATNs). ATNs model adversarial
example generation as a feed-forward neural network. We find that the white-box
attack success rate of a pure U-Net ATN falls substantially short of
gradient-based attacks like PGD on large face recognition datasets. We
therefore propose a new architecture for ATNs that closes this gap while
maintaining a 10000x speedup over PGD. Furthermore, we find that at a given
perturbation magnitude, our ATN adversarial perturbations are more effective in
transferring to new face recognition models than PGD. ReFace attacks can
successfully deceive commercial face recognition services in a transfer attack
setting and reduce face identification accuracy from 82% to 16.4% for AWS
SearchFaces API and Azure face verification accuracy from 91% to 50.1%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building Spatio-temporal Transformers for Egocentric 3D Pose Estimation. (arXiv:2206.04785v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04785">
<div class="article-summary-box-inner">
<span><p>Egocentric 3D human pose estimation (HPE) from images is challenging due to
severe self-occlusions and strong distortion introduced by the fish-eye view
from the head mounted camera. Although existing works use intermediate
heatmap-based representations to counter distortion with some success,
addressing self-occlusion remains an open problem. In this work, we leverage
information from past frames to guide our self-attention-based 3D HPE
estimation procedure -- Ego-STAN. Specifically, we build a spatio-temporal
Transformer model that attends to semantically rich convolutional neural
network-based feature maps. We also propose feature map tokens: a new set of
learnable parameters to attend to these feature maps. Finally, we demonstrate
Ego-STAN's superior performance on the xR-EgoPose dataset where it achieves a
30.6% improvement on the overall mean per-joint position error, while leading
to a 22% drop in parameters compared to the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learn2Augment: Learning to Composite Videos for Data Augmentation in Action Recognition. (arXiv:2206.04790v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04790">
<div class="article-summary-box-inner">
<span><p>We address the problem of data augmentation for video action recognition.
Standard augmentation strategies in video are hand-designed and sample the
space of possible augmented data points either at random, without knowing which
augmented points will be better, or through heuristics. We propose to learn
what makes a good video for action recognition and select only high-quality
samples for augmentation. In particular, we choose video compositing of a
foreground and a background video as the data augmentation process, which
results in diverse and realistic new samples. We learn which pairs of videos to
augment without having to actually composite them. This reduces the space of
possible augmentations, which has two advantages: it saves computational cost
and increases the accuracy of the final trained classifier, as the augmented
pairs are of higher quality than average. We present experimental results on
the entire spectrum of training settings: few-shot, semi-supervised and fully
supervised. We observe consistent improvements across all of them over prior
work and baselines on Kinetics, UCF101, HMDB51, and achieve a new
state-of-the-art on settings with limited data. We see improvements of up to
8.6% in the semi-supervised setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stable and memory-efficient image recovery using monotone operator learning (MOL). (arXiv:2206.04797v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04797">
<div class="article-summary-box-inner">
<span><p>We introduce a monotone deep equilibrium learning framework for large-scale
inverse problems in imaging. The proposed algorithm relies on forward-backward
splitting, where each iteration consists of a gradient descent involving the
score function and a conjugate gradient algorithm to encourage data
consistency. The score function is modeled as a monotone convolutional neural
network. The use of a monotone operator offers several benefits, including
guaranteed convergence, uniqueness of fixed point, and robustness to input
perturbations, similar to the use of convex priors in compressive sensing. In
addition, the proposed formulation is significantly more memory-efficient than
unrolled methods, which allows us to apply it to 3D problems that current
unrolled algorithms cannot handle. Experiments show that the proposed scheme
can offer improved performance in 3D settings while being stable in the
presence of input perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">R4D: Utilizing Reference Objects for Long-Range Distance Estimation. (arXiv:2206.04831v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04831">
<div class="article-summary-box-inner">
<span><p>Estimating the distance of objects is a safety-critical task for autonomous
driving. Focusing on short-range objects, existing methods and datasets neglect
the equally important long-range objects. In this paper, we introduce a
challenging and under-explored task, which we refer to as Long-Range Distance
Estimation, as well as two datasets to validate new methods developed for this
task. We then proposeR4D, the first framework to accurately estimate the
distance of long-range objects by using references with known distances in the
scene. Drawing inspiration from human perception, R4D builds a graph by
connecting a target object to all references. An edge in the graph encodes the
relative distance information between a pair of target and reference objects.
An attention module is then used to weigh the importance of reference objects
and combine them into one target object distance prediction. Experiments on the
two proposed datasets demonstrate the effectiveness and robustness of R4D by
showing significant improvements compared to existing baselines. We are looking
to make the proposed dataset, Waymo OpenDataset - Long-Range Labels, available
publicly at waymo.com/open/download.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masked Autoencoders are Robust Data Augmentors. (arXiv:2206.04846v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04846">
<div class="article-summary-box-inner">
<span><p>Deep neural networks are capable of learning powerful representations to
tackle complex vision tasks but expose undesirable properties like the
over-fitting issue. To this end, regularization techniques like image
augmentation are necessary for deep neural networks to generalize well.
Nevertheless, most prevalent image augmentation recipes confine themselves to
off-the-shelf linear transformations like scale, flip, and colorjitter. Due to
their hand-crafted property, these augmentations are insufficient to generate
truly hard augmented examples. In this paper, we propose a novel perspective of
augmentation to regularize the training process. Inspired by the recent success
of applying masked image modeling to self-supervised learning, we adopt the
self-supervised masked autoencoder to generate the distorted view of the input
images. We show that utilizing such model-based nonlinear transformation as
data augmentation can improve high-level recognition tasks. We term the
proposed method as \textbf{M}ask-\textbf{R}econstruct \textbf{A}ugmentation
(MRA). The extensive experiments on various image classification benchmarks
verify the effectiveness of the proposed augmentation. Specifically, MRA
consistently enhances the performance on supervised, semi-supervised as well as
few-shot classification. The code will be available at
\url{https://github.com/haohang96/MRA}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Heterogeneous Face Recognition via Face Synthesis with Identity-Attribute Disentanglement. (arXiv:2206.04854v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04854">
<div class="article-summary-box-inner">
<span><p>Heterogeneous Face Recognition (HFR) aims to match faces across different
domains (e.g., visible to near-infrared images), which has been widely applied
in authentication and forensics scenarios. However, HFR is a challenging
problem because of the large cross-domain discrepancy, limited heterogeneous
data pairs, and large variation of facial attributes. To address these
challenges, we propose a new HFR method from the perspective of heterogeneous
data augmentation, named Face Synthesis with Identity-Attribute Disentanglement
(FSIAD). Firstly, the identity-attribute disentanglement (IAD) decouples face
images into identity-related representations and identity-unrelated
representations (called attributes), and then decreases the correlation between
identities and attributes. Secondly, we devise a face synthesis module (FSM) to
generate a large number of images with stochastic combinations of disentangled
identities and attributes for enriching the attribute diversity of synthetic
images. Both the original images and the synthetic ones are utilized to train
the HFR network for tackling the challenges and improving the performance of
HFR. Extensive experiments on five HFR databases validate that FSIAD obtains
superior performance than previous HFR approaches. Particularly, FSIAD obtains
4.8% improvement over state of the art in terms of VR@FAR=0.01% on LAMP-HQ, the
largest HFR database so far.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Symbolic image detection using scene and knowledge graphs. (arXiv:2206.04863v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04863">
<div class="article-summary-box-inner">
<span><p>Sometimes the meaning conveyed by images goes beyond the list of objects they
contain; instead, images may express a powerful message to affect the viewers'
minds. Inferring this message requires reasoning about the relationships
between the objects, and general common-sense knowledge about the components.
In this paper, we use a scene graph, a graph representation of an image, to
capture visual components. In addition, we generate a knowledge graph using
facts extracted from ConceptNet to reason about objects and attributes. To
detect the symbols, we propose a neural network framework named SKG-Sym. The
framework first generates the representations of the scene graph of the image
and its knowledge graph using Graph Convolution Network. The framework then
fuses the representations and uses an MLP to classify them. We extend the
network further to use an attention mechanism which learn the importance of the
graph representations. We evaluate our methods on a dataset of advertisements,
and compare it with baseline symbolism classification methods (ResNet and VGG).
Results show that our methods outperform ResNet in terms of F-score and the
attention-based mechanism is competitive with VGG while it has much lower model
complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Gender Gap in Face Recognition Accuracy Is a Hairy Problem. (arXiv:2206.04867v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04867">
<div class="article-summary-box-inner">
<span><p>It is broadly accepted that there is a "gender gap" in face recognition
accuracy, with females having higher false match and false non-match rates.
However, relatively little is known about the cause(s) of this gender gap. Even
the recent NIST report on demographic effects lists "analyze cause and effect"
under "what we did not do". We first demonstrate that female and male
hairstyles have important differences that impact face recognition accuracy. In
particular, compared to females, male facial hair contributes to creating a
greater average difference in appearance between different male faces. We then
demonstrate that when the data used to estimate recognition accuracy is
balanced across gender for how hairstyles occlude the face, the initially
observed gender gap in accuracy largely disappears. We show this result for two
different matchers, and analyzing images of Caucasians and of
African-Americans. These results suggest that future research on demographic
variation in accuracy should include a check for balanced quality of the test
data as part of the problem formulation. To promote reproducible research,
matchers, attribute classifiers, and datasets used in this research are/will be
publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The 1st Data Science for Pavements Challenge. (arXiv:2206.04874v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04874">
<div class="article-summary-box-inner">
<span><p>The Data Science for Pavement Challenge (DSPC) seeks to accelerate the
research and development of automated vision systems for pavement condition
monitoring and evaluation by providing a platform with benchmarked datasets and
codes for teams to innovate and develop machine learning algorithms that are
practice-ready for use by industry. The first edition of the competition
attracted 22 teams from 8 countries. Participants were required to
automatically detect and classify different types of pavement distresses
present in images captured from multiple sources, and under different
conditions. The competition was data-centric: teams were tasked to increase the
accuracy of a predefined model architecture by utilizing various data
modification methods such as cleaning, labeling and augmentation. A real-time,
online evaluation system was developed to rank teams based on the F1 score.
Leaderboard results showed the promise and challenges of machine for advancing
automation in pavement monitoring and evaluation. This paper summarizes the
solutions from the top 5 teams. These teams proposed innovations in the areas
of data cleaning, annotation, augmentation, and detection parameter tuning. The
F1 score for the top-ranked team was approximately 0.9. The paper concludes
with a review of different experiments that worked well for the current
challenge and those that did not yield any significant improvement in model
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Per-Shot Convex Hull Prediction By Recurrent Learning. (arXiv:2206.04877v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04877">
<div class="article-summary-box-inner">
<span><p>Adaptive video streaming relies on the construction of efficient bitrate
ladders to deliver the best possible visual quality to viewers under bandwidth
constraints. The traditional method of content dependent bitrate ladder
selection requires a video shot to be pre-encoded with multiple encoding
parameters to find the optimal operating points given by the convex hull of the
resulting rate-quality curves. However, this pre-encoding step is equivalent to
an exhaustive search process over the space of possible encoding parameters,
which causes significant overhead in terms of both computation and time
expenditure. To reduce this overhead, we propose a deep learning based method
of content aware convex hull prediction. We employ a recurrent convolutional
network (RCN) to implicitly analyze the spatiotemporal complexity of video
shots in order to predict their convex hulls. A two-step transfer learning
scheme is adopted to train our proposed RCN-Hull model, which ensures
sufficient content diversity to analyze scene complexity, while also making it
possible capture the scene statistics of pristine source videos. Our
experimental results reveal that our proposed model yields better
approximations of the optimal convex hulls, and offers competitive time savings
as compared to existing approaches. On average, the pre-encoding time was
reduced by 58.0% by our method, while the average Bjontegaard delta bitrate
(BD-rate) of the predicted convex hulls against ground truth was 0.08%, while
the mean absolute deviation of the BD-rate distribution was 0.44%
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Foggy Scene Understanding via Self Spatial-Temporal Label Diffusion. (arXiv:2206.04879v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04879">
<div class="article-summary-box-inner">
<span><p>Understanding foggy image sequence in the driving scenes is critical for
autonomous driving, but it remains a challenging task due to the difficulty in
collecting and annotating real-world images of adverse weather. Recently, the
self-training strategy has been considered a powerful solution for unsupervised
domain adaptation, which iteratively adapts the model from the source domain to
the target domain by generating target pseudo labels and re-training the model.
However, the selection of confident pseudo labels inevitably suffers from the
conflict between sparsity and accuracy, both of which will lead to suboptimal
models. To tackle this problem, we exploit the characteristics of the foggy
image sequence of driving scenes to densify the confident pseudo labels.
Specifically, based on the two discoveries of local spatial similarity and
adjacent temporal correspondence of the sequential image data, we propose a
novel Target-Domain driven pseudo label Diffusion (TDo-Dif) scheme. It employs
superpixels and optical flows to identify the spatial similarity and temporal
correspondence, respectively and then diffuses the confident but sparse pseudo
labels within a superpixel or a temporal corresponding pair linked by the flow.
Moreover, to ensure the feature similarity of the diffused pixels, we introduce
local spatial similarity loss and temporal contrastive loss in the model
re-training stage. Experimental results show that our TDo-Dif scheme helps the
adaptive model achieve 51.92% and 53.84% mean intersection-over-union (mIoU) on
two publicly available natural foggy datasets (Foggy Zurich and Foggy Driving),
which exceeds the state-of-the-art unsupervised domain adaptive semantic
segmentation methods. Models and data can be found at
https://github.com/velor2012/TDo-Dif.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Clean Label Backdoor Attack with Two-phase Specific Triggers. (arXiv:2206.04881v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04881">
<div class="article-summary-box-inner">
<span><p>Backdoor attacks threaten Deep Neural Networks (DNNs). Towards stealthiness,
researchers propose clean-label backdoor attacks, which require the adversaries
not to alter the labels of the poisoned training datasets. Clean-label settings
make the attack more stealthy due to the correct image-label pairs, but some
problems still exist: first, traditional methods for poisoning training data
are ineffective; second, traditional triggers are not stealthy which are still
perceptible. To solve these problems, we propose a two-phase and image-specific
triggers generation method to enhance clean-label backdoor attacks. Our methods
are (1) powerful: our triggers can both promote the two phases (i.e., the
backdoor implantation and activation phase) in backdoor attacks simultaneously;
(2) stealthy: our triggers are generated from each image. They are
image-specific instead of fixed triggers. Extensive experiments demonstrate
that our approach can achieve a fantastic attack success rate~(98.98%) with low
poisoning rate~(5%), high stealthiness under many evaluation metrics and is
resistant to backdoor defense methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AntPivot: Livestream Highlight Detection via Hierarchical Attention Mechanism. (arXiv:2206.04888v1 [cs.MM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04888">
<div class="article-summary-box-inner">
<span><p>In recent days, streaming technology has greatly promoted the development in
the field of livestream. Due to the excessive length of livestream records,
it's quite essential to extract highlight segments with the aim of effective
reproduction and redistribution. Although there are lots of approaches proven
to be effective in the highlight detection for other modals, the challenges
existing in livestream processing, such as the extreme durations, large topic
shifts, much irrelevant information and so forth, heavily hamper the adaptation
and compatibility of these methods. In this paper, we formulate a new task
Livestream Highlight Detection, discuss and analyze the difficulties listed
above and propose a novel architecture AntPivot to solve this problem.
Concretely, we first encode the original data into multiple views and model
their temporal relations to capture clues in a hierarchical attention
mechanism. Afterwards, we try to convert the detection of highlight clips into
the search for optimal decision sequences and use the fully integrated
representations to predict the final results in a dynamic-programming
mechanism. Furthermore, we construct a fully-annotated dataset AntHighlight to
instantiate this task and evaluate the performance of our model. The extensive
experiments indicate the effectiveness and validity of our proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeRF-In: Free-Form NeRF Inpainting with RGB-D Priors. (arXiv:2206.04901v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04901">
<div class="article-summary-box-inner">
<span><p>Though Neural Radiance Field (NeRF) demonstrates compelling novel view
synthesis results, it is still unintuitive to edit a pre-trained NeRF because
the neural network's parameters and the scene geometry/appearance are often not
explicitly associated. In this paper, we introduce the first framework that
enables users to remove unwanted objects or retouch undesired regions in a 3D
scene represented by a pre-trained NeRF without any category-specific data and
training. The user first draws a free-form mask to specify a region containing
unwanted objects over a rendered view from the pre-trained NeRF. Our framework
first transfers the user-provided mask to other rendered views and estimates
guiding color and depth images within these transferred masked regions. Next,
we formulate an optimization problem that jointly inpaints the image content in
all masked regions across multiple views by updating the NeRF model's
parameters. We demonstrate our framework on diverse scenes and show it obtained
visual plausible and structurally consistent results across multiple views
using shorter time and less user manual efforts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Out of Sight, Out of Mind: A Source-View-Wise Feature Aggregation for Multi-View Image-Based Rendering. (arXiv:2206.04906v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04906">
<div class="article-summary-box-inner">
<span><p>To estimate the volume density and color of a 3D point in the multi-view
image-based rendering, a common approach is to inspect the consensus existence
among the given source image features, which is one of the informative cues for
the estimation procedure. To this end, most of the previous methods utilize
equally-weighted aggregation features. However, this could make it hard to
check the consensus existence when some outliers, which frequently occur by
occlusions, are included in the source image feature set. In this paper, we
propose a novel source-view-wise feature aggregation method, which facilitates
us to find out the consensus in a robust way by leveraging local structures in
the feature set. We first calculate the source-view-wise distance distribution
for each source feature for the proposed aggregation. After that, the distance
distribution is converted to several similarity distributions with the proposed
learnable similarity mapping functions. Finally, for each element in the
feature set, the aggregation features are extracted by calculating the weighted
means and variances, where the weights are derived from the similarity
distributions. In experiments, we validate the proposed method on various
benchmark datasets, including synthetic and real image scenes. The experimental
results demonstrate that incorporating the proposed features improves the
performance by a large margin, resulting in the state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PatchComplete: Learning Multi-Resolution Patch Priors for 3D Shape Completion on Unseen Categories. (arXiv:2206.04916v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04916">
<div class="article-summary-box-inner">
<span><p>While 3D shape representations enable powerful reasoning in many visual and
perception applications, learning 3D shape priors tends to be constrained to
the specific categories trained on, leading to an inefficient learning process,
particularly for general applications with unseen categories. Thus, we propose
PatchComplete, which learns effective shape priors based on multi-resolution
local patches, which are often more general than full shapes (e.g., chairs and
tables often both share legs) and thus enable geometric reasoning about unseen
class categories. To learn these shared substructures, we learn
multi-resolution patch priors across all train categories, which are then
associated to input partial shape observations by attention across the patch
priors, and finally decoded into a complete shape reconstruction. Such
patch-based priors avoid overfitting to specific train categories and enable
reconstruction on entirely unseen categories at test time. We demonstrate the
effectiveness of our approach on synthetic ShapeNet data as well as challenging
real-scanned objects from ScanNet, which include noise and clutter, improving
over state of the art in novel-category shape completion by 19.3% in chamfer
distance on ShapeNet, and 9.0% for ScanNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ego2HandsPose: A Dataset for Egocentric Two-hand 3D Global Pose Estimation. (arXiv:2206.04927v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04927">
<div class="article-summary-box-inner">
<span><p>Color-based two-hand 3D pose estimation in the global coordinate system is
essential in many applications. However, there are very few datasets dedicated
to this task and no existing dataset supports estimation in a non-laboratory
environment. This is largely attributed to the sophisticated data collection
process required for 3D hand pose annotations, which also leads to difficulty
in obtaining instances with the level of visual diversity needed for estimation
in the wild. Progressing towards this goal, a large-scale dataset Ego2Hands was
recently proposed to address the task of two-hand segmentation and detection in
the wild. The proposed composition-based data generation technique can create
two-hand instances with quality, quantity and diversity that generalize well to
unseen domains. In this work, we present Ego2HandsPose, an extension of
Ego2Hands that contains 3D hand pose annotation and is the first dataset that
enables color-based two-hand 3D tracking in unseen domains. To this end, we
develop a set of parametric fitting algorithms to enable 1) 3D hand pose
annotation using a single image, 2) automatic conversion from 2D to 3D hand
poses and 3) accurate two-hand tracking with temporal consistency. We provide
incremental quantitative analysis on the multi-stage pipeline and show that
training on our dataset achieves state-of-the-art results that significantly
outperforms other datasets for the task of egocentric two-hand global 3D pose
estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Template: Topology-aware Reconstruction and Disentangled Generation of 3D Meshes. (arXiv:2206.04942v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04942">
<div class="article-summary-box-inner">
<span><p>This paper introduces a novel framework called DTNet for 3D mesh
reconstruction and generation via Disentangled Topology. Beyond previous works,
we learn a topology-aware neural template specific to each input then deform
the template to reconstruct a detailed mesh while preserving the learned
topology. One key insight is to decouple the complex mesh reconstruction into
two sub-tasks: topology formulation and shape deformation. Thanks to the
decoupling, DT-Net implicitly learns a disentangled representation for the
topology and shape in the latent space. Hence, it can enable novel disentangled
controls for supporting various shape generation applications, e.g., remix the
topologies of 3D objects, that are not achievable by previous reconstruction
works. Extensive experimental results demonstrate that our method is able to
produce high-quality meshes, particularly with diverse topologies, as compared
with the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Multi-view Semi-supervised Clustering with Sample Pairwise Constraints. (arXiv:2206.04949v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04949">
<div class="article-summary-box-inner">
<span><p>Multi-view clustering has attracted much attention thanks to the capacity of
multi-source information integration. Although numerous advanced methods have
been proposed in past decades, most of them generally overlook the significance
of weakly-supervised information and fail to preserve the feature properties of
multiple views, thus resulting in unsatisfactory clustering performance. To
address these issues, in this paper, we propose a novel Deep Multi-view
Semi-supervised Clustering (DMSC) method, which jointly optimizes three kinds
of losses during networks finetuning, including multi-view clustering loss,
semi-supervised pairwise constraint loss and multiple autoencoders
reconstruction loss. Specifically, a KL divergence based multi-view clustering
loss is imposed on the common representation of multi-view data to perform
heterogeneous feature optimization, multi-view weighting and clustering
prediction simultaneously. Then, we innovatively propose to integrate pairwise
constraints into the process of multi-view clustering by enforcing the learned
multi-view representation of must-link samples (cannot-link samples) to be
similar (dissimilar), such that the formed clustering architecture can be more
credible. Moreover, unlike existing rivals that only preserve the encoders for
each heterogeneous branch during networks finetuning, we further propose to
tune the intact autoencoders frame that contains both encoders and decoders. In
this way, the issue of serious corruption of view-specific and view-shared
feature space could be alleviated, making the whole training procedure more
stable. Through comprehensive experiments on eight popular image datasets, we
demonstrate that our proposed approach performs better than the
state-of-the-art multi-view and single-view competitors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Deep Subspace Clustering with Entropy-norm. (arXiv:2206.04958v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04958">
<div class="article-summary-box-inner">
<span><p>Auto-Encoder based deep subspace clustering (DSC) is widely used in computer
vision, motion segmentation and image processing. However, it suffers from the
following three issues in the self-expressive matrix learning process: the
first one is less useful information for learning self-expressive weights due
to the simple reconstruction loss; the second one is that the construction of
the self-expression layer associated with the sample size requires
high-computational cost; and the last one is the limited connectivity of the
existing regularization terms. In order to address these issues, in this paper
we propose a novel model named Self-Supervised deep Subspace Clustering with
Entropy-norm (S$^{3}$CE). Specifically, S$^{3}$CE exploits a self-supervised
contrastive network to gain a more effetive feature vector. The local structure
and dense connectivity of the original data benefit from the self-expressive
layer and additional entropy-norm constraint. Moreover, a new module with data
enhancement is designed to help S$^{3}$CE focus on the key information of data,
and improve the clustering performance of positive and negative instances
through spectral clustering. Extensive experimental results demonstrate the
superior performance of S$^{3}$CE in comparison to the state-of-the-art
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NR-DFERNet: Noise-Robust Network for Dynamic Facial Expression Recognition. (arXiv:2206.04975v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04975">
<div class="article-summary-box-inner">
<span><p>Dynamic facial expression recognition (DFER) in the wild is an extremely
challenging task, due to a large number of noisy frames in the video sequences.
Previous works focus on extracting more discriminative features, but ignore
distinguishing the key frames from the noisy frames. To tackle this problem, we
propose a noise-robust dynamic facial expression recognition network
(NR-DFERNet), which can effectively reduce the interference of noisy frames on
the DFER task. Specifically, at the spatial stage, we devise a dynamic-static
fusion module (DSF) that introduces dynamic features to static features for
learning more discriminative spatial features. To suppress the impact of target
irrelevant frames, we introduce a novel dynamic class token (DCT) for the
transformer at the temporal stage. Moreover, we design a snippet-based filter
(SF) at the decision stage to reduce the effect of too many neutral frames on
non-neutral sequence classification. Extensive experimental results demonstrate
that our NR-DFERNet outperforms the state-of-the-art methods on both the DFEW
and AFEW benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Convolutional Layers Are Not Translation Equivariant. (arXiv:2206.04979v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04979">
<div class="article-summary-box-inner">
<span><p>The purpose of this paper is to correct a misconception about convolutional
neural networks (CNNs). CNNs are made up of convolutional layers which are
shift equivariant due to weight sharing. However, contrary to popular belief,
convolutional layers are not translation equivariant, even when boundary
effects are ignored and when pooling and subsampling are absent. This is
because shift equivariance is a discrete symmetry while translation
equivariance is a continuous symmetry. That discrete systems do not in general
inherit continuous equivariances is a fundamental limitation of equivariant
deep learning. We discuss two implications of this fact. First, CNNs have
achieved success in image processing despite not inheriting the translation
equivariance of the physical systems they model. Second, using CNNs to solve
partial differential equations (PDEs) will not result in translation
equivariant solvers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Position Labels for Self-Supervised Vision Transformer. (arXiv:2206.04981v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04981">
<div class="article-summary-box-inner">
<span><p>Position encoding is important for vision transformer (ViT) to capture the
spatial structure of the input image. General efficacy has been proven in ViT.
In our work we propose to train ViT to recognize the 2D position encoding of
patches of the input image, this apparently simple task actually yields a
meaningful self-supervisory task. Based on previous work on ViT position
encoding, we propose two position labels dedicated to 2D images including
absolute position and relative position. Our position labels can be easily
plugged into transformer, combined with the various current ViT variants. It
can work in two ways: 1.As an auxiliary training target for vanilla ViT (e.g.,
ViT-B and Swin-B) to improve model performance. 2. Combine the self-supervised
ViT (e.g., MAE) to provide a more powerful self-supervised signal for semantic
feature learning. Experiments demonstrate that solely due to the proposed
self-supervised methods, Swin-B and ViT-B obtained improvements of 1.9% (top-1
Acc) and 5.6% (top-1 Acc) on Mini-ImageNet, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Subjective Quality Assessment for Images Generated by Computer Graphics. (arXiv:2206.05008v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05008">
<div class="article-summary-box-inner">
<span><p>With the development of rendering techniques, computer graphics generated
images (CGIs) have been widely used in practical application scenarios such as
architecture design, video games, simulators, movies, etc. Different from
natural scene images (NSIs), the distortions of CGIs are usually caused by poor
rending settings and limited computation resources. What's more, some CGIs may
also suffer from compression distortions in transmission systems like cloud
gaming and stream media. However, limited work has been put forward to tackle
the problem of computer graphics generated images' quality assessment (CG-IQA).
Therefore, in this paper, we establish a large-scale subjective CG-IQA database
to deal with the challenge of CG-IQA tasks. We collect 25,454 in-the-wild CGIs
through previous databases and personal collection. After data cleaning, we
carefully select 1,200 CGIs to conduct the subjective experiment. Several
popular no-reference image quality assessment (NR-IQA) methods are tested on
our database. The experimental results show that the handcrafted-based methods
achieve low correlation with subjective judgment and deep learning based
methods obtain relatively better performance, which demonstrates that the
current NR-IQA models are not suitable for CG-IQA tasks and more effective
models are urgently needed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial Cross-Attention Improves Self-Supervised Visual Representation Learning. (arXiv:2206.05028v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05028">
<div class="article-summary-box-inner">
<span><p>Unsupervised representation learning methods like SwAV are proved to be
effective in learning visual semantics of a target dataset. The main idea
behind these methods is that different views of a same image represent the same
semantics. In this paper, we further introduce an add-on module to facilitate
the injection of the knowledge accounting for spatial cross correlations among
the samples. This in turn results in distilling intra-class information
including feature level locations and cross similarities between same-class
instances. The proposed add-on can be added to existing methods such as the
SwAV. We can later remove the add-on module for inference without any
modification of the learned weights. Through an extensive set of empirical
evaluations, we verify that our method yields an improved performance in
detecting the class activation maps, top-1 classification accuracy, and
down-stream tasks such as object detection, with different configuration
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Generation with Multimodal Priors using Denoising Diffusion Probabilistic Models. (arXiv:2206.05039v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05039">
<div class="article-summary-box-inner">
<span><p>Image synthesis under multi-modal priors is a useful and challenging task
that has received increasing attention in recent years. A major challenge in
using generative models to accomplish this task is the lack of paired data
containing all modalities (i.e. priors) and corresponding outputs. In recent
work, a variational auto-encoder (VAE) model was trained in a weakly supervised
manner to address this challenge. Since the generative power of VAEs is usually
limited, it is difficult for this method to synthesize images belonging to
complex distributions. To this end, we propose a solution based on a denoising
diffusion probabilistic models to synthesise images under multi-model priors.
Based on the fact that the distribution over each time step in the diffusion
model is Gaussian, in this work we show that there exists a closed-form
expression to the generate the image corresponds to the given modalities. The
proposed solution does not require explicit retraining for all modalities and
can leverage the outputs of individual modalities to generate realistic images
according to different constraints. We conduct studies on two real-world
datasets to demonstrate the effectiveness of our approach
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A GPU-Accelerated Light-field Super-resolution Framework Based on Mixed Noise Model and Weighted Regularization. (arXiv:2206.05047v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05047">
<div class="article-summary-box-inner">
<span><p>This paper presents a GPU-accelerated computational framework for
reconstructing high resolution (HR) LF images under a mixed Gaussian-Impulse
noise condition. The main focus is on developing a high-performance approach
considering processing speed and reconstruction quality. From a statistical
perspective, we derive a joint $\ell^1$-$\ell^2$ data fidelity term for
penalizing the HR reconstruction error taking into account the mixed noise
situation. For regularization, we employ the weighted non-local total variation
approach, which allows us to effectively realize LF image prior through a
proper weighting scheme. We show that the alternating direction method of
multipliers algorithm (ADMM) can be used to simplify the computation complexity
and results in a high-performance parallel computation on the GPU Platform. An
extensive experiment is conducted on both synthetic 4D LF dataset and natural
image dataset to validate the proposed SR model's robustness and evaluate the
accelerated optimizer's performance. The experimental results show that our
approach achieves better reconstruction quality under severe mixed-noise
conditions as compared to the state-of-the-art approaches. In addition, the
proposed approach overcomes the limitation of the previous work in handling
large-scale SR tasks. While fitting within a single off-the-shelf GPU, the
proposed accelerator provides an average speedup of 2.46$\times$ and
1.57$\times$ for $\times 2$ and $\times 3$ SR tasks, respectively. In addition,
a speedup of $77\times$ is achieved as compared to CPU execution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Denoising Generalized Expectation-Consistent Approximation for MRI Image Recovery. (arXiv:2206.05049v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05049">
<div class="article-summary-box-inner">
<span><p>To solve inverse problems, plug-and-play (PnP) methods have been developed
that replace the proximal step in a convex optimization algorithm with a call
to an application-specific denoiser, often implemented using a deep neural
network (DNN). Although such methods have been successful, they can be
improved. For example, denoisers are usually designed/trained to remove white
Gaussian noise, but the denoiser input error in PnP algorithms is usually far
from white or Gaussian. Approximate message passing (AMP) methods provide white
and Gaussian denoiser input error, but only when the forward operator is a
large random matrix. In this work, for Fourier-based forward operators, we
propose a PnP algorithm based on generalized expectation-consistent (GEC)
approximation -- a close cousin of AMP -- that offers predictable error
statistics at each iteration, as well as a new DNN denoiser that leverages
those statistics. We apply our approach to magnetic resonance imaging (MRI)
image recovery and demonstrate its advantages over existing PnP and AMP
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A No-reference Quality Assessment Metric for Point Cloud Based on Captured Video Sequences. (arXiv:2206.05054v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05054">
<div class="article-summary-box-inner">
<span><p>Point cloud is one of the most widely used digital formats of 3D models, the
visual quality of which is quite sensitive to distortions such as downsampling,
noise, and compression. To tackle the challenge of point cloud quality
assessment (PCQA) in scenarios where reference is not available, we propose a
no-reference quality assessment metric for colored point cloud based on
captured video sequences. Specifically, three video sequences are obtained by
rotating the camera around the point cloud through three specific orbits. The
video sequences not only contain the static views but also include the
multi-frame temporal information, which greatly helps understand the human
perception of the point clouds. Then we modify the ResNet3D as the feature
extraction model to learn the correlation between the capture videos and
corresponding subjective quality scores. The experimental results show that our
method outperforms most of the state-of-the-art full-reference and no-reference
PCQA metrics, which validates the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning self-calibrated optic disc and cup segmentation from multi-rater annotations. (arXiv:2206.05092v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05092">
<div class="article-summary-box-inner">
<span><p>The segmentation of optic disc(OD) and optic cup(OC) from fundus images is an
important fundamental task for glaucoma diagnosis. In the clinical practice, it
is often necessary to collect opinions from multiple experts to obtain the
final OD/OC annotation. This clinical routine helps to mitigate the individual
bias. But when data is multiply annotated, standard deep learning models will
be inapplicable. In this paper, we propose a novel neural network framework to
learn OD/OC segmentation from multi-rater annotations. The segmentation results
are self-calibrated through the iterative optimization of multi-rater
expertness estimation and calibrated OD/OC segmentation. In this way, the
proposed method can realize a mutual improvement of both tasks and finally
obtain a refined segmentation result. Specifically, we propose Diverging
Model(DivM) and Converging Model(ConM) to process the two tasks respectively.
ConM segments the raw image based on the multi-rater expertness map provided by
DivM. DivM generates multi-rater expertness map from the segmentation mask
provided by ConM. The experiment results show that by recurrently running ConM
and DivM, the results can be self-calibrated so as to outperform a range of
state-of-the-art(SOTA) multi-rater segmentation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Federated Momentum Contrastive Clustering. (arXiv:2206.05093v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05093">
<div class="article-summary-box-inner">
<span><p>We present federated momentum contrastive clustering (FedMCC), a learning
framework that can not only extract discriminative representations over
distributed local data but also perform data clustering. In FedMCC, a
transformed data pair passes through both the online and target networks,
resulting in four representations over which the losses are determined. The
resulting high-quality representations generated by FedMCC can outperform
several existing self-supervised learning methods for linear evaluation and
semi-supervised learning tasks. FedMCC can easily be adapted to ordinary
centralized clustering through what we call momentum contrastive clustering
(MCC). We show that MCC achieves state-of-the-art clustering accuracy results
in certain datasets such as STL-10 and ImageNet-10. We also present a method to
reduce the memory footprint of our clustering schemes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimVP: Simpler yet Better Video Prediction. (arXiv:2206.05099v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05099">
<div class="article-summary-box-inner">
<span><p>From CNN, RNN, to ViT, we have witnessed remarkable advancements in video
prediction, incorporating auxiliary inputs, elaborate neural architectures, and
sophisticated training strategies. We admire these progresses but are confused
about the necessity: is there a simple method that can perform comparably well?
This paper proposes SimVP, a simple video prediction model that is completely
built upon CNN and trained by MSE loss in an end-to-end fashion. Without
introducing any additional tricks and complicated strategies, we can achieve
state-of-the-art performance on five benchmark datasets. Through extended
experiments, we demonstrate that SimVP has strong generalization and
extensibility on real-world datasets. The significant reduction of training
cost makes it easier to scale to complex scenarios. We believe SimVP can serve
as a solid baseline to stimulate the further development of video prediction.
The code is available at
\href{https://github.com/gaozhangyang/SimVP-Simpler-yet-Better-Video-Prediction}{Github}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Saccade Mechanisms for Image Classification, Object Detection and Tracking. (arXiv:2206.05102v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05102">
<div class="article-summary-box-inner">
<span><p>We examine how the saccade mechanism from biological vision can be used to
make deep neural networks more efficient for classification and object
detection problems. Our proposed approach is based on the ideas of
attention-driven visual processing and saccades, miniature eye movements
influenced by attention. We conduct experiments by analyzing: i) the robustness
of different deep neural network (DNN) feature extractors to partially-sensed
images for image classification and object detection, and ii) the utility of
saccades in masking image patches for image classification and object tracking.
Experiments with convolutional nets (ResNet-18) and transformer-based models
(ViT, DETR, TransTrack) are conducted on several datasets (CIFAR-10, DAVSOD,
MSCOCO, and MOT17). Our experiments show intelligent data reduction via
learning to mimic human saccades when used in conjunction with state-of-the-art
DNNs for classification, detection, and tracking tasks. We observed minimal
drop in performance for the classification and detection tasks while only using
about 30\% of the original sensor data. We discuss how the saccade mechanism
can inform hardware design via ``in-pixel'' processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Globally-Optimal Contrast Maximisation for Event Cameras. (arXiv:2206.05127v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05127">
<div class="article-summary-box-inner">
<span><p>Event cameras are bio-inspired sensors that perform well in challenging
illumination conditions and have high temporal resolution. However, their
concept is fundamentally different from traditional frame-based cameras. The
pixels of an event camera operate independently and asynchronously. They
measure changes of the logarithmic brightness and return them in the highly
discretised form of time-stamped events indicating a relative change of a
certain quantity since the last event. New models and algorithms are needed to
process this kind of measurements. The present work looks at several motion
estimation problems with event cameras. The flow of the events is modelled by a
general homographic warping in a space-time volume, and the objective is
formulated as a maximisation of contrast within the image of warped events. Our
core contribution consists of deriving globally optimal solutions to these
generally non-convex problems, which removes the dependency on a good initial
guess plaguing existing methods. Our methods rely on branch-and-bound
optimisation and employ novel and efficient, recursive upper and lower bounds
derived for six different contrast estimation functions. The practical validity
of our approach is demonstrated by a successful application to three different
event camera motion estimation problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-time Hyper-Dimensional Reconfiguration at the Edge using Hardware Accelerators. (arXiv:2206.05128v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05128">
<div class="article-summary-box-inner">
<span><p>In this paper we present Hyper-Dimensional Reconfigurable Analytics at the
Tactical Edge (HyDRATE) using low-SWaP embedded hardware that can perform
real-time reconfiguration at the edge leveraging non-MAC (free of
floating-point MultiplyACcumulate operations) deep neural nets (DNN) combined
with hyperdimensional (HD) computing accelerators. We describe the algorithm,
trained quantized model generation, and simulated performance of a feature
extractor free of multiply-accumulates feeding a hyperdimensional logic-based
classifier. Then we show how performance increases with the number of
hyperdimensions. We describe the realized low-SWaP FPGA hardware and embedded
software system compared to traditional DNNs and detail the implemented
hardware accelerators. We discuss the measured system latency and power, noise
robustness due to use of learnable quantization and HD computing, actual versus
simulated system performance for a video activity classification task and
demonstration of reconfiguration on this same dataset. We show that
reconfigurability in the field is achieved by retraining only the feed-forward
HD classifier without gradient descent backpropagation (gradient-free), using
few-shot learning of new classes at the edge. Initial work performed used LRCN
DNN and is currently extended to use Two-stream DNN with improved performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly-supervised segmentation using inherently-explainable classification models and their application to brain tumour classification. (arXiv:2206.05148v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05148">
<div class="article-summary-box-inner">
<span><p>Deep learning models have shown their potential for several applications.
However, most of the models are opaque and difficult to trust due to their
complex reasoning - commonly known as the black-box problem. Some fields, such
as medicine, require a high degree of transparency to accept and adopt such
technologies. Consequently, creating explainable/interpretable models or
applying post-hoc methods on classifiers to build trust in deep learning models
are required. Moreover, deep learning methods can be used for segmentation
tasks, which typically require hard-to-obtain, time-consuming
manually-annotated segmentation labels for training. This paper introduces
three inherently-explainable classifiers to tackle both of these problems as
one. The localisation heatmaps provided by the networks -- representing the
models' focus areas and being used in classification decision-making -- can be
directly interpreted, without requiring any post-hoc methods to derive
information for model explanation. The models are trained by using the input
image and only the classification labels as ground-truth in a supervised
fashion - without using any information about the location of the region of
interest (i.e. the segmentation labels), making the segmentation training of
the models weakly-supervised through classification labels. The final
segmentation is obtained by thresholding these heatmaps. The models were
employed for the task of multi-class brain tumour classification using two
different datasets, resulting in the best F1-score of 0.93 for the supervised
classification task while securing a median Dice score of 0.67$\pm$0.08 for the
weakly-supervised segmentation task. Furthermore, the obtained accuracy on a
subset of tumour-only images outperformed the state-of-the-art glioma tumour
grading binary classifiers with the best model achieving 98.7\% accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Referring Image Matting. (arXiv:2206.05149v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05149">
<div class="article-summary-box-inner">
<span><p>Image matting refers to extracting the accurate foregrounds in the image.
Current automatic methods tend to extract all the salient objects in the image
indiscriminately. In this paper, we propose a new task named Referring Image
Matting (RIM), referring to extracting the meticulous alpha matte of the
specific object that can best match the given natural language description.
However, prevalent visual grounding methods are all limited to the segmentation
level, probably due to the lack of high-quality datasets for RIM. To fill the
gap, we establish the first large-scale challenging dataset RefMatte by
designing a comprehensive image composition and expression generation engine to
produce synthetic images on top of current public high-quality matting
foregrounds with flexible logics and re-labelled diverse attributes. RefMatte
consists of 230 object categories, 47,500 images, 118,749 expression-region
entities, and 474,996 expressions, which can be further extended easily in the
future. Besides this, we also construct a real-world test set with manually
generated phrase annotations consisting of 100 natural images to further
evaluate the generalization of RIM models. We first define the task of RIM in
two settings, i.e., prompt-based and expression-based, and then benchmark
several representative methods together with specific model designs for image
matting. The results provide empirical insights into the limitations of
existing methods as well as possible solutions. We believe the new task RIM
along with the RefMatte dataset will open new research directions in this area
and facilitate future studies. The dataset and code will be made publicly
available at https://github.com/JizhiziLi/RIM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MEAT: Maneuver Extraction from Agent Trajectories. (arXiv:2206.05158v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05158">
<div class="article-summary-box-inner">
<span><p>Advances in learning-based trajectory prediction are enabled by large-scale
datasets. However, in-depth analysis of such datasets is limited. Moreover, the
evaluation of prediction models is limited to metrics averaged over all samples
in the dataset. We propose an automated methodology that allows to extract
maneuvers (e.g., left turn, lane change) from agent trajectories in such
datasets. The methodology considers information about the agent dynamics and
information about the lane segments the agent traveled along. Although it is
possible to use the resulting maneuvers for training classification networks,
we exemplary use them for extensive trajectory dataset analysis and
maneuver-specific evaluation of multiple state-of-the-art trajectory prediction
models. Additionally, an analysis of the datasets and an evaluation of the
prediction models based on the agent dynamics is provided.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Image Processing Pipeline for Camera Trap Time-Lapse Recordings. (arXiv:2206.05159v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05159">
<div class="article-summary-box-inner">
<span><p>A new open-source image processing pipeline for analyzing camera trap
time-lapse recordings is described. This pipeline includes machine learning
models to assist human-in-the-loop video segmentation and animal
re-identification. We present some performance results and observations on the
utility of this pipeline after using it in a year-long project studying the
spatial ecology and social behavior of the gopher tortoise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Feature Self-relation for Self-supervised Transformer. (arXiv:2206.05184v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05184">
<div class="article-summary-box-inner">
<span><p>Learning representations with self-supervision for convolutional networks
(CNN) has proven effective for vision tasks. As an alternative for CNN, vision
transformers (ViTs) emerge strong representation ability with the pixel-level
self-attention and channel-level feed-forward networks. Recent works reveal
that self-supervised learning helps unleash the great potential of ViTs. Still,
most works follow self-supervised strategy designed for CNNs, e.g.,
instance-level discrimination of samples, but they ignore the unique properties
of ViTs. We observe that modeling relations among pixels and channels
distinguishes ViTs from other networks. To enforce this property, we explore
the feature self-relations for training self-supervised ViTs. Specifically,
instead of conducting self-supervised learning solely on feature embeddings
from multiple views, we utilize the feature self-relations, i.e.,
pixel/channel-level self-relations, for self-supervised learning. Self-relation
based learning further enhance the relation modeling ability of ViTs, resulting
in strong representations that stably improve performance on multiple
downstream tasks. Our source code will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning the Space of Deep Models. (arXiv:2206.05194v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05194">
<div class="article-summary-box-inner">
<span><p>Embedding of large but redundant data, such as images or text, in a hierarchy
of lower-dimensional spaces is one of the key features of representation
learning approaches, which nowadays provide state-of-the-art solutions to
problems once believed hard or impossible to solve. In this work, in a plot
twist with a strong meta aftertaste, we show how trained deep models are as
redundant as the data they are optimized to process, and how it is therefore
possible to use deep learning models to embed deep learning models. In
particular, we show that it is possible to use representation learning to learn
a fixed-size, low-dimensional embedding space of trained deep models and that
such space can be explored by interpolation or optimization to attain
ready-to-use models. We find that it is possible to learn an embedding space of
multiple instances of the same architecture and of multiple architectures. We
address image classification and neural representation of signals, showing how
our embedding space can be learnt so as to capture the notions of performance
and 3D shape, respectively. In the Multi-Architecture setting we also show how
an embedding trained only on a subset of architectures can learn to generate
already-trained instances of architectures it never sees instantiated at
training time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ClamNet: Using contrastive learning with variable depth Unets for medical image segmentation. (arXiv:2206.05225v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05225">
<div class="article-summary-box-inner">
<span><p>Unets have become the standard method for semantic segmentation of medical
images, along with fully convolutional networks (FCN). Unet++ was introduced as
a variant of Unet, in order to solve some of the problems facing Unet and FCNs.
Unet++ provided networks with an ensemble of variable depth Unets, hence
eliminating the need for professionals estimating the best suitable depth for a
task. While Unet and all its variants, including Unet++ aimed at providing
networks that were able to train well without requiring large quantities of
annotated data, none of them attempted to eliminate the need for pixel-wise
annotated data altogether. Obtaining such data for each disease to be diagnosed
comes at a high cost. Hence such data is scarce. In this paper we use
contrastive learning to train Unet++ for semantic segmentation of medical
images using medical images from various sources including magnetic resonance
imaging (MRI) and computed tomography (CT), without the need for pixel-wise
annotations. Here we describe the architecture of the proposed model and the
training method used. This is still a work in progress and so we abstain from
including results in this paper. The results and the trained model would be
made available upon publication or in subsequent versions of this paper on
arxiv.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optical Diffraction Tomography based on 3D Physics-Inspired Neural Network (PINN). (arXiv:2206.05236v1 [physics.optics])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05236">
<div class="article-summary-box-inner">
<span><p>Optical diffraction tomography (ODT) is an emerging 3D imaging technique that
is used for the 3D reconstruction of the refractive index (RI) for
semi-transparent samples. Various inverse models have been proposed to
reconstruct the 3D RI based on the holographic detection of different samples
such as the Born and the Rytov approximations. However, such approximations
usually suffer from the so-called missing-cone problem that results in an
elongation of the final reconstruction along the optical axis. Different
iterative schemes have been proposed to solve the missing cone problem relying
on physical forward models and an error function that aims at filling in the
k-space and thus eliminating the missing-cone problem and reaching better
reconstruction accuracy. In this paper, we propose a different approach where a
3D neural network (NN) is employed. The NN is trained with a cost function
derived from a physical model based on the physics of optical wave propagation.
The 3D NN starts with an initial guess for the 3D RI reconstruction (i.e. Born,
or Rytov) and aims at reconstructing better 3D reconstruction based on an error
function. With this technique, the NN can be trained without any examples of
the relation between the ill-posed reconstruction (Born or Rytov) and the
ground truth (true shape).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lost in Transmission: On the Impact of Networking Corruptions on Video Machine Learning Models. (arXiv:2206.05252v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05252">
<div class="article-summary-box-inner">
<span><p>We study how networking corruptions--data corruptions caused by networking
errors--affect video machine learning (ML) models. We discover apparent
networking corruptions in Kinetics-400, a benchmark video ML dataset. In a
simulation study, we investigate (1) what artifacts networking corruptions
cause, (2) how such artifacts affect ML models, and (3) whether standard
robustness methods can mitigate their negative effects. We find that networking
corruptions cause visual and temporal artifacts (i.e., smeared colors or frame
drops). These networking corruptions degrade performance on a variety of video
ML tasks, but effects vary by task and dataset, depending on how much temporal
context the tasks require. Lastly, we evaluate data augmentation--a standard
defense for data corruptions--but find that it does not recover performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Spatial Invariance of Convolutional Networks for Object Counting. (arXiv:2206.05253v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05253">
<div class="article-summary-box-inner">
<span><p>Previous work generally believes that improving the spatial invariance of
convolutional networks is the key to object counting. However, after verifying
several mainstream counting networks, we surprisingly found too strict
pixel-level spatial invariance would cause overfit noise in the density map
generation. In this paper, we try to use locally connected Gaussian kernels to
replace the original convolution filter to estimate the spatial position in the
density map. The purpose of this is to allow the feature extraction process to
potentially stimulate the density map generation process to overcome the
annotation noise. Inspired by previous work, we propose a low-rank
approximation accompanied with translation invariance to favorably implement
the approximation of massive Gaussian convolution. Our work points a new
direction for follow-up research, which should investigate how to properly
relax the overly strict pixel-level spatial invariance for object counting. We
evaluate our methods on 4 mainstream object counting networks (i.e., MCNN,
CSRNet, SANet, and ResNet-50). Extensive experiments were conducted on 7
popular benchmarks for 3 applications (i.e., crowd, vehicle, and plant
counting). Experimental results show that our methods significantly outperform
other state-of-the-art methods and achieve promising learning of the spatial
position of objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining Image Classifiers Using Contrastive Counterfactuals in Generative Latent Spaces. (arXiv:2206.05257v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05257">
<div class="article-summary-box-inner">
<span><p>Despite their high accuracies, modern complex image classifiers cannot be
trusted for sensitive tasks due to their unknown decision-making process and
potential biases. Counterfactual explanations are very effective in providing
transparency for these black-box algorithms. Nevertheless, generating
counterfactuals that can have a consistent impact on classifier outputs and yet
expose interpretable feature changes is a very challenging task. We introduce a
novel method to generate causal and yet interpretable counterfactual
explanations for image classifiers using pretrained generative models without
any re-training or conditioning. The generative models in this technique are
not bound to be trained on the same data as the target classifier. We use this
framework to obtain contrastive and causal sufficiency and necessity scores as
global explanations for black-box classifiers. On the task of face attribute
classification, we show how different attributes influence the classifier
output by providing both causal and contrastive feature attributions, and the
corresponding counterfactual images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Self-Supervised Learning More Robust Than Supervised Learning?. (arXiv:2206.05259v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05259">
<div class="article-summary-box-inner">
<span><p>Self-supervised contrastive learning is a powerful tool to learn visual
representation without labels. Prior work has primarily focused on evaluating
the recognition accuracy of various pre-training algorithms, but has overlooked
other behavioral aspects. In addition to accuracy, distributional robustness
plays a critical role in the reliability of machine learning models. We design
and conduct a series of robustness tests to quantify the behavioral differences
between contrastive learning and supervised learning to downstream or
pre-training data distribution changes. These tests leverage data corruptions
at multiple levels, ranging from pixel-level gamma distortion to patch-level
shuffling and to dataset-level distribution shift. Our tests unveil intriguing
robustness behaviors of contrastive and supervised learning. On the one hand,
under downstream corruptions, we generally observe that contrastive learning is
surprisingly more robust than supervised learning. On the other hand, under
pre-training corruptions, we find contrastive learning vulnerable to patch
shuffling and pixel intensity change, yet less sensitive to dataset-level
distribution change. We attempt to explain these results through the role of
data augmentation and feature space properties. Our insight has implications in
improving the downstream robustness of supervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Balanced Product of Experts for Long-Tailed Recognition. (arXiv:2206.05260v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05260">
<div class="article-summary-box-inner">
<span><p>Many real-world recognition problems suffer from an imbalanced or long-tailed
label distribution. Those distributions make representation learning more
challenging due to limited generalization over the tail classes. If the test
distribution differs from the training distribution, e.g. uniform versus
long-tailed, the problem of the distribution shift needs to be addressed. To
this aim, recent works have extended softmax cross-entropy using margin
modifications, inspired by Bayes' theorem. In this paper, we generalize several
approaches with a Balanced Product of Experts (BalPoE), which combines a family
of models with different test-time target distributions to tackle the imbalance
in the data. The proposed experts are trained in a single stage, either jointly
or independently, and fused seamlessly into a BalPoE. We show that BalPoE is
Fisher consistent for minimizing the balanced error and perform extensive
experiments to validate the effectiveness of our approach. Finally, we
investigate the effect of Mixup in this setting, discovering that
regularization is a key ingredient for learning calibrated experts. Our
experiments show that a regularized BalPoE can perform remarkably well in test
accuracy and calibration metrics, leading to state-of-the-art results on
CIFAR-100-LT, ImageNet-LT, and iNaturalist-2018 datasets. The code will be made
publicly available upon paper acceptance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Balancing for Domain Generalization. (arXiv:2206.05263v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05263">
<div class="article-summary-box-inner">
<span><p>While machine learning models rapidly advance the state-of-the-art on various
real-world tasks, out-of-domain (OOD) generalization remains a challenging
problem given the vulnerability of these models to spurious correlations. While
current domain generalization methods usually focus on enforcing certain
invariance properties across different domains by new loss function designs, we
propose a balanced mini-batch sampling strategy to reduce the domain-specific
spurious correlations in the observed training distributions. More
specifically, we propose a two-phased method that 1) identifies the source of
spurious correlations, and 2) builds balanced mini-batches free from spurious
correlations by matching on the identified source. We provide an
identifiability guarantee of the source of spuriousness and show that our
proposed approach provably samples from a balanced, spurious-free distribution
over all training environments. Experiments are conducted on three computer
vision datasets with documented spurious correlations, demonstrating
empirically that our balanced mini-batch sampling strategy improves the
performance of four different established domain generalization model baselines
compared to the random mini-batch sampling strategy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?. (arXiv:2206.05266v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05266">
<div class="article-summary-box-inner">
<span><p>We investigate whether self-supervised learning (SSL) can improve online
reinforcement learning (RL) from pixels. We extend the contrastive
reinforcement learning framework (e.g., CURL) that jointly optimizes SSL and RL
losses and conduct an extensive amount of experiments with various
self-supervised losses. Our observations suggest that the existing SSL
framework for RL fails to bring meaningful improvement over the baselines only
taking advantage of image augmentation when the same amount of data and
augmentation is used. We further perform an evolutionary search to find the
optimal combination of multiple self-supervised losses for RL, but find that
even such a loss combination fails to meaningfully outperform the methods that
only utilize carefully designed image augmentations. Often, the use of
self-supervised losses under the existing framework lowered RL performances. We
evaluate the approach in multiple different environments including a real-world
robot environment and confirm that no single self-supervised loss or image
augmentation method can dominate all environments and that the current
framework for joint optimization of SSL and RL is limited. Finally, we
empirically investigate the pretraining framework for SSL + RL and the
properties of representations learned with different approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Street Crossing Aid Using Light-weight CNNs for the Visually Impaired. (arXiv:1909.09598v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.09598">
<div class="article-summary-box-inner">
<span><p>In this paper, we address an issue that the visually impaired commonly face
while crossing intersections and propose a solution that takes form as a mobile
application. The application utilizes a deep learning convolutional neural
network model, LytNetV2, to output necessary information that the visually
impaired may lack when without human companions or guide-dogs. A prototype of
the application runs on iOS devices of versions 11 or above. It is designed for
comprehensiveness, concision, accuracy, and computational efficiency through
delivering the two most important pieces of information, pedestrian traffic
light color and direction, required to cross the road in real-time.
Furthermore, it is specifically aimed to support those facing financial burden
as the solution takes the form of a free mobile application. Through the
modification and utilization of key principles in MobileNetV3 such as depthwise
seperable convolutions and squeeze-excite layers, the deep neural network model
achieves a classification accuracy of 96% and average angle error of 6.15
degrees, while running at a frame rate of 16.34 frames per second.
Additionally, the model is trained as an image classifier, allowing for a
faster and more accurate model. The network is able to outperform other methods
such as object detection and non-deep learning algorithms in both accuracy and
thoroughness. The information is delivered through both auditory signals and
vibrations, and it has been tested on seven visually impaired and has received
above satisfactory responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toyota Smarthome Untrimmed: Real-World Untrimmed Videos for Activity Detection. (arXiv:2010.14982v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14982">
<div class="article-summary-box-inner">
<span><p>Designing activity detection systems that can be successfully deployed in
daily-living environments requires datasets that pose the challenges typical of
real-world scenarios. In this paper, we introduce a new untrimmed daily-living
dataset that features several real-world challenges: Toyota Smarthome Untrimmed
(TSU). TSU contains a wide variety of activities performed in a spontaneous
manner. The dataset contains dense annotations including elementary, composite
activities and activities involving interactions with objects. We provide an
analysis of the real-world challenges featured by our dataset, highlighting the
open issues for detection algorithms. We show that current state-of-the-art
methods fail to achieve satisfactory performance on the TSU dataset. Therefore,
we propose a new baseline method for activity detection to tackle the novel
challenges provided by our dataset. This method leverages one modality (i.e.
optic flow) to generate the attention weights to guide another modality (i.e
RGB) to better detect the activity boundaries. This is particularly beneficial
to detect activities characterized by high temporal variance. We show that the
method we propose outperforms state-of-the-art methods on TSU and on another
popular challenging dataset, Charades.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object-Region Video Transformers. (arXiv:2110.06915v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06915">
<div class="article-summary-box-inner">
<span><p>Recently, video transformers have shown great success in video understanding,
exceeding CNN performance; yet existing video transformer models do not
explicitly model objects, although objects can be essential for recognizing
actions. In this work, we present Object-Region Video Transformers (ORViT), an
\emph{object-centric} approach that extends video transformer layers with a
block that directly incorporates object representations. The key idea is to
fuse object-centric representations starting from early layers and propagate
them into the transformer-layers, thus affecting the spatio-temporal
representations throughout the network. Our ORViT block consists of two
object-level streams: appearance and dynamics. In the appearance stream, an
"Object-Region Attention" module applies self-attention over the patches and
\emph{object regions}. In this way, visual object regions interact with uniform
patch tokens and enrich them with contextualized object information. We further
model object dynamics via a separate "Object-Dynamics Module", which captures
trajectory interactions, and show how to integrate the two streams. We evaluate
our model on four tasks and five datasets: compositional and few-shot action
recognition on SomethingElse, spatio-temporal action detection on AVA, and
standard action recognition on Something-Something V2, Diving48 and
Epic-Kitchen100. We show strong performance improvement across all tasks and
datasets considered, demonstrating the value of a model that incorporates
object representations into a transformer architecture. For code and pretrained
models, visit the project page at \url{https://roeiherz.github.io/ORViT/}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grafting Transformer on Automatically Designed Convolutional Neural Network for Hyperspectral Image Classification. (arXiv:2110.11084v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11084">
<div class="article-summary-box-inner">
<span><p>Hyperspectral image (HSI) classification has been a hot topic for decides, as
hyperspectral images have rich spatial and spectral information and provide
strong basis for distinguishing different land-cover objects. Benefiting from
the development of deep learning technologies, deep learning based HSI
classification methods have achieved promising performance. Recently, several
neural architecture search (NAS) algorithms have been proposed for HSI
classification, which further improve the accuracy of HSI classification to a
new level. In this paper, NAS and Transformer are combined for handling HSI
classification task for the first time. Compared with previous work, the
proposed method has two main differences. First, we revisit the search spaces
designed in previous HSI classification NAS methods and propose a novel hybrid
search space, consisting of the space dominated cell and the spectrum dominated
cell. Compared with search spaces proposed in previous works, the proposed
hybrid search space is more aligned with the characteristic of HSI data, that
is, HSIs have a relatively low spatial resolution and an extremely high
spectral resolution. Second, to further improve the classification accuracy, we
attempt to graft the emerging transformer module on the automatically designed
convolutional neural network (CNN) to add global information to local region
focused features learned by CNN. Experimental results on three public HSI
datasets show that the proposed method achieves much better performance than
comparison approaches, including manually designed network and NAS based HSI
classification methods. Especially on the most recently captured dataset
Houston University, overall accuracy is improved by nearly 6 percentage points.
Code is available at: https://github.com/Cecilia-xue/HyT-NAS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Based Automated COVID-19 Classification from Computed Tomography Images. (arXiv:2111.11191v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11191">
<div class="article-summary-box-inner">
<span><p>The paper represents a method of a Convolution Neural Networks (CNN) model
for image classification with image preprocessing and hyperparameters tuning,
aiming at increasing the predictive performance for COVID-19 diagnosis while
avoiding deeper and thus more complex alternatives. Firstly, the CNN model
includes four similar convolutional layers followed by a flattening and two
dense layers. This work proposes a less complex solution based on simply
classifying 2D slices of CT scans using a CNN model. Despite the simplicity in
architecture, the proposed CNN model showed improved quantitative results
exceeding state-of-the-arts on the dataset of images, in terms of the macro F1
score. The results were achieved on the original CT slices of the dataset.
Secondly, the original dataset was processed via anatomy-relevant masking of
slices, removing non-representative slices from the CT volume, and
hyperparameters tuning. For slice processing, a fixed-sized rectangular area
was used for cropping an anatomy-relevant region of interest in the images, and
a threshold based on the number of white pixels in binarized slices was
employed to remove non-representative slices from the 3D-CT scans. The CNN
model with a learning rate schedule with exponential decay and slice flipping
techniques was deployed on the processed slices. The proposed method was used
to make predictions on the 2D slices. For final diagnosis at a patient level,
majority voting was applied on the slices of each CT scan to make the
diagnosis. The macro F1 score of the proposed method well exceeded the baseline
approach and other alternatives' scores on the validation set as well as on a
test partition of the previously unseen images from the COV19-CT-DB dataset
partition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for Efficient Object Detection. (arXiv:2111.13336v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13336">
<div class="article-summary-box-inner">
<span><p>In object detection, the detection backbone consumes more than half of the
overall inference cost. Recent researches attempt to reduce this cost by
optimizing the backbone architecture with the help of Neural Architecture
Search (NAS). However, existing NAS methods for object detection require
hundreds to thousands of GPU hours of searching, making them impractical in
fast-paced research and development. In this work, we propose a novel zero-shot
NAS method to address this issue. The proposed method, named MAE-DET,
automatically designs efficient detection backbones via the Maximum Entropy
Principle without training network parameters, reducing the architecture design
cost to nearly zero yet delivering the state-of-the-art (SOTA) performance.
Under the hood, MAE-DET maximizes the differential entropy of detection
backbones, leading to a better feature extractor for object detection under the
same computational budgets. After merely one GPU day of fully automatic design,
MAE-DET innovates SOTA detection backbones on multiple detection benchmark
datasets with little human intervention. Comparing to ResNet-50 backbone,
MAE-DET is $+2.0\%$ better in mAP when using the same amount of
FLOPs/parameters, and is $1.54$ times faster on NVIDIA V100 at the same mAP.
Code and pre-trained models are available at
https://github.com/alibaba/lightweight-neuralarchitecture-search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GMFlow: Learning Optical Flow via Global Matching. (arXiv:2111.13680v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13680">
<div class="article-summary-box-inner">
<span><p>Learning-based optical flow estimation has been dominated with the pipeline
of cost volume with convolutions for flow regression, which is inherently
limited to local correlations and thus is hard to address the long-standing
challenge of large displacements. To alleviate this, the state-of-the-art
framework RAFT gradually improves its prediction quality by using a large
number of iterative refinements, achieving remarkable performance but
introducing linearly increasing inference time. To enable both high accuracy
and efficiency, we completely revamp the dominant flow regression pipeline by
reformulating optical flow as a global matching problem, which identifies the
correspondences by directly comparing feature similarities. Specifically, we
propose a GMFlow framework, which consists of three main components: a
customized Transformer for feature enhancement, a correlation and softmax layer
for global feature matching, and a self-attention layer for flow propagation.
We further introduce a refinement step that reuses GMFlow at higher feature
resolution for residual flow prediction. Our new framework outperforms
31-refinements RAFT on the challenging Sintel benchmark, while using only one
refinement and running faster, suggesting a new paradigm for accurate and
efficient optical flow estimation. Code is available at
https://github.com/haofeixu/gmflow.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MC-Blur: A Comprehensive Benchmark for Image Deblurring. (arXiv:2112.00234v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00234">
<div class="article-summary-box-inner">
<span><p>Blur artifacts can seriously degrade the visual quality of images, and
numerous deblurring methods have been proposed for specific scenarios. However,
in most real-world images, blur is caused by different factors, e.g., motion
and defocus. In this paper, we address how different deblurring methods perform
in the case of multiple types of blur. For in-depth performance evaluation, we
construct a new large-scale multi-cause image deblurring dataset (called
MC-Blur), including real-world and synthesized blurry images with mixed factors
of blurs. The images in the proposed MC-Blur dataset are collected using
different techniques: averaging sharp images captured by a 1000-fps high-speed
camera, convolving Ultra-High-Definition (UHD) sharp images with large-size
kernels, adding defocus to images, and real-world blurry images captured by
various camera models. Based on the MC-Blur dataset, we conduct extensive
benchmarking studies to compare SOTA methods in different scenarios, analyze
their efficiency, and investigate the built dataset's capacity. These
benchmarking results provide a comprehensive overview of the advantages and
limitations of current deblurring methods, and reveal the advances of our
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lumbar Bone Mineral Density Estimation from Chest X-ray Images: Anatomy-aware Attentive Multi-ROI Modeling. (arXiv:2201.01838v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01838">
<div class="article-summary-box-inner">
<span><p>Osteoporosis is a common chronic metabolic bone disease often under-diagnosed
and under-treated due to the limited access to bone mineral density (BMD)
examinations, e.g. via Dual-energy X-ray Absorptiometry (DXA). This paper
proposes a method to predict BMD from Chest X-ray (CXR), one of the most
commonly accessible and low-cost medical imaging examinations. Our method first
automatically detects Regions of Interest (ROIs) of local CXR bone structures.
Then a multi-ROI deep model with transformer encoder is developed to exploit
both local and global information in the chest X-ray image for accurate BMD
estimation. Our method is evaluated on 13719 CXR patient cases with ground
truth BMD measured by the gold standard DXA. The model predicted BMD has a
strong correlation with the ground truth (Pearson correlation coefficient 0.894
on lumbar 1). When applied in osteoporosis screening, it achieves a high
classification performance (average AUC of 0.968). As the first effort of using
CXR scans to predict the BMD, the proposed algorithm holds strong potential for
early osteoporosis screening and public health promotion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Head and eye egocentric gesture recognition for human-robot interaction using eyewear cameras. (arXiv:2201.11500v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11500">
<div class="article-summary-box-inner">
<span><p>Non-verbal communication plays a particularly important role in a wide range
of scenarios in Human-Robot Interaction (HRI). Accordingly, this work addresses
the problem of human gesture recognition. In particular, we focus on head and
eye gestures, and adopt an egocentric (first-person) perspective using eyewear
cameras. We argue that this egocentric view may offer a number of conceptual
and technical benefits over scene- or robot-centric perspectives. A
motion-based recognition approach is proposed, which operates at two temporal
granularities. Locally, frame-to-frame homographies are estimated with a
convolutional neural network (CNN). The output of this CNN is input to a long
short-term memory (LSTM) to capture longer-term temporal visual relationships,
which are relevant to characterize gestures. Regarding the configuration of the
network architecture, one particularly interesting finding is that using the
output of an internal layer of the homography CNN increases the recognition
rate with respect to using the homography matrix itself. While this work
focuses on action recognition, and no robot or user study has been conducted
yet, the system has been designed to meet real-time constraints. The
encouraging results suggest that the proposed egocentric perspective is viable,
and this proof-of-concept work provides novel and useful contributions to the
exciting area of HRI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Step at a Time: Long-Horizon Vision-and-Language Navigation with Milestones. (arXiv:2202.07028v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07028">
<div class="article-summary-box-inner">
<span><p>We study the problem of developing autonomous agents that can follow human
instructions to infer and perform a sequence of actions to complete the
underlying task. Significant progress has been made in recent years, especially
for tasks with short horizons. However, when it comes to long-horizon tasks
with extended sequences of actions, an agent can easily ignore some
instructions or get stuck in the middle of the long instructions and eventually
fail the task. To address this challenge, we propose a model-agnostic
milestone-based task tracker (M-TRACK) to guide the agent and monitor its
progress. Specifically, we propose a milestone builder that tags the
instructions with navigation and interaction milestones which the agent needs
to complete step by step, and a milestone checker that systemically checks the
agent's progress in its current milestone and determines when to proceed to the
next. On the challenging ALFRED dataset, our M-TRACK leads to a notable 33% and
52% relative improvement in unseen success rate over two competitive base
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image translation of Ultrasound to Pseudo Anatomical Display by CycleGAN. (arXiv:2202.08053v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08053">
<div class="article-summary-box-inner">
<span><p>Ultrasound is the second most used modality in medical imaging. It is cost
effective, hazardless, portable and implemented routinely in numerous clinical
procedures. Nonetheless, image quality is characterized by granulated
appearance, poor SNR and speckle noise. Specific for malignant tumors, the
margins are blurred and indistinct. Thus, there is a great need for improving
ultrasound image quality. We hypothesize that this can be achieved, using
neural networks, by translation into a more realistic display which mimics an
anatomical cut through the tissue. In order to achieve this goal, the
preferable approach would be to use a set of paired images. However, this is
practically impossible in our case. Therefore, Cycle Generative Adversarial
Network (CycleGAN) was used, in order to learn each domain properties
separately and enforce cross domain cycle consistency. The two datasets which
were used for training the model were "Breast Ultrasound Images" (BUSI) and a
set of optic images of poultry breast tissue samples acquired at our lab. The
generated pseudo anatomical images provide improved visual discrimination of
the lesions with clearer border definition and pronounced contrast. In order to
evaluate the preservation of the anatomical features, the lesions in the
ultrasonic images and the generated pseudo anatomical images were both
automatically segmented and compared. This comparison yielded median dice score
of 0.91 for the benign tumors and 0.70 for the malignant ones. The median
lesion center error was 0.58% and 3.27% for the benign and malignancies
respectively and the median area error index was 0.40% and 4.34% for the benign
and malignancies respectively. In conclusion, these generated pseudo anatomical
images, which are presented in a more intuitive way, enhance tissue anatomy and
can potentially simplify the diagnosis and improve the clinical outcome.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Do You Do It? Fine-Grained Action Understanding with Pseudo-Adverbs. (arXiv:2203.12344v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12344">
<div class="article-summary-box-inner">
<span><p>We aim to understand how actions are performed and identify subtle
differences, such as 'fold firmly' vs. 'fold gently'. To this end, we propose a
method which recognizes adverbs across different actions. However, such
fine-grained annotations are difficult to obtain and their long-tailed nature
makes it challenging to recognize adverbs in rare action-adverb compositions.
Our approach therefore uses semi-supervised learning with multiple adverb
pseudo-labels to leverage videos with only action labels. Combined with
adaptive thresholding of these pseudo-adverbs we are able to make efficient use
of the available data while tackling the long-tailed distribution.
Additionally, we gather adverb annotations for three existing video retrieval
datasets, which allows us to introduce the new tasks of recognizing adverbs in
unseen action-adverb compositions and unseen domains. Experiments demonstrate
the effectiveness of our method, which outperforms prior work in recognizing
adverbs and semi-supervised works adapted for adverb recognition. We also show
how adverbs can relate fine-grained actions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Plain Vision Transformer Backbones for Object Detection. (arXiv:2203.16527v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16527">
<div class="article-summary-box-inner">
<span><p>We explore the plain, non-hierarchical Vision Transformer (ViT) as a backbone
network for object detection. This design enables the original ViT architecture
to be fine-tuned for object detection without needing to redesign a
hierarchical backbone for pre-training. With minimal adaptations for
fine-tuning, our plain-backbone detector can achieve competitive results.
Surprisingly, we observe: (i) it is sufficient to build a simple feature
pyramid from a single-scale feature map (without the common FPN design) and
(ii) it is sufficient to use window attention (without shifting) aided with
very few cross-window propagation blocks. With plain ViT backbones pre-trained
as Masked Autoencoders (MAE), our detector, named ViTDet, can compete with the
previous leading methods that were all based on hierarchical backbones,
reaching up to 61.3 AP_box on the COCO dataset using only ImageNet-1K
pre-training. We hope our study will draw attention to research on
plain-backbone detectors. Code for ViTDet is available in Detectron2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Convolutional Neural Networks on Raspberry Pi for Image Classification. (arXiv:2204.00943v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.00943">
<div class="article-summary-box-inner">
<span><p>With the good performance of deep learning algorithms in the field of
computer vision (CV), the convolutional neural network (CNN) architecture has
become a main backbone of the computer vision task. With the widespread use of
mobile devices, neural network models based on platforms with low computing
power are gradually being paid attention. However, due to the limitation of
computing power, deep learning algorithms are usually not available on mobile
devices. This paper proposes a lightweight convolutional neural network,
TripleNet, which can operate easily on Raspberry Pi. Adopted from the concept
of block connections in ThreshNet, the newly proposed network model compresses
and accelerates the network model, reduces the amount of parameters of the
network, and shortens the inference time of each image while ensuring the
accuracy. Our proposed TripleNet and other state-of-the-art (SOTA) neural
networks perform image classification experiments with the CIFAR-10 and SVHN
datasets on Raspberry Pi. The experimental results show that, compared with
GhostNet, MobileNet, ThreshNet, EfficientNet, and HarDNet, the inference time
of TripleNet per image is shortened by 15%, 16%, 17%, 24%, and 30%,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The 6th AI City Challenge. (arXiv:2204.10380v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10380">
<div class="article-summary-box-inner">
<span><p>The 6th edition of the AI City Challenge specifically focuses on problems in
two domains where there is tremendous unlocked potential at the intersection of
computer vision and artificial intelligence: Intelligent Traffic Systems (ITS),
and brick and mortar retail businesses. The four challenge tracks of the 2022
AI City Challenge received participation requests from 254 teams across 27
countries. Track 1 addressed city-scale multi-target multi-camera (MTMC)
vehicle tracking. Track 2 addressed natural-language-based vehicle track
retrieval. Track 3 was a brand new track for naturalistic driving analysis,
where the data were captured by several cameras mounted inside the vehicle
focusing on driver safety, and the task was to classify driver actions. Track 4
was another new track aiming to achieve retail store automated checkout using
only a single view camera. We released two leader boards for submissions based
on different methods, including a public leader board for the contest, where no
use of external data is allowed, and a general leader board for all submitted
results. The top performance of participating teams established strong
baselines and even outperformed the state-of-the-art in the proposed challenge
tracks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Supervised Distillation for Continual Representation Learning. (arXiv:2205.05476v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05476">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel training procedure for the continual
representation learning problem in which a neural network model is sequentially
learned to alleviate catastrophic forgetting in visual search tasks. Our
method, called Contrastive Supervised Distillation (CSD), reduces feature
forgetting while learning discriminative features. This is achieved by
leveraging labels information in a distillation setting in which the student
model is contrastively learned from the teacher model. Extensive experiments
show that CSD performs favorably in mitigating catastrophic forgetting by
outperforming current state-of-the-art methods. Our results also provide
further evidence that feature forgetting evaluated in visual retrieval tasks is
not as catastrophic as in classification tasks. Code at:
https://github.com/NiccoBiondi/ContrastiveSupervisedDistillation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods. (arXiv:2205.11508v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11508">
<div class="article-summary-box-inner">
<span><p>Self-Supervised Learning (SSL) surmises that inputs and pairwise positive
relationships are enough to learn meaningful representations. Although SSL has
recently reached a milestone: outperforming supervised methods in many
modalities\dots the theoretical foundations are limited, method-specific, and
fail to provide principled design guidelines to practitioners. In this paper,
we propose a unifying framework under the helm of spectral manifold learning to
address those limitations. Through the course of this study, we will rigorously
demonstrate that VICReg, SimCLR, BarlowTwins et al. correspond to eponymous
spectral methods such as Laplacian Eigenmaps, Multidimensional Scaling et al.
</p>
<p>This unification will then allow us to obtain (i) the closed-form optimal
representation for each method, (ii) the closed-form optimal network parameters
in the linear regime for each method, (iii) the impact of the pairwise
relations used during training on each of those quantities and on downstream
task performances, and most importantly, (iv) the first theoretical bridge
between contrastive and non-contrastive methods towards global and local
spectral embedding methods respectively, hinting at the benefits and
limitations of each. For example, (i) if the pairwise relation is aligned with
the downstream task, any SSL method can be employed successfully and will
recover the supervised method, but in the low data regime, VICReg's invariance
hyper-parameter should be high; (ii) if the pairwise relation is misaligned
with the downstream task, VICReg with small invariance hyper-parameter should
be preferred over SimCLR or BarlowTwins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Model Generalization for Monocular 3D Object Detection. (arXiv:2205.11664v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11664">
<div class="article-summary-box-inner">
<span><p>Monocular 3D object detection (Mono3D) has achieved tremendous improvements
with emerging large-scale autonomous driving datasets and the rapid development
of deep learning techniques. However, caused by severe domain gaps (e.g., the
field of view (FOV), pixel size, and object size among datasets), Mono3D
detectors have difficulty in generalization, leading to drastic performance
degradation on unseen domains. To solve these issues, we combine the
position-invariant transform and multi-scale training with the pixel-size depth
strategy to construct an effective unified camera-generalized paradigm (CGP).
It fully considers discrepancies in the FOV and pixel size of images captured
by different cameras. Moreover, we further investigate the obstacle in
quantitative metrics when cross-dataset inference through an exhaustive
systematic study. We discern that the size bias of prediction leads to a
colossal failure. Hence, we propose the 2D-3D geometry-consistent object
scaling strategy (GCOS) to bridge the gap via an instance-level augment. Our
method called DGMono3D achieves remarkable performance on all evaluated
datasets and surpasses the SoTA unsupervised domain adaptation scheme even
without utilizing data on the target domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DGSVis: Visual Analysis of Hierarchical Snapshots in Dynamic Graph. (arXiv:2205.13220v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.13220">
<div class="article-summary-box-inner">
<span><p>Dynamic graph visualization attracts researchers' concentration as it
represents time-varying relationships between entities in multiple domains
(e.g., social media analysis, academic cooperation analysis, team sports
analysis). Integrating visual analytic methods is consequential in presenting,
comparing, and reviewing dynamic graphs. Even though dynamic graph
visualization is developed for many years, how to effectively visualize
large-scale and time-intensive dynamic graph data with subtle changes is still
challenging for researchers. To provide an effective analysis method for this
type of dynamic graph data, we propose a snapshot generation algorithm
involving Human-In-Loop to help users divide the dynamic graphs into
multi-granularity and hierarchical snapshots for further analysis. In addition,
we design a visual analysis prototype system (DGSVis) to assist users in
accessing the dynamic graph insights effectively. DGSVis integrates a graphical
operation interface to help users generate snapshots visually and
interactively. It is equipped with the overview and details for visualizing
hierarchical snapshots of the dynamic graph data. To illustrate the usability
and efficiency of our proposed methods for this type of dynamic graph data, we
introduce two case studies based on basketball player networks in a
competition. In addition, we conduct an evaluation and receive exciting
feedback from experienced visualization experts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Illumination Adaptive Transformer. (arXiv:2205.14871v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14871">
<div class="article-summary-box-inner">
<span><p>Challenging illumination conditions (low light, underexposure and
overexposure) in the real world not only cast an unpleasant visual appearance
but also taint the computer vision tasks. Existing light adaptive methods often
deal with each condition individually. What is more, most of them often operate
on a RAW image or over-simplify the camera image signal processing (ISP)
pipeline. By decomposing the light transformation pipeline into local and
global ISP components, we propose a lightweight fast Illumination Adaptive
Transformer (IAT) which comprises two transformer-style branches: local
estimation branch and global ISP branch. While the local branch estimates the
pixel-wise local components relevant to illumination, the global branch defines
learnable quires that attend the whole image to decode the parameters. Our IAT
could also conduct both object detection and semantic segmentation under
various light conditions. We have extensively evaluated IAT on multiple
real-world datasets on 2 low-level tasks and 3 high-level tasks. With only 90k
parameters and 0.004s processing speed (excluding high-level module), our IAT
has consistently achieved superior performance over SOTA. Code is available at
https://github.com/cuiziteng/Illumination-Adaptive-Transformer
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CompleteDT: Point Cloud Completion with Dense Augment Inference Transformers. (arXiv:2205.14999v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14999">
<div class="article-summary-box-inner">
<span><p>Point cloud completion task aims to predict the missing part of incomplete
point clouds and generate complete point clouds with details. In this paper, we
propose a novel point cloud completion network, namely CompleteDT.
Specifically, features are learned from point clouds with different
resolutions, which is sampled from the incomplete input, and are converted to a
series of \textit{spots} based on the geometrical structure. Then, the Dense
Relation Augment Module (DRA) based on the transformer is proposed to learn
features within \textit{spots} and consider the correlation among these
\textit{spots}. The DRA consists of Point Local-Attention Module (PLA) and
Point Dense Multi-Scale Attention Module (PDMA), where the PLA captures the
local information within the local \textit{spots} by adaptively measuring
weights of neighbors and the PDMA exploits the global relationship between
these \textit{spots} in a multi-scale densely connected manner. Lastly, the
complete shape is predicted from \textit{spots} by the Multi-resolution Point
Fusion Module (MPF), which gradually generates complete point clouds from
\textit{spots}, and updates \textit{spots} based on these generated point
clouds. Experimental results show that, because the DRA based on the
transformer can learn the expressive features from the incomplete input and the
MPF can fully explore these feature to predict the complete input, our method
largely outperforms the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">xView3-SAR: Detecting Dark Fishing Activity Using Synthetic Aperture Radar Imagery. (arXiv:2206.00897v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.00897">
<div class="article-summary-box-inner">
<span><p>Unsustainable fishing practices worldwide pose a major threat to marine
resources and ecosystems. Identifying vessels that evade monitoring systems --
known as "dark vessels" -- is key to managing and securing the health of marine
environments. With the rise of satellite-based synthetic aperture radar (SAR)
imaging and modern machine learning (ML), it is now possible to automate
detection of dark vessels day or night, under all-weather conditions. SAR
images, however, require domain-specific treatment and is not widely accessible
to the ML community. Moreover, the objects (vessels) are small and sparse,
challenging traditional computer vision approaches. We present the largest
labeled dataset for training ML models to detect and characterize vessels from
SAR. xView3-SAR consists of nearly 1,000 analysis-ready SAR images from the
Sentinel-1 mission that are, on average, 29,400-by-24,400 pixels each. The
images are annotated using a combination of automated and manual analysis.
Co-located bathymetry and wind state rasters accompany every SAR image. We
provide an overview of the results from the xView3 Computer Vision Challenge,
an international competition using xView3-SAR for ship detection and
characterization at large scale. We release the data (https://iuu.xview.us/)
and code (https://github.com/DIUx-xView) to support ongoing development and
evaluation of ML approaches for this important application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images. (arXiv:2206.01256v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01256">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose PETRv2, a unified framework for 3D perception from
multi-view images. Based on PETR, PETRv2 explores the effectiveness of temporal
modeling, which utilizes the temporal information of previous frames to boost
3D object detection. More specifically, we extend the 3D position embedding (3D
PE) in PETR for temporal modeling. The 3D PE achieves the temporal alignment on
object position of different frames. A feature-guided position encoder is
further introduced to improve the data adaptability of 3D PE. To support for
high-quality BEV segmentation, PETRv2 provides a simply yet effective solution
by adding a set of segmentation queries. Each segmentation query is responsible
for segmenting one specific patch of BEV map. PETRv2 achieves state-of-the-art
performance on 3D object detection and BEV segmentation. Detailed robustness
analysis is also conducted on PETR framework. We hope PETRv2 can serve as a
strong baseline for 3D perception. Code is available at
\url{https://github.com/megvii-research/PETR}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PIDNet: A Real-time Semantic Segmentation Network Inspired from PID Controller. (arXiv:2206.02066v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02066">
<div class="article-summary-box-inner">
<span><p>Two-branch network architecture has shown its efficiency and effectiveness
for real-time semantic segmentation tasks. However, direct fusion of low-level
details and high-level semantics will lead to a phenomenon that the detailed
features are easily overwhelmed by surrounding contextual information, namely
overshoot in this paper, which limits the improvement of the accuracy of
existed two-branch models. In this paper, we bridge a connection between
Convolutional Neural Network (CNN) and Proportional-Integral-Derivative (PID)
controller and reveal that the two-branch network is nothing but a
Proportional-Integral (PI) controller, which inherently suffers from the
similar overshoot issue. To alleviate this issue, we propose a novel
three-branch network architecture: PIDNet, which possesses three branches to
parse the detailed, context and boundary information (derivative of semantics),
respectively, and employs boundary attention to guide the fusion of detailed
and context branches in final stage. The family of PIDNets achieve the best
trade-off between inference speed and accuracy and their test accuracy
surpasses all the existed models with similar inference speed on Cityscapes,
CamVid and COCO-Stuff datasets. Especially, PIDNet-S achieves 78.6% mIOU with
inference speed of 93.2 FPS on Cityscapes test set and 80.1% mIOU with speed of
153.7 FPS on CamVid test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Understanding Why Mask-Reconstruction Pretraining Helps in Downstream Tasks. (arXiv:2206.03826v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03826">
<div class="article-summary-box-inner">
<span><p>For unsupervised pretraining, mask-reconstruction pretraining (MRP)
approaches randomly mask input patches and then reconstruct pixels or semantic
features of these masked patches via an auto-encoder. Then for a downstream
task, supervised fine-tuning the pretrained encoder remarkably surpasses the
conventional supervised learning (SL) trained from scratch. However, it is
still unclear 1) how MRP performs semantic learning in the pretraining phase
and 2) why it helps in downstream tasks. To solve these problems, we
theoretically show that on an auto-encoder of a two/one-layered convolution
encoder/decoder, MRP can capture all discriminative semantics in the
pretraining dataset, and accordingly show its provable improvement over SL on
the classification downstream task. Specifically, we assume that pretraining
dataset contains multi-view samples of ratio $1-\mu$ and single-view samples of
ratio $\mu$, where multi/single-view samples has multiple/single discriminative
semantics. Then for pretraining, we prove that 1) the convolution kernels of
the MRP encoder captures all discriminative semantics in the pretraining data;
and 2) a convolution kernel captures at most one semantic. Accordingly, in the
downstream supervised fine-tuning, most semantics would be captured and
different semantics would not be fused together. This helps the downstream
fine-tuned network to easily establish the relation between kernels and
semantic class labels. In this way, the fine-tuned encoder in MRP provably
achieves zero test error with high probability for both multi-view and
single-view test data. In contrast, as proved by~[3], conventional SL can only
obtain a test accuracy between around $0.5\mu$ for single-view test data. These
results together explain the benefits of MRP in downstream tasks. Experimental
results testify to multi-view data assumptions and our theoretical
implications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Narrowing the Coordinate-frame Gap in Behavior Prediction Models: Distillation for Efficient and Accurate Scene-centric Motion Forecasting. (arXiv:2206.03970v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03970">
<div class="article-summary-box-inner">
<span><p>Behavior prediction models have proliferated in recent years, especially in
the popular real-world robotics application of autonomous driving, where
representing the distribution over possible futures of moving agents is
essential for safe and comfortable motion planning. In these models, the choice
of coordinate frames to represent inputs and outputs has crucial trade offs
which broadly fall into one of two categories. Agent-centric models transform
inputs and perform inference in agent-centric coordinates. These models are
intrinsically invariant to translation and rotation between scene elements, are
best-performing on public leaderboards, but scale quadratically with the number
of agents and scene elements. Scene-centric models use a fixed coordinate
system to process all agents. This gives them the advantage of sharing
representations among all agents, offering efficient amortized inference
computation which scales linearly with the number of agents. However, these
models have to learn invariance to translation and rotation between scene
elements, and typically underperform agent-centric models. In this work, we
develop knowledge distillation techniques between probabilistic motion
forecasting models, and apply these techniques to close the gap in performance
between agent-centric and scene-centric models. This improves scene-centric
model performance by 13.2% on the public Argoverse benchmark, 7.8% on Waymo
Open Dataset and up to 9.4% on a large In-House dataset. These improved
scene-centric models rank highly in public leaderboards and are up to 15 times
more efficient than their agent-centric teacher counterparts in busy scenes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerating Score-based Generative Models for High-Resolution Image Synthesis. (arXiv:2206.04029v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04029">
<div class="article-summary-box-inner">
<span><p>Score-based generative models (SGMs) have recently emerged as a promising
class of generative models. The key idea is to produce high-quality images by
recurrently adding Gaussian noises and gradients to a Gaussian sample until
converging to the target distribution, a.k.a. the diffusion sampling. To ensure
stability of convergence in sampling and generation quality, however, this
sequential sampling process has to take a small step size and many sampling
iterations (e.g., 2000). Several acceleration methods have been proposed with
focus on low-resolution generation. In this work, we consider the acceleration
of high-resolution generation with SGMs, a more challenging yet more important
problem. We prove theoretically that this slow convergence drawback is
primarily due to the ignorance of the target distribution. Further, we
introduce a novel Target Distribution Aware Sampling (TDAS) method by
leveraging the structural priors in space and frequency domains. Extensive
experiments on CIFAR-10, CelebA, LSUN, and FFHQ datasets validate that TDAS can
consistently accelerate state-of-the-art SGMs, particularly on more challenging
high resolution (1024x1024) image generation tasks by up to 18.4x, whilst
largely maintaining the synthesis quality. With fewer sampling iterations, TDAS
can still generate good quality images. In contrast, the existing methods
degrade drastically or even fails completely
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04170">
<div class="article-summary-box-inner">
<span><p>Recent advances in Deep Learning and Computer Vision have alleviated many of
the bottlenecks, allowing algorithms to be label-free with better performance.
Specifically, Transformers provide a global perspective of the image, which
Convolutional Neural Networks (CNN) lack by design. Here we present Cross
Architectural Self-Supervision, a novel self-supervised learning approach which
leverages transformers and CNN simultaneously, while also being computationally
accessible to general practitioners via easily available cloud services.
Compared to existing state-of-the-art self-supervised learning approaches, we
empirically show CASS trained CNNs, and Transformers gained an average of 8.5%
with 100% labelled data, 7.3% with 10% labelled data, and 11.5% with 1%
labelled data, across three diverse datasets. Notably, one of the employed
datasets included histopathology slides of an autoimmune disease, a topic
underrepresented in Medical Imaging and has minimal data. In addition, our
findings reveal that CASS is twice as efficient as other state-of-the-art
methods in terms of training time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple Cues Lead to a Strong Multi-Object Tracker. (arXiv:2206.04656v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04656">
<div class="article-summary-box-inner">
<span><p>For a long time, the most common paradigm in Multi-Object Tracking was
tracking-by-detection (TbD), where objects are first detected and then
associated over video frames. For association, most models resource to motion
and appearance cues. While still relying on these cues, recent approaches based
on, e.g., attention have shown an ever-increasing need for training data and
overall complex frameworks. We claim that 1) strong cues can be obtained from
little amounts of training data if some key design choices are applied, 2)
given these strong cues, standard Hungarian matching-based association is
enough to obtain impressive results. Our main insight is to identify key
components that allow a standard reidentification network to excel at
appearance-based tracking. We extensively analyze its failure cases and show
that a combination of our appearance features with a simple motion model leads
to strong tracking results. Our model achieves state-of-the-art performance on
MOT17 and MOT20 datasets outperforming previous state-of-the-art trackers by up
to 5.4pp in IDF1 and 4.4pp in HOTA. We will release the code and models after
the paper's acceptance.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-06-13 23:08:28.230276380 UTC">2022-06-13 23:08:28 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>