<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-01-17T01:30:00Z">01-17</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">The Combinatorics of \textit{Salva Veritate} Principles. (arXiv:2201.05173v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05173">
<div class="article-summary-box-inner">
<span><p>Various concepts of grammatical compositionality arise in many theories of
both natural and artificial languages, and often play a key role in accounts of
the syntax-semantics interface. We propose that many instances of
compositionality should entail non-trivial combinatorial claims about the
expressive power of languages which satisfy these compositional properties. As
an example, we present a formal analysis demonstrating that a particular class
of languages which admit salva vertitate substitutions - a property which we
claim to be a particularly strong example of compositional principle - must
also satisfy a very natural combinatorial constraint identified in this paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Approaches to Conversational Information Retrieval. (arXiv:2201.05176v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05176">
<div class="article-summary-box-inner">
<span><p>A conversational information retrieval (CIR) system is an information
retrieval (IR) system with a conversational interface which allows users to
interact with the system to seek information via multi-turn conversations of
natural language, in spoken or written form. Recent progress in deep learning
has brought tremendous improvements in natural language processing (NLP) and
conversational AI, leading to a plethora of commercial conversational services
that allow naturally spoken and typed interaction, increasing the need for more
human-centric interactions in IR. As a result, we have witnessed a resurgent
interest in developing modern CIR systems in both research communities and
industry. This book surveys recent advances in CIR, focusing on neural
approaches that have been developed in the last few years. This book is based
on the authors' tutorial at SIGIR'2020 (Gao et al., 2020b), with IR and NLP
communities as the primary target audience. However, audiences with other
background, such as machine learning and human-computer interaction, will also
find it an accessible introduction to CIR. We hope that this book will prove a
valuable resource for students, researchers, and software developers. This
manuscript is a working draft. Comments are welcome.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making a (Counterfactual) Difference One Rationale at a Time. (arXiv:2201.05177v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05177">
<div class="article-summary-box-inner">
<span><p>Rationales, snippets of extracted text that explain an inference, have
emerged as a popular framework for interpretable natural language processing
(NLP). Rationale models typically consist of two cooperating modules: a
selector and a classifier with the goal of maximizing the mutual information
(MMI) between the "selected" text and the document label. Despite their
promises, MMI-based methods often pick up on spurious text patterns and result
in models with nonsensical behaviors. In this work, we investigate whether
counterfactual data augmentation (CDA), without human assistance, can improve
the performance of the selector by lowering the mutual information between
spurious signals and the document label. Our counterfactuals are produced in an
unsupervised fashion using class-dependent generative models. From an
information theoretic lens, we derive properties of the unaugmented dataset for
which our CDA approach would succeed. The effectiveness of CDA is empirically
evaluated by comparing against several baselines including an improved
MMI-based rationale schema on two multi aspect datasets. Our results show that
CDA produces rationales that better capture the signal of interest.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NLP in Human Rights Research -- Extracting Knowledge Graphs About Police and Army Units and Their Commanders. (arXiv:2201.05230v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05230">
<div class="article-summary-box-inner">
<span><p>In this working paper we explore the use of an NLP system to assist the work
of Security Force Monitor (SFM). SFM creates data about the organizational
structure, command personnel and operations of police, army and other security
forces, which assists human rights researchers, journalists and litigators in
their work to help identify and bring to account specific units and personnel
alleged to have committed abuses of human rights and international criminal
law. This working paper presents an NLP system that extracts from English
language news reports the names of security force units and the biographical
details of their personnel, and infers the formal relationship between them.
Published alongside this working paper are the system's code and training
dataset. We find that the experimental NLP system performs the task at a fair
to good level. Its performance is sufficient to justify further development
into a live workflow that will give insight into whether its performance
translates into savings in time and resource that would make it an effective
technical intervention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimal alphabet for single text compression. (arXiv:2201.05234v1 [cs.IT])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05234">
<div class="article-summary-box-inner">
<span><p>A text can be viewed via different representations, i.e. as a sequence of
letters, n-grams of letters, syllables, words, and phrases. Here we study the
optimal noiseless compression of texts using the Huffman code, where the
alphabet of encoding coincides with one of those representations. We show that
it is necessary to account for the codebook when compressing a single text.
Hence, the total compression comprises of the optimally compressed text --
characterized by the entropy of the alphabet elements -- and the codebook which
is text-specific and therefore has to be included for noiseless
(de)compression. For texts of Project Gutenberg the best compression is
provided by syllables, i.e. the minimal meaning-expressing element of the
language. If only sufficiently short texts are retained, the optimal alphabet
is that of letters or 2-grams of letters depending on the retained length.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Pretrained Language Models Based Text Generation. (arXiv:2201.05273v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05273">
<div class="article-summary-box-inner">
<span><p>Text Generation aims to produce plausible and readable text in human language
from input data. The resurgence of deep learning has greatly advanced this
field by neural generation models, especially the paradigm of pretrained
language models (PLMs). Grounding text generation on PLMs is seen as a
promising direction in both academia and industry. In this survey, we present
the recent advances achieved in the topic of PLMs for text generation. In
detail, we begin with introducing three key points of applying PLMs to text
generation: 1) how to encode the input data as representations preserving input
semantics which can be fused into PLMs; 2) how to design a universal and
performant architecture of PLMs served as generation models; and 3) how to
optimize PLMs given the reference text and ensure the generated text satisfying
special text properties. Then, we figure out several challenges and future
directions within each key point. Next, we present a summary of various useful
resources and typical text generation applications to work with PLMs. Finally,
we conclude and summarize the contribution of this survey.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Narrative Semantic Overlap Task: Evaluation and Benchmark. (arXiv:2201.05294v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05294">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce an important yet relatively unexplored NLP task
called Multi-Narrative Semantic Overlap (MNSO), which entails generating a
Semantic Overlap of multiple alternate narratives. As no benchmark dataset is
readily available for this task, we created one by crawling 2,925 narrative
pairs from the web and then, went through the tedious process of manually
creating 411 different ground-truth semantic overlaps by engaging human
annotators. As a way to evaluate this novel task, we first conducted a
systematic study by borrowing the popular ROUGE metric from text-summarization
literature and discovered that ROUGE is not suitable for our task.
Subsequently, we conducted further human annotations/validations to create 200
document-level and 1,518 sentence-level ground-truth labels which helped us
formulate a new precision-recall style evaluation metric, called SEM-F1
(semantic F1). Experimental results show that the proposed SEM-F1 metric yields
higher correlation with human judgement as well as higher inter-rater-agreement
compared to ROUGE metric.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Thousand Words Are Worth More Than a Picture: Natural Language-Centric Outside-Knowledge Visual Question Answering. (arXiv:2201.05299v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05299">
<div class="article-summary-box-inner">
<span><p>Outside-knowledge visual question answering (OK-VQA) requires the agent to
comprehend the image, make use of relevant knowledge from the entire web, and
digest all the information to answer the question. Most previous works address
the problem by first fusing the image and question in the multi-modal space,
which is inflexible for further fusion with a vast amount of external
knowledge. In this paper, we call for a paradigm shift for the OK-VQA task,
which transforms the image into plain text, so that we can enable knowledge
passage retrieval, and generative question-answering in the natural language
space. This paradigm takes advantage of the sheer volume of gigantic knowledge
bases and the richness of pre-trained language models. A
Transform-Retrieve-Generate framework (TRiG) framework is proposed, which can
be plug-and-played with alternative image-to-text models and textual knowledge
bases. Experimental results show that our TRiG framework outperforms all
state-of-the-art supervised methods by at least 11.1% absolute margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Applying a Generic Sequence-to-Sequence Model for Simple and Effective Keyphrase Generation. (arXiv:2201.05302v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05302">
<div class="article-summary-box-inner">
<span><p>In recent years, a number of keyphrase generation (KPG) approaches were
proposed consisting of complex model architectures, dedicated training
paradigms and decoding strategies. In this work, we opt for simplicity and show
how a commonly used seq2seq language model, BART, can be easily adapted to
generate keyphrases from the text in a single batch computation using a simple
training procedure. Empirical results on five benchmarks show that our approach
is as good as the existing state-of-the-art KPG systems, but using a much
simpler and easy to deploy framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ExtraPhrase: Efficient Data Augmentation for Abstractive Summarization. (arXiv:2201.05313v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05313">
<div class="article-summary-box-inner">
<span><p>Neural models trained with large amount of parallel data have achieved
impressive performance in abstractive summarization tasks. However, large-scale
parallel corpora are expensive and challenging to construct. In this work, we
introduce a low-cost and effective strategy, ExtraPhrase, to augment training
data for abstractive summarization tasks. ExtraPhrase constructs pseudo
training data in two steps: extractive summarization and paraphrasing. We
extract major parts of an input text in the extractive summarization step, and
obtain its diverse expressions with the paraphrasing step. Through experiments,
we show that ExtraPhrase improves the performance of abstractive summarization
tasks by more than 0.50 points in ROUGE scores compared to the setting without
data augmentation. ExtraPhrase also outperforms existing methods such as
back-translation and self-training. We also show that ExtraPhrase is
significantly effective when the amount of genuine training data is remarkably
small, i.e., a low-resource setting. Moreover, ExtraPhrase is more
cost-efficient than the existing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CommonsenseQA 2.0: Exposing the Limits of AI through Gamification. (arXiv:2201.05320v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05320">
<div class="article-summary-box-inner">
<span><p>Constructing benchmarks that test the abilities of modern natural language
understanding models is difficult - pre-trained language models exploit
artifacts in benchmarks to achieve human parity, but still fail on adversarial
examples and make errors that demonstrate a lack of common sense. In this work,
we propose gamification as a framework for data construction. The goal of
players in the game is to compose questions that mislead a rival AI while using
specific phrases for extra points. The game environment leads to enhanced user
engagement and simultaneously gives the game designer control over the
collected data, allowing us to collect high-quality data at scale. Using our
method we create CommonsenseQA 2.0, which includes 14,343 yes/no questions, and
demonstrate its difficulty for models that are orders-of-magnitude larger than
the AI used in the game itself. Our best baseline, the T5-based Unicorn with
11B parameters achieves an accuracy of 70.2%, substantially higher than GPT-3
(52.9%) in a few-shot inference setup. Both score well below human performance
which is at 94.1%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">This Must Be the Place: Predicting Engagement of Online Communities in a Large-scale Distributed Campaign. (arXiv:2201.05334v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05334">
<div class="article-summary-box-inner">
<span><p>Understanding collective decision making at a large-scale, and elucidating
how community organization and community dynamics shape collective behavior are
at the heart of social science research. In this work we study the behavior of
thousands of communities with millions of active members. We define a novel
task: predicting which community will undertake an unexpected, large-scale,
distributed campaign. To this end, we develop a hybrid model, combining textual
cues, community meta-data, and structural properties. We show how this
multi-faceted model can accurately predict large-scale collective
decision-making in a distributed environment. We demonstrate the applicability
of our model through Reddit's r/place a large-scale online experiment in which
millions of users, self-organized in thousands of communities, clashed and
collaborated in an effort to realize their agenda.
</p>
<p>Our hybrid model achieves a high F1 prediction score of 0.826. We find that
coarse meta-features are as important for prediction accuracy as fine-grained
textual cues, while explicit structural features play a smaller role.
Interpreting our model, we provide and support various social insights about
the unique characteristics of the communities that participated in the r/place
experiment.
</p>
<p>Our results and analysis shed light on the complex social dynamics that drive
collective behavior, and on the factors that propel user coordination. The
scale and the unique conditions of the r/place experiment suggest that our
findings may apply in broader contexts, such as online activism, (countering)
the spread of hate speech and reducing political polarization. The broader
applicability of the model is demonstrated through an extensive analysis of the
WallStreetBets community, their role in r/place and the GameStop short squeeze
campaign of 2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models. (arXiv:2201.05337v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05337">
<div class="article-summary-box-inner">
<span><p>Controllable Text Generation (CTG) is emerging area in the field of natural
language generation (NLG). It is regarded as crucial for the development of
advanced text generation technologies that are more natural and better meet the
specific constraints in practical applications. In recent years, methods using
large-scale pre-trained language models (PLMs), in particular the widely used
transformer-based PLMs, have become a new paradigm of NLG, allowing generation
of more diverse and fluent text. However, due to the lower level of
interpretability of deep neural networks, the controllability of these methods
need to be guaranteed. To this end, controllable text generation using
transformer-based PLMs has become a rapidly growing yet challenging new
research hotspot. A diverse range of approaches have emerged in the recent 3-4
years, targeting different CTG tasks which may require different types of
controlled constraints. In this paper, we present a systematic critical review
on the common tasks, main approaches and evaluation methods in this area.
Finally, we discuss the challenges that the field is facing, and put forward
various promising future directions. To the best of our knowledge, this is the
first survey paper to summarize CTG techniques from the perspective of PLMs. We
hope it can help researchers in related fields to quickly track the academic
frontier, providing them with a landscape of the area and a roadmap for future
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Polarity and Subjectivity Detection with Multitask Learning and BERT Embedding. (arXiv:2201.05363v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05363">
<div class="article-summary-box-inner">
<span><p>Multitask learning often helps improve the performance of related tasks as
these often have inter-dependence on each other and perform better when solved
in a joint framework. In this paper, we present a deep multitask learning
framework that jointly performs polarity and subjective detection. We propose
an attention-based multitask model for predicting polarity and subjectivity.
The input sentences are transformed into vectors using pre-trained BERT and
Glove embeddings, and the results depict that BERT embedding based model works
better than the Glove based model. We compare our approach with
state-of-the-art models in both subjective and polarity classification
single-task and multitask frameworks. The proposed approach reports baseline
performances for both polarity detection and subjectivity detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mental Health Assessment for the Chatbots. (arXiv:2201.05382v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05382">
<div class="article-summary-box-inner">
<span><p>Previous researches on dialogue system assessment usually focus on the
quality evaluation (e.g. fluency, relevance, etc) of responses generated by the
chatbots, which are local and technical metrics. For a chatbot which responds
to millions of online users including minors, we argue that it should have a
healthy mental tendency in order to avoid the negative psychological impact on
them. In this paper, we establish several mental health assessment dimensions
for chatbots (depression, anxiety, alcohol addiction, empathy) and introduce
the questionnaire-based mental health assessment methods. We conduct
assessments on some well-known open-domain chatbots and find that there are
severe mental health issues for all these chatbots. We consider that it is due
to the neglect of the mental health risks during the dataset building and the
model training procedures. We expect to attract researchers' attention to the
serious mental health problems of chatbots and improve the chatbots' ability in
positive emotional interaction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressively Optimized Bi-Granular Document Representation for Scalable Embedding Based Retrieval. (arXiv:2201.05409v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05409">
<div class="article-summary-box-inner">
<span><p>Ad-hoc search calls for the selection of appropriate answers from a
massive-scale corpus. Nowadays, the embedding-based retrieval (EBR) becomes a
promising solution, where deep learning based document representation and ANN
search techniques are allied to handle this task. However, a major challenge is
that the ANN index can be too large to fit into memory, given the considerable
size of answer corpus. In this work, we tackle this problem with Bi-Granular
Document Representation, where the lightweight sparse embeddings are indexed
and standby in memory for coarse-grained candidate search, and the heavyweight
dense embeddings are hosted in disk for fine-grained post verification. For the
best of retrieval accuracy, a Progressive Optimization framework is designed.
The sparse embeddings are learned ahead for high-quality search of candidates.
Conditioned on the candidate distribution induced by the sparse embeddings, the
dense embeddings are continuously learned to optimize the discrimination of
ground-truth from the shortlisted candidates. Besides, two techniques: the
contrastive quantization and the locality-centric sampling are introduced for
the learning of sparse and dense embeddings, which substantially contribute to
their performances. Thanks to the above features, our method effectively
handles massive-scale EBR with strong advantages in accuracy: with up to +4.3%
recall gain on million-scale corpus, and up to +17.5% recall gain on
billion-scale corpus. Besides, Our method is applied to a major sponsored
search platform with substantial gains on revenue (+1.95%), Recall (+1.01%) and
CTR (+0.49%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eliciting Knowledge from Pretrained Language Models for Prototypical Prompt Verbalizer. (arXiv:2201.05411v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05411">
<div class="article-summary-box-inner">
<span><p>Recent advances on prompt-tuning cast few-shot classification tasks as a
masked language modeling problem. By wrapping input into a template and using a
verbalizer which constructs a mapping between label space and label word space,
prompt-tuning can achieve excellent results in zero-shot and few-shot
scenarios. However, typical prompt-tuning needs a manually designed verbalizer
which requires domain expertise and human efforts. And the insufficient label
space may introduce considerable bias into the results. In this paper, we focus
on eliciting knowledge from pretrained language models and propose a
prototypical prompt verbalizer for prompt-tuning. Labels are represented by
prototypical embeddings in the feature space rather than by discrete words. The
distances between the embedding at the masked position of input and
prototypical embeddings are used as classification criterion. For zero-shot
settings, knowledge is elicited from pretrained language models by a manually
designed template to form initial prototypical embeddings. For few-shot
settings, models are tuned to learn meaningful and interpretable prototypical
embeddings. Our method optimizes models by contrastive learning. Extensive
experimental results on several many-class text classification datasets with
low-resource settings demonstrate the effectiveness of our approach compared
with other verbalizer construction methods. Our implementation is available at
https://github.com/Ydongd/prototypical-prompt-verbalizer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Impact of Stop Sets on Stopping Active Learning for Text Classification. (arXiv:2201.05460v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05460">
<div class="article-summary-box-inner">
<span><p>Active learning is an increasingly important branch of machine learning and a
powerful technique for natural language processing. The main advantage of
active learning is its potential to reduce the amount of labeled data needed to
learn high-performing models. A vital aspect of an effective active learning
algorithm is the determination of when to stop obtaining additional labeled
data. Several leading state-of-the-art stopping methods use a stop set to help
make this decision. However, there has been relatively less attention given to
the choice of stop set than to the stopping algorithms that are applied on the
stop set. Different choices of stop sets can lead to significant differences in
stopping method performance. We investigate the impact of different stop set
choices on different stopping methods. This paper shows the choice of the stop
set can have a significant impact on the performance of stopping methods and
the impact is different for stability-based methods from that on
confidence-based methods. Furthermore, the unbiased representative stop sets
suggested by original authors of methods work better than the systematically
biased stop sets used in recently published work, and stopping methods based on
stabilizing predictions have stronger performance than confidence-based
stopping methods when unbiased representative stop sets are used. We provide
the largest quantity of experimental results on the impact of stop sets to
date. The findings are important for helping to illuminate the impact of this
important aspect of stopping methods that has been under-considered in recently
published work and that can have a large practical impact on the performance of
stopping methods for important semantic computing applications such as
technology assisted review and text classification more broadly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings. (arXiv:2201.05575v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05575">
<div class="article-summary-box-inner">
<span><p>Previous knowledge graph embedding approaches usually map entities to
representations and utilize score functions to predict the target entities, yet
they struggle to reason rare or emerging unseen entities. In this paper, we
propose kNN-KGE, a new knowledge graph embedding approach, by linearly
interpolating its entity distribution with k-nearest neighbors. We compute the
nearest neighbors based on the distance in the entity embedding space from the
knowledge store. Our approach can allow rare or emerging entities to be
memorized explicitly rather than implicitly in model parameters. Experimental
results demonstrate that our approach can improve inductive and transductive
link prediction results and yield better performance for low-resource settings
with only a few triples, which might be easier to reason via explicit memory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Czech Grammar Error Correction with a Large and Diverse Corpus. (arXiv:2201.05590v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05590">
<div class="article-summary-box-inner">
<span><p>We introduce a large and diverse Czech corpus annotated for grammatical error
correction (GEC) with the aim to contribute to the still scarce data resources
in this domain for languages other than English. The Grammar Error Correction
Corpus for Czech (GECCC) offers a variety of four domains, covering error
distributions ranging from high error density essays written by non-native
speakers, to website texts, where errors are expected to be much less common.
We compare several Czech GEC systems, including several Transformer-based ones,
setting a strong baseline to future research. Finally, we meta-evaluate common
GEC metrics against human judgements on our data. We make the new Czech GEC
corpus publicly available under the CC BY-SA 4.0 license at
<a href="http://hdl.handle.net/11234/1-4639">this http URL</a> .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Warm Start and a Clean Crawled Corpus -- A Recipe for Good Language Models. (arXiv:2201.05601v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05601">
<div class="article-summary-box-inner">
<span><p>We train several language models for Icelandic, including IceBERT, that
achieve state-of-the-art performance in a variety of downstream tasks,
including part-of-speech tagging, named entity recognition, grammatical error
detection and constituency parsing. To train the models we introduce a new
corpus of Icelandic text, the Icelandic Common Crawl Corpus (IC3), a collection
of high quality texts found online by targeting the Icelandic top-level-domain
(TLD). Several other public data sources are also collected for a total of 16GB
of Icelandic text. To enhance the evaluation of model performance and to raise
the bar in baselines for Icelandic, we translate and adapt the WinoGrande
dataset for co-reference resolution. Through these efforts we demonstrate that
a properly cleaned crawled corpus is sufficient to achieve state-of-the-art
results in NLP applications for low to medium resource languages, by comparison
with models trained on a curated corpus. We further show that initializing
models using existing multilingual models can lead to state-of-the-art results
for some downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Open Text 1.0: Public Domain News in 44 Languages. (arXiv:2201.05609v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05609">
<div class="article-summary-box-inner">
<span><p>We present a new multilingual corpus containing text in 44 languages, many of
which have relatively few existing resources for natural language processing.
The first release of the corpus contains over 2.7 million news articles and 1
million shorter passages published between 2001--2021, collected from Voice of
America news websites. We describe our process for collecting, filtering, and
processing the data. The source material is in the public domain, our
collection is licensed using a creative commons license (CC BY 4.0), and all
software used to create the corpus is released under the MIT License. The
corpus will be regularly updated as additional documents are published.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Knowledge-Enhanced Text Generation. (arXiv:2010.04389v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04389">
<div class="article-summary-box-inner">
<span><p>The goal of text generation is to make machines express in human language. It
is one of the most important yet challenging tasks in natural language
processing (NLP). Since 2014, various neural encoder-decoder models pioneered
by Seq2Seq have been proposed to achieve the goal by learning to map input text
to output text. However, the input text alone often provides limited knowledge
to generate the desired output, so the performance of text generation is still
far from satisfaction in many real-world scenarios. To address this issue,
researchers have considered incorporating various forms of knowledge beyond the
input text into the generation models. This research direction is known as
knowledge-enhanced text generation. In this survey, we present a comprehensive
review of the research on knowledge enhanced text generation over the past five
years. The main content includes two parts: (i) general methods and
architectures for integrating knowledge into text generation; (ii) specific
techniques and applications according to different forms of knowledge data.
This survey can have broad audiences, researchers and practitioners, in
academia and industry.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AuGPT: Auxiliary Tasks and Data Augmentation for End-To-End Dialogue with Pre-Trained Language Models. (arXiv:2102.05126v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05126">
<div class="article-summary-box-inner">
<span><p>Attention-based pre-trained language models such as GPT-2 brought
considerable progress to end-to-end dialogue modelling. However, they also
present considerable risks for task-oriented dialogue, such as lack of
knowledge grounding or diversity. To address these issues, we introduce
modified training objectives for language model finetuning, and we employ
massive data augmentation via back-translation to increase the diversity of the
training data. We further examine the possibilities of combining data from
multiples sources to improve performance on the target dataset. We carefully
evaluate our contributions with both human and automatic methods. Our model
substantially outperforms the baseline on the MultiWOZ data and shows
competitive performance with state of the art in both automatic and human
evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recommending Metamodel Concepts during Modeling Activities with Pre-Trained Language Models. (arXiv:2104.01642v2 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01642">
<div class="article-summary-box-inner">
<span><p>The design of conceptually sound metamodels that embody proper semantics in
relation to the application domain is particularly tedious in Model-Driven
Engineering. As metamodels define complex relationships between domain
concepts, it is crucial for a modeler to define these concepts thoroughly while
being consistent with respect to the application domain. We propose an approach
to assist a modeler in the design of a metamodel by recommending relevant
domain concepts in several modeling scenarios. Our approach does not require to
extract knowledge from the domain or to hand-design completion rules. Instead,
we design a fully data-driven approach using a deep learning model that is able
to abstract domain concepts by learning from both structural and lexical
metamodel properties in a corpus of thousands of independent metamodels. We
evaluate our approach on a test set containing 166 metamodels, unseen during
the model training, with more than 5000 test samples. Our preliminary results
show that the trained model is able to provide accurate top-$5$ lists of
relevant recommendations for concept renaming scenarios. Although promising,
the results are less compelling for the scenario of the iterative construction
of the metamodel, in part because of the conservative strategy we use to
evaluate the recommendations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Prompt-based Few-shot Learning for Grounded Dialog Generation. (arXiv:2109.06513v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06513">
<div class="article-summary-box-inner">
<span><p>Dialog models can be greatly strengthened through grounding on various
external information, but grounded dialog corpora are usually not naturally
accessible. In this work, we focus on the few-shot learning for grounded dialog
generation (GDG). We first propose a simple prompting method for GDG tasks,
where different constructs of model input, such as the grounding source and the
conversation context, are distinguished through continuous or discrete prompts.
On three typical GDG tasks, we empirically demonstrate and analyze in-depth the
effectiveness of our method. We then conduct extensive experiments to
thoroughly investigate how our prompting method works with different
pre-trained models. We show that prompted language models perform superiorly to
conversational models, and further analyze various factors that influence the
effects of prompting. Overall, our work introduces a prompt-based perspective
to the few-shot learning for GDG tasks, and provides valuable findings and
insights for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Logic-Based Framework for Natural Language Inference in Dutch. (arXiv:2110.03323v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03323">
<div class="article-summary-box-inner">
<span><p>We present a framework for deriving inference relations between Dutch
sentence pairs. The proposed framework relies on logic-based reasoning to
produce inspectable proofs leading up to inference labels; its judgements are
therefore transparent and formally verifiable. At its core, the system is
powered by two ${\lambda}$-calculi, used as syntactic and semantic theories,
respectively. Sentences are first converted to syntactic proofs and terms of
the linear ${\lambda}$-calculus using a choice of two parsers: an Alpino-based
pipeline, and Neural Proof Nets. The syntactic terms are then converted to
semantic terms of the simply typed ${\lambda}$-calculus, via a set of hand
designed type- and term-level transformations. Pairs of semantic terms are then
fed to an automated theorem prover for natural logic which reasons with them
while using the lexical relations found in the Open Dutch WordNet. We evaluate
the reasoning pipeline on the recently created Dutch natural language inference
dataset, and achieve promising results, remaining only within a $1.1-3.2{\%}$
performance margin to strong neural baselines. To the best of our knowledge,
the reasoning pipeline is the first logic-based system for Dutch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emoji-based Co-attention Network for Microblog Sentiment Analysis. (arXiv:2110.14227v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14227">
<div class="article-summary-box-inner">
<span><p>Emojis are widely used in online social networks to express emotions,
attitudes, and opinions. As emotional-oriented characters, emojis can be
modeled as important features of emotions towards the recipient or subject for
sentiment analysis. However, existing methods mainly take emojis as heuristic
information that fails to resolve the problem of ambiguity noise. Recent
researches have utilized emojis as an independent input to classify text
sentiment but they ignore the emotional impact of the interaction between text
and emojis. It results that the emotional semantics of emojis cannot be fully
explored. In this paper, we propose an emoji-based co-attention network that
learns the mutual emotional semantics between text and emojis on microblogs.
Our model adopts the co-attention mechanism based on bidirectional long
short-term memory incorporating the text and emojis, and integrates a
squeeze-and-excitation block in a convolutional neural network classifier to
increase its sensitivity to emotional semantic features. Experimental results
show that the proposed method can significantly outperform several baselines
for sentiment analysis on short texts of social media.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emoji-aware Co-attention Network with EmoGraph2vec Model for Sentiment Anaylsis. (arXiv:2110.14636v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14636">
<div class="article-summary-box-inner">
<span><p>In social media platforms, emojis have an extremely high occurrence in
computer-mediated communications. Many emojis are used to strengthen the
emotional expressions and the emojis that co-occurs in a sentence also have a
strong sentiment connection. However, when it comes to emoji representation
learning, most studies have only utilized the fixed descriptions provided by
the Unicode Consortium, without consideration of actual usage scenario. As for
the sentiment analysis task, many researchers ignore the emotional impact of
the interaction between text and emojis. It results that the emotional
semantics of emojis cannot be fully explored. In this work, we propose a method
to learn emoji representations called EmoGraph2vec and design an emoji-aware
co-attention network that learns the mutual emotional semantics between text
and emojis on short texts of social media. In EmoGraph2vec, we form an emoji
co-occurrence network on real social data and enrich the semantic information
based on an external knowledge base EmojiNet to obtain emoji node embeddings.
Our model designs a co-attention mechanism to incorporate the text and emojis,
and integrates a squeeze-and-excitation (SE) block into a convolutional neural
network as a classifier. Finally, we use the transfer learning method to
increase converge speed and achieve higher accuracy. Experimental results show
that the proposed model can outperform several baselines for sentiment analysis
on benchmark datasets. Additionally, we conduct a series of ablation and
comparison experiments to investigate the effectiveness of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Privacy attacks for automatic speech recognition acoustic models in a federated learning framework. (arXiv:2111.03777v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03777">
<div class="article-summary-box-inner">
<span><p>This paper investigates methods to effectively retrieve speaker information
from the personalized speaker adapted neural network acoustic models (AMs) in
automatic speech recognition (ASR). This problem is especially important in the
context of federated learning of ASR acoustic models where a global model is
learnt on the server based on the updates received from multiple clients. We
propose an approach to analyze information in neural network AMs based on a
neural network footprint on the so-called Indicator dataset. Using this method,
we develop two attack models that aim to infer speaker identity from the
updated personalized models without access to the actual users' speech data.
Experiments on the TED-LIUM 3 corpus demonstrate that the proposed approaches
are very effective and can provide equal error rate (EER) of 1-2%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making sense of electrical vehicle discussions using sentiment analysis on closely related news and user comments. (arXiv:2112.12327v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12327">
<div class="article-summary-box-inner">
<span><p>We used a token-wise and document-wise sentiment analysis using both
unsupervised and supervised models applied to both news and user reviews
dataset. And our token-wise sentiment analysis found a statistically
significant difference in sentiment between the two groups (both of which were
very large N), our document-wise supervised sentiment analysis found no
significant difference in sentiment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal Attention Network for Stock Movements Prediction. (arXiv:2112.13593v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13593">
<div class="article-summary-box-inner">
<span><p>Stock prices move as piece-wise trending fluctuation rather than a purely
random walk. Traditionally, the prediction of future stock movements is based
on the historical trading record. Nowadays, with the development of social
media, many active participants in the market choose to publicize their
strategies, which provides a window to glimpse over the whole market's attitude
towards future movements by extracting the semantics behind social media.
However, social media contains conflicting information and cannot replace
historical records completely. In this work, we propose a multi-modality
attention network to reduce conflicts and integrate semantic and numeric
features to predict future stock movements comprehensively. Specifically, we
first extract semantic information from social media and estimate their
credibility based on posters' identity and public reputation. Then we
incorporate the semantic from online posts and numeric features from historical
records to make the trading strategy. Experimental results show that our
approach outperforms previous methods by a significant margin in both
prediction accuracy (61.20\%) and trading profits (9.13\%). It demonstrates
that our method improves the performance of stock movements prediction and
informs future research on multi-modality fusion towards stock prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TiltedBERT: Resource Adjustable Version of BERT. (arXiv:2201.03327v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03327">
<div class="article-summary-box-inner">
<span><p>In this paper, we proposed a novel adjustable finetuning method that improves
the training and inference time of the BERT model on downstream tasks. In the
proposed method, we first detect more important word vectors in each layer by
our proposed redundancy metric and then eliminate the less important word
vectors with our proposed strategy. In our method, the word vector elimination
rate in each layer is controlled by the Tilt-Rate hyper-parameter, and the
model learns to work with a considerably lower number of Floating Point
Operations (FLOPs) than the original BERTbase model. Our proposed method does
not need any extra training steps, and also it can be generalized to other
transformer-based models. We perform extensive experiments that show the word
vectors in higher layers have an impressive amount of redundancy that can be
eliminated and decrease the training and inference time. Experimental results
on extensive sentiment analysis, classification and regression datasets, and
benchmarks like IMDB and GLUE showed that our proposed method is effective in
various datasets. By applying our method on the BERTbase model, we decrease the
inference time up to 5.3 times with less than 0.85% accuracy degradation on
average. After the fine-tuning stage, the inference time of our model can be
adjusted with our method offline-tuning property for a wide range of the
Tilt-Rate value selections. Also, we propose a mathematical speedup analysis
that can estimate the speedup of our method accurately. With the help of this
analysis, the proper Tilt-Rate value can be selected before fine-tuning or
while offline-tuning stages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentiment Analysis with Deep Learning Models: A Comparative Study on a Decade of Sinhala Language Facebook Data. (arXiv:2201.03941v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03941">
<div class="article-summary-box-inner">
<span><p>The relationship between Facebook posts and the corresponding reaction
feature is an interesting subject to explore and understand. To achieve this
end, we test state-of-the-art Sinhala sentiment analysis models against a data
set containing a decade worth of Sinhala posts with millions of reactions. For
the purpose of establishing benchmarks and with the goal of identifying the
best model for Sinhala sentiment analysis, we also test, on the same data set
configuration, other deep learning models catered for sentiment analysis. In
this study we report that the 3 layer Bidirectional LSTM model achieves an F1
score of 84.58% for Sinhala sentiment analysis, surpassing the current
state-of-the-art model; Capsule B, which only manages to get an F1 score of
82.04%. Further, since all the deep learning models show F1 scores above 75% we
conclude that it is safe to claim that Facebook reactions are suitable to
predict the sentiment of a text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Automated Error Analysis: Learning to Characterize Errors. (arXiv:2201.05017v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05017">
<div class="article-summary-box-inner">
<span><p>Characterizing the patterns of errors that a system makes helps researchers
focus future development on increasing its accuracy and robustness. We propose
a novel form of "meta learning" that automatically learns interpretable rules
that characterize the types of errors that a system makes, and demonstrate
these rules' ability to help understand and improve two NLP systems. Our
approach works by collecting error cases on validation data, extracting
meta-features describing these samples, and finally learning rules that
characterize errors using these features. We apply our approach to VilBERT, for
Visual Question Answering, and RoBERTa, for Common Sense Question Answering.
Our system learns interpretable rules that provide insights into systemic
errors these systems make on the given tasks. Using these insights, we are also
able to "close the loop" and modestly improve performance of these systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Resources in the Tamasheq Language. (arXiv:2201.05051v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05051">
<div class="article-summary-box-inner">
<span><p>In this paper we present two datasets for Tamasheq, a developing language
mainly spoken in Mali and Niger. These two datasets were made available for the
IWSLT 2022 low-resource speech translation track, and they consist of
collections of radio recordings from the Studio Kalangou (Niger) and Studio
Tamani (Mali) daily broadcast news. We share (i) a massive amount of unlabeled
audio data (671 hours) in five languages: French from Niger, Fulfulde, Hausa,
Tamasheq and Zarma, and (ii) a smaller parallel corpus of audio recordings (17
hours) in Tamasheq, with utterance-level translations in the French language.
All this data is shared under the Creative Commons BY-NC-ND 3.0 license. We
hope these resources will inspire the speech community to develop and benchmark
models using the Tamasheq language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grow-and-Clip: Informative-yet-Concise Evidence Distillation for Answer Explanation. (arXiv:2201.05088v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05088">
<div class="article-summary-box-inner">
<span><p>Interpreting the predictions of existing Question Answering (QA) models is
critical to many real-world intelligent applications, such as QA systems for
healthcare, education, and finance. However, existing QA models lack
interpretability and provide no feedback or explanation for end-users to help
them understand why a specific prediction is the answer to a question. In this
research, we argue that the evidences of an answer is critical to enhancing the
interpretability of QA models. Unlike previous research that simply extracts
several sentence(s) in the context as evidence, we are the first to explicitly
define the concept of evidence as the supporting facts in a context which are
informative, concise, and readable. Besides, we provide effective strategies to
quantitatively measure the informativeness, conciseness and readability of
evidence. Furthermore, we propose Grow-and-Clip Evidence Distillation (GCED)
algorithm to extract evidences from the contexts by trade-off informativeness,
conciseness, and readability. We conduct extensive experiments on the SQuAD and
TriviaQA datasets with several baseline models to evaluate the effect of GCED
on interpreting answers to questions. Human evaluation are also carried out to
check the quality of distilled evidences. Experimental results show that
automatic distilled evidences have human-like informativeness, conciseness and
readability, which can enhance the interpretability of the answers to
questions.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Enhancement of CNNs via Separation Index Maximizing at the First Convolutional Layer. (arXiv:2201.05217v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05217">
<div class="article-summary-box-inner">
<span><p>In this paper, a straightforward enhancement learning algorithm based on
Separation Index (SI) concept is proposed for Convolutional Neural Networks
(CNNs). At first, the SI as a supervised complexity measure is explained its
usage in better learning of CNNs for classification problems illustrate. Then,
a learning strategy proposes through which the first layer of a CNN is
optimized by maximizing the SI, and the further layers are trained through the
backpropagation algorithm to learn further layers. In order to maximize the SI
at the first layer, A variant of ranking loss is optimized by using the quasi
least square error technique. Applying such a learning strategy to some known
CNNs and datasets, its enhancement impact in almost all cases is demonstrated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Density Estimation from Schlieren Images through Machine Learning. (arXiv:2201.05233v1 [physics.flu-dyn])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05233">
<div class="article-summary-box-inner">
<span><p>This study proposes a radically alternate approach for extracting
quantitative information from schlieren images. The method uses a scaled,
derivative enhanced Gaussian process model to obtain true density estimates
from two corresponding schlieren images with the knife-edge at horizontal and
vertical orientations. We illustrate our approach on schlieren images taken
from a wind tunnel sting model, and a supersonic aircraft in flight.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Leaning-Based Ultra-Fast Stair Detection. (arXiv:2201.05275v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05275">
<div class="article-summary-box-inner">
<span><p>Staircases are some of the most common building structures in urban
environments. Stair detection is an important task for various applications,
including the environmental perception of exoskeleton robots, humanoid robots,
and rescue robots and the navigation of visually impaired people. Most existing
stair detection algorithms have difficulty dealing with the diversity of stair
structure materials, extreme light and serious occlusion. Inspired by human
perception, we propose an end-to-end method based on deep learning.
Specifically, we treat the process of stair line detection as a multitask
involving coarse-grained semantic segmentation and object detection. The input
images are divided into cells, and a simple neural network is used to judge
whether each cell contains stair lines. For cells containing stair lines, the
locations of the stair lines relative to each cell are regressed. Extensive
experiments on our dataset show that our method can achieve high performance in
terms of both speed and accuracy. A lightweight version can even achieve 300+
frames per second with the same resolution. Our code is available at GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boundary-aware Self-supervised Learning for Video Scene Segmentation. (arXiv:2201.05277v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05277">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning has drawn attention through its effectiveness in
learning in-domain representations with no ground-truth annotations; in
particular, it is shown that properly designed pretext tasks (e.g., contrastive
prediction task) bring significant performance gains for downstream tasks
(e.g., classification task). Inspired from this, we tackle video scene
segmentation, which is a task of temporally localizing scene boundaries in a
video, with a self-supervised learning framework where we mainly focus on
designing effective pretext tasks. In our framework, we discover a
pseudo-boundary from a sequence of shots by splitting it into two continuous,
non-overlapping sub-sequences and leverage the pseudo-boundary to facilitate
the pre-training. Based on this, we introduce three novel boundary-aware
pretext tasks: 1) Shot-Scene Matching (SSM), 2) Contextual Group Matching (CGM)
and 3) Pseudo-boundary Prediction (PP); SSM and CGM guide the model to maximize
intra-scene similarity and inter-scene discrimination while PP encourages the
model to identify transitional moments. Through comprehensive analysis, we
empirically show that pre-training and transferring contextual representation
are both critical to improving the video scene segmentation performance.
Lastly, we achieve the new state-of-the-art on the MovieNet-SSeg benchmark. The
code is available at https://github.com/kakaobrain/bassl.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Manifoldron: Direct Space Partition via Manifold Discovery. (arXiv:2201.05279v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05279">
<div class="article-summary-box-inner">
<span><p>A neural network with the widely-used ReLU activation has been shown to
partition the sample space into many convex polytopes for prediction. However,
the parameterized way a neural network and other machine learning models use to
partition the space has imperfections, e.g., the compromised interpretability
for complex models, the inflexibility in decision boundary construction due to
the generic character of the model, and the risk of being trapped into shortcut
solutions. In contrast, although the non-parameterized models can adorably
avoid or downplay these issues, they are usually insufficiently powerful either
due to over-simplification or the failure to accommodate the manifold
structures of data. In this context, we first propose a new type of machine
learning models referred to as Manifoldron that directly derives decision
boundaries from data and partitions the space via manifold structure discovery.
Then, we systematically analyze the key characteristics of the Manifoldron
including interpretability, manifold characterization capability, and its link
to neural networks. The experimental results on 9 small and 11 large datasets
demonstrate that the proposed Manifoldron performs competitively compared to
the mainstream machine learning models. We have shared our code
https://github.com/wdayang/Manifoldron for free download and evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Argus++: Robust Real-time Activity Detection for Unconstrained Video Streams with Overlapping Cube Proposals. (arXiv:2201.05290v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05290">
<div class="article-summary-box-inner">
<span><p>Activity detection is one of the attractive computer vision tasks to exploit
the video streams captured by widely installed cameras. Although achieving
impressive performance, conventional activity detection algorithms are usually
designed under certain constraints, such as using trimmed and/or
object-centered video clips as inputs. Therefore, they failed to deal with the
multi-scale multi-instance cases in real-world unconstrained video streams,
which are untrimmed and have large field-of-views. Real-time requirements for
streaming analysis also mark brute force expansion of them unfeasible.
</p>
<p>To overcome these issues, we propose Argus++, a robust real-time activity
detection system for analyzing unconstrained video streams. The design of
Argus++ introduces overlapping spatio-temporal cubes as an intermediate concept
of activity proposals to ensure coverage and completeness of activity detection
through over-sampling. The overall system is optimized for real-time processing
on standalone consumer-level hardware. Extensive experiments on different
surveillance and driving scenarios demonstrated its superior performance in a
series of activity detection benchmarks, including CVPR ActivityNet ActEV 2021,
NIST ActEV SDL UF/KF, TRECVID ActEV 2020/2021, and ICCV ROAD 2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MMNet: Muscle motion-guided network for micro-expression recognition. (arXiv:2201.05297v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05297">
<div class="article-summary-box-inner">
<span><p>Facial micro-expressions (MEs) are involuntary facial motions revealing
peoples real feelings and play an important role in the early intervention of
mental illness, the national security, and many human-computer interaction
systems. However, existing micro-expression datasets are limited and usually
pose some challenges for training good classifiers. To model the subtle facial
muscle motions, we propose a robust micro-expression recognition (MER)
framework, namely muscle motion-guided network (MMNet). Specifically, a
continuous attention (CA) block is introduced to focus on modeling local subtle
muscle motion patterns with little identity information, which is different
from most previous methods that directly extract features from complete video
frames with much identity information. Besides, we design a position
calibration (PC) module based on the vision transformer. By adding the position
embeddings of the face generated by PC module at the end of the two branches,
the PC module can help to add position information to facial muscle motion
pattern features for the MER. Extensive experiments on three public
micro-expression datasets demonstrate that our approach outperforms
state-of-the-art methods by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Thousand Words Are Worth More Than a Picture: Natural Language-Centric Outside-Knowledge Visual Question Answering. (arXiv:2201.05299v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05299">
<div class="article-summary-box-inner">
<span><p>Outside-knowledge visual question answering (OK-VQA) requires the agent to
comprehend the image, make use of relevant knowledge from the entire web, and
digest all the information to answer the question. Most previous works address
the problem by first fusing the image and question in the multi-modal space,
which is inflexible for further fusion with a vast amount of external
knowledge. In this paper, we call for a paradigm shift for the OK-VQA task,
which transforms the image into plain text, so that we can enable knowledge
passage retrieval, and generative question-answering in the natural language
space. This paradigm takes advantage of the sheer volume of gigantic knowledge
bases and the richness of pre-trained language models. A
Transform-Retrieve-Generate framework (TRiG) framework is proposed, which can
be plug-and-played with alternative image-to-text models and textual knowledge
bases. Experimental results show that our TRiG framework outperforms all
state-of-the-art supervised methods by at least 11.1% absolute margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Temporal Video Grounding with Deep Semantic Clustering. (arXiv:2201.05307v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05307">
<div class="article-summary-box-inner">
<span><p>Temporal video grounding (TVG) aims to localize a target segment in a video
according to a given sentence query. Though respectable works have made decent
achievements in this task, they severely rely on abundant video-query paired
data, which is expensive and time-consuming to collect in real-world scenarios.
In this paper, we explore whether a video grounding model can be learned
without any paired annotations. To the best of our knowledge, this paper is the
first work trying to address TVG in an unsupervised setting. Considering there
is no paired supervision, we propose a novel Deep Semantic Clustering Network
(DSCNet) to leverage all semantic information from the whole query set to
compose the possible activity in each video for grounding. Specifically, we
first develop a language semantic mining module, which extracts implicit
semantic features from the whole query set. Then, these language semantic
features serve as the guidance to compose the activity in video via a
video-based semantic aggregation module. Finally, we utilize a foreground
attention branch to filter out the redundant background activities and refine
the grounding results. To validate the effectiveness of our DSCNet, we conduct
experiments on both ActivityNet Captions and Charades-STA datasets. The results
demonstrate that DSCNet achieves competitive performance, and even outperforms
most weakly-supervised approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Skeleton-Based Human Activity Discovery Technique Using Particle Swarm Optimization with Gaussian Mutation. (arXiv:2201.05314v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05314">
<div class="article-summary-box-inner">
<span><p>Human activity discovery aims to distinguish the activities performed by
humans, without any prior information of what defines each activity. Most
methods presented in human activity recognition are supervised, where there are
labeled inputs to train the system. In reality, it is difficult to label data
because of its huge volume and the variety of activities performed by humans.
In this paper, a novel unsupervised approach is proposed to perform human
activity discovery in 3D skeleton sequences. First, important frames are
selected based on kinetic energy. Next, the displacement of joints, set of
statistical, angles, and orientation features are extracted to represent the
activities information. Since not all extracted features have useful
information, the dimension of features is reduced using PCA. Most human
activity discovery proposed are not fully unsupervised. They use pre-segmented
videos before categorizing activities. To deal with this, we used the
fragmented sliding time window method to segment the time series of activities
with some overlapping. Then, activities are discovered by a novel hybrid
particle swarm optimization with a Gaussian mutation algorithm to avoid getting
stuck in the local optimum. Finally, k-means is applied to the outcome
centroids to overcome the slow rate of PSO. Experiments on three datasets have
been presented and the results show the proposed method has superior
performance in discovering activities in all evaluation parameters compared to
the other state-of-the-art methods and has increased accuracy of at least 4 %
on average. The code is available here:
https://github.com/parhamhadikhani/Human-Activity-Discovery-HPGMK
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-automated Virtual Unfolded View Generation Method of Stomach from CT Volumes. (arXiv:2201.05331v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05331">
<div class="article-summary-box-inner">
<span><p>CT image-based diagnosis of the stomach is developed as a new way of
diagnostic method. A virtual unfolded (VU) view is suitable for displaying its
wall. In this paper, we propose a semi-automated method for generating VU views
of the stomach. Our method requires minimum manual operations. The
determination of the unfolding forces and the termination of the unfolding
process are automated. The unfolded shape of the stomach is estimated based on
its radius. The unfolding forces are determined so that the stomach wall is
deformed to the expected shape. The iterative deformation process is terminated
if the difference of the shapes between the deformed shape and expected shape
is small. Our experiments using 67 CT volumes showed that our proposed method
can generate good VU views for 76.1% cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AWSnet: An Auto-weighted Supervision Attention Network for Myocardial Scar and Edema Segmentation in Multi-sequence Cardiac Magnetic Resonance Images. (arXiv:2201.05344v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05344">
<div class="article-summary-box-inner">
<span><p>Multi-sequence cardiac magnetic resonance (CMR) provides essential pathology
information (scar and edema) to diagnose myocardial infarction. However,
automatic pathology segmentation can be challenging due to the difficulty of
effectively exploring the underlying information from the multi-sequence CMR
data. This paper aims to tackle the scar and edema segmentation from
multi-sequence CMR with a novel auto-weighted supervision framework, where the
interactions among different supervised layers are explored under a
task-specific objective using reinforcement learning. Furthermore, we design a
coarse-to-fine framework to boost the small myocardial pathology region
segmentation with shape prior knowledge. The coarse segmentation model
identifies the left ventricle myocardial structure as a shape prior, while the
fine segmentation model integrates a pixel-wise attention strategy with an
auto-weighted supervision model to learn and extract salient pathological
structures from the multi-sequence CMR data. Extensive experimental results on
a publicly available dataset from Myocardial pathology segmentation combining
multi-sequence CMR (MyoPS 2020) demonstrate our method can achieve promising
performance compared with other state-of-the-art methods. Our method is
promising in advancing the myocardial pathology assessment on multi-sequence
CMR data. To motivate the community, we have made our code publicly available
via https://github.com/soleilssss/AWSnet/tree/master.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Saliency Constrained Arbitrary Image Style Transfer using SIFT and DCNN. (arXiv:2201.05346v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05346">
<div class="article-summary-box-inner">
<span><p>This paper develops a new image synthesis approach to transfer an example
image (style image) to other images (content images) by using Deep
Convolutional Neural Networks (DCNN) model. When common neural style transfer
methods are used, the textures and colors in the style image are usually
transferred imperfectly to the content image, or some visible errors are
generated. This paper proposes a novel saliency constrained method to reduce or
avoid such effects. It first evaluates some existing saliency detection methods
to select the most suitable one for use in our method. The selected saliency
detection method is used to detect the object in the style image, corresponding
to the object of the content image with the same saliency. In addition, aim to
solve the problem that the size or resolution is different in the style image
and content, the scale-invariant feature transform is used to generate a series
of style images and content images which can be used to generate more feature
maps for patches matching. It then proposes a new loss function combining the
saliency loss, style loss and content loss, adding gradient of saliency
constraint into style transfer in iterations. Finally the source images and
saliency detection results are utilized as multichannel input to an improved
deep CNN framework for style transfer. The experiments show that the saliency
maps of source images can help find the correct matching and avoid artifacts.
Experimental results on different kind of images demonstrate that our method
outperforms nine representative methods from recent publications and has good
robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Deep Hybrid Boosted and Ensemble Learning-based Brain Tumor Analysis using MRI. (arXiv:2201.05373v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05373">
<div class="article-summary-box-inner">
<span><p>Brain tumors analysis is important in timely diagnosis and effective
treatment to cure patients. Tumor analysis is challenging because of tumor
morphology like size, location, texture, and heteromorphic appearance in the
medical images. In this regard, a novel two-phase deep learning-based framework
is proposed to detect and categorize brain tumors in magnetic resonance images
(MRIs). In the first phase, a novel deep boosted features and ensemble
classifiers (DBF-EC) scheme is proposed to detect tumor MRI images from healthy
individuals effectively. The deep boosted feature space is achieved through the
customized and well-performing deep convolutional neural networks (CNNs), and
consequently, fed into the ensemble of machine learning (ML) classifiers. While
in the second phase, a new hybrid features fusion-based brain tumor
classification approach is proposed, comprised of dynamic-static feature and ML
classifier to categorize different tumor types. The dynamic features are
extracted from the proposed BRAIN-RENet CNN, which carefully learns
heteromorphic and inconsistent behavior of various tumors, while the static
features are extracted using HOG. The effectiveness of the proposed two-phase
brain tumor analysis framework is validated on two standard benchmark datasets;
collected from Kaggle and Figshare containing different types of tumor,
including glioma, meningioma, pituitary, and normal images. Experimental
results proved that the proposed DBF-EC detection scheme outperforms and
achieved accuracy (99.56%), precision (0.9991), recall (0.9899), F1-Score
(0.9945), MCC (0.9892), and AUC-PR (0.9990). While the classification scheme,
the joint employment of the deep features fusion of proposed BRAIN-RENet and
HOG features improves performance significantly in terms of recall (0.9913),
precision (0.9906), F1-Score (0.9909), and accuracy (99.20%) on diverse
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SRVIO: Super Robust Visual Inertial Odometry for dynamic environments and challenging Loop-closure conditions. (arXiv:2201.05386v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05386">
<div class="article-summary-box-inner">
<span><p>The visual localization or odometry problem is a well-known challenge in the
field of autonomous robots and cars. Traditionally, this problem can ba tackled
with the help of expensive sensors such as lidars. Nowadays, the leading
research is on robust localization using economic sensors, such as cameras and
IMUs. The geometric methods based on these sensors are pretty good in normal
conditions withstable lighting and no dynamic objects. These methods suffer
from significant loss and divergence in such challenging environments. The
scientists came to use deep neural networks (DNNs) as the savior to mitigate
this problem. The main idea behind using DNNs was to better understand the
problem inside the data and overcome complex conditions (such as a dynamic
object in front of the camera, extreme lighting conditions, keeping the track
at high speeds, etc.) The prior endto-end DNN methods are able to overcome some
of the mentioned challenges. However, no general and robust framework for all
of these scenarios is available. In this paper, we have combined geometric and
DNN based methods to have the pros of geometric SLAM frameworks and overcome
the remaining challenges with the DNNs help. To do this, we have modified the
Vins-Mono framework (the most robust and accurate framework till now) and we
were able to achieve state-of-the-art results on TUM-Dynamic, TUM-VI, ADVIO and
EuRoC datasets compared to geometric and end-to-end DNN based SLAMs. Our
proposed framework was also able to achieve acceptable results on extreme
simulated cases resembling the challenges mentioned earlier easy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HardBoost: Boosting Zero-Shot Learning with Hard Classes. (arXiv:2201.05479v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05479">
<div class="article-summary-box-inner">
<span><p>This work is a systematical analysis on the so-called hard class problem in
zero-shot learning (ZSL), that is, some unseen classes disproportionally affect
the ZSL performances than others, as well as how to remedy the problem by
detecting and exploiting hard classes. At first, we report our empirical
finding that the hard class problem is a ubiquitous phenomenon and persists
regardless of used specific methods in ZSL. Then, we find that high semantic
affinity among unseen classes is a plausible underlying cause of hardness and
design two metrics to detect hard classes. Finally, two frameworks are proposed
to remedy the problem by detecting and exploiting hard classes, one under
inductive setting, the other under transductive setting. The proposed
frameworks could accommodate most existing ZSL methods to further significantly
boost their performances with little efforts. Extensive experiments on three
popular benchmarks demonstrate the benefits by identifying and exploiting the
hard classes in ZSL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergence of Machine Language: Towards Symbolic Intelligence with Neural Networks. (arXiv:2201.05489v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05489">
<div class="article-summary-box-inner">
<span><p>Representation is a core issue in artificial intelligence. Humans use
discrete language to communicate and learn from each other, while machines use
continuous features (like vector, matrix, or tensor in deep neural networks) to
represent cognitive patterns. Discrete symbols are low-dimensional, decoupled,
and have strong reasoning ability, while continuous features are
high-dimensional, coupled, and have incredible abstracting capabilities. In
recent years, deep learning has developed the idea of continuous representation
to the extreme, using millions of parameters to achieve high accuracies.
Although this is reasonable from the statistical perspective, it has other
major problems like lacking interpretability, poor generalization, and is easy
to be attacked. Since both paradigms have strengths and weaknesses, a better
choice is to seek reconciliation. In this paper, we make an initial attempt
towards this direction. Specifically, we propose to combine symbolism and
connectionism principles by using neural networks to derive a discrete
representation. This process is highly similar to human language, which is a
natural combination of discrete symbols and neural systems, where the brain
processes continuous signals and represents intelligence via discrete language.
To mimic this functionality, we denote our approach as machine language. By
designing an interactive environment and task, we demonstrated that machines
could generate a spontaneous, flexible, and semantic language through
cooperation. Moreover, through experiments we show that discrete language
representation has several advantages compared with continuous feature
representation, from the aspects of interpretability, generalization, and
robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Determination of building flood risk maps from LiDAR mobile mapping data. (arXiv:2201.05514v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05514">
<div class="article-summary-box-inner">
<span><p>With increasing urbanization, flooding is a major challenge for many cities
today. Based on forecast precipitation, topography, and pipe networks, flood
simulations can provide early warnings for areas and buildings at risk of
flooding. Basement windows, doors, and underground garage entrances are common
places where floodwater can flow into a building. Some buildings have been
prepared or designed considering the threat of flooding, but others have not.
Therefore, knowing the heights of these facade openings helps to identify
places that are more susceptible to water ingress. However, such data is not
yet readily available in most cities. Traditional surveying of the desired
targets may be used, but this is a very time-consuming and laborious process.
This research presents a new process for the extraction of windows and doors
from LiDAR mobile mapping data. Deep learning object detection models are
trained to identify these objects. Usually, this requires to provide large
amounts of manual annotations. In this paper, we mitigate this problem by
leveraging a rule-based method. In a first step, the rule-based method is used
to generate pseudo-labels. A semi-supervised learning strategy is then applied
with three different levels of supervision. The results show that using only
automatically generated pseudo-labels, the learning-based model outperforms the
rule-based approach by 14.6% in terms of F1-score. After five hours of human
supervision, it is possible to improve the model by another 6.2%. By comparing
the detected facade openings' heights with the predicted water levels from a
flood simulation model, a map can be produced which assigns per-building flood
risk levels. This information can be combined with flood forecasting to provide
a more targeted disaster prevention guide for the city's infrastructure and
residential buildings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViT2Hash: Unsupervised Information-Preserving Hashing. (arXiv:2201.05541v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05541">
<div class="article-summary-box-inner">
<span><p>Unsupervised image hashing, which maps images into binary codes without
supervision, is a compressor with a high compression rate. Hence, how to
preserving meaningful information of the original data is a critical problem.
Inspired by the large-scale vision pre-training model, known as ViT, which has
shown significant progress for learning visual representations, in this paper,
we propose a simple information-preserving compressor to finetune the ViT model
for the target unsupervised hashing task. Specifically, from pixels to
continuous features, we first propose a feature-preserving module, using the
corrupted image as input to reconstruct the original feature from the
pre-trained ViT model and the complete image, so that the feature extractor can
focus on preserving the meaningful information of original data. Secondly, from
continuous features to hash codes, we propose a hashing-preserving module,
which aims to keep the semantic information from the pre-trained ViT model by
using the proposed Kullback-Leibler divergence loss. Besides, the quantization
loss and the similarity loss are added to minimize the quantization error. Our
method is very simple and achieves a significantly higher degree of MAP on
three benchmark image datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal registration of FISH and nanoSIMS images using convolutional neural network models. (arXiv:2201.05545v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05545">
<div class="article-summary-box-inner">
<span><p>Nanoscale secondary ion mass spectrometry (nanoSIMS) and fluorescence in situ
hybridization (FISH) microscopy provide high-resolution, multimodal image
representations of the identity and cell activity respectively of targeted
microbial communities in microbiological research. Despite its importance to
microbiologists, multimodal registration of FISH and nanoSIMS images is
challenging given the morphological distortion and background noise in both
images. In this study, we use convolutional neural networks (CNNs) for
multiscale feature extraction, shape context for computation of the minimum
transformation cost feature matching and the thin-plate spline (TPS) model for
multimodal registration of the FISH and nanoSIMS images. All the six tested CNN
models, VGG16, VGG19, GoogLeNet and ShuffleNet, ResNet18 and ResNet101
performed well, demonstrating the utility of CNNs in the registration of
multimodal images with significant background noise and morphology distortion.
We also show aggregate shape preserved by binarization to be a robust feature
for registering multimodal microbiology-related images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HYLDA: End-to-end Hybrid Learning Domain Adaptation for LiDAR Semantic Segmentation. (arXiv:2201.05585v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05585">
<div class="article-summary-box-inner">
<span><p>In this paper we address the problem of training a LiDAR semantic
segmentation network using a fully-labeled source dataset and a target dataset
that only has a small number of labels. To this end, we develop a novel
image-to-image translation engine, and couple it with a LiDAR semantic
segmentation network, resulting in an integrated domain adaptation architecture
we call HYLDA. To train the system end-to-end, we adopt a diverse set of
learning paradigms, including 1) self-supervision on a simple auxiliary
reconstruction task, 2) semi-supervised training using a few available labeled
target domain frames, and 3) unsupervised training on the fake translated
images generated by the image-to-image translation stage, together with the
labeled frames from the source domain. In the latter case, the semantic
segmentation network participates in the updating of the image-to-image
translation engine. We demonstrate experimentally that HYLDA effectively
addresses the challenging problem of improving generalization on validation
data from the target domain when only a few target labeled frames are available
for training. We perform an extensive evaluation where we compare HYLDA against
strong baseline methods using two publicly available LiDAR semantic
segmentation datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When less is more: Simplifying inputs aids neural network understanding. (arXiv:2201.05610v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05610">
<div class="article-summary-box-inner">
<span><p>How do neural network image classifiers respond to simpler and simpler
inputs? And what do such responses reveal about the learning process? To answer
these questions, we need a clear measure of input simplicity (or inversely,
complexity), an optimization objective that correlates with simplification, and
a framework to incorporate such objective into training and inference. Lastly
we need a variety of testbeds to experiment and evaluate the impact of such
simplification on learning. In this work, we measure simplicity with the
encoding bit size given by a pretrained generative model, and minimize the bit
size to simplify inputs in training and inference. We investigate the effect of
such simplification in several scenarios: conventional training, dataset
condensation and post-hoc explanations. In all settings, inputs are simplified
along with the original classification task, and we investigate the trade-off
between input simplicity and task performance. For images with injected
distractors, such simplification naturally removes superfluous information. For
dataset condensation, we find that inputs can be simplified with almost no
accuracy degradation. When used in post-hoc explanation, our learning-based
simplification approach offers a valuable new tool to explore the basis of
network decisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Networks with pixels embedding: a method to improve noise resistance in images classification. (arXiv:2005.11679v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.11679">
<div class="article-summary-box-inner">
<span><p>In the task of image classification, usually, the network is sensitive to
noises. For example, an image of cat with noises might be misclassified as an
ostrich. Conventionally, to overcome the problem of noises, one uses the
technique of data augmentation, that is, to teach the network to distinguish
noises by adding more images with noises in the training dataset. In this work,
we provide a noise-resistance network in images classification by introducing a
technique of pixel embedding. We test the network with pixel embedding, which
is abbreviated as the network with PE, on the mnist database of handwritten
digits. It shows that the network with PE outperforms the conventional network
on images with noises. The technique of pixel embedding can be used in many
tasks of image classification to improve noise resistance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">THIN: THrowable Information Networks and Application for Facial Expression Recognition In The Wild. (arXiv:2010.07614v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07614">
<div class="article-summary-box-inner">
<span><p>For a number of machine learning problems, an exogenous variable can be
identified such that it heavily influences the appearance of the different
classes, and an ideal classifier should be invariant to this variable. An
example of such exogenous variable is identity if facial expression recognition
(FER) is considered. In this paper, we propose a dual exogenous/endogenous
representation. The former captures the exogenous variable whereas the second
one models the task at hand (e.g. facial expression). We design a prediction
layer that uses a tree-gated deep ensemble conditioned by the exogenous
representation. We also propose an exogenous dispelling loss to remove the
exogenous information from the endogenous representation. Thus, the exogenous
information is used two times in a throwable fashion, first as a conditioning
variable for the target task, and second to create invariance within the
endogenous representation. We call this method THIN, standing for THrowable
Information Networks. We experimentally validate THIN in several contexts where
an exogenous information can be identified, such as digit recognition under
large rotations and shape recognition at multiple scales. We also apply it to
FER with identity as the exogenous variable. We demonstrate that THIN
significantly outperforms state-of-the-art approaches on several challenging
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Bird's-Eye View of Road Semantics using an Onboard Camera. (arXiv:2012.03040v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03040">
<div class="article-summary-box-inner">
<span><p>Autonomous navigation requires scene understanding of the action-space to
move or anticipate events. For planner agents moving on the ground plane, such
as autonomous vehicles, this translates to scene understanding in the
bird's-eye view (BEV). However, the onboard cameras of autonomous cars are
customarily mounted horizontally for a better view of the surrounding. In this
work, we study scene understanding in the form of online estimation of semantic
BEV maps using the video input from a single onboard camera. We study three key
aspects of this task, image-level understanding, BEV level understanding, and
the aggregation of temporal information. Based on these three pillars we
propose a novel architecture that combines these three aspects. In our
extensive experiments, we demonstrate that the considered aspects are
complementary to each other for BEV understanding. Furthermore, the proposed
architecture significantly surpasses the current state-of-the-art. Code:
https://github.com/ybarancan/BEV_feat_stitch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPICE: Semantic Pseudo-labeling for Image Clustering. (arXiv:2103.09382v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09382">
<div class="article-summary-box-inner">
<span><p>The similarity among samples and the discrepancy between clusters are two
crucial aspects of image clustering. However, current deep clustering methods
suffer from the inaccurate estimation of either feature similarity or semantic
discrepancy. In this paper, we present a Semantic Pseudo-labeling-based Image
ClustEring (SPICE) framework, which divides the clustering network into a
feature model for measuring the instance-level similarity and a clustering head
for identifying the cluster-level discrepancy. We design two semantics-aware
pseudo-labeling algorithms, prototype pseudo-labeling, and reliable
pseudo-labeling, which enable accurate and reliable self-supervision over
clustering. Without using any ground-truth label, we optimize the clustering
network in three stages: 1) train the feature model through contrastive
learning to measure the instance similarity, 2) train the clustering head with
the prototype pseudo-labeling algorithm to identify cluster semantics, and 3)
jointly train the feature model and clustering head with the reliable
pseudo-labeling algorithm to improve the clustering performance. Extensive
experimental results demonstrate that SPICE achieves significant improvements
(~10%) over existing methods and establishes the new state-of-the-art
clustering results on six image benchmark datasets in terms of three popular
metrics. Importantly, SPICE significantly reduces the gap between unsupervised
and fully-supervised classification; e.g., there is only a 2% (91.8% vs 93.8%)
accuracy difference on CIFAR-10. Our code has been made publically available at
https://github.com/niuchuangnn/SPICE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly supervised segmentation with cross-modality equivariant constraints. (arXiv:2104.02488v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02488">
<div class="article-summary-box-inner">
<span><p>Weakly supervised learning has emerged as an appealing alternative to
alleviate the need for large labeled datasets in semantic segmentation. Most
current approaches exploit class activation maps (CAMs), which can be generated
from image-level annotations. Nevertheless, resulting maps have been
demonstrated to be highly discriminant, failing to serve as optimal proxy
pixel-level labels. We present a novel learning strategy that leverages
self-supervision in a multi-modal image scenario to significantly enhance
original CAMs. In particular, the proposed method is based on two observations.
First, the learning of fully-supervised segmentation networks implicitly
imposes equivariance by means of data augmentation, whereas this implicit
constraint disappears on CAMs generated with image tags. And second, the
commonalities between image modalities can be employed as an efficient
self-supervisory signal, correcting the inconsistency shown by CAMs obtained
across multiple modalities. To effectively train our model, we integrate a
novel loss function that includes a within-modality and a cross-modality
equivariant term to explicitly impose these constraints during training. In
addition, we add a KL-divergence on the class prediction distributions to
facilitate the information exchange between modalities, which, combined with
the equivariant regularizers further improves the performance of our model.
Exhaustive experiments on the popular multi-modal BRATS dataset demonstrate
that our approach outperforms relevant recent literature under the same
learning conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PDO-eS2CNNs: Partial Differential Operator Based Equivariant Spherical CNNs. (arXiv:2104.03584v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03584">
<div class="article-summary-box-inner">
<span><p>Spherical signals exist in many applications, e.g., planetary data, LiDAR
scans and digitalization of 3D objects, calling for models that can process
spherical data effectively. It does not perform well when simply projecting
spherical data into the 2D plane and then using planar convolution neural
networks (CNNs), because of the distortion from projection and ineffective
translation equivariance. Actually, good principles of designing spherical CNNs
are avoiding distortions and converting the shift equivariance property in
planar CNNs to rotation equivariance in the spherical domain. In this work, we
use partial differential operators (PDOs) to design a spherical equivariant
CNN, PDO-eS2CNN, which is exactly rotation equivariant in the continuous
domain. We then discretize PDO-eS2CNNs, and analyze the equivariance error
resulted from discretization. This is the first time that the equivariance
error is theoretically analyzed in the spherical domain. In experiments,
PDO-eS2CNNs show greater parameter efficiency and outperform other spherical
CNNs significantly on several tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransVG: End-to-End Visual Grounding with Transformers. (arXiv:2104.08541v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08541">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a neat yet effective transformer-based framework
for visual grounding, namely TransVG, to address the task of grounding a
language query to the corresponding region onto an image. The state-of-the-art
methods, including two-stage or one-stage ones, rely on a complex module with
manually-designed mechanisms to perform the query reasoning and multi-modal
fusion. However, the involvement of certain mechanisms in fusion module design,
such as query decomposition and image scene graph, makes the models easily
overfit to datasets with specific scenarios, and limits the plenitudinous
interaction between the visual-linguistic context. To avoid this caveat, we
propose to establish the multi-modal correspondence by leveraging transformers,
and empirically show that the complex fusion modules e.g., modular attention
network, dynamic graph, and multi-modal tree) can be replaced by a simple stack
of transformer encoder layers with higher performance. Moreover, we
re-formulate the visual grounding as a direct coordinates regression problem
and avoid making predictions out of a set of candidates i.e., region proposals
or anchor boxes). Extensive experiments are conducted on five widely used
datasets, and a series of state-of-the-art records are set by our TransVG. We
build the benchmark of transformer-based visual grounding framework and make
the code available at \url{https://github.com/djiajunustc/TransVG}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CAGAN: Text-To-Image Generation with Combined Attention GANs. (arXiv:2104.12663v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12663">
<div class="article-summary-box-inner">
<span><p>Generating images according to natural language descriptions is a challenging
task. Prior research has mainly focused to enhance the quality of generation by
investigating the use of spatial attention and/or textual attention thereby
neglecting the relationship between channels. In this work, we propose the
Combined Attention Generative Adversarial Network (CAGAN) to generate
photo-realistic images according to textual descriptions. The proposed CAGAN
utilises two attention models: word attention to draw different sub-regions
conditioned on related words; and squeeze-and-excitation attention to capture
non-linear interaction among channels. With spectral normalisation to stabilise
training, our proposed CAGAN improves the state of the art on the IS and FID on
the CUB dataset and the FID on the more challenging COCO dataset. Furthermore,
we demonstrate that judging a model by a single evaluation metric can be
misleading by developing an additional model adding local self-attention which
scores a higher IS, outperforming the state of the art on the CUB dataset, but
generates unrealistic images through feature repetition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of Brain Tumours in MR Images using Deep Spatiospatial Models. (arXiv:2105.14071v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14071">
<div class="article-summary-box-inner">
<span><p>A brain tumour is a mass or cluster of abnormal cells in the brain, which has
the possibility of becoming life-threatening because of its ability to invade
neighbouring tissues and also form metastases. An accurate diagnosis is
essential for successful treatment planning and magnetic resonance imaging is
the principal imaging modality for diagnostic of brain tumours and their
extent. Deep Learning methods in computer vision applications have shown
significant improvement in recent years, most of which can be credited to the
fact that a sizeable amount of data is available to train models on, and the
improvements in the model architectures yielding better approximations in a
supervised setting. Classifying tumours using such deep learning methods has
made significant progress with the availability of open datasets with reliable
annotations. Typically those methods are either 3D models, which use 3D
volumetric MRIs or even 2D models considering each slice separately. However,
by treating the slice spatial dimension separately, spatiotemporal models can
be employed as spatiospatial models for this task. These models have the
capabilities of learning specific spatial and temporal relationship, while
reducing computational costs. This paper uses two spatiotemporal models, ResNet
(2+1)D and ResNet Mixed Convolution, to classify different types of brain
tumours. It was observed that both these models performed superior to the pure
3D convolutional model, ResNet18. Furthermore, it was also observed that
pre-training the models on a different, even unrelated dataset before training
them for the task of tumour classification improves the performance. Finally,
Pre-trained ResNet Mixed Convolution was observed to be the best model in these
experiments, achieving a macro F1-score of 0.93 and a test accuracy of 96.98\%,
while at the same time being the model with the least computational cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. (arXiv:2106.04619v4 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04619">
<div class="article-summary-box-inner">
<span><p>Self-supervised representation learning has shown remarkable success in a
number of domains. A common practice is to perform data augmentation via
hand-crafted transformations intended to leave the semantics of the data
invariant. We seek to understand the empirical success of this approach from a
theoretical perspective. We formulate the augmentation process as a latent
variable model by postulating a partition of the latent representation into a
content component, which is assumed invariant to augmentation, and a style
component, which is allowed to change. Unlike prior work on disentanglement and
independent component analysis, we allow for both nontrivial statistical and
causal dependencies in the latent space. We study the identifiability of the
latent representation based on pairs of views of the observations and prove
sufficient conditions that allow us to identify the invariant content partition
up to an invertible mapping in both generative and discriminative settings. We
find numerical simulations with dependent latent variables are consistent with
our theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,
visually complex images with rich causal dependencies, which we use to study
the effect of data augmentations performed in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation of cell-level anomalies in electroluminescence images of photovoltaic modules. (arXiv:2106.10962v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10962">
<div class="article-summary-box-inner">
<span><p>In the operation &amp; maintenance (O&amp;M) of photovoltaic (PV) plants, the early
identification of failures has become crucial to maintain productivity and
prolong components' life. Of all defects, cell-level anomalies can lead to
serious failures and may affect surrounding PV modules in the long run. These
fine defects are usually captured with high spatial resolution
electroluminescence (EL) imaging. The difficulty of acquiring such images has
limited the availability of data. For this work, multiple data resources and
augmentation techniques have been used to surpass this limitation. Current
state-of-the-art detection methods extract barely low-level information from
individual PV cell images, and their performance is conditioned by the
available training data. In this article, we propose an end-to-end deep
learning pipeline that detects, locates and segments cell-level anomalies from
entire photovoltaic modules via EL images. The proposed modular pipeline
combines three deep learning techniques: 1. object detection (modified
Faster-RNN), 2. image classification (EfficientNet) and 3. weakly supervised
segmentation (autoencoder). The modular nature of the pipeline allows to
upgrade the deep learning models to the further improvements in the
state-of-the-art and also extend the pipeline towards new functionalities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Explainability: A Tutorial on Gradient-Based Attribution Methods for Deep Neural Networks. (arXiv:2107.11400v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11400">
<div class="article-summary-box-inner">
<span><p>With the rise of deep neural networks, the challenge of explaining the
predictions of these networks has become increasingly recognized. While many
methods for explaining the decisions of deep neural networks exist, there is
currently no consensus on how to evaluate them. On the other hand, robustness
is a popular topic for deep learning research; however, it is hardly talked
about in explainability until very recently. In this tutorial paper, we start
by presenting gradient-based interpretability methods. These techniques use
gradient signals to assign the burden of the decision on the input features.
Later, we discuss how gradient-based methods can be evaluated for their
robustness and the role that adversarial robustness plays in having meaningful
explanations. We also discuss the limitations of gradient-based methods.
Finally, we present the best practices and attributes that should be examined
before choosing an explainability method. We conclude with the future
directions for research in the area at the convergence of robustness and
explainability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects. (arXiv:2108.07368v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07368">
<div class="article-summary-box-inner">
<span><p>Segmenting medical images accurately and reliably is important for disease
diagnosis and treatment. It is a challenging task because of the wide variety
of objects' sizes, shapes, and scanning modalities. Recently, many
convolutional neural networks (CNN) have been designed for segmentation tasks
and achieved great success. Few studies, however, have fully considered the
sizes of objects, and thus most demonstrate poor performance for small objects
segmentation. This can have a significant impact on the early detection of
diseases. This paper proposes a Context Axial Reserve Attention Network
(CaraNet) to improve the segmentation performance on small objects compared
with several recent state-of-the-art models. We test our CaraNet on brain tumor
(BraTS 2018) and polyp (Kvasir-SEG, CVC-ColonDB, CVC-ClinicDB, CVC-300, and
ETIS-LaribPolypDB) segmentation datasets. Our CaraNet achieves the top-rank
mean Dice segmentation accuracy, and results show a distinct advantage of
CaraNet in the segmentation of small medical objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning 3D Mineral Prospectivity from 3D Geological Models Using Convolutional Neural Networks: Application to a Structure-controlled Hydrothermal Gold Deposit. (arXiv:2109.00756v2 [physics.geo-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00756">
<div class="article-summary-box-inner">
<span><p>The three-dimensional (3D) geological models are the typical and key data
source in the 3D mineral prospecitivity modeling. Identifying
prospectivity-informative predictor variables from the 3D geological models is
a challenging and tedious task. Motivated by the ability of convolutional
neural networks (CNNs) to learn the intrinsic features, in this paper, we
present a novel method that leverages CNNs to learn 3D mineral prospectivity
from the 3D geological models. By exploiting the learning ability of CNNs, the
presented method allows for disentangling complex correlation to the
mineralization and thus opens a door to circumvent the tedious work for
designing the predictor variables. Specifically, to explore the unstructured 3D
geological models with the CNNs whose input should be structured, we develop a
2D CNN framework in which the geometry of geological boundary is compiled and
reorganized into multi-channel images and fed into the CNN. This ensures an
effective and efficient training of CNNs while allowing the prospective model
to approximate the ore-forming process. The presented method is applied to a
typical structure-controlled hydrothermal deposit, the Dayingezhuang gold
deposit, eastern China, in which the presented method was compared with the
prospectivity modeling methods using hand-designed predictor variables. The
results demonstrate the presented method capacitates a performance boost of the
3D prospectivity modeling and empowers us to decrease work-load and prospecting
risk in prediction of deep-seated orebodies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-token Modeling with Conditional Computation. (arXiv:2109.02008v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02008">
<div class="article-summary-box-inner">
<span><p>Mixture-of-Experts (MoE), a conditional computation architecture, achieved
promising performance by scaling local module (i.e. feed-forward network) of
transformer. However, scaling the cross-token module (i.e. self-attention) is
challenging due to the unstable training. This work proposes Sparse-MLP, an
all-MLP model which applies sparsely-activated MLPs to cross-token modeling.
Specifically, in each Sparse block of our all-MLP model, we apply two stages of
MoE layers: one with MLP experts mixing information within channels along image
patch dimension, the other with MLP experts mixing information within patches
along the channel dimension. In addition, by proposing importance-score routing
strategy for MoE and redesigning the image representation shape, we further
improve our model's computational efficiency. Experimentally, we are more
computation-efficient than Vision Transformers with comparable accuracy. Also,
our models can outperform MLP-Mixer by 2.5\% on ImageNet Top-1 accuracy with
fewer parameters and computational cost. On downstream tasks, i.e. Cifar10 and
Cifar100, our models can still achieve better performance than baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RobustART: Benchmarking Robustness on Architecture Design and Training Techniques. (arXiv:2109.05211v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05211">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) are vulnerable to adversarial noises, which
motivates the benchmark of model robustness. Existing benchmarks mainly focus
on evaluating defenses, but there are no comprehensive studies of how
architecture design and training techniques affect robustness. Comprehensively
benchmarking their relationships is beneficial for better understanding and
developing robust DNNs. Thus, we propose RobustART, the first comprehensive
Robustness investigation benchmark on ImageNet regarding ARchitecture design
(49 human-designed off-the-shelf architectures and 1200+ networks from neural
architecture search) and Training techniques (10+ techniques, e.g., data
augmentation) towards diverse noises (adversarial, natural, and system noises).
Extensive experiments substantiated several insights for the first time, e.g.,
(1) adversarial training is effective for the robustness against all noises
types for Transformers and MLP-Mixers; (2) given comparable model sizes and
aligned training settings, CNNs &gt; Transformers &gt; MLP-Mixers on robustness
against natural and system noises; Transformers &gt; MLP-Mixers &gt; CNNs on
adversarial robustness; (3) for some light-weight architectures, increasing
model sizes or using extra data cannot improve robustness. Our benchmark
presents: (1) an open-source platform for comprehensive robustness evaluation;
(2) a variety of pre-trained models to facilitate robustness evaluation; and
(3) a new view to better understand the mechanism towards designing robust
DNNs. We will continuously develop to this ecosystem for the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Competence-Aware Path Planning via Introspective Perception. (arXiv:2109.13974v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13974">
<div class="article-summary-box-inner">
<span><p>Robots deployed in the real world over extended periods of time need to
reason about unexpected failures, learn to predict them, and to proactively
take actions to avoid future failures. Existing approaches for competence-aware
planning are either model-based, requiring explicit enumeration of known
failure modes, or purely statistical, using state- and location-specific
failure statistics to infer competence. We instead propose a structured
model-free approach to competence-aware planning by reasoning about plan
execution failures due to errors in perception, without requiring a priori
enumeration of failure sources or requiring location-specific failure
statistics. We introduce competence-aware path planning via introspective
perception (CPIP), a Bayesian framework to iteratively learn and exploit
task-level competence in novel deployment environments. CPIP factorizes the
competence-aware planning problem into two components. First, perception errors
are learned in a model-free and location-agnostic setting via introspective
perception prior to deployment in novel environments. Second, during actual
deployments, the prediction of task-level failures is learned in a
context-aware setting. Experiments in a simulation show that the proposed CPIP
approach outperforms the frequentist baseline in multiple mobile robot tasks,
and is further validated via real robot experiments in an environment with
perceptually challenging obstacles and terrain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Convolutional Neural Network Compression through Generalized Kronecker Product Decomposition. (arXiv:2109.14710v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14710">
<div class="article-summary-box-inner">
<span><p>Modern Convolutional Neural Network (CNN) architectures, despite their
superiority in solving various problems, are generally too large to be deployed
on resource constrained edge devices. In this paper, we reduce memory usage and
floating-point operations required by convolutional layers in CNNs. We compress
these layers by generalizing the Kronecker Product Decomposition to apply to
multidimensional tensors, leading to the Generalized Kronecker Product
Decomposition (GKPD). Our approach yields a plug-and-play module that can be
used as a drop-in replacement for any convolutional layer. Experimental results
for image classification on CIFAR-10 and ImageNet datasets using ResNet,
MobileNetv2 and SeNet architectures substantiate the effectiveness of our
proposed approach. We find that GKPD outperforms state-of-the-art decomposition
methods including Tensor-Train and Tensor-Ring as well as other relevant
compression methods such as pruning and knowledge distillation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Online Visual Invariances for Novel Objects via Supervised and Self-Supervised Training. (arXiv:2110.01476v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01476">
<div class="article-summary-box-inner">
<span><p>Humans can identify objects following various spatial transformations such as
scale and viewpoint. This extends to novel objects, after a single presentation
at a single pose, sometimes referred to as online invariance. CNNs have been
proposed as a compelling model of human vision, but their ability to identify
objects across transformations is typically tested on held-out samples of
trained categories after extensive data augmentation. This paper assesses
whether standard CNNs can support human-like online invariance by training
models to recognize images of synthetic 3D objects that undergo several
transformations: rotation, scaling, translation, brightness, contrast, and
viewpoint. Through the analysis of models' internal representations, we show
that standard supervised CNNs trained on transformed objects can acquire strong
invariances on novel classes even when trained with as few as 50 objects taken
from 10 classes. This extended to a different dataset of photographs of real
objects. We also show that these invariances can be acquired in a
self-supervised way, through solving the same/different task. We suggest that
this latter approach may be similar to how humans acquire invariances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-Based Detection, Classification and Prediction/Prognosis in Medical Imaging: Towards Radiophenomics. (arXiv:2110.10332v4 [physics.med-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.10332">
<div class="article-summary-box-inner">
<span><p>Artificial intelligence (AI) techniques have significant potential to enable
effective, robust and automated image phenotyping including identification of
subtle patterns. AI-based detection searches the image space to find the
regions of interest based on patterns and features. There is a spectrum of
tumor histologies from benign to malignant that can be identified by AI-based
classification approaches using image features. The extraction of minable
information from images gives way to the field of radiomics and can be explored
via explicit (handcrafted/engineered) and deep radiomics frameworks. Radiomics
analysis has the potential to be utilized as a noninvasive technique for the
accurate characterization of tumors to improve diagnosis and treatment
monitoring. This work reviews AI-based techniques, with a special focus on
oncological PET and PET/CT imaging, for different detection, classification,
and prediction/prognosis tasks. We also discuss needed efforts to enable the
translation of AI techniques to routine clinical workflows, and potential
improvements and complementary techniques such as the use of natural language
processing on electronic health records and neuro-symbolic AI techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lebanon Solar Rooftop Potential Assessment using Buildings Segmentation from Aerial Images. (arXiv:2111.11397v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11397">
<div class="article-summary-box-inner">
<span><p>Estimating the solar rooftop potential of buildings' rooftops at a large
scale is a fundamental step for every country to utilize its solar power
efficiently. However, such estimation becomes time-consuming and costly if done
through on-site measurements. This paper uses deep learning-based multi-class
instance segmentation to extract buildings' footprints from satellite images.
Hence, we introduce Lebanon's first complete and comprehensive buildings'
footprints map. Furthermore, we propose a photovoltaic panels placement
algorithm to estimate the solar potential of every rooftop, which results in
Lebanon's first buildings' solar rooftop potential map too. Finally, we report
total solar rooftop potential per district and localize regions corresponding
to the highest solar rooftop potential yield.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Principled Disentanglement for Domain Generalization. (arXiv:2111.13839v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13839">
<div class="article-summary-box-inner">
<span><p>A fundamental challenge for machine learning models is generalizing to
out-of-distribution (OOD) data, in part due to spurious correlations. To tackle
this challenge, we first formalize the OOD generalization problem as
constrained optimization, called Disentanglement-constrained Domain
Generalization (DDG). We relax this non-trivial constrained optimization to a
tractable form with finite-dimensional parameterization and empirical
approximation. Then a theoretical analysis of the extent to which the above
transformations deviates from the original problem is provided. Based on the
transformation, we propose a primal-dual algorithm for joint representation
disentanglement and domain generalization. In contrast to traditional
approaches based on domain adversarial training and domain labels, DDG jointly
learns semantic and variation encoders for disentanglement, enabling flexible
manipulation and augmentation on training data. DDG aims to learn intrinsic
representations of semantic concepts that are invariant to nuisance factors and
generalizable across different domains. Comprehensive experiments on popular
benchmarks show that DDG can achieve competitive OOD performance and uncover
interpretable salient structures within data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boundary Aware Learning for Out-of-distribution Detection. (arXiv:2112.11648v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11648">
<div class="article-summary-box-inner">
<span><p>This paper focuses on the problem of detecting out-of-distribution (ood)
samples with neural nets. In image recognition tasks, the trained classifier
often gives high confidence score for input images which are remote from the
in-distribution (id) data, and this has greatly limited its application in real
world. For alleviating this problem, we propose a GAN based boundary aware
classifier (GBAC) for generating a closed hyperspace which only contains most
id data. Our method is based on the fact that the traditional neural net
seperates the feature space as several unclosed regions which are not suitable
for ood detection. With GBAC as an auxiliary module, the ood data distributed
outside the closed hyperspace will be assigned with much lower score, allowing
more effective ood detection while maintaining the classification performance.
Moreover, we present a fast sampling method for generating hard ood
representations which lie on the boundary of pre-mentioned closed hyperspace.
Experiments taken on several datasets and neural net architectures promise the
effectiveness of GBAC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Culture-to-Culture Image Translation with Generative Adversarial Networks. (arXiv:2201.01565v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01565">
<div class="article-summary-box-inner">
<span><p>This article introduces the concept of image "culturization", i.e., defined
as the process of altering the "brushstroke of cultural features" that make
objects perceived as belonging to a given culture while preserving their
functionalities. First, we propose a pipeline for translating objects' images
from a source to a target cultural domain based on Generative Adversarial
Networks (GAN). Then, we gather data through an online questionnaire to test
four hypotheses concerning the preferences of Italian participants towards
objects and environments belonging to different cultures. As expected, results
depend on individual tastes and preference: however, they are in line with our
conjecture that some people, during the interaction with a robot or another
intelligent system, might prefer to be shown images whose cultural domain has
been modified to match their cultural background.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Incremental Learning Approach to Automatically Recognize Pulmonary Diseases from the Multi-vendor Chest Radiographs. (arXiv:2201.02574v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02574">
<div class="article-summary-box-inner">
<span><p>Pulmonary diseases can cause severe respiratory problems, leading to sudden
death if not treated timely. Many researchers have utilized deep learning
systems to diagnose pulmonary disorders using chest X-rays (CXRs). However,
such systems require exhaustive training efforts on large-scale data to
effectively diagnose chest abnormalities. Furthermore, procuring such
large-scale data is often infeasible and impractical, especially for rare
diseases. With the recent advances in incremental learning, researchers have
periodically tuned deep neural networks to learn different classification tasks
with few training examples. Although, such systems can resist catastrophic
forgetting, they treat the knowledge representations independently of each
other, and this limits their classification performance. Also, to the best of
our knowledge, there is no incremental learning-driven image diagnostic
framework that is specifically designed to screen pulmonary disorders from the
CXRs. To address this, we present a novel framework that can learn to screen
different chest abnormalities incrementally. In addition to this, the proposed
framework is penalized through an incremental learning loss function that
infers Bayesian theory to recognize structural and semantic inter-dependencies
between incrementally learned knowledge representations to diagnose the
pulmonary diseases effectively, regardless of the scanner specifications. We
tested the proposed framework on five public CXR datasets containing different
chest abnormalities, where it outperformed various state-of-the-art system
through various metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransVOD: End-to-end Video Object Detection with Spatial-Temporal Transformers. (arXiv:2201.05047v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05047">
<div class="article-summary-box-inner">
<span><p>Detection Transformer (DETR) and Deformable DETR have been proposed to
eliminate the need for many hand-designed components in object detection while
demonstrating good performance as previous complex hand-crafted detectors.
However, their performance on Video Object Detection (VOD) has not been well
explored. In this paper, we present TransVOD, the first end-to-end video object
detection system based on spatial-temporal Transformer architectures. The first
goal of this paper is to streamline the pipeline of VOD, effectively removing
the need for many hand-crafted components for feature aggregation, e.g.,
optical flow model, relation networks. Besides, benefited from the object query
design in DETR, our method does not need complicated post-processing methods
such as Seq-NMS. In particular, we present a temporal Transformer to aggregate
both the spatial object queries and the feature memories of each frame. Our
temporal transformer consists of two components: Temporal Query Encoder (TQE)
to fuse object queries, and Temporal Deformable Transformer Decoder (TDTD) to
obtain current frame detection results. These designs boost the strong baseline
deformable DETR by a significant margin (3%-4% mAP) on the ImageNet VID
dataset. Then, we present two improved versions of TransVOD including
TransVOD++ and TransVOD Lite. The former fuses object-level information into
object query via dynamic convolution while the latter models the entire video
clips as the output to speed up the inference time. We give detailed analysis
of all three models in the experiment part. In particular, our proposed
TransVOD++ sets a new state-of-the-art record in terms of accuracy on ImageNet
VID with 90.0% mAP. Our proposed TransVOD Lite also achieves the best speed and
accuracy trade-off with 83.7% mAP while running at around 30 FPS on a single
V100 GPU device. Code and models will be available for further research.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-01-17 23:07:18.015598716 UTC">2022-01-17 23:07:18 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>