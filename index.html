<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-07T01:30:00Z">09-07</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">ALLWAS: Active Learning on Language models in WASserstein space. (arXiv:2109.01691v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01691">
<div class="article-summary-box-inner">
<span><p>Active learning has emerged as a standard paradigm in areas with scarcity of
labeled training data, such as in the medical domain. Language models have
emerged as the prevalent choice of several natural language tasks due to the
performance boost offered by these models. However, in several domains, such as
medicine, the scarcity of labeled training data is a common issue. Also, these
models may not work well in cases where class imbalance is prevalent. Active
learning may prove helpful in these cases to boost the performance with a
limited label budget. To this end, we propose a novel method using sampling
techniques based on submodular optimization and optimal transport for active
learning in language models, dubbed ALLWAS. We construct a sampling strategy
based on submodular optimization of the designed objective in the gradient
domain. Furthermore, to enable learning from few samples, we propose a novel
strategy for sampling from the Wasserstein barycenters. Our empirical
evaluations on standard benchmark datasets for text classification show that
our methods perform significantly better (&gt;20% relative increase in some cases)
than existing approaches for active learning on language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Error Detection in Large-Scale Natural Language Understanding Systems Using Transformer Models. (arXiv:2109.01754v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01754">
<div class="article-summary-box-inner">
<span><p>Large-scale conversational assistants like Alexa, Siri, Cortana and Google
Assistant process every utterance using multiple models for domain, intent and
named entity recognition. Given the decoupled nature of model development and
large traffic volumes, it is extremely difficult to identify utterances
processed erroneously by such systems. We address this challenge to detect
domain classification errors using offline Transformer models. We combine
utterance encodings from a RoBERTa model with the Nbest hypothesis produced by
the production system. We then fine-tune end-to-end in a multitask setting
using a small dataset of humanannotated utterances with domain classification
errors. We tested our approach for detecting misclassifications from one domain
that accounts for &lt;0.5% of the traffic in a large-scale conversational AI
system. Our approach achieves an F1 score of 30% outperforming a bi- LSTM
baseline by 16.9% and a standalone RoBERTa model by 4.8%. We improve this
further by 2.2% to 32.2% by ensembling multiple models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation for Cross-Domain Named Entity Recognition. (arXiv:2109.01758v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01758">
<div class="article-summary-box-inner">
<span><p>Current work in named entity recognition (NER) shows that data augmentation
techniques can produce more robust models. However, most existing techniques
focus on augmenting in-domain data in low-resource scenarios where annotated
data is quite limited. In contrast, we study cross-domain data augmentation for
the NER task. We investigate the possibility of leveraging data from
high-resource domains by projecting it into the low-resource domains.
Specifically, we propose a novel neural architecture to transform the data
representation from a high-resource to a low-resource domain by learning the
patterns (e.g. style, noise, abbreviations, etc.) in the text that
differentiate them and a shared feature space where both domains are aligned.
We experiment with diverse datasets and show that transforming the data to the
low-resource domain representation achieves significant improvements over only
using data from high-resource domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Representation Learning for Efficient and Effective Similarity Search and Recommendation. (arXiv:2109.01815v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01815">
<div class="article-summary-box-inner">
<span><p>How data is represented and operationalized is critical for building
computational solutions that are both effective and efficient. A common
approach is to represent data objects as binary vectors, denoted \textit{hash
codes}, which require little storage and enable efficient similarity search
through direct indexing into a hash table or through similarity computations in
an appropriate space. Due to the limited expressibility of hash codes, compared
to real-valued representations, a core open challenge is how to generate hash
codes that well capture semantic content or latent properties using a small
number of bits, while ensuring that the hash codes are distributed in a way
that does not reduce their search efficiency. State of the art methods use
representation learning for generating such hash codes, focusing on neural
autoencoder architectures where semantics are encoded into the hash codes by
learning to reconstruct the original inputs of the hash codes. This thesis
addresses the above challenge and makes a number of contributions to
representation learning that (i) improve effectiveness of hash codes through
more expressive representations and a more effective similarity measure than
the current state of the art, namely the Hamming distance, and (ii) improve
efficiency of hash codes by learning representations that are especially suited
to the choice of search method. The contributions are empirically validated on
several tasks related to similarity search and recommendation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Frustratingly Simple Pretraining Alternatives to Masked Language Modeling. (arXiv:2109.01819v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01819">
<div class="article-summary-box-inner">
<span><p>Masked language modeling (MLM), a self-supervised pretraining objective, is
widely used in natural language processing for learning text representations.
MLM trains a model to predict a random sample of input tokens that have been
replaced by a [MASK] placeholder in a multi-class setting over the entire
vocabulary. When pretraining, it is common to use alongside MLM other auxiliary
objectives on the token or sequence level to improve downstream performance
(e.g. next sentence prediction). However, no previous work so far has attempted
in examining whether other simpler linguistically intuitive or not objectives
can be used standalone as main pretraining objectives. In this paper, we
explore five simple pretraining objectives based on token-level classification
tasks as replacements of MLM. Empirical results on GLUE and SQuAD show that our
proposed methods achieve comparable or better performance to MLM using a
BERT-BASE architecture. We further validate our methods using smaller models,
showing that pretraining a model with 41% of the BERT-BASE's parameters,
BERT-MEDIUM results in only a 1% drop in GLUE scores with our best objective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Expressive Communication with Internet Memes: A New Multimodal Conversation Dataset and Benchmark. (arXiv:2109.01839v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01839">
<div class="article-summary-box-inner">
<span><p>As a kind of new expression elements, Internet memes are popular and
extensively used in online chatting scenarios since they manage to make
dialogues vivid, moving, and interesting. However, most current dialogue
researches focus on text-only dialogue tasks. In this paper, we propose a new
task named as \textbf{M}eme incorporated \textbf{O}pen-domain \textbf{D}ialogue
(MOD). Compared to previous dialogue tasks, MOD is much more challenging since
it requires the model to understand the multimodal elements as well as the
emotions behind them. To facilitate the MOD research, we construct a
large-scale open-domain multimodal dialogue dataset incorporating abundant
Internet memes into utterances. The dataset consists of $\sim$45K Chinese
conversations with $\sim$606K utterances. Each conversation contains about $13$
utterances with about $4$ Internet memes on average and each utterance equipped
with an Internet meme is annotated with the corresponding emotion. In addition,
we present a simple and effective method, which utilizes a unified generation
network to solve the MOD task. Experimental results demonstrate that our method
trained on the proposed corpus is able to achieve expressive communication
including texts and memes. The corpus and models have been publicly available
at https://github.com/lizekang/DSTC10-MOD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supervised Contrastive Learning for Multimodal Unreliable News Detection in COVID-19 Pandemic. (arXiv:2109.01850v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01850">
<div class="article-summary-box-inner">
<span><p>As the digital news industry becomes the main channel of information
dissemination, the adverse impact of fake news is explosively magnified. The
credibility of a news report should not be considered in isolation. Rather,
previously published news articles on the similar event could be used to assess
the credibility of a news report. Inspired by this, we propose a BERT-based
multimodal unreliable news detection framework, which captures both textual and
visual information from unreliable articles utilising the contrastive learning
strategy. The contrastive learner interacts with the unreliable news classifier
to push similar credible news (or similar unreliable news) closer while moving
news articles with similar content but opposite credibility labels away from
each other in the multimodal embedding space. Experimental results on a
COVID-19 related dataset, ReCOVery, show that our model outperforms a number of
competitive baseline in unreliable news detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pushing Paraphrase Away from Original Sentence: A Multi-Round Paraphrase Generation Approach. (arXiv:2109.01862v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01862">
<div class="article-summary-box-inner">
<span><p>In recent years, neural paraphrase generation based on Seq2Seq has achieved
superior performance, however, the generated paraphrase still has the problem
of lack of diversity. In this paper, we focus on improving the diversity
between the generated paraphrase and the original sentence, i.e., making
generated paraphrase different from the original sentence as much as possible.
We propose BTmPG (Back-Translation guided multi-round Paraphrase Generation),
which leverages multi-round paraphrase generation to improve diversity and
employs back-translation to preserve semantic information. We evaluate BTmPG on
two benchmark datasets. Both automatic and human evaluation show BTmPG can
improve the diversity of paraphrase while preserving the semantics of the
original sentence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncovering the Limits of Text-based Emotion Detection. (arXiv:2109.01900v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01900">
<div class="article-summary-box-inner">
<span><p>Identifying emotions from text is crucial for a variety of real world tasks.
We consider the two largest now-available corpora for emotion classification:
GoEmotions, with 58k messages labelled by readers, and Vent, with 33M
writer-labelled messages. We design a benchmark and evaluate several feature
spaces and learning algorithms, including two simple yet novel models on top of
BERT that outperform previous strong baselines on GoEmotions. Through an
experiment with human participants, we also analyze the differences between how
writers express emotions and how readers perceive them. Our results suggest
that emotions expressed by writers are harder to identify than emotions that
readers perceive. We share a public web interface for researchers to explore
our models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Neural Network-Based Linguistic Similarity Measure for Entrainment in Conversations. (arXiv:2109.01924v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01924">
<div class="article-summary-box-inner">
<span><p>Linguistic entrainment is a phenomenon where people tend to mimic each other
in conversation. The core instrument to quantify entrainment is a linguistic
similarity measure between conversational partners. Most of the current
similarity measures are based on bag-of-words approaches that rely on
linguistic markers, ignoring the overall language structure and dialogue
context. To address this issue, we propose to use a neural network model to
perform the similarity measure for entrainment. Our model is context-aware, and
it further leverages a novel component to learn the shared high-level
linguistic features across dialogues. We first investigate the effectiveness of
our novel component. Then we use the model to perform similarity measure in a
corpus-based entrainment analysis. We observe promising results for both
evaluation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Relative Spatial Reasoning for Visual Question Answering. (arXiv:2109.01934v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01934">
<div class="article-summary-box-inner">
<span><p>Vision-and-language (V\&amp;L) reasoning necessitates perception of visual
concepts such as objects and actions, understanding semantics and language
grounding, and reasoning about the interplay between the two modalities. One
crucial aspect of visual reasoning is spatial understanding, which involves
understanding relative locations of objects, i.e.\ implicitly learning the
geometry of the scene. In this work, we evaluate the faithfulness of V\&amp;L
models to such geometric understanding, by formulating the prediction of
pair-wise relative locations of objects as a classification as well as a
regression task. Our findings suggest that state-of-the-art transformer-based
V\&amp;L models lack sufficient abilities to excel at this task. Motivated by this,
we design two objectives as proxies for 3D spatial reasoning (SR) -- object
centroid estimation, and relative position estimation, and train V\&amp;L with weak
supervision from off-the-shelf depth estimators. This leads to considerable
improvements in accuracy for the "GQA" visual question answering challenge (in
fully supervised, few-shot, and O.O.D settings) as well as improvements in
relative spatial reasoning. Code and data will be released
\href{https://github.com/pratyay-banerjee/weak_sup_vqa}{here}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Detection of Contextual Synonyms in a Multi-Class Setting: Phenotype Annotation Use Case. (arXiv:2109.01935v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01935">
<div class="article-summary-box-inner">
<span><p>Contextualised word embeddings is a powerful tool to detect contextual
synonyms. However, most of the current state-of-the-art (SOTA) deep learning
concept extraction methods remain supervised and underexploit the potential of
the context. In this paper, we propose a self-supervised pre-training approach
which is able to detect contextual synonyms of concepts being training on the
data created by shallow matching. We apply our methodology in the sparse
multi-class setting (over 15,000 concepts) to extract phenotype information
from electronic health records. We further investigate data augmentation
techniques to address the problem of the class sparsity. Our approach achieves
a new SOTA for the unsupervised phenotype concept annotation on clinical text
on F1 and Recall outperforming the previous SOTA with a gain of up to 4.5 and
4.0 absolute points, respectively. After fine-tuning with as little as 20\% of
the labelled data, we also outperform BioBERT and ClinicalBERT. The extrinsic
evaluation on three ICU benchmarks also shows the benefit of using the
phenotypes annotated by our model as features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the ability of monolingual models to learn language-agnostic representations. (arXiv:2109.01942v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01942">
<div class="article-summary-box-inner">
<span><p>Pretrained multilingual models have become a de facto default approach for
zero-shot cross-lingual transfer. Previous work has shown that these models are
able to achieve cross-lingual representations when pretrained on two or more
languages with shared parameters. In this work, we provide evidence that a
model can achieve language-agnostic representations even when pretrained on a
single language. That is, we find that monolingual models pretrained and
finetuned on different languages achieve competitive performance compared to
the ones that use the same target language. Surprisingly, the models show a
similar performance on a same task regardless of the pretraining language. For
example, models pretrained on distant languages such as German and Portuguese
perform similarly on English tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Joint Learning of Chest X-Ray and Radiology Report by Word Region Alignment. (arXiv:2109.01949v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01949">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning provides an opportunity to explore unlabeled chest
X-rays and their associated free-text reports accumulated in clinical routine
without manual supervision. This paper proposes a Joint Image Text
Representation Learning Network (JoImTeRNet) for pre-training on chest X-ray
images and their radiology reports. The model was pre-trained on both the
global image-sentence level and the local image region-word level for
visual-textual matching. Both are bidirectionally constrained on Cross-Entropy
based and ranking-based Triplet Matching Losses. The region-word matching is
calculated using the attention mechanism without direct supervision about their
mapping. The pre-trained multi-modal representation learning paves the way for
downstream tasks concerning image and/or text encoding. We demonstrate the
representation learning quality by cross-modality retrievals and multi-label
classifications on two datasets: OpenI-IU and MIMIC-CXR
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models. (arXiv:2109.01951v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01951">
<div class="article-summary-box-inner">
<span><p>The task of learning from only a few examples (called a few-shot setting) is
of key importance and relevance to a real-world setting. For question answering
(QA), the current state-of-the-art pre-trained models typically need
fine-tuning on tens of thousands of examples to obtain good results. Their
performance degrades significantly in a few-shot setting (&lt; 100 examples). To
address this, we propose a simple fine-tuning framework that leverages
pre-trained text-to-text models and is directly aligned with their pre-training
framework. Specifically, we construct the input as a concatenation of the
question, a mask token representing the answer span and a context. Given this
input, the model is fine-tuned using the same objective as that of its
pre-training objective. Through experimental studies on various few-shot
configurations, we show that this formulation leads to significant gains on
multiple QA benchmarks (an absolute gain of 34.2 F1 points on average when
there are only 16 training examples). The gains extend further when used with
larger models (Eg:- 72.3 F1 on SQuAD using BART-large with only 32 examples)
and translate well to a multilingual setting . On the multilingual TydiQA
benchmark, our model outperforms the XLM-Roberta-large by an absolute margin of
upto 40 F1 points and an average of 33 F1 points in a few-shot setting (&lt;= 64
training examples). We conduct detailed ablation studies to analyze factors
contributing to these gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SideControl: Controlled Open-domain Dialogue Generation via Additive Side Networks. (arXiv:2109.01958v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01958">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-trained language models boost the performance of
open-domain dialogue systems. Prior works leverage Transformer-based
pre-trained language models to generate texts with desired attributes in two
general approaches: (1) gradient-based methods: updating all latent
representations of pre-trained models with gradients from attribute models; (2)
weighted-decoding methods: re-ranking beam candidates from pre-trained models
with attribute functions. However, gradient-based methods lead to high
computation cost and can easily get overfitted on small training sets, while
weighted-decoding methods are inherently constrained by the low-variance
high-bias pre-trained model. In this work, we propose a novel approach to
control the generation of Transformer-based pre-trained language models: the
SideControl framework, which leverages a novel control attributes loss to
incorporate useful control signals, and is shown to perform well with very
limited training samples. We evaluate our proposed method on two benchmark
open-domain dialogue datasets, and results show that the SideControl framework
has better controllability, higher generation quality and better
sample-efficiency than existing gradient-based and weighted-decoding baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Evaluation for Explainable AI. (arXiv:2109.01962v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01962">
<div class="article-summary-box-inner">
<span><p>While recent years have witnessed the emergence of various explainable
methods in machine learning, to what degree the explanations really represent
the reasoning process behind the model prediction -- namely, the faithfulness
of explanation -- is still an open problem. One commonly used way to measure
faithfulness is \textit{erasure-based} criteria. Though conceptually simple,
erasure-based criterion could inevitably introduce biases and artifacts. We
propose a new methodology to evaluate the faithfulness of explanations from the
\textit{counterfactual reasoning} perspective: the model should produce
substantially different outputs for the original input and its corresponding
counterfactual edited on a faithful feature. Specially, we introduce two
algorithms to find the proper counterfactuals in both discrete and continuous
scenarios and then use the acquired counterfactuals to measure faithfulness.
Empirical results on several datasets show that compared with existing metrics,
our proposed counterfactual evaluation method can achieve top correlation with
the ground truth under diffe
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Hierarchical Structures with Differentiable Nondeterministic Stacks. (arXiv:2109.01982v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01982">
<div class="article-summary-box-inner">
<span><p>Learning hierarchical structures in sequential data -- from simple
algorithmic patterns to natural language -- in a reliable, generalizable way
remains a challenging problem for neural language models. Past work has shown
that recurrent neural networks (RNNs) struggle to generalize on held-out
algorithmic or syntactic patterns without supervision or some inductive bias.
To remedy this, many papers have explored augmenting RNNs with various
differentiable stacks, by analogy with finite automata and pushdown automata.
In this paper, we present a stack RNN model based on the recently proposed
Nondeterministic Stack RNN (NS-RNN) that achieves lower cross-entropy than all
previous stack RNNs on five context-free language modeling tasks (within 0.05
nats of the information-theoretic lower bound), including a task in which the
NS-RNN previously failed to outperform a deterministic stack RNN baseline. Our
model assigns arbitrary positive weights instead of probabilities to stack
actions, and we provide an analysis of why this improves training. We also
propose a restricted version of the NS-RNN that makes it practical to use for
language modeling on natural language and present results on the Penn Treebank
corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Re-entry Prediction for Online Conversations via Self-Supervised Learning. (arXiv:2109.02020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02020">
<div class="article-summary-box-inner">
<span><p>In recent years, world business in online discussions and opinion sharing on
social media is booming. Re-entry prediction task is thus proposed to help
people keep track of the discussions which they wish to continue. Nevertheless,
existing works only focus on exploiting chatting history and context
information, and ignore the potential useful learning signals underlying
conversation data, such as conversation thread patterns and repeated engagement
of target users, which help better understand the behavior of target users in
conversations. In this paper, we propose three interesting and well-founded
auxiliary tasks, namely, Spread Pattern, Repeated Target user, and Turn
Authorship, as the self-supervised signals for re-entry prediction. These
auxiliary tasks are trained together with the main task in a multi-task manner.
Experimental results on two datasets newly collected from Twitter and Reddit
show that our method outperforms the previous state-of-the-arts with fewer
parameters and faster convergence. Extensive experiments and analysis show the
effectiveness of our proposed models and also point out some key ideas in
designing self-supervised tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Efficient Masked Language Modeling for Vision and Language. (arXiv:2109.02040v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02040">
<div class="article-summary-box-inner">
<span><p>Masked language modeling (MLM) is one of the key sub-tasks in vision-language
pretraining. In the cross-modal setting, tokens in the sentence are masked at
random, and the model predicts the masked tokens given the image and the text.
In this paper, we observe several key disadvantages of MLM in this setting.
First, as captions tend to be short, in a third of the sentences no token is
sampled. Second, the majority of masked tokens are stop-words and punctuation,
leading to under-utilization of the image. We investigate a range of
alternative masking strategies specific to the cross-modal setting that address
these shortcomings, aiming for better fusion of text and image in the learned
representation. When pre-training the LXMERT model, our alternative masking
strategies consistently improve over the original masking strategy on three
downstream tasks, especially in low resource settings. Further, our
pre-training approach substantially outperforms the baseline model on a
prompt-based probing task designed to elicit image objects. These results and
our analysis indicate that our method allows for better utilization of the
training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Attention Branch Network with Combined Loss Function for Automatic Speaker Verification Spoof Detection. (arXiv:2109.02051v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02051">
<div class="article-summary-box-inner">
<span><p>Many endeavors have sought to develop countermeasure techniques as
enhancements on Automatic Speaker Verification (ASV) systems, in order to make
them more robust against spoof attacks. As evidenced by the latest ASVspoof
2019 countermeasure challenge, models currently deployed for the task of ASV
are, at their best, devoid of suitable degrees of generalization to unseen
attacks. Upon further investigation of the proposed methods, it appears that a
broader three-tiered view of the proposed systems. comprised of the classifier,
feature extraction phase, and model loss function, may to some extent lessen
the problem. Accordingly, the present study proposes the Efficient Attention
Branch Network (EABN) modular architecture with a combined loss function to
address the generalization problem...
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Self-Debiasing Framework for Robust NLU Training. (arXiv:2109.02071v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02071">
<div class="article-summary-box-inner">
<span><p>Existing Natural Language Understanding (NLU) models have been shown to
incorporate dataset biases leading to strong performance on in-distribution
(ID) test sets but poor performance on out-of-distribution (OOD) ones. We
introduce a simple yet effective debiasing framework whereby the shallow
representations of the main model are used to derive a bias model and both
models are trained simultaneously. We demonstrate on three well studied NLU
tasks that despite its simplicity, our method leads to competitive OOD results.
It significantly outperforms other debiasing approaches on two tasks, while
still delivering high in-distribution performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowing False Negatives: An Adversarial Training Method for Distantly Supervised Relation Extraction. (arXiv:2109.02099v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02099">
<div class="article-summary-box-inner">
<span><p>Distantly supervised relation extraction (RE) automatically aligns
unstructured text with relation instances in a knowledge base (KB). Due to the
incompleteness of current KBs, sentences implying certain relations may be
annotated as N/A instances, which causes the so-called false negative (FN)
problem. Current RE methods usually overlook this problem, inducing improper
biases in both training and testing procedures. To address this issue, we
propose a two-stage approach. First, it finds out possible FN samples by
heuristically leveraging the memory mechanism of deep neural networks. Then, it
aligns those unlabeled data with the training data into a unified feature space
by adversarial training to assign pseudo labels and further utilize the
information contained in them. Experiments on two wildly-used benchmark
datasets demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teaching Autoregressive Language Models Complex Tasks By Demonstration. (arXiv:2109.02102v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02102">
<div class="article-summary-box-inner">
<span><p>This paper demonstrates that by fine-tuning an autoregressive language model
(GPT-Neo) on appropriately structured step-by-step demonstrations, it is
possible to teach it to execute a mathematical task that has previously proved
difficult for Transformers - longhand modulo operations - with a relatively
small number of examples. Specifically, we fine-tune GPT-Neo to solve the
numbers__div_remainder task from the DeepMind Mathematics Dataset; Saxton et
al. (<a href="/abs/1904.01557">arXiv:1904.01557</a>) reported below 40% accuracy on this task with 2 million
training examples. We show that after fine-tuning on 200 appropriately
structured demonstrations of solving long division problems and reporting the
remainders, the smallest available GPT-Neo model achieves over 80% accuracy.
This is achieved by constructing an appropriate dataset for fine-tuning, with
no changes to the learning algorithm. These results suggest that fine-tuning
autoregressive language models on small sets of well-crafted demonstrations may
be a useful paradigm for enabling individuals without training in machine
learning to coax such models to perform some kinds of complex multi-step tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Models for Text Coherence Assessment. (arXiv:2109.02176v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02176">
<div class="article-summary-box-inner">
<span><p>Coherence is an important aspect of text quality and is crucial for ensuring
its readability. It is essential desirable for outputs from text generation
systems like summarization, question answering, machine translation, question
generation, table-to-text, etc. An automated coherence scoring model is also
helpful in essay scoring or providing writing feedback. A large body of
previous work has leveraged entity-based methods, syntactic patterns, discourse
relations, and more recently traditional deep learning architectures for text
coherence assessment. Previous work suffers from drawbacks like the inability
to handle long-range dependencies, out-of-vocabulary words, or model sequence
information. We hypothesize that coherence assessment is a cognitively complex
task that requires deeper models and can benefit from other related tasks.
Accordingly, in this paper, we propose four different Transformer-based
architectures for the task: vanilla Transformer, hierarchical Transformer,
multi-task learning-based model, and a model with fact-based input
representation. Our experiments with popular benchmark datasets across multiple
domains on four different coherence assessment tasks demonstrate that our
models achieve state-of-the-art results outperforming existing models by a good
margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nearest Neighbour Few-Shot Learning for Cross-lingual Classification. (arXiv:2109.02221v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02221">
<div class="article-summary-box-inner">
<span><p>Even though large pre-trained multilingual models (e.g. mBERT, XLM-R) have
led to significant performance gains on a wide range of cross-lingual NLP
tasks, success on many downstream tasks still relies on the availability of
sufficient annotated data. Traditional fine-tuning of pre-trained models using
only a few target samples can cause over-fitting. This can be quite limiting as
most languages in the world are under-resourced. In this work, we investigate
cross-lingual adaptation using a simple nearest neighbor few-shot (&lt;15 samples)
inference technique for classification tasks. We experiment using a total of 16
distinct languages across two NLP tasks- XNLI and PAWS-X. Our approach
consistently improves traditional fine-tuning using only a handful of labeled
samples in target locales. We also demonstrate its generalization capability
across tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Combinatorial Optimization for Word-level Adversarial Textual Attack. (arXiv:2109.02229v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02229">
<div class="article-summary-box-inner">
<span><p>Over the past few years, various word-level textual attack approaches have
been proposed to reveal the vulnerability of deep neural networks used in
natural language processing. Typically, these approaches involve an important
optimization step to determine which substitute to be used for each word in the
original input. However, current research on this step is still rather limited,
from the perspectives of both problem-understanding and problem-solving. In
this paper, we address these issues by uncovering the theoretical properties of
the problem and proposing an efficient local search algorithm (LS) to solve it.
We establish the first provable approximation guarantee on solving the problem
in general cases. Notably, for adversarial textual attack, it is even better
than the previous bound which only holds in special case. Extensive experiments
involving five NLP tasks, six datasets and eleven NLP models show that LS can
largely reduce the number of queries usually by an order of magnitude to
achieve high attack success rates. Further experiments show that the
adversarial examples crafted by LS usually have higher quality, exhibit better
transferability, and can bring more robustness improvement to victim models by
adversarial training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERT might be Overkill: A Tiny but Effective Biomedical Entity Linker based on Residual Convolutional Neural Networks. (arXiv:2109.02237v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02237">
<div class="article-summary-box-inner">
<span><p>Biomedical entity linking is the task of linking entity mentions in a
biomedical document to referent entities in a knowledge base. Recently, many
BERT-based models have been introduced for the task. While these models have
achieved competitive results on many datasets, they are computationally
expensive and contain about 110M parameters. Little is known about the factors
contributing to their impressive performance and whether the
over-parameterization is needed. In this work, we shed some light on the inner
working mechanisms of these large BERT-based models. Through a set of probing
experiments, we have found that the entity linking performance only changes
slightly when the input word order is shuffled or when the attention scope is
limited to a fixed window size. From these observations, we propose an
efficient convolutional neural network with residual connections for biomedical
entity linking. Because of the sparse connectivity and weight sharing
properties, our model has a small number of parameters and is highly efficient.
On five public datasets, our model achieves comparable or even better linking
accuracy than the state-of-the-art BERT-based models while having about 60
times fewer parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">STaCK: Sentence Ordering with Temporal Commonsense Knowledge. (arXiv:2109.02247v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02247">
<div class="article-summary-box-inner">
<span><p>Sentence order prediction is the task of finding the correct order of
sentences in a randomly ordered document. Correctly ordering the sentences
requires an understanding of coherence with respect to the chronological
sequence of events described in the text. Document-level contextual
understanding and commonsense knowledge centered around these events are often
essential in uncovering this coherence and predicting the exact chronological
order. In this paper, we introduce STaCK -- a framework based on graph neural
networks and temporal commonsense knowledge to model global information and
predict the relative order of sentences. Our graph network accumulates temporal
evidence using knowledge of `past' and `future' and formulates sentence
ordering as a constrained edge classification problem. We report results on
five different datasets, and empirically show that the proposed method is
naturally suitable for order prediction. The implementation of this work is
publicly available at: https://github.com/declare-lab/sentence-ordering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sent2Span: Span Detection for PICO Extraction in the Biomedical Text without Span Annotations. (arXiv:2109.02254v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02254">
<div class="article-summary-box-inner">
<span><p>The rapid growth in published clinical trials makes it difficult to maintain
up-to-date systematic reviews, which requires finding all relevant trials. This
leads to policy and practice decisions based on out-of-date, incomplete, and
biased subsets of available clinical evidence. Extracting and then normalising
Population, Intervention, Comparator, and Outcome (PICO) information from
clinical trial articles may be an effective way to automatically assign trials
to systematic reviews and avoid searching and screening - the two most
time-consuming systematic review processes. We propose and test a novel
approach to PICO span detection. The major difference between our proposed
method and previous approaches comes from detecting spans without needing
annotated span data and using only crowdsourced sentence-level annotations.
Experiments on two datasets show that PICO span detection results achieve much
higher results for recall when compared to fully supervised methods with PICO
sentence detection at least as good as human annotations. By removing the
reliance on expert annotations for span detection, this work could be used in
human-machine pipeline for turning low-quality crowdsourced, and sentence-level
PICO annotations into structured information that can be used to quickly assign
trials to relevant systematic reviews.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Aware Balancing for Multilingual and Multi-Domain Neural Machine Translation Training. (arXiv:2109.02284v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02284">
<div class="article-summary-box-inner">
<span><p>Learning multilingual and multi-domain translation model is challenging as
the heterogeneous and imbalanced data make the model converge inconsistently
over different corpora in real world. One common practice is to adjust the
share of each corpus in the training, so that the learning process is balanced
and low-resource cases can benefit from the high resource ones. However,
automatic balancing methods usually depend on the intra- and inter-dataset
characteristics, which is usually agnostic or requires human priors. In this
work, we propose an approach, MultiUAT, that dynamically adjusts the training
data usage based on the model's uncertainty on a small set of trusted clean
data for multi-corpus machine translation. We experiments with two classes of
uncertainty measures on multilingual (16 languages with 4 settings) and
multi-domain settings (4 for in-domain and 2 for out-of-domain on
English-German translation) and demonstrate our approach MultiUAT substantially
outperforms its baselines, including both static and dynamic strategies. We
analyze the cross-domain transfer and show the deficiency of static and
similarity based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Numerical Reasoning Skills in the Modular Approach for Complex Question Answering on Text. (arXiv:2109.02289v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02289">
<div class="article-summary-box-inner">
<span><p>Numerical reasoning skills are essential for complex question answering (CQA)
over text. It requires opertaions including counting, comparison, addition and
subtraction. A successful approach to CQA on text, Neural Module Networks
(NMNs), follows the programmer-interpreter paradigm and leverages specialised
modules to perform compositional reasoning. However, the NMNs framework does
not consider the relationship between numbers and entities in both questions
and paragraphs. We propose effective techniques to improve NMNs' numerical
reasoning capabilities by making the interpreter question-aware and capturing
the relationship between entities and numbers. On the same subset of the DROP
dataset for CQA on text, experimental results show that our additions
outperform the original NMNs by 3.0 points for the overall F1 score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Visual Dialog Questioner with Entity-based Strategy Learning and Augmented Guesser. (arXiv:2109.02297v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02297">
<div class="article-summary-box-inner">
<span><p>Considering the importance of building a good Visual Dialog (VD) Questioner,
many researchers study the topic under a Q-Bot-A-Bot image-guessing game
setting, where the Questioner needs to raise a series of questions to collect
information of an undisclosed image. Despite progress has been made in
Supervised Learning (SL) and Reinforcement Learning (RL), issues still exist.
Firstly, previous methods do not provide explicit and effective guidance for
Questioner to generate visually related and informative questions. Secondly,
the effect of RL is hampered by an incompetent component, i.e., the Guesser,
who makes image predictions based on the generated dialogs and assigns rewards
accordingly. To enhance VD Questioner: 1) we propose a Related entity enhanced
Questioner (ReeQ) that generates questions under the guidance of related
entities and learns entity-based questioning strategy from human dialogs; 2) we
propose an Augmented Guesser (AugG) that is strong and is optimized for the VD
setting especially. Experimental results on the VisDial v1.0 dataset show that
our approach achieves state-of-theart performance on both image-guessing task
and question diversity. Human study further proves that our model generates
more visually related, informative and coherent questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LightTag: Text Annotation Platform. (arXiv:2109.02320v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02320">
<div class="article-summary-box-inner">
<span><p>Text annotation tools assume that their user's goal is to create a labeled
corpus. However, users view annotation as a necessary evil on the way to
deliver business value through NLP. Thus an annotation tool should optimize for
the throughput of the global NLP process, not only the productivity of
individual annotators. LightTag is a text annotation tool designed and built on
that principle. This paper shares our design rationale, data modeling choices,
and user interface decisions then illustrates how those choices serve the full
NLP lifecycle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hocalarim: Mining Turkish Student Reviews. (arXiv:2109.02325v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02325">
<div class="article-summary-box-inner">
<span><p>We introduce Hocalarim (MyProfessors), the largest student review dataset
available for the Turkish language. It consists of over 5000 professor reviews
left online by students, with different aspects of education rated on a scale
of 1 to 5 stars. We investigate the properties of the dataset and present its
statistics. We examine the impact of students' institution type on their
ratings and the correlation of students' bias to give positive or negative
feedback.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Putting a Spin on Language: A Quantum Interpretation of Unary Connectives for Linguistic Applications. (arXiv:2004.04128v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.04128">
<div class="article-summary-box-inner">
<span><p>Extended versions of the Lambek Calculus currently used in computational
linguistics rely on unary modalities to allow for the controlled application of
structural rules affecting word order and phrase structure. These controlled
structural operations give rise to derivational ambiguities that are missed by
the original Lambek Calculus or its pregroup simplification. Proposals for
compositional interpretation of extended Lambek Calculus in the compact closed
category of FVect and linear maps have been made, but in these proposals the
syntax-semantics mapping ignores the control modalities, effectively
restricting their role to the syntax. Our aim is to turn the modalities into
first-class citizens of the vectorial interpretation. Building on the
directional density matrix semantics, we extend the interpretation of the type
system with an extra spin density matrix space. The interpretation of proofs
then results in ambiguous derivations being tensored with orthogonal spin
states. Our method introduces a way of simultaneously representing co-existing
interpretations of ambiguous utterances, and provides a uniform framework for
the integration of lexical and derivational ambiguity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantum Natural Language Processing on Near-Term Quantum Computers. (arXiv:2005.04147v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.04147">
<div class="article-summary-box-inner">
<span><p>In this work, we describe a full-stack pipeline for natural language
processing on near-term quantum computers, aka QNLP. The language-modelling
framework we employ is that of compositional distributional semantics
(DisCoCat), which extends and complements the compositional structure of
pregroup grammars. Within this model, the grammatical reduction of a sentence
is interpreted as a diagram, encoding a specific interaction of words according
to the grammar. It is this interaction which, together with a specific choice
of word embedding, realises the meaning (or "semantics") of a sentence.
Building on the formal quantum-like nature of such interactions, we present a
method for mapping DisCoCat diagrams to quantum circuits. Our methodology is
compatible both with NISQ devices and with established Quantum Machine Learning
techniques, paving the way to near-term applications of quantum technology to
natural language processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Impact and dynamics of hate and counter speech online. (arXiv:2009.08392v3 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08392">
<div class="article-summary-box-inner">
<span><p>Citizen-generated counter speech is a promising way to fight hate speech and
promote peaceful, non-polarized discourse. However, there is a lack of
large-scale longitudinal studies of its effectiveness for reducing hate speech.
To this end, we perform an exploratory analysis of the effectiveness of counter
speech using several different macro- and micro-level measures to analyze
180,000 political conversations that took place on German Twitter over four
years. We report on the dynamic interactions of hate and counter speech over
time and provide insights into whether, as in `classic' bullying situations,
organized efforts are more effective than independent individuals in steering
online discourse. Taken together, our results build a multifaceted picture of
the dynamics of hate and counter speech online. While we make no causal claims
due to the complexity of discourse dynamics, our findings suggest that
organized hate speech is associated with changes in public discourse and that
counter speech -- especially when organized -- may help curb hateful rhetoric
in online discourse.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic with Natural Language Processing (NLP). (arXiv:2010.16413v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.16413">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has had a significant impact on society, both because
of the serious health effects of COVID-19 and because of public health measures
implemented to slow its spread. Many of these difficulties are fundamentally
information needs; attempts to address these needs have caused an information
overload for both researchers and the public. Natural language processing
(NLP), the branch of artificial intelligence that interprets human language,
can be applied to address many of the information needs made urgent by the
COVID-19 pandemic. This review surveys approximately 150 NLP studies and more
than 50 systems and datasets addressing the COVID-19 pandemic. We detail work
on four core NLP tasks: information retrieval, named entity recognition,
literature-based discovery, and question answering. We also describe work that
directly addresses aspects of the pandemic through four additional tasks: topic
modeling, sentiment and emotion analysis, caseload forecasting, and
misinformation detection. We conclude by discussing observable trends and
remaining challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference. (arXiv:2011.14203v5 [cs.AR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14203">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models such as BERT provide significant accuracy
improvement for a multitude of natural language processing (NLP) tasks.
However, their hefty computational and memory demands make them challenging to
deploy to resource-constrained edge platforms with strict latency requirements.
We present EdgeBERT, an in-depth algorithm-hardware co-design for latency-aware
energy optimization for multi-task NLP. EdgeBERT employs entropy-based early
exit predication in order to perform dynamic voltage-frequency scaling (DVFS),
at a sentence granularity, for minimal energy consumption while adhering to a
prescribed target latency. Computation and memory footprint overheads are
further alleviated by employing a calibrated combination of adaptive attention
span, selective network pruning, and floating-point quantization. Furthermore,
in order to maximize the synergistic benefits of these algorithms in always-on
and intermediate edge computing settings, we specialize a 12nm scalable
hardware accelerator system, integrating a fast-switching low-dropout voltage
regulator (LDO), an all-digital phase-locked loop (ADPLL), as well as,
high-density embedded non-volatile memories (eNVMs) wherein the sparse
floating-point bit encodings of the shared multi-task parameters are carefully
stored. Altogether, latency-aware multi-task NLP inference acceleration on the
EdgeBERT hardware system generates up to 7x, 2.5x, and 53x lower energy
compared to the conventional inference without early stopping, the
latency-unbounded early exit approach, and CUDA adaptations on an Nvidia Jetson
Tegra X2 mobile GPU, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Feed-Forward Layers Are Key-Value Memories. (arXiv:2012.14913v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14913">
<div class="article-summary-box-inner">
<span><p>Feed-forward layers constitute two-thirds of a transformer model's
parameters, yet their role in the network remains under-explored. We show that
feed-forward layers in transformer-based language models operate as key-value
memories, where each key correlates with textual patterns in the training
examples, and each value induces a distribution over the output vocabulary. Our
experiments show that the learned patterns are human-interpretable, and that
lower layers tend to capture shallow patterns, while upper layers learn more
semantic ones. The values complement the keys' input patterns by inducing
output distributions that concentrate probability mass on tokens likely to
appear immediately after each pattern, particularly in the upper layers.
Finally, we demonstrate that the output of a feed-forward layer is a
composition of its memories, which is subsequently refined throughout the
model's layers via residual connections to produce the final output
distribution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion Dynamics in Movie Dialogues. (arXiv:2103.01345v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01345">
<div class="article-summary-box-inner">
<span><p>Emotion dynamics is a framework for measuring how an individual's emotions
change over time. It is a powerful tool for understanding how we behave and
interact with the world. In this paper, we introduce a framework to track
emotion dynamics through one's utterances. Specifically we introduce a number
of utterance emotion dynamics (UED) metrics inspired by work in Psychology. We
use this approach to trace emotional arcs of movie characters. We analyze
thousands of such character arcs to test hypotheses that inform our broader
understanding of stories. Notably, we show that there is a tendency for
characters to use increasingly more negative words and become increasingly
emotionally discordant with each other until about 90 percent of the narrative
length. UED also has applications in behavior studies, social sciences, and
public health.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Interplay of Variant, Size, and Task Type in Arabic Pre-trained Language Models. (arXiv:2103.06678v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06678">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore the effects of language variants, data sizes, and
fine-tuning task types in Arabic pre-trained language models. To do so, we
build three pre-trained language models across three variants of Arabic: Modern
Standard Arabic (MSA), dialectal Arabic, and classical Arabic, in addition to a
fourth language model which is pre-trained on a mix of the three. We also
examine the importance of pre-training data size by building additional models
that are pre-trained on a scaled-down set of the MSA variant. We compare our
different models to each other, as well as to eight publicly available models
by fine-tuning them on five NLP tasks spanning 12 datasets. Our results suggest
that the variant proximity of pre-training data to fine-tuning data is more
important than the pre-training data size. We exploit this insight in defining
an optimized system selection model for the studied tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constructive and Toxic Speech Detection for Open-domain Social Media Comments in Vietnamese. (arXiv:2103.10069v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10069">
<div class="article-summary-box-inner">
<span><p>The rise of social media has led to the increasing of comments on online
forums. However, there still exists invalid comments which are not informative
for users. Moreover, those comments are also quite toxic and harmful to people.
In this paper, we create a dataset for constructive and toxic speech detection,
named UIT-ViCTSD (Vietnamese Constructive and Toxic Speech Detection dataset)
with 10,000 human-annotated comments. For these tasks, we propose a system for
constructive and toxic speech detection with the state-of-the-art transfer
learning model in Vietnamese NLP as PhoBERT. With this system, we obtain
F1-scores of 78.59% and 59.40% for classifying constructive and toxic comments,
respectively. Besides, we implement various baseline models as traditional
Machine Learning and Deep Neural Network-Based models to evaluate the dataset.
With the results, we can solve several tasks on the online discussions and
develop the framework for identifying constructiveness and toxicity of
Vietnamese social media comments automatically.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What's in your Head? Emergent Behaviour in Multi-Task Transformer Models. (arXiv:2104.06129v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06129">
<div class="article-summary-box-inner">
<span><p>The primary paradigm for multi-task training in natural language processing
is to represent the input with a shared pre-trained language model, and add a
small, thin network (head) per task. Given an input, a target head is the head
that is selected for outputting the final prediction. In this work, we examine
the behaviour of non-target heads, that is, the output of heads when given
input that belongs to a different task than the one they were trained for. We
find that non-target heads exhibit emergent behaviour, which may either explain
the target task, or generalize beyond their original task. For example, in a
numerical reasoning task, a span extraction head extracts from the input the
arguments to a computation that results in a number generated by a target
generative head. In addition, a summarization head that is trained with a
target question answering head, outputs query-based summaries when given a
question and a context from which the answer is to be extracted. This emergent
behaviour suggests that multi-task training leads to non-trivial extrapolation
of skills, which can be harnessed for interpretability and generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Planning with Learned Entity Prompts for Abstractive Summarization. (arXiv:2104.07606v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07606">
<div class="article-summary-box-inner">
<span><p>We introduce a simple but flexible mechanism to learn an intermediate plan to
ground the generation of abstractive summaries. Specifically, we prepend (or
prompt) target summaries with entity chains -- ordered sequences of entities
mentioned in the summary. Transformer-based sequence-to-sequence models are
then trained to generate the entity chain and then continue generating the
summary conditioned on the entity chain and the input. We experimented with
both pretraining and finetuning with this content planning objective. When
evaluated on CNN/DailyMail, XSum, SAMSum and BillSum, we demonstrate
empirically that the grounded generation with the planning objective improves
entity specificity and planning in summaries for all datasets, and achieves
state-of-the-art performance on XSum and SAMSum in terms of Rouge. Moreover, we
demonstrate empirically that planning with entity chains provides a mechanism
to control hallucinations in abstractive summaries. By prompting the decoder
with a modified content plan that drops hallucinated entities, we outperform
state-of-the-art approaches for faithfulness when evaluated automatically and
by humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Masked Segmental Language Model for Unsupervised Natural Language Segmentation. (arXiv:2104.07829v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07829">
<div class="article-summary-box-inner">
<span><p>Segmentation remains an important preprocessing step both in languages where
"words" or other important syntactic/semantic units (like morphemes) are not
clearly delineated by white space, as well as when dealing with continuous
speech data, where there is often no meaningful pause between words.
Near-perfect supervised methods have been developed for use in resource-rich
languages such as Chinese, but many of the world's languages are both
morphologically complex, and have no large dataset of "gold" segmentations into
meaningful units. To solve this problem, we propose a new type of Segmental
Language Model (Sun and Deng, 2018; Kawakami et al., 2019; Wang et al., 2021)
for use in both unsupervised and lightly supervised segmentation tasks. We
introduce a Masked Segmental Language Model (MSLM) built on a span-masking
transformer architecture, harnessing the power of a bi-directional masked
modeling context and attention. In a series of experiments, our model
consistently outperforms Recurrent SLMs on Chinese (PKU Corpus) in segmentation
quality, and performs similarly to the Recurrent model on English (PTB). We
conclude by discussing the different challenges posed in segmenting
phonemic-type writing systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Matching-oriented Product Quantization For Ad-hoc Retrieval. (arXiv:2104.07858v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07858">
<div class="article-summary-box-inner">
<span><p>Product quantization (PQ) is a widely used technique for ad-hoc retrieval.
Recent studies propose supervised PQ, where the embedding and quantization
models can be jointly trained with supervised learning. However, there is a
lack of appropriate formulation of the joint training objective; thus, the
improvements over previous non-supervised baselines are limited in reality. In
this work, we propose the Matching-oriented Product Quantization (MoPQ), where
a novel objective Multinoulli Contrastive Loss (MCL) is formulated. With the
minimization of MCL, we are able to maximize the matching probability of query
and ground-truth key, which contributes to the optimal retrieval accuracy.
Given that the exact computation of MCL is intractable due to the demand of
vast contrastive samples, we further propose the Differentiable Cross-device
Sampling (DCS), which significantly augments the contrastive samples for
precise approximation of MCL. We conduct extensive experimental studies on four
real-world datasets, whose results verify the effectiveness of MoPQ.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Task Generalization via Natural Language Crowdsourcing Instructions. (arXiv:2104.08773v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08773">
<div class="article-summary-box-inner">
<span><p>Humans (e.g., crowdworkers) have a remarkable ability in solving different
tasks, by simply reading textual instructions that define them and looking at a
few examples. NLP models built with the conventional paradigm, however, often
struggle with generalization across tasks (e.g., a question-answering system
cannot solve classification tasks). A long-standing challenge in AI is to build
a model that is equipped with the understanding of human-readable instructions
that define the tasks, and can generalize to new tasks. To study this, we
introduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their
human-authored instructions and 193k task instances. The instructions are
obtained from crowdsourcing instructions used to collect existing NLP datasets
and mapped to a unified schema. We adopt generative pre-trained language models
to encode task-specific instructions along with input and generate task output.
Our results indicate that models can benefit from instructions to generalize
across tasks. These models, however, are far behind supervised task-specific
models, indicating significant room for more progress in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An automated domain-independent text reading, interpreting and extracting approach for reviewing the scientific literature. (arXiv:2107.14638v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14638">
<div class="article-summary-box-inner">
<span><p>It is presented here a machine learning-based (ML) natural language
processing (NLP) approach capable to automatically recognize and extract
categorical and numerical parameters from a corpus of articles. The approach
(named a.RIX) operates with a concomitant/interchangeable use of ML models such
as neuron networks (NNs), latent semantic analysis (LSA), naive-Bayes
classifiers (NBC), and a pattern recognition model using regular expression
(REGEX). A corpus of 7,873 scientific articles dealing with natural products
(NPs) was used to demonstrate the efficiency of the a.RIX engine. The engine
automatically extracts categorical and numerical parameters such as (i) the
plant species from which active molecules are extracted, (ii) the
microorganisms species for which active molecules can act against, and (iii)
the values of minimum inhibitory concentration (MIC) against these
microorganisms. The parameters are extracted without part-of-speech tagging
(POS) and named entity recognition (NER) approaches (i.e. without the need of
text annotation), and the models training is performed with unsupervised
approaches. In this way, a.RIX can be essentially used on articles from any
scientific field. Finally, it can potentially make obsolete the current article
reviewing process in some areas, especially those in which machine learning
models capture texts structure, text semantics, and latent knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Opinion Prediction with User Fingerprinting. (arXiv:2108.00270v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00270">
<div class="article-summary-box-inner">
<span><p>Opinion prediction is an emerging research area with diverse real-world
applications, such as market research and situational awareness. We identify
two lines of approaches to the problem of opinion prediction. One uses
topic-based sentiment analysis with time-series modeling, while the other uses
static embedding of text. The latter approaches seek user-specific solutions by
generating user fingerprints. Such approaches are useful in predicting user's
reactions to unseen content. In this work, we propose a novel dynamic
fingerprinting method that leverages contextual embedding of user's comments
conditioned on relevant user's reading history. We integrate BERT variants with
a recurrent neural network to generate predictions. The results show up to 13\%
improvement in micro F1-score compared to previous approaches. Experimental
results show novel insights that were previously unknown such as better
predictions for an increase in dynamic history length, the impact of the nature
of the article on performance, thereby laying the foundation for further
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating harm in language models with conditional-likelihood filtration. (arXiv:2108.07790v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07790">
<div class="article-summary-box-inner">
<span><p>Language models trained on large-scale unfiltered datasets curated from the
open web acquire systemic biases, prejudices, and harmful views from their
training data. We present a methodology for programmatically identifying and
removing harmful text from web-scale datasets. A pretrained language model is
used to calculate the log-likelihood of researcher-written trigger phrases
conditioned on a specific document, which is used to identify and filter
documents from the dataset. We demonstrate that models trained on this filtered
dataset exhibit lower propensity to generate harmful text, with a marginal
decrease in performance on standard language modeling benchmarks compared to
unfiltered baselines. We provide a partial explanation for this performance gap
by surfacing examples of hate speech and other undesirable content from
standard language modeling benchmarks. Finally, we discuss the generalization
of this method and how trigger phrases which reflect specific values can be
used by researchers to build language models which are more closely aligned
with their values.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query Attribute Value Extraction. (arXiv:2108.08468v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08468">
<div class="article-summary-box-inner">
<span><p>We study the problem of query attribute value extraction, which aims to
identify named entities from user queries as diverse surface form attribute
values and afterward transform them into formally canonical forms. Such a
problem consists of two phases: {named entity recognition (NER)} and {attribute
value normalization (AVN)}. However, existing works only focus on the NER phase
but neglect equally important AVN. To bridge this gap, this paper proposes a
unified query attribute value extraction system in e-commerce search named
QUEACO, which involves both two phases. Moreover, by leveraging large-scale
weakly-labeled behavior data, we further improve the extraction performance
with less supervision cost. Specifically, for the NER phase, QUEACO adopts a
novel teacher-student network, where a teacher network that is trained on the
strongly-labeled data generates pseudo-labels to refine the weakly-labeled data
for training a student network. Meanwhile, the teacher network can be
dynamically adapted by the feedback of the student's performance on
strongly-labeled data to maximally denoise the noisy supervisions from the weak
labels. For the AVN phase, we also leverage the weakly-labeled
query-to-attribute behavior data to normalize surface form attribute values
from queries into canonical forms from products. Extensive experiments on a
real-world large-scale E-commerce dataset demonstrate the effectiveness of
QUEACO.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fastformer: Additive Attention Can Be All You Need. (arXiv:2108.09084v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09084">
<div class="article-summary-box-inner">
<span><p>Transformer is a powerful model for text understanding. However, it is
inefficient due to its quadratic complexity to input sequence length. Although
there are many methods on Transformer acceleration, they are still either
inefficient on long sequences or not effective enough. In this paper, we
propose Fastformer, which is an efficient Transformer model based on additive
attention. In Fastformer, instead of modeling the pair-wise interactions
between tokens, we first use additive attention mechanism to model global
contexts, and then further transform each token representation based on its
interaction with global context representations. In this way, Fastformer can
achieve effective context modeling with linear complexity. Extensive
experiments on five datasets show that Fastformer is much more efficient than
many existing Transformer models and can meanwhile achieve comparable or even
better long text modeling performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation Extraction from Tables using Artificially Generated Metadata. (arXiv:2108.10750v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10750">
<div class="article-summary-box-inner">
<span><p>Relation Extraction (RE) from tables is the task of identifying relations
between pairs of columns of a table. Generally, RE models for this task require
labelled tables for training. These labelled tables can also be generated
artificially from a Knowledge Graph (KG), which makes the cost to acquire them
much lower in comparison to manual annotations. However, unlike real tables,
these synthetic tables lack associated metadata, such as, column-headers,
captions, etc; this is because synthetic tables are created out of KGs that do
not store such metadata. Meanwhile, previous works have shown that metadata is
important for accurate RE from tables. To address this issue, we propose
methods to artificially create some of this metadata for synthetic tables.
Afterward, we experiment with a BERT-based model, in line with recently
published works, that takes as input a combination of proposed artificial
metadata and table content. Our empirical results show that this leads to an
improvement of 9\%-45\% in F1 score, in absolute terms, over 2 tabular
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12202">
<div class="article-summary-box-inner">
<span><p>In joint entity and relation extraction, existing work either sequentially
encode task-specific features, leading to an imbalance in inter-task feature
interaction where features extracted later have no direct contact with those
that come first. Or they encode entity features and relation features in a
parallel manner, meaning that feature representation learning for each task is
largely independent of each other except for input sharing. We propose a
partition filter network to model two-way interaction between tasks properly,
where feature encoding is decomposed into two steps: partition and filter. In
our encoder, we leverage two gates: entity and relation gate, to segment
neurons into two task partitions and one shared partition. The shared partition
represents inter-task information valuable to both tasks and is evenly shared
across two tasks to ensure proper two-way interaction. The task partitions
represent intra-task information and are formed through concerted efforts of
both gates, making sure that encoding of task-specific features is dependent
upon each other. Experiment results on six public datasets show that our model
performs significantly better than previous approaches. In addition, contrary
to what previous work claims, our auxiliary experiments suggest that relation
prediction is contributory to named entity prediction in a non-negligible way.
The source code can be found at https://github.com/Coopercoppers/PFN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CSDS: A Fine-Grained Chinese Dataset for Customer Service Dialogue Summarization. (arXiv:2108.13139v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13139">
<div class="article-summary-box-inner">
<span><p>Dialogue summarization has drawn much attention recently. Especially in the
customer service domain, agents could use dialogue summaries to help boost
their works by quickly knowing customer's issues and service progress. These
applications require summaries to contain the perspective of a single speaker
and have a clear topic flow structure, while neither are available in existing
datasets. Therefore, in this paper, we introduce a novel Chinese dataset for
Customer Service Dialogue Summarization (CSDS). CSDS improves the abstractive
summaries in two aspects: (1) In addition to the overall summary for the whole
dialogue, role-oriented summaries are also provided to acquire different
speakers' viewpoints. (2) All the summaries sum up each topic separately, thus
containing the topic-level structure of the dialogue. We define tasks in CSDS
as generating the overall summary and different role-oriented summaries for a
given dialogue. Next, we compare various summarization methods on CSDS, and
experiment results show that existing methods are prone to generate redundant
and incoherent summaries. Besides, the performance becomes much worse when
analyzing the performance on role-oriented summaries and topic structures. We
hope that this study could benchmark Chinese dialogue summarization and benefit
further studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Retriever-Reader Meets Scenario-Based Multiple-Choice Questions. (arXiv:2108.13875v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13875">
<div class="article-summary-box-inner">
<span><p>Scenario-based question answering (SQA) requires retrieving and reading
paragraphs from a large corpus to answer a question which is contextualized by
a long scenario description. Since a scenario contains both keyphrases for
retrieval and much noise, retrieval for SQA is extremely difficult. Moreover,
it can hardly be supervised due to the lack of relevance labels of paragraphs
for SQA. To meet the challenge, in this paper we propose a joint
retriever-reader model called JEEVES where the retriever is implicitly
supervised only using QA labels via a novel word weighting mechanism. JEEVES
significantly outperforms a variety of strong baselines on multiple-choice
questions in three SQA datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M^2-MedDialog: A Dataset and Benchmarks for Multi-domain Multi-service Medical Dialogues. (arXiv:2109.00430v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00430">
<div class="article-summary-box-inner">
<span><p>Medical dialogue systems (MDSs) aim to assist doctors and patients with a
range of professional medical services, i.e., diagnosis, consultation, and
treatment. However, one-stop MDS is still unexplored because: (1) no dataset
has so large-scale dialogues contains both multiple medical services and
fine-grained medical labels (i.e., intents, slots, values); (2) no model has
addressed a MDS based on multiple-service conversations in a unified framework.
In this work, we first build a Multiple-domain Multiple-service medical
dialogue (M^2-MedDialog)dataset, which contains 1,557 conversations between
doctors and patients, covering 276 types of diseases, 2,468 medical entities,
and 3 specialties of medical services. To the best of our knowledge, it is the
only medical dialogue dataset that includes both multiple medical services and
fine-grained medical labels. Then, we formulate a one-stop MDS as a
sequence-to-sequence generation problem. We unify a MDS with causal language
modeling and conditional causal language modeling, respectively. Specifically,
we employ several pretrained models (i.e., BERT-WWM, BERT-MED, GPT2, and MT5)
and their variants to get benchmarks on M^2-MedDialog dataset. We also propose
pseudo labeling and natural perturbation methods to expand M2-MedDialog dataset
and enhance the state-of-the-art pretrained models. We demonstrate the results
achieved by the benchmarks so far through extensive experiments on
M2-MedDialog. We release the dataset, the code, as well as the evaluation
scripts to facilitate future research in this important research direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning. (arXiv:2109.00840v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00840">
<div class="article-summary-box-inner">
<span><p>Though language model text embeddings have revolutionized NLP research, their
ability to capture high-level semantic information, such as relations between
entities in text, is limited. In this paper, we propose a novel contrastive
learning framework that trains sentence embeddings to encode the relations in a
graph structure. Given a sentence (unstructured text) and its graph, we use
contrastive learning to impose relation-related structure on the token-level
representations of the sentence obtained with a CharacterBERT (El Boukkouri et
al.,2020) model. The resulting relation-aware sentence embeddings achieve
state-of-the-art results on the relation extraction task using only a simple
KNN classifier, thereby demonstrating the success of the proposed method.
Additional visualization by a tSNE analysis shows the effectiveness of the
learned representation space compared to baselines. Furthermore, we show that
we can learn a different space for named entity recognition, again using a
contrastive learning objective, and demonstrate how to successfully combine
both representation spaces in an entity-relation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TravelBERT: Pre-training Language Model Incorporating Domain-specific Heterogeneous Knowledge into A Unified Representation. (arXiv:2109.01048v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01048">
<div class="article-summary-box-inner">
<span><p>Existing technologies expand BERT from different perspectives, e.g. designing
different pre-training tasks, different semantic granularities and different
model architectures. Few models consider expanding BERT from different text
formats. In this paper, we propose a heterogeneous knowledge language model
(HKLM), a unified pre-trained language model (PLM) for all forms of text,
including unstructured text, semi-structured text and well-structured text. To
capture the corresponding relations among these multi-format knowledge, our
approach uses masked language model objective to learn word knowledge, uses
triple classification objective and title matching objective to learn entity
knowledge and topic knowledge respectively. To obtain the aforementioned
multi-format text, we construct a corpus in the tourism domain and conduct
experiments on 5 tourism NLP datasets. The results show that our approach
outperforms the pre-training of plain text using only 1/4 of the data. The
code, datasets, corpus and knowledge graph will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextualized Embeddings based Convolutional Neural Networks for Duplicate Question Identification. (arXiv:2109.01560v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01560">
<div class="article-summary-box-inner">
<span><p>Question Paraphrase Identification (QPI) is a critical task for large-scale
Question-Answering forums. The purpose of QPI is to determine whether a given
pair of questions are semantically identical or not. Previous approaches for
this task have yielded promising results, but have often relied on complex
recurrence mechanisms that are expensive and time-consuming in nature. In this
paper, we propose a novel architecture combining a Bidirectional Transformer
Encoder with Convolutional Neural Networks for the QPI task. We produce the
predictions from the proposed architecture using two different inference
setups: Siamese and Matched Aggregation. Experimental results demonstrate that
our model achieves state-of-the-art performance on the Quora Question Pairs
dataset. We empirically prove that the addition of convolution layers to the
model architecture improves the results in both inference setups. We also
investigate the impact of partial and complete fine-tuning and analyze the
trade-off between computational power and accuracy in the process. Based on the
obtained results, we conclude that the Matched-Aggregation setup consistently
outperforms the Siamese setup. Our work provides insights into what
architecture combinations and setups are likely to produce better results for
the QPI task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Handwritten Character Recognition of South Indian Scripts: A Review. (arXiv:1106.0107v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1106.0107">
<div class="article-summary-box-inner">
<span><p>Handwritten character recognition is always a frontier area of research in
the field of pattern recognition and image processing and there is a large
demand for OCR on hand written documents. Even though, sufficient studies have
performed in foreign scripts like Chinese, Japanese and Arabic characters, only
a very few work can be traced for handwritten character recognition of Indian
scripts especially for the South Indian scripts. This paper provides an
overview of offline handwritten character recognition in South Indian Scripts,
namely Malayalam, Tamil, Kannada and Telungu.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Separable Attention for Multi-Contrast MR Image Super-Resolution. (arXiv:2109.01664v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01664">
<div class="article-summary-box-inner">
<span><p>Super-resolving the Magnetic Resonance (MR) image of a target contrast under
the guidance of the corresponding auxiliary contrast, which provides additional
anatomical information, is a new and effective solution for fast MR imaging.
However, current multi-contrast super-resolution (SR) methods tend to
concatenate different contrasts directly, ignoring their relationships in
different clues, \eg, in the foreground and background. In this paper, we
propose a separable attention network (comprising a foreground priority
attention and background separation attention), named SANet. Our method can
explore the foreground and background areas in the forward and reverse
directions with the help of the auxiliary contrast, enabling it to learn
clearer anatomical structures and edge information for the SR of a
target-contrast MR image. SANet provides three appealing benefits: (1) It is
the first model to explore a separable attention mechanism that uses the
auxiliary contrast to predict the foreground and background regions, diverting
more attention to refining any uncertain details between these regions and
correcting the fine areas in the reconstructed results. (2) A multi-stage
integration module is proposed to learn the response of multi-contrast fusion
at different stages, obtain the dependency between the fused features, and
improve their representation ability. (3) Extensive experiments with various
state-of-the-art multi-contrast SR methods on fastMRI and clinical \textit{in
vivo} datasets demonstrate the superiority of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Reliable Are Out-of-Distribution Generalization Methods for Medical Image Segmentation?. (arXiv:2109.01668v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01668">
<div class="article-summary-box-inner">
<span><p>The recent achievements of Deep Learning rely on the test data being similar
in distribution to the training data. In an ideal case, Deep Learning models
would achieve Out-of-Distribution (OoD) Generalization, i.e. reliably make
predictions on out-of-distribution data. Yet in practice, models usually fail
to generalize well when facing a shift in distribution. Several methods were
thereby designed to improve the robustness of the features learned by a model
through Regularization- or Domain-Prediction-based schemes. Segmenting medical
images such as MRIs of the hippocampus is essential for the diagnosis and
treatment of neuropsychiatric disorders. But these brain images often suffer
from distribution shift due to the patient's age and various pathologies
affecting the shape of the organ. In this work, we evaluate OoD Generalization
solutions for the problem of hippocampus segmentation in MR data using both
fully- and semi-supervised training. We find that no method performs reliably
in all experiments. Only the V-REx loss stands out as it remains easy to tune,
while it outperforms a standard U-Net in most cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Few-Shot Segmentation Via Meta-Learning. (arXiv:2109.01693v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01693">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation is a classic computer vision task with multiple
applications, which includes medical and remote sensing image analysis. Despite
recent advances with deep-based approaches, labeling samples (pixels) for
training models is laborious and, in some cases, unfeasible. In this paper, we
present two novel meta learning methods, named WeaSeL and ProtoSeg, for the
few-shot semantic segmentation task with sparse annotations. We conducted
extensive evaluation of the proposed methods in different applications (12
datasets) in medical imaging and agricultural remote sensing, which are very
distinct fields of knowledge and usually subject to data scarcity. The results
demonstrated the potential of our method, achieving suitable results for
segmenting both coffee/orange crops and anatomical parts of the human body in
comparison with full dense annotation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting 3D ResNets for Video Recognition. (arXiv:2109.01696v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01696">
<div class="article-summary-box-inner">
<span><p>A recent work from Bello shows that training and scaling strategies may be
more significant than model architectures for visual recognition. This short
note studies effective training and scaling strategies for video recognition
models. We propose a simple scaling strategy for 3D ResNets, in combination
with improved training strategies and minor architectural changes. The
resulting models, termed 3D ResNet-RS, attain competitive performance of 81.0
on Kinetics-400 and 83.8 on Kinetics-600 without pre-training. When pre-trained
on a large Web Video Text dataset, our best model achieves 83.5 and 84.3 on
Kinetics-400 and Kinetics-600. The proposed scaling rule is further evaluated
in a self-supervised setup using contrastive learning, demonstrating improved
performance. Code is available at:
https://github.com/tensorflow/models/tree/master/official.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Accurate Alignment in Real-time 3D Hand-Mesh Reconstruction. (arXiv:2109.01723v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01723">
<div class="article-summary-box-inner">
<span><p>3D hand-mesh reconstruction from RGB images facilitates many applications,
including augmented reality (AR). However, this requires not only real-time
speed and accurate hand pose and shape but also plausible mesh-image alignment.
While existing works already achieve promising results, meeting all three
requirements is very challenging. This paper presents a novel pipeline by
decoupling the hand-mesh reconstruction task into three stages: a joint stage
to predict hand joints and segmentation; a mesh stage to predict a rough hand
mesh; and a refine stage to fine-tune it with an offset mesh for mesh-image
alignment. With careful design in the network structure and in the loss
functions, we can promote high-quality finger-level mesh-image alignment and
drive the models together to deliver real-time predictions. Extensive
quantitative and qualitative results on benchmark datasets demonstrate that the
quality of our results outperforms the state-of-the-art methods on
hand-mesh/pose precision and hand-image alignment. In the end, we also showcase
several real-time AR scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Navigating the Mise-en-Page: Interpretive Machine Learning Approaches to the Visual Layouts of Multi-Ethnic Periodicals. (arXiv:2109.01732v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01732">
<div class="article-summary-box-inner">
<span><p>This paper presents a computational method of analysis that draws from
machine learning, library science, and literary studies to map the visual
layouts of multi-ethnic newspapers from the late 19th and early 20th century
United States. This work departs from prior approaches to newspapers that focus
on individual pieces of textual and visual content. Our method combines
Chronicling America's MARC data and the Newspaper Navigator machine learning
dataset to identify the visual patterns of newspaper page layouts. By analyzing
high-dimensional visual similarity, we aim to better understand how editors
spoke and protested through the layout of their papers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">F3S: Free Flow Fever Screening. (arXiv:2109.01733v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01733">
<div class="article-summary-box-inner">
<span><p>Identification of people with elevated body temperature can reduce or
dramatically slow down the spread of infectious diseases like COVID-19. We
present a novel fever-screening system, F3S, that uses edge machine learning
techniques to accurately measure core body temperatures of multiple individuals
in a free-flow setting. F3S performs real-time sensor fusion of visual camera
with thermal camera data streams to detect elevated body temperature, and it
has several unique features: (a) visual and thermal streams represent very
different modalities, and we dynamically associate semantically-equivalent
regions across visual and thermal frames by using a new, dynamic alignment
technique that analyzes content and context in real-time, (b) we track people
through occlusions, identify the eye (inner canthus), forehead, face and head
regions where possible, and provide an accurate temperature reading by using a
prioritized refinement algorithm, and (c) we robustly detect elevated body
temperature even in the presence of personal protective equipment like masks,
or sunglasses or hats, all of which can be affected by hot weather and lead to
spurious temperature readings. F3S has been deployed at over a dozen large
commercial establishments, providing contact-less, free-flow, real-time fever
screening for thousands of employees and customers in indoors and outdoor
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A realistic approach to generate masked faces applied on two novel masked face recognition data sets. (arXiv:2109.01745v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01745">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic raises the problem of adapting face recognition systems
to the new reality, where people may wear surgical masks to cover their noses
and mouths. Traditional data sets (e.g., CelebA, CASIA-WebFace) used for
training these systems were released before the pandemic, so they now seem
unsuited due to the lack of examples of people wearing masks. We propose a
method for enhancing data sets containing faces without masks by creating
synthetic masks and overlaying them on faces in the original images. Our method
relies on Spark AR Studio, a developer program made by Facebook that is used to
create Instagram face filters. In our approach, we use 9 masks of different
colors, shapes and fabrics. We employ our method to generate a number of
445,446 (90%) samples of masks for the CASIA-WebFace data set and 196,254
(96.8%) masks for the CelebA data set, releasing the mask images at
https://github.com/securifai/masked_faces. We show that our method produces
significantly more realistic training examples of masks overlaid on faces by
asking volunteers to qualitatively compare it to other methods or data sets
designed for the same task. We also demonstrate the usefulness of our method by
evaluating state-of-the-art face recognition systems (FaceNet, VGG-face,
ArcFace) trained on the enhanced data sets and showing that they outperform
equivalent systems trained on the original data sets (containing faces without
masks), when the test benchmark contains masked faces.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CodeNeRF: Disentangled Neural Radiance Fields for Object Categories. (arXiv:2109.01750v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01750">
<div class="article-summary-box-inner">
<span><p>CodeNeRF is an implicit 3D neural representation that learns the variation of
object shapes and textures across a category and can be trained, from a set of
posed images, to synthesize novel views of unseen objects. Unlike the original
NeRF, which is scene specific, CodeNeRF learns to disentangle shape and texture
by learning separate embeddings. At test time, given a single unposed image of
an unseen object, CodeNeRF jointly estimates camera viewpoint, and shape and
appearance codes via optimization. Unseen objects can be reconstructed from a
single image, and then rendered from new viewpoints or their shape and texture
edited by varying the latent codes. We conduct experiments on the SRN
benchmark, which show that CodeNeRF generalises well to unseen objects and
achieves on-par performance with methods that require known camera pose at test
time. Our results on real-world images demonstrate that CodeNeRF can bridge the
sim-to-real gap. Project page: \url{https://github.com/wayne1123/code-nerf}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seam Carving Detection and Localization using Two-Stage Deep Neural Networks. (arXiv:2109.01764v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01764">
<div class="article-summary-box-inner">
<span><p>Seam carving is a method to resize an image in a content aware fashion.
However, this method can also be used to carve out objects from images. In this
paper, we propose a two-step method to detect and localize seam carved images.
First, we build a detector to detect small patches in an image that has been
seam carved. Next, we compute a heatmap on an image based on the patch
detector's output. Using these heatmaps, we build another detector to detect if
a whole image is seam carved or not. Our experimental results show that our
approach is effective in detecting and localizing seam carved images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">To be Critical: Self-Calibrated Weakly Supervised Learning for Salient Object Detection. (arXiv:2109.01770v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01770">
<div class="article-summary-box-inner">
<span><p>Weakly-supervised salient object detection (WSOD) aims to develop saliency
models using image-level annotations. Despite of the success of previous works,
explorations on an effective training strategy for the saliency network and
accurate matches between image-level annotations and salient objects are still
inadequate. In this work, 1) we propose a self-calibrated training strategy by
explicitly establishing a mutual calibration loop between pseudo labels and
network predictions, liberating the saliency network from error-prone
propagation caused by pseudo labels. 2) we prove that even a much smaller
dataset (merely 1.8% of ImageNet) with well-matched annotations can facilitate
models to achieve better performance as well as generalizability. This sheds
new light on the development of WSOD and encourages more contributions to the
community. Comprehensive experiments demonstrate that our method outperforms
all the existing WSOD methods by adopting the self-calibrated strategy only.
Steady improvements are further achieved by training on the proposed dataset.
Additionally, our method achieves 94.7% of the performance of fully-supervised
methods on average. And what is more, the fully supervised models adopting our
predicted results as "ground truths" achieve successful results (95.6% for
BASNet and 97.3% for ITSD on F-measure), while costing only 0.32% of labeling
time for pixel-level annotation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PR-Net: Preference Reasoning for Personalized Video Highlight Detection. (arXiv:2109.01799v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01799">
<div class="article-summary-box-inner">
<span><p>Personalized video highlight detection aims to shorten a long video to
interesting moments according to a user's preference, which has recently raised
the community's attention. Current methods regard the user's history as
holistic information to predict the user's preference but negating the inherent
diversity of the user's interests, resulting in vague preference
representation. In this paper, we propose a simple yet efficient preference
reasoning framework (PR-Net) to explicitly take the diverse interests into
account for frame-level highlight prediction. Specifically, distinct
user-specific preferences for each input query frame are produced, presented as
the similarity weighted sum of history highlights to the corresponding query
frame. Next, distinct comprehensive preferences are formed by the user-specific
preferences and a learnable generic preference for more overall highlight
measurement. Lastly, the degree of highlight and non-highlight for each query
frame is calculated as semantic similarity to its comprehensive and
non-highlight preferences, respectively. Besides, to alleviate the ambiguity
due to the incomplete annotation, a new bi-directional contrastive loss is
proposed to ensure a compact and differentiable metric space. In this way, our
method significantly outperforms state-of-the-art methods with a relative
improvement of 12% in mean accuracy precision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Approach for UAV Small Object Detection with Simulation-based Transfer Learning and Adaptive Fusion. (arXiv:2109.01800v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01800">
<div class="article-summary-box-inner">
<span><p>Precisely detection of Unmanned Aerial Vehicles(UAVs) plays a critical role
in UAV defense systems. Deep learning is widely adopted for UAV object
detection whereas researches on this topic are limited by the amount of dataset
and small scale of UAV. To tackle these problems, a novel comprehensive
approach that combines transfer learning based on simulation data and adaptive
fusion is proposed. Firstly, the open-source plugin AirSim proposed by
Microsoft is used to generate mass realistic simulation data. Secondly,
transfer learning is applied to obtain a pre-trained YOLOv5 model on the
simulated dataset and fine-tuned model on the real-world dataset. Finally, an
adaptive fusion mechanism is proposed to further improve small object detection
performance. Experiment results demonstrate the effectiveness of
simulation-based transfer learning which leads to a 2.7% performance increase
on UAV object detection. Furthermore, with transfer learning and adaptive
fusion mechanism, 7.1% improvement is achieved compared to the original YOLO v5
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Transfer Learning for Event-based End-task Prediction via Pluggable Event to Image Translation. (arXiv:2109.01801v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01801">
<div class="article-summary-box-inner">
<span><p>Event cameras are novel sensors that perceive the per-pixel intensity changes
and output asynchronous event streams with high dynamic range and less motion
blur. It has been shown that events alone can be used for end-task learning,
\eg, semantic segmentation, based on encoder-decoder-like networks. However, as
events are sparse and mostly reflect edge information, it is difficult to
recover original details merely relying on the decoder. Moreover, most methods
resort to pixel-wise loss alone for supervision, which might be insufficient to
fully exploit the visual details from sparse events, thus leading to less
optimal performance. In this paper, we propose a simple yet flexible two-stream
framework named Dual Transfer Learning (DTL) to effectively enhance the
performance on the end-tasks without adding extra inference cost. The proposed
approach consists of three parts: event to end-task learning (EEL) branch,
event to image translation (EIT) branch, and transfer learning (TL) module that
simultaneously explores the feature-level affinity information and pixel-level
knowledge from the EIT branch to improve the EEL branch. This simple yet novel
method leads to strong representation learning from events and is evidenced by
the significant performance boost on the end-tasks such as semantic
segmentation and depth estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stimuli-Aware Visual Emotion Analysis. (arXiv:2109.01812v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01812">
<div class="article-summary-box-inner">
<span><p>Visual emotion analysis (VEA) has attracted great attention recently, due to
the increasing tendency of expressing and understanding emotions through images
on social networks. Different from traditional vision tasks, VEA is inherently
more challenging since it involves a much higher level of complexity and
ambiguity in human cognitive process. Most of the existing methods adopt deep
learning techniques to extract general features from the whole image,
disregarding the specific features evoked by various emotional stimuli.
Inspired by the \textit{Stimuli-Organism-Response (S-O-R)} emotion model in
psychological theory, we proposed a stimuli-aware VEA method consisting of
three stages, namely stimuli selection (S), feature extraction (O) and emotion
prediction (R). First, specific emotional stimuli (i.e., color, object, face)
are selected from images by employing the off-the-shelf tools. To the best of
our knowledge, it is the first time to introduce stimuli selection process into
VEA in an end-to-end network. Then, we design three specific networks, i.e.,
Global-Net, Semantic-Net and Expression-Net, to extract distinct emotional
features from different stimuli simultaneously. Finally, benefiting from the
inherent structure of Mikel's wheel, we design a novel hierarchical
cross-entropy loss to distinguish hard false examples from easy ones in an
emotion-specific manner. Experiments demonstrate that the proposed method
consistently outperforms the state-of-the-art approaches on four public visual
emotion datasets. Ablation study and visualizations further prove the validity
and interpretability of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RiWNet: A moving object instance segmentation Network being Robust in adverse Weather conditions. (arXiv:2109.01820v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01820">
<div class="article-summary-box-inner">
<span><p>Segmenting each moving object instance in a scene is essential for many
applications. But like many other computer vision tasks, this task performs
well in optimal weather, but then adverse weather tends to fail. To be robust
in weather conditions, the usual way is to train network in data of given
weather pattern or to fuse multiple sensors. We focus on a new possibility,
that is, to improve its resilience to weather interference through the
network's structural design. First, we propose a novel FPN structure called
RiWFPN with a progressive top-down interaction and attention refinement module.
RiWFPN can directly replace other FPN structures to improve the robustness of
the network in non-optimal weather conditions. Then we extend SOLOV2 to capture
temporal information in video to learn motion information, and propose a moving
object instance segmentation network with RiWFPN called RiWNet. Finally, in
order to verify the effect of moving instance segmentation in different weather
disturbances, we propose a VKTTI-moving dataset which is a moving instance
segmentation dataset based on the VKTTI dataset, taking into account different
weather scenes such as rain, fog, sunset, morning as well as overcast. The
experiment proves how RiWFPN improves the network's resilience to adverse
weather effects compared to other FPN structures. We compare RiWNet to several
other state-of-the-art methods in some challenging datasets, and RiWNet shows
better performance especially under adverse weather conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-View Spatial-Temporal Graph Convolutional Networks with Domain Generalization for Sleep Stage Classification. (arXiv:2109.01824v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01824">
<div class="article-summary-box-inner">
<span><p>Sleep stage classification is essential for sleep assessment and disease
diagnosis. Although previous attempts to classify sleep stages have achieved
high classification performance, several challenges remain open: 1) How to
effectively utilize time-varying spatial and temporal features from
multi-channel brain signals remains challenging. Prior works have not been able
to fully utilize the spatial topological information among brain regions. 2)
Due to the many differences found in individual biological signals, how to
overcome the differences of subjects and improve the generalization of deep
neural networks is important. 3) Most deep learning methods ignore the
interpretability of the model to the brain. To address the above challenges, we
propose a multi-view spatial-temporal graph convolutional networks (MSTGCN)
with domain generalization for sleep stage classification. Specifically, we
construct two brain view graphs for MSTGCN based on the functional connectivity
and physical distance proximity of the brain regions. The MSTGCN consists of
graph convolutions for extracting spatial features and temporal convolutions
for capturing the transition rules among sleep stages. In addition, attention
mechanism is employed for capturing the most relevant spatial-temporal
information for sleep stage classification. Finally, domain generalization and
MSTGCN are integrated into a unified framework to extract subject-invariant
sleep features. Experiments on two public datasets demonstrate that the
proposed model outperforms the state-of-the-art baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GOHOME: Graph-Oriented Heatmap Output forfuture Motion Estimation. (arXiv:2109.01827v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01827">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose GOHOME, a method leveraging graph representations
of the High Definition Map and sparse projections to generate a heatmap output
representing the future position probability distribution for a given agent in
a traffic scene. This heatmap output yields an unconstrained 2D grid
representation of agent future possible locations, allowing inherent
multimodality and a measure of the uncertainty of the prediction. Our
graph-oriented model avoids the high computation burden of representing the
surrounding context as squared images and processing it with classical CNNs,
but focuses instead only on the most probable lanes where the agent could end
up in the immediate future. GOHOME reaches 3$rd$ on Argoverse Motion
Forecasting Benchmark on the MissRate$_6$ metric while achieving significant
speed-up and memory burden diminution compared to 1$^{st}$ place method HOME.
We also highlight that heatmap output enables multimodal ensembling and improve
1$^{st}$ place MissRate$_6$ by more than 15$\%$ with our best ensemble.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OCTAVA: an open-source toolbox for quantitative analysis of optical coherence tomography angiography images. (arXiv:2109.01835v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01835">
<div class="article-summary-box-inner">
<span><p>Optical coherence tomography angiography (OCTA) performs non-invasive
visualization and characterization of microvasculature in research and clinical
applications mainly in ophthalmology and dermatology. A wide variety of
instruments, imaging protocols, processing methods and metrics have been used
to describe the microvasculature, such that comparing different study outcomes
is currently not feasible. With the goal of contributing to standardization of
OCTA data analysis, we report a user-friendly, open-source toolbox, OCTAVA
(OCTA Vascular Analyzer), to automate the pre-processing, segmentation, and
quantitative analysis of en face OCTA maximum intensity projection images in a
standardized workflow. We present each analysis step, including optimization of
filtering and choice of segmentation algorithm, and definition of metrics. We
perform quantitative analysis of OCTA images from different commercial and
non-commercial instruments and samples and show OCTAVA can accurately and
reproducibly determine metrics for characterization of microvasculature. Wide
adoption could enable studies and aggregation of data on a scale sufficient to
develop reliable microvascular biomarkers for early detection, and to guide
treatment, of microvascular disease.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAMA: A Rapid Multicut Algorithm on GPU. (arXiv:2109.01838v1 [cs.DC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01838">
<div class="article-summary-box-inner">
<span><p>We propose a highly parallel primal-dual algorithm for the multicut (a.k.a.
correlation clustering) problem, a classical graph clustering problem widely
used in machine learning and computer vision. Our algorithm consists of three
steps executed recursively: (1) Finding conflicted cycles that correspond to
violated inequalities of the underlying multicut relaxation, (2) Performing
message passing between the edges and cycles to optimize the Lagrange
relaxation coming from the found violated cycles producing reduced costs and
(3) Contracting edges with high reduced costs through matrix-matrix
multiplications.
</p>
<p>Our algorithm produces primal solutions and dual lower bounds that estimate
the distance to optimum. We implement our algorithm on GPUs and show resulting
one to two order-of-magnitudes improvements in execution speed without
sacrificing solution quality compared to traditional serial algorithms that run
on CPUs. We can solve very large scale benchmark problems with up to
$\mathcal{O}(10^8)$ variables in a few seconds with small primal-dual gaps. We
make our code available at https://github.com/pawelswoboda/RAMA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Expressive Communication with Internet Memes: A New Multimodal Conversation Dataset and Benchmark. (arXiv:2109.01839v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01839">
<div class="article-summary-box-inner">
<span><p>As a kind of new expression elements, Internet memes are popular and
extensively used in online chatting scenarios since they manage to make
dialogues vivid, moving, and interesting. However, most current dialogue
researches focus on text-only dialogue tasks. In this paper, we propose a new
task named as \textbf{M}eme incorporated \textbf{O}pen-domain \textbf{D}ialogue
(MOD). Compared to previous dialogue tasks, MOD is much more challenging since
it requires the model to understand the multimodal elements as well as the
emotions behind them. To facilitate the MOD research, we construct a
large-scale open-domain multimodal dialogue dataset incorporating abundant
Internet memes into utterances. The dataset consists of $\sim$45K Chinese
conversations with $\sim$606K utterances. Each conversation contains about $13$
utterances with about $4$ Internet memes on average and each utterance equipped
with an Internet meme is annotated with the corresponding emotion. In addition,
we present a simple and effective method, which utilizes a unified generation
network to solve the MOD task. Experimental results demonstrate that our method
trained on the proposed corpus is able to achieve expressive communication
including texts and memes. The corpus and models have been publicly available
at https://github.com/lizekang/DSTC10-MOD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Privacy-Preserving Image Retrieval Scheme Using A Codebook Generated From Independent Plain-Image Dataset. (arXiv:2109.01841v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01841">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a privacy-preserving image-retrieval scheme using a
codebook generated by using a plain-image dataset. Encryption-then-compression
(EtC) images, which were proposed for EtC systems, have been used in
conventional privacy-preserving image-retrieval schemes, in which a codebook is
generated from EtC images uploaded by image owners, and extended SIMPLE
descriptors are then calculated as image descriptors by using the codebook. In
contrast, in the proposed scheme, a codebook is generated from a dataset
independent of uploaded images. The use of an independent dataset enables us
not only to use a codebook that does not require recalculation but also to
constantly provide a high retrieval accuracy. In an experiment, the proposed
scheme is demonstrated to maintain a high retrieval performance, even if
codebooks are generated from a plain image dataset independent of image owners'
encrypted images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On robustness of generative representations against catastrophic forgetting. (arXiv:2109.01844v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01844">
<div class="article-summary-box-inner">
<span><p>Catastrophic forgetting of previously learned knowledge while learning new
tasks is a widely observed limitation of contemporary neural networks. Although
many continual learning methods are proposed to mitigate this drawback, the
main question remains unanswered: what is the root cause of catastrophic
forgetting? In this work, we aim at answering this question by posing and
validating a set of research hypotheses related to the specificity of
representations built internally by neural models. More specifically, we design
a set of empirical evaluations that compare the robustness of representations
in discriminative and generative models against catastrophic forgetting. We
observe that representations learned by discriminative models are more prone to
catastrophic forgetting than their generative counterparts, which sheds new
light on the advantages of developing generative models for continual learning.
Finally, our work opens new research pathways and possibilities to adopt
generative models in continual learning beyond mere replay mechanisms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering. (arXiv:2109.01847v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01847">
<div class="article-summary-box-inner">
<span><p>Implicit neural rendering techniques have shown promising results for novel
view synthesis. However, existing methods usually encode the entire scene as a
whole, which is generally not aware of the object identity and limits the
ability to the high-level editing tasks such as moving or adding furniture. In
this paper, we present a novel neural scene rendering system, which learns an
object-compositional neural radiance field and produces realistic rendering
with editing capability for a clustered and real-world scene. Specifically, we
design a novel two-pathway architecture, in which the scene branch encodes the
scene geometry and appearance, and the object branch encodes each standalone
object conditioned on learnable object activation codes. To survive the
training in heavily cluttered scenes, we propose a scene-guided training
strategy to solve the 3D space ambiguity in the occluded regions and learn
sharp boundaries for each object. Extensive experiments demonstrate that our
system not only achieves competitive performance for static scene novel-view
synthesis, but also produces realistic rendering for object-level editing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting isocitrate dehydrogenase mutationstatus in glioma using structural brain networksand graph neural networks. (arXiv:2109.01854v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01854">
<div class="article-summary-box-inner">
<span><p>Glioma is a common malignant brain tumor that shows distinct survival among
patients. The isocitrate dehydrogenase (IDH) gene mutation status provides
critical diagnostic and prognostic value for glioma and is now accepted as the
standard of care. A non-invasive prediction of IDH mutation based on the
pre-treatment MRI has crucial clinical significance. Machine learning and deep
learning models show reasonable performance in predicting IDH mutation status.
However, most models neglect the systematic brain alterations caused by tumor
invasion, where the infiltration along white matter tracts throughout the brain
is identified as a hallmark of glioma. Structural brain network provides an
effective tool to characterise brain organisation, which could be captured by
the graph neural networks (GNN) for a more accurate prediction of IDH mutation
status.
</p>
<p>Here we propose a method to predict the IDH mutation using GNN, based on the
structural brain network of patients. Specifically, we firstly construct a
network template of healthy subjects, which consists of atlases of edges (white
matter tracts) and nodes (cortical and subcortical brain regions) to provide
regions of interest (ROI). Next, we employ autoencoders to extract the latent
multi-modal MRI features from the ROIs of the edge and node in patients. These
features of edge and node of brain networks are used to train a GNN
architecture in predicting IDH mutation status. The results show that the
proposed method outperforms the baseline models using 3D-CNN and 3D-DenseNet.
In addition, the model interpretation suggests its ability to identify the
tracts infiltrated by tumor and corresponds to clinical prior knowledge. In
conclusion, integrating brain networks with GNN offers a new avenue to study
brain lesions using computational neuroscience and computer vision approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatiotemporal Inconsistency Learning for DeepFake Video Detection. (arXiv:2109.01860v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01860">
<div class="article-summary-box-inner">
<span><p>The rapid development of facial manipulation techniques has aroused public
concerns in recent years. Following the success of deep learning, existing
methods always formulate DeepFake video detection as a binary classification
problem and develop frame-based and video-based solutions. However, little
attention has been paid to capturing the spatial-temporal inconsistency in
forged videos. To address this issue, we term this task as a Spatial-Temporal
Inconsistency Learning (STIL) process and instantiate it into a novel STIL
block, which consists of a Spatial Inconsistency Module (SIM), a Temporal
Inconsistency Module (TIM), and an Information Supplement Module (ISM).
Specifically, we present a novel temporal modeling paradigm in TIM by
exploiting the temporal difference over adjacent frames along with both
horizontal and vertical directions. And the ISM simultaneously utilizes the
spatial information from SIM and temporal information from TIM to establish a
more comprehensive spatial-temporal representation. Moreover, our STIL block is
flexible and could be plugged into existing 2D CNNs. Extensive experiments and
visualizations are presented to demonstrate the effectiveness of our method
against the state-of-the-art competitors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Mitosis Detection Using a Cascade Mask-RCNN Approach With Domain-Specific Residual Cycle-GAN Data Augmentation. (arXiv:2109.01878v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01878">
<div class="article-summary-box-inner">
<span><p>For the MIDOG mitosis detection challenge, we created a cascade algorithm
consisting of a Mask-RCNN detector, followed by a classification ensemble
consisting of ResNet50 and DenseNet201 to refine detected mitotic candidates.
The MIDOG training data consists of 200 frames originating from four scanners,
three of which are annotated for mitotic instances with centroid annotations.
Our main algorithmic choices are as follows: first, to enhance the
generalizability of our detector and classification networks, we use a
state-of-the-art residual Cycle-GAN to transform each scanner domain to every
other scanner domain. During training, we then randomly load, for each image,
one of the four domains. In this way, our networks can learn from the fourth
non-annotated scanner domain even if we don't have annotations for it. Second,
for training the detector network, rather than using centroid-based fixed-size
bounding boxes, we create mitosis-specific bounding boxes. We do this by
manually annotating a small selection of mitoses, training a Mask-RCNN on this
small dataset, and applying it to the rest of the data to obtain full
annotations. We trained the follow-up classification ensemble using only the
challenge-provided positive and hard-negative examples. On the preliminary test
set, the algorithm scores an F1 score of 0.7578, putting us as the second-place
team on the leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Moving Object Detection for Event-based Vision using k-means Clustering. (arXiv:2109.01879v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01879">
<div class="article-summary-box-inner">
<span><p>Moving object detection is a crucial task in computer vision. Event-based
cameras are bio-inspired cameras that work by mimicking the working of the
human eye. These cameras have multiple advantages over conventional frame-based
cameras, like reduced latency, HDR, reduced motion blur during high motion, low
power consumption, etc. However, these advantages come at a high cost, as
event-based cameras are noise sensitive and have low resolution. Moreover, the
task of moving object detection in these cameras is difficult, as event-based
sensors capture only the binary changes in brightness of a scene, lacking
useful visual features like texture and color. In this paper, we investigate
the application of the k-means clustering technique in detecting moving objects
in event-based data. Experimental results in publicly available datasets using
k-means show significant improvement in performance over the state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep learning facilitates fully automated brain image registration of optoacoustic tomography and magnetic resonance imaging. (arXiv:2109.01880v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01880">
<div class="article-summary-box-inner">
<span><p>Multi-spectral optoacoustic tomography (MSOT) is an emerging optical imaging
method providing multiplex molecular and functional information from the rodent
brain. It can be greatly augmented by magnetic resonance imaging (MRI) that
offers excellent soft-tissue contrast and high-resolution brain anatomy.
Nevertheless, registration of multi-modal images remains challenging, chiefly
due to the entirely different image contrast rendered by these modalities.
Previously reported registration algorithms mostly relied on manual
user-dependent brain segmentation, which compromised data interpretation and
accurate quantification. Here we propose a fully automated registration method
for MSOT-MRI multimodal imaging empowered by deep learning. The automated
workflow includes neural network-based image segmentation to generate suitable
masks, which are subsequently registered using an additional neural network.
Performance of the algorithm is showcased with datasets acquired by
cross-sectional MSOT and high-field MRI preclinical scanners. The automated
registration method is further validated with manual and half-automated
registration, demonstrating its robustness and accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Image-Anomaly Mitigation for Autonomous Mobile Robots. (arXiv:2109.01889v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01889">
<div class="article-summary-box-inner">
<span><p>Camera anomalies like rain or dust can severelydegrade image quality and its
related tasks, such as localizationand segmentation. In this work we address
this importantissue by implementing a pre-processing step that can
effectivelymitigate such artifacts in a real-time fashion, thus supportingthe
deployment of autonomous systems with limited computecapabilities. We propose a
shallow generator with aggregation,trained in an adversarial setting to solve
the ill-posed problemof reconstructing the occluded regions. We add an enhancer
tofurther preserve high-frequency details and image colorization.We also
produce one of the largest publicly available datasets1to train our
architecture and use realistic synthetic raindrops toobtain an improved
initialization of the model. We benchmarkour framework on existing datasets and
on our own imagesobtaining state-of-the-art results while enabling real-time
per-formance, with up to 40x faster inference time than existingapproaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust fine-tuning of zero-shot models. (arXiv:2109.01903v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01903">
<div class="article-summary-box-inner">
<span><p>Large pre-trained models such as CLIP offer consistent accuracy across a
range of data distributions when performing zero-shot inference (i.e., without
fine-tuning on a specific dataset). Although existing fine-tuning approaches
substantially improve accuracy in-distribution, they also reduce
out-of-distribution robustness. We address this tension by introducing a simple
and effective method for improving robustness: ensembling the weights of the
zero-shot and fine-tuned models. Compared to standard fine-tuning, the
resulting weight-space ensembles provide large accuracy improvements
out-of-distribution, while matching or improving in-distribution accuracy. On
ImageNet and five derived distribution shifts, weight-space ensembles improve
out-of-distribution accuracy by 2 to 10 percentage points while increasing
in-distribution accuracy by nearly 1 percentage point relative to standard
fine-tuning. These improvements come at no additional computational cost during
fine-tuning or inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Spatial Attention Network for Semantic Segmentation. (arXiv:2109.01915v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01915">
<div class="article-summary-box-inner">
<span><p>The spatial attention mechanism captures long-range dependencies by
aggregating global contextual information to each query location, which is
beneficial for semantic segmentation. In this paper, we present a sparse
spatial attention network (SSANet) to improve the efficiency of the spatial
attention mechanism without sacrificing the performance. Specifically, a sparse
non-local (SNL) block is proposed to sample a subset of key and value elements
for each query element to capture long-range relations adaptively and generate
a sparse affinity matrix to aggregate contextual information efficiently.
Experimental results show that the proposed approach outperforms other context
aggregation methods and achieves state-of-the-art performance on the
Cityscapes, PASCAL Context and ADE20K datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Audio-Visual Transformer Based Crowd Counting. (arXiv:2109.01926v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01926">
<div class="article-summary-box-inner">
<span><p>Crowd estimation is a very challenging problem. The most recent study tries
to exploit auditory information to aid the visual models, however, the
performance is limited due to the lack of an effective approach for feature
extraction and integration. The paper proposes a new audiovisual multi-task
network to address the critical challenges in crowd counting by effectively
utilizing both visual and audio inputs for better modalities association and
productive feature extraction. The proposed network introduces the notion of
auxiliary and explicit image patch-importance ranking (PIR) and patch-wise
crowd estimate (PCE) information to produce a third (run-time) modality. These
modalities (audio, visual, run-time) undergo a transformer-inspired
cross-modality co-attention mechanism to finally output the crowd estimate. To
acquire rich visual features, we propose a multi-branch structure with
transformer-style fusion in-between. Extensive experimental evaluations show
that the proposed scheme outperforms the state-of-the-art networks under all
evaluation settings with up to 33.8% improvement. We also analyze and compare
the vision-only variant of our network and empirically demonstrate its
superiority over previous approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ISyNet: Convolutional Neural Networks design for AI accelerator. (arXiv:2109.01932v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01932">
<div class="article-summary-box-inner">
<span><p>In recent years Deep Learning reached significant results in many practical
problems, such as computer vision, natural language processing, speech
recognition and many others. For many years the main goal of the research was
to improve the quality of models, even if the complexity was impractically
high. However, for the production solutions, which often require real-time
work, the latency of the model plays a very important role. Current
state-of-the-art architectures are found with neural architecture search (NAS)
taking model complexity into account. However, designing of the search space
suitable for specific hardware is still a challenging task. To address this
problem we propose a measure of hardware efficiency of neural architecture
search space - matrix efficiency measure (MEM); a search space comprising of
hardware-efficient operations; a latency-aware scaling method; and ISyNet - a
set of architectures designed to be fast on the specialized neural processing
unit (NPU) hardware and accurate at the same time. We show the advantage of the
designed architectures for the NPU devices on ImageNet and the generalization
ability for the downstream classification and detection tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Relative Spatial Reasoning for Visual Question Answering. (arXiv:2109.01934v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01934">
<div class="article-summary-box-inner">
<span><p>Vision-and-language (V\&amp;L) reasoning necessitates perception of visual
concepts such as objects and actions, understanding semantics and language
grounding, and reasoning about the interplay between the two modalities. One
crucial aspect of visual reasoning is spatial understanding, which involves
understanding relative locations of objects, i.e.\ implicitly learning the
geometry of the scene. In this work, we evaluate the faithfulness of V\&amp;L
models to such geometric understanding, by formulating the prediction of
pair-wise relative locations of objects as a classification as well as a
regression task. Our findings suggest that state-of-the-art transformer-based
V\&amp;L models lack sufficient abilities to excel at this task. Motivated by this,
we design two objectives as proxies for 3D spatial reasoning (SR) -- object
centroid estimation, and relative position estimation, and train V\&amp;L with weak
supervision from off-the-shelf depth estimators. This leads to considerable
improvements in accuracy for the "GQA" visual question answering challenge (in
fully supervised, few-shot, and O.O.D settings) as well as improvements in
relative spatial reasoning. Code and data will be released
\href{https://github.com/pratyay-banerjee/weak_sup_vqa}{here}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Utilizing Adversarial Targeted Attacks to Boost Adversarial Robustness. (arXiv:2109.01945v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01945">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks have been shown to be highly effective at degrading the
performance of deep neural networks (DNNs). The most prominent defense is
adversarial training, a method for learning a robust model. Nevertheless,
adversarial training does not make DNNs immune to adversarial perturbations. We
propose a novel solution by adopting the recently suggested Predictive
Normalized Maximum Likelihood. Specifically, our defense performs adversarial
targeted attacks according to different hypotheses, where each hypothesis
assumes a specific label for the test sample. Then, by comparing the hypothesis
probabilities, we predict the label. Our refinement process corresponds to
recent findings of the adversarial subspace properties. We extensively evaluate
our approach on 16 adversarial attack benchmarks using ResNet-50,
WideResNet-28, and a2-layer ConvNet trained with ImageNet, CIFAR10, and MNIST,
showing a significant improvement of up to 5.7%, 3.7%, and 0.6% respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Joint Learning of Chest X-Ray and Radiology Report by Word Region Alignment. (arXiv:2109.01949v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01949">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning provides an opportunity to explore unlabeled chest
X-rays and their associated free-text reports accumulated in clinical routine
without manual supervision. This paper proposes a Joint Image Text
Representation Learning Network (JoImTeRNet) for pre-training on chest X-ray
images and their radiology reports. The model was pre-trained on both the
global image-sentence level and the local image region-word level for
visual-textual matching. Both are bidirectionally constrained on Cross-Entropy
based and ranking-based Triplet Matching Losses. The region-word matching is
calculated using the attention mechanism without direct supervision about their
mapping. The pre-trained multi-modal representation learning paves the way for
downstream tasks concerning image and/or text encoding. We demonstrate the
representation learning quality by cross-modality retrievals and multi-label
classifications on two datasets: OpenI-IU and MIMIC-CXR
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Saliency Prior for Reducing Visual Distraction. (arXiv:2109.01980v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01980">
<div class="article-summary-box-inner">
<span><p>Using only a model that was trained to predict where people look at images,
and no additional training data, we can produce a range of powerful editing
effects for reducing distraction in images. Given an image and a mask
specifying the region to edit, we backpropagate through a state-of-the-art
saliency model to parameterize a differentiable editing operator, such that the
saliency within the masked region is reduced. We demonstrate several operators,
including: a recoloring operator, which learns to apply a color transform that
camouflages and blends distractors into their surroundings; a warping operator,
which warps less salient image regions to cover distractors, gradually
collapsing objects into themselves and effectively removing them (an effect
akin to inpainting); a GAN operator, which uses a semantic prior to fully
replace image regions with plausible, less salient alternatives. The resulting
effects are consistent with cognitive research on the human visual system
(e.g., since color mismatch is salient, the recoloring operator learns to
harmonize objects' colors with their surrounding to reduce their saliency),
and, importantly, are all achieved solely through the guidance of the
pretrained saliency model, with no additional supervision. We present results
on a variety of natural images and conduct a perceptual study to evaluate and
validate the changes in viewers' eye-gaze between the original images and our
edited results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Compression with Recurrent Neural Network and Generalized Divisive Normalization. (arXiv:2109.01999v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01999">
<div class="article-summary-box-inner">
<span><p>Image compression is a method to remove spatial redundancy between adjacent
pixels and reconstruct a high-quality image. In the past few years, deep
learning has gained huge attention from the research community and produced
promising image reconstruction results. Therefore, recent methods focused on
developing deeper and more complex networks, which significantly increased
network complexity. In this paper, two effective novel blocks are developed:
analysis and synthesis block that employs the convolution layer and Generalized
Divisive Normalization (GDN) in the variable-rate encoder and decoder side. Our
network utilizes a pixel RNN approach for quantization. Furthermore, to improve
the whole network, we encode a residual image using LSTM cells to reduce
unnecessary information. Experimental results demonstrated that the proposed
variable-rate framework with novel blocks outperforms existing methods and
standard image codecs, such as George's ~\cite{002} and JPEG in terms of image
similarity. The project page along with code and models are available at
https://khawar512.github.io/cvpr/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse-MLP: A Fully-MLP Architecture with Conditional Computation. (arXiv:2109.02008v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02008">
<div class="article-summary-box-inner">
<span><p>Mixture of Experts (MoE) with sparse conditional computation has been proved
an effective architecture for scaling attention-based models to more parameters
with comparable computation cost. In this paper, we propose Sparse-MLP, scaling
the recent MLP-Mixer model with sparse MoE layers, to achieve a more
computation-efficient architecture. We replace a subset of dense MLP blocks in
the MLP-Mixer model with Sparse blocks. In each Sparse block, we apply two
stages of MoE layers: one with MLP experts mixing information within channels
along image patch dimension, one with MLP experts mixing information within
patches along the channel dimension. Besides, to reduce computational cost in
routing and improve experts capacity, we design Re-represent layers in each
Sparse block. These layers are to re-scale image representations by two simple
but effective linear transformations. By pre-training on ImageNet-1k with MoCo
v3 algorithm, our models can outperform dense MLP models with comparable
parameters and less computational cost on several downstream image
classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Navigational Path-Planning For All-Terrain Autonomous Agricultural Robot. (arXiv:2109.02015v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02015">
<div class="article-summary-box-inner">
<span><p>The shortage of workforce and increasing cost of maintenance has forced many
farm industrialists to shift towards automated and mechanized approaches. The
key component for autonomous systems is the path planning techniques used.
Coverage path planning (CPP) algorithm is used for navigating over farmlands to
perform various agricultural operations such as seeding, ploughing, or spraying
pesticides and fertilizers. This report paper compares novel algorithms for
autonomous navigation of farmlands. For reduction of navigational constraints,
a high-resolution grid map representation is taken into consideration specific
to Indian environments. The free space is covered by distinguishing the grid
cells as covered, unexplored, partially explored and presence of an obstacle.
The performance of the compared algorithms is evaluated with metrics such as
time efficiency, space efficiency, accuracy, and robustness to changes in the
environment. Robotic Operating System (ROS), Dassault Systemes Experience
Platform (3DS Experience), MATLAB along Python were used for the simulation of
the compared algorithms. The results proved the applicability of the algorithms
for autonomous field navigation and feasibility with robotic path planning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Efficient Masked Language Modeling for Vision and Language. (arXiv:2109.02040v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02040">
<div class="article-summary-box-inner">
<span><p>Masked language modeling (MLM) is one of the key sub-tasks in vision-language
pretraining. In the cross-modal setting, tokens in the sentence are masked at
random, and the model predicts the masked tokens given the image and the text.
In this paper, we observe several key disadvantages of MLM in this setting.
First, as captions tend to be short, in a third of the sentences no token is
sampled. Second, the majority of masked tokens are stop-words and punctuation,
leading to under-utilization of the image. We investigate a range of
alternative masking strategies specific to the cross-modal setting that address
these shortcomings, aiming for better fusion of text and image in the learned
representation. When pre-training the LXMERT model, our alternative masking
strategies consistently improve over the original masking strategy on three
downstream tasks, especially in low resource settings. Further, our
pre-training approach substantially outperforms the baseline model on a
prompt-based probing task designed to elicit image objects. These results and
our analysis indicate that our method allows for better utilization of the
training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sensor Data Augmentation with Resampling for Contrastive Learning in Human Activity Recognition. (arXiv:2109.02054v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02054">
<div class="article-summary-box-inner">
<span><p>Human activity recognition plays an increasingly important role not only in
our daily lives, but also in the medical and rehabilitation fields. The
development of deep learning has also contributed to the advancement of human
activity recognition, but the large amount of data annotation work required to
train deep learning models is a major obstacle to the development of human
activity recognition. Contrastive learning has started to be used in the field
of sensor-based human activity recognition due to its ability to avoid the cost
of labeling large datasets and its ability to better distinguish between sample
representations of different instances. Among them, data augmentation, an
important part of contrast learning, has a significant impact on model
effectiveness, but current data augmentation methods do not perform too
successfully in contrast learning frameworks for wearable sensor-based activity
recognition. To optimize the effect of contrast learning models, in this paper,
we investigate the sampling frequency of sensors and propose a resampling data
augmentation method. In addition, we also propose a contrast learning framework
based on human activity recognition and apply the resampling augmentation
method to the data augmentation phase of contrast learning. The experimental
results show that the resampling augmentation method outperforms supervised
learning by 9.88% on UCI HAR and 7.69% on Motion Sensor in the fine-tuning
evaluation of contrast learning with a small amount of labeled data, and also
reveal that not all data augmentation methods will have positive effects in the
contrast learning framework. Finally, we explored the influence of the
combination of different augmentation methods on contrastive learning, and the
experimental results showed that the effect of most combination augmentation
methods was better than that of single augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Object-to-Zone Graph for Object Navigation. (arXiv:2109.02066v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02066">
<div class="article-summary-box-inner">
<span><p>The goal of object navigation is to reach the expected objects according to
visual information in the unseen environments. Previous works usually implement
deep models to train an agent to predict actions in real-time. However, in the
unseen environment, when the target object is not in egocentric view, the agent
may not be able to make wise decisions due to the lack of guidance. In this
paper, we propose a hierarchical object-to-zone (HOZ) graph to guide the agent
in a coarse-to-fine manner, and an online-learning mechanism is also proposed
to update HOZ according to the real-time observation in new environments. In
particular, the HOZ graph is composed of scene nodes, zone nodes and object
nodes. With the pre-learned HOZ graph, the real-time observation and the target
goal, the agent can constantly plan an optimal path from zone to zone. In the
estimated path, the next potential zone is regarded as sub-goal, which is also
fed into the deep reinforcement learning model for action prediction. Our
methods are evaluated on the AI2-Thor simulator. In addition to widely used
evaluation metrics SR and SPL, we also propose a new evaluation metric of SAE
that focuses on the effective action rate. Experimental results demonstrate the
effectiveness and efficiency of our proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fusformer: A Transformer-based Fusion Approach for Hyperspectral Image Super-resolution. (arXiv:2109.02079v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02079">
<div class="article-summary-box-inner">
<span><p>Hyperspectral image has become increasingly crucial due to its abundant
spectral information. However, It has poor spatial resolution with the
limitation of the current imaging mechanism. Nowadays, many convolutional
neural networks have been proposed for the hyperspectral image super-resolution
problem. However, convolutional neural network (CNN) based methods only
consider the local information instead of the global one with the limited
kernel size of receptive field in the convolution operation. In this paper, we
design a network based on the transformer for fusing the low-resolution
hyperspectral images and high-resolution multispectral images to obtain the
high-resolution hyperspectral images. Thanks to the representing ability of the
transformer, our approach is able to explore the intrinsic relationships of
features globally. Furthermore, considering the LR-HSIs hold the main spectral
structure, the network focuses on the spatial detail estimation releasing from
the burden of reconstructing the whole data. It reduces the mapping space of
the proposed network, which enhances the final performance. Various experiments
and quality indexes show our approach's superiority compared with other
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Person Generation: A Survey from the Perspective of Face, Pose and Cloth Synthesis. (arXiv:2109.02081v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02081">
<div class="article-summary-box-inner">
<span><p>Deep person generation has attracted extensive research attention due to its
wide applications in virtual agents, video conferencing, online shopping and
art/movie production. With the advancement of deep learning, visual appearances
(face, pose, cloth) of a person image can be easily generated or manipulated on
demand. In this survey, we first summarize the scope of person generation, and
then systematically review recent progress and technical trends in deep person
generation, covering three major tasks: talking-head generation (face),
pose-guided person generation (pose) and garment-oriented person generation
(cloth). More than two hundred papers are covered for a thorough overview, and
the milestone works are highlighted to witness the major technical
breakthrough. Based on these fundamental tasks, a number of applications are
investigated, e.g., virtual fitting, digital human, generative data
augmentation. We hope this survey could shed some light on the future prospects
of deep person generation, and provide a helpful foundation for full
applications towards digital human.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">(M)SLAe-Net: Multi-Scale Multi-Level Attention embedded Network for Retinal Vessel Segmentation. (arXiv:2109.02084v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02084">
<div class="article-summary-box-inner">
<span><p>Segmentation plays a crucial role in diagnosis. Studying the retinal
vasculatures from fundus images help identify early signs of many crucial
illnesses such as diabetic retinopathy. Due to the varying shape, size, and
patterns of retinal vessels, along with artefacts and noises in fundus images,
no one-stage method can accurately segment retinal vessels. In this work, we
propose a multi-scale, multi-level attention embedded CNN architecture
((M)SLAe-Net) to address the issue of multi-stage processing for robust and
precise segmentation of retinal vessels. We do this by extracting features at
multiple scales and multiple levels of the network, enabling our model to
holistically extracts the local and global features. Multi-scale features are
extracted using our novel dynamic dilated pyramid pooling (D-DPP) module. We
also aggregate the features from all the network levels. These effectively
resolved the issues of varying shapes and artefacts and hence the need for
multiple stages. To assist in better pixel-level classification, we use the
Squeeze and Attention(SA) module, a smartly adapted version of the Squeeze and
Excitation(SE) module for segmentation tasks in our network to facilitate
pixel-group attention. Our unique network design and novel D-DPP module with
efficient task-specific loss function for thin vessels enabled our model for
better cross data performance. Exhaustive experimental results on DRIVE, STARE,
HRF, and CHASE-DB1 show the superiority of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Timbre Transfer with Variational Auto Encoding and Cycle-Consistent Adversarial Networks. (arXiv:2109.02096v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02096">
<div class="article-summary-box-inner">
<span><p>This research project investigates the application of deep learning to timbre
transfer, where the timbre of a source audio can be converted to the timbre of
a target audio with minimal loss in quality. The adopted approach combines
Variational Autoencoders with Generative Adversarial Networks to construct
meaningful representations of the source audio and produce realistic
generations of the target audio and is applied to the Flickr 8k Audio dataset
for transferring the vocal timbre between speakers and the URMP dataset for
transferring the musical timbre between instruments. Furthermore, variations of
the adopted approach are trained, and generalised performance is compared using
the metrics SSIM (Structural Similarity Index) and FAD (Frech\'et Audio
Distance). It was found that a many-to-many approach supersedes a one-to-one
approach in terms of reconstructive capabilities, and that the adoption of a
basic over a bottleneck residual block design is more suitable for enriching
content information about a latent space. It was also found that the decision
on whether cyclic loss takes on a variational autoencoder or vanilla
autoencoder approach does not have a significant impact on reconstructive and
adversarial translation aspects of the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cluster-Promoting Quantization with Bit-Drop for Minimizing Network Quantization Loss. (arXiv:2109.02100v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02100">
<div class="article-summary-box-inner">
<span><p>Network quantization, which aims to reduce the bit-lengths of the network
weights and activations, has emerged for their deployments to resource-limited
devices. Although recent studies have successfully discretized a full-precision
network, they still incur large quantization errors after training, thus giving
rise to a significant performance gap between a full-precision network and its
quantized counterpart. In this work, we propose a novel quantization method for
neural networks, Cluster-Promoting Quantization (CPQ) that finds the optimal
quantization grids while naturally encouraging the underlying full-precision
weights to gather around those quantization grids cohesively during training.
This property of CPQ is thanks to our two main ingredients that enable
differentiable quantization: i) the use of the categorical distribution
designed by a specific probabilistic parametrization in the forward pass and
ii) our proposed multi-class straight-through estimator (STE) in the backward
pass. Since our second component, multi-class STE, is intrinsically biased, we
additionally propose a new bit-drop technique, DropBits, that revises the
standard dropout regularization to randomly drop bits instead of neurons. As a
natural extension of DropBits, we further introduce the way of learning
heterogeneous quantization levels to find proper bit-length for each layer by
imposing an additional regularization on DropBits. We experimentally validate
our method on various benchmark datasets and network architectures, and also
support a new hypothesis for quantization: learning heterogeneous quantization
levels outperforms the case using the same but fixed quantization levels from
scratch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognition of COVID-19 Disease Utilizing X-Ray Imaging of the Chest Using CNN. (arXiv:2109.02103v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02103">
<div class="article-summary-box-inner">
<span><p>Since this COVID-19 pandemic thrives, the utilization of X-Ray images of the
Chest (CXR) as a complementary screening technique to RT-PCR testing grows to
its clinical use for respiratory complaints. Many new deep learning approaches
have developed as a consequence. The goal of this research is to assess the
convolutional neural networks (CNNs) to diagnosis COVID-19 utisizing X-ray
images of chest. The performance of CNN with one, three, and four convolution
layers has been evaluated in this research. A dataset of 13,808 CXR photographs
are used in this research. When evaluated on X-ray images with three splits of
the dataset, our preliminary experimental results show that the CNN model with
three convolution layers can reliably detect with 96 percent accuracy
(precision being 96 percent). This fact indicates the commitment of our
suggested model for reliable screening of COVID-19.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Underwater 3D Reconstruction Using Light Fields. (arXiv:2109.02116v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02116">
<div class="article-summary-box-inner">
<span><p>Underwater 3D reconstruction is challenging due to the refraction of light at
the water-air interface (most electronic devices cannot be directly submerged
in water). In this paper, we present an underwater 3D reconstruction solution
using light field cameras. We first develop a light field camera calibration
algorithm that simultaneously estimates the camera parameters and the geometry
of the water-air interface. We then design a novel depth estimation algorithm
for 3D reconstruction. Specifically, we match correspondences on curved
epipolar lines caused by water refraction. We also observe that the
view-dependent specular reflection is very weak in the underwater environment,
resulting the angularly sampled rays in light field has uniform intensity. We
therefore propose an angular uniformity constraint for depth optimization. We
also develop a fast algorithm for locating the angular patches in presence of
non-linear light paths. Extensive synthetic and real experiments demonstrate
that our method can perform underwater 3D reconstruction with high accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identification of Driver Phone Usage Violations via State-of-the-Art Object Detection with Tracking. (arXiv:2109.02119v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02119">
<div class="article-summary-box-inner">
<span><p>The use of mobiles phones when driving have been a major factor when it comes
to road traffic incidents and the process of capturing such violations can be a
laborious task. Advancements in both modern object detection frameworks and
high-performance hardware has paved the way for a more automated approach when
it comes to video surveillance. In this work, we propose a custom-trained
state-of-the-art object detector to work with roadside cameras to capture
driver phone usage without the need for human intervention. The proposed
approach also addresses the issues caused by windscreen glare and introduces
the steps required to remedy this. Twelve pre-trained models are fine-tuned
with our custom dataset using four popular object detection methods: YOLO, SSD,
Faster R-CNN, and CenterNet. Out of all the object detectors tested, the YOLO
yields the highest accuracy levels of up to 96% (AP10) and frame rates of up to
~30 FPS. DeepSort object tracking algorithm is also integrated into the
best-performing model to collect records of only the unique violations, and
enable the proposed approach to count the number of vehicles. The proposed
automated system will collect the output images of the identified violations,
timestamps of each violation, and total vehicle count. Data can be accessed via
a purpose-built user interface.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stochastic Neural Radiance Fields:Quantifying Uncertainty in Implicit 3D Representations. (arXiv:2109.02123v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02123">
<div class="article-summary-box-inner">
<span><p>Neural Radiance Fields (NeRF) has become a popular framework for learning
implicit 3D representations and addressing different tasks such as novel-view
synthesis or depth-map estimation. However, in downstream applications where
decisions need to be made based on automatic predictions, it is critical to
leverage the confidence associated with the model estimations. Whereas
uncertainty quantification is a long-standing problem in Machine Learning, it
has been largely overlooked in the recent NeRF literature. In this context, we
propose Stochastic Neural Radiance Fields (S-NeRF), a generalization of
standard NeRF that learns a probability distribution over all the possible
radiance fields modeling the scene. This distribution allows to quantify the
uncertainty associated with the scene information provided by the model. S-NeRF
optimization is posed as a Bayesian learning problem which is efficiently
addressed using the Variational Inference framework. Exhaustive experiments
over benchmark datasets demonstrate that S-NeRF is able to provide more
reliable predictions and confidence values than generic approaches previously
proposed for uncertainty estimation in other domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Action Recognition Using Confidence Distillation. (arXiv:2109.02137v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02137">
<div class="article-summary-box-inner">
<span><p>Modern neural networks are powerful predictive models. However, when it comes
to recognizing that they may be wrong about their predictions, they perform
poorly. For example, for one of the most common activation functions, the ReLU
and its variants, even a well-calibrated model can produce incorrect but high
confidence predictions. In the related task of action recognition, most current
classification methods are based on clip-level classifiers that densely sample
a given video for non-overlapping, same-sized clips and aggregate the results
using an aggregation function - typically averaging - to achieve video level
predictions. While this approach has shown to be effective, it is sub-optimal
in recognition accuracy and has a high computational overhead. To mitigate both
these issues, we propose the confidence distillation framework to teach a
representation of uncertainty of the teacher to the student sampler and divide
the task of full video prediction between the student and the teacher models.
We conduct extensive experiments on three action recognition datasets and
demonstrate that our framework achieves significant improvements in action
recognition accuracy (up to 20%) and computational efficiency (more than 40%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial Domain Feature Extraction Methods for Unconstrained Handwritten Malayalam Character Recognition. (arXiv:2109.02153v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02153">
<div class="article-summary-box-inner">
<span><p>Handwritten character recognition is an active research challenge,especially
for Indian scripts. This paper deals with handwritten Malayalam, with a
complete set of basic characters, vowel and consonant signs and compound
characters that may be present in the script. Spatial domain features suitable
for recognition are chosen in this work. For classification, k-NN, SVM and ELM
are employed
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Attentive Deep Neural Network for Exposing GAN-generated Faces. (arXiv:2109.02167v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02167">
<div class="article-summary-box-inner">
<span><p>GAN-based techniques that generate and synthesize realistic faces have caused
severe social concerns and security problems. Existing methods for detecting
GAN-generated faces can perform well on limited public datasets. However,
images from existing public datasets do not represent real-world scenarios well
enough in terms of view variations and data distributions (where real faces
largely outnumber synthetic faces). The state-of-the-art methods do not
generalize well in real-world problems and lack the interpretability of
detection results. Performance of existing GAN-face detection models degrades
significantly when facing imbalanced data distributions. To address these
shortcomings, we propose a robust, attentive, end-to-end network that can spot
GAN-generated faces by analyzing their eye inconsistencies. Specifically, our
model learns to identify inconsistent eye components by localizing and
comparing the iris artifacts between the two eyes automatically. Our deep
network addresses the imbalance learning issues by considering the AUC loss and
the traditional cross-entropy loss jointly. Comprehensive evaluations of the
FFHQ dataset in terms of both balanced and imbalanced scenarios demonstrate the
superiority of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Right Ventricular Segmentation from Short- and Long-Axis MRIs via Information Transition. (arXiv:2109.02171v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02171">
<div class="article-summary-box-inner">
<span><p>Right ventricular (RV) segmentation from magnetic resonance imaging (MRI) is
a crucial step for cardiac morphology and function analysis. However, automatic
RV segmentation from MRI is still challenging, mainly due to the heterogeneous
intensity, the complex variable shapes, and the unclear RV boundary. Moreover,
current methods for the RV segmentation tend to suffer from performance
degradation at the basal and apical slices of MRI. In this work, we propose an
automatic RV segmentation framework, where the information from long-axis (LA)
views is utilized to assist the segmentation of short-axis (SA) views via
information transition. Specifically, we employed the transformed segmentation
from LA views as a prior information, to extract the ROI from SA views for
better segmentation. The information transition aims to remove the surrounding
ambiguous regions in the SA views. %, such as the tricuspid valve regions. We
tested our model on a public dataset with 360 multi-center, multi-vendor and
multi-disease subjects that consist of both LA and SA MRIs. Our experimental
results show that including LA views can be effective to improve the accuracy
of the SA segmentation. Our model is publicly available at
https://github.com/NanYoMy/MMs-2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Agent Variational Occlusion Inference Using People as Sensors. (arXiv:2109.02173v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02173">
<div class="article-summary-box-inner">
<span><p>Autonomous vehicles must reason about spatial occlusions in urban
environments to ensure safety without being overly cautious. Prior work
explored occlusion inference from observed social behaviors of road agents.
Inferring occupancy from agent behaviors is an inherently multimodal problem; a
driver may behave in the same manner for different occupancy patterns ahead of
them (e.g., a driver may move at constant speed in traffic or on an open road).
Past work, however, does not account for this multimodality, thus neglecting to
model this source of aleatoric uncertainty in the relationship between driver
behaviors and their environment. We propose an occlusion inference method that
characterizes observed behaviors of human agents as sensor measurements, and
fuses them with those from a standard sensor suite. To capture the aleatoric
uncertainty, we train a conditional variational autoencoder with a discrete
latent space to learn a multimodal mapping from observed driver trajectories to
an occupancy grid representation of the view ahead of the driver. Our method
handles multi-agent scenarios, combining measurements from multiple observed
drivers using evidential theory to solve the sensor fusion problem. Our
approach is validated on a real-world dataset, outperforming baselines and
demonstrating real-time capable performance. Our code is available at
https://github.com/sisl/MultiAgentVariationalOcclusionInference .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Square Root Marginalization for Sliding-Window Bundle Adjustment. (arXiv:2109.02182v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02182">
<div class="article-summary-box-inner">
<span><p>In this paper we propose a novel square root sliding-window bundle adjustment
suitable for real-time odometry applications. The square root formulation
pervades three major aspects of our optimization-based sliding-window
estimator: for bundle adjustment we eliminate landmark variables with nullspace
projection; to store the marginalization prior we employ a matrix square root
of the Hessian; and when marginalizing old poses we avoid forming normal
equations and update the square root prior directly with a specialized QR
decomposition. We show that the proposed square root marginalization is
algebraically equivalent to the conventional use of Schur complement (SC) on
the Hessian. Moreover, it elegantly deals with rank-deficient Jacobians
producing a prior equivalent to SC with Moore-Penrose inverse. Our evaluation
of visual and visual-inertial odometry on real-world datasets demonstrates that
the proposed estimator is 36% faster than the baseline. It furthermore shows
that in single precision, conventional Hessian-based marginalization leads to
numeric failures and reduced accuracy. We analyse numeric properties of the
marginalization prior to explain why our square root form does not suffer from
the same effect and therefore entails superior performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parsing Table Structures in the Wild. (arXiv:2109.02199v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02199">
<div class="article-summary-box-inner">
<span><p>This paper tackles the problem of table structure parsing (TSP) from images
in the wild. In contrast to existing studies that mainly focus on parsing
well-aligned tabular images with simple layouts from scanned PDF documents, we
aim to establish a practical table structure parsing system for real-world
scenarios where tabular input images are taken or scanned with severe
deformation, bending or occlusions. For designing such a system, we propose an
approach named Cycle-CenterNet on the top of CenterNet with a novel
cycle-pairing module to simultaneously detect and group tabular cells into
structured tables. In the cycle-pairing module, a new pairing loss function is
proposed for the network training. Alongside with our Cycle-CenterNet, we also
present a large-scale dataset, named Wired Table in the Wild (WTW), which
includes well-annotated structure parsing of multiple style tables in several
scenes like the photo, scanning files, web pages, \emph{etc.}. In experiments,
we demonstrate that our Cycle-CenterNet consistently achieves the best accuracy
of table structure parsing on the new WTW dataset by 24.6\% absolute
improvement evaluated by the TEDS metric. A more comprehensive experimental
analysis also validates the advantages of our proposed methods for the TSP
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Fine-Grained Motion Embedding for Landscape Animation. (arXiv:2109.02216v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02216">
<div class="article-summary-box-inner">
<span><p>In this paper we focus on landscape animation, which aims to generate
time-lapse videos from a single landscape image. Motion is crucial for
landscape animation as it determines how objects move in videos. Existing
methods are able to generate appealing videos by learning motion from real
time-lapse videos. However, current methods suffer from inaccurate motion
generation, which leads to unrealistic video results. To tackle this problem,
we propose a model named FGLA to generate high-quality and realistic videos by
learning Fine-Grained motion embedding for Landscape Animation. Our model
consists of two parts: (1) a motion encoder which embeds time-lapse motion in a
fine-grained way. (2) a motion generator which generates realistic motion to
animate input images. To train and evaluate on diverse time-lapse videos, we
build the largest high-resolution Time-lapse video dataset with Diverse scenes,
namely Time-lapse-D, which includes 16,874 video clips with over 10 million
frames. Quantitative and qualitative experimental results demonstrate the
superiority of our method. In particular, our method achieves relative
improvements by 19% on LIPIS and 5.6% on FVD compared with state-of-the-art
methods on our dataset. A user study carried out with 700 human subjects shows
that our approach visually outperforms existing methods by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning Graph Networks for Kinship Verification: from Star-shaped to Hierarchical. (arXiv:2109.02219v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02219">
<div class="article-summary-box-inner">
<span><p>In this paper, we investigate the problem of facial kinship verification by
learning hierarchical reasoning graph networks. Conventional methods usually
focus on learning discriminative features for each facial image of a paired
sample and neglect how to fuse the obtained two facial image features and
reason about the relations between them. To address this, we propose a
Star-shaped Reasoning Graph Network (S-RGN). Our S-RGN first constructs a
star-shaped graph where each surrounding node encodes the information of
comparisons in a feature dimension and the central node is employed as the
bridge for the interaction of surrounding nodes. Then we perform relational
reasoning on this star graph with iterative message passing. The proposed S-RGN
uses only one central node to analyze and process information from all
surrounding nodes, which limits its reasoning capacity. We further develop a
Hierarchical Reasoning Graph Network (H-RGN) to exploit more powerful and
flexible capacity. More specifically, our H-RGN introduces a set of latent
reasoning nodes and constructs a hierarchical graph with them. Then bottom-up
comparative information abstraction and top-down comprehensive signal
propagation are iteratively performed on the hierarchical graph to update the
node features. Extensive experimental results on four widely used kinship
databases show that the proposed methods achieve very competitive results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GDP: Stabilized Neural Network Pruning via Gates with Differentiable Polarization. (arXiv:2109.02220v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02220">
<div class="article-summary-box-inner">
<span><p>Model compression techniques are recently gaining explosive attention for
obtaining efficient AI models for various real-time applications. Channel
pruning is one important compression strategy and is widely used in slimming
various DNNs. Previous gate-based or importance-based pruning methods aim to
remove channels whose importance is smallest. However, it remains unclear what
criteria the channel importance should be measured on, leading to various
channel selection heuristics. Some other sampling-based pruning methods deploy
sampling strategies to train sub-nets, which often causes the training
instability and the compressed model's degraded performance. In view of the
research gaps, we present a new module named Gates with Differentiable
Polarization (GDP), inspired by principled optimization ideas. GDP can be
plugged before convolutional layers without bells and whistles, to control the
on-and-off of each channel or whole layer block. During the training process,
the polarization effect will drive a subset of gates to smoothly decrease to
exact zero, while other gates gradually stay away from zero by a large margin.
When training terminates, those zero-gated channels can be painlessly removed,
while other non-zero gates can be absorbed into the succeeding convolution
kernel, causing completely no interruption to training nor damage to the
trained model. Experiments conducted over CIFAR-10 and ImageNet datasets show
that the proposed GDP algorithm achieves the state-of-the-art performance on
various benchmark DNNs at a broad range of pruning ratios. We also apply GDP to
DeepLabV3Plus-ResNet50 on the challenging Pascal VOC segmentation task, whose
test performance sees no drop (even slightly improved) with over 60% FLOPs
saving.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GeneAnnotator: A Semi-automatic Annotation Tool for Visual Scene Graph. (arXiv:2109.02226v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02226">
<div class="article-summary-box-inner">
<span><p>In this manuscript, we introduce a semi-automatic scene graph annotation tool
for images, the GeneAnnotator. This software allows human annotators to
describe the existing relationships between participators in the visual scene
in the form of directed graphs, hence enabling the learning and reasoning on
visual relationships, e.g., image captioning, VQA and scene graph generation,
etc. The annotations for certain image datasets could either be merged in a
single VG150 data-format file to support most existing models for scene graph
learning or transformed into a separated annotation file for each single image
to build customized datasets. Moreover, GeneAnnotator provides a rule-based
relationship recommending algorithm to reduce the heavy annotation workload.
With GeneAnnotator, we propose Traffic Genome, a comprehensive scene graph
dataset with 1000 diverse traffic images, which in return validates the
effectiveness of the proposed software for scene graph annotation. The project
source code, with usage examples and sample data is available at
https://github.com/Milomilo0320/A-Semi-automatic-Annotation-Software-for-Scene-Graph,
under the Apache open-source license.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Generate Scene Graph from Natural Language Supervision. (arXiv:2109.02227v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02227">
<div class="article-summary-box-inner">
<span><p>Learning from image-text data has demonstrated recent success for many
recognition tasks, yet is currently limited to visual features or individual
visual concepts such as objects. In this paper, we propose one of the first
methods that learn from image-sentence pairs to extract a graphical
representation of localized objects and their relationships within an image,
known as scene graph. To bridge the gap between images and texts, we leverage
an off-the-shelf object detector to identify and localize object instances,
match labels of detected regions to concepts parsed from captions, and thus
create "pseudo" labels for learning scene graph. Further, we design a
Transformer-based model to predict these "pseudo" labels via a masked token
prediction task. Learning from only image-sentence pairs, our model achieves
30% relative gain over a latest method trained with human-annotated unlocalized
scene graphs. Our model also shows strong results for weakly and fully
supervised scene graph generation. In addition, we explore an open-vocabulary
setting for detecting scene graphs, and present the first result for open-set
scene graph generation. Our code is available at
https://github.com/YiwuZhong/SGG_from_NLS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image recognition via Vietoris-Rips complex. (arXiv:2109.02231v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02231">
<div class="article-summary-box-inner">
<span><p>Extracting informative features from images has been of capital importance in
computer vision. In this paper, we propose a way to extract such features from
images by a method based on algebraic topology. To that end, we construct a
weighted graph from an image, which extracts local information of an image. By
considering this weighted graph as a pseudo-metric space, we construct a
Vietoris-Rips complex with a parameter $\varepsilon$ by a well-known process of
algebraic topology. We can extract information of complexity of the image and
can detect a sub-image with a relatively high concentration of information from
this Vietoris-Rips complex. The parameter $\varepsilon$ of the Vietoris-Rips
complex produces robustness to noise. We empirically show that the extracted
feature captures well images' characteristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Product Quantization for Deep Unsupervised Image Retrieval. (arXiv:2109.02244v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02244">
<div class="article-summary-box-inner">
<span><p>Supervised deep learning-based hash and vector quantization are enabling fast
and large-scale image retrieval systems. By fully exploiting label annotations,
they are achieving outstanding retrieval performances compared to the
conventional methods. However, it is painstaking to assign labels precisely for
a vast amount of training data, and also, the annotation process is
error-prone. To tackle these issues, we propose the first deep unsupervised
image retrieval method dubbed Self-supervised Product Quantization (SPQ)
network, which is label-free and trained in a self-supervised manner. We design
a Cross Quantized Contrastive learning strategy that jointly learns codewords
and deep visual descriptors by comparing individually transformed images
(views). Our method analyzes the image contents to extract descriptive
features, allowing us to understand image representations for accurate
retrieval. By conducting extensive experiments on benchmarks, we demonstrate
that the proposed method yields state-of-the-art results even without
supervised pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Models Improve Radiomics Performance in Different Tasks and Different Datasets: An Experimental Study. (arXiv:2109.02252v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02252">
<div class="article-summary-box-inner">
<span><p>Radiomics is an active area of research focusing on high throughput feature
extraction from medical images with a wide array of applications in clinical
practice, such as clinical decision support in oncology. However, noise in low
dose computed tomography (CT) scans can impair the accurate extraction of
radiomic features. In this article, we investigate the possibility of using
deep learning generative models to improve the performance of radiomics from
low dose CTs. We used two datasets of low dose CT scans -NSCLC Radiogenomics
and LIDC-IDRI - as test datasets for two tasks - pre-treatment survival
prediction and lung cancer diagnosis. We used encoder-decoder networks and
conditional generative adversarial networks (CGANs) trained in a previous study
as generative models to transform low dose CT images into full dose CT images.
Radiomic features extracted from the original and improved CT scans were used
to build two classifiers - a support vector machine (SVM) and a deep attention
based multiple instance learning model - for survival prediction and lung
cancer diagnosis respectively. Finally, we compared the performance of the
models derived from the original and improved CT scans. Encoder-decoder
networks and CGANs improved the area under the curve (AUC) of survival
prediction from 0.52 to 0.57 (p-value&lt;0.01). On the other hand, Encoder-decoder
network and CGAN can improve the AUC of lung cancer diagnosis from 0.84 to 0.88
and 0.89 respectively (p-value&lt;0.01). Moreover, there are no statistically
significant differences in improving AUC by using encoder-decoder network and
CGAN (p-value=0.34) when networks trained at 75 and 100 epochs. Generative
models can improve the performance of low dose CT-based radiomics in different
tasks. Hence, denoising using generative models seems to be a necessary
pre-processing step for calculating radiomic features from low dose CTs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CTRL-C: Camera calibration TRansformer with Line-Classification. (arXiv:2109.02259v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02259">
<div class="article-summary-box-inner">
<span><p>Single image camera calibration is the task of estimating the camera
parameters from a single input image, such as the vanishing points, focal
length, and horizon line. In this work, we propose Camera calibration
TRansformer with Line-Classification (CTRL-C), an end-to-end neural
network-based approach to single image camera calibration, which directly
estimates the camera parameters from an image and a set of line segments. Our
network adopts the transformer architecture to capture the global structure of
an image with multi-modal inputs in an end-to-end manner. We also propose an
auxiliary task of line classification to train the network to extract the
global geometric information from lines effectively. Our experiments
demonstrate that CTRL-C outperforms the previous state-of-the-art methods on
the Google Street View and SUN360 benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Spatial-Temporal Semantic Consistency for Video Scene Parsing. (arXiv:2109.02281v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02281">
<div class="article-summary-box-inner">
<span><p>Compared with image scene parsing, video scene parsing introduces temporal
information, which can effectively improve the consistency and accuracy of
prediction. In this paper, we propose a Spatial-Temporal Semantic Consistency
method to capture class-exclusive context information. Specifically, we design
a spatial-temporal consistency loss to constrain the semantic consistency in
spatial and temporal dimensions. In addition, we adopt an pseudo-labeling
strategy to enrich the training dataset. We obtain the scores of 59.84% and
58.85% mIoU on development (test part 1) and testing set of VSPW, respectively.
And our method wins the 1st place on VSPW challenge at ICCV2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Melania Trump have a body double from the perspective of automatic face recognition?. (arXiv:2109.02283v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02283">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore whether automatic face recognition can help in
verifying widespread misinformation on social media, particularly conspiracy
theories that are based on the existence of body doubles. The conspiracy theory
addressed in this paper is the case of the Melania Trump body double. We
employed four different state-of-the-art descriptors for face recognition to
verify the integrity of the claim of the studied conspiracy theory. In
addition, we assessed the impact of different image quality metrics on the
variation of face recognition results. Two sets of image quality metrics were
considered: acquisition-related metrics and subject-related metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Realistic Single-View 3D Object Reconstructionwith Unsupervised Learning from Multiple Images. (arXiv:2109.02288v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02288">
<div class="article-summary-box-inner">
<span><p>Recovering the 3D structure of an object from a single image is a challenging
task due to its ill-posed nature. One approach is to utilize the plentiful
photos of the same object category to learn a strong 3D shape prior for the
object. This approach has successfully been demonstrated by a recent work of Wu
et al. (2020), which obtained impressive 3D reconstruction networks with
unsupervised learning. However, their algorithm is only applicable to symmetric
objects. In this paper, we eliminate the symmetry requirement with a novel
unsupervised algorithm that can learn a 3D reconstruction network from a
multi-image dataset. Our algorithm is more general and covers the
symmetry-required scenario as a special case. Besides, we employ a novel albedo
loss that improves the reconstructed details and realisticity. Our method
surpasses the previous work in both quality and robustness, as shown in
experiments on datasets of various structures, including single-view,
multi-view, image-collection, and video sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Encoder-decoder with Multi-level Attention for 3D Human Shape and Pose Estimation. (arXiv:2109.02303v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02303">
<div class="article-summary-box-inner">
<span><p>3D human shape and pose estimation is the essential task for human motion
analysis, which is widely used in many 3D applications. However, existing
methods cannot simultaneously capture the relations at multiple levels,
including spatial-temporal level and human joint level. Therefore they fail to
make accurate predictions in some hard scenarios when there is cluttered
background, occlusion, or extreme pose. To this end, we propose Multi-level
Attention Encoder-Decoder Network (MAED), including a Spatial-Temporal Encoder
(STE) and a Kinematic Topology Decoder (KTD) to model multi-level attentions in
a unified framework. STE consists of a series of cascaded blocks based on
Multi-Head Self-Attention, and each block uses two parallel branches to learn
spatial and temporal attention respectively. Meanwhile, KTD aims at modeling
the joint level attention. It regards pose estimation as a top-down
hierarchical process similar to SMPL kinematic tree. With the training set of
3DPW, MAED outperforms previous state-of-the-art methods by 6.2, 7.2, and 2.4
mm of PA-MPJPE on the three widely used benchmarks 3DPW, MPI-INF-3DHP, and
Human3.6M respectively. Our code is available at
https://github.com/ziniuwan/maed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Segmentation of the Optic Nerve Head Region in Optical Coherence Tomography: A Methodological Review. (arXiv:2109.02322v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02322">
<div class="article-summary-box-inner">
<span><p>The optic nerve head represents the intraocular section of the optic nerve
(ONH), which is prone to damage by intraocular pressure. The advent of optical
coherence tomography (OCT) has enabled the evaluation of novel optic nerve head
parameters, namely the depth and curvature of the lamina cribrosa (LC).
Together with the Bruch's membrane opening minimum-rim-width, these seem to be
promising optic nerve head parameters for diagnosis and monitoring of retinal
diseases such as glaucoma. Nonetheless, these optical coherence tomography
derived biomarkers are mostly extracted through manual segmentation, which is
time-consuming and prone to bias, thus limiting their usability in clinical
practice. The automatic segmentation of optic nerve head in OCT scans could
further improve the current clinical management of glaucoma and other diseases.
</p>
<p>This review summarizes the current state-of-the-art in automatic segmentation
of the ONH in OCT. PubMed and Scopus were used to perform a systematic review.
Additional works from other databases (IEEE, Google Scholar and ARVO IOVS) were
also included, resulting in a total of 27 reviewed studies.
</p>
<p>For each algorithm, the methods, the size and type of dataset used for
validation, and the respective results were carefully analyzed. The results
show that deep learning-based algorithms provide the highest accuracy,
sensitivity and specificity for segmenting the different structures of the ONH
including the LC. However, a lack of consensus regarding the definition of
segmented regions, extracted parameters and validation approaches has been
observed, highlighting the importance and need of standardized methodologies
for ONH segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Cardiac Resting Phase Detection Targeted on the Right Coronary Artery. (arXiv:2109.02342v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02342">
<div class="article-summary-box-inner">
<span><p>Purpose: Static cardiac imaging such as late gadolinium enhancement, mapping,
or 3-D coronary angiography require prior information, e.g., the phase during a
cardiac cycle with least motion, called resting phase (RP). The purpose of this
work is to propose a fully automated framework that allows the detection of the
right coronary artery (RCA) RP within CINE series. Methods: The proposed
prototype system consists of three main steps. First, the localization of the
regions of interest (ROI) is performed. Second, as CINE series are
time-resolved, the cropped ROI series over all time points are taken for
tracking motions quantitatively. Third, the output motion values are used to
classify RPs. In this work, we focused on the detection of the area with the
outer edge of the cross-section of the RCA as our target. The proposed
framework was evaluated on 102 clinically acquired dataset at 1.5T and 3T. The
automatically classified RPs were compared with the ground truth RPs annotated
manually by a medical expert for testing the robustness and feasibility of the
framework. Results: The predicted RCA RPs showed high agreement with the
experts annotated RPs with 92.7% accuracy, 90.5% sensitivity and 95.0%
specificity for the unseen study dataset. The mean absolute difference of the
start and end RP was 13.6 ${\pm}$ 18.6 ms for the validation study dataset
(n=102). Conclusion: In this work, automated RP detection has been introduced
by the proposed framework and demonstrated feasibility, robustness, and
applicability for diverse static imaging acquisitions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information Theory-Guided Heuristic Progressive Multi-View Coding. (arXiv:2109.02344v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02344">
<div class="article-summary-box-inner">
<span><p>Multi-view representation learning captures comprehensive information from
multiple views of a shared context. Recent works intuitively apply contrastive
learning (CL) to learn representations, regarded as a pairwise manner, which is
still scalable: view-specific noise is not filtered in learning view-shared
representations; the fake negative pairs, where the negative terms are actually
within the same class as the positive, and the real negative pairs are
coequally treated; and evenly measuring the similarities between terms might
interfere with optimization. Importantly, few works research the theoretical
framework of generalized self-supervised multi-view learning, especially for
more than two views. To this end, we rethink the existing multi-view learning
paradigm from the information theoretical perspective and then propose a novel
information theoretical framework for generalized multi-view learning. Guided
by it, we build a multi-view coding method with a three-tier progressive
architecture, namely Information theory-guided heuristic Progressive Multi-view
Coding (IPMC). In the distribution-tier, IPMC aligns the distribution between
views to reduce view-specific noise. In the set-tier, IPMC builds self-adjusted
pools for contrasting, which utilizes a view filter to adaptively modify the
pools. Lastly, in the instance-tier, we adopt a designed unified loss to learn
discriminative representations and reduce the gradient interference.
Theoretically and empirically, we demonstrate the superiority of IPMC over
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tensor Normalization and Full Distribution Training. (arXiv:2109.02345v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02345">
<div class="article-summary-box-inner">
<span><p>In this work, we introduce pixel wise tensor normalization, which is inserted
after rectifier linear units and, together with batch normalization, provides a
significant improvement in the accuracy of modern deep neural networks. In
addition, this work deals with the robustness of networks. We show that the
factorized superposition of images from the training set and the reformulation
of the multi class problem into a multi-label problem yields significantly more
robust networks. The reformulation and the adjustment of the multi class log
loss also improves the results compared to the overlay with only one class as
label.
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/?p=%2FTNandFDT&amp;mode=list
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fair Federated Learning for Heterogeneous Face Data. (arXiv:2109.02351v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02351">
<div class="article-summary-box-inner">
<span><p>We consider the problem of achieving fair classification in Federated
Learning (FL) under data heterogeneity. Most of the approaches proposed for
fair classification require diverse data that represent the different
demographic groups involved. In contrast, it is common for each client to own
data that represents only a single demographic group. Hence the existing
approaches cannot be adopted for fair classification models at the client
level. To resolve this challenge, we propose several aggregation techniques. We
empirically validate these techniques by comparing the resulting fairness
metrics and accuracy on CelebA, UTK, and FairFace datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Recognition with Deep Learning from Biased Image Datasets. (arXiv:2109.02357v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02357">
<div class="article-summary-box-inner">
<span><p>In practice, and more especially when training deep neural networks, visual
recognition rules are often learned based on various sources of information. On
the other hand, the recent deployment of facial recognition systems with uneven
predictive performances on different population segments highlights the
representativeness issues possibly induced by a naive aggregation of image
datasets. Indeed, sampling bias does not vanish simply by considering larger
datasets, and ignoring its impact may completely jeopardize the generalization
capacity of the learned prediction rules. In this paper, we show how biasing
models, originally introduced for nonparametric estimation in (Gill et al.,
1988), and recently revisited from the perspective of statistical learning
theory in (Laforgue and Cl\'emen\c{c}on, 2019), can be applied to remedy these
problems in the context of visual recognition. Based on the (approximate)
knowledge of the biasing mechanisms at work, our approach consists in
reweighting the observations, so as to form a nearly debiased estimator of the
target distribution. One key condition for our method to be theoretically valid
is that the supports of the distributions generating the biased datasets at
disposal must overlap, and cover the support of the target distribution. In
order to meet this requirement in practice, we propose to use a low dimensional
image representation, shared across the image databases. Finally, we provide
numerical experiments highlighting the relevance of our approach whenever the
biasing functions are appropriately chosen.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing the Machine Readability of Traffic Sign Pictograms in Austria and Germany. (arXiv:2109.02362v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02362">
<div class="article-summary-box-inner">
<span><p>We compare the machine readability of pictograms found on Austrian and German
traffic signs. To that end, we train classification models on synthetic data
sets and evaluate their classification accuracy in a controlled setting. In
particular, we focus on differences between currently deployed pictograms in
the two countries, and a set of new pictograms designed to increase human
readability. Besides other results, we find that machine-learning models
generalize poorly to data sets with pictogram designs they have not been
trained on. We conclude that manufacturers of advanced driver-assistance
systems (ADAS) must take special care to properly address small visual
differences between current and newly designed traffic sign pictograms, as well
as between pictograms from different countries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Multidiversified Ensemble Clustering of High-Dimensional Data: From Subspaces to Metrics and Beyond. (arXiv:1710.03113v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1710.03113">
<div class="article-summary-box-inner">
<span><p>The rapid emergence of high-dimensional data in various areas has brought new
challenges to current ensemble clustering research. To deal with the curse of
dimensionality, recently considerable efforts in ensemble clustering have been
made by means of different subspace-based techniques. However, besides the
emphasis on subspaces, rather limited attention has been paid to the potential
diversity in similarity/dissimilarity metrics. It remains a surprisingly open
problem in ensemble clustering how to create and aggregate a large population
of diversified metrics, and furthermore, how to jointly investigate the
multi-level diversity in the large populations of metrics, subspaces, and
clusters in a unified framework. To tackle this problem, this paper proposes a
novel multidiversified ensemble clustering approach. In particular, we create a
large number of diversified metrics by randomizing a scaled exponential
similarity kernel, which are then coupled with random subspaces to form a large
set of metric-subspace pairs. Based on the similarity matrices derived from
these metric-subspace pairs, an ensemble of diversified base clusterings can
thereby be constructed. Further, an entropy-based criterion is utilized to
explore the cluster-wise diversity in ensembles, based on which three specific
ensemble clustering algorithms are presented by incorporating three types of
consensus functions. Extensive experiments are conducted on 30 high-dimensional
datasets, including 18 cancer gene expression datasets and 12 image/speech
datasets, which demonstrate the superiority of our algorithms over the
state-of-the-art. The source code is available at
https://github.com/huangdonghere/MDEC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Customization Strategies and Convergence Behaviors of Task-specific ADMM. (arXiv:1909.10819v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.10819">
<div class="article-summary-box-inner">
<span><p>Alternating Direction Method of Multiplier (ADMM) has been a popular
algorithmic framework for separable optimization problems with linear
constraints. For numerical ADMM fail to exploit the particular structure of the
problem at hand nor the input data information, leveraging task-specific
modules (e.g., neural networks and other data-driven architectures) to extend
ADMM is a significant but challenging task. This work focuses on designing a
flexible algorithmic framework to incorporate various task-specific modules
(with no additional constraints) to improve the performance of ADMM in
real-world applications. Specifically, we propose Guidance from Optimality
(GO), a new customization strategy, to embed task-specific modules into ADMM
(GO-ADMM). By introducing an optimality-based criterion to guide the
propagation, GO-ADMM establishes an updating scheme agnostic to the choice of
additional modules. The existing task-specific methods just plug their
task-specific modules into the numerical iterations in a straightforward
manner. Even with some restrictive constraints on the plug-in modules, they can
only obtain some relatively weaker convergence properties for the resulted ADMM
iterations. Fortunately, without any restrictions on the embedded modules, we
prove the convergence of GO-ADMM regarding objective values and constraint
violations, and derive the worst-case convergence rate measured by iteration
complexity. Extensive experiments are conducted to verify the theoretical
results and demonstrate the efficiency of GO-ADMM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance. (arXiv:1909.10837v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.10837">
<div class="article-summary-box-inner">
<span><p>Spiking neural network (SNN) is interesting both theoretically and
practically because of its strong bio-inspiration nature and potentially
outstanding energy efficiency. Unfortunately, its development has fallen far
behind the conventional deep neural network (DNN), mainly because of difficult
training and lack of widely accepted hardware experiment platforms. In this
paper, we show that a deep temporal-coded SNN can be trained easily and
directly over the benchmark datasets CIFAR10 and ImageNet, with testing
accuracy within 1% of the DNN of equivalent size and architecture. Training
becomes similar to DNN thanks to the closed-form solution to the spiking
waveform dynamics. Considering that SNNs should be implemented in practical
neuromorphic hardwares, we train the deep SNN with weights quantized to 8, 4, 2
bits and with weights perturbed by random noise to demonstrate its robustness
in practical applications. In addition, we develop a phase-domain signal
processing circuit schematic to implement our spiking neuron with 90% gain of
energy efficiency over existing work. This paper demonstrates that the
temporal-coded deep SNN is feasible for applications with high performance and
high energy efficient.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Do Compressed Deep Neural Networks Forget?. (arXiv:1911.05248v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.05248">
<div class="article-summary-box-inner">
<span><p>Deep neural network pruning and quantization techniques have demonstrated it
is possible to achieve high levels of compression with surprisingly little
degradation to test set accuracy. However, this measure of performance conceals
significant differences in how different classes and images are impacted by
model compression techniques. We find that models with radically different
numbers of weights have comparable top-line performance metrics but diverge
considerably in behavior on a narrow subset of the dataset. This small subset
of data points, which we term Pruning Identified Exemplars (PIEs) are
systematically more impacted by the introduction of sparsity. Compression
disproportionately impacts model performance on the underrepresented long-tail
of the data distribution. PIEs over-index on atypical or noisy images that are
far more challenging for both humans and algorithms to classify. Our work
provides intuition into the role of capacity in deep neural networks and the
trade-offs incurred by compression. An understanding of this disparate impact
is critical given the widespread deployment of compressed models in the wild.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Multi-Object Detector by Estimating Bounding Box Distribution for Input Image. (arXiv:1911.12721v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.12721">
<div class="article-summary-box-inner">
<span><p>In multi-object detection using neural networks, the fundamental problem is,
"How should the network learn a variable number of bounding boxes in different
input images?". Previous methods train a multi-object detection network through
a procedure that directly assigns the ground truth bounding boxes to the
specific locations of the network's output. However, this procedure makes the
training of a multi-object detection network too heuristic and complicated. In
this paper, we reformulate the multi-object detection task as a problem of
density estimation of bounding boxes. Instead of assigning each ground truth to
specific locations of network's output, we train a network by estimating the
probability density of bounding boxes in an input image using a mixture model.
For this purpose, we propose a novel network for object detection called
Mixture Density Object Detector (MDOD), and the corresponding objective
function for the density-estimation-based training. We applied MDOD to MS COCO
dataset. Our proposed method not only deals with multi-object detection
problems in a new approach, but also improves detection performances through
MDOD. The code is available: https://github.com/yoojy31/MDOD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Long Tail Visual Relationship Recognition with Large Vocabulary. (arXiv:2004.00436v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.00436">
<div class="article-summary-box-inner">
<span><p>Several approaches have been proposed in recent literature to alleviate the
long-tail problem, mainly in object classification tasks. In this paper, we
make the first large-scale study concerning the task of Long-Tail Visual
Relationship Recognition (LTVRR). LTVRR aims at improving the learning of
structured visual relationships that come from the long-tail (e.g., "rabbit
grazing on grass"). In this setup, the subject, relation, and object classes
each follow a long-tail distribution. To begin our study and make a future
benchmark for the community, we introduce two LTVRR-related benchmarks, dubbed
VG8K-LT and GQA-LT, built upon the widely used Visual Genome and GQA datasets.
We use these benchmarks to study the performance of several state-of-the-art
long-tail models on the LTVRR setup. Lastly, we propose a visiolinguistic
hubless (VilHub) loss and a Mixup augmentation technique adapted to LTVRR
setup, dubbed as RelMix. Both VilHub and RelMix can be easily integrated on top
of existing models and despite being simple, our results show that they can
remarkably improve the performance, especially on tail classes. Benchmarks,
code, and models have been made available at:
https://github.com/Vision-CAIR/LTVRR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AIBench Scenario: Scenario-distilling AI Benchmarking. (arXiv:2005.03459v4 [cs.PF] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.03459">
<div class="article-summary-box-inner">
<span><p>Modern real-world application scenarios like Internet services consist of a
diversity of AI and non-AI modules with huge code sizes and long and
complicated execution paths, which raises serious benchmarking or evaluating
challenges. Using AI components or micro benchmarks alone can lead to
error-prone conclusions. This paper presents a methodology to attack the above
challenge. We formalize a real-world application scenario as a Directed Acyclic
Graph-based model and propose the rules to distill it into a permutation of
essential AI and non-AI tasks, which we call a scenario benchmark. Together
with seventeen industry partners, we extract nine typical scenario benchmarks.
We design and implement an extensible, configurable, and flexible benchmark
framework. We implement two Internet service AI scenario benchmarks based on
the framework as proxies to two real-world application scenarios. We consider
scenario, component, and micro benchmarks as three indispensable parts for
evaluating. Our evaluation shows the advantage of our methodology against using
component or micro AI benchmarks alone. The specifications, source code,
testbed, and results are publicly available from
\url{https://www.benchcouncil.org/aibench/scenario/}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Privacy Preserving Edge Computing Framework for Image Classification. (arXiv:2005.04563v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.04563">
<div class="article-summary-box-inner">
<span><p>In order to extract knowledge from the large data collected by edge devices,
traditional cloud based approach that requires data upload may not be feasible
due to communication bandwidth limitation as well as privacy and security
concerns of end users. To address these challenges, a novel privacy preserving
edge computing framework is proposed in this paper for image classification.
Specifically, autoencoder will be trained unsupervised at each edge device
individually, then the obtained latent vectors will be transmitted to the edge
server for the training of a classifier. This framework would reduce the
communications overhead and protect the data of the end users. Comparing to
federated learning, the training of the classifier in the proposed framework
does not subject to the constraints of the edge devices, and the autoencoder
can be trained independently at each edge device without any server
involvement. Furthermore, the privacy of the end users' data is protected by
transmitting latent vectors without additional cost of encryption. Experimental
results provide insights on the image classification performance vs. various
design parameters such as the data compression ratio of the autoencoder and the
model complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TearingNet: Point Cloud Autoencoder to Learn Topology-Friendly Representations. (arXiv:2006.10187v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10187">
<div class="article-summary-box-inner">
<span><p>Topology matters. Despite the recent success of point cloud processing with
geometric deep learning, it remains arduous to capture the complex topologies
of point cloud data with a learning model. Given a point cloud dataset
containing objects with various genera, or scenes with multiple objects, we
propose an autoencoder, TearingNet, which tackles the challenging task of
representing the point clouds using a fixed-length descriptor. Unlike existing
works directly deforming predefined primitives of genus zero (e.g., a 2D square
patch) to an object-level point cloud, our TearingNet is characterized by a
proposed Tearing network module and a Folding network module interacting with
each other iteratively. Particularly, the Tearing network module learns the
point cloud topology explicitly. By breaking the edges of a primitive graph, it
tears the graph into patches or with holes to emulate the topology of a target
point cloud, leading to faithful reconstructions. Experimentation shows the
superiority of our proposal in terms of reconstructing point clouds as well as
generating more topology-friendly representations than benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Explanation Based on Gradual Construction for Deep Networks. (arXiv:2008.01897v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01897">
<div class="article-summary-box-inner">
<span><p>To understand the black-box characteristics of deep networks, counterfactual
explanation that deduces not only the important features of an input space but
also how those features should be modified to classify input as a target class
has gained an increasing interest. The patterns that deep networks have learned
from a training dataset can be grasped by observing the feature variation among
various classes. However, current approaches perform the feature modification
to increase the classification probability for the target class irrespective of
the internal characteristics of deep networks. This often leads to unclear
explanations that deviate from real-world data distributions. To address this
problem, we propose a counterfactual explanation method that exploits the
statistics learned from a training dataset. Especially, we gradually construct
an explanation by iterating over masking and composition steps. The masking
step aims to select an important feature from the input data to be classified
as a target class. Meanwhile, the composition step aims to optimize the
previously selected feature by ensuring that its output score is close to the
logit space of the training data that are classified as the target class.
Experimental results show that our method produces human-friendly
interpretations on various classification datasets and verify that such
interpretations can be achieved with fewer feature modification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Signal Processing for Geometric Data and Beyond: Theory and Applications. (arXiv:2008.01918v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01918">
<div class="article-summary-box-inner">
<span><p>Geometric data acquired from real-world scenes, e.g., 2D depth images, 3D
point clouds, and 4D dynamic point clouds, have found a wide range of
applications including immersive telepresence, autonomous driving,
surveillance, etc. Due to irregular sampling patterns of most geometric data,
traditional image/video processing methodologies are limited, while Graph
Signal Processing (GSP) -- a fast-developing field in the signal processing
community -- enables processing signals that reside on irregular domains and
plays a critical role in numerous applications of geometric data from low-level
processing to high-level analysis. To further advance the research in this
field, we provide the first timely and comprehensive overview of GSP
methodologies for geometric data in a unified manner by bridging the
connections between geometric data and graphs, among the various geometric data
modalities, and with spectral/nodal graph filtering techniques. We also discuss
the recently developed Graph Neural Networks (GNNs) and interpret the operation
of these networks from the perspective of GSP. We conclude with a brief
discussion of open problems and challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Assessing the Generalization Envelope of Deep Neural Networks: Predictive Uncertainty, Out-of-distribution and Adversarial Samples. (arXiv:2008.09381v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.09381">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks (DNNs) achieve state-of-the-art performance on numerous
applications. However, it is difficult to tell beforehand if a DNN receiving an
input will deliver the correct output since their decision criteria are usually
nontransparent. A DNN delivers the correct output if the input is within the
area enclosed by its generalization envelope. In this case, the information
contained in the input sample is processed reasonably by the network. It is of
large practical importance to assess at inference time if a DNN generalizes
correctly. Currently, the approaches to achieve this goal are investigated in
different problem set-ups rather independently from one another, leading to
three main research and literature fields: predictive uncertainty,
out-of-distribution detection and adversarial example detection. This survey
connects the three fields within the larger framework of investigating the
generalization performance of machine learning methods and in particular DNNs.
We underline the common ground, point at the most promising approaches and give
a structured overview of the methods that provide at inference time means to
establish if the current input is within the generalization envelope of a DNN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Spectral Image Synthesis for Crop/Weed Segmentation in Precision Farming. (arXiv:2009.05750v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05750">
<div class="article-summary-box-inner">
<span><p>An effective perception system is a fundamental component for farming robots,
as it enables them to properly perceive the surrounding environment and to
carry out targeted operations. The most recent methods make use of
state-of-the-art machine learning techniques to learn a valid model for the
target task. However, those techniques need a large amount of labeled data for
training. A recent approach to deal with this issue is data augmentation
through Generative Adversarial Networks (GANs), where entire synthetic scenes
are added to the training data, thus enlarging and diversifying their
informative content. In this work, we propose an alternative solution with
respect to the common data augmentation methods, applying it to the fundamental
problem of crop/weed segmentation in precision farming. Starting from real
images, we create semi-artificial samples by replacing the most relevant object
classes (i.e., crop and weeds) with their synthesized counterparts. To do that,
we employ a conditional GAN (cGAN), where the generative model is trained by
conditioning the shape of the generated object. Moreover, in addition to RGB
data, we take into account also near-infrared (NIR) information, generating
four channel multi-spectral synthetic images. Quantitative experiments, carried
out on three publicly available datasets, show that (i) our model is capable of
generating realistic multi-spectral images of plants and (ii) the usage of such
synthetic images in the training process improves the segmentation performance
of state-of-the-art semantic segmentation convolutional networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tailoring: encoding inductive biases by optimizing unsupervised objectives at prediction time. (arXiv:2009.10623v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10623">
<div class="article-summary-box-inner">
<span><p>From CNNs to attention mechanisms, encoding inductive biases into neural
networks has been a fruitful source of improvement in machine learning. Adding
auxiliary losses to the main objective function is a general way of encoding
biases that can help networks learn better representations. However, since
auxiliary losses are minimized only on training data, they suffer from the same
generalization gap as regular task losses. Moreover, by adding a term to the
loss function, the model optimizes a different objective than the one we care
about. In this work we address both problems: first, we take inspiration from
\textit{transductive learning} and note that after receiving an input but
before making a prediction, we can fine-tune our networks on any unsupervised
loss. We call this process {\em tailoring}, because we customize the model to
each input to ensure our prediction satisfies the inductive bias. Second, we
formulate {\em meta-tailoring}, a nested optimization similar to that in
meta-learning, and train our models to perform well on the task objective after
adapting them using an unsupervised loss. The advantages of tailoring and
meta-tailoring are discussed theoretically and demonstrated empirically on a
diverse set of examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Out-of-Distribution Detection for Automotive Perception. (arXiv:2011.01413v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01413">
<div class="article-summary-box-inner">
<span><p>Neural networks (NNs) are widely used for object classification in autonomous
driving. However, NNs can fail on input data not well represented by the
training dataset, known as out-of-distribution (OOD) data. A mechanism to
detect OOD samples is important for safety-critical applications, such as
automotive perception, to trigger a safe fallback mode. NNs often rely on
softmax normalization for confidence estimation, which can lead to high
confidences being assigned to OOD samples, thus hindering the detection of
failures. This paper presents a method for determining whether inputs are OOD,
which does not require OOD data during training and does not increase the
computational cost of inference. The latter property is especially important in
automotive applications with limited computational resources and real-time
constraints. Our proposed approach outperforms state-of-the-art methods on
real-world automotive datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SHAD3S: A model to Sketch, Shade and Shadow. (arXiv:2011.06822v3 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06822">
<div class="article-summary-box-inner">
<span><p>Hatching is a common method used by artists to accentuate the third dimension
of a sketch, and to illuminate the scene. Our system SHAD3S attempts to compete
with a human at hatching generic three-dimensional (3D) shapes, and also tries
to assist her in a form exploration exercise. The novelty of our approach lies
in the fact that we make no assumptions about the input other than that it
represents a 3D shape, and yet, given a contextual information of illumination
and texture, we synthesise an accurate hatch pattern over the sketch, without
access to 3D or pseudo 3D. In the process, we contribute towards a) a cheap yet
effective method to synthesise a sufficiently large high fidelity dataset,
pertinent to task; b) creating a pipeline with conditional generative
adversarial network (CGAN); and c) creating an interactive utility with GIMP,
that is a tool for artists to engage with automated hatching or a
form-exploration exercise. User evaluation of the tool suggests that the model
performance does generalise satisfactorily over diverse input, both in terms of
style as well as shape. A simple comparison of inception scores suggest that
the generated distribution is as diverse as the ground truth.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Data Hiding Using Inverse Gradient Attention. (arXiv:2011.10850v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10850">
<div class="article-summary-box-inner">
<span><p>Data hiding is the procedure of encoding desired information into the cover
image to resist potential noises while ensuring the embedded image has few
perceptual perturbations from the original one. Recently, with the tremendous
successes gained by deep neural networks in various fields, the researches of
data hiding with deep learning models have attracted an increasing number of
attentions. In the data hiding task, each pixel of cover images should be
treated differently since they have divergent tolerabilities. The neglect of
considering the sensitivity of each pixel will inevitably affect the model
robustness for information hiding. Targeting this problem, we propose a novel
deep data hiding scheme with Inverse Gradient Attention (IGA), combing the
ideas of adversarial learning and attention mechanism to endow different
sensitivities for different pixels. With the proposed component, the model can
spotlight pixels with more robustness for data hiding. Empirically, extensive
experiments show that the proposed model outperforms the state-of-the-art
methods on two prevalent datasets under multiple evaluations. Besides, we
further identify and discuss the connections between the proposed inverse
gradient attention and high-frequency regions within images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dissecting Image Crops. (arXiv:2011.11831v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11831">
<div class="article-summary-box-inner">
<span><p>The elementary operation of cropping underpins nearly every computer vision
system, ranging from data augmentation and translation invariance to
computational photography and representation learning. This paper investigates
the subtle traces introduced by this operation. For example, despite
refinements to camera optics, lenses will leave behind certain clues, notably
chromatic aberration and vignetting. Photographers also leave behind other
clues relating to image aesthetics and scene composition. We study how to
detect these traces, and investigate the impact that cropping has on the image
distribution. While our aim is to dissect the fundamental impact of spatial
crops, there are also a number of practical implications to our work, such as
revealing faulty photojournalism and equipping neural network researchers with
a better understanding of shortcut learning. Code is available at
https://github.com/basilevh/dissecting-image-crops.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Siamese Basis Function Networks for Data-efficient Defect Classification in Technical Domains. (arXiv:2012.01338v7 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01338">
<div class="article-summary-box-inner">
<span><p>Training deep learning models in technical domains is often accompanied by
the challenge that although the task is clear, insufficient data for training
is available. In this work, we propose a novel approach based on the
combination of Siamese networks and radial basis function networks to perform
data-efficient classification without pretraining by measuring the distance
between images in semantic space in a data-efficient manner. We develop the
models using three technical datasets, the NEU dataset, the BSD dataset, and
the TEX dataset. In addition to the technical domain, we show the general
applicability to classical datasets (cifar10 and MNIST) as well. The approach
is tested against state-of-the-art models (Resnet50 and Resnet101) by stepwise
reduction of the number of samples available for training. The authors show
that the proposed approach outperforms the state-of-the-art models in the low
data regime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Surprising Efficiency of Committee-based Models. (arXiv:2012.01988v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01988">
<div class="article-summary-box-inner">
<span><p>Committee-based models, i.e., model ensembles or cascades, are underexplored
in recent work on developing efficient models. While committee-based models
themselves are not new, there lacks a systematic understanding of their
efficiency in comparison with single models. To fill this gap, we conduct a
comprehensive analysis of the efficiency of committee-based models. We find
that committee-based models provide a complementary paradigm to achieve
superior efficiency without tuning the architecture: even the most simplistic
method for building ensembles or cascades from existing pre-trained networks
can attain a significant speedup and higher accuracy over state-of-the-art
single models, and also outperforms sophisticated neural architecture search
methods (e.g., BigNAS). The superior efficiency of committee-based models holds
true for several tasks, including image classification, video classification,
and semantic segmentation, and various architecture families, such as
EfficientNet, ResNet, MobileNetV2, and X3D.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Radiance Flow for 4D View Synthesis and Video Processing. (arXiv:2012.09790v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09790">
<div class="article-summary-box-inner">
<span><p>We present a method, Neural Radiance Flow (NeRFlow),to learn a 4D
spatial-temporal representation of a dynamic scene from a set of RGB images.
Key to our approach is the use of a neural implicit representation that learns
to capture the 3D occupancy, radiance, and dynamics of the scene. By enforcing
consistency across different modalities, our representation enables multi-view
rendering in diverse dynamic scenes, including water pouring, robotic
interaction, and real images, outperforming state-of-the-art methods for
spatial-temporal view synthesis. Our approach works even when inputs images are
captured with only one camera. We further demonstrate that the learned
representation can serve as an implicit scene prior, enabling video processing
tasks such as image super-resolution and de-noising without any additional
supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Tightness of Semidefinite Relaxations for Rotation Estimation. (arXiv:2101.02099v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02099">
<div class="article-summary-box-inner">
<span><p>Why is it that semidefinite relaxations have been so successful in numerous
applications in computer vision and robotics for solving non-convex
optimization problems involving rotations? In studying the empirical
performance we note that there are few failure cases reported in the
literature, in particular for estimation problems with a single rotation,
motivating us to gain further theoretical understanding.
</p>
<p>A general framework based on tools from algebraic geometry is introduced for
analyzing the power of semidefinite relaxations of problems with quadratic
objective functions and rotational constraints. Applications include
registration, hand-eye calibration and rotation averaging. We characterize the
extreme points, and show that there exist failure cases for which the
relaxation is not tight, even in the case of a single rotation. We also show
that some problem classes are always tight given an appropriate
parametrization. Our theoretical findings are accompanied with numerical
simulations, providing further evidence and understanding of the results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Continual Learning in Image Classification: An Empirical Survey. (arXiv:2101.10423v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10423">
<div class="article-summary-box-inner">
<span><p>Online continual learning for image classification studies the problem of
learning to classify images from an online stream of data and tasks, where
tasks may include new classes (class incremental) or data nonstationarity
(domain incremental). One of the key challenges of continual learning is to
avoid catastrophic forgetting (CF), i.e., forgetting old tasks in the presence
of more recent tasks. Over the past few years, many methods and tricks have
been introduced to address this problem, but many have not been fairly and
systematically compared under a variety of realistic and practical settings. To
better understand the relative advantages of various approaches and the
settings where they work best, this survey aims to (1) compare state-of-the-art
methods such as MIR, iCARL, and GDumb and determine which works best at
different experimental settings; (2) determine if the best class incremental
methods are also competitive in domain incremental setting; (3) evaluate the
performance of 7 simple but effective trick such as "review" trick and nearest
class mean (NCM) classifier to assess their relative impact. Regarding (1), we
observe iCaRL remains competitive when the memory buffer is small; GDumb
outperforms many recently proposed methods in medium-size datasets and MIR
performs the best in larger-scale datasets. For (2), we note that GDumb
performs quite poorly while MIR -- already competitive for (1) -- is also
strongly competitive in this very different but important setting. Overall,
this allows us to conclude that MIR is overall a strong and versatile method
across a wide variety of settings. For (3), we find that all 7 tricks are
beneficial, and when augmented with the "review" trick and NCM classifier, MIR
produces performance levels that bring online continual learning much closer to
its ultimate goal of matching offline training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-tuning deep learning model parameters for improved super-resolution of dynamic MRI with prior-knowledge. (arXiv:2102.02711v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02711">
<div class="article-summary-box-inner">
<span><p>Dynamic imaging is a beneficial tool for interventions to assess
physiological changes. Nonetheless during dynamic MRI, while achieving a high
temporal resolution, the spatial resolution is compromised. To overcome this
spatio-temporal trade-off, this research presents a super-resolution (SR) MRI
reconstruction with prior knowledge based fine-tuning to maximise spatial
information while reducing the required scan-time for dynamic MRIs. An U-Net
based network with perceptual loss is trained on a benchmark dataset and
fine-tuned using one subject-specific static high resolution MRI as prior
knowledge to obtain high resolution dynamic images during the inference stage.
3D dynamic data for three subjects were acquired with different parameters to
test the generalisation capabilities of the network. The method was tested for
different levels of in-plane undersampling for dynamic MRI. The reconstructed
dynamic SR results after fine-tuning showed higher similarity with the high
resolution ground-truth, while quantitatively achieving statistically
significant improvement. The average SSIM of the lowest resolution experimented
during this research (6.25~\% of the k-space) before and after fine-tuning were
0.939 $\pm$ 0.008 and 0.957 $\pm$ 0.006 respectively. This could theoretically
result in an acceleration factor of 16, which can potentially be acquired in
less than half a second. The proposed approach shows that the super-resolution
MRI reconstruction with prior-information can alleviate the spatio-temporal
trade-off in dynamic MRI, even for high acceleration factors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CORSAIR: Convolutional Object Retrieval and Symmetry-AIded Registration. (arXiv:2103.06911v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06911">
<div class="article-summary-box-inner">
<span><p>This paper considers online object-level mapping using partial point-cloud
observations obtained online in an unknown environment. We develop and approach
for fully Convolutional Object Retrieval and Symmetry-AIded Registration
(CORSAIR). Our model extends the Fully Convolutional Geometric Features model
to learn a global object-shape embedding in addition to local point-wise
features from the point-cloud observations. The global feature is used to
retrieve a similar object from a category database, and the local features are
used for robust pose registration between the observed and the retrieved
object. Our formulation also leverages symmetries, present in the object
shapes, to obtain promising local-feature pairs from different symmetry classes
for matching. We present results from synthetic and real-world datasets with
different object categories to verify the robustness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VMAF And Variants: Towards A Unified VQA. (arXiv:2103.07770v6 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07770">
<div class="article-summary-box-inner">
<span><p>Video quality assessment (VQA) is now a fast-growing subject, maturing in the
full reference (FR) case, yet challenging in the exploding no reference (NR)
case. We investigate variants of the popular VMAF video quality assessment
algorithm for the FR case, using both support vector regression and feedforward
neural networks. We extend it to the NR case, using some different features but
similar learning, to develop a partially unified framework for VQA. When fully
trained, FR algorithms such as VMAF perform well on test datasets, with 90%+
match in PCC and SRCC; but for predicting performance in the wild, we
train/test from scratch for each database. With an 80/20 train/test split, we
still achieve 90%+ performance on average in both PCC and SRCC, with 8-9% gains
over VMAF. Moreover, we even get decent performance (~75%) if we ignore the
reference, treating FR as NR, partly justifying our attempts at unification. In
the true NR case, we reduce complexity vs. leading recent algorithms VIDEVAL,
RAPIQUE, yet achieve a stunning 90% in SRCC (~12% gain), while roughly matching
in PCC (78% vs. 79.6%). At lower complexities, we can still achieve 87% in
SRCC, 70% in PCC. In short, we find encouraging improvements in trainability in
both FR and NR, while also constraining computational complexity against
leading methods
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Triplet-Watershed for Hyperspectral Image Classification. (arXiv:2103.09384v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09384">
<div class="article-summary-box-inner">
<span><p>Hyperspectral images (HSI) consist of rich spatial and spectral information,
which can potentially be used for several applications. However, noise, band
correlations and high dimensionality restrict the applicability of such data.
This is recently addressed using creative deep learning network architectures
such as ResNet, SSRN, and A2S2K. However, the last layer, i.e the
classification layer, remains unchanged and is taken to be the softmax
classifier. In this article, we propose to use a watershed classifier.
Watershed classifier extends the watershed operator from Mathematical
Morphology for classification. In its vanilla form, the watershed classifier
does not have any trainable parameters. In this article, we propose a novel
approach to train deep learning networks to obtain representations suitable for
the watershed classifier. The watershed classifier exploits the connectivity
patterns, a characteristic of HSI datasets, for better inference. We show that
exploiting such characteristics allows the Triplet-Watershed to achieve
state-of-art results in supervised and semi-supervised contexts. These results
are validated on Indianpines (IP), University of Pavia (UP), Kennedy Space
Center (KSC) and University of Houston (UH) datasets, relying on simple convnet
architecture using a quarter of parameters compared to previous
state-of-the-art networks. The source code for reproducing the experiments and
supplementary material (high resolution images) is available at
https://github.com/ac20/TripletWatershed Code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instance-level Image Retrieval using Reranking Transformers. (arXiv:2103.12236v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12236">
<div class="article-summary-box-inner">
<span><p>Instance-level image retrieval is the task of searching in a large database
for images that match an object in a query image. To address this task, systems
usually rely on a retrieval step that uses global image descriptors, and a
subsequent step that performs domain-specific refinements or reranking by
leveraging operations such as geometric verification based on local features.
In this work, we propose Reranking Transformers (RRTs) as a general model to
incorporate both local and global features to rerank the matching images in a
supervised fashion and thus replace the relatively expensive process of
geometric verification. RRTs are lightweight and can be easily parallelized so
that reranking a set of top matching results can be performed in a single
forward-pass. We perform extensive experiments on the Revisited Oxford and
Paris datasets, and the Google Landmarks v2 dataset, showing that RRTs
outperform previous reranking approaches while using much fewer local
descriptors. Moreover, we demonstrate that, unlike existing approaches, RRTs
can be optimized jointly with the feature extractor, which can lead to feature
representations tailored to downstream tasks and further accuracy improvements.
The code and trained models are publicly available at
https://github.com/uvavision/RerankingTransformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scene Graphs: A Survey of Generations and Applications. (arXiv:2104.01111v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01111">
<div class="article-summary-box-inner">
<span><p>Scene graph is a structured representation of a scene that can clearly
express the objects, attributes, and relationships between objects in the
scene. As computer vision technology continues to develop, people are no longer
satisfied with simply detecting and recognizing objects in images; instead,
people look forward to a higher level of understanding and reasoning about
visual scenes. For example, given an image, we want to not only detect and
recognize objects in the image, but also know the relationship between objects
(visual relationship detection), and generate a text description (image
captioning) based on the image content. Alternatively, we might want the
machine to tell us what the little girl in the image is doing (Visual Question
Answering (VQA)), or even remove the dog from the image and find similar images
(image editing and retrieval), etc. These tasks require a higher level of
understanding and reasoning for image vision tasks. The scene graph is just
such a powerful tool for scene understanding. Therefore, scene graphs have
attracted the attention of a large number of researchers, and related research
is often cross-modal, complex, and rapidly developing. However, no relatively
systematic survey of scene graphs exists at present. To this end, this survey
conducts a comprehensive investigation of the current scene graph research.
More specifically, we first summarized the general definition of the scene
graph, then conducted a comprehensive and systematic discussion on the
generation method of the scene graph (SGG) and the SGG with the aid of prior
knowledge. We then investigated the main applications of scene graphs and
summarized the most commonly used datasets. Finally, we provide some insights
into the future development of scene graphs. We believe this will be a very
helpful foundation for future research on scene graphs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robotic Waste Sorter with Agile Manipulation and Quickly Trainable Detector. (arXiv:2104.01260v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01260">
<div class="article-summary-box-inner">
<span><p>Owing to human labor shortages, the automation of labor-intensive manual
waste-sorting is needed. The goal of automating waste-sorting is to replace the
human role of robust detection and agile manipulation of waste items with
robots. To achieve this, we propose three methods. First, we provide a combined
manipulation method using graspless push-and-drop and pick-and-release
manipulation. Second, we provide a robotic system that can automatically
collect object images to quickly train a deep neural-network model. Third, we
provide a method to mitigate the differences in the appearance of target
objects from two scenes: one for dataset collection and the other for waste
sorting in a recycling factory. If differences exist, the performance of a
trained waste detector may decrease. We address differences in illumination and
background by applying object scaling, histogram matching with histogram
equalization, and background synthesis to the source target-object images. Via
experiments in an indoor experimental workplace for waste-sorting, we confirm
that the proposed methods enable quick collection of the training image sets
for three classes of waste items (i.e., aluminum can, glass bottle, and plastic
bottle) and detection with higher performance than the methods that do not
consider the differences. We also confirm that the proposed method enables the
robot quickly manipulate the objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intelligent Monitoring of Stress Induced by Water Deficiency in Plants using Deep Learning. (arXiv:2104.07911v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07911">
<div class="article-summary-box-inner">
<span><p>In the recent decade, high-throughput plant phenotyping techniques, which
combine non-invasive image analysis and machine learning, have been
successfully applied to identify and quantify plant health and diseases.
However, these techniques usually do not consider the progressive nature of
plant stress and often require images showing severe signs of stress to ensure
high confidence detection, thereby reducing the feasibility for early detection
and recovery of plants under stress. To overcome the problem mentioned above,
we propose a deep learning pipeline for the temporal analysis of the visual
changes induced in the plant due to stress and apply it to the specific water
stress identification case in Chickpea plant shoot images. For this, we have
considered an image dataset of two chickpea varieties JG-62 and Pusa-372, under
three water stress conditions; control, young seedling, and before flowering,
captured over five months. We have employed a variant of Convolutional Neural
Network - Long Short Term Memory (CNN-LSTM) network to learn spatio-temporal
patterns from the chickpea plant dataset and use them for water stress
classification. Our model has achieved ceiling level classification performance
of 98.52% on JG-62 and 97.78% on Pusa-372 chickpea plant data and has
outperformed the best reported time-invariant technique by at least 14% for
both JG-62 and Pusa-372 species, to the best of our knowledge. Furthermore, our
CNN-LSTM model has demonstrated robustness to noisy input, with a less than
2.5% dip in average model accuracy and a small standard deviation about the
mean for both species. Lastly, we have performed an ablation study to analyze
the performance of the CNN-LSTM model by decreasing the number of temporal
session data used for training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Task Generalization via Natural Language Crowdsourcing Instructions. (arXiv:2104.08773v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08773">
<div class="article-summary-box-inner">
<span><p>Humans (e.g., crowdworkers) have a remarkable ability in solving different
tasks, by simply reading textual instructions that define them and looking at a
few examples. NLP models built with the conventional paradigm, however, often
struggle with generalization across tasks (e.g., a question-answering system
cannot solve classification tasks). A long-standing challenge in AI is to build
a model that is equipped with the understanding of human-readable instructions
that define the tasks, and can generalize to new tasks. To study this, we
introduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their
human-authored instructions and 193k task instances. The instructions are
obtained from crowdsourcing instructions used to collect existing NLP datasets
and mapped to a unified schema. We adopt generative pre-trained language models
to encode task-specific instructions along with input and generate task output.
Our results indicate that models can benefit from instructions to generalize
across tasks. These models, however, are far behind supervised task-specific
models, indicating significant room for more progress in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Segmentation, Compression and Reconstruction from Edge Distribution Estimation with Random Field and Random Cluster Theories. (arXiv:2104.10762v12 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10762">
<div class="article-summary-box-inner">
<span><p>Random field and random cluster theory are used to describe certain
mathematical results concerning the probability distribution of image pixel
intensities characterized as generic $2D$ integer arrays. The size of the
smallest bounded region within an image is estimated for segmenting an image,
from which, the equilibrium distribution of intensities can be recovered. From
the estimated bounded regions, properties of the sub-optimal and equilibrium
distributions of intensities are derived, which leads to an image compression
methodology whereby only slightly more than half of all pixels are required for
a worst-case reconstruction of the original image. A custom deep belief network
and heuristic allows for the unsupervised segmentation, detection and
localization of objects in an image. An example illustrates the mathematical
results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate and fast matrix factorization for low-rank learning. (arXiv:2104.10785v4 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10785">
<div class="article-summary-box-inner">
<span><p>In this paper, we tackle two important problems in low-rank learning, which
are partial singular value decomposition and numerical rank estimation of huge
matrices. By using the concepts of Krylov subspaces such as Golub-Kahan
bidiagonalization (GK-bidiagonalization) as well as Ritz vectors, we propose
two methods for solving these problems in a fast and accurate way. Our
experiments show the advantages of the proposed methods compared to the
traditional and randomized singular value decomposition methods. The proposed
methods are appropriate for applications involving huge matrices where the
accuracy of the desired singular values and also all of their corresponding
singular vectors are essential. As a real application, we evaluate the
performance of our methods on the problem of Riemannian similarity learning
between two various image datasets of MNIST and USPS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Clustering Networks for Self-supervised Learning from Unlabeled Videos. (arXiv:2104.12671v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12671">
<div class="article-summary-box-inner">
<span><p>Multimodal self-supervised learning is getting more and more attention as it
allows not only to train large networks without human supervision but also to
search and retrieve data across various modalities. In this context, this paper
proposes a self-supervised training framework that learns a common multimodal
embedding space that, in addition to sharing representations across different
modalities, enforces a grouping of semantically similar instances. To this end,
we extend the concept of instance-level contrastive learning with a multimodal
clustering step in the training pipeline to capture semantic similarities
across modalities. The resulting embedding space enables retrieval of samples
across all modalities, even from unseen datasets and different domains. To
evaluate our approach, we train our model on the HowTo100M dataset and evaluate
its zero-shot retrieval capabilities in two challenging domains, namely
text-to-video retrieval, and temporal action localization, showing
state-of-the-art results on four different datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inpainting Transformer for Anomaly Detection. (arXiv:2104.13897v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13897">
<div class="article-summary-box-inner">
<span><p>Anomaly detection in computer vision is the task of identifying images which
deviate from a set of normal images. A common approach is to train deep
convolutional autoencoders to inpaint covered parts of an image and compare the
output with the original image. By training on anomaly-free samples only, the
model is assumed to not being able to reconstruct anomalous regions properly.
For anomaly detection by inpainting we suggest it to be beneficial to
incorporate information from potentially distant regions. In particular we pose
anomaly detection as a patch-inpainting problem and propose to solve it with a
purely self-attention based approach discarding convolutions. The proposed
Inpainting Transformer (InTra) is trained to inpaint covered patches in a large
sequence of image patches, thereby integrating information across large regions
of the input image. When training from scratch, in comparison to other methods
not using extra training data, InTra achieves results on par with the current
state-of-the-art on the MVTec AD dataset for detection and surpassing them on
segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to drive from a world on rails. (arXiv:2105.00636v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00636">
<div class="article-summary-box-inner">
<span><p>We learn an interactive vision-based driving policy from pre-recorded driving
logs via a model-based approach. A forward model of the world supervises a
driving policy that predicts the outcome of any potential driving trajectory.
To support learning from pre-recorded logs, we assume that the world is on
rails, meaning neither the agent nor its actions influence the environment.
This assumption greatly simplifies the learning problem, factorizing the
dynamics into a nonreactive world model and a low-dimensional and compact
forward model of the ego-vehicle. Our approach computes action-values for each
training trajectory using a tabular dynamic-programming evaluation of the
Bellman equations; these action-values in turn supervise the final vision-based
driving policy. Despite the world-on-rails assumption, the final driving policy
acts well in a dynamic and reactive world. At the time of writing, our method
ranks first on the CARLA leaderboard, attaining a 25% higher driving score
while using 40 times less data. Our method is also an order of magnitude more
sample-efficient than state-of-the-art model-free reinforcement learning
techniques on navigational tasks in the ProcGen benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-task fully convolutional network for tree species mapping in dense forests using small training hyperspectral data. (arXiv:2106.00799v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00799">
<div class="article-summary-box-inner">
<span><p>This work proposes a multi-task fully convolutional architecture for tree
species mapping in dense forests from sparse and scarce polygon-level
annotations using hyperspectral UAV-borne data. Our model implements a partial
loss function that enables dense tree semantic labeling outcomes from non-dense
training samples, and a distance regression complementary task that enforces
tree crown boundary constraints and substantially improves the model
performance. Our multi-task architecture uses a shared backbone network that
learns common representations for both tasks and two task-specific decoders,
one for the semantic segmentation output and one for the distance map
regression. We report that introducing the complementary task boosts the
semantic segmentation performance compared to the single-task counterpart in up
to 11% reaching an average user's accuracy of 88.63% and an average producer's
accuracy of 88.59%, achieving state-of-art performance for tree species
classification in tropical forests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rotation Equivariant Feature Image Pyramid Network for Object Detection in Optical Remote Sensing Imagery. (arXiv:2106.00880v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00880">
<div class="article-summary-box-inner">
<span><p>Detection of objects is extremely important in various aerial vision-based
applications. Over the last few years, the methods based on convolution neural
networks have made substantial progress. However, because of the large variety
of object scales, densities, and arbitrary orientations, the current detectors
struggle with the extraction of semantically strong features for small-scale
objects by a predefined convolution kernel. To address this problem, we propose
the rotation equivariant feature image pyramid network (REFIPN), an image
pyramid network based on rotation equivariance convolution. The proposed model
adopts single-shot detector in parallel with a lightweight image pyramid module
to extract representative features and generate regions of interest in an
optimization approach. The proposed network extracts feature in a wide range of
scales and orientations by using novel convolution filters. These features are
used to generate vector fields and determine the weight and angle of the
highest-scoring orientation for all spatial locations on an image. By this
approach, the performance for small-sized object detection is enhanced without
sacrificing the performance for large-sized object detection. The performance
of the proposed model is validated on two commonly used aerial benchmarks and
the results show our proposed model can achieve state-of-the-art performance
with satisfactory efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tackling the Background Bias in Sparse Object Detection via Cropped Windows. (arXiv:2106.02288v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02288">
<div class="article-summary-box-inner">
<span><p>Object detection on Unmanned Aerial Vehicles (UAVs) is still a challenging
task. The recordings are mostly sparse and contain only small objects. In this
work, we propose a simple tiling method that improves the detection capability
in the remote sensing case without modifying the model itself. By reducing the
background bias and enabling the usage of higher image resolutions during
training, our method can improve the performance of models substantially. The
procedure was validated on three different data sets and outperformed similar
approaches in performance and speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Virtual Temporal Samples for Recurrent Neural Networks: applied to semantic segmentation in agriculture. (arXiv:2106.10118v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10118">
<div class="article-summary-box-inner">
<span><p>This paper explores the potential for performing temporal semantic
segmentation in the context of agricultural robotics without temporally
labelled data. We achieve this by proposing to generate virtual temporal
samples from labelled still images. By exploiting the relatively static scene
and assuming that the robot (camera) moves we are able to generate virtually
labelled temporal sequences with no extra annotation effort. Normally, to train
a recurrent neural network (RNN), labelled samples from a video (temporal)
sequence are required which is laborious and has stymied work in this
direction. By generating virtual temporal samples, we demonstrate that it is
possible to train a lightweight RNN to perform semantic segmentation on two
challenging agricultural datasets. Our results show that by training a temporal
semantic segmenter using virtual samples we can increase the performance by an
absolute amount of $4.6$ and $4.9$ on sweet pepper and sugar beet datasets,
respectively. This indicates that our virtual data augmentation technique is
able to accurately classify agricultural images temporally without the use of
complicated synthetic data generation techniques nor with the overhead of
labelling large amounts of temporal sequences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Marching Cubes. (arXiv:2106.11272v3 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11272">
<div class="article-summary-box-inner">
<span><p>We introduce Neural Marching Cubes (NMC), a data-driven approach for
extracting a triangle mesh from a discretized implicit field. Classical MC is
defined by coarse tessellation templates isolated to individual cubes. While
more refined tessellations have been proposed, they all make heuristic
assumptions, such as trilinearity, when determining the vertex positions and
local mesh topologies in each cube. In principle, none of these approaches can
reconstruct geometric features that reveal coherence or dependencies between
nearby cubes (e.g., a sharp edge), as such information is unaccounted for,
resulting in poor estimates of the true underlying implicit field. To tackle
these challenges, we re-cast MC from a deep learning perspective, by designing
tessellation templates more apt at preserving geometric features, and learning
the vertex positions and mesh topologies from training meshes, to account for
contextual information from nearby cubes. We develop a compact per-cube
parameterization to represent the output triangle mesh, while being compatible
with neural processing, so that a simple 3D convolutional network can be
employed for the training. We show that all topological cases in each cube that
are applicable to our design can be easily derived using our representation,
and the resulting tessellations can also be obtained naturally and efficiently
by following a few design guidelines. In addition, our network learns local
features with limited receptive fields, hence it generalizes well to new shapes
and new datasets. We evaluate our neural MC approach by quantitative and
qualitative comparisons to all well-known MC variants. In particular, we
demonstrate the ability of our network to recover sharp features such as edges
and corners, a long-standing issue of MC and its variants. Our network also
reconstructs local mesh topologies more accurately than previous approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Survey of Image-Based Food Recognition and Volume Estimation Methods for Dietary Assessment. (arXiv:2106.11776v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11776">
<div class="article-summary-box-inner">
<span><p>Dietary studies showed that dietary-related problem such as obesity is
associated with other chronic diseases like hypertension, irregular blood sugar
levels, and increased risk of heart attacks. The primary cause of these
problems is poor lifestyle choices and unhealthy dietary habits, which are
manageable using interactive mHealth apps. However, traditional dietary
monitoring systems using manual food logging suffer from imprecision,
underreporting, time consumption, and low adherence. Recent dietary monitoring
systems tackle these challenges by automatic assessment of dietary intake
through machine learning methods. This survey discusses the most performing
methodologies that have been developed so far for automatic food recognition
and volume estimation. First, we will present the rationale of visual-based
methods for food recognition. The core of the paper is the presentation,
discussion and evaluation of these methods on popular food image databases.
Following that, we discussed the mobile applications that are implementing
these methods. The survey ends with a discussion of research gaps and open
issues in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topological Semantic Mapping by Consolidation of Deep Visual Features. (arXiv:2106.12709v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12709">
<div class="article-summary-box-inner">
<span><p>Many works in the recent literature introduce semantic mapping methods that
use CNNs (Convolutional Neural Networks) to recognize semantic properties in
images. The types of properties (eg.: room size, place category, and objects)
and their classes (eg.: kitchen and bathroom, for place category) are usually
predefined and restricted to a specific task. Thus, all the visual data
acquired and processed during the construction of the maps are lost and only
the recognized semantic properties remain on the maps. In contrast, this work
introduces a topological semantic mapping method that uses deep visual features
extracted by a CNN (GoogLeNet), from 2D images captured in multiple views of
the environment as the robot operates, to create, through averages,
consolidated representations of the visual features acquired in the regions
covered by each topological node. These representations allow flexible
recognition of semantic properties of the regions and use in other visual
tasks. Experiments with a real-world indoor dataset showed that the method is
able to consolidate the visual features of regions and use them to recognize
objects and place categories as semantic properties, and to indicate the
topological location of images, with very promising results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-Supervised Raw-to-Raw Mapping. (arXiv:2106.13883v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13883">
<div class="article-summary-box-inner">
<span><p>The raw-RGB colors of a camera sensor vary due to the spectral sensitivity
differences across different sensor makes and models. This paper focuses on the
task of mapping between different sensor raw-RGB color spaces. Prior work
addressed this problem using a pairwise calibration to achieve accurate color
mapping. Although being accurate, this approach is less practical as it
requires: (1) capturing pair of images by both camera devices with a color
calibration object placed in each new scene; (2) accurate image alignment or
manual annotation of the color calibration object. This paper aims to tackle
color mapping in the raw space through a more practical setup. Specifically, we
present a semi-supervised raw-to-raw mapping method trained on a small set of
paired images alongside an unpaired set of images captured by each camera
device. Through extensive experiments, we show that our method achieves better
results compared to other domain adaptation alternatives in addition to the
single-calibration solution. We have generated a new dataset of raw images from
two different smartphone cameras as part of this effort. Our dataset includes
unpaired and paired sets for our semi-supervised training and evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CAMS: Color-Aware Multi-Style Transfer. (arXiv:2106.13920v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13920">
<div class="article-summary-box-inner">
<span><p>Image style transfer aims to manipulate the appearance of a source image, or
"content" image, to share similar texture and colors of a target "style" image.
Ideally, the style transfer manipulation should also preserve the semantic
content of the source image. A commonly used approach to assist in transferring
styles is based on Gram matrix optimization. One problem of Gram matrix-based
optimization is that it does not consider the correlation between colors and
their styles. Specifically, certain textures or structures should be associated
with specific colors. This is particularly challenging when the target style
image exhibits multiple style types. In this work, we propose a color-aware
multi-style transfer method that generates aesthetically pleasing results while
preserving the style-color correlation between style and generated images. We
achieve this desired outcome by introducing a simple but efficient modification
to classic Gram matrix-based style transfer optimization. A nice feature of our
method is that it enables the users to manually select the color associations
between the target style and content image for more transfer flexibility. We
validated our method with several qualitative comparisons, including a user
study conducted with 30 participants. In comparison with prior work, our method
is simple, easy to implement, and achieves visually appealing results when
targeting images that have multiple styles. Source code is available at
https://github.com/mahmoudnafifi/color-aware-style-transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Does Heterogeneous Label Noise Impact Generalization in Neural Nets?. (arXiv:2106.15475v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15475">
<div class="article-summary-box-inner">
<span><p>Incorrectly labeled examples, or label noise, is common in real-world
computer vision datasets. While the impact of label noise on learning in deep
neural networks has been studied in prior work, these studies have exclusively
focused on homogeneous label noise, i.e., the degree of label noise is the same
across all categories. However, in the real-world, label noise is often
heterogeneous, with some categories being affected to a greater extent than
others. Here, we address this gap in the literature. We hypothesized that
heterogeneous label noise would only affect the classes that had label noise
unless there was transfer from those classes to the classes without label
noise. To test this hypothesis, we designed a series of computer vision studies
using MNIST, CIFAR-10, CIFAR-100, and MS-COCO where we imposed heterogeneous
label noise during the training of multi-class, multi-task, and multi-label
systems. Our results provide evidence in support of our hypothesis: label noise
only affects the class affected by it unless there is transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Greedy Offset-Guided Keypoint Grouping for Human Pose Estimation. (arXiv:2107.03098v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03098">
<div class="article-summary-box-inner">
<span><p>We propose a simple yet reliable bottom-up approach with a good trade-off
between accuracy and efficiency for the problem of multi-person pose
estimation. Given an image, we employ an Hourglass Network to infer all the
keypoints from different persons indiscriminately as well as the guiding
offsets connecting the adjacent keypoints belonging to the same persons. Then,
we greedily group the candidate keypoints into multiple human poses (if any),
utilizing the predicted guiding offsets. And we refer to this process as greedy
offset-guided keypoint grouping (GOG). Moreover, we revisit the
encoding-decoding method for the multi-person keypoint coordinates and reveal
some important facts affecting accuracy. Experiments have demonstrated the
obvious performance improvements brought by the introduced components. Our
approach is comparable to the state of the art on the challenging COCO dataset
under fair conditions. The source code and our pre-trained model are publicly
available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-view Image-based Hand Geometry Refinement using Differentiable Monte Carlo Ray Tracing. (arXiv:2107.05509v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05509">
<div class="article-summary-box-inner">
<span><p>The amount and quality of datasets and tools available in the research field
of hand pose and shape estimation act as evidence to the significant progress
that has been made.However, even the datasets of the highest quality, reported
to date, have shortcomings in annotation. We propose a refinement approach,
based on differentiable ray tracing,and demonstrate how a high-quality publicly
available, multi-camera dataset of hands(InterHand2.6M) can become an even
better dataset, with respect to annotation quality. Differentiable ray tracing
has not been employed so far to relevant problems and is hereby shown to be
superior to the approximative alternatives that have been employed in the past.
To tackle the lack of reliable ground truth, as far as quantitative evaluation
is concerned, we resort to realistic synthetic data, to show that the
improvement we induce is indeed significant. The same becomes evident in real
data through visual evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DRIVE: Deep Reinforced Accident Anticipation with Visual Explanation. (arXiv:2107.10189v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10189">
<div class="article-summary-box-inner">
<span><p>Traffic accident anticipation aims to accurately and promptly predict the
occurrence of a future accident from dashcam videos, which is vital for a
safety-guaranteed self-driving system. To encourage an early and accurate
decision, existing approaches typically focus on capturing the cues of spatial
and temporal context before a future accident occurs. However, their
decision-making lacks visual explanation and ignores the dynamic interaction
with the environment. In this paper, we propose Deep ReInforced accident
anticipation with Visual Explanation, named DRIVE. The method simulates both
the bottom-up and top-down visual attention mechanism in a dashcam observation
environment so that the decision from the proposed stochastic multi-task agent
can be visually explained by attentive regions. Moreover, the proposed dense
anticipation reward and sparse fixation reward are effective in training the
DRIVE model with our improved reinforcement learning algorithm. Experimental
results show that the DRIVE model achieves state-of-the-art performance on
multiple real-world traffic accident datasets. Code and pre-trained model are
available at \url{https://www.rit.edu/actionlab/drive}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personalized Image Semantic Segmentation. (arXiv:2107.13978v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13978">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation models trained on public datasets have achieved great
success in recent years. However, these models didn't consider the
personalization issue of segmentation though it is important in practice. In
this paper, we address the problem of personalized image segmentation. The
objective is to generate more accurate segmentation results on unlabeled
personalized images by investigating the data's personalized traits. To open up
future research in this area, we collect a large dataset containing various
users' personalized images called PIS (Personalized Image Semantic
Segmentation). We also survey some recent researches related to this problem
and report their performance on our dataset. Furthermore, by observing the
correlation among a user's personalized images, we propose a baseline method
that incorporates the inter-image context when segmenting certain images.
Extensive experiments show that our method outperforms the existing methods on
the proposed dataset. The code and the PIS dataset will be made publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Free Lunch for Co-Saliency Detection: Context Adjustment. (arXiv:2108.02093v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02093">
<div class="article-summary-box-inner">
<span><p>We unveil a long-standing problem in the prevailing co-saliency detection
systems: there is indeed inconsistency between training and testing.
Constructing a high-quality co-saliency detection dataset involves
time-consuming and labor-intensive pixel-level labeling, which has forced most
recent works to rely instead on semantic segmentation or saliency detection
datasets for training. However, the lack of proper co-saliency and the absence
of multiple foreground objects in these datasets can lead to spurious
variations and inherent biases learned by models. To tackle this, we introduce
the idea of counterfactual training through context adjustment, and propose a
"cost-free" group-cut-paste (GCP) procedure to leverage images from
off-the-shelf saliency detection datasets and synthesize new samples. Following
GCP, we collect a novel dataset called Context Adjustment Training (CAT). CAT
consists of 33,500 images, making it four times larger than the current
co-saliency detection datasets. All images are automatically annotated with
high-quality mask annotations, object categories, and edge maps. Extensive
experiments with state-of-the-art models are conducted to demonstrate the
superiority of our dataset. We hope that the scale, diversity, and quality of
our dataset can benefit researchers in this area and beyond. The dataset and
benchmark toolkit will be publicly accessible through our project page.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parallel Capsule Networks for Classification of White Blood Cells. (arXiv:2108.02644v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02644">
<div class="article-summary-box-inner">
<span><p>Capsule Networks (CapsNets) is a machine learning architecture proposed to
overcome some of the shortcomings of convolutional neural networks (CNNs).
However, CapsNets have mainly outperformed CNNs in datasets where images are
small and/or the objects to identify have minimal background noise. In this
work, we present a new architecture, parallel CapsNets, which exploits the
concept of branching the network to isolate certain capsules, allowing each
branch to identify different entities. We applied our concept to the two
current types of CapsNet architectures, studying the performance for networks
with different layers of capsules. We tested our design in a public, highly
unbalanced dataset of acute myeloid leukaemia images (15 classes). Our
experiments showed that conventional CapsNets show similar performance than our
baseline CNN (ResNeXt-50) but depict instability problems. In contrast,
parallel CapsNets can outperform ResNeXt-50, is more stable, and shows better
rotational invariance than both, conventional CapsNets and ResNeXt-50.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Embodied Vision Navigation: A Survey. (arXiv:2108.04097v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04097">
<div class="article-summary-box-inner">
<span><p>Navigation is one of the fundamental features of a autonomous robot. And the
ability of long-term navigation with semantic instruction is a `holy grail`
goals of intelligent robots. The development of 3D simulation technology
provide a large scale of data to simulate the real-world environment. The deep
learning proves its ability to robustly learn various embodied navigation
tasks. However, deep learning on embodied navigation is still in its infancy
due to the unique challenges faced by the navigation exploration and learning
from partial observed visual input. Recently, deep learning in embodied
navigation has become even thriving, with numerous methods have been proposed
to tackle different challenges in this area. To give a promising direction for
future research, in this paper, we present a comprehensive review of embodied
navigation tasks and the recent progress in deep learning based methods. It
includes two major tasks: target-oriented navigation and the
instruction-oriented navigation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FakeAVCeleb: A Novel Audio-Video Multimodal Deepfake Dataset. (arXiv:2108.05080v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05080">
<div class="article-summary-box-inner">
<span><p>While significant advancements have been made in the generation of deepfakes
using deep learning technologies, its misuse is a well-known issue now.
Deepfakes can cause severe security and privacy issues as they can be used to
impersonate a person's identity in a video by replacing his/her face with
another person's face. Recently, a new problem of generating synthesized human
voice of a person is emerging, where AI-based deep learning models can
synthesize any person's voice requiring just a few seconds of audio. With the
emerging threat of impersonation attacks using deepfake audios and videos, a
new generation of deepfake detectors is needed to focus on both video and audio
collectively. A large amount of good quality datasets is typically required to
capture the real-world scenarios to develop a competent deepfake detector.
Existing deepfake datasets either contain deepfake videos or audios, which are
racially biased as well. Hence, there is a crucial need for creating a good
video as well as an audio deepfake dataset, which can be used to detect audio
and video deepfake simultaneously. To fill this gap, we propose a novel
Audio-Video Deepfake dataset (FakeAVCeleb) that contains not only deepfake
videos but also respective synthesized lip-synced fake audios. We generate this
dataset using the current most popular deepfake generation methods. We selected
real YouTube videos of celebrities with four racial backgrounds (Caucasian,
Black, East Asian, and South Asian) to develop a more realistic multimodal
dataset that addresses racial bias and further help develop multimodal deepfake
detectors. We performed several experiments using state-of-the-art detection
methods to evaluate our deepfake dataset and demonstrate the challenges and
usefulness of our multimodal Audio-Video deepfake dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Confidence Adaptive Regularization for Deep Learning with Noisy Labels. (arXiv:2108.08212v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08212">
<div class="article-summary-box-inner">
<span><p>Recent studies on the memorization effects of deep neural networks on noisy
labels show that the networks first fit the correctly-labeled training samples
before memorizing the mislabeled samples. Motivated by this early-learning
phenomenon, we propose a novel method to prevent memorization of the mislabeled
samples. Unlike the existing approaches which use the model output to identify
or ignore the mislabeled samples, we introduce an indicator branch to the
original model and enable the model to produce a confidence value for each
sample. The confidence values are incorporated in our loss function which is
learned to assign large confidence values to correctly-labeled samples and
small confidence values to mislabeled samples. We also propose an auxiliary
regularization term to further improve the robustness of the model. To improve
the performance, we gradually correct the noisy labels with a well-designed
target estimation strategy. We provide the theoretical analysis and conduct the
experiments on synthetic and real-world datasets, demonstrating that our
approach achieves comparable results to the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ranking Models in Unlabeled New Environments. (arXiv:2108.10310v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10310">
<div class="article-summary-box-inner">
<span><p>Consider a scenario where we are supplied with a number of ready-to-use
models trained on a certain source domain and hope to directly apply the most
appropriate ones to different target domains based on the models' relative
performance. Ideally we should annotate a validation set for model performance
assessment on each new target environment, but such annotations are often very
expensive. Under this circumstance, we introduce the problem of ranking models
in unlabeled new environments. For this problem, we propose to adopt a proxy
dataset that 1) is fully labeled and 2) well reflects the true model rankings
in a given target environment, and use the performance rankings on the proxy
sets as surrogates. We first select labeled datasets as the proxy.
Specifically, datasets that are more similar to the unlabeled target domain are
found to better preserve the relative performance rankings. Motivated by this,
we further propose to search the proxy set by sampling images from various
datasets that have similar distributions as the target. We analyze the problem
and its solutions on the person re-identification (re-ID) task, for which
sufficient datasets are publicly available, and show that a carefully
constructed proxy set effectively captures relative performance ranking in new
environments. Code is available at \url{https://github.com/sxzrt/Proxy-Set}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CPFN: Cascaded Primitive Fitting Networks for High-Resolution Point Clouds. (arXiv:2109.00113v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00113">
<div class="article-summary-box-inner">
<span><p>Representing human-made objects as a collection of base primitives has a long
history in computer vision and reverse engineering. In the case of
high-resolution point cloud scans, the challenge is to be able to detect both
large primitives as well as those explaining the detailed parts. While the
classical RANSAC approach requires case-specific parameter tuning,
state-of-the-art networks are limited by memory consumption of their backbone
modules such as PointNet++, and hence fail to detect the fine-scale primitives.
We present Cascaded Primitive Fitting Networks (CPFN) that relies on an
adaptive patch sampling network to assemble detection results of global and
local primitive detection networks. As a key enabler, we present a merging
formulation that dynamically aggregates the primitives across global and local
scales. Our evaluation demonstrates that CPFN improves the state-of-the-art
SPFN performance by 13-14% on high-resolution point cloud datasets and
specifically improves the detection of fine-scale primitives by 20-22%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regional Adversarial Training for Better Robust Generalization. (arXiv:2109.00678v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00678">
<div class="article-summary-box-inner">
<span><p>Adversarial training (AT) has been demonstrated as one of the most promising
defense methods against various adversarial attacks. To our knowledge, existing
AT-based methods usually train with the locally most adversarial perturbed
points and treat all the perturbed points equally, which may lead to
considerably weaker adversarial robust generalization on test data. In this
work, we introduce a new adversarial training framework that considers the
diversity as well as characteristics of the perturbed points in the vicinity of
benign samples. To realize the framework, we propose a Regional Adversarial
Training (RAT) defense method that first utilizes the attack path generated by
the typical iterative attack method of projected gradient descent (PGD), and
constructs an adversarial region based on the attack path. Then, RAT samples
diverse perturbed training points efficiently inside this region, and utilizes
a distance-aware label smoothing mechanism to capture our intuition that
perturbed points at different locations should have different impact on the
model performance. Extensive experiments on several benchmark datasets show
that RAT consistently makes significant improvement on standard adversarial
training (SAT), and exhibits better robust generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatio-temporal-spectral-angular observation model that integrates observations from UAV and mobile mapping vehicle for better urban mapping. (arXiv:2109.00900v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00900">
<div class="article-summary-box-inner">
<span><p>In a complex urban scene, observation from a single sensor unavoidably leads
to voids in observations, failing to describe urban objects in a comprehensive
manner. In this paper, we propose a spatio-temporal-spectral-angular
observation model to integrate observations from UAV and mobile mapping vehicle
platform, realizing a joint, coordinated observation operation from both air
and ground. We develop a multi-source remote sensing data acquisition system to
effectively acquire multi-angle data of complex urban scenes. Multi-source data
fusion solves the missing data problem caused by occlusion and achieves
accurate, rapid, and complete collection of holographic spatial and temporal
information in complex urban scenes. We carried out an experiment on Baisha
Town, Chongqing, China and obtained multi-sensor, multi-angle data from UAV and
mobile mapping vehicle. We first extracted the point cloud from UAV and then
integrated the UAV and mobile mapping vehicle point cloud. The integrated
results combined both the characteristic of UAV and mobile mapping vehicle
point cloud, confirming the practicability of the proposed joint data
acquisition platform and the effectiveness of spatio-temporal-spectral-angular
observation model. Compared with the observation from UAV or mobile mapping
vehicle alone, the integrated system provides an effective data acquisition
solution towards comprehensive urban monitoring.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards disease-aware image editing of chest X-rays. (arXiv:2109.01071v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01071">
<div class="article-summary-box-inner">
<span><p>Disease-aware image editing by means of generative adversarial networks
(GANs) constitutes a promising avenue for advancing the use of AI in the
healthcare sector. Here, we present a proof of concept of this idea. While
GAN-based techniques have been successful in generating and manipulating
natural images, their application to the medical domain, however, is still in
its infancy. Working with the CheXpert data set, we show that StyleGAN can be
trained to generate realistic chest X-rays. Inspired by the Cyclic Reverse
Generator (CRG) framework, we train an encoder that allows for faithfully
inverting the generator on synthetic X-rays and provides organ-level
reconstructions of real ones. Employing a guided manipulation of latent codes,
we confer the medical condition of cardiomegaly (increased heart size) onto
real X-rays from healthy patients. This work was presented in the Medical
Imaging meets Neurips Workshop 2020, which was held as part of the 34th
Conference on Neural Information Processing Systems (NeurIPS 2020) in
Vancouver, Canada
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Networks for Data Augmentation of Human Physical Activity Recognition. (arXiv:2109.01081v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01081">
<div class="article-summary-box-inner">
<span><p>Data augmentation is a widely used technique in classification to increase
data used in training. It improves generalization and reduces amount of
annotated human activity data needed for training which reduces labour and time
needed with the dataset. Sensor time-series data, unlike images, cannot be
augmented by computationally simple transformation algorithms. State of the art
models like Recurrent Generative Adversarial Networks (RGAN) are used to
generate realistic synthetic data. In this paper, transformer based generative
adversarial networks which have global attention on data, are compared on
PAMAP2 and Real World Human Activity Recognition data sets with RGAN. The newer
approach provides improvements in time and savings in computational resources
needed for data augmentation than previous approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Semi-Automated Algorithm for Volumetric Segmentation of the Left Ventricle in Temporal 3D Echocardiography Sequences. (arXiv:2109.01132v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01132">
<div class="article-summary-box-inner">
<span><p>Purpose: Echocardiography is commonly used as a non-invasive imaging tool in
clinical practice for the assessment of cardiac function. However, delineation
of the left ventricle is challenging due to the inherent properties of
ultrasound imaging, such as the presence of speckle noise and the low
signal-to-noise ratio. Methods: We propose a semi-automated segmentation
algorithm for the delineation of the left ventricle in temporal 3D
echocardiography sequences. The method requires minimal user interaction and
relies on a diffeomorphic registration approach. Advantages of the method
include no dependence on prior geometrical information, training data, or
registration from an atlas. Results: The method was evaluated using
three-dimensional ultrasound scan sequences from 18 patients from the
Mazankowski Alberta Heart Institute, Edmonton, Canada, and compared to manual
delineations provided by an expert cardiologist and four other registration
algorithms. The segmentation approach yielded the following results over the
cardiac cycle: a mean absolute difference of 1.01 (0.21) mm, a Hausdorff
distance of 4.41 (1.43) mm, and a Dice overlap score of 0.93 (0.02).
Conclusions: The method performed well compared to the four other registration
algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimal Target Shape for LiDAR Pose Estimation. (arXiv:2109.01181v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01181">
<div class="article-summary-box-inner">
<span><p>Targets are essential in problems such as object tracking in cluttered or
textureless environments, camera (and multi-sensor) calibration tasks, and
simultaneous localization and mapping (SLAM). Target shapes for these tasks
typically are symmetric (square, rectangular, or circular) and work well for
structured, dense sensor data such as pixel arrays (i.e., image). However,
symmetric shapes lead to pose ambiguity when using sparse sensor data such as
LiDAR point clouds and suffer from the quantization uncertainty of the LiDAR.
This paper introduces the concept of optimizing target shape to remove pose
ambiguity for LiDAR point clouds. A target is designed to induce large
gradients at edge points under rotation and translation relative to the LiDAR
to ameliorate the quantization uncertainty associated with point cloud
sparseness. Moreover, given a target shape, we present a means that leverages
the target's geometry to estimate the target's vertices while globally
estimating the pose. Both the simulation and the experimental results (verified
by a motion capture system) confirm that by using the optimal shape and the
global solver, we achieve centimeter error in translation and a few degrees in
rotation even when a partially illuminated target is placed 30 meters away. All
the implementations and datasets are available at
https://github.com/UMich-BipedLab/optimal_shape_global_pose_estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual-Camera Super-Resolution with Aligned Attention Modules. (arXiv:2109.01349v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01349">
<div class="article-summary-box-inner">
<span><p>We present a novel approach to reference-based super-resolution (RefSR) with
the focus on dual-camera super-resolution (DCSR), which utilizes reference
images for high-quality and high-fidelity results. Our proposed method
generalizes the standard patch-based feature matching with spatial alignment
operations. We further explore the dual-camera super-resolution that is one
promising application of RefSR, and build a dataset that consists of 146 image
pairs from the main and telephoto cameras in a smartphone. To bridge the domain
gaps between real-world images and the training images, we propose a
self-supervised domain adaptation strategy for real-world images. Extensive
experiments on our dataset and a public benchmark demonstrate clear improvement
achieved by our method over state of the art in both quantitative evaluation
and visual comparisons.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CX-ToM: Counterfactual Explanations with Theory-of-Mind for Enhancing Human Trust in Image Recognition Models. (arXiv:2109.01401v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01401">
<div class="article-summary-box-inner">
<span><p>We propose CX-ToM, short for counterfactual explanations with theory-of mind,
a new explainable AI (XAI) framework for explaining decisions made by a deep
convolutional neural network (CNN). In contrast to the current methods in XAI
that generate explanations as a single shot response, we pose explanation as an
iterative communication process, i.e. dialog, between the machine and human
user. More concretely, our CX-ToM framework generates sequence of explanations
in a dialog by mediating the differences between the minds of machine and human
user. To do this, we use Theory of Mind (ToM) which helps us in explicitly
modeling human's intention, machine's mind as inferred by the human as well as
human's mind as inferred by the machine. Moreover, most state-of-the-art XAI
frameworks provide attention (or heat map) based explanations. In our work, we
show that these attention based explanations are not sufficient for increasing
human trust in the underlying CNN model. In CX-ToM, we instead use
counterfactual explanations called fault-lines which we define as follows:
given an input image I for which a CNN classification model M predicts class
c_pred, a fault-line identifies the minimal semantic-level features (e.g.,
stripes on zebra, pointed ears of dog), referred to as explainable concepts,
that need to be added to or deleted from I in order to alter the classification
category of I by M to another specified class c_alt. We argue that, due to the
iterative, conceptual and counterfactual nature of CX-ToM explanations, our
framework is practical and more natural for both expert and non-expert users to
understand the internal workings of complex deep learning models. Extensive
quantitative and qualitative experiments verify our hypotheses, demonstrating
that our CX-ToM significantly outperforms the state-of-the-art explainable AI
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Handwritten Character Recognition of South Indian Scripts: A Review. (arXiv:1106.0107v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1106.0107">
<div class="article-summary-box-inner">
<span><p>Handwritten character recognition is always a frontier area of research in
the field of pattern recognition and image processing and there is a large
demand for OCR on hand written documents. Even though, sufficient studies have
performed in foreign scripts like Chinese, Japanese and Arabic characters, only
a very few work can be traced for handwritten character recognition of Indian
scripts especially for the South Indian scripts. This paper provides an
overview of offline handwritten character recognition in South Indian Scripts,
namely Malayalam, Tamil, Kannada and Telungu.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-07 23:02:14.890590374 UTC">2021-09-07 23:02:14 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>