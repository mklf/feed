<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-11-03T01:30:00Z">11-03</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">ASMDD: Arabic Speech Mispronunciation Detection Dataset. (arXiv:2111.01136v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01136">
<div class="article-summary-box-inner">
<span><p>The largest dataset of Arabic speech mispronunciation detections in Egyptian
dialogues is introduced. The dataset is composed of annotated audio files
representing the top 100 words that are most frequently used in the Arabic
language, pronounced by 100 Egyptian children (aged between 2 and 8 years old).
The dataset is collected and annotated on segmental pronunciation error
detections by expert listeners.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating robustness of You Only Hear Once(YOHO) Algorithm on noisy audios in the VOICe Dataset. (arXiv:2111.01205v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01205">
<div class="article-summary-box-inner">
<span><p>Sound event detection (SED) in machine listening entails identifying the
different sounds in an audio file and identifying the start and end time of a
particular sound event in the audio. SED finds use in various applications such
as audio surveillance, speech recognition, and context-based indexing and
retrieval of data in a multimedia database. However, in real-life scenarios,
the audios from various sources are seldom devoid of any interfering noise or
disturbance. In this paper, we test the performance of the You Only Hear Once
(YOHO) algorithm on noisy audio data. Inspired by the You Only Look Once (YOLO)
algorithm in computer vision, the YOHO algorithm can match the performance of
the various state-of-the-art algorithms on datasets such as Music Speech
Detection Dataset, TUT Sound Event, and Urban-SED datasets but at lower
inference times. In this paper, we explore the performance of the YOHO
algorithm on the VOICe dataset containing audio files with noise at different
sound-to-noise ratios (SNR). YOHO could outperform or at least match the best
performing SED algorithms reported in the VOICe dataset paper and make
inferences in less time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying causal associations in tweets using deep learning: Use case on diabetes-related tweets from 2017-2021. (arXiv:2111.01225v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01225">
<div class="article-summary-box-inner">
<span><p>Objective: Leveraging machine learning methods, we aim to extract both
explicit and implicit cause-effect associations in patient-reported,
diabetes-related tweets and provide a tool to better understand opinion,
feelings and observations shared within the diabetes online community from a
causality perspective. Materials and Methods: More than 30 million
diabetes-related tweets in English were collected between April 2017 and
January 2021. Deep learning and natural language processing methods were
applied to focus on tweets with personal and emotional content. A
cause-effect-tweet dataset was manually labeled and used to train 1) a
fine-tuned Bertweet model to detect causal sentences containing a causal
association 2) a CRF model with BERT based features to extract possible
cause-effect associations. Causes and effects were clustered in a
semi-supervised approach and visualised in an interactive cause-effect-network.
Results: Causal sentences were detected with a recall of 68% in an imbalanced
dataset. A CRF model with BERT based features outperformed a fine-tuned BERT
model for cause-effect detection with a macro recall of 68%. This led to 96,676
sentences with cause-effect associations. "Diabetes" was identified as the
central cluster followed by "Death" and "Insulin". Insulin pricing related
causes were frequently associated with "Death". Conclusions: A novel
methodology was developed to detect causal sentences and identify both explicit
and implicit, single and multi-word cause and corresponding effect as expressed
in diabetes-related tweets leveraging BERT-based architectures and visualised
as cause-effect-network. Extracting causal associations on real-life, patient
reported outcomes in social media data provides a useful complementary source
of information in diabetes research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Switch Point biased Self-Training: Re-purposing Pretrained Models for Code-Switching. (arXiv:2111.01231v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01231">
<div class="article-summary-box-inner">
<span><p>Code-switching (CS), a ubiquitous phenomenon due to the ease of communication
it offers in multilingual communities still remains an understudied problem in
language processing. The primary reasons behind this are: (1) minimal efforts
in leveraging large pretrained multilingual models, and (2) the lack of
annotated data. The distinguishing case of low performance of multilingual
models in CS is the intra-sentence mixing of languages leading to switch
points. We first benchmark two sequence labeling tasks -- POS and NER on 4
different language pairs with a suite of pretrained models to identify the
problems and select the best performing model, char-BERT, among them
(addressing (1)). We then propose a self training method to repurpose the
existing pretrained models using a switch-point bias by leveraging unannotated
data (addressing (2)). We finally demonstrate that our approach performs well
on both tasks by reducing the gap between the switch point performance while
retaining the overall performance on two distinct language pairs in both the
tasks. Our code is available here:
https://github.com/PC09/EMNLP2021-Switch-Point-biased-Self-Training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Cost Algorithmic Recourse for Users With Uncertain Cost Functions. (arXiv:2111.01235v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01235">
<div class="article-summary-box-inner">
<span><p>The problem of identifying algorithmic recourse for people affected by
machine learning model decisions has received much attention recently. Some
recent works model user-incurred cost, which is directly linked to user
satisfaction. But they assume a single global cost function that is shared
across all users. This is an unrealistic assumption when users have dissimilar
preferences about their willingness to act upon a feature and different costs
associated with changing that feature. In this work, we formalize the notion of
user-specific cost functions and introduce a new method for identifying
actionable recourses for users. By default, we assume that users' cost
functions are hidden from the recourse method, though our framework allows
users to partially or completely specify their preferences or cost function. We
propose an objective function, Expected Minimum Cost (EMC), based on two key
ideas: (1) when presenting a set of options to a user, it is vital that there
is at least one low-cost solution the user could adopt; (2) when we do not know
the user's true cost function, we can approximately optimize for user
satisfaction by first sampling plausible cost functions, then finding a set
that achieves a good cost for the user in expectation. We optimize EMC with a
novel discrete optimization algorithm, Cost-Optimized Local Search (COLS),
which is guaranteed to improve the recourse set quality over iterations.
Experimental evaluation on popular real-world datasets with simulated user
costs demonstrates that our method satisfies up to 25.89 percentage points more
users compared to strong baseline methods. Using standard fairness metrics, we
also show that our method can provide more fair solutions across demographic
groups than comparable methods, and we verify that our method is robust to
misspecification of the cost function distribution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey. (arXiv:2111.01243v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01243">
<div class="article-summary-box-inner">
<span><p>Large, pre-trained transformer-based language models such as BERT have
drastically changed the Natural Language Processing (NLP) field. We present a
survey of recent work that uses these large language models to solve NLP tasks
via pre-training then fine-tuning, prompting, or text generation approaches. We
also present approaches that use pre-trained language models to generate data
for training augmentation or other purposes. We conclude with discussions on
limitations and suggested directions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence Transduction with Graph-based Supervision. (arXiv:2111.01272v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01272">
<div class="article-summary-box-inner">
<span><p>The recurrent neural network transducer (RNN-T) objective plays a major role
in building today's best automatic speech recognition (ASR) systems for
production. Similarly to the connectionist temporal classification (CTC)
objective, the RNN-T loss uses specific rules that define how a set of
alignments is generated to form a lattice for the full-sum training. However,
it is yet largely unknown if these rules are optimal and do lead to the best
possible ASR results. In this work, we present a new transducer objective
function that generalizes the RNN-T loss to accept a graph representation of
the labels, thus providing a flexible and efficient framework to manipulate
training lattices, for example for restricting alignments or studying different
transition rules. We demonstrate that transducer-based ASR with CTC-like
lattice achieves better results compared to standard RNN-T, while also ensuring
a strictly monotonic alignment, which will allow better optimization of the
decoding procedure. For example, the proposed CTC-like transducer system
achieves a word error rate of 5.9% for the test-other condition of LibriSpeech,
corresponding to an improvement of 4.8% relative to an equivalent RNN-T based
system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP. (arXiv:2111.01322v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01322">
<div class="article-summary-box-inner">
<span><p>Meta-learning considers the problem of learning an efficient learning process
that can leverage its past experience to accurately solve new tasks. However,
the efficacy of meta-learning crucially depends on the distribution of tasks
available for training, and this is often assumed to be known a priori or
constructed from limited supervised datasets. In this work, we aim to provide
task distributions for meta-learning by considering self-supervised tasks
automatically proposed from unlabeled text, to enable large-scale meta-learning
in NLP. We design multiple distributions of self-supervised tasks by
considering important aspects of task diversity, difficulty, type, domain, and
curriculum, and investigate how they affect meta-learning performance. Our
analysis shows that all these factors meaningfully alter the task distribution,
some inducing significant improvements in downstream few-shot accuracy of the
meta-learned models. Empirically, results on 20 downstream tasks show
significant improvements in few-shot learning -- adding up to +4.2% absolute
accuracy (on average) to the previous unsupervised meta-learning method, and
perform comparably to supervised methods on the FewRel 2.0 benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual Transfer for Speech Processing using Acoustic Language Similarity. (arXiv:2111.01326v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01326">
<div class="article-summary-box-inner">
<span><p>Speech processing systems currently do not support the vast majority of
languages, in part due to the lack of data in low-resource languages.
Cross-lingual transfer offers a compelling way to help bridge this digital
divide by incorporating high-resource data into low-resource systems. Current
cross-lingual algorithms have shown success in text-based tasks and
speech-related tasks over some low-resource languages. However, scaling up
speech systems to support hundreds of low-resource languages remains unsolved.
To help bridge this gap, we propose a language similarity approach that can
efficiently identify acoustic cross-lingual transfer pairs across hundreds of
languages. We demonstrate the effectiveness of our approach in language family
classification, speech recognition, and speech synthesis tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting to the Long Tail: A Meta-Analysis of Transfer Learning Research for Language Understanding Tasks. (arXiv:2111.01340v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01340">
<div class="article-summary-box-inner">
<span><p>Natural language understanding (NLU) has made massive progress driven by
large benchmarks, paired with research on transfer learning to broaden its
impact. Benchmarks are dominated by a small set of frequent phenomena, leaving
a long tail of infrequent phenomena underrepresented. In this work, we reflect
on the question: have transfer learning methods sufficiently addressed
performance of benchmark-trained models on the long tail? Since benchmarks do
not list included/excluded phenomena, we conceptualize the long tail using
macro-level dimensions such as underrepresented genres, topics, etc. We assess
trends in transfer learning research through a qualitative meta-analysis of 100
representative papers on transfer learning for NLU. Our analysis asks three
questions: (i) Which long tail dimensions do transfer learning studies target?
(ii) Which properties help adaptation methods improve performance on the long
tail? (iii) Which methodological gaps have greatest negative impact on long
tail performance? Our answers to these questions highlight major avenues for
future research in transfer learning for the long tail. Lastly, we present a
case study comparing the performance of various adaptation methods on clinical
narratives to show how systematically conducted meta-experiments can provide
insights that enable us to make progress along these future avenues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating Pretrained Language Model for Dialogue Policy Learning. (arXiv:2111.01398v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01398">
<div class="article-summary-box-inner">
<span><p>Reinforcement Learning (RL) has been witnessed its potential for training a
dialogue policy agent towards maximizing the accumulated rewards given from
users. However, the reward can be very sparse for it is usually only provided
at the end of a dialog session, which causes unaffordable interaction
requirements for an acceptable dialog agent. Distinguished from many efforts
dedicated to optimizing the policy and recovering the reward alternatively
which suffers from easily getting stuck in local optima and model collapse, we
decompose the adversarial training into two steps: 1) we integrate a
pre-trained language model as a discriminator to judge whether the current
system action is good enough for the last user action (i.e., \textit{next
action prediction}); 2) the discriminator gives and extra local dense reward to
guide the agent's exploration. The experimental result demonstrates that our
method significantly improves the complete rate (~4.4\%) and success rate
(~8.0\%) of the dialogue system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Review of Dialogue Systems: From Trained Monkeys to Stochastic Parrots. (arXiv:2111.01414v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01414">
<div class="article-summary-box-inner">
<span><p>In spoken dialogue systems, we aim to deploy artificial intelligence to build
automated dialogue agents that can converse with humans. Dialogue systems are
increasingly being designed to move beyond just imitating conversation and also
improve from such interactions over time. In this survey, we present a broad
overview of methods developed to build dialogue systems over the years.
Different use cases for dialogue systems ranging from task-based systems to
open domain chatbots motivate and necessitate specific systems. Starting from
simple rule-based systems, research has progressed towards increasingly complex
architectures trained on a massive corpus of datasets, like deep learning
systems. Motivated with the intuition of resembling human dialogues, progress
has been made towards incorporating emotions into the natural language
generator, using reinforcement learning. While we see a trend of highly
marginal improvement on some metrics, we find that limited justification exists
for the metrics, and evaluation practices are not uniform. To conclude, we flag
these concerns and highlight possible research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">System Combination for Grammatical Error Correction Based on Integer Programming. (arXiv:2111.01465v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01465">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a system combination method for grammatical error
correction (GEC), based on nonlinear integer programming (IP). Our method
optimizes a novel F score objective based on error types, and combines multiple
end-to-end GEC systems. The proposed IP approach optimizes the selection of a
single best system for each grammatical error type present in the data.
Experiments of the IP approach on combining state-of-the-art standalone GEC
systems show that the combined system outperforms all standalone systems. It
improves F0.5 score by 3.61% when combining the two best participating systems
in the BEA 2019 shared task, and achieves F0.5 score of 73.08%. We also perform
experiments to compare our IP approach with another state-of-the-art system
combination method for GEC, demonstrating IP's competitive combination
capability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Translation using Diffusion Models. (arXiv:2111.01471v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01471">
<div class="article-summary-box-inner">
<span><p>In this work, we show a novel method for neural machine translation (NMT),
using a denoising diffusion probabilistic model (DDPM), adjusted for textual
data, following recent advances in the field. We show that it's possible to
translate sentences non-autoregressively using a diffusion model conditioned on
the source sentence. We also show that our model is able to translate between
pairs of languages unseen during training (zero-shot learning).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detection of Hate Speech using BERT and Hate Speech Word Embedding with Deep Model. (arXiv:2111.01515v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01515">
<div class="article-summary-box-inner">
<span><p>The enormous amount of data being generated on the web and social media has
increased the demand for detecting online hate speech. Detecting hate speech
will reduce their negative impact and influence on others. A lot of effort in
the Natural Language Processing (NLP) domain aimed to detect hate speech in
general or detect specific hate speech such as religion, race, gender, or
sexual orientation. Hate communities tend to use abbreviations, intentional
spelling mistakes, and coded words in their communication to evade detection,
adding more challenges to hate speech detection tasks. Thus, word
representation will play an increasingly pivotal role in detecting hate speech.
This paper investigates the feasibility of leveraging domain-specific word
embedding in Bidirectional LSTM based deep model to automatically
detect/classify hate speech. Furthermore, we investigate the use of the
transfer learning language model (BERT) on hate speech problem as a binary
classification task. The experiments showed that domainspecific word embedding
with the Bidirectional LSTM based deep model achieved a 93% f1-score while BERT
achieved up to 96% f1-score on a combined balanced dataset from available hate
speech datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HydraText: Multi-objective Optimization for Adversarial Textual Attack. (arXiv:2111.01528v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01528">
<div class="article-summary-box-inner">
<span><p>The field of adversarial textual attack has significantly grown over the last
years, where the commonly considered objective is to craft adversarial examples
that can successfully fool the target models. However, the imperceptibility of
attacks, which is also an essential objective, is often left out by previous
studies. In this work, we advocate considering both objectives at the same
time, and propose a novel multi-optimization approach (dubbed HydraText) with
provable performance guarantee to achieve successful attacks with high
imperceptibility. We demonstrate the efficacy of HydraText through extensive
experiments under both score-based and decision-based settings, involving five
modern NLP models across five benchmark datasets. In comparison to existing
state-of-the-art attacks, HydraText consistently achieves simultaneously higher
success rates, lower modification rates, and higher semantic similarity to the
original texts. A human evaluation study shows that the adversarial examples
crafted by HydraText maintain validity and naturality well. Finally, these
examples also exhibit good transferability and can bring notable robustness
improvement to the target models by adversarial training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UQuAD1.0: Development of an Urdu Question Answering Training Data for Machine Reading Comprehension. (arXiv:2111.01543v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01543">
<div class="article-summary-box-inner">
<span><p>In recent years, low-resource Machine Reading Comprehension (MRC) has made
significant progress, with models getting remarkable performance on various
language datasets. However, none of these models have been customized for the
Urdu language. This work explores the semi-automated creation of the Urdu
Question Answering Dataset (UQuAD1.0) by combining machine-translated SQuAD
with human-generated samples derived from Wikipedia articles and Urdu RC
worksheets from Cambridge O-level books. UQuAD1.0 is a large-scale Urdu dataset
intended for extractive machine reading comprehension tasks consisting of 49k
question Answers pairs in question, passage, and answer format. In UQuAD1.0,
45000 pairs of QA were generated by machine translation of the original
SQuAD1.0 and approximately 4000 pairs via crowdsourcing. In this study, we used
two types of MRC models: rule-based baseline and advanced Transformer-based
models. However, we have discovered that the latter outperforms the others;
thus, we have decided to concentrate solely on Transformer-based architectures.
Using XLMRoBERTa and multi-lingual BERT, we acquire an F1 score of 0.66 and
0.63, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LMdiff: A Visual Diff Tool to Compare Language Models. (arXiv:2111.01582v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01582">
<div class="article-summary-box-inner">
<span><p>While different language models are ubiquitous in NLP, it is hard to contrast
their outputs and identify which contexts one can handle better than the other.
To address this question, we introduce LMdiff, a tool that visually compares
probability distributions of two models that differ, e.g., through finetuning,
distillation, or simply training with different parameter sizes. LMdiff allows
the generation of hypotheses about model behavior by investigating text
instances token by token and further assists in choosing these interesting text
instances by identifying the most interesting phrases from large corpora. We
showcase the applicability of LMdiff for hypothesis generation across multiple
case studies. A demo is available at <a href="http://lmdiff.net">this http URL</a> .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards text-based phishing detection. (arXiv:2111.01676v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01676">
<div class="article-summary-box-inner">
<span><p>This paper reports on an experiment into text-based phishing detection using
readily available resources and without the use of semantics. The developed
algorithm is a modified version of previously published work that works with
the same tools. The results obtained in recognizing phishing emails are
considerably better than the previously reported work; but the rate of text
falsely identified as phishing is slightly worse. It is expected that adding
semantic component will reduce the false positive rate while preserving the
detection accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Classifier Training Efficiency for Automatic Cyberbullying Detection with Feature Density. (arXiv:2111.01689v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01689">
<div class="article-summary-box-inner">
<span><p>We study the effectiveness of Feature Density (FD) using different
linguistically-backed feature preprocessing methods in order to estimate
dataset complexity, which in turn is used to comparatively estimate the
potential performance of machine learning (ML) classifiers prior to any
training. We hypothesise that estimating dataset complexity allows for the
reduction of the number of required experiments iterations. This way we can
optimize the resource-intensive training of ML models which is becoming a
serious issue due to the increases in available dataset sizes and the ever
rising popularity of models based on Deep Neural Networks (DNN). The problem of
constantly increasing needs for more powerful computational resources is also
affecting the environment due to alarmingly-growing amount of CO2 emissions
caused by training of large-scale ML models. The research was conducted on
multiple datasets, including popular datasets, such as Yelp business review
dataset used for training typical sentiment analysis models, as well as more
recent datasets trying to tackle the problem of cyberbullying, which, being a
serious social problem, is also a much more sophisticated problem form the
point of view of linguistic representation. We use cyberbullying datasets
collected for multiple languages, namely English, Japanese and Polish. The
difference in linguistic complexity of datasets allows us to additionally
discuss the efficacy of linguistically-backed word preprocessing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recent Advances in End-to-End Automatic Speech Recognition. (arXiv:2111.01690v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01690">
<div class="article-summary-box-inner">
<span><p>Recently, the speech community is seeing a significant trend of moving from
deep neural network based hybrid modeling to end-to-end (E2E) modeling for
automatic speech recognition (ASR). While E2E models achieve the
state-of-the-art results in most benchmarks in terms of ASR accuracy, hybrid
models are still used in a large proportion of commercial ASR systems at the
current time. There are lots of practical factors that affect the production
model deployment decision. Traditional hybrid models, being optimized for
production for decades, are usually good at these factors. Without providing
excellent solutions to all these factors, it is hard for E2E models to be
widely commercialized. In this paper, we will overview the recent advances in
E2E models, focusing on technologies addressing those challenges from the
industry's perspective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing Effectiveness of Using Internal Signals for Check-Worthy Claim Identification in Unlabeled Data for Automated Fact-Checking. (arXiv:2111.01706v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01706">
<div class="article-summary-box-inner">
<span><p>While recent work on automated fact-checking has focused mainly on verifying
and explaining claims, for which the list of claims is readily available,
identifying check-worthy claim sentences from a text remains challenging.
Current claim identification models rely on manual annotations for each
sentence in the text, which is an expensive task and challenging to conduct on
a frequent basis across multiple domains. This paper explores methodology to
identify check-worthy claim sentences from fake news articles, irrespective of
domain, without explicit sentence-level annotations. We leverage two internal
supervisory signals - headline and the abstractive summary - to rank the
sentences based on semantic similarity. We hypothesize that this ranking
directly correlates to the check-worthiness of the sentences. To assess the
effectiveness of this hypothesis, we build pipelines that leverage the ranking
of sentences based on either the headline or the abstractive summary. The
top-ranked sentences are used for the downstream fact-checking tasks of
evidence retrieval and the article's veracity prediction by the pipeline. Our
findings suggest that the top 3 ranked sentences contain enough information for
evidence-based fact-checking of a fake news article. We also show that while
the headline has more gisting similarity with how a fact-checking website
writes a claim, the summary-based pipeline is the most promising for an
end-to-end fact-checking system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personalized One-Shot Lipreading for an ALS Patient. (arXiv:2111.01740v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01740">
<div class="article-summary-box-inner">
<span><p>Lipreading or visually recognizing speech from the mouth movements of a
speaker is a challenging and mentally taxing task. Unfortunately, multiple
medical conditions force people to depend on this skill in their day-to-day
lives for essential communication. Patients suffering from Amyotrophic Lateral
Sclerosis (ALS) often lose muscle control, consequently their ability to
generate speech and communicate via lip movements. Existing large datasets do
not focus on medical patients or curate personalized vocabulary relevant to an
individual. Collecting a large-scale dataset of a patient, needed to train
mod-ern data-hungry deep learning models is, however, extremely challenging. In
this work, we propose a personalized network to lipread an ALS patient using
only one-shot examples. We depend on synthetically generated lip movements to
augment the one-shot scenario. A Variational Encoder based domain adaptation
technique is used to bridge the real-synthetic domain gap. Our approach
significantly improves and achieves high top-5accuracy with 83.2% accuracy
compared to 62.6% achieved by comparable methods for the patient. Apart from
evaluating our approach on the ALS patient, we also extend it to people with
hearing impairment relying extensively on lip movements to communicate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cryptonite: A Cryptic Crossword Benchmark for Extreme Ambiguity in Language. (arXiv:2103.01242v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01242">
<div class="article-summary-box-inner">
<span><p>Current NLP datasets targeting ambiguity can be solved by a native speaker
with relative ease. We present Cryptonite, a large-scale dataset based on
cryptic crosswords, which is both linguistically complex and naturally sourced.
Each example in Cryptonite is a cryptic clue, a short phrase or sentence with a
misleading surface reading, whose solving requires disambiguating semantic,
syntactic, and phonetic wordplays, as well as world knowledge. Cryptic clues
pose a challenge even for experienced solvers, though top-tier experts can
solve them with almost 100% accuracy. Cryptonite is a challenging task for
current models; fine-tuning T5-Large on 470k cryptic clues achieves only 7.6%
accuracy, on par with the accuracy of a rule-based clue solver (8.6%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Robustness of Intent Classification and Slot Labeling in Goal-oriented Dialog Systems to Real-world Noise. (arXiv:2104.07149v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07149">
<div class="article-summary-box-inner">
<span><p>Intent Classification (IC) and Slot Labeling (SL) models, which form the
basis of dialogue systems, often encounter noisy data in real-word
environments. In this work, we investigate how robust IC/SL models are to noisy
data. We collect and publicly release a test-suite for seven common noise types
found in production human-to-bot conversations (abbreviations, casing,
misspellings, morphological variants, paraphrases, punctuation and synonyms).
On this test-suite, we show that common noise types substantially degrade the
IC accuracy and SL F1 performance of state-of-the-art BERT-based IC/SL models.
By leveraging cross-noise robustness transfer -- training on one noise type to
improve robustness on another noise type -- we design aggregate
data-augmentation approaches that increase the model performance across all
seven noise types by +10.8% for IC accuracy and +15 points for SL F1 on
average. To the best of our knowledge, this is the first work to present a
single IC/SL model that is robust to a wide range of noise phenomena.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KLUE: Korean Language Understanding Evaluation. (arXiv:2105.09680v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09680">
<div class="article-summary-box-inner">
<span><p>We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE
is a collection of 8 Korean natural language understanding (NLU) tasks,
including Topic Classification, SemanticTextual Similarity, Natural Language
Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing,
Machine Reading Comprehension, and Dialogue State Tracking. We build all of the
tasks from scratch from diverse source corpora while respecting copyrights, to
ensure accessibility for anyone without any restrictions. With ethical
considerations in mind, we carefully design annotation protocols. Along with
the benchmark tasks and data, we provide suitable evaluation metrics and
fine-tuning recipes for pretrained language models for each task. We
furthermore release the pretrained language models (PLM), KLUE-BERT and
KLUE-RoBERTa, to help reproducing baseline models on KLUE and thereby
facilitate future research. We make a few interesting observations from the
preliminary experiments using the proposed KLUE benchmark suite, already
demonstrating the usefulness of this new benchmark suite. First, we find
KLUE-RoBERTa-large outperforms other baselines, including multilingual PLMs and
existing open-source Korean PLMs. Second, we see minimal degradation in
performance even when we replace personally identifiable information from the
pretraining corpus, suggesting that privacy and NLU capability are not at odds
with each other. Lastly, we find that using BPE tokenization in combination
with morpheme-level pre-tokenization is effective in tasks involving
morpheme-level tagging, detection and generation. In addition to accelerating
Korean NLP research, our comprehensive documentation on creating KLUE will
facilitate creating similar resources for other languages in the future. KLUE
is available at https://klue-benchmark.com.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence-to-Sequence Learning with Latent Neural Grammars. (arXiv:2109.01135v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01135">
<div class="article-summary-box-inner">
<span><p>Sequence-to-sequence learning with neural networks has become the de facto
standard for sequence prediction tasks. This approach typically models the
local distribution over the next word with a powerful neural network that can
condition on arbitrary context. While flexible and performant, these models
often require large datasets for training and can fail spectacularly on
benchmarks designed to test for compositional generalization. This work
explores an alternative, hierarchical approach to sequence-to-sequence learning
with quasi-synchronous grammars, where each node in the target tree is
transduced by a node in the source tree. Both the source and target trees are
treated as latent and induced during training. We develop a neural
parameterization of the grammar which enables parameter sharing over the
combinatorial space of derivation rules without the need for manual feature
engineering. We apply this latent neural grammar to various domains -- a
diagnostic language navigation task designed to test for compositional
generalization (SCAN), style transfer, and small-scale machine translation --
and find that it performs respectably compared to standard baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Latent Tree Induction with Distant Supervision via Span Constraints. (arXiv:2109.05112v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05112">
<div class="article-summary-box-inner">
<span><p>For over thirty years, researchers have developed and analyzed methods for
latent tree induction as an approach for unsupervised syntactic parsing.
Nonetheless, modern systems still do not perform well enough compared to their
supervised counterparts to have any practical use as structural annotation of
text. In this work, we present a technique that uses distant supervision in the
form of span constraints (i.e. phrase bracketing) to improve performance in
unsupervised constituency parsing. Using a relatively small number of span
constraints we can substantially improve the output from DIORA, an already
competitive unsupervised parsing system. Compared with full parse tree
annotation, span constraints can be acquired with minimal effort, such as with
a lexicon derived from Wikipedia, to find exact text matches. Our experiments
show span constraints based on entities improves constituency parsing on
English WSJ Penn Treebank by more than 5 F1. Furthermore, our method extends to
any domain where span constraints are easily attainable, and as a case study we
demonstrate its effectiveness by parsing biomedical text from the CRAFT
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MeLT: Message-Level Transformer with Masked Document Representations as Pre-Training for Stance Detection. (arXiv:2109.08113v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08113">
<div class="article-summary-box-inner">
<span><p>Much of natural language processing is focused on leveraging large capacity
language models, typically trained over single messages with a task of
predicting one or more tokens. However, modeling human language at
higher-levels of context (i.e., sequences of messages) is under-explored. In
stance detection and other social media tasks where the goal is to predict an
attribute of a message, we have contextual data that is loosely semantically
connected by authorship. Here, we introduce Message-Level Transformer (MeLT) --
a hierarchical message-encoder pre-trained over Twitter and applied to the task
of stance prediction. We focus on stance prediction as a task benefiting from
knowing the context of the message (i.e., the sequence of previous messages).
The model is trained using a variant of masked-language modeling; where instead
of predicting tokens, it seeks to generate an entire masked (aggregated)
message vector via reconstruction loss. We find that applying this pre-trained
masked message-level transformer to the downstream task of stance detection
achieves F1 performance of 67%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmenting semantic lexicons using word embeddings and transfer learning. (arXiv:2109.09010v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09010">
<div class="article-summary-box-inner">
<span><p>Sentiment-aware intelligent systems are essential to a wide array of
applications. These systems are driven by language models which broadly fall
into two paradigms: Lexicon-based and contextual. Although recent contextual
models are increasingly dominant, we still see demand for lexicon-based models
because of their interpretability and ease of use. For example, lexicon-based
models allow researchers to readily determine which words and phrases
contribute most to a change in measured sentiment. A challenge for any
lexicon-based approach is that the lexicon needs to be routinely expanded with
new words and expressions. Here, we propose two models for automatic lexicon
expansion. Our first model establishes a baseline employing a simple and
shallow neural network initialized with pre-trained word embeddings using a
non-contextual approach. Our second model improves upon our baseline, featuring
a deep Transformer-based network that brings to bear word definitions to
estimate their lexical polarity. Our evaluation shows that both models are able
to score new words with a similar accuracy to reviewers from Amazon Mechanical
Turk, but at a fraction of the cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Impact of Pre-trained Language Models on Dialog Evaluation. (arXiv:2110.01895v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01895">
<div class="article-summary-box-inner">
<span><p>Recently, there is a surge of interest in applying pre-trained language
models (Pr-LM) in automatic open-domain dialog evaluation. Pr-LMs offer a
promising direction for addressing the multi-domain evaluation challenge. Yet,
the impact of different Pr-LMs on the performance of automatic metrics is not
well-understood. This paper examines 8 different Pr-LMs and studies their
impact on three typical automatic dialog evaluation metrics across three
different dialog evaluation benchmarks. Specifically, we analyze how the choice
of Pr-LMs affects the performance of automatic metrics. Extensive correlation
analyses on each of the metrics are performed to assess the effects of
different Pr-LMs along various axes, including pre-training objectives, dialog
evaluation criteria, model size, and cross-dataset robustness. This study
serves as the first comprehensive assessment of the effects of different Pr-LMs
on automatic dialog evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Concept Map Generation through Task-Guided Graph Translation. (arXiv:2110.15720v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15720">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the rapid development of concept map generation
techniques due to their advantages in providing well-structured summarization
of knowledge from free texts. Traditional unsupervised methods do not generate
task-oriented concept maps, whereas deep generative models require large
amounts of training data. In this work, we present GT-D2G (Graph Translation
based Document-To-Graph), an automatic concept map generation framework that
leverages generalized NLP pipelines to derive semantic-rich initial graphs, and
translates them into more concise structures under the weak supervision of
document labels. The quality and interpretability of such concept maps are
validated through human evaluation on three real-world corpora, and their
utility in the downstream task is further demonstrated in the controlled
experiments with scarce document labels.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Bayesian Models for Organ Contouring in Headand Neck Radiotherapy. (arXiv:2111.01134v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01134">
<div class="article-summary-box-inner">
<span><p>Deep learning models for organ contouring in radiotherapy are poised for
clinical usage, but currently, there exist few tools for automated quality
assessment (QA) of the predicted contours. Using Bayesian models and their
associated uncertainty, one can potentially automate the process of detecting
inaccurate predictions. We investigate two Bayesian models for auto-contouring,
DropOut and FlipOut, using a quantitative measure - expected calibration error
(ECE) and a qualitative measure - region-based accuracy-vs-uncertainty (R-AvU)
graphs. It is well understood that a model should have low ECE to be considered
trustworthy. However, in a QA context, a model should also have high
uncertainty in inaccurate regions and low uncertainty in accurate regions. Such
behaviour could direct visual attention of expert users to potentially
inaccurate regions, leading to a speed up in the QA process. Using R-AvU
graphs, we qualitatively compare the behaviour of different models in accurate
and inaccurate regions. Experiments are conducted on the MICCAI2015 Head and
Neck Segmentation Challenge and on the DeepMindTCIA CT dataset using three
models: DropOut-DICE, Dropout-CE (Cross Entropy) and FlipOut-CE. Quantitative
results show that DropOut-DICE has the highest ECE, while Dropout-CE and
FlipOut-CE have the lowest ECE. To better understand the difference between
DropOut-CE and FlipOut-CE, we use the R-AvU graph which shows that FlipOut-CE
has better uncertainty coverage in inaccurate regions than DropOut-CE. Such a
combination of quantitative and qualitative metrics explores a new approach
that helps to select which model can be deployed as a QA tool in clinical
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Arch-Net: Model Distillation for Architecture Agnostic Model Deployment. (arXiv:2111.01135v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01135">
<div class="article-summary-box-inner">
<span><p>Vast requirement of computation power of Deep Neural Networks is a major
hurdle to their real world applications. Many recent Application Specific
Integrated Circuit (ASIC) chips feature dedicated hardware support for Neural
Network Acceleration. However, as ASICs take multiple years to develop, they
are inevitably out-paced by the latest development in Neural Architecture
Research. For example, Transformer Networks do not have native support on many
popular chips, and hence are difficult to deploy. In this paper, we propose
Arch-Net, a family of Neural Networks made up of only operators efficiently
supported across most architectures of ASICs. When a Arch-Net is produced, less
common network constructs, like Layer Normalization and Embedding Layers, are
eliminated in a progressive manner through label-free Blockwise Model
Distillation, while performing sub-eight bit quantization at the same time to
maximize performance. Empirical results on machine translation and image
classification tasks confirm that we can transform latest developed Neural
Architectures into fast running and as-accurate Arch-Net, ready for deployment
on multiple mass-produced ASIC chips. The code will be available at
https://github.com/megvii-research/Arch-Net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient Frequency Modulation for Visually Explaining Video Understanding Models. (arXiv:2111.01215v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01215">
<div class="article-summary-box-inner">
<span><p>In many applications, it is essential to understand why a machine learning
model makes the decisions it does, but this is inhibited by the black-box
nature of state-of-the-art neural networks. Because of this, increasing
attention has been paid to explainability in deep learning, including in the
area of video understanding. Due to the temporal dimension of video data, the
main challenge of explaining a video action recognition model is to produce
spatiotemporally consistent visual explanations, which has been ignored in the
existing literature. In this paper, we propose Frequency-based Extremal
Perturbation (F-EP) to explain a video understanding model's decisions. Because
the explanations given by perturbation methods are noisy and non-smooth both
spatially and temporally, we propose to modulate the frequencies of gradient
maps from the neural network model with a Discrete Cosine Transform (DCT). We
show in a range of experiments that F-EP provides more spatiotemporally
consistent explanations that more faithfully represent the model's decisions
compared to the existing state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HRViT: Multi-Scale High-Resolution Vision Transformer. (arXiv:2111.01236v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01236">
<div class="article-summary-box-inner">
<span><p>Vision transformers (ViTs) have attracted much attention for their superior
performance on computer vision tasks. To address their limitations of
single-scale low-resolution representations, prior work adapts ViTs to
high-resolution dense prediction tasks with hierarchical architectures to
generate pyramid features. However, multi-scale representation learning is
still under-explored on ViTs, given their classification-like sequential
topology. To enhance ViTs with more capability to learn semantically-rich and
spatially-precise multi-scale representations, in this work, we present an
efficient integration of high-resolution multi-branch architectures with vision
transformers, dubbed HRViT, pushing the Pareto front of dense prediction tasks
to a new level. We explore heterogeneous branch design, reduce the redundancy
in linear layers, and augment the model nonlinearity to balance the model
performance and hardware efficiency. The proposed HRViT achieves 50.20% mIoU on
ADE20K and 83.16% mIoU on Cityscapes for semantic segmentation tasks,
surpassing state-of-the-art MiT and CSWin with an average of +1.78 mIoU
improvement, 28% parameter reduction, and 21% FLOPs reduction, demonstrating
the potential of HRViT as strong vision backbones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Eye-in-Hand Camera Calibration from a Single Image. (arXiv:2111.01245v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01245">
<div class="article-summary-box-inner">
<span><p>Eye-in-hand camera calibration is a fundamental and long-studied problem in
robotics. We present a study on using learning-based methods for solving this
problem online from a single RGB image, whilst training our models with
entirely synthetic data. We study three main approaches: one direct regression
model that directly predicts the extrinsic matrix from an image, one sparse
correspondence model that regresses 2D keypoints and then uses PnP, and one
dense correspondence model that uses regressed depth and segmentation maps to
enable ICP pose estimation. In our experiments, we benchmark these methods
against each other and against well-established classical methods, to find the
surprising result that direct regression outperforms other approaches, and we
perform noise-sensitivity analysis to gain further insights into these results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Scene Flow Prior. (arXiv:2111.01253v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01253">
<div class="article-summary-box-inner">
<span><p>Before the deep learning revolution, many perception algorithms were based on
runtime optimization in conjunction with a strong prior/regularization penalty.
A prime example of this in computer vision is optical and scene flow.
Supervised learning has largely displaced the need for explicit regularization.
Instead, they rely on large amounts of labeled data to capture prior
statistics, which are not always readily available for many problems. Although
optimization is employed to learn the neural network, the weights of this
network are frozen at runtime. As a result, these learning solutions are
domain-specific and do not generalize well to other statistically different
scenarios. This paper revisits the scene flow problem that relies predominantly
on runtime optimization and strong regularization. A central innovation here is
the inclusion of a neural scene flow prior, which uses the architecture of
neural networks as a new type of implicit regularizer. Unlike learning-based
scene flow methods, optimization occurs at runtime, and our approach needs no
offline datasets -- making it ideal for deployment in new environments such as
autonomous driving. We show that an architecture based exclusively on
multilayer perceptrons (MLPs) can be used as a scene flow prior. Our method
attains competitive -- if not better -- results on scene flow benchmarks. Also,
our neural prior's implicit and continuous scene flow representation allows us
to estimate dense long-term correspondences across a sequence of point clouds.
The dense motion information is represented by scene flow fields where points
can be propagated through time by integrating motion vectors. We demonstrate
such a capability by accumulating a sequence of lidar point clouds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Detection of Motion Boundaries and Occlusions. (arXiv:2111.01261v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01261">
<div class="article-summary-box-inner">
<span><p>We propose MONet, a convolutional neural network that jointly detects motion
boundaries (MBs) and occlusion regions (Occs) in video both forward and
backward in time. Detection is difficult because optical flow is discontinuous
along MBs and undefined in Occs, while many flow estimators assume smoothness
and a flow defined everywhere. To reason in the two time directions
simultaneously, we direct-warp the estimated maps between the two frames. Since
appearance mismatches between frames often signal vicinity to MBs or Occs, we
construct a cost block that for each feature in one frame records the lowest
discrepancy with matching features in a search range. This cost block is
two-dimensional, and much less expensive than the four-dimensional cost volumes
used in flow analysis. Cost-block features are computed by an encoder, and MB
and Occ estimates are computed by a decoder. We found that arranging decoder
layers fine-to-coarse, rather than coarse-to-fine, improves performance. MONet
outperforms the prior state of the art for both tasks on the Sintel and
FlyingChairsOcc benchmarks without any fine-tuning on them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masking Modalities for Cross-modal Video Retrieval. (arXiv:2111.01300v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01300">
<div class="article-summary-box-inner">
<span><p>Pre-training on large scale unlabelled datasets has shown impressive
performance improvements in the fields of computer vision and natural language
processing. Given the advent of large-scale instructional video datasets, a
common strategy for pre-training video encoders is to use the accompanying
speech as weak supervision. However, as speech is used to supervise the
pre-training, it is never seen by the video encoder, which does not learn to
process that modality. We address this drawback of current pre-training
methods, which fail to exploit the rich cues in spoken language. Our proposal
is to pre-train a video encoder using all the available video modalities as
supervision, namely, appearance, sound, and transcribed speech. We mask an
entire modality in the input and predict it using the other two modalities.
This encourages each modality to collaborate with the others, and our video
encoder learns to process appearance and audio as well as speech. We show the
superior performance of our "modality masking" pre-training approach for video
retrieval on the How2R, YouCook2 and Condensed Movies datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Semi-supervised Video Object Segmentation Problem from a Cyclic Perspective. (arXiv:2111.01323v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01323">
<div class="article-summary-box-inner">
<span><p>Modern video object segmentation (VOS) algorithms have achieved remarkably
high performance in a sequential processing order, while most of currently
prevailing pipelines still show some obvious inadequacy like accumulative
error, unknown robustness or lack of proper interpretation tools. In this
paper, we place the semi-supervised video object segmentation problem into a
cyclic workflow and find the defects above can be collectively addressed via
the inherent cyclic property of semi-supervised VOS systems. Firstly, a cyclic
mechanism incorporated to the standard sequential flow can produce more
consistent representations for pixel-wise correspondance. Relying on the
accurate reference mask in the starting frame, we show that the error
propagation problem can be mitigated. Next, a simple gradient correction
module, which naturally extends the offline cyclic pipeline to an online
manner, can highlight the high-frequent and detailed part of results to further
improve the segmentation quality while keeping feasible computation cost.
Meanwhile such correction can protect the network from severe performance
degration resulted from interference signals. Finally we develop cycle
effective receptive field (cycle-ERF) based on gradient correction process to
provide a new perspective into analyzing object-specific regions of interests.
We conduct comprehensive comparison and detailed analysis on challenging
benchmarks of DAVIS16, DAVIS17 and Youtube-VOS, demonstrating that the cyclic
mechanism is helpful to enhance segmentation quality, improve the robustness of
VOS systems, and further provide qualitative comparison and interpretation on
how different VOS algorithms work. The code of this project can be found at
https://github.com/lyxok1/STM-Training
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attribute-Based Deep Periocular Recognition: Leveraging Soft Biometrics to Improve Periocular Recognition. (arXiv:2111.01325v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01325">
<div class="article-summary-box-inner">
<span><p>In recent years, periocular recognition has been developed as a valuable
biometric identification approach, especially in wild environments (for
example, masked faces due to COVID-19 pandemic) where facial recognition may
not be applicable. This paper presents a new deep periocular recognition
framework called attribute-based deep periocular recognition (ADPR), which
predicts soft biometrics and incorporates the prediction into a periocular
recognition algorithm to determine identity from periocular images with high
accuracy. We propose an end-to-end framework, which uses several shared
convolutional neural network (CNN)layers (a common network) whose output feeds
two separate dedicated branches (modality dedicated layers); the first branch
classifies periocular images while the second branch predicts softn biometrics.
Next, the features from these two branches are fused together for a final
periocular recognition. The proposed method is different from existing methods
as it not only uses a shared CNN feature space to train these two tasks
jointly, but it also fuses predicted soft biometric features with the
periocular features in the training step to improve the overall periocular
recognition performance. Our proposed model is extensively evaluated using four
different publicly available datasets. Experimental results indicate that our
soft biometric based periocular recognition approach outperforms other
state-of-the-art methods for periocular recognition in wild environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Federated Split Vision Transformer for COVID-19CXR Diagnosis using Task-Agnostic Training. (arXiv:2111.01338v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01338">
<div class="article-summary-box-inner">
<span><p>Federated learning, which shares the weights of the neural network across
clients, is gaining attention in the healthcare sector as it enables training
on a large corpus of decentralized data while maintaining data privacy. For
example, this enables neural network training for COVID-19 diagnosis on chest
X-ray (CXR) images without collecting patient CXR data across multiple
hospitals. Unfortunately, the exchange of the weights quickly consumes the
network bandwidth if highly expressive network architecture is employed.
So-called split learning partially solves this problem by dividing a neural
network into a client and a server part, so that the client part of the network
takes up less extensive computation resources and bandwidth. However, it is not
clear how to find the optimal split without sacrificing the overall network
performance. To amalgamate these methods and thereby maximize their distinct
strengths, here we show that the Vision Transformer, a recently developed deep
learning architecture with straightforward decomposable configuration, is
ideally suitable for split learning without sacrificing performance. Even under
the non-independent and identically distributed data distribution which
emulates a real collaboration between hospitals using CXR datasets from
multiple sources, the proposed framework was able to attain performance
comparable to data-centralized training. In addition, the proposed framework
along with heterogeneous multi-task clients also improves individual task
performances including the diagnosis of COVID-19, eliminating the need for
sharing large weights with innumerable parameters. Our results affirm the
suitability of Transformer for collaborative learning in medical imaging and
pave the way forward for future real-world implementations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constructing High-Order Signed Distance Maps from Computed Tomography Data with Application to Bone Morphometry. (arXiv:2111.01350v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01350">
<div class="article-summary-box-inner">
<span><p>An algorithm is presented for constructing high-order signed distance fields
for two phase materials imaged with computed tomography. The signed distance
field is high-order in that it is free of the quantization artifact associated
with the distance transform of sampled signals. The narrowband is solved using
a closest point algorithm extended for implicit embeddings that are not a
signed distance field. The high-order fast sweeping algorithm is used to extend
the narrowband to the remainder of the domain. The order of accuracy of the
narrowband and extension methods are verified on ideal implicit surfaces. The
method is applied to ten excised cubes of bovine trabecular bone. Localization
of the surface, estimation of phase densities, and local morphometry is
validated with these subjects. Since the embedding is high-order, gradients and
thus curvatures can be accurately estimated locally in the image data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Vision Transformers Perform Convolution?. (arXiv:2111.01353v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01353">
<div class="article-summary-box-inner">
<span><p>Several recent studies have demonstrated that attention-based networks, such
as Vision Transformer (ViT), can outperform Convolutional Neural Networks
(CNNs) on several computer vision tasks without using convolutional layers.
This naturally leads to the following questions: Can a self-attention layer of
ViT express any convolution operation? In this work, we prove that a single ViT
layer with image patches as the input can perform any convolution operation
constructively, where the multi-head attention mechanism and the relative
positional encoding play essential roles. We further provide a lower bound on
the number of heads for Vision Transformers to express CNNs. Corresponding with
our analysis, experimental results show that the construction in our proof can
help inject convolutional bias into Transformers and significantly improve the
performance of ViT in low data regimes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boundary Distribution Estimation to Precise Object Detection. (arXiv:2111.01396v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01396">
<div class="article-summary-box-inner">
<span><p>In principal modern detectors, the task of object localization is implemented
by the box subnet which concentrates on bounding box regression. The box subnet
customarily predicts the position of the object by regressing box center
position and scaling factors. Although this approach is frequently adopted, we
observe that the result of localization remains defective, which makes the
performance of the detector unsatisfactory. In this paper, we prove the flaws
in the previous method through theoretical analysis and experimental
verification and propose a novel solution to detect objects precisely. Rather
than plainly focusing on center and size, our approach refines the edges of the
bounding box on previous localization results by estimating the distribution at
the boundary of the object. Experimental results have shown the potentiality
and generalization of our proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Pixel-Level Meta-Learner for Weakly Supervised Few-Shot Semantic Segmentation. (arXiv:2111.01418v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01418">
<div class="article-summary-box-inner">
<span><p>Few-shot semantic segmentation addresses the learning task in which only few
images with ground truth pixel-level labels are available for the novel classes
of interest. One is typically required to collect a large mount of data (i.e.,
base classes) with such ground truth information, followed by meta-learning
strategies to address the above learning task. When only image-level semantic
labels can be observed during both training and testing, it is considered as an
even more challenging task of weakly supervised few-shot semantic segmentation.
To address this problem, we propose a novel meta-learning framework, which
predicts pseudo pixel-level segmentation masks from a limited amount of data
and their semantic labels. More importantly, our learning scheme further
exploits the produced pixel-level information for query image inputs with
segmentation guarantees. Thus, our proposed learning model can be viewed as a
pixel-level meta-learner. Through extensive experiments on benchmark datasets,
we show that our model achieves satisfactory performances under fully
supervised settings, yet performs favorably against state-of-the-art methods
under weakly supervised settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HHP-Net: A light Heteroscedastic neural network for Head Pose estimation with uncertainty. (arXiv:2111.01440v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01440">
<div class="article-summary-box-inner">
<span><p>In this paper we introduce a novel method to estimate the head pose of people
in single images starting from a small set of head keypoints. To this purpose,
we propose a regression model that exploits keypoints computed automatically by
2D pose estimation algorithms and outputs the head pose represented by yaw,
pitch, and roll. Our model is simple to implement and more efficient with
respect to the state of the art -- faster in inference and smaller in terms of
memory occupancy -- with comparable accuracy. Our method also provides a
measure of the heteroscedastic uncertainties associated with the three angles,
through an appropriately designed loss function; we show there is a correlation
between error and uncertainty values, thus this extra source of information may
be used in subsequent computational steps. As an example application, we
address social interaction analysis in images: we propose an algorithm for a
quantitative estimation of the level of interaction between people, starting
from their head poses and reasoning on their mutual positions. The code is
available at https://github.com/cantarinigiorgio/HHP-Net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Out of distribution detection for skin and malaria images. (arXiv:2111.01505v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01505">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have shown promising results in disease detection and
classification using medical image data. However, they still suffer from the
challenges of handling real-world scenarios especially reliably detecting
out-of-distribution (OoD) samples. We propose an approach to robustly classify
OoD samples in skin and malaria images without the need to access labeled OoD
samples during training. Specifically, we use metric learning along with
logistic regression to force the deep networks to learn much rich class
representative features. To guide the learning process against the OoD
examples, we generate ID similar-looking examples by either removing
class-specific salient regions in the image or permuting image parts and
distancing them away from in-distribution samples. During inference time, the
K-reciprocal nearest neighbor is employed to detect out-of-distribution
samples. For skin cancer OoD detection, we employ two standard benchmark skin
cancer ISIC datasets as ID, and six different datasets with varying difficulty
levels were taken as out of distribution. For malaria OoD detection, we use the
BBBC041 malaria dataset as ID and five different challenging datasets as out of
distribution. We achieved state-of-the-art results, improving 5% and 4% in
TNR@TPR95% over the previous state-of-the-art for skin cancer and malaria OoD
detection respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ISP-Agnostic Image Reconstruction for Under-Display Cameras. (arXiv:2111.01511v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01511">
<div class="article-summary-box-inner">
<span><p>Under-display cameras have been proposed in recent years as a way to reduce
the form factor of mobile devices while maximizing the screen area.
Unfortunately, placing the camera behind the screen results in significant
image distortions, including loss of contrast, blur, noise, color shift,
scattering artifacts, and reduced light sensitivity. In this paper, we propose
an image-restoration pipeline that is ISP-agnostic, i.e. it can be combined
with any legacy ISP to produce a final image that matches the appearance of
regular cameras using the same ISP. This is achieved with a deep learning
approach that performs a RAW-to-RAW image restoration. To obtain large
quantities of real under-display camera training data with sufficient contrast
and scene diversity, we furthermore develop a data capture method utilizing an
HDR monitor, as well as a data augmentation method to generate suitable HDR
content. The monitor data is supplemented with real-world data that has less
scene diversity but allows us to achieve fine detail recovery without being
limited by the monitor resolution. Together, this approach successfully
restores color and contrast as well as image detail.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comprehensive and Clinically Accurate Head and Neck Organs at Risk Delineation via Stratified Deep Learning: A Large-scale Multi-Institutional Study. (arXiv:2111.01544v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01544">
<div class="article-summary-box-inner">
<span><p>Accurate organ at risk (OAR) segmentation is critical to reduce the
radiotherapy post-treatment complications. Consensus guidelines recommend a set
of more than 40 OARs in the head and neck (H&amp;N) region, however, due to the
predictable prohibitive labor-cost of this task, most institutions choose a
substantially simplified protocol by delineating a smaller subset of OARs and
neglecting the dose distributions associated with other OARs. In this work we
propose a novel, automated and highly effective stratified OAR segmentation
(SOARS) system using deep learning to precisely delineate a comprehensive set
of 42 H&amp;N OARs. SOARS stratifies 42 OARs into anchor, mid-level, and small &amp;
hard subcategories, with specifically derived neural network architectures for
each category by neural architecture search (NAS) principles. We built SOARS
models using 176 training patients in an internal institution and independently
evaluated on 1327 external patients across six different institutions. It
consistently outperformed other state-of-the-art methods by at least 3-5% in
Dice score for each institutional evaluation (up to 36% relative error
reduction in other metrics). More importantly, extensive multi-user studies
evidently demonstrated that 98% of the SOARS predictions need only very minor
or no revisions for direct clinical acceptance (saving 90% radiation
oncologists workload), and their segmentation and dosimetric accuracy are
within or smaller than the inter-user variation. These findings confirmed the
strong clinical applicability of SOARS for the OAR delineation process in H&amp;N
cancer radiotherapy workflows, with improved efficiency, comprehensiveness, and
quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima. (arXiv:2111.01549v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01549">
<div class="article-summary-box-inner">
<span><p>This paper considers incremental few-shot learning, which requires a model to
continually recognize new categories with only a few examples provided. Our
study shows that existing methods severely suffer from catastrophic forgetting,
a well-known problem in incremental learning, which is aggravated due to data
scarcity and imbalance in the few-shot setting. Our analysis further suggests
that to prevent catastrophic forgetting, actions need to be taken in the
primitive stage -- the training of base classes instead of later few-shot
learning sessions. Therefore, we propose to search for flat local minima of the
base training objective function and then fine-tune the model parameters within
the flat region on new tasks. In this way, the model can efficiently learn new
classes while preserving the old ones. Comprehensive experimental results
demonstrate that our approach outperforms all prior state-of-the-art methods
and is very close to the approximate upper bound. The source code is available
at https://github.com/moukamisama/F2M.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accounting for Dependencies in Deep Learning Based Multiple Instance Learning for Whole Slide Imaging. (arXiv:2111.01556v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01556">
<div class="article-summary-box-inner">
<span><p>Multiple instance learning (MIL) is a key algorithm for classification of
whole slide images (WSI). Histology WSIs can have billions of pixels, which
create enormous computational and annotation challenges. Typically, such images
are divided into a set of patches (a bag of instances), where only bag-level
class labels are provided. Deep learning based MIL methods calculate instance
features using convolutional neural network (CNN). Our proposed approach is
also deep learning based, with the following two contributions: Firstly, we
propose to explicitly account for dependencies between instances during
training by embedding self-attention Transformer blocks to capture dependencies
between instances. For example, a tumor grade may depend on the presence of
several particular patterns at different locations in WSI, which requires to
account for dependencies between patches. Secondly, we propose an instance-wise
loss function based on instance pseudo-labels. We compare the proposed
algorithm to multiple baseline methods, evaluate it on the PANDA challenge
dataset, the largest publicly available WSI dataset with over 11K images, and
demonstrate state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PointNu-Net: Simultaneous Multi-tissue Histology Nuclei Segmentation and Classification in the Clinical Wild. (arXiv:2111.01557v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01557">
<div class="article-summary-box-inner">
<span><p>Automatic nuclei segmentation and classification plays a vital role in
digital pathology. However, previous works are mostly built on data with
limited diversity and small sizes, making the results questionable or
misleading in actual downstream tasks. In this paper, we aim to build a
reliable and robust method capable of dealing with data from the 'the clinical
wild'. Specifically, we study and design a new method to simultaneously detect,
segment, and classify nuclei from Haematoxylin and Eosin (H&amp;E) stained
histopathology data, and evaluate our approach using the recent largest
dataset: PanNuke. We address the detection and classification of each nuclei as
a novel semantic keypoint estimation problem to determine the center point of
each nuclei. Next, the corresponding class-agnostic masks for nuclei center
points are obtained using dynamic instance segmentation. By decoupling two
simultaneous challenging tasks, our method can benefit from class-aware
detection and class-agnostic segmentation, thus leading to a significant
performance boost. We demonstrate the superior performance of our proposed
approach for nuclei segmentation and classification across 19 different tissue
types, delivering new benchmark results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sub-cortical structure segmentation database for young population. (arXiv:2111.01561v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01561">
<div class="article-summary-box-inner">
<span><p>Segmentation of sub-cortical structures from MRI scans is of interest in many
neurological diagnosis. Since this is a laborious task machine learning and
specifically deep learning (DL) methods have become explored. The structural
complexity of the brain demands a large, high quality segmentation dataset to
develop good DL-based solutions for sub-cortical structure segmentation.
Towards this, we are releasing a set of 114, 1.5 Tesla, T1 MRI scans with
manual delineations for 14 sub-cortical structures. The scans in the dataset
were acquired from healthy young (21-30 years) subjects ( 58 male and 56
female) and all the structures are manually delineated by experienced radiology
experts. Segmentation experiments have been conducted with this dataset and
results demonstrate that accurate results can be obtained with deep-learning
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fitness Landscape Footprint: A Framework to Compare Neural Architecture Search Problems. (arXiv:2111.01584v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01584">
<div class="article-summary-box-inner">
<span><p>Neural architecture search is a promising area of research dedicated to
automating the design of neural network models. This field is rapidly growing,
with a surge of methodologies ranging from Bayesian optimization,neuroevoltion,
to differentiable search, and applications in various contexts. However,
despite all great advances, few studies have presented insights on the
difficulty of the problem itself, thus the success (or fail) of these
methodologies remains unexplained. In this sense, the field of optimization has
developed methods that highlight key aspects to describe optimization problems.
The fitness landscape analysis stands out when it comes to characterize
reliably and quantitatively search algorithms. In this paper, we propose to use
fitness landscape analysis to study a neural architecture search problem.
Particularly, we introduce the fitness landscape footprint, an aggregation of
eight (8)general-purpose metrics to synthesize the landscape of an architecture
search problem. We studied two problems, the classical image classification
benchmark CIFAR-10, and the Remote-Sensing problem So2Sat LCZ42. The results
present a quantitative appraisal of the problems, allowing to characterize the
relative difficulty and other characteristics, such as the ruggedness or the
persistence, that helps to tailor a search strategy to the problem. Also, the
footprint is a tool that enables the comparison of multiple problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detect-and-Segment: a Deep Learning Approach to Automate Wound Image Segmentation. (arXiv:2111.01590v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01590">
<div class="article-summary-box-inner">
<span><p>Chronic wounds significantly impact quality of life. If not properly managed,
they can severely deteriorate. Image-based wound analysis could aid in
objectively assessing the wound status by quantifying important features that
are related to healing. However, the high heterogeneity of the wound types,
image background composition, and capturing conditions challenge the robust
segmentation of wound images. We present Detect-and-Segment (DS), a deep
learning approach to produce wound segmentation maps with high generalization
capabilities. In our approach, dedicated deep neural networks detected the
wound position, isolated the wound from the uninformative background, and
computed the wound segmentation map. We evaluated this approach using one data
set with images of diabetic foot ulcers. For further testing, 4 supplemental
independent data sets with larger variety of wound types from different body
locations were used. The Matthews' correlation coefficient (MCC) improved from
0.29 when computing the segmentation on the full image to 0.85 when combining
detection and segmentation in the same approach. When tested on the wound
images drawn from the supplemental data sets, the DS approach increased the
mean MCC from 0.17 to 0.85. Furthermore, the DS approach enabled the training
of segmentation models with up to 90% less training data while maintaining the
segmentation performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating 3D Motion and Forces of Human-Object Interactions from Internet Videos. (arXiv:2111.01591v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01591">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a method to automatically reconstruct the 3D
motion of a person interacting with an object from a single RGB video. Our
method estimates the 3D poses of the person together with the object pose, the
contact positions and the contact forces exerted on the human body. The main
contributions of this work are three-fold. First, we introduce an approach to
jointly estimate the motion and the actuation forces of the person on the
manipulated object by modeling contacts and the dynamics of the interactions.
This is cast as a large-scale trajectory optimization problem. Second, we
develop a method to automatically recognize from the input video the 2D
position and timing of contacts between the person and the object or the
ground, thereby significantly simplifying the complexity of the optimization.
Third, we validate our approach on a recent video+MoCap dataset capturing
typical parkour actions, and demonstrate its performance on a new dataset of
Internet videos showing people manipulating a variety of tools in unconstrained
environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trajectory Prediction with Graph-based Dual-scale Context Fusion. (arXiv:2111.01592v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01592">
<div class="article-summary-box-inner">
<span><p>Motion prediction for traffic participants is essential for a safe and robust
automated driving system, especially in cluttered urban environments. However,
it is highly challenging due to the complex road topology as well as the
uncertain intentions of the other agents. In this paper, we present a
graph-based trajectory prediction network named the Dual Scale Predictor (DSP),
which encodes both the static and dynamical driving context in a hierarchical
manner. Different from methods based on a rasterized map or sparse lane graph,
we consider the driving context as a graph with two layers, focusing on both
geometrical and topological features. Graph neural networks (GNNs) are applied
to extract features with different levels of granularity, and features are
subsequently aggregated with attention-based inter-layer networks, realizing
better local-global feature fusion. Following the recent goal-driven trajectory
prediction pipeline, goal candidates with high likelihood for the target agent
are extracted, and predicted trajectories are generated conditioned on these
goals. Thanks to the proposed dual-scale context fusion network, our DSP is
able to generate accurate and human-like multi-modal trajectories. We evaluate
the proposed method on the large-scale Argoverse motion forecasting benchmark,
and it achieves promising results, outperforming the recent state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Critical Study on the Recent Deep Learning Based Semi-Supervised Video Anomaly Detection Methods. (arXiv:2111.01604v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01604">
<div class="article-summary-box-inner">
<span><p>Video anomaly detection is one of the hot research topics in computer vision
nowadays, as abnormal events contain a high amount of information. Anomalies
are one of the main detection targets in surveillance systems, usually needing
real-time actions. Regarding the availability of labeled data for training
(i.e., there is not enough labeled data for abnormalities), semi-supervised
anomaly detection approaches have gained interest recently. This paper
introduces the researchers of the field to a new perspective and reviews the
recent deep-learning based semi-supervised video anomaly detection approaches,
based on a common strategy they use for anomaly detection. Our goal is to help
researchers develop more effective video anomaly detection methods. As the
selection of a right Deep Neural Network plays an important role for several
parts of this task, a quick comparative review on DNNs is prepared first.
Unlike previous surveys, DNNs are reviewed from a spatiotemporal feature
extraction viewpoint, customized for video anomaly detection. This part of the
review can help researchers in this field select suitable networks for
different parts of their methods. Moreover, some of the state-of-the-art
anomaly detection methods, based on their detection strategy, are critically
surveyed. The review provides a novel and deep look at existing methods and
results in stating the shortcomings of these approaches, which can be a hint
for future works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PolyTrack: Tracking with Bounding Polygons. (arXiv:2111.01606v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01606">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a novel method called PolyTrack for fast
multi-object tracking and segmentation using bounding polygons. Polytrack
detects objects by producing heatmaps of their center keypoint. For each of
them, a rough segmentation is done by computing a bounding polygon over each
instance instead of the traditional bounding box. Tracking is done by taking
two consecutive frames as input and computing a center offset for each object
detected in the first frame to predict its location in the second frame. A
Kalman filter is also applied to reduce the number of ID switches. Since our
target application is automated driving systems, we apply our method on urban
environment videos. We trained and evaluated PolyTrack on the MOTS and
KITTIMOTS datasets. Results show that tracking polygons can be a good
alternative to bounding box and mask tracking. The code of PolyTrack is
available at https://github.com/gafaua/PolyTrack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StyleGAN of All Trades: Image Manipulation with Only Pretrained StyleGAN. (arXiv:2111.01619v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01619">
<div class="article-summary-box-inner">
<span><p>Recently, StyleGAN has enabled various image manipulation and editing tasks
thanks to the high-quality generation and the disentangled latent space.
However, additional architectures or task-specific training paradigms are
usually required for different tasks. In this work, we take a deeper look at
the spatial properties of StyleGAN. We show that with a pretrained StyleGAN
along with some operations, without any additional architecture, we can perform
comparably to the state-of-the-art methods on various tasks, including image
blending, panorama generation, generation from a single image, controllable and
local multimodal image to image translation, and attributes transfer. The
proposed method is simple, effective, efficient, and applicable to any existing
pretrained StyleGAN model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Tri-attention Fusion Guided Multi-modal Segmentation Network. (arXiv:2111.01623v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01623">
<div class="article-summary-box-inner">
<span><p>In the field of multimodal segmentation, the correlation between different
modalities can be considered for improving the segmentation results.
Considering the correlation between different MR modalities, in this paper, we
propose a multi-modality segmentation network guided by a novel tri-attention
fusion. Our network includes N model-independent encoding paths with N image
sources, a tri-attention fusion block, a dual-attention fusion block, and a
decoding path. The model independent encoding paths can capture
modality-specific features from the N modalities. Considering that not all the
features extracted from the encoders are useful for segmentation, we propose to
use dual attention based fusion to re-weight the features along the modality
and space paths, which can suppress less informative features and emphasize the
useful ones for each modality at different positions. Since there exists a
strong correlation between different modalities, based on the dual attention
fusion block, we propose a correlation attention module to form the
tri-attention fusion block. In the correlation attention module, a correlation
description block is first used to learn the correlation between modalities and
then a constraint based on the correlation is used to guide the network to
learn the latent correlated features which are more relevant for segmentation.
Finally, the obtained fused feature representation is projected by the decoder
to obtain the segmentation results. Our experiment results tested on BraTS 2018
dataset for brain tumor segmentation demonstrate the effectiveness of our
proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Attention in Fine-grained Classification. (arXiv:2111.01628v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01628">
<div class="article-summary-box-inner">
<span><p>The way humans attend to, process and classify a given image has the
potential to vastly benefit the performance of deep learning models. Exploiting
where humans are focusing can rectify models when they are deviating from
essential features for correct decisions. To validate that human attention
contains valuable information for decision-making processes such as
fine-grained classification, we compare human attention and model explanations
in discovering important features. Towards this goal, we collect human gaze
data for the fine-grained classification dataset CUB and build a dataset named
CUB-GHA (Gaze-based Human Attention). Furthermore, we propose the Gaze
Augmentation Training (GAT) and Knowledge Fusion Network (KFN) to integrate
human gaze knowledge into classification models. We implement our proposals in
CUB-GHA and the recently released medical dataset CXR-Eye of chest X-ray
images, which includes gaze data collected from a radiologist. Our result
reveals that integrating human attention knowledge benefits classification
effectively, e.g. improving the baseline by 4.38% on CXR. Hence, our work
provides not only valuable insights into understanding human attention in
fine-grained classification, but also contributes to future research in
integrating human gaze with computer vision tasks. CUB-GHA and code are
available at https://github.com/yaorong0921/CUB-GHA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable Medical Image Segmentation via Generative Adversarial Networks and Layer-wise Relevance Propagation. (arXiv:2111.01665v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01665">
<div class="article-summary-box-inner">
<span><p>This paper contributes to automating medical image segmentation by proposing
generative adversarial network-based models to segment both polyps and
instruments in endoscopy images. A major contribution of this work is to
provide explanations for the predictions using a layer-wise relevance
propagation approach designating which input image pixels are relevant to the
predictions and to what extent. On the polyp segmentation task, the models
achieved 0.84 of accuracy and 0.46 on Jaccard index. On the instrument
segmentation task, the models achieved 0.96 of accuracy and 0.70 on Jaccard
index. The code is available at https://github.com/Awadelrahman/MedAI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relational Self-Attention: What's Missing in Attention for Video Understanding. (arXiv:2111.01673v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01673">
<div class="article-summary-box-inner">
<span><p>Convolution has been arguably the most important feature transform for modern
neural networks, leading to the advance of deep learning. Recent emergence of
Transformer networks, which replace convolution layers with self-attention
blocks, has revealed the limitation of stationary convolution kernels and
opened the door to the era of dynamic feature transforms. The existing dynamic
transforms, including self-attention, however, are all limited for video
understanding where correspondence relations in space and time, i.e., motion
information, are crucial for effective representation. In this work, we
introduce a relational feature transform, dubbed the relational self-attention
(RSA), that leverages rich structures of spatio-temporal relations in videos by
dynamically generating relational kernels and aggregating relational contexts.
Our experiments and ablation studies show that the RSA network substantially
outperforms convolution and self-attention counterparts, achieving the state of
the art on the standard motion-centric benchmarks for video action recognition,
such as Something-Something-V1 &amp; V2, Diving48, and FineGym.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Minimizing Energy Consumption Leads to the Emergence of Gaits in Legged Robots. (arXiv:2111.01674v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01674">
<div class="article-summary-box-inner">
<span><p>Legged locomotion is commonly studied and expressed as a discrete set of gait
patterns, like walk, trot, gallop, which are usually treated as given and
pre-programmed in legged robots for efficient locomotion at different speeds.
However, fixing a set of pre-programmed gaits limits the generality of
locomotion. Recent animal motor studies show that these conventional gaits are
only prevalent in ideal flat terrain conditions while real-world locomotion is
unstructured and more like bouts of intermittent steps. What principles could
lead to both structured and unstructured patterns across mammals and how to
synthesize them in robots? In this work, we take an analysis-by-synthesis
approach and learn to move by minimizing mechanical energy. We demonstrate that
learning to minimize energy consumption plays a key role in the emergence of
natural locomotion gaits at different speeds in real quadruped robots. The
emergent gaits are structured in ideal terrains and look similar to that of
horses and sheep. The same approach leads to unstructured gaits in rough
terrains which is consistent with the findings in animal motor control. We
validate our hypothesis in both simulation and real hardware across natural
terrains. Videos at https://energy-locomotion.github.io
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Top1 Solution of QQ Browser 2021 Ai Algorithm Competition Track 1 : Multimodal Video Similarity. (arXiv:2111.01677v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01677">
<div class="article-summary-box-inner">
<span><p>In this paper, we describe the solution to the QQ Browser 2021 Ai Algorithm
Competition (AIAC) Track 1. We use the multi-modal transformer model for the
video embedding extraction. In the pretrain phase, we train the model with
three tasks, (1) Video Tag Classification (VTC), (2) Mask Language Modeling
(MLM) and (3) Mask Frame Modeling (MFM). In the finetune phase, we train the
model with video similarity based on rank normalized human labels. Our full
pipeline, after ensembling several models, scores 0.852 on the leaderboard,
which we achieved the 1st place in the competition. The source codes have been
released at Github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Saliency detection with moving camera via background model completion. (arXiv:2111.01681v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01681">
<div class="article-summary-box-inner">
<span><p>To detect saliency in video is a fundamental step in many computer vision
systems. Saliency is the significant target(s) in the video. The object of
interest is further analyzed for high-level applications. The segregation of
saliency and the background can be made if they exhibit different visual cues.
Therefore, saliency detection is often formulated as background subtraction.
However, saliency detection is challenging. For instance, dynamic background
can result in false positive errors. In another scenario, camouflage will lead
to false negative errors. With moving camera, the captured scenes are even more
complicated to handle. We propose a new framework, called saliency detection
via background model completion (SD-BMC), that comprises of a background
modeler and the deep learning background/foreground segmentation network. The
background modeler generates an initial clean background image from a short
image sequence. Based on the idea of video completion, a good background frame
can be synthesized with the co-existence of changing background and moving
objects. We adopt the background/foreground segmenter, although pre-trained
with a specific video dataset, can also detect saliency in unseen videos. The
background modeler can adjust the background image dynamically when the
background/foreground segmenter output deteriorates during processing of a long
video. To the best of our knowledge, our framework is the first one to adopt
video completion for background modeling and saliency detection in videos
captured by moving camera. The results, obtained from the PTZ videos, show that
our proposed framework outperforms some deep learning-based background
subtraction models by 11% or more. With more challenging videos, our framework
also outperforms many high ranking background subtraction methods by more than
3%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive observation of Covid-19 vaccination effects on skin-cellular structures by use of Intelligent Laser Speckle Classification (ILSC). (arXiv:2111.01682v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01682">
<div class="article-summary-box-inner">
<span><p>We have made a progressive observation of Covid-19 Astra Zeneca Vaccination
effect on Skin cellular network and properties by use of well established
Intelligent Laser Speckle Classification (ILSC) image based technique and
managed to distinguish between three different subjects groups via their laser
speckle skin image samplings such as early-vaccinated, late-vaccinated and
non-vaccinated individuals. The results have proven that the ILSC technique in
association with the optimised Bayesian network is capable of classifying skin
changes of vaccinated and non-vaccinated individuals and also of detecting
progressive development made on skin cellular properties for a month period.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Synthetic Images To Uncover Population Biases In Facial Landmarks Detection. (arXiv:2111.01683v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01683">
<div class="article-summary-box-inner">
<span><p>In order to analyze a trained model performance and identify its weak spots,
one has to set aside a portion of the data for testing. The test set has to be
large enough to detect statistically significant biases with respect to all the
relevant sub-groups in the target population. This requirement may be difficult
to satisfy, especially in data-hungry applications. We propose to overcome this
difficulty by generating synthetic test set. We use the face landmarks
detection task to validate our proposal by showing that all the biases observed
on real datasets are also seen on a carefully designed synthetic dataset. This
shows that synthetic test sets can efficiently detect a model's weak spots and
overcome limitations of real test set in terms of quantity and/or diversity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking the Knowledge Distillation From the Perspective of Model Calibration. (arXiv:2111.01684v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01684">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed dramatically improvements in the knowledge
distillation, which can generate a compact student model for better efficiency
while retaining the model effectiveness of the teacher model. Previous studies
find that: more accurate teachers do not necessary make for better teachers due
to the mismatch of abilities. In this paper, we aim to analysis the phenomenon
from the perspective of model calibration. We found that the larger teacher
model may be too over-confident, thus the student model cannot effectively
imitate. While, after the simple model calibration of the teacher model, the
size of the teacher model has a positive correlation with the performance of
the student model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Learning the Search Distribution of Black-Box Random Search Based Adversarial Attacks. (arXiv:2111.01714v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01714">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks based on randomized search schemes have obtained
state-of-the-art results in black-box robustness evaluation recently. However,
as we demonstrate in this work, their efficiency in different query budget
regimes depends on manual design and heuristic tuning of the underlying
proposal distributions. We study how this issue can be addressed by adapting
the proposal distribution online based on the information obtained during the
attack. We consider Square Attack, which is a state-of-the-art score-based
black-box attack, and demonstrate how its performance can be improved by a
learned controller that adjusts the parameters of the proposal distribution
online during the attack. We train the controller using gradient-based
end-to-end training on a CIFAR10 model with white box access. We demonstrate
that plugging the learned controller into the attack consistently improves its
black-box robustness estimate in different query regimes by up to 20% for a
wide range of different models with black-box access. We further show that the
learned adaptation principle transfers well to the other data distributions
such as CIFAR100 or ImageNet and to the targeted attack setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Absolute distance prediction based on deep learning object detection and monocular depth estimation models. (arXiv:2111.01715v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01715">
<div class="article-summary-box-inner">
<span><p>Determining the distance between the objects in a scene and the camera sensor
from 2D images is feasible by estimating depth images using stereo cameras or
3D cameras. The outcome of depth estimation is relative distances that can be
used to calculate absolute distances to be applicable in reality. However,
distance estimation is very challenging using 2D monocular cameras. This paper
presents a deep learning framework that consists of two deep networks for depth
estimation and object detection using a single image. Firstly, objects in the
scene are detected and localized using the You Only Look Once (YOLOv5) network.
In parallel, the estimated depth image is computed using a deep autoencoder
network to detect the relative distances. The proposed object detection based
YOLO was trained using a supervised learning technique, in turn, the network of
depth estimation was self-supervised training. The presented distance
estimation framework was evaluated on real images of outdoor scenes. The
achieved results show that the proposed framework is promising and it yields an
accuracy of 96% with RMSE of 0.203 of the correct absolute distance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MixFace: Improving Face Verification Focusing on Fine-grained Conditions. (arXiv:2111.01717v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01717">
<div class="article-summary-box-inner">
<span><p>The performance of face recognition has become saturated for public benchmark
datasets such as LFW, CFP-FP, and AgeDB, owing to the rapid advances in CNNs.
However, the effects of faces with various fine-grained conditions on FR models
have not been investigated because of the absence of such datasets. This paper
analyzes their effects in terms of different conditions and loss functions
using K-FACE, a recently introduced FR dataset with fine-grained conditions. We
propose a novel loss function, MixFace, that combines classification and metric
losses. The superiority of MixFace in terms of effectiveness and robustness is
demonstrated experimentally on various benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CPSeg: Cluster-free Panoptic Segmentation of 3D LiDAR Point Clouds. (arXiv:2111.01723v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01723">
<div class="article-summary-box-inner">
<span><p>A fast and accurate panoptic segmentation system for LiDAR point clouds is
crucial for autonomous driving vehicles to understand the surrounding objects
and scenes. Existing approaches usually rely on proposals or clustering to
segment foreground instances. As a result, they struggle to achieve real-time
performance. In this paper, we propose a novel real-time end-to-end panoptic
segmentation network for LiDAR point clouds, called CPSeg. In particular, CPSeg
comprises a shared encoder, a dual decoder, a task-aware attention module (TAM)
and a cluster-free instance segmentation head. TAM is designed to enforce these
two decoders to learn rich task-aware features for semantic and instance
embedding. Moreover, CPSeg incorporates a new cluster-free instance
segmentation head to dynamically pillarize foreground points according to the
learned embedding. Then, it acquires instance labels by finding connected
pillars with a pairwise embedding comparison. Thus, the conventional
proposal-based or clustering-based instance segmentation is transformed into a
binary segmentation problem on the pairwise embedding comparison matrix. To
help the network regress instance embedding, a fast and deterministic depth
completion algorithm is proposed to calculate surface normal of each point
cloud in real-time. The proposed method is benchmarked on two large-scale
autonomous driving datasets, namely, SemanticKITTI and nuScenes. Notably,
extensive experimental results show that CPSeg achieves the state-of-the-art
results among real-time approaches on both datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personalized One-Shot Lipreading for an ALS Patient. (arXiv:2111.01740v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01740">
<div class="article-summary-box-inner">
<span><p>Lipreading or visually recognizing speech from the mouth movements of a
speaker is a challenging and mentally taxing task. Unfortunately, multiple
medical conditions force people to depend on this skill in their day-to-day
lives for essential communication. Patients suffering from Amyotrophic Lateral
Sclerosis (ALS) often lose muscle control, consequently their ability to
generate speech and communicate via lip movements. Existing large datasets do
not focus on medical patients or curate personalized vocabulary relevant to an
individual. Collecting a large-scale dataset of a patient, needed to train
mod-ern data-hungry deep learning models is, however, extremely challenging. In
this work, we propose a personalized network to lipread an ALS patient using
only one-shot examples. We depend on synthetically generated lip movements to
augment the one-shot scenario. A Variational Encoder based domain adaptation
technique is used to bridge the real-synthetic domain gap. Our approach
significantly improves and achieves high top-5accuracy with 83.2% accuracy
compared to 62.6% achieved by comparable methods for the patient. Apart from
evaluating our approach on the ALS patient, we also extend it to people with
hearing impairment relying extensively on lip movements to communicate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LogAvgExp Provides a Principled and Performant Global Pooling Operator. (arXiv:2111.01742v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01742">
<div class="article-summary-box-inner">
<span><p>We seek to improve the pooling operation in neural networks, by applying a
more theoretically justified operator. We demonstrate that LogSumExp provides a
natural OR operator for logits. When one corrects for the number of elements
inside the pooling operator, this becomes $\text{LogAvgExp} :=
\log(\text{mean}(\exp(x)))$. By introducing a single temperature parameter,
LogAvgExp smoothly transitions from the max of its operands to the mean (found
at the limiting cases $t \to 0^+$ and $t \to +\infty$). We experimentally
tested LogAvgExp, both with and without a learnable temperature parameter, in a
variety of deep neural network architectures for computer vision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Increasing Liquid State Machine Performance with Edge-of-Chaos Dynamics Organized by Astrocyte-modulated Plasticity. (arXiv:2111.01760v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01760">
<div class="article-summary-box-inner">
<span><p>The liquid state machine (LSM) combines low training complexity and
biological plausibility, which has made it an attractive machine learning
framework for edge and neuromorphic computing paradigms. Originally proposed as
a model of brain computation, the LSM tunes its internal weights without
backpropagation of gradients, which results in lower performance compared to
multi-layer neural networks. Recent findings in neuroscience suggest that
astrocytes, a long-neglected non-neuronal brain cell, modulate synaptic
plasticity and brain dynamics, tuning brain networks to the vicinity of the
computationally optimal critical phase transition between order and chaos.
Inspired by this disruptive understanding of how brain networks self-tune, we
propose the neuron-astrocyte liquid state machine (NALSM) that addresses
under-performance through self-organized near-critical dynamics. Similar to its
biological counterpart, the astrocyte model integrates neuronal activity and
provides global feedback to spike-timing-dependent plasticity (STDP), which
self-organizes NALSM dynamics around a critical branching factor that is
associated with the edge-of-chaos. We demonstrate that NALSM achieves
state-of-the-art accuracy versus comparable LSM methods, without the need for
data-specific hand-tuning. With a top accuracy of 97.61% on MNIST, 97.51% on
N-MNIST, and 85.84% on Fashion-MNIST, NALSM achieved comparable performance to
current fully-connected multi-layer spiking neural networks trained via
backpropagation. Our findings suggest that the further development of
brain-inspired machine learning methods has the potential to reach the
performance of deep learning, with the added benefits of supporting robust and
energy-efficient neuromorphic computing on the edge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PatchGame: Learning to Signal Mid-level Patches in Referential Games. (arXiv:2111.01785v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01785">
<div class="article-summary-box-inner">
<span><p>We study a referential game (a type of signaling game) where two agents
communicate with each other via a discrete bottleneck to achieve a common goal.
In our referential game, the goal of the speaker is to compose a message or a
symbolic representation of "important" image patches, while the task for the
listener is to match the speaker's message to a different view of the same
image. We show that it is indeed possible for the two agents to develop a
communication protocol without explicit or implicit supervision. We further
investigate the developed protocol and show the applications in speeding up
recent Vision Transformers by using only important patches, and as pre-training
for downstream recognition tasks (e.g., classification). Code available at
https://github.com/kampta/PatchGame.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Not all Failure Modes are Created Equal: Training Deep Neural Networks for Explicable (Mis)Classification. (arXiv:2006.14841v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.14841">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks are often brittle on image classification tasks and
known to misclassify inputs. While these misclassifications may be inevitable,
all failure modes cannot be considered equal. Certain misclassifications (eg.
classifying the image of a dog to an airplane) can perplex humans and result in
the loss of human trust in the system. Even worse, these errors (eg. a person
misclassified as a primate) can have odious societal impacts. Thus, in this
work, we aim to reduce inexplicable errors. To address this challenge, we first
discuss methods to obtain the class-level semantics that capture the human's
expectation ($M^h$) regarding which classes are semantically close {\em vs.}
ones that are far away. We show that for popular image benchmarks (like
CIFAR-10, CIFAR-100, ImageNet), class-level semantics can be readily obtained
by leveraging either human subject studies or publicly available human-curated
knowledge bases. Second, we propose the use of Weighted Loss Functions (WLFs)
to penalize misclassifications by the weight of their inexplicability. Finally,
we show that training (or fine-tuning) existing classifiers with the proposed
methods lead to Deep Neural Networks that have (1) comparable top-1 accuracy,
(2) more explicable failure modes on both in-distribution and
out-of-distribution (OOD) test data, and (3) incur significantly less cost in
the gathering of additional human labels compared to existing works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised 3D Human Pose Representation with Viewpoint and Pose Disentanglement. (arXiv:2007.07053v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.07053">
<div class="article-summary-box-inner">
<span><p>Learning a good 3D human pose representation is important for human pose
related tasks, e.g. human 3D pose estimation and action recognition. Within all
these problems, preserving the intrinsic pose information and adapting to view
variations are two critical issues. In this work, we propose a novel Siamese
denoising autoencoder to learn a 3D pose representation by disentangling the
pose-dependent and view-dependent feature from the human skeleton data, in a
fully unsupervised manner. These two disentangled features are utilized
together as the representation of the 3D pose. To consider both the kinematic
and geometric dependencies, a sequential bidirectional recursive network
(SeBiReNet) is further proposed to model the human skeleton data. Extensive
experiments demonstrate that the learned representation 1) preserves the
intrinsic information of human pose, 2) shows good transferability across
datasets and tasks. Notably, our approach achieves state-of-the-art performance
on two inherently different tasks: pose denoising and unsupervised action
recognition. Code and models are available at:
\url{https://github.com/NIEQiang001/unsupervised-human-pose.git}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Learning of Multi-Object 3D Scene Decompositions Using Deep Shape Priors. (arXiv:2010.04030v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04030">
<div class="article-summary-box-inner">
<span><p>Representing scenes at the granularity of objects is a prerequisite for scene
understanding and decision making. We propose PriSMONet, a novel approach based
on Prior Shape knowledge for learning Multi-Object 3D scene decomposition and
representations from single images. Our approach learns to decompose images of
synthetic scenes with multiple objects on a planar surface into its constituent
scene objects and to infer their 3D properties from a single view. A recurrent
encoder regresses a latent representation of 3D shape, pose and texture of each
object from an input RGB image. By differentiable rendering, we train our model
to decompose scenes from RGB-D images in a self-supervised way. The 3D shapes
are represented continuously in function-space as signed distance functions
which we pre-train from example shapes in a supervised way. These shape priors
provide weak supervision signals to better condition the challenging overall
learning task. We evaluate the accuracy of our model in inferring 3D scene
layout, demonstrate its generative capabilities, assess its generalization to
real images, and point out benefits of the learned representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modular Action Concept Grounding in Semantic Video Prediction. (arXiv:2011.11201v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11201">
<div class="article-summary-box-inner">
<span><p>Recent works in video prediction have mainly focused on passive forecasting
and low-level action-conditional prediction, which sidesteps the learning of
interaction between agents and objects. We introduce the task of semantic
action-conditional video prediction, which uses semantic action labels to
describe those interactions and can be regarded as an inverse problem of action
recognition. The challenge of this new task primarily lies in how to
effectively inform the model of semantic action information. Inspired by the
idea of Mixture of Experts, we embody each abstract label by a structured
combination of various visual concept learners and propose a novel video
prediction model, Modular Action Concept Network (MAC). Our method is evaluated
on two newly designed synthetic datasets, CLEVR-Building-Blocks and
Sapien-Kitchen, and one real-world dataset called Tower-Creation. Extensive
experiments demonstrate that MAC can correctly condition on given instructions
and generate corresponding future frames without need of bounding boxes. We
further show that the trained model can make out-of-distribution
generalization, be quickly adapted to new object categories and exploit its
learnt features for object detection, showing the progression towards
higher-level cognitive abilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00517">
<div class="article-summary-box-inner">
<span><p>Computer vision and machine learning can be used to automate various tasks in
cancer diagnostic and detection. If an attacker can manipulate the automated
processing, the results can be devastating and in the worst case lead to wrong
diagnosis and treatment. In this research, the goal is to demonstrate the use
of one-pixel attacks in a real-life scenario with a real pathology dataset,
TUPAC16, which consists of digitized whole-slide images. We attack against the
IBM CODAIT's MAX breast cancer detector using adversarial images. These
adversarial examples are found using differential evolution to perform the
one-pixel modification to the images in the dataset. The results indicate that
a minor one-pixel modification of a whole slide image under analysis can affect
the diagnosis by reversing the automatic diagnosis result. The attack poses a
threat from the cyber security perspective: the one-pixel method can be used as
an attack vector by a motivated attacker.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Self-Similarity in Space and Time as Generalized Motion for Video Action Recognition. (arXiv:2102.07092v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07092">
<div class="article-summary-box-inner">
<span><p>Spatio-temporal convolution often fails to learn motion dynamics in videos
and thus an effective motion representation is required for video understanding
in the wild. In this paper, we propose a rich and robust motion representation
based on spatio-temporal self-similarity (STSS). Given a sequence of frames,
STSS represents each local region as similarities to its neighbors in space and
time. By converting appearance features into relational values, it enables the
learner to better recognize structural patterns in space and time. We leverage
the whole volume of STSS and let our model learn to extract an effective motion
representation from it. The proposed neural block, dubbed SELFY, can be easily
inserted into neural architectures and trained end-to-end without additional
supervision. With a sufficient volume of the neighborhood in space and time, it
effectively captures long-term interaction and fast motion in the video,
leading to robust action recognition. Our experimental analysis demonstrates
its superiority over previous methods for motion modeling as well as its
complementarity to spatio-temporal features from direct convolution. On the
standard action recognition benchmarks, Something-Something-V1 &amp; V2, Diving-48,
and FineGym, the proposed method achieves the state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss. (arXiv:2102.09808v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09808">
<div class="article-summary-box-inner">
<span><p>Although deep feedforward neural networks share some characteristics with the
primate visual system, a key distinction is their dynamics. Deep nets typically
operate in serial stages wherein each layer completes its computation before
processing begins in subsequent layers. In contrast, biological systems have
cascaded dynamics: information propagates from neurons at all layers in
parallel but transmission occurs gradually over time, leading to speed-accuracy
trade offs even in feedforward architectures. We explore the consequences of
biologically inspired parallel hardware by constructing cascaded ResNets in
which each residual block has propagation delays but all blocks update in
parallel in a stateful manner. Because information transmitted through skip
connections avoids delays, the functional depth of the architecture increases
over time, yielding anytime predictions that improve with internal-processing
time. We introduce a temporal-difference training loss that achieves a strictly
superior speed-accuracy profile over standard losses and enables the cascaded
architecture to outperform state-of-the-art anytime-prediction methods. The
cascaded architecture has intriguing properties, including: it classifies
typical instances more rapidly than atypical instances; it is more robust to
both persistent and transient noise than is a conventional ResNet; and its
time-varying output trace provides a signal that can be exploited to improve
information processing and inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Dataset Collaborative Learning for Semantic Segmentation in Autonomous Driving. (arXiv:2103.11351v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11351">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation is an important task for scene understanding in
self-driving cars and robotics, which aims to assign dense labels for all
pixels in the image. Existing work typically improves semantic segmentation
performance by exploring different network architectures on a target dataset.
Little attention has been paid to build a unified system by simultaneously
learning from multiple datasets due to the inherent distribution shift across
different datasets. In this paper, we propose a simple, flexible, and general
method for semantic segmentation, termed Cross-Dataset Collaborative Learning
(CDCL). Our goal is to train a unified model for improving the performance in
each dataset by leveraging information from all the datasets. Specifically, we
first introduce a family of Dataset-Aware Blocks (DAB) as the fundamental
computing units of the network, which help capture homogeneous convolutional
representations and heterogeneous statistics across different datasets. Second,
we present a Dataset Alternation Training (DAT) mechanism to facilitate the
collaborative optimization procedure. We conduct extensive evaluations on
diverse semantic segmentation datasets for autonomous driving. Experiments
demonstrate that our method consistently achieves notable improvements over
prior single-dataset and cross-dataset training methods without introducing
extra FLOPs. Particularly, with the same architecture of PSPNet (ResNet-18),
our method outperforms the single-dataset baseline by 5.65\%, 6.57\%, and
5.79\% mIoU on the validation sets of Cityscapes, BDD100K, CamVid,
respectively. We also apply CDCL for point cloud 3D semantic segmentation and
achieve improved performance, which further validates the superiority and
generality of our method. Code and models will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shared Latent Space of Font Shapes and Their Noisy Impressions. (arXiv:2103.12347v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12347">
<div class="article-summary-box-inner">
<span><p>Styles of typefaces or fonts are often associated with specific impressions,
such as heavy, contemporary, or elegant. This indicates that there are certain
correlations between font shapes and their impressions. To understand the
correlations, this paper realizes a shared latent space where a font and its
impressions are embedded nearby. The difficulty is that the impression words
attached to a font are often very noisy. This is because impression words are
very subjective and diverse. More importantly, some impression words have no
direct relevance to the font shapes and will disturb the realization of the
shared latent space. We, therefore, use DeepSets for enhancing shape-relevant
words and suppressing shape irrelevant words automatically while training the
shared latent space. Quantitative and qualitative experimental results with a
large-scale font-impression dataset demonstrate that the shared latent space by
the proposed method describes the correlation appropriately, especially for the
shape-relevant impression words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Novelty Detection and Analysis of Traffic Scenario Infrastructures in the Latent Space of a Vision Transformer-Based Triplet Autoencoder. (arXiv:2105.01924v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01924">
<div class="article-summary-box-inner">
<span><p>Detecting unknown and untested scenarios is crucial for scenario-based
testing. Scenario-based testing is considered to be a possible approach to
validate autonomous vehicles. A traffic scenario consists of multiple
components, with infrastructure being one of it. In this work, a method to
detect novel traffic scenarios based on their infrastructure images is
presented. An autoencoder triplet network provides latent representations for
infrastructure images which are used for outlier detection. The triplet
training of the network is based on the connectivity graphs of the
infrastructure. By using the proposed architecture, expert-knowledge is used to
shape the latent space such that it incorporates a pre-defined similarity in
the neighborhood relationships of an autoencoder. An ablation study on the
architecture is highlighting the importance of the triplet autoencoder
combination. The best performing architecture is based on vision transformers,
a convolution-free attention-based network. The presented method outperforms
other state-of-the-art outlier detection approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GasHisSDB: A New Gastric Histopathology Image Dataset for Computer Aided Diagnosis of Gastric Cancer. (arXiv:2106.02473v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02473">
<div class="article-summary-box-inner">
<span><p>Background and Objective: Gastric cancer has turned out to be the fifth most
common cancer globally, and early detection of gastric cancer is essential to
save lives. Histopathological examination of gastric cancer is the gold
standard for the diagnosis of gastric cancer. However, computer-aided
diagnostic techniques are challenging to evaluate due to the scarcity of
publicly available gastric histopathology image datasets. Methods: In this
paper, a noble publicly available Gastric Histopathology Sub-size Image
Database (GasHisSDB) is published to identify classifiers' performance.
Specifically, two types of data are included: normal and abnormal, with a total
of 245,196 tissue case images. In order to prove that the methods of different
periods in the field of image classification have discrepancies on GasHisSDB,
we select a variety of classifiers for evaluation. Seven classical machine
learning classifiers, three Convolutional Neural Network classifiers, and a
novel transformer-based classifier are selected for testing on image
classification tasks. Results: This study performed extensive experiments using
traditional machine learning and deep learning methods to prove that the
methods of different periods have discrepancies on GasHisSDB. Traditional
machine learning achieved the best accuracy rate of 86.08% and a minimum of
just 41.12%. The best accuracy of deep learning reached 96.47% and the lowest
was 86.21%. Accuracy rates vary significantly across classifiers. Conclusions:
To the best of our knowledge, it is the first publicly available gastric cancer
histopathology dataset containing a large number of images for weakly
supervised learning. We believe that GasHisSDB can attract researchers to
explore new algorithms for the automated diagnosis of gastric cancer, which can
help physicians and patients in the clinical setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Improving Adversarial Transferability of Vision Transformers. (arXiv:2106.04169v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04169">
<div class="article-summary-box-inner">
<span><p>Vision transformers (ViTs) process input images as sequences of patches via
self-attention; a radically different architecture than convolutional neural
networks (CNNs). This makes it interesting to study the adversarial feature
space of ViT models and their transferability. In particular, we observe that
adversarial patterns found via conventional adversarial attacks show very low
black-box transferability even for large ViT models. However, we show that this
phenomenon is only due to the sub-optimal attack procedures that do not
leverage the true representation potential of ViTs. A deep ViT is composed of
multiple blocks, with a consistent architecture comprising of self-attention
and feed-forward layers, where each block is capable of independently producing
a class token. Formulating an attack using only the last class token
(conventional approach) does not directly leverage the discriminative
information stored in the earlier tokens, leading to poor adversarial
transferability of ViTs. Using the compositional nature of ViT models, we
enhance the transferability of existing attacks by introducing two novel
strategies specific to the architecture of ViT models. (i) Self-Ensemble: We
propose a method to find multiple discriminative pathways by dissecting a
single ViT model into an ensemble of networks. This allows explicitly utilizing
class-specific information at each ViT block. (ii) Token Refinement: We then
propose to refine the tokens to further enhance the discriminative capacity at
each block of ViT. Our token refinement systematically combines the class
tokens with structural information preserved within the patch tokens. An
adversarial attack, when applied to such refined tokens within the ensemble of
classifiers found in a single vision transformer, has significantly higher
transferability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Densely connected normalizing flows. (arXiv:2106.04627v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04627">
<div class="article-summary-box-inner">
<span><p>Normalizing flows are bijective mappings between inputs and latent
representations with a fully factorized distribution. They are very attractive
due to exact likelihood valuation and efficient sampling. However, their
effective capacity is often insufficient since the bijectivity constraint
limits the model width. We address this issue by incrementally padding
intermediate representations with noise. We precondition the noise in
accordance with previous invertible units, which we describe as cross-unit
coupling. Our invertible glow-like modules increase the model expressivity by
fusing a densely connected block with Nystrom self-attention. We refer to our
architecture as DenseFlow since both cross-unit and intra-module couplings rely
on dense connectivity. Experiments show significant improvements due to the
proposed contributions and reveal state-of-the-art density estimation under
moderate computing budgets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey: Image Mixing and Deleting for Data Augmentation. (arXiv:2106.07085v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07085">
<div class="article-summary-box-inner">
<span><p>Data augmentation has been widely used to improve deep nerual networks
performance. Numerous approaches are suggested, for example, dropout,
regularization and image augmentation, to avoid over-ftting and enhancing
generalization of neural networks. One of the sub-area within data augmentation
is image mixing and deleting. This specific type of augmentation either mixes
two images or delete image regions to hide or make certain characteristics of
images confusing for the network to force it to emphasize on overall structure
of object in image. The model trained with this approach has shown to perform
and generalize well as compared to one trained without imgage mixing or
deleting. Additional benefit achieved with this method of training is
robustness against image corruptions. Due to its low compute cost and success
in recent past, many techniques of image mixing and deleting are proposed. This
paper provides detailed review on these devised approaches, dividing
augmentation strategies in three main categories cut and delete, cut and mix
and mixup. The second part of paper emprically evaluates these approaches for
image classification, finegrained image recognition and object detection where
it is shown that this category of data augmentation improves the overall
performance for deep neural networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v4 [math.OC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08208">
<div class="article-summary-box-inner">
<span><p>Adaptive gradient methods have shown excellent performances for solving many
machine learning problems. Although multiple adaptive methods were recently
studied, they mainly focus on either empirical or theoretical aspects and also
only work for specific problems by using some specific adaptive learning rates.
It is desired to design a universal framework for practical algorithms of
adaptive gradients with theoretical guarantee to solve general problems. To
fill this gap, we propose a faster and universal framework of adaptive
gradients (i.e., SUPER-ADAM) by introducing a universal adaptive matrix that
includes most existing adaptive gradient forms. Moreover, our framework can
flexibly integrate the momentum and variance reduced techniques. In particular,
our novel framework provides the convergence analysis support for adaptive
gradient methods under the nonconvex setting. In theoretical analysis, we prove
that our SUPER-ADAM algorithm can achieve the best known complexity of
$\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary point of
nonconvex optimization, which matches the lower bound for stochastic smooth
nonconvex optimization. In numerical experiments, we employ various deep
learning tasks to validate that our algorithm consistently outperforms the
existing adaptive algorithms. Code is available at
https://github.com/LIJUNYI95/SuperAdam
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity. (arXiv:2106.14568v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14568">
<div class="article-summary-box-inner">
<span><p>Recent works on sparse neural networks have demonstrated the possibility to
train a sparse subnetwork independently from scratch, to match the performance
of its corresponding dense network. However, identifying such sparse
subnetworks (winning tickets) either involves a costly iterative
train-prune-retrain process (e.g., Lottery Ticket Hypothesis) or an
over-extended training time (e.g., Dynamic Sparse Training). In this work, we
draw a unique connection between sparse neural network training and the deep
ensembling technique, yielding a novel ensemble learning framework called
FreeTickets. Instead of starting from a dense network, FreeTickets randomly
initializes a sparse subnetwork and then trains the subnetwork while
dynamically adjusting its sparse mask, resulting in many diverse sparse
subnetworks throughout the training process. FreeTickets is defined as the
ensemble of these sparse subnetworks freely obtained during this one-pass,
sparse-to-sparse training, which uses only a fraction of the computational
resources required by the vanilla dense training. Moreover, despite being an
ensemble of models, FreeTickets has even fewer parameters and training FLOPs
compared to a single dense model: this seemingly counter-intuitive outcome is
due to the high sparsity of each subnetwork. FreeTickets is observed to
demonstrate a significant all-round improvement compared to standard dense
baselines, in prediction accuracy, uncertainty estimation, robustness, and
efficiency. FreeTickets easily outperforms the naive deep ensemble with
ResNet50 on ImageNet using only a quarter of the training FLOPs required by the
latter. Our results provide insights into the strength of sparse neural
networks and suggest that the benefits of sparsity go way beyond the usually
expected inference efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Mesh Prior: Unsupervised Mesh Restoration using Graph Convolutional Networks. (arXiv:2107.02909v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02909">
<div class="article-summary-box-inner">
<span><p>This paper addresses mesh restoration problems, i.e., denoising and
completion, by learning self-similarity in an unsupervised manner. For this
purpose, the proposed method, which we refer to as Deep Mesh Prior, uses a
graph convolutional network on meshes to learn the self-similarity. The network
takes a single incomplete mesh as input data and directly outputs the
reconstructed mesh without being trained using large-scale datasets. Our method
does not use any intermediate representations such as an implicit field because
the whole process works on a mesh. We demonstrate that our unsupervised method
performs equally well or even better than the state-of-the-art methods using
large-scale datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Machine Learning based Segmentation Models on Jet Fire Radiation Zones. (arXiv:2107.03461v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03461">
<div class="article-summary-box-inner">
<span><p>Risk assessment is relevant in any workplace, however there is a degree of
unpredictability when dealing with flammable or hazardous materials so that
detection of fire accidents by itself may not be enough. An example of this is
the impingement of jet fires, where the heat fluxes of the flame could reach
nearby equipment and dramatically increase the probability of a domino effect
with catastrophic results. Because of this, the characterization of such fire
accidents is important from a risk management point of view. One such
characterization would be the segmentation of different radiation zones within
the flame, so this paper presents an exploratory research regarding several
traditional computer vision and Deep Learning segmentation approaches to solve
this specific problem. A data set of propane jet fires is used to train and
evaluate the different approaches and given the difference in the distribution
of the zones and background of the images, different loss functions, that seek
to alleviate data imbalance, are also explored. Additionally, different metrics
are correlated to a manual ranking performed by experts to make an evaluation
that closely resembles the expert's criteria. The Hausdorff Distance and
Adjusted Random Index were the metrics with the highest correlation and the
best results were obtained from the UNet architecture with a Weighted
Cross-Entropy Loss. These results can be used in future research to extract
more geometric information from the segmentation masks or could even be
implemented on other types of fire accidents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning-based Frozen Section to FFPE Translation. (arXiv:2107.11786v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11786">
<div class="article-summary-box-inner">
<span><p>Frozen sectioning (FS) is the preparation method of choice for microscopic
evaluation of tissues during surgical operations. The high speed of the
procedure allows pathologists to rapidly assess the key microscopic features,
such as tumour margins and malignant status to guide surgical decision-making
and minimise disruptions to the course of the operation. However, FS is prone
to introducing many misleading artificial structures (histological artefacts),
such as nuclear ice crystals, compression, and cutting artefacts, hindering
timely and accurate diagnostic judgement of the pathologist. Additional
training and prolonged experience is often required to make highly effective
and time-critical diagnosis on frozen sections. On the other hand, the gold
standard tissue preparation technique of formalin-fixation and
paraffin-embedding (FFPE) provides significantly superior image quality, but is
a very time-consuming process (12-48 hours), making it unsuitable for
intra-operative use. In this paper, we propose an artificial intelligence (AI)
method that improves FS image quality by computationally transforming
frozen-sectioned whole-slide images (FS-WSIs) into whole-slide FFPE-style
images in minutes. AI-FFPE rectifies FS artefacts with the guidance of an
attention mechanism that puts a particular emphasis on artefacts while
utilising a self-regularization mechanism established between FS input image
and synthesized FFPE-style image that preserves clinically relevant features.
As a result, AI-FFPE method successfully generates FFPE-style images without
significantly extending tissue processing time and consequently improves
diagnostic accuracy. We demonstrate the efficacy of AI-FFPE on lung and brain
frozen sections using a variety of different qualitative and quantitative
metrics including visual Turing tests from 20 board certified pathologists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unlimited Neighborhood Interaction for Heterogeneous Trajectory Prediction. (arXiv:2108.00238v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00238">
<div class="article-summary-box-inner">
<span><p>Understanding complex social interactions among agents is a key challenge for
trajectory prediction. Most existing methods consider the interactions between
pairwise traffic agents or in a local area, while the nature of interactions is
unlimited, involving an uncertain number of agents and non-local areas
simultaneously. Besides, they treat heterogeneous traffic agents the same,
namely those among agents of different categories, while neglecting people's
diverse reaction patterns toward traffic agents in ifferent categories. To
address these problems, we propose a simple yet effective Unlimited
Neighborhood Interaction Network (UNIN), which predicts trajectories of
heterogeneous agents in multiple categories. Specifically, the proposed
unlimited neighborhood interaction module generates the fused-features of all
agents involved in an interaction simultaneously, which is adaptive to any
number of agents and any range of interaction area. Meanwhile, a hierarchical
graph attention module is proposed to obtain category-to-category interaction
and agent-to-agent interaction. Finally, parameters of a Gaussian Mixture Model
are estimated for generating the future trajectories. Extensive experimental
results on benchmark datasets demonstrate a significant performance improvement
of our method over the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks. (arXiv:2108.03272v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03272">
<div class="article-summary-box-inner">
<span><p>Recent research in embodied AI has been boosted by the use of simulation
environments to develop and train robot learning approaches. However, the use
of simulation has skewed the attention to tasks that only require what robotics
simulators can simulate: motion and physical contact. We present iGibson 2.0,
an open-source simulation environment that supports the simulation of a more
diverse set of household tasks through three key innovations. First, iGibson
2.0 supports object states, including temperature, wetness level, cleanliness
level, and toggled and sliced states, necessary to cover a wider range of
tasks. Second, iGibson 2.0 implements a set of predicate logic functions that
map the simulator states to logic states like Cooked or Soaked. Additionally,
given a logic state, iGibson 2.0 can sample valid physical states that satisfy
it. This functionality can generate potentially infinite instances of tasks
with minimal effort from the users. The sampling mechanism allows our scenes to
be more densely populated with small objects in semantically meaningful
locations. Third, iGibson 2.0 includes a virtual reality (VR) interface to
immerse humans in its scenes to collect demonstrations. As a result, we can
collect demonstrations from humans on these new types of tasks, and use them
for imitation learning. We evaluate the new capabilities of iGibson 2.0 to
enable robot learning of novel tasks, in the hope of demonstrating the
potential of this new simulator to support new research in embodied AI. iGibson
2.0 and its new dataset will be publicly available at
<a href="http://svl.stanford.edu/igibson/.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Generalization of Batch Whitening by Convolutional Unit Optimization. (arXiv:2108.10629v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10629">
<div class="article-summary-box-inner">
<span><p>Batch Whitening is a technique that accelerates and stabilizes training by
transforming input features to have a zero mean (Centering) and a unit variance
(Scaling), and by removing linear correlation between channels (Decorrelation).
In commonly used structures, which are empirically optimized with Batch
Normalization, the normalization layer appears between convolution and
activation function. Following Batch Whitening studies have employed the same
structure without further analysis; even Batch Whitening was analyzed on the
premise that the input of a linear layer is whitened. To bridge the gap, we
propose a new Convolutional Unit that is in line with the theory, and our
method generally improves the performance of Batch Whitening. Moreover, we show
the inefficacy of the original Convolutional Unit by investigating rank and
correlation of features. As our method is employable off-the-shelf whitening
modules, we use Iterative Normalization (IterNorm), the state-of-the-art
whitening module, and obtain significantly improved performance on five image
classification datasets: CIFAR-10, CIFAR-100, CUB-200-2011, Stanford Dogs, and
ImageNet. Notably, we verify that our method improves stability and performance
of whitening when using large learning rate, group size, and iteration number.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-domain semantic segmentation with overlapping labels. (arXiv:2108.11224v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11224">
<div class="article-summary-box-inner">
<span><p>Deep supervised models have an unprecedented capacity to absorb large
quantities of training data. Hence, training on many datasets becomes a method
of choice towards graceful degradation in unusual scenes. Unfortunately,
different datasets often use incompatible labels. For instance, the Cityscapes
road class subsumes all driving surfaces, while Vistas defines separate classes
for road markings, manholes etc. We address this challenge by proposing a
principled method for seamless learning on datasets with overlapping classes
based on partial labels and probabilistic loss. Our method achieves competitive
within-dataset and cross-dataset generalization, as well as ability to learn
visual concepts which are not separately labeled in any of the training
datasets. Experiments reveal competitive or state-of-the-art performance on two
multi-domain dataset collections and on the WildDash 2 benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learnable Multi-level Frequency Decomposition and Hierarchical Attention Mechanism for Generalized Face Presentation Attack Detection. (arXiv:2109.07950v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07950">
<div class="article-summary-box-inner">
<span><p>With the increased deployment of face recognition systems in our daily lives,
face presentation attack detection (PAD) is attracting much attention and
playing a key role in securing face recognition systems. Despite the great
performance achieved by the hand-crafted and deep-learning-based methods in
intra-dataset evaluations, the performance drops when dealing with unseen
scenarios. In this work, we propose a dual-stream convolution neural networks
(CNNs) framework. One stream adapts four learnable frequency filters to learn
features in the frequency domain, which are less influenced by variations in
sensors/illuminations. The other stream leverages the RGB images to complement
the features of the frequency domain. Moreover, we propose a hierarchical
attention module integration to join the information from the two streams at
different stages by considering the nature of deep features in different layers
of the CNN. The proposed method is evaluated in the intra-dataset and
cross-dataset setups, and the results demonstrate that our proposed approach
enhances the generalizability in most experimental setups in comparison to
state-of-the-art, including the methods designed explicitly for domain
adaption/shift problems. We successfully prove the design of our proposed PAD
solution in a step-wise ablation study that involves our proposed learnable
frequency decomposition, our hierarchical attention module design, and the used
loss function. Training codes and pre-trained models are publicly released
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Oriented Object Detection in Aerial Images Based on Area Ratio of Parallelogram. (arXiv:2109.10187v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10187">
<div class="article-summary-box-inner">
<span><p>Oriented object detection is a challenging task in aerial images since the
objects in aerial images are displayed in arbitrary directions and are
frequently densely packed. The mainstream detectors describe rotating objects
using a five-parament or eight-parament representations, which suffer from
representation ambiguity for orientated object definition. In this paper, we
propose a novel representation method based on area ratio of parallelogram,
called ARP. Specifically, ARP regresses the minimum bounding rectangle of the
oriented object and three area ratios. Three area ratios include the area ratio
of a directed object to the smallest circumscribed rectangle and two
parallelograms to the minimum circumscribed rectangle. It simplifies offset
learning and eliminates the issue of angular periodicity or label point
sequences for oriented objects. To further remedy the confusion issue of nearly
horizontal objects, the area ratio between the object and its minimal
circumscribed rectangle is employed to guide the selection of horizontal or
oriented detection for each object. Moreover, the rotated efficient
Intersection over Union (R-EIoU) loss with horizontal bounding box and three
area ratios are designed to optimize the bounding box regression for rotating
objects. Experimental results on remote sensing datasets, including HRSC2016,
DOTA, and UCAS-AOD, show that our method achieves superior detection
performance than many state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust and Decomposable Average Precision for Image Retrieval. (arXiv:2110.01445v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01445">
<div class="article-summary-box-inner">
<span><p>In image retrieval, standard evaluation metrics rely on score ranking, e.g.
average precision (AP). In this paper, we introduce a method for robust and
decomposable average precision (ROADMAP) addressing two major challenges for
end-to-end training of deep neural networks with AP: non-differentiability and
non-decomposability. Firstly, we propose a new differentiable approximation of
the rank function, which provides an upper bound of the AP loss and ensures
robust training. Secondly, we design a simple yet effective loss function to
reduce the decomposability gap between the AP in the whole training set and its
averaged batch approximation, for which we provide theoretical guarantees.
Extensive experiments conducted on three image retrieval datasets show that
ROADMAP outperforms several recent AP approximation methods and highlight the
importance of our two contributions. Finally, using ROADMAP for training deep
models yields very good performances, outperforming state-of-the-art results on
the three datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Let there be a clock on the beach: Reducing Object Hallucination in Image Captioning. (arXiv:2110.01705v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01705">
<div class="article-summary-box-inner">
<span><p>Explaining an image with missing or non-existent objects is known as object
bias (hallucination) in image captioning. This behaviour is quite common in the
state-of-the-art captioning models which is not desirable by humans. To
decrease the object hallucination in captioning, we propose three simple yet
efficient training augmentation method for sentences which requires no new
training data or increase in the model size. By extensive analysis, we show
that the proposed methods can significantly diminish our models' object bias on
hallucination metrics. Moreover, we experimentally demonstrate that our methods
decrease the dependency on the visual features. All of our code, configuration
files and model weights will be made public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision-based Excavator Activity Analysis and Safety Monitoring System. (arXiv:2110.03083v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03083">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose an excavator activity analysis and safety
monitoring system, leveraging recent advancements in deep learning and computer
vision. Our proposed system detects the surrounding environment and the
excavators while estimating the poses and actions of the excavators. Compared
to previous systems, our method achieves higher accuracy in object detection,
pose estimation, and action recognition tasks. In addition, we build an
excavator dataset using the Autonomous Excavator System (AES) on the waste
disposal recycle scene to demonstrate the effectiveness of our system. We also
evaluate our method on a benchmark construction dataset. The experimental
results show that the proposed action recognition approach outperforms the
state-of-the-art approaches on top-1 accuracy by about 5.18%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cartoon Explanations of Image Classifiers. (arXiv:2110.03485v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03485">
<div class="article-summary-box-inner">
<span><p>We present CartoonX (Cartoon Explanation), a novel model-agnostic explanation
method tailored towards image classifiers and based on the rate-distortion
explanation (RDE) framework. Natural images are roughly piece-wise smooth
signals -- also called cartoon images -- and tend to be sparse in the wavelet
domain. CartoonX is the first explanation method to exploit this by requiring
its explanations to be sparse in the wavelet domain, thus extracting the
\emph{relevant piece-wise smooth} part of an image instead of relevant
pixel-sparse regions. We demonstrate experimentally that CartoonX is not only
highly interpretable due to its piece-wise smooth nature but also particularly
apt at explaining misclassifications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Closer Look at Prototype Classifier for Few-shot Image Classification. (arXiv:2110.05076v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05076">
<div class="article-summary-box-inner">
<span><p>The prototypical network is a prototype classifier based on meta-learning and
is widely used for few-shot learning because it classifies unseen examples by
constructing class-specific prototypes without adjusting hyper-parameters
during meta-testing. Interestingly, recent research has attracted a lot of
attention, showing that a linear classifier with fine-tuning, which does not
use a meta-learning algorithm, performs comparably with the prototypical
network. However, fine-tuning requires additional hyper-parameters when
adapting a model to a new environment. In addition, although the purpose of
few-shot learning is to enable the model to quickly adapt to a new environment,
fine-tuning needs to be applied every time a new class appears, making fast
adaptation difficult. In this paper, we analyze how a prototype classifier
works equally well without fine-tuning and meta-learning. We experimentally
found that directly using the feature vector extracted using standard
pre-trained models to construct a prototype classifier in meta-testing does not
perform as well as the prototypical network and linear classifiers with
fine-tuning and feature vectors of pre-trained models. Thus, we derive a novel
generalization bound for the prototypical network and show that focusing on the
variance of the norm of a feature vector can improve performance. We
experimentally investigated several normalization methods for minimizing the
variance of the norm and found that the same performance can be obtained by
using the L2 normalization and embedding space transformation without
fine-tuning or meta-learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09113">
<div class="article-summary-box-inner">
<span><p>Salt and pepper noise removal is a common inverse problem in image
processing. Traditional denoising methods have two limitations. First, noise
characteristics are often not described accurately. For example, the noise
location information is often ignored and the sparsity of the salt and pepper
noise is often described by L1 norm, which cannot illustrate the sparse
variables clearly. Second, conventional methods separate the contaminated image
into a recovered image and a noise part, thus resulting in recovering an image
with unsatisfied smooth parts and detail parts. In this study, we introduce a
noise detection strategy to determine the position of the noise, and a
non-convex sparsity regularization depicted by Lp quasi-norm is employed to
describe the sparsity of the noise, thereby addressing the first limitation.
The morphological component analysis framework with stationary Framelet
transform is adopted to decompose the processed image into cartoon, texture,
and noise parts to resolve the second limitation. Then, the alternating
direction method of multipliers (ADMM) is employed to solve the proposed model.
Finally, experiments are conducted to verify the proposed method and compare it
with some current state-of-the-art denoising methods. The experimental results
show that the proposed method can remove salt and pepper noise while preserving
the details of the processed image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-Based Detection, Classification and Prediction/Prognosis in Medical Imaging: Towards Radiophenomics. (arXiv:2110.10332v3 [physics.med-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.10332">
<div class="article-summary-box-inner">
<span><p>Artificial intelligence (AI) techniques have significant potential to enable
effective, robust and automated image phenotyping including identification of
subtle patterns. AI-based detection searches the image space to find the
regions of interest based on patterns and features. There is a spectrum of
tumor histologies from benign to malignant that can be identified by AI-based
classification approaches using image features. The extraction of minable
information from images gives way to the field of radiomics and can be explored
via explicit (handcrafted/engineered) and deep radiomics frameworks. Radiomics
analysis has the potential to be utilized as a noninvasive technique for the
accurate characterization of tumors to improve diagnosis and treatment
monitoring. This work reviews AI-based techniques, with a special focus on
oncological PET and PET/CT imaging, for different detection, classification,
and prediction/prognosis tasks. We also discuss needed efforts to enable the
translation of AI techniques to routine clinical workflows, and potential
improvements and complementary techniques such as the use of natural language
processing on electronic health records and neuro-symbolic AI techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for HDR Imaging: State-of-the-Art and Future Trends. (arXiv:2110.10394v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.10394">
<div class="article-summary-box-inner">
<span><p>High dynamic range (HDR) imaging is a technique that allows an extensive
dynamic range of exposures, which is important in image processing, computer
graphics, and computer vision. In recent years, there has been a significant
advancement in HDR imaging using deep learning (DL). This study conducts a
comprehensive and insightful survey and analysis of recent developments in deep
HDR imaging methodologies. We hierarchically and structurally group existing
deep HDR imaging methods into five categories based on (1) number/domain of
input exposures, (2) number of learning tasks, (3) novel sensor data, (4) novel
learning strategies, and (5) applications. Importantly, we provide a
constructive discussion on each category regarding its potential and
challenges. Moreover, we review some crucial aspects of deep HDR imaging, such
as datasets and evaluation metrics. Finally, we highlight some open problems
and point out future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Effect of Wearing a Face Mask on Face Image Quality. (arXiv:2110.11283v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11283">
<div class="article-summary-box-inner">
<span><p>Due to the COVID-19 situation, face masks have become a main part of our
daily life. Wearing mouth-and-nose protection has been made a mandate in many
public places, to prevent the spread of the COVID-19 virus. However, face masks
affect the performance of face recognition, since a large area of the face is
covered. The effect of wearing a face mask on the different components of the
face recognition system in a collaborative environment is a problem that is
still to be fully studied. This work studies, for the first time, the effect of
wearing a face mask on face image quality by utilising state-of-the-art face
image quality assessment methods of different natures. This aims at providing
better understanding on the effect of face masks on the operation of face
recognition as a whole system. In addition, we further studied the effect of
simulated masks on face image utility in comparison to real face masks. We
discuss the correlation between the mask effect on face image quality and that
on the face verification performance by automatic systems and human experts,
indicating a consistent trend between both factors. The evaluation is conducted
on the database containing (1) no-masked faces, (2) real face masks, and (3)
simulated face masks, by synthetically generating digital facial masks on
no-masked faces. Finally, a visual interpretation of the face areas
contributing to the quality score of a selected set of quality assessment
methods is provided to give a deeper insight into the difference of network
decisions in masked and non-masked faces, among other variations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UVO Challenge on Video-based Open-World Segmentation 2021: 1st Place Solution. (arXiv:2110.11661v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11661">
<div class="article-summary-box-inner">
<span><p>In this report, we introduce our (pretty straightforard) two-step
"detect-then-match" video instance segmentation method. The first step performs
instance segmentation for each frame to get a large number of instance mask
proposals. The second step is to do inter-frame instance mask matching with the
help of optical flow. We demonstrate that with high quality mask proposals, a
simple matching mechanism is good enough for tracking. Our approach achieves
the first place in the UVO 2021 Video-based Open-World Segmentation Challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parametric Variational Linear Units (PVLUs) in Deep Convolutional Networks. (arXiv:2110.12246v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12246">
<div class="article-summary-box-inner">
<span><p>The Rectified Linear Unit is currently a state-of-the-art activation function
in deep convolutional neural networks. To combat ReLU's dying neuron problem,
we propose the Parametric Variational Linear Unit (PVLU), which adds a
sinusoidal function with trainable coefficients to ReLU. Along with introducing
nonlinearity and non-zero gradients across the entire real domain, PVLU acts as
a mechanism of fine-tuning when implemented in the context of transfer
learning. On a simple, non-transfer sequential CNN, PVLU substitution allowed
for relative error decreases of 16.3% and 11.3% (without and with data
augmentation) on CIFAR-100. PVLU is also tested on transfer learning models.
The VGG-16 and VGG-19 models experience relative error reductions of 9.5% and
10.7% on CIFAR-10, respectively, after the substitution of ReLU with PVLU. When
training on Gaussian-filtered CIFAR-10 images, similar improvements are noted
for the VGG models. Most notably, fine-tuning using PVLU allows for relative
error reductions up to and exceeding 10% for near state-of-the-art residual
neural network architectures on the CIFAR datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion. (arXiv:2110.13746v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13746">
<div class="article-summary-box-inner">
<span><p>We present neural radiance fields for rendering and temporal (4D)
reconstruction of humans in motion (H-NeRF), as captured by a sparse set of
cameras or even from a monocular video. Our approach combines ideas from neural
scene representation, novel-view synthesis, and implicit statistical geometric
human representations, coupled using novel loss functions. Instead of learning
a radiance field with a uniform occupancy prior, we constrain it by a
structured implicit human body model, represented using signed distance
functions. This allows us to robustly fuse information from sparse views and
generalize well beyond the poses or views observed in training. Moreover, we
apply geometric constraints to co-learn the structure of the observed subject
-- including both body and clothing -- and to regularize the radiance field to
geometrically plausible solutions. Extensive experiments on multiple datasets
demonstrate the robustness and the accuracy of our approach, its generalization
capabilities significantly outside a small training set of poses and views, and
statistical extrapolation beyond the observed shape.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FocusFace: Multi-task Contrastive Learning for Masked Face Recognition. (arXiv:2110.14940v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14940">
<div class="article-summary-box-inner">
<span><p>SARS-CoV-2 has presented direct and indirect challenges to the scientific
community. One of the most prominent indirect challenges advents from the
mandatory use of face masks in a large number of countries. Face recognition
methods struggle to perform identity verification with similar accuracy on
masked and unmasked individuals. It has been shown that the performance of
these methods drops considerably in the presence of face masks, especially if
the reference image is unmasked. We propose FocusFace, a multi-task
architecture that uses contrastive learning to be able to accurately perform
masked face recognition. The proposed architecture is designed to be trained
from scratch or to work on top of state-of-the-art face recognition methods
without sacrificing the capabilities of a existing models in conventional face
recognition tasks. We also explore different approaches to design the
contrastive learning module. Results are presented in terms of masked-masked
(M-M) and unmasked-masked (U-M) face verification performance. For both
settings, the results are on par with published methods, but for M-M
specifically, the proposed method was able to outperform all the solutions that
it was compared to. We further show that when using our method on top of
already existing methods the training computational costs decrease
significantly while retaining similar performances. The implementation and the
trained models are available at GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Effective Image Restorer: Denoising and Luminance Adjustment for Low-photon-count Imaging. (arXiv:2110.15715v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15715">
<div class="article-summary-box-inner">
<span><p>Imaging under photon-scarce situations introduces challenges to many
applications as the captured images are with low signal-to-noise ratio and poor
luminance. In this paper, we investigate the raw image restoration under
low-photon-count conditions by simulating the imaging of quanta image sensor
(QIS). We develop a lightweight framework, which consists of a multi-level
pyramid denoising network (MPDNet) and a luminance adjustment (LA) module to
achieve separate denoising and luminance enhancement. The main component of our
framework is the multi-skip attention residual block (MARB), which integrates
multi-scale feature fusion and attention mechanism for better feature
representation. Our MPDNet adopts the idea of Laplacian pyramid to learn the
small-scale noise map and larger-scale high-frequency details at different
levels, and feature extractions are conducted on the multi-scale input images
to encode richer contextual information. Our LA module enhances the luminance
of the denoised image by estimating its illumination, which can better avoid
color distortion. Extensive experimental results have demonstrated that our
image restorer can achieve superior performance on the degraded images with
various photon levels by suppressing noise and recovering luminance and color
effectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Explanations for Convolutional Neural Networks via Latent Traversal of Generative Adversarial Networks. (arXiv:2111.00116v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00116">
<div class="article-summary-box-inner">
<span><p>Lack of explainability in artificial intelligence, specifically deep neural
networks, remains a bottleneck for implementing models in practice. Popular
techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM)
provide a coarse map of salient features in an image, which rarely tells the
whole story of what a convolutional neural network (CNN) learned. Using
COVID-19 chest X-rays, we present a method for interpreting what a CNN has
learned by utilizing Generative Adversarial Networks (GANs). Our GAN framework
disentangles lung structure from COVID-19 features. Using this GAN, we can
visualize the transition of a pair of COVID negative lungs in a chest
radiograph to a COVID positive pair by interpolating in the latent space of the
GAN, which provides fine-grained visualization of how the CNN responds to
varying features within the lungs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognizing Families In the Wild (RFIW): The 5th Edition. (arXiv:2111.00598v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00598">
<div class="article-summary-box-inner">
<span><p>Recognizing Families In the Wild (RFIW), held as a data challenge in
conjunction with the 16th IEEE International Conference on Automatic Face and
Gesture Recognition (FG), is a large-scale, multi-track visual kinship
recognition evaluation. This is our fifth edition of RFIW, for which we
continue the effort to attract scholars, bring together professionals, publish
new work, and discuss prospects. In this paper, we summarize submissions for
the three tasks of this year's RFIW: specifically, we review the results for
kinship verification, tri-subject verification, and family member search and
retrieval. We take a look at the RFIW problem, as well as share current efforts
and make recommendations for promising future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of Human and Machine Face Detection using a Novel Distinctive Human Appearance Dataset. (arXiv:2111.00660v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00660">
<div class="article-summary-box-inner">
<span><p>Face detection is a long-standing challenge in the field of computer vision,
with the ultimate goal being to accurately localize human faces in an
unconstrained environment. There are significant technical hurdles in making
these systems accurate due to confounding factors related to pose, image
resolution, illumination, occlusion, and viewpoint [44]. That being said, with
recent developments in machine learning, face-detection systems have achieved
extraordinary accuracy, largely built on data-driven deep-learning models [70].
Though encouraging, a critical aspect that limits face-detection performance
and social responsibility of deployed systems is the inherent diversity of
human appearance. Every human appearance reflects something unique about a
person, including their heritage, identity, experiences, and visible
manifestations of self-expression. However, there are questions about how well
face-detection systems perform when faced with varying face size and shape,
skin color, body modification, and body ornamentation. Towards this goal, we
collected the Distinctive Human Appearance dataset, an image set that
represents appearances with low frequency and that tend to be undersampled in
face datasets. Then, we evaluated current state-of-the-art face-detection
models in their ability to detect faces in these images. The evaluation results
show that face-detection algorithms do not generalize well to these diverse
appearances. Evaluating and characterizing the state of current face-detection
models will accelerate research and development towards creating fairer and
more accurate face-detection systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling Object Detectors with Feature Richness. (arXiv:2111.00674v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00674">
<div class="article-summary-box-inner">
<span><p>In recent years, large-scale deep models have achieved great success, but the
huge computational complexity and massive storage requirements make it a great
challenge to deploy them in resource-limited devices. As a model compression
and acceleration method, knowledge distillation effectively improves the
performance of small models by transferring the dark knowledge from the teacher
detector. However, most of the existing distillation-based detection methods
mainly imitating features near bounding boxes, which suffer from two
limitations. First, they ignore the beneficial features outside the bounding
boxes. Second, these methods imitate some features which are mistakenly
regarded as the background by the teacher detector. To address the above
issues, we propose a novel Feature-Richness Score (FRS) method to choose
important features that improve generalized detectability during distilling.
The proposed method effectively retrieves the important features outside the
bounding boxes and removes the detrimental features within the bounding boxes.
Extensive experiments show that our methods achieve excellent performance on
both anchor-based and anchor-free detectors. For example, RetinaNet with
ResNet-50 achieves 39.7% in mAP on the COCO2017 dataset, which even surpasses
the ResNet-101 based teacher detector 38.9% by 0.8%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaPool: Exponential Adaptive Pooling for Information-Retaining Downsampling. (arXiv:2111.00772v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00772">
<div class="article-summary-box-inner">
<span><p>Pooling layers are essential building blocks of Convolutional Neural Networks
(CNNs) that reduce computational overhead and increase the receptive fields of
proceeding convolutional operations. They aim to produce downsampled volumes
that closely resemble the input volume while, ideally, also being
computationally and memory efficient. It is a challenge to meet both
requirements jointly. To this end, we propose an adaptive and exponentially
weighted pooling method named adaPool. Our proposed method uses a parameterized
fusion of two sets of pooling kernels that are based on the exponent of the
Dice-Sorensen coefficient and the exponential maximum, respectively. A key
property of adaPool is its bidirectional nature. In contrast to common pooling
methods, weights can be used to upsample a downsampled activation map. We term
this method adaUnPool. We demonstrate how adaPool improves the preservation of
detail through a range of tasks including image and video classification and
object detection. We then evaluate adaUnPool on image and video frame
super-resolution and frame interpolation tasks. For benchmarking, we introduce
Inter4K, a novel high-quality, high frame-rate video dataset. Our combined
experiments demonstrate that adaPool systematically achieves better results
across tasks and backbone architectures, while introducing a minor additional
computational and memory overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Livestock Monitoring with Transformer. (arXiv:2111.00801v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00801">
<div class="article-summary-box-inner">
<span><p>Tracking the behaviour of livestock enables early detection and thus
prevention of contagious diseases in modern animal farms. Apart from economic
gains, this would reduce the amount of antibiotics used in livestock farming
which otherwise enters the human diet exasperating the epidemic of antibiotic
resistance - a leading cause of death. We could use standard video cameras,
available in most modern farms, to monitor livestock. However, most computer
vision algorithms perform poorly on this task, primarily because, (i) animals
bred in farms look identical, lacking any obvious spatial signature, (ii) none
of the existing trackers are robust for long duration, and (iii) real-world
conditions such as changing illumination, frequent occlusion, varying camera
angles, and sizes of the animals make it hard for models to generalize. Given
these challenges, we develop an end-to-end behaviour monitoring system for
group-housed pigs to perform simultaneous instance level segmentation,
tracking, action recognition and re-identification (STAR) tasks. We present
starformer, the first end-to-end multiple-object livestock monitoring framework
that learns instance-level embeddings for grouped pigs through the use of
transformer architecture. For benchmarking, we present Pigtrace, a carefully
curated dataset comprising video sequences with instance level bounding box,
segmentation, tracking and activity classification of pigs in real indoor
farming environment. Using simultaneous optimization on STAR tasks we show that
starformer outperforms popular baseline models trained for individual tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smart Fashion: A Review of AI Applications in the Fashion & Apparel Industry. (arXiv:2111.00905v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00905">
<div class="article-summary-box-inner">
<span><p>The fashion industry is on the verge of an unprecedented change. The
implementation of machine learning, computer vision, and artificial
intelligence (AI) in fashion applications is opening lots of new opportunities
for this industry. This paper provides a comprehensive survey on this matter,
categorizing more than 580 related articles into 22 well-defined
fashion-related tasks. Such structured task-based multi-label classification of
fashion research articles provides researchers with explicit research
directions and facilitates their access to the related studies, improving the
visibility of studies simultaneously. For each task, a time chart is provided
to analyze the progress through the years. Furthermore, we provide a list of 86
public fashion datasets accompanied by a list of suggested applications and
additional information for each.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nested Multiple Instance Learning with Attention Mechanisms. (arXiv:2111.00947v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00947">
<div class="article-summary-box-inner">
<span><p>Multiple instance learning (MIL) is a type of weakly supervised learning
where multiple instances of data with unknown labels are sorted into bags.
Since knowledge about the individual instances is incomplete, labels are
assigned to the bags containing the instances. While this method fits diverse
applications were labelled data is scarce, it lacks depth for solving more
complex scenarios where associations between sets of instances have to be made,
like finding relevant regions of interest in an image or detecting events in a
set of time-series signals. Nested MIL considers labelled bags within bags,
where only the outermost bag is labelled and inner-bags and instances are
represented as latent labels. In addition, we propose using an attention
mechanism to add interpretability, providing awareness into the impact of each
instance to the weak bag label. Experiments in classical image datasets show
that our proposed model provides high accuracy performance as well as spotting
relevant instances on image regions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness of deep learning algorithms in astronomy -- galaxy morphology studies. (arXiv:2111.00961v2 [astro-ph.GA] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00961">
<div class="article-summary-box-inner">
<span><p>Deep learning models are being increasingly adopted in wide array of
scientific domains, especially to handle high-dimensionality and volume of the
scientific data. However, these models tend to be brittle due to their
complexity and overparametrization, especially to the inadvertent adversarial
perturbations that can appear due to common image processing such as
compression or blurring that are often seen with real scientific data. It is
crucial to understand this brittleness and develop models robust to these
adversarial perturbations. To this end, we study the effect of observational
noise from the exposure time, as well as the worst case scenario of a one-pixel
attack as a proxy for compression or telescope errors on performance of
ResNet18 trained to distinguish between galaxies of different morphologies in
LSST mock data. We also explore how domain adaptation techniques can help
improve model robustness in case of this type of naturally occurring attacks
and help scientists build more trustworthy and stable models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sign-to-Speech Model for Sign Language Understanding: A Case Study of Nigerian Sign Language. (arXiv:2111.00995v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00995">
<div class="article-summary-box-inner">
<span><p>Through this paper, we seek to reduce the communication barrier between the
hearing-impaired community and the larger society who are usually not familiar
with sign language in the sub-Saharan region of Africa with the largest
occurrences of hearing disability cases, while using Nigeria as a case study.
The dataset is a pioneer dataset for the Nigerian Sign Language and was created
in collaboration with relevant stakeholders. We pre-processed the data in
readiness for two different object detection models and a classification model
and employed diverse evaluation metrics to gauge model performance on
sign-language to text conversion tasks. Finally, we convert the predicted sign
texts to speech and deploy the best performing model in a lightweight
application that works in real-time and achieves impressive results converting
sign words/phrases to text and subsequently, into speech.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-11-03 23:02:25.345089978 UTC">2021-11-03 23:02:25 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.6</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>