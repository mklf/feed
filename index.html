<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-01-31T01:30:00Z">01-31</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Recursive Decoding: A Situated Cognition Approach to Compositional Generation in Grounded Language Understanding. (arXiv:2201.11766v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11766">
<div class="article-summary-box-inner">
<span><p>Compositional generalization is a troubling blind spot for neural language
models. Recent efforts have presented techniques for improving a model's
ability to encode novel combinations of known inputs, but less work has focused
on generating novel combinations of known outputs. Here we focus on this latter
"decode-side" form of generalization in the context of gSCAN, a synthetic
benchmark for compositional generalization in grounded language understanding.
We present Recursive Decoding (RD), a novel procedure for training and using
seq2seq models, targeted towards decode-side generalization. Rather than
generating an entire output sequence in one pass, models are trained to predict
one token at a time. Inputs (i.e., the external gSCAN environment) are then
incrementally updated based on predicted tokens, and re-encoded for the next
decoder time step. RD thus decomposes a complex, out-of-distribution sequence
generation task into a series of incremental predictions that each resemble
what the model has already seen during training. RD yields dramatic improvement
on two previously neglected generalization tasks in gSCAN. We provide analyses
to elucidate these gains over failure of a baseline, and then discuss
implications for generalization in naturalistic grounded language
understanding, and seq2seq more generally.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Going Extreme: Comparative Analysis of Hate Speech in Parler and Gab. (arXiv:2201.11770v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11770">
<div class="article-summary-box-inner">
<span><p>Social platforms such as Gab and Parler, branded as `free-speech' networks,
have seen a significant growth of their user base in recent years. This
popularity is mainly attributed to the stricter moderation enforced by
mainstream platforms such as Twitter, Facebook, and Reddit. In this work we
provide the first large scale analysis of hate-speech on Parler.
</p>
<p>We experiment with an array of algorithms for hate-speech detection,
demonstrating limitations of transfer learning in that domain, given the
illusive and ever changing nature of the ways hate-speech is delivered. In
order to improve classification accuracy we annotated 10K Parler posts, which
we use to fine-tune a BERT classifier. Classification of individual posts is
then leveraged for the classification of millions of users via label
propagation over the social network. Classifying users by their propensity to
disseminate hate, we find that hate mongers make 16.1\% of Parler active users,
and that they have distinct characteristics comparing to other user groups. We
find that hate mongers are more active, more central and express distinct
levels of sentiment and convey a distinct array of emotions like anger and
sadness. We further complement our analysis by comparing the trends discovered
in Parler and those found in Gab.
</p>
<p>To the best of our knowledge, this is among the first works to analyze hate
speech in Parler in a quantitative manner and on the user level, and the first
annotated dataset to be made available to the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Visual Transfer Learning using Knowledge Graphs. (arXiv:2201.11794v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11794">
<div class="article-summary-box-inner">
<span><p>Recent approaches of computer vision utilize deep learning methods as they
perform quite well if training and testing domains follow the same underlying
data distribution. However, it has been shown that minor variations in the
images that occur when using these methods in the real world can lead to
unpredictable errors. Transfer learning is the area of machine learning that
tries to prevent these errors. Especially, approaches that augment image data
using auxiliary knowledge encoded in language embeddings or knowledge graphs
(KGs) have achieved promising results in recent years. This survey focuses on
visual transfer learning approaches using KGs. KGs can represent auxiliary
knowledge either in an underlying graph-structured schema or in a vector-based
knowledge graph embedding. Intending to enable the reader to solve visual
transfer learning problems with the help of specific KG-DL configurations we
start with a description of relevant modeling structures of a KG of various
expressions, such as directed labeled graphs, hypergraphs, and hyper-relational
graphs. We explain the notion of feature extractor, while specifically
referring to visual and semantic features. We provide a broad overview of
knowledge graph embedding methods and describe several joint training
objectives suitable to combine them with high dimensional visual embeddings.
The main section introduces four different categories on how a KG can be
combined with a DL pipeline: 1) Knowledge Graph as a Reviewer; 2) Knowledge
Graph as a Trainee; 3) Knowledge Graph as a Trainer; and 4) Knowledge Graph as
a Peer. To help researchers find evaluation benchmarks, we provide an overview
of generic KGs and a set of image processing datasets and benchmarks including
various types of auxiliary knowledge. Last, we summarize related surveys and
give an outlook about challenges and open issues for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentiment-Aware Automatic Speech Recognition pre-training for enhanced Speech Emotion Recognition. (arXiv:2201.11826v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11826">
<div class="article-summary-box-inner">
<span><p>We propose a novel multi-task pre-training method for Speech Emotion
Recognition (SER). We pre-train SER model simultaneously on Automatic Speech
Recognition (ASR) and sentiment classification tasks to make the acoustic ASR
model more ``emotion aware''. We generate targets for the sentiment
classification using text-to-sentiment model trained on publicly available
data. Finally, we fine-tune the acoustic ASR on emotion annotated speech data.
We evaluated the proposed approach on the MSP-Podcast dataset, where we
achieved the best reported concordance correlation coefficient (CCC) of 0.41
for valence prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clinical-Longformer and Clinical-BigBird: Transformers for long clinical sequences. (arXiv:2201.11838v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11838">
<div class="article-summary-box-inner">
<span><p>Transformers-based models, such as BERT, have dramatically improved the
performance for various natural language processing tasks. The clinical
knowledge enriched model, namely ClinicalBERT, also achieved state-of-the-art
results when performed on clinical named entity recognition and natural
language inference tasks. One of the core limitations of these transformers is
the substantial memory consumption due to their full self-attention mechanism.
To overcome this, long sequence transformer models, e.g. Longformer and
BigBird, were proposed with the idea of sparse attention mechanism to reduce
the memory usage from quadratic to the sequence length to a linear scale. These
models extended the maximum input sequence length from 512 to 4096, which
enhanced the ability of modeling long-term dependency and consequently achieved
optimal results in a variety of tasks. Inspired by the success of these long
sequence transformer models, we introduce two domain enriched language models,
namely Clinical-Longformer and Clinical-BigBird, which are pre-trained from
large-scale clinical corpora. We evaluate both pre-trained models using 10
baseline tasks including named entity recognition, question answering, and
document classification tasks. The results demonstrate that Clinical-Longformer
and Clinical-BigBird consistently and significantly outperform ClinicalBERT as
well as other short-sequence transformers in all downstream tasks. We have made
the pre-trained models available for public download at:
[https://huggingface.co/yikuan8/Clinical-Longformer].
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural-FST Class Language Model for End-to-End Speech Recognition. (arXiv:2201.11867v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11867">
<div class="article-summary-box-inner">
<span><p>We propose Neural-FST Class Language Model (NFCLM) for end-to-end speech
recognition, a novel method that combines neural network language models
(NNLMs) and finite state transducers (FSTs) in a mathematically consistent
framework. Our method utilizes a background NNLM which models generic
background text together with a collection of domain-specific entities modeled
as individual FSTs. Each output token is generated by a mixture of these
components; the mixture weights are estimated with a separately trained neural
decider. We show that NFCLM significantly outperforms NNLM by 15.8% relative in
terms of Word Error Rate. NFCLM achieves similar performance as traditional
NNLM and FST shallow fusion while being less prone to overbiasing and 12 times
more compact, making it more suitable for on-device usage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiple-Source Domain Adaptation via Coordinated Domain Encoders and Paired Classifiers. (arXiv:2201.11870v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11870">
<div class="article-summary-box-inner">
<span><p>We present a novel multiple-source unsupervised model for text classification
under domain shift. Our model exploits the update rates in document
representations to dynamically integrate domain encoders. It also employs a
probabilistic heuristic to infer the error rate in the target domain in order
to pair source classifiers. Our heuristic exploits data transformation cost and
the classifier accuracy in the target feature space. We have used real world
scenarios of Domain Adaptation to evaluate the efficacy of our algorithm. We
also used pretrained multi-layer transformers as the document encoder in the
experiments to demonstrate whether the improvement achieved by domain
adaptation models can be delivered by out-of-the-box language model
pretraining. The experiments testify that our model is the top performing
approach in this setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Entity Mention Detection for Targetted Twitter Streams with Global Contextual Embeddings. (arXiv:2201.11885v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11885">
<div class="article-summary-box-inner">
<span><p>Microblogging sites, like Twitter, have emerged as ubiquitous sources of
information. Two important tasks related to the automatic extraction and
analysis of information in Microblogs are Entity Mention Detection (EMD) and
Entity Detection (ED). The state-of-the-art EMD systems aim to model the
non-literary nature of microblog text by training upon offline static datasets.
They extract a combination of surface-level features -- orthographic, lexical,
and semantic -- from individual messages for noisy text modeling and entity
extraction. But given the constantly evolving nature of microblog streams,
detecting all entity mentions from such varying yet limited context of short
messages remains a difficult problem. To this end, we propose a framework named
EMD Globalizer, better suited for the execution of EMD learners on microblog
streams. It deviates from the processing of isolated microblog messages by
existing EMD systems, where learned knowledge from the immediate context of a
message is used to suggest entities. After an initial extraction of entity
candidates by an EMD system, the proposed framework leverages occurrence mining
to find additional candidate mentions that are missed during this first
detection. Aggregating the local contextual representations of these mentions,
a global embedding is drawn from the collective context of an entity candidate
within a stream. The global embeddings are then utilized to separate entities
within the candidates from false positives. All mentions of said entities from
the stream are produced in the framework's final outputs. Our experiments show
that EMD Globalizer can enhance the effectiveness of all existing EMD systems
that we tested (on average by 25.61%) with a small additional computational
overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The CARE Dataset for Affective Response Detection. (arXiv:2201.11895v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11895">
<div class="article-summary-box-inner">
<span><p>Social media plays an increasing role in our communication with friends and
family, and our consumption of information and entertainment. Hence, to design
effective ranking functions for posts on social media, it would be useful to
predict the affective response to a post (e.g., whether the user is likely to
be humored, inspired, angered, informed). Similar to work on emotion
recognition (which focuses on the affect of the publisher of the post), the
traditional approach to recognizing affective response would involve an
expensive investment in human annotation of training data.
</p>
<p>We introduce CARE$_{db}$, a dataset of 230k social media posts annotated
according to 7 affective responses using the Common Affective Response
Expression (CARE) method. The CARE method is a means of leveraging the signal
that is present in comments that are posted in response to a post, providing
high-precision evidence about the affective response of the readers to the post
without human annotation. Unlike human annotation, the annotation process we
describe here can be iterated upon to expand the coverage of the method,
particularly for new affective responses. We present experiments that
demonstrate that the CARE annotations compare favorably with crowd-sourced
annotations. Finally, we use CARE$_{db}$ to train competitive BERT-based models
for predicting affective response as well as emotion detection, demonstrating
the utility of the dataset for related tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chain of Thought Prompting Elicits Reasoning in Large Language Models. (arXiv:2201.11903v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11903">
<div class="article-summary-box-inner">
<span><p>Although scaling up language model size has reliably improved performance on
a range of NLP tasks, even the largest models currently struggle with certain
reasoning tasks such as math word problems, symbolic manipulation, and
commonsense reasoning. This paper explores the ability of language models to
generate a coherent chain of thought -- a series of short sentences that mimic
the reasoning process a person might have when responding to a question.
Experiments show that inducing a chain of thought via prompting can enable
sufficiently large language models to better perform reasoning tasks that
otherwise have flat scaling curves.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Secure and Efficient Federated Learning Framework for NLP. (arXiv:2201.11934v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11934">
<div class="article-summary-box-inner">
<span><p>In this work, we consider the problem of designing secure and efficient
federated learning (FL) frameworks. Existing solutions either involve a trusted
aggregator or require heavyweight cryptographic primitives, which degrades
performance significantly. Moreover, many existing secure FL designs work only
under the restrictive assumption that none of the clients can be dropped out
from the training protocol. To tackle these problems, we propose SEFL, a secure
and efficient FL framework that (1) eliminates the need for the trusted
entities; (2) achieves similar and even better model accuracy compared with
existing FL designs; (3) is resilient to client dropouts. Through extensive
experimental studies on natural language processing (NLP) tasks, we demonstrate
that the SEFL achieves comparable accuracy compared to existing FL solutions,
and the proposed pruning technique can improve runtime performance up to 13.7x.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiffGAN-TTS: High-Fidelity and Efficient Text-to-Speech with Denoising Diffusion GANs. (arXiv:2201.11972v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11972">
<div class="article-summary-box-inner">
<span><p>Denoising diffusion probabilistic models (DDPMs) are expressive generative
models that have been used to solve a variety of speech synthesis problems.
However, because of their high sampling costs, DDPMs are difficult to use in
real-time speech processing applications. In this paper, we introduce
DiffGAN-TTS, a novel DDPM-based text-to-speech (TTS) model achieving
high-fidelity and efficient speech synthesis. DiffGAN-TTS is based on denoising
diffusion generative adversarial networks (GANs), which adopt an
adversarially-trained expressive model to approximate the denoising
distribution. We show with multi-speaker TTS experiments that DiffGAN-TTS can
generate high-fidelity speech samples within only 4 denoising steps. We present
an active shallow diffusion mechanism to further speed up inference. A
two-stage training scheme is proposed, with a basic TTS acoustic model trained
at stage one providing valuable prior information for a DDPM trained at stage
two. Our experiments show that DiffGAN-TTS can achieve high synthesis
performance with only 1 denoising step.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model. (arXiv:2201.11990v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11990">
<div class="article-summary-box-inner">
<span><p>Pretrained general-purpose language models can achieve state-of-the-art
accuracies in various natural language processing domains by adapting to
downstream tasks via zero-shot, few-shot and fine-tuning techniques. Because of
their success, the size of these models has increased rapidly, requiring
high-performance hardware, software, and algorithmic techniques to enable
training such large models. As the result of a joint effort between Microsoft
and NVIDIA, we present details on the training of the largest monolithic
transformer based language model, Megatron-Turing NLG 530B (MT-NLG), with 530
billion parameters. In this paper, we first focus on the infrastructure as well
as the 3D parallelism methodology used to train this model using DeepSpeed and
Megatron. Next, we detail the training process, the design of our training
corpus, and our data curation techniques, which we believe is a key ingredient
to the success of the model. Finally, we discuss various evaluation results, as
well as other interesting observations and new properties exhibited by MT-NLG.
We demonstrate that MT-NLG achieves superior zero-, one-, and few-shot learning
accuracies on several NLP benchmarks and establishes new state-of-the-art
results. We believe that our contributions will help further the development of
large-scale training infrastructures, large-scale language models, and natural
language generations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linear Adversarial Concept Erasure. (arXiv:2201.12091v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12091">
<div class="article-summary-box-inner">
<span><p>Modern neural models trained on textual data rely on pre-trained
representations that emerge without direct supervision. As these
representations are increasingly being used in real-world applications, the
inability to \emph{control} their content becomes an increasingly important
problem.
</p>
<p>We formulate the problem of identifying and erasing a linear subspace that
corresponds to a given concept, in order to prevent linear predictors from
recovering the concept. We model this problem as a constrained, linear minimax
game, and show that existing solutions are generally not optimal for this task.
We derive a closed-form solution for certain objectives, and propose a convex
relaxation, R-LACE, that works well for others. When evaluated in the context
of binary gender removal, the method recovers a low-dimensional subspace whose
removal mitigates bias by intrinsic and extrinsic evaluation. We show that the
method -- despite being linear -- is highly expressive, effectively mitigating
bias in deep nonlinear classifiers while maintaining tractability and
interpretability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PCL: Peer-Contrastive Learning with Diverse Augmentations for Unsupervised Sentence Embeddings. (arXiv:2201.12093v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12093">
<div class="article-summary-box-inner">
<span><p>Learning sentence embeddings in an unsupervised manner is fundamental in
natural language processing. Recent common practice is to couple pre-trained
language models with unsupervised contrastive learning, whose success relies on
augmenting a sentence with a semantically-close positive instance to construct
contrastive pairs. Nonetheless, existing approaches usually depend on a
mono-augmenting strategy, which causes learning shortcuts towards the
augmenting biases and thus corrupts the quality of sentence embeddings. A
straightforward solution is resorting to more diverse positives from a
multi-augmenting strategy, while an open question remains about how to
unsupervisedly learn from the diverse positives but with uneven augmenting
qualities in the text field. As one answer, we propose a novel Peer-Contrastive
Learning (PCL) with diverse augmentations. PCL constructs diverse contrastive
positives and negatives at the group level for unsupervised sentence
embeddings. PCL can perform peer-positive contrast as well as peer-network
cooperation, which offers an inherent anti-bias ability and an effective way to
learn from diverse augmentations. Experiments on STS benchmarks verify the
effectiveness of our PCL against its competitors in unsupervised sentence
embeddings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving End-to-End Models for Set Prediction in Spoken Language Understanding. (arXiv:2201.12105v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12105">
<div class="article-summary-box-inner">
<span><p>The goal of spoken language understanding (SLU) systems is to determine the
meaning of the input speech signal, unlike speech recognition which aims to
produce verbatim transcripts. Advances in end-to-end (E2E) speech modeling have
made it possible to train solely on semantic entities, which are far cheaper to
collect than verbatim transcripts. We focus on this set prediction problem,
where entity order is unspecified. Using two classes of E2E models, RNN
transducers and attention based encoder-decoders, we show that these models
work best when the training entity sequence is arranged in spoken order. To
improve E2E SLU models when entity spoken order is unknown, we propose a novel
data augmentation technique along with an implicit attention based alignment
method to infer the spoken order. F1 scores significantly increased by more
than 11% for RNN-T and about 2% for attention based encoder-decoder SLU models,
outperforming previously reported results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Protum: A New Method For Prompt Tuning Based on "[MASK]". (arXiv:2201.12109v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12109">
<div class="article-summary-box-inner">
<span><p>Recently, prompt tuning \cite{lester2021power} has gradually become a new
paradigm for NLP, which only depends on the representation of the words by
freezing the parameters of pre-trained language models (PLMs) to obtain
remarkable performance on downstream tasks. It maintains the consistency of
Masked Language Model (MLM) \cite{devlin2018bert} task in the process of
pre-training, and avoids some issues that may happened during fine-tuning.
Naturally, we consider that the "[MASK]" tokens carry more useful information
than other tokens because the model combines with context to predict the masked
tokens. Among the current prompt tuning methods, there will be a serious
problem of random composition of the answer tokens in prediction when they
predict multiple words so that they have to map tokens to labels with the help
verbalizer. In response to the above issue, we propose a new \textbf{Pro}mpt
\textbf{Tu}ning based on "[\textbf{M}ASK]" (\textbf{Protum}) method in this
paper, which constructs a classification task through the information carried
by the hidden layer of "[MASK]" tokens and then predicts the labels directly
rather than the answer tokens. At the same time, we explore how different
hidden layers under "[MASK]" impact on our classification model on many
different data sets. Finally, we find that our \textbf{Protum} can achieve much
better performance than fine-tuning after continuous pre-training with less
time consumption. Our model facilitates the practical application of large
models in NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Attention-Model Explainability through Faithfulness Violation Test. (arXiv:2201.12114v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12114">
<div class="article-summary-box-inner">
<span><p>Attention mechanisms are dominating the explainability of deep models. They
produce probability distributions over the input, which are widely deemed as
feature-importance indicators. However, in this paper, we find one critical
limitation in attention explanations: weakness in identifying the polarity of
feature impact. This would be somehow misleading -- features with higher
attention weights may not faithfully contribute to model predictions; instead,
they can impose suppression effects. With this finding, we reflect on the
explainability of current attention-based techniques, such as
Attentio$\odot$Gradient and LRP-based attention explanations. We first propose
an actionable diagnostic methodology (henceforth faithfulness violation test)
to measure the consistency between explanation weights and the impact polarity.
Through the extensive experiments, we then show that most tested explanation
methods are unexpectedly hindered by the faithfulness violation issue,
especially the raw attention. Empirical analyses on the factors affecting
violation issues further provide useful observations for adopting explanation
methods in attention models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Wikipedia Help Offline Reinforcement Learning?. (arXiv:2201.12122v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12122">
<div class="article-summary-box-inner">
<span><p>Fine-tuning reinforcement learning (RL) models has been challenging because
of a lack of large scale off-the-shelf datasets as well as high variance in
transferability among different environments. Recent work has looked at
tackling offline RL from the perspective of sequence modeling with improved
results as result of the introduction of the Transformer architecture. However,
when the model is trained from scratch, it suffers from slow convergence
speeds. In this paper, we look to take advantage of this formulation of
reinforcement learning as sequence modeling and investigate the transferability
of pre-trained sequence models on other domains (vision, language) when
finetuned on offline RL tasks (control, games). To this end, we also propose
techniques to improve transfer between these domains. Results show consistent
performance gains in terms of both convergence speed and reward on a variety of
environments, accelerating training by 3-6x and achieving state-of-the-art
performance in a variety of tasks using Wikipedia-pretrained and GPT2 language
models. We hope that this work not only brings light to the potentials of
leveraging generic sequence modeling techniques and pre-trained models for RL,
but also inspires future work on sharing knowledge between generative modeling
tasks of completely different domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing language context confusion for end-to-end code-switching automatic speech recognition. (arXiv:2201.12155v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12155">
<div class="article-summary-box-inner">
<span><p>Code-switching is about dealing with alternative languages in the
communication process. Training end-to-end (E2E) automatic speech recognition
(ASR) systems for code-switching is known to be a challenging problem because
of the lack of data compounded by the increased language context confusion due
to the presence of more than one language. In this paper, we propose a
language-related attention mechanism to reduce multilingual context confusion
for the E2E code-switching ASR model based on the Equivalence Constraint Theory
(EC). The linguistic theory requires that any monolingual fragment that occurs
in the code-switching sentence must occur in one of the monolingual sentences.
It establishes a bridge between monolingual data and code-switching data. By
calculating the respective attention of multiple languages, our method can
efficiently transfer language knowledge from rich monolingual data. We evaluate
our method on ASRU 2019 Mandarin-English code-switching challenge dataset.
Compared with the baseline model, the proposed method achieves 11.37% relative
mix error rate reduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Concept Erasure in Kernel Space. (arXiv:2201.12191v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12191">
<div class="article-summary-box-inner">
<span><p>The representation space of neural models for textual data emerges in an
unsupervised manner during training. Understanding how human-interpretable
concepts, such as gender, are encoded in these representations would improve
the ability of users to \emph{control} the content of these representations and
analyze the working of the models that rely on them. One prominent approach to
the control problem is the identification and removal of linear concept
subspaces -- subspaces in the representation space that correspond to a given
concept. While those are tractable and interpretable, neural network do not
necessarily represent concepts in linear subspaces.
</p>
<p>We propose a kernalization of the linear concept-removal objective of
[Ravfogel et al. 2022], and show that it is effective in guarding against the
ability of certain nonlinear adversaries to recover the concept. Interestingly,
our findings suggest that the division between linear and nonlinear models is
overly simplistic: when considering the concept of binary gender and its
neutralization, we do not find a single kernel space that exclusively contains
all the concept-related information. It is therefore challenging to protect
against \emph{all} nonlinear adversaries at once.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Broad Coverage Named Entity Resource: A Data-Efficient Approach for Many Diverse Languages. (arXiv:2201.12219v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12219">
<div class="article-summary-box-inner">
<span><p>Parallel corpora are ideal for extracting a multilingual named entity (MNE)
resource, i.e., a dataset of names translated into multiple languages. Prior
work on extracting MNE datasets from parallel corpora required resources such
as large monolingual corpora or word aligners that are unavailable or perform
poorly for underresourced languages. We present CLC-BN, a new method for
creating an MNE resource, and apply it to the Parallel Bible Corpus, a corpus
of more than 1000 languages. CLC-BN learns a neural transliteration model from
parallel-corpus statistics, without requiring any other bilingual resources,
word aligners, or seed data. Experimental results show that CLC-BN clearly
outperforms prior work. We release an MNE resource for 1340 languages and
demonstrate its effectiveness in two downstream tasks: knowledge graph
augmentation and bilingual lexicon induction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Cooperative Networks for Natural Language Generation. (arXiv:2201.12320v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12320">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GANs) have known a tremendous success for
many continuous generation tasks, especially in the field of image generation.
However, for discrete outputs such as language, optimizing GANs remains an open
problem with many instabilities, as no gradient can be properly back-propagated
from the discriminator output to the generator parameters. An alternative is to
learn the generator network via reinforcement learning, using the discriminator
signal as a reward, but such a technique suffers from moving rewards and
vanishing gradient problems. Finally, it often falls short compared to direct
maximum-likelihood approaches. In this paper, we introduce Generative
Cooperative Networks, in which the discriminator architecture is cooperatively
used along with the generation policy to output samples of realistic texts for
the task at hand. We give theoretical guarantees of convergence for our
approach, and study various efficient decoding schemes to empirically achieve
state-of-the-art results in two main NLG tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summarizing Differences between Text Distributions with Natural Language. (arXiv:2201.12323v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12323">
<div class="article-summary-box-inner">
<span><p>How do two distributions of texts differ? Humans are slow at answering this,
since discovering patterns might require tediously reading through hundreds of
samples. We propose to automatically summarize the differences by "learning a
natural language hypothesis": given two distributions $D_{0}$ and $D_{1}$, we
search for a description that is more often true for $D_{1}$, e.g., "is
military-related." To tackle this problem, we fine-tune GPT-3 to propose
descriptions with the prompt: "[samples of $D_{0}$] + [samples of $D_{1}$] +
the difference between them is _____". We then re-rank the descriptions by
checking how often they hold on a larger set of samples with a learned
verifier. On a benchmark of 54 real-world binary classification tasks, while
GPT-3 Curie (13B) only generates a description similar to human annotation 7%
of the time, the performance reaches 61% with fine-tuning and re-ranking, and
our best system using GPT-3 Davinci (175B) reaches 76%. We apply our system to
describe distribution shifts, debug dataset shortcuts, summarize unknown tasks,
and label text clusters, and present analyses based on automatically generated
descriptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Look It Up: Bilingual Dictionaries Improve Neural Machine Translation. (arXiv:2010.05997v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05997">
<div class="article-summary-box-inner">
<span><p>Despite advances in neural machine translation (NMT) quality, rare words
continue to be problematic. For humans, the solution to the rare-word problem
has long been dictionaries, but dictionaries cannot be straightforwardly
incorporated into NMT. In this paper, we describe a new method for "attaching"
dictionary definitions to rare words so that the network can learn the best way
to use them. We demonstrate improvements of up to 1.8 BLEU using bilingual
dictionaries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CNN Encoding of Acoustic Parameters for Prominence Detection. (arXiv:2104.05488v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05488">
<div class="article-summary-box-inner">
<span><p>Expressive reading, considered the defining attribute of oral reading
fluency, comprises the prosodic realization of phrasing and prominence. In the
context of evaluating oral reading, it helps to establish the speaker's
comprehension of the text. We consider a labeled dataset of children's reading
recordings for the speaker-independent detection of prominent words using
acoustic-prosodic and lexico-syntactic features. A previous well-tuned random
forest ensemble predictor is replaced by an RNN sequence classifier to exploit
potential context dependency across the longer utterance. Further, deep
learning is applied to obtain word-level features from low-level acoustic
contours of fundamental frequency, intensity and spectral shape in an
end-to-end fashion. Performance comparisons are presented across the different
feature types and across different feature learning architectures for prominent
word prediction to draw insights wherever possible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CEAR: Cross-Entity Aware Reranker for Knowledge Base Completion. (arXiv:2104.08741v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08741">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (LMs) like BERT have shown to store factual
knowledge about the world. This knowledge can be used to augment the
information present in Knowledge Bases, which tend to be incomplete. However,
prior attempts at using BERT for task of Knowledge Base Completion (KBC)
resulted in performance worse than embedding based techniques that rely only on
the graph structure. In this work we develop a novel model, Cross-Entity Aware
Reranker (CEAR), that uses BERT to re-rank the output of existing KBC models
with cross-entity attention. Unlike prior work that scores each entity
independently, CEAR uses BERT to score the entities together, which is
effective for exploiting its factual knowledge. CEAR achieves a new state of
art for the OLPBench dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incorporating Word Sense Disambiguation in Neural Language Models. (arXiv:2106.07967v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07967">
<div class="article-summary-box-inner">
<span><p>We present two supervised (pre-)training methods to incorporate gloss
definitions from lexical resources into neural language models (LMs). The
training improves our models' performance for Word Sense Disambiguation (WSD)
but also benefits general language understanding tasks while adding almost no
parameters. We evaluate our techniques with seven different neural LMs and find
that XLNet is more suitable for WSD than BERT. Our best-performing methods
exceeds state-of-the-art WSD techniques on the SemCor 3.0 dataset by 0.5% F1
and increase BERT's performance on the GLUE benchmark by 1.1% on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-conditioning pre-trained language models. (arXiv:2110.02802v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02802">
<div class="article-summary-box-inner">
<span><p>In this paper we aim to investigate the mechanisms that guide text generation
with pre-trained Transformer-based Language Models (TLMs). Grounded on the
Product of Experts formulation by Hinton (1999), we describe a generative
mechanism that exploits expert units which naturally exist in TLMs. Such units
are responsible for detecting concepts in the input and conditioning text
generation on such concepts. We describe how to identify expert units and how
to activate them during inference in order to induce any desired concept in the
generated output. We find that the activation of a surprisingly small amount of
units is sufficient to steer text generation (as little as 3 units in a model
with 345M parameters). While the objective of this work is to learn more about
how TLMs work, we show that our method is effective for conditioning without
fine-tuning or using extra parameters, even on fine-grained homograph concepts.
Additionally, we show that our method can be used to correct gender bias
present in the output of TLMs and achieves gender parity for all evaluated
contexts. We compare our method with FUDGE and PPLM-BoW, and show that our
approach is able to achieve gender parity at a lower perplexity. The proposed
method is accessible to a wide audience thanks to its simplicity and minimal
compute needs. The findings in this paper are a step forward in understanding
the generative mechanisms of TLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NATURE: Natural Auxiliary Text Utterances for Realistic Spoken Language Evaluation. (arXiv:2111.05196v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.05196">
<div class="article-summary-box-inner">
<span><p>Slot-filling and intent detection are the backbone of conversational agents
such as voice assistants, and are active areas of research. Even though
state-of-the-art techniques on publicly available benchmarks show impressive
performance, their ability to generalize to realistic scenarios is yet to be
demonstrated. In this work, we present NATURE, a set of simple spoken-language
oriented transformations, applied to the evaluation set of datasets, to
introduce human spoken language variations while preserving the semantics of an
utterance. We apply NATURE to common slot-filling and intent detection
benchmarks and demonstrate that simple perturbations from the standard
evaluation set by NATURE can deteriorate model performance significantly.
Through our experiments we demonstrate that when NATURE operators are applied
to evaluation set of popular benchmarks the model accuracy can drop by up to
40%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis. (arXiv:2201.08277v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08277">
<div class="article-summary-box-inner">
<span><p>Sentiment analysis is one of the most widely studied applications in NLP, but
most work focuses on languages with large amounts of data. We introduce the
first large-scale human-annotated Twitter sentiment dataset for the four most
widely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and
Yor\`ub\'a ) consisting of around 30,000 annotated tweets per language (and
14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed
tweets. We propose text collection, filtering, processing and labeling methods
that enable us to create datasets for these low-resource languages. We evaluate
a rangeof pre-trained models and transfer strategies on the dataset. We find
that language-specific models and language-adaptivefine-tuning generally
perform best. We release the datasets, trained models, sentiment lexicons, and
code to incentivizeresearch on sentiment analysis in under-represented
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence. (arXiv:2201.11176v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11176">
<div class="article-summary-box-inner">
<span><p>Recently, there has been a growing interest in designing text generation
systems from a discourse coherence perspective, e.g., modeling the
interdependence between sentences. Still, recent BERT-based evaluation metrics
cannot recognize coherence and fail to punish incoherent elements in system
outputs. In this work, we introduce DiscoScore, a parametrized discourse
metric, which uses BERT to model discourse coherence from different
perspectives, driven by Centering theory. Our experiments encompass 16
non-discourse and discourse metrics, including DiscoScore and popular coherence
models, evaluated on summarization and document-level machine translation (MT).
We find that (i) the majority of BERT-based metrics correlate much worse with
human rated coherence than early discourse metrics, invented a decade ago; (ii)
the recent state-of-the-art BARTScore is weak when operated at system level --
which is particularly problematic as systems are typically compared in this
manner. DiscoScore, in contrast, achieves strong system-level correlation with
human ratings, not only in coherence but also in factual consistency and other
aspects, and surpasses BARTScore by over 10 correlation points on average.
Further, aiming to understand DiscoScore, we provide justifications to the
importance of discourse coherence for evaluation metrics, and explain the
superiority of one variant over another. Our code is available at
\url{https://github.com/AIPHES/DiscoScore}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discovering Phonetic Inventories with Crosslingual Automatic Speech Recognition. (arXiv:2201.11207v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11207">
<div class="article-summary-box-inner">
<span><p>The high cost of data acquisition makes Automatic Speech Recognition (ASR)
model training problematic for most existing languages, including languages
that do not even have a written script, or for which the phone inventories
remain unknown. Past works explored multilingual training, transfer learning,
as well as zero-shot learning in order to build ASR systems for these
low-resource languages. While it has been shown that the pooling of resources
from multiple languages is helpful, we have not yet seen a successful
application of an ASR model to a language unseen during training. A crucial
step in the adaptation of ASR from seen to unseen languages is the creation of
the phone inventory of the unseen language. The ultimate goal of our work is to
build the phone inventory of a language unseen during training in an
unsupervised way without any knowledge about the language. In this paper, we 1)
investigate the influence of different factors (i.e., model architecture,
phonotactic model, type of speech representation) on phone recognition in an
unknown language; 2) provide an analysis of which phones transfer well across
languages and which do not in order to understand the limitations of and areas
for further improvement for automatic phone inventory creation; and 3) present
different methods to build a phone inventory of an unseen language in an
unsupervised way. To that end, we conducted mono-, multi-, and crosslingual
experiments on a set of 13 phonetically diverse languages and several in-depth
analyses. We found a number of universal phone tokens (IPA symbols) that are
well-recognized cross-linguistically. Through a detailed analysis of results,
we conclude that unique sounds, similar sounds, and tone languages remain a
major challenge for phonetic inventory discovery.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Denoising of Retinal OCT with Diffusion Probabilistic Model. (arXiv:2201.11760v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11760">
<div class="article-summary-box-inner">
<span><p>Optical coherence tomography (OCT) is a prevalent non-invasive imaging method
which provides high resolution volumetric visualization of retina. However, its
inherent defect, the speckle noise, can seriously deteriorate the tissue
visibility in OCT. Deep learning based approaches have been widely used for
image restoration, but most of these require a noise-free reference image for
supervision. In this study, we present a diffusion probabilistic model that is
fully unsupervised to learn from noise instead of signal. A diffusion process
is defined by adding a sequence of Gaussian noise to self-fused OCT b-scans.
Then the reverse process of diffusion, modeled by a Markov chain, provides an
adjustable level of denoising. Our experiment results demonstrate that our
method can significantly improve the image quality with a simple working
pipeline and a small amount of training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Analysis of Recurrent Learning Algorithms In Neural Lossy Image Compression Systems. (arXiv:2201.11782v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11782">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning have resulted in image compression
algorithms that outperform JPEG and JPEG 2000 on the standard Kodak benchmark.
However, they are slow to train (due to backprop-through-time) and, to the best
of our knowledge, have not been systematically evaluated on a large variety of
datasets. In this paper, we perform the first large-scale comparison of recent
state-of-the-art hybrid neural compression algorithms, while exploring the
effects of alternative training strategies (when applicable). The hybrid
recurrent neural decoder is a former state-of-the-art model (recently overtaken
by a Google model) that can be trained using backprop-through-time (BPTT) or
with alternative algorithms like sparse attentive backtracking (SAB), unbiased
online recurrent optimization (UORO), and real-time recurrent learning (RTRL).
We compare these training alternatives along with the Google models (GOOG and
E2E) on 6 benchmark datasets. Surprisingly, we found that the model trained
with SAB performs better (outperforming even BPTT), resulting in faster
convergence and a better peak signal-to-noise ratio.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Denoising Diffusion Restoration Models. (arXiv:2201.11793v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11793">
<div class="article-summary-box-inner">
<span><p>Many interesting tasks in image restoration can be cast as linear inverse
problems. A recent family of approaches for solving these problems uses
stochastic algorithms that sample from the posterior distribution of natural
images given the measurements. However, efficient solutions often require
problem-specific supervised training to model the posterior, whereas
unsupervised methods that are not problem-specific typically rely on
inefficient iterative methods. This work addresses these issues by introducing
Denoising Diffusion Restoration Models (DDRM), an efficient, unsupervised
posterior sampling method. Motivated by variational inference, DDRM takes
advantage of a pre-trained denoising diffusion generative model for solving any
linear inverse problem. We demonstrate DDRM's versatility on several image
datasets for super-resolution, deblurring, inpainting, and colorization under
various amounts of measurement noise. DDRM outperforms the current leading
unsupervised methods on the diverse ImageNet dataset in reconstruction quality,
perceptual quality, and runtime, being 5x faster than the nearest competitor.
DDRM also generalizes well for natural images out of the distribution of the
observed ImageNet training set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Visual Transfer Learning using Knowledge Graphs. (arXiv:2201.11794v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11794">
<div class="article-summary-box-inner">
<span><p>Recent approaches of computer vision utilize deep learning methods as they
perform quite well if training and testing domains follow the same underlying
data distribution. However, it has been shown that minor variations in the
images that occur when using these methods in the real world can lead to
unpredictable errors. Transfer learning is the area of machine learning that
tries to prevent these errors. Especially, approaches that augment image data
using auxiliary knowledge encoded in language embeddings or knowledge graphs
(KGs) have achieved promising results in recent years. This survey focuses on
visual transfer learning approaches using KGs. KGs can represent auxiliary
knowledge either in an underlying graph-structured schema or in a vector-based
knowledge graph embedding. Intending to enable the reader to solve visual
transfer learning problems with the help of specific KG-DL configurations we
start with a description of relevant modeling structures of a KG of various
expressions, such as directed labeled graphs, hypergraphs, and hyper-relational
graphs. We explain the notion of feature extractor, while specifically
referring to visual and semantic features. We provide a broad overview of
knowledge graph embedding methods and describe several joint training
objectives suitable to combine them with high dimensional visual embeddings.
The main section introduces four different categories on how a KG can be
combined with a DL pipeline: 1) Knowledge Graph as a Reviewer; 2) Knowledge
Graph as a Trainee; 3) Knowledge Graph as a Trainer; and 4) Knowledge Graph as
a Peer. To help researchers find evaluation benchmarks, we provide an overview
of generic KGs and a set of image processing datasets and benchmarks including
various types of auxiliary knowledge. Last, we summarize related surveys and
give an outlook about challenges and open issues for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural JPEG: End-to-End Image Compression Leveraging a Standard JPEG Encoder-Decoder. (arXiv:2201.11795v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11795">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning have led to superhuman performance across a
variety of applications. Recently, these methods have been successfully
employed to improve the rate-distortion performance in the task of image
compression. However, current methods either use additional post-processing
blocks on the decoder end to improve compression or propose an end-to-end
compression scheme based on heuristics. For the majority of these, the trained
deep neural networks (DNNs) are not compatible with standard encoders and would
be difficult to deply on personal computers and cellphones. In light of this,
we propose a system that learns to improve the encoding performance by
enhancing its internal neural representations on both the encoder and decoder
ends, an approach we call Neural JPEG. We propose frequency domain pre-editing
and post-editing methods to optimize the distribution of the DCT coefficients
at both encoder and decoder ends in order to improve the standard compression
(JPEG) method. Moreover, we design and integrate a scheme for jointly learning
quantization tables within this hybrid neural compression framework.Experiments
demonstrate that our approach successfully improves the rate-distortion
performance over JPEG across various quality metrics, such as PSNR and MS-SSIM,
and generates visually appealing images with better color retention quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LAP: An Attention-Based Module for Faithful Interpretation and Knowledge Injection in Convolutional Neural Networks. (arXiv:2201.11808v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11808">
<div class="article-summary-box-inner">
<span><p>Despite the state-of-the-art performance of deep convolutional neural
networks, they are susceptible to bias and malfunction in unseen situations.
The complex computation behind their reasoning is not sufficiently
human-understandable to develop trust. External explainer methods have tried to
interpret the network decisions in a human-understandable way, but they are
accused of fallacies due to their assumptions and simplifications. On the other
side, the inherent self-interpretability of models, while being more robust to
the mentioned fallacies, cannot be applied to the already trained models. In
this work, we propose a new attention-based pooling layer, called Local
Attention Pooling (LAP), that accomplishes self-interpretability and the
possibility for knowledge injection while improving the model's performance.
Moreover, several weakly-supervised knowledge injection methodologies are
provided to enhance the process of training. We verified our claims by
evaluating several LAP-extended models on three different datasets, including
Imagenet. The proposed framework offers more valid human-understandable and
more faithful-to-the-model interpretations than the commonly used white-box
explainer methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles. (arXiv:2201.11812v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11812">
<div class="article-summary-box-inner">
<span><p>Modern vehicles, including autonomous vehicles and connected vehicles, are
increasingly connected to the external world, which enables various
functionalities and services. However, the improving connectivity also
increases the attack surfaces of the Internet of Vehicles (IoV), causing its
vulnerabilities to cyber-threats. Due to the lack of authentication and
encryption procedures in vehicular networks, Intrusion Detection Systems (IDSs)
are essential approaches to protect modern vehicle systems from network
attacks. In this paper, a transfer learning and ensemble learning-based IDS is
proposed for IoV systems using convolutional neural networks (CNNs) and
hyper-parameter optimization techniques. In the experiments, the proposed IDS
has demonstrated over 99.25% detection rates and F1-scores on two well-known
public benchmark IoV security datasets: the Car-Hacking dataset and the
CICIDS2017 dataset. This shows the effectiveness of the proposed IDS for
cyber-attack detection in both intra-vehicle and external vehicular networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pressure Eye: In-bed Contact Pressure Estimation via Contact-less Imaging. (arXiv:2201.11828v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11828">
<div class="article-summary-box-inner">
<span><p>Computer vision has achieved great success in interpreting semantic meanings
from images, yet estimating underlying (non-visual) physical properties of an
object is often limited to their bulk values rather than reconstructing a dense
map. In this work, we present our pressure eye (PEye) approach to estimate
contact pressure between a human body and the surface she is lying on with high
resolution from vision signals directly. PEye approach could ultimately enable
the prediction and early detection of pressure ulcers in bed-bound patients,
that currently depends on the use of expensive pressure mats. Our PEye network
is configured in a dual encoding shared decoding form to fuse visual cues and
some relevant physical parameters in order to reconstruct high resolution
pressure maps (PMs). We also present a pixel-wise resampling approach based on
Naive Bayes assumption to further enhance the PM regression performance. A
percentage of correct sensing (PCS) tailored for sensing estimation accuracy
evaluation is also proposed which provides another perspective for performance
evaluation under varying error tolerances. We tested our approach via a series
of extensive experiments using multimodal sensing technologies to collect data
from 102 subjects while lying on a bed. The individual's high resolution
contact pressure data could be estimated from their RGB or long wavelength
infrared (LWIR) images with 91.8% and 91.2% estimation accuracies in
$PCS_{efs0.1}$ criteria, superior to state-of-the-art methods in the related
image regression/translation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discriminative Supervised Subspace Learning for Cross-modal Retrieval. (arXiv:2201.11843v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11843">
<div class="article-summary-box-inner">
<span><p>Nowadays the measure between heterogeneous data is still an open problem for
cross-modal retrieval. The core of cross-modal retrieval is how to measure the
similarity between different types of data. Many approaches have been developed
to solve the problem. As one of the mainstream, approaches based on subspace
learning pay attention to learning a common subspace where the similarity among
multi-modal data can be measured directly. However, many of the existing
approaches only focus on learning a latent subspace. They ignore the full use
of discriminative information so that the semantically structural information
is not well preserved. Therefore satisfactory results can not be achieved as
expected. We in this paper propose a discriminative supervised subspace
learning for cross-modal retrieval(DS2L), to make full use of discriminative
information and better preserve the semantically structural information.
Specifically, we first construct a shared semantic graph to preserve the
semantic structure within each modality. Subsequently, the Hilbert-Schmidt
Independence Criterion(HSIC) is introduced to preserve the consistence between
feature-similarity and semantic-similarity of samples. Thirdly, we introduce a
similarity preservation term, thus our model can compensate for the
shortcomings of insufficient use of discriminative data and better preserve the
semantically structural information within each modality. The experimental
results obtained on three well-known benchmark datasets demonstrate the
effectiveness and competitiveness of the proposed method against the compared
classic subspace learning approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speckle-based optical cryptosystem and its application for human face recognition via deep learning. (arXiv:2201.11844v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11844">
<div class="article-summary-box-inner">
<span><p>Face recognition has recently become ubiquitous in many scenes for
authentication or security purposes. Meanwhile, there are increasing concerns
about the privacy of face images, which are sensitive biometric data that
should be carefully protected. Software-based cryptosystems are widely adopted
nowadays to encrypt face images, but the security level is limited by
insufficient digital secret key length or computing power. Hardware-based
optical cryptosystems can generate enormously longer secret keys and enable
encryption at light speed, but most reported optical methods, such as double
random phase encryption, are less compatible with other systems due to system
complexity. In this study, a plain yet high-efficient speckle-based optical
cryptosystem is proposed and implemented. A scattering ground glass is
exploited to generate physical secret keys of gigabit length and encrypt face
images via seemingly random optical speckles at light speed. Face images can
then be decrypted from the random speckles by a well-trained decryption neural
network, such that face recognition can be realized with up to 98% accuracy.
The proposed cryptosystem has wide applicability, and it may open a new avenue
for high-security complex information encryption and decryption by utilizing
optical speckles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards an Automatic Diagnosis of Peripheral and Central Palsy Using Machine Learning on Facial Features. (arXiv:2201.11852v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11852">
<div class="article-summary-box-inner">
<span><p>Central palsy is a form of facial paralysis that requires urgent medical
attention and has to be differentiated from other, similar conditions such as
peripheral palsy. To aid in fast and accurate diagnosis of this condition, we
propose a machine learning approach to automatically classify peripheral and
central facial palsy. The Palda dataset is used, which contains 103 peripheral
palsy images, 40 central palsy, and 60 healthy people. Experiments are run on
five machine learning algorithms. The best performing algorithms were found to
be the SVM (total accuracy of 85.1%) and the Gaussian naive Bayes (80.7%). The
lowest false negative rate on central palsy was achieved by the naive Bayes
approach (80% compared to 70%). This condition could prove to be the most
severe, and thus its sensitivity is another good way to compare algorithms. By
extrapolation, a dataset size of 334 total pictures is estimated to achieve a
central palsy sensitivity of 95%. All code used for these machine learning
experiments is freely available online at https://github.com/cvvletter/palsy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Shape Metrics to Describe 2D Data Points. (arXiv:2201.11857v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11857">
<div class="article-summary-box-inner">
<span><p>Traditional machine learning (ML) algorithms, such as multiple regression,
require human analysts to make decisions on how to treat the data. These
decisions can make the model building process subjective and difficult to
replicate for those who did not build the model. Deep learning approaches
benefit by allowing the model to learn what features are important once the
human analyst builds the architecture. Thus, a method for automating certain
human decisions for traditional ML modeling would help to improve the
reproducibility and remove subjective aspects of the model building process. To
that end, we propose to use shape metrics to describe 2D data to help make
analyses more explainable and interpretable. The proposed approach provides a
foundation to help automate various aspects of model building in an
interpretable and explainable fashion. This is particularly important in
applications in the medical community where the `right to explainability' is
crucial. We provide various simulated data sets ranging from probability
distributions, functions, and model quality control checks (such as QQ-Plots
and residual analyses from ordinary least squares) to showcase the breadth of
this approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of White Blood Cell Leukemia with Low Number of Interpretable and Explainable Features. (arXiv:2201.11864v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11864">
<div class="article-summary-box-inner">
<span><p>White Blood Cell (WBC) Leukaemia is detected through image-based
classification. Convolutional Neural Networks are used to learn the features
needed to classify images of cells a malignant or healthy. However, this type
of model requires learning a large number of parameters and is difficult to
interpret and explain. Explainable AI (XAI) attempts to alleviate this issue by
providing insights to how models make decisions. Therefore, we present an XAI
model which uses only 24 explainable and interpretable features and is highly
competitive to other approaches by outperforming them by about 4.38\%. Further,
our approach provides insight into which variables are the most important for
the classification of the cells. This insight provides evidence that when labs
treat the WBCs differently, the importance of various metrics changes
substantially. Understanding the important features for classification is vital
in medical imaging diagnosis and, by extension, understanding the AI models
built in scientific pursuits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrating Histopathology Image Classifiers using Label Smoothing. (arXiv:2201.11866v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11866">
<div class="article-summary-box-inner">
<span><p>The classification of histopathology images fundamentally differs from
traditional image classification tasks because histopathology images naturally
exhibit a range of diagnostic features, resulting in a diverse range of
annotator agreement levels. However, examples with high annotator disagreement
are often either assigned the majority label or discarded entirely when
training histopathology image classifiers. This widespread practice often
yields classifiers that do not account for example difficulty and exhibit poor
model calibration. In this paper, we ask: can we improve model calibration by
endowing histopathology image classifiers with inductive biases about example
difficulty?
</p>
<p>We propose several label smoothing methods that utilize per-image annotator
agreement. Though our methods are simple, we find that they substantially
improve model calibration, while maintaining (or even improving) accuracy. For
colorectal polyp classification, a common yet challenging task in
gastrointestinal pathology, we find that our proposed agreement-aware label
smoothing methods reduce calibration error by almost 70%. Moreover, we find
that using model confidence as a proxy for annotator agreement also improves
calibration and accuracy, suggesting that datasets without multiple annotators
can still benefit from our proposed label smoothing methods via our proposed
confidence-aware label smoothing methods.
</p>
<p>Given the importance of calibration (especially in histopathology image
analysis), the improvements from our proposed techniques merit further
exploration and potential implementation in other histopathology image
classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Infrastructure-Based Object Detection and Tracking for Cooperative Driving Automation: A Survey. (arXiv:2201.11871v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11871">
<div class="article-summary-box-inner">
<span><p>Object detection plays a fundamental role in enabling Cooperative Driving
Automation (CDA), which is regarded as the revolutionary solution to addressing
safety, mobility, and sustainability issues of contemporary transportation
systems. Although current computer vision technologies could provide
satisfactory object detection results in occlusion-free scenarios, the
perception performance of onboard sensors could be inevitably limited by the
range and occlusion. Owing to flexible position and pose for sensor
installation, infrastructure-based detection and tracking systems can enhance
the perception capability for connected vehicles and thus quickly become one of
the most popular research topics. In this paper, we review the research
progress for infrastructure-based object detection and tracking systems.
Architectures of roadside perception systems based on different types of
sensors are reviewed to show a high-level description of the workflows for
infrastructure-based perception systems. Roadside sensors and different
perception methodologies are reviewed and analyzed with detailed literature to
provide a low-level explanation for specific methods followed by Datasets and
Simulators to draw an overall landscape of infrastructure-based object
detection and tracking methods. Discussions are conducted to point out current
opportunities, open problems, and anticipated future trends.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Indicative Image Retrieval: Turning Blackbox Learning into Grey. (arXiv:2201.11898v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11898">
<div class="article-summary-box-inner">
<span><p>Deep learning became the game changer for image retrieval soon after it was
introduced. It promotes the feature extraction (by representation learning) as
the core of image retrieval, with the relevance/matching evaluation being
degenerated into simple similarity metrics. In many applications, we need the
matching evidence to be indicated rather than just have the ranked list (e.g.,
the locations of the target proteins/cells/lesions in medical images). It is
like the matched words need to be highlighted in search engines. However, this
is not easy to implement without explicit relevance/matching modeling. The deep
representation learning models are not feasible because of their blackbox
nature. In this paper, we revisit the importance of relevance/matching modeling
in deep learning era with an indicative retrieval setting. The study shows that
it is possible to skip the representation learning and model the matching
evidence directly. By removing the dependency on the pre-trained models, it has
avoided a lot of related issues (e.g., the domain gap between classification
and retrieval, the detail-diffusion caused by convolution, and so on). More
importantly, the study demonstrates that the matching can be explicitly modeled
and backtracked later for generating the matching evidence indications. It can
improve the explainability of deep inference. Our method obtains a best
performance in literature on both Oxford-5k and Paris-6k, and sets a new record
of 97.77% on Oxford-5k (97.81% on Paris-6k) without extracting any deep
features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stereo Matching with Cost Volume based Sparse Disparity Propagation. (arXiv:2201.11937v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11937">
<div class="article-summary-box-inner">
<span><p>Stereo matching is crucial for binocular stereo vision. Existing methods
mainly focus on simple disparity map fusion to improve stereo matching, which
require multiple dense or sparse disparity maps. In this paper, we propose a
simple yet novel scheme, termed feature disparity propagation, to improve
general stereo matching based on matching cost volume and sparse matching
feature points. Specifically, our scheme first calculates a reliable sparse
disparity map by local feature matching, and then refines the disparity map by
propagating reliable disparities to neighboring pixels in the matching cost
domain. In addition, considering the gradient and multi-scale information of
local disparity regions, we present a $\rho$-Census cost measure based on the
well-known AD-Census, which guarantees the robustness of cost volume even
without the cost aggregation step. Extensive experiments on Middlebury stereo
benchmark V3 demonstrate that our scheme achieves promising performance
comparable to state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DICP: Doppler Iterative Closest Point Algorithm. (arXiv:2201.11944v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11944">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a novel algorithm for point cloud registration for
range sensors capable of measuring per-return instantaneous radial velocity:
Doppler ICP. Existing variants of ICP that solely rely on geometry or other
features generally fail to estimate the motion of the sensor correctly in
scenarios that have non-distinctive features and/or repetitive geometric
structures such as hallways, tunnels, highways, and bridges. We propose a new
Doppler velocity objective function that exploits the compatibility of each
point's Doppler measurement and the sensor's current motion estimate. We
jointly optimize the Doppler velocity objective function and the geometric
objective function which sufficiently constrains the point cloud alignment
problem even in feature-denied environments. Furthermore, the correspondence
matches used for the alignment are improved by pruning away the points from
dynamic targets which generally degrade the ICP solution. We evaluate our
method on data collected from real sensors and from simulation. Our results
show a significant performance improvement in terms of the registration
accuracy with the added benefit of faster convergence guided by the Doppler
velocity gradients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shuffle Augmentation of Features from Unlabeled Data for Unsupervised Domain Adaptation. (arXiv:2201.11963v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11963">
<div class="article-summary-box-inner">
<span><p>Unsupervised Domain Adaptation (UDA), a branch of transfer learning where
labels for target samples are unavailable, has been widely researched and
developed in recent years with the help of adversarially trained models.
Although existing UDA algorithms are able to guide neural networks to extract
transferable and discriminative features, classifiers are merely trained under
the supervision of labeled source data. Given the inevitable discrepancy
between source and target domains, the classifiers can hardly be aware of the
target classification boundaries. In this paper, Shuffle Augmentation of
Features (SAF), a novel UDA framework, is proposed to address the problem by
providing the classifier with supervisory signals from target feature
representations. SAF learns from the target samples, adaptively distills
class-aware target features, and implicitly guides the classifier to find
comprehensive class borders. Demonstrated by extensive experiments, the SAF
module can be integrated into any existing adversarial UDA models to achieve
performance improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Visual Quality Assessment of GAN-Generated Face Images. (arXiv:2201.11975v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11975">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the dramatically increased interest in face
generation with generative adversarial networks (GANs). A number of successful
GAN algorithms have been developed to produce vivid face images towards
different application scenarios. However, little work has been dedicated to
automatic quality assessment of such GAN-generated face images (GFIs), even
less have been devoted to generalized and robust quality assessment of GFIs
generated with unseen GAN model. Herein, we make the first attempt to study the
subjective and objective quality towards generalized quality assessment of
GFIs. More specifically, we establish a large-scale database consisting of GFIs
from four GAN algorithms, the pseudo labels from image quality assessment (IQA)
measures, as well as the human opinion scores via subjective testing.
Subsequently, we develop a quality assessment model that is able to deliver
accurate quality predictions for GFIs from both available and unseen GAN
algorithms based on meta-learning. In particular, to learn shared knowledge
from GFIs pairs that are born of limited GAN algorithms, we develop the
convolutional block attention (CBA) and facial attributes-based analysis (ABA)
modules, ensuring that the learned knowledge tends to be consistent with human
visual perception. Extensive experiments exhibit that the proposed model
achieves better performance compared with the state-of-the-art IQA models, and
is capable of retaining the effectiveness when evaluating GFIs from the unseen
GAN algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computer-aided Recognition and Assessment of a Porous Bioelastomer on Ultrasound Images for Regenerative Medicine Applications. (arXiv:2201.11987v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11987">
<div class="article-summary-box-inner">
<span><p>Biodegradable elastic scaffolds have attracted more and more attention in the
field of soft tissue repair and tissue engineering. These scaffolds made of
porous bioelastomers support tissue ingrowth along with their own degradation.
It is necessary to develop a computer-aided analyzing method based on
ultrasound images to identify the degradation performance of the scaffold, not
only to obviate the need to do destructive testing, but also to monitor the
scaffold's degradation and tissue ingrowth over time. It is difficult using a
single traditional image processing algorithm to extract continuous and
accurate contour of a porous bioelastomer. This paper proposes a joint
algorithm for the bioelastomer's contour detection and a texture feature
extraction method for monitoring the degradation behavior of the bioelastomer.
Mean-shift clustering method is used to obtain the bioelastomer's and native
tissue's clustering feature information. Then the OTSU image binarization
method automatically selects the optimal threshold value to convert the
grayscale ultrasound image into a binary image. The Canny edge detector is used
to extract the complete bioelastomer's contour. The first-order and
second-order statistical features of texture are extracted. The proposed joint
algorithm not only achieves the ideal extraction of the bioelastomer's contours
in ultrasound images, but also gives valuable feedback of the degradation
behavior of the bioelastomer at the implant site based on the changes of
texture characteristics and contour area. The preliminary results of this study
suggest that the proposed computer-aided image processing techniques have
values and potentials in the non-invasive analysis of tissue scaffolds in vivo
based on ultrasound images and may help tissue engineers evaluate the tissue
scaffold's degradation and cellular ingrowth progress and improve the scaffold
designs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hybrid Contrastive Learning with Cluster Ensemble for Unsupervised Person Re-identification. (arXiv:2201.11995v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11995">
<div class="article-summary-box-inner">
<span><p>Unsupervised person re-identification (ReID) aims to match a query image of a
pedestrian to the images in gallery set without supervision labels. The most
popular approaches to tackle unsupervised person ReID are usually performing a
clustering algorithm to yield pseudo labels at first and then exploit the
pseudo labels to train a deep neural network. However, the pseudo labels are
noisy and sensitive to the hyper-parameter(s) in clustering algorithm. In this
paper, we propose a Hybrid Contrastive Learning (HCL) approach for unsupervised
person ReID, which is based on a hybrid between instance-level and
cluster-level contrastive loss functions. Moreover, we present a
Multi-Granularity Clustering Ensemble based Hybrid Contrastive Learning
(MGCE-HCL) approach, which adopts a multi-granularity clustering ensemble
strategy to mine priority information among the pseudo positive sample pairs
and defines a priority-weighted hybrid contrastive loss for better tolerating
the noises in the pseudo positive samples. We conduct extensive experiments on
two benchmark datasets Market-1501 and DukeMTMC-reID. Experimental results
validate the effectiveness of our proposals.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Networks for Image and Video Super-Resolution. (arXiv:2201.11996v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11996">
<div class="article-summary-box-inner">
<span><p>Efficiency of gradient propagation in intermediate layers of convolutional
neural networks is of key importance for super-resolution task. To this end, we
propose a deep architecture for single image super-resolution (SISR), which is
built using efficient convolutional units we refer to as mixed-dense connection
blocks (MDCB). The design of MDCB combines the strengths of both residual and
dense connection strategies, while overcoming their limitations. To enable
super-resolution for multiple factors, we propose a scale-recurrent framework
which reutilizes the filters learnt for lower scale factors recursively for
higher factors. This leads to improved performance and promotes parametric
efficiency for higher factors. We train two versions of our network to enhance
complementary image qualities using different loss configurations. We further
employ our network for video super-resolution task, where our network learns to
aggregate information from multiple frames and maintain spatio-temporal
consistency. The proposed networks lead to qualitative and quantitative
improvements over state-of-the-art techniques on image and video
super-resolution benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Superresolution using Scale-Recurrent Dense Network. (arXiv:2201.11998v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11998">
<div class="article-summary-box-inner">
<span><p>Recent advances in the design of convolutional neural network (CNN) have
yielded significant improvements in the performance of image super-resolution
(SR). The boost in performance can be attributed to the presence of residual or
dense connections within the intermediate layers of these networks. The
efficient combination of such connections can reduce the number of parameters
drastically while maintaining the restoration quality. In this paper, we
propose a scale recurrent SR architecture built upon units containing series of
dense connections within a residual block (Residual Dense Blocks (RDBs)) that
allow extraction of abundant local features from the image. Our scale recurrent
design delivers competitive performance for higher scale factors while being
parametrically more efficient as compared to current state-of-the-art
approaches. To further improve the performance of our network, we employ
multiple residual connections in intermediate layers (referred to as
Multi-Residual Dense Blocks), which improves gradient propagation in existing
layers. Recent works have discovered that conventional loss functions can guide
a network to produce results which have high PSNRs but are perceptually
inferior. We mitigate this issue by utilizing a Generative Adversarial Network
(GAN) based framework and deep feature (VGG) losses to train our network. We
experimentally demonstrate that different weighted combinations of the VGG loss
and the adversarial loss enable our network outputs to traverse along the
perception-distortion curve. The proposed networks perform favorably against
existing methods, both perceptually and objectively (PSNR-based) with fewer
parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unfolding a blurred image. (arXiv:2201.12010v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12010">
<div class="article-summary-box-inner">
<span><p>We present a solution for the goal of extracting a video from a single motion
blurred image to sequentially reconstruct the clear views of a scene as beheld
by the camera during the time of exposure. We first learn motion representation
from sharp videos in an unsupervised manner through training of a convolutional
recurrent video autoencoder network that performs a surrogate task of video
reconstruction. Once trained, it is employed for guided training of a motion
encoder for blurred images. This network extracts embedded motion information
from the blurred image to generate a sharp video in conjunction with the
trained recurrent video decoder. As an intermediate step, we also design an
efficient architecture that enables real-time single image deblurring and
outperforms competing methods across all factors: accuracy, speed, and
compactness. Experiments on real scenes and standard datasets demonstrate the
superiority of our framework over the state-of-the-art and its ability to
generate a plausible sequence of temporally consistent sharp frames.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RGB-D SLAM Using Attention Guided Frame Association. (arXiv:2201.12047v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12047">
<div class="article-summary-box-inner">
<span><p>Deep learning models as an emerging topic have shown great progress in
various fields. Especially, visualization tools such as class activation
mapping methods provided visual explanation on the reasoning of convolutional
neural networks (CNNs). By using the gradients of the network layers, it is
possible to demonstrate where the networks pay attention during a specific
image recognition task. Moreover, these gradients can be integrated with CNN
features for localizing more generalized task dependent attentive (salient)
objects in scenes. Despite this progress, there is not much explicit usage of
this gradient (network attention) information to integrate with CNN
representations for object semantics. This can be very useful for visual tasks
such as simultaneous localization and mapping (SLAM) where CNN representations
of spatially attentive object locations may lead to improved performance.
Therefore, in this work, we propose the use of task specific network attention
for RGB-D indoor SLAM. To do so, we integrate layer-wise object attention
information (layer gradients) with CNN layer representations to improve frame
association performance in a state-of-the-art RGB-D indoor SLAM method.
Experiments show promising initial results with improved performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detection of fake faces in videos. (arXiv:2201.12051v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12051">
<div class="article-summary-box-inner">
<span><p>: Deep learning methodologies have been used to create applications that can
cause threats to privacy, democracy and national security and could be used to
further amplify malicious activities. One of those deep learning-powered
applications in recent times is synthesized videos of famous personalities.
According to Forbes, Generative Adversarial Networks(GANs) generated fake
videos growing exponentially every year and the organization known as Deeptrace
had estimated an increase of deepfakes by 84% from the year 2018 to 2019. They
are used to generate and modify human faces, where most of the existing fake
videos are of prurient non-consensual nature, of which its estimates to be
around 96% and some carried out impersonating personalities for cyber crime. In
this paper, available video datasets are identified and a pretrained model
BlazeFace is used to detect faces, and a ResNet and Xception ensembled
architectured neural network trained on the dataset to achieve the goal of
detection of fake faces in videos. The model is optimized over a loss value and
log loss values and evaluated over its F1 score. Over a sample of data, it is
observed that focal loss provides better accuracy, F1 score and loss as the
gamma of the focal loss becomes a hyper parameter. This provides a k-folded
accuracy of around 91% at its peak in a training cycle with the real world
accuracy subjected to change over time as the model decays.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">You Only Cut Once: Boosting Data Augmentation with a Single Cut. (arXiv:2201.12078v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12078">
<div class="article-summary-box-inner">
<span><p>We present You Only Cut Once (YOCO) for performing data augmentations. YOCO
cuts one image into two pieces and performs data augmentations individually
within each piece. Applying YOCO improves the diversity of the augmentation per
sample and encourages neural networks to recognize objects from partial
information. YOCO enjoys the properties of parameter-free, easy usage, and
boosting almost all augmentations for free. Thorough experiments are conducted
to evaluate its effectiveness. We first demonstrate that YOCO can be seamlessly
applied to varying data augmentations, neural network architectures, and brings
performance gains on CIFAR and ImageNet classification tasks, sometimes
surpassing conventional image-level augmentation by large margins. Moreover, we
show YOCO benefits contrastive pre-training toward a more powerful
representation that can be better transferred to multiple downstream tasks.
Finally, we study a number of variants of YOCO and empirically analyze the
performance for respective settings. Code is available at GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DynaMixer: A Vision MLP Architecture with Dynamic Mixing. (arXiv:2201.12083v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12083">
<div class="article-summary-box-inner">
<span><p>Recently, MLP-like vision models have achieved promising performances on
mainstream visual recognition tasks. In contrast with vision transformers and
CNNs, the success of MLP-like models shows that simple information fusion
operations among tokens and channels can yield a good representation power for
deep recognition models. However, existing MLP-like models fuse tokens through
static fusion operations, lacking adaptability to the contents of the tokens to
be mixed. Thus, customary information fusion procedures are not effective
enough. To this end, this paper presents an efficient MLP-like network
architecture, dubbed DynaMixer, resorting to dynamic information fusion.
Critically, we propose a procedure, on which the DynaMixer model relies, to
dynamically generate mixing matrices by leveraging the contents of all the
tokens to be mixed. To reduce the time complexity and improve the robustness, a
dimensionality reduction technique and a multi-segment fusion mechanism are
adopted. Our proposed DynaMixer model (97M parameters) achieves 84.3\% top-1
accuracy on the ImageNet-1K dataset without extra training data, performing
favorably against the state-of-the-art vision MLP models. When the number of
parameters is reduced to 26M, it still achieves 82.7\% top-1 accuracy,
surpassing the existing MLP-like models with a similar capacity. The
implementation of DynaMixer will be made available to the public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Psychophysical Evaluation of Human Performance in Detecting Digital Face Image Manipulations. (arXiv:2201.12084v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12084">
<div class="article-summary-box-inner">
<span><p>In recent years, increasing deployment of face recognition technology in
security-critical settings, such as border control or law enforcement, has led
to considerable interest in the vulnerability of face recognition systems to
attacks utilising legitimate documents, which are issued on the basis of
digitally manipulated face images. As automated manipulation and attack
detection remains a challenging task, conventional processes with human
inspectors performing identity verification remain indispensable. These
circumstances merit a closer investigation of human capabilities in detecting
manipulated face images, as previous work in this field is sparse and often
concentrated only on specific scenarios and biometric characteristics.
</p>
<p>This work introduces a web-based, remote visual discrimination experiment on
the basis of principles adopted from the field of psychophysics and
subsequently discusses interdisciplinary opportunities with the aim of
examining human proficiency in detecting different types of digitally
manipulated face images, specifically face swapping, morphing, and retouching.
In addition to analysing appropriate performance measures, a possible metric of
detectability is explored. Experimental data of 306 probands indicate that
detection performance is widely distributed across the population and detection
of certain types of face image manipulations is much more challenging than
others.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation. (arXiv:2201.12086v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12086">
<div class="article-summary-box-inner">
<span><p>Vision-Language Pre-training (VLP) has advanced the performance for many
vision-language tasks. However, most existing pre-trained models only excel in
either understanding-based tasks or generation-based tasks. Furthermore,
performance improvement has been largely achieved by scaling up the dataset
with noisy image-text pairs collected from the web, which is a suboptimal
source of supervision. In this paper, we propose BLIP, a new VLP framework
which transfers flexibly to both vision-language understanding and generation
tasks. BLIP effectively utilizes the noisy web data by bootstrapping the
captions, where a captioner generates synthetic captions and a filter removes
the noisy ones. We achieve state-of-the-art results on a wide range of
vision-language tasks, such as image-text retrieval (+2.7% in average
recall@1), image captioning (+2.8% in CIDEr), and VQA (+1.6% in VQA score).
BLIP also demonstrates strong generalization ability when directly transferred
to video-language tasks in a zero-shot manner. Code, models, and datasets are
released at https://github.com/salesforce/BLIP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label uncertainty-guided multi-stream model for disease screening. (arXiv:2201.12089v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12089">
<div class="article-summary-box-inner">
<span><p>The annotation of disease severity for medical image datasets often relies on
collaborative decisions from multiple human graders. The intra-observer
variability derived from individual differences always persists in this
process, yet the influence is often underestimated. In this paper, we cast the
intra-observer variability as an uncertainty problem and incorporate the label
uncertainty information as guidance into the disease screening model to improve
the final decision. The main idea is dividing the images into simple and hard
cases by uncertainty information, and then developing a multi-stream network to
deal with different cases separately. Particularly, for hard cases, we
strengthen the network's capacity in capturing the correct disease features and
resisting the interference of uncertainty. Experiments on a fundus image-based
glaucoma screening case study show that the proposed model outperforms several
baselines, especially in screening hard cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neighborhood-aware Geometric Encoding Network for Point Cloud Registration. (arXiv:2201.12094v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12094">
<div class="article-summary-box-inner">
<span><p>The distinguishing geometric features determine the success of point cloud
registration. However, most point clouds are partially overlapping, corrupted
by noise, and comprised of indistinguishable surfaces, which makes it a
challenge to extract discriminative features. Here, we propose the
Neighborhood-aware Geometric Encoding Network (NgeNet) for accurate point cloud
registration. NgeNet utilizes a geometric guided encoding module to take
geometric characteristics into consideration, a multi-scale architecture to
focus on the semantically rich regions in different scales, and a consistent
voting strategy to select features with proper neighborhood size and reject the
specious features. The awareness of adaptive neighborhood points is obtained
through the multi-scale architecture accompanied by voting. Specifically, the
proposed techniques in NgeNet are model-agnostic, which could be easily
migrated to other networks. Comprehensive experiments on indoor, outdoor and
object-centric synthetic datasets demonstrate that NgeNet surpasses all of the
published state-of-the-art methods. The code will be available at
https://github.com/zhulf0804/NgeNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Owner-member Relationship with Graph Convolution Network in Fisheye Camera System. (arXiv:2201.12099v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12099">
<div class="article-summary-box-inner">
<span><p>The owner-member relationship between wheels and vehicles contributes
significantly to the 3D perception of vehicles, especially in embedded
environments. However, to leverage this relationship we must face two major
challenges: i) Traditional IoU-based heuristics have difficulty handling
occluded traffic congestion scenarios. ii) The effectiveness and applicability
of the solution in a vehicle-mounted system is difficult. To address these
issues, we propose an innovative relationship prediction method, DeepWORD, by
designing a graph convolutional network (GCN). Specifically, to improve the
information richness, we use feature maps with local correlation as input to
the nodes. Subsequently, we introduce a graph attention network (GAT) to
dynamically correct the a priori estimation bias. Finally, we designed a
dataset as a large-scale benchmark which has annotated owner-member
relationship, called WORD. In the experiments we learned that the proposed
method achieved state-of-the-art accuracy and real-time performance. The WORD
dataset is made publicly available at
https://github.com/NamespaceMain/ownermember-relationship-dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature Visualization within an Automated Design Assessment leveraging Explainable Artificial Intelligence Methods. (arXiv:2201.12107v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12107">
<div class="article-summary-box-inner">
<span><p>Not only automation of manufacturing processes but also automation of
automation procedures itself become increasingly relevant to automation
research. In this context, automated capability assessment, mainly leveraged by
deep learning systems driven from 3D CAD data, have been presented. Current
assessment systems may be able to assess CAD data with regards to abstract
features, e.g. the ability to automatically separate components from bulk
goods, or the presence of gripping surfaces. Nevertheless, they suffer from the
factor of black box systems, where an assessment can be learned and generated
easily, but without any geometrical indicator about the reasons of the system's
decision. By utilizing explainable AI (xAI) methods, we attempt to open up the
black box. Explainable AI methods have been used in order to assess whether a
neural network has successfully learned a given task or to analyze which
features of an input might lead to an adversarial attack. These methods aim to
derive additional insights into a neural network, by analyzing patterns from a
given input and its impact to the network output. Within the NeuroCAD Project,
xAI methods are used to identify geometrical features which are associated with
a certain abstract feature. Within this work, a sensitivity analysis (SA), the
layer-wise relevance propagation (LRP), the Gradient-weighted Class Activation
Mapping (Grad-CAM) method as well as the Local Interpretable Model-Agnostic
Explanations (LIME) have been implemented in the NeuroCAD environment, allowing
not only to assess CAD models but also to identify features which have been
relevant for the network decision. In the medium run, this might enable to
identify regions of interest supporting product designers to optimize their
models with regards to assembly processes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Attention-Model Explainability through Faithfulness Violation Test. (arXiv:2201.12114v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12114">
<div class="article-summary-box-inner">
<span><p>Attention mechanisms are dominating the explainability of deep models. They
produce probability distributions over the input, which are widely deemed as
feature-importance indicators. However, in this paper, we find one critical
limitation in attention explanations: weakness in identifying the polarity of
feature impact. This would be somehow misleading -- features with higher
attention weights may not faithfully contribute to model predictions; instead,
they can impose suppression effects. With this finding, we reflect on the
explainability of current attention-based techniques, such as
Attentio$\odot$Gradient and LRP-based attention explanations. We first propose
an actionable diagnostic methodology (henceforth faithfulness violation test)
to measure the consistency between explanation weights and the impact polarity.
Through the extensive experiments, we then show that most tested explanation
methods are unexpectedly hindered by the faithfulness violation issue,
especially the raw attention. Empirical analyses on the factors affecting
violation issues further provide useful observations for adopting explanation
methods in attention models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DELAUNAY: a dataset of abstract art for psychophysical and machine learning research. (arXiv:2201.12123v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12123">
<div class="article-summary-box-inner">
<span><p>Image datasets are commonly used in psychophysical experiments and in machine
learning research. Most publicly available datasets are comprised of images of
realistic and natural objects. However, while typical machine learning models
lack any domain specific knowledge about natural objects, humans can leverage
prior experience for such data, making comparisons between artificial and
natural learning challenging. Here, we introduce DELAUNAY, a dataset of
abstract paintings and non-figurative art objects labelled by the artists'
names. This dataset provides a middle ground between natural images and
artificial patterns and can thus be used in a variety of contexts, for example
to investigate the sample efficiency of humans and artificial neural networks.
Finally, we train an off-the-shelf convolutional neural network on DELAUNAY,
highlighting several of its intriguing features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">O-ViT: Orthogonal Vision Transformer. (arXiv:2201.12133v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12133">
<div class="article-summary-box-inner">
<span><p>Inspired by the tremendous success of the self-attention mechanism in natural
language processing, the Vision Transformer (ViT) creatively applies it to
image patch sequences and achieves incredible performance. However, the scaled
dot-product self-attention of ViT brings about scale ambiguity to the structure
of the original feature space. To address this problem, we propose a novel
method named Orthogonal Vision Transformer (O-ViT), to optimize ViT from the
geometric perspective. O-ViT limits parameters of self-attention blocks to be
on the norm-keeping orthogonal manifold, which can keep the geometry of the
feature space. Moreover, O-ViT achieves both orthogonal constraints and cheap
optimization overhead by adopting a surjective mapping between the orthogonal
group and its Lie algebra.We have conducted comparative experiments on image
recognition tasks to demonstrate O-ViT's validity and experiments show that
O-ViT can boost the performance of ViT by up to 3.6%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Carotid artery wall segmentation in ultrasound image sequences using a deep convolutional neural network. (arXiv:2201.12152v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12152">
<div class="article-summary-box-inner">
<span><p>The objective of this study is the segmentation of the intima-media complex
of the common carotid artery, on longitudinal ultrasound images, to measure its
thickness. We propose a fully automatic region-based segmentation method,
involving a supervised region-based deep-learning approach based on a dilated
U-net network. It was trained and evaluated using a 5-fold cross-validation on
a multicenter database composed of 2176 images annotated by two experts. The
resulting mean absolute difference (&lt;120 um) compared to reference annotations
was less than the inter-observer variability (180 um). With a 98.7% success
rate, i.e., only 1.3% cases requiring manual correction, the proposed method
has been shown to be robust and thus may be recommended for use in clinical
practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Single-shot Depth Estimation using Perceptual Reconstruction. (arXiv:2201.12170v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12170">
<div class="article-summary-box-inner">
<span><p>Real-time estimation of actual object depth is a module that is essential to
performing various autonomous system tasks such as 3D reconstruction, scene
understanding and condition assessment of machinery parts. During the last
decade of machine learning, extensive deployment of deep learning methods to
computer vision tasks has yielded approaches that succeed in achieving
realistic depth synthesis out of a simple RGB modality. While most of these
models are based on paired depth data or availability of video sequences and
stereo images, methods for single-view depth synthesis in a fully unsupervised
setting have hardly been explored. This study presents the most recent advances
in the field of generative neural networks, leveraging them to perform fully
unsupervised single-shot depth synthesis. Two generators for RGB-to-depth and
depth-to-RGB transfer are implemented and simultaneously optimized using the
Wasserstein-1 distance and a novel perceptual reconstruction term. To ensure
that the proposed method is plausible, we comprehensively evaluate the models
using industrial surface depth data as well as the Texas 3D Face Recognition
Database and the SURREAL dataset that records body depth. The success observed
in this study suggests the great potential for unsupervised single-shot depth
estimation in real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks. (arXiv:2201.12179v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12179">
<div class="article-summary-box-inner">
<span><p>Model inversion attacks (MIAs) aim to create synthetic images that reflect
the class-wise characteristics from a target classifier's training data by
exploiting the model's learned knowledge. Previous research has developed
generative MIAs using generative adversarial networks (GANs) as image priors
that are tailored to a specific target model. This makes the attacks time- and
resource-consuming, inflexible, and susceptible to distributional shifts
between datasets. To overcome these drawbacks, we present Plug &amp; Play Attacks
that loosen the dependency between the target model and image prior and enable
the use of a single trained GAN to attack a broad range of targets with only
minor attack adjustments needed. Moreover, we show that powerful MIAs are
possible even with publicly available pre-trained GANs and under strong
distributional shifts, whereas previous approaches fail to produce meaningful
results. Our extensive evaluation confirms the improved robustness and
flexibility of Plug &amp; Play Attacks and their ability to create high-quality
images revealing sensitive class characteristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A tomographic workflow to enable deep learning for X-ray based foreign object detection. (arXiv:2201.12184v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12184">
<div class="article-summary-box-inner">
<span><p>Detection of unwanted (`foreign') objects within products is a common
procedure in many branches of industry for maintaining production quality.
X-ray imaging is a fast, non-invasive and widely applicable method for foreign
object detection. Deep learning has recently emerged as a powerful approach for
recognizing patterns in radiographs (i.e., X-ray images), enabling automated
X-ray based foreign object detection. However, these methods require a large
number of training examples and manual annotation of these examples is a
subjective and laborious task. In this work, we propose a Computed Tomography
(CT) based method for producing training data for supervised learning of
foreign object detection, with minimal labour requirements. In our approach, a
few representative objects are CT scanned and reconstructed in 3D. The
radiographs that have been acquired as part of the CT-scan data serve as input
for the machine learning method. High-quality ground truth locations of the
foreign objects are obtained through accurate 3D reconstructions and
segmentations. Using these segmented volumes, corresponding 2D segmentations
are obtained by creating virtual projections. We outline the benefits of
objectively and reproducibly generating training data in this way compared to
conventional radiograph annotation. In addition, we show how the accuracy
depends on the number of objects used for the CT reconstructions. The results
show that in this workflow generally only a relatively small number of
representative objects (i.e., fewer than 10) are needed to achieve adequate
detection performance in an industrial setting. Moreover, for real experimental
data we show that the workflow leads to higher foreign object detection
accuracies than with standard radiograph annotation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M\"{o}bius Convolutions for Spherical CNNs. (arXiv:2201.12212v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12212">
<div class="article-summary-box-inner">
<span><p>M\"{o}bius transformations play an important role in both geometry and
spherical image processing -- they are the group of conformal automorphisms of
2D surfaces and the spherical equivalent of homographies. Here we present a
novel, M\"{o}bius-equivariant spherical convolution operator which we call
M\"{o}bius convolution, and with it, develop the foundations for
M\"{o}bius-equivariant spherical CNNs. Our approach is based on a simple
observation: to achieve equivariance, we only need to consider the
lower-dimensional subgroup which transforms the positions of points as seen in
the frames of their neighbors. To efficiently compute M\"{o}bius convolutions
at scale we derive an approximation of the action of the transformations on
spherical filters, allowing us to compute our convolutions in the spectral
domain with the fast Spherical Harmonic Transform. The resulting framework is
both flexible and descriptive, and we demonstrate its utility by achieving
promising results in both shape classification and image segmentation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-paced learning to improve text row detection in historical documents with missing lables. (arXiv:2201.12216v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12216">
<div class="article-summary-box-inner">
<span><p>An important preliminary step of optical character recognition systems is the
detection of text rows. To address this task in the context of historical data
with missing labels, we propose a self-paced learning algorithm capable of
improving the row detection performance. We conjecture that pages with more
ground-truth bounding boxes are less likely to have missing annotations. Based
on this hypothesis, we sort the training examples in descending order with
respect to the number of ground-truth bounding boxes, and organize them into k
batches. Using our self-paced learning method, we train a row detector over k
iterations, progressively adding batches with less ground-truth annotations. At
each iteration, we combine the ground-truth bounding boxes with pseudo-bounding
boxes (bounding boxes predicted by the model itself) using non-maximum
suppression, and we include the resulting annotations at the next training
iteration. We demonstrate that our self-paced learning strategy brings
significant performance gains on two data sets of historical documents,
improving the average precision of YOLOv4 with more than 12% on one data set
and 39% on the other.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite Time Neural ODEs (Continuous DEQs). (arXiv:2201.12240v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12240">
<div class="article-summary-box-inner">
<span><p>Implicit deep learning architectures, like Neural ODEs and Deep Equilibrium
Models (DEQs), separate the definition of a layer from the description of its
solution process. While implicit layers allow features such as depth to adapt
to new scenarios and inputs automatically, this adaptivity makes its
computational expense challenging to predict. Numerous authors have noted that
implicit layer techniques can be more computationally intensive than explicit
layer methods. In this manuscript, we address the question: is there a way to
simultaneously achieve the robustness of implicit layers while allowing the
reduced computational expense of an explicit layer? To solve this we develop
Skip DEQ, an implicit-explicit (IMEX) layer that simultaneously trains an
explicit prediction followed by an implicit correction. We show that training
this explicit layer is free and even decreases the training time by 2.5x and
prediction time by 3.4x. We then further increase the "implicitness" of the DEQ
by redefining the method in terms of an infinite time neural ODE which
paradoxically decreases the training cost over a standard neural ODE by not
requiring backpropagation through time. We demonstrate how the resulting
Continuous Skip DEQ architecture trains more robustly than the original DEQ
while achieving faster training and prediction times. Together, this manuscript
shows how bridging the dichotomy of implicit and explicit deep learning can
combine the advantages of both techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Review on Deep-Learning Algorithms for Fetal Ultrasound-Image Analysis. (arXiv:2201.12260v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12260">
<div class="article-summary-box-inner">
<span><p>Deep-learning (DL) algorithms are becoming the standard for processing
ultrasound (US) fetal images. Despite a large number of survey papers already
present in this field, most of them are focusing on a broader area of
medical-image analysis or not covering all fetal US DL applications. This paper
surveys the most recent work in the field, with a total of 145 research papers
published after 2017. Each paper is analyzed and commented on from both the
methodology and application perspective. We categorized the papers in (i) fetal
standard-plane detection, (ii) anatomical-structure analysis, and (iii)
biometry parameter estimation. For each category, main limitations and open
issues are presented. Summary tables are included to facilitate the comparison
among the different approaches. Publicly-available datasets and performance
metrics commonly used to assess algorithm performance are summarized, too. This
paper ends with a critical summary of the current state of the art on DL
algorithms for fetal US image analysis and a discussion on current challenges
that have to be tackled by researchers working in the field to translate the
research methodology into the actual clinical practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D-FlowNet: Event-based optical flow estimation with 3D representation. (arXiv:2201.12265v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12265">
<div class="article-summary-box-inner">
<span><p>Event-based cameras can overpass frame-based cameras limitations for
important tasks such as high-speed motion detection during self-driving cars
navigation in low illumination conditions. The event cameras' high temporal
resolution and high dynamic range, allow them to work in fast motion and
extreme light scenarios. However, conventional computer vision methods, such as
Deep Neural Networks, are not well adapted to work with event data as they are
asynchronous and discrete. Moreover, the traditional 2D-encoding representation
methods for event data, sacrifice the time resolution. In this paper, we first
improve the 2D-encoding representation by expanding it into three dimensions to
better preserve the temporal distribution of the events. We then propose
3D-FlowNet, a novel network architecture that can process the 3D input
representation and output optical flow estimations according to the new
encoding methods. A self-supervised training strategy is adopted to compensate
the lack of labeled datasets for the event-based camera. Finally, the proposed
network is trained and evaluated with the Multi-Vehicle Stereo Event Camera
(MVSEC) dataset. The results show that our 3D-FlowNet outperforms
state-of-the-art approaches with less training epoch (30 compared to 100 of
Spike-FlowNet).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HSADML: Hyper-Sphere Angular Deep Metric based Learning for Brain Tumor Classification. (arXiv:2201.12269v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12269">
<div class="article-summary-box-inner">
<span><p>Brain Tumors are abnormal mass of clustered cells penetrating regions of
brain. Their timely identification and classification help doctors to provide
appropriate treatment. However, Classifi-cation of Brain Tumors is quite
intricate because of high-intra class similarity and low-inter class
variability. Due to morphological similarity amongst various MRI-Slices of
different classes the challenge deepens more. This all leads to hampering
generalizability of classification models. To this end, this paper proposes
HSADML, a novel framework which enables deep metric learning (DML) using
SphereFace Loss. SphereFace loss embeds the features into a
hyperspheric-manifold and then imposes margin on the embeddings to enhance
differentiability between the classes. With utilization of SphereFace loss
based deep metric learning it is ensured that samples from class clustered
together while the different ones are pushed apart. Results reflects the
promi-nence in the approach, the proposed framework achieved state-of-the-art
98.69% validation accu-racy using k-NN (k=1) and this is significantly higher
than normal SoftMax Loss training which though obtains 98.47% validation
accuracy but that too with limited inter-class separability and intra-class
closeness. Experimental analysis done over various classifiers and loss
function set-tings suggests potential in the approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking Conventional Vision Models on Neuromorphic Fall Detection and Action Recognition Dataset. (arXiv:2201.12285v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12285">
<div class="article-summary-box-inner">
<span><p>Neuromorphic vision-based sensors are gaining popularity in recent years with
their ability to capture Spatio-temporal events with low power sensing. These
sensors record events or spikes over traditional cameras which helps in
preserving the privacy of the subject being recorded. These events are captured
as per-pixel brightness changes and the output data stream is encoded with
time, location, and pixel intensity change information. This paper proposes and
benchmarks the performance of fine-tuned conventional vision models on
neuromorphic human action recognition and fall detection datasets. The
Spatio-temporal event streams from the Dynamic Vision Sensing cameras are
encoded into a standard sequence image frames. These video frames are used for
benchmarking conventional deep learning-based architectures. In this proposed
approach, we fine-tuned the state-of-the-art vision models for this Dynamic
Vision Sensing (DVS) application and named these models as DVS-R2+1D, DVS-CSN,
DVS-C2D, DVS-SlowFast, DVS-X3D, and DVS-MViT. Upon comparing the performance of
these models, we see the current state-of-the-art MViT based architecture
DVS-MViT outperforms all the other models with an accuracy of 0.958 and an F-1
score of 0.958. The second best is the DVS-C2D with an accuracy of 0.916 and an
F-1 score of 0.916. Third and Fourth are DVS-R2+1D and DVS-SlowFast with an
accuracy of 0.875 and 0.833 and F-1 score of 0.875 and 0.861 respectively.
DVS-CSN and DVS-X3D were the least performing models with an accuracy of 0.708
and 0.625 and an F1 score of 0.722 and 0.625 respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VRT: A Video Restoration Transformer. (arXiv:2201.12288v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12288">
<div class="article-summary-box-inner">
<span><p>Video restoration (e.g., video super-resolution) aims to restore high-quality
frames from low-quality frames. Different from single image restoration, video
restoration generally requires to utilize temporal information from multiple
adjacent but usually misaligned video frames. Existing deep methods generally
tackle with this by exploiting a sliding window strategy or a recurrent
architecture, which either is restricted by frame-by-frame restoration or lacks
long-range modelling ability. In this paper, we propose a Video Restoration
Transformer (VRT) with parallel frame prediction and long-range temporal
dependency modelling abilities. More specifically, VRT is composed of multiple
scales, each of which consists of two kinds of modules: temporal mutual self
attention (TMSA) and parallel warping. TMSA divides the video into small clips,
on which mutual attention is applied for joint motion estimation, feature
alignment and feature fusion, while self attention is used for feature
extraction. To enable cross-clip interactions, the video sequence is shifted
for every other layer. Besides, parallel warping is used to further fuse
information from neighboring frames by parallel feature warping. Experimental
results on three tasks, including video super-resolution, video deblurring and
video denoising, demonstrate that VRT outperforms the state-of-the-art methods
by large margins ($\textbf{up to 2.16dB}$) on nine benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking Robustness of 3D Point Cloud Recognition Against Common Corruptions. (arXiv:2201.12296v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12296">
<div class="article-summary-box-inner">
<span><p>Deep neural networks on 3D point cloud data have been widely used in the real
world, especially in safety-critical applications. However, their robustness
against corruptions is less studied. In this paper, we present ModelNet40-C,
the first comprehensive benchmark on 3D point cloud corruption robustness,
consisting of 15 common and realistic corruptions. Our evaluation shows a
significant gap between the performances on ModelNet40 and ModelNet40-C for
state-of-the-art (SOTA) models. To reduce the gap, we propose a simple but
effective method by combining PointCutMix-R and TENT after evaluating a wide
range of augmentation and test-time adaptation strategies. We identify a number
of critical insights for future studies on corruption robustness in point cloud
recognition. For instance, we unveil that Transformer-based architectures with
proper training recipes achieve the strongest robustness. We hope our in-depth
analysis will motivate the development of robust training strategies or
architecture designs in the 3D point cloud domain. Our codebase and dataset are
included in https://github.com/jiachens/ModelNet40-C
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">REET: Robustness Evaluation and Enhancement Toolbox for Computational Pathology. (arXiv:2201.12311v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12311">
<div class="article-summary-box-inner">
<span><p>Motivation: Digitization of pathology laboratories through digital slide
scanners and advances in deep learning approaches for objective histological
assessment have resulted in rapid progress in the field of computational
pathology (CPath) with wide-ranging applications in medical and pharmaceutical
research as well as clinical workflows. However, the estimation of robustness
of CPath models to variations in input images is an open problem with a
significant impact on the down-stream practical applicability, deployment and
acceptability of these approaches. Furthermore, development of domain-specific
strategies for enhancement of robustness of such models is of prime importance
as well.
</p>
<p>Implementation and Availability: In this work, we propose the first
domain-specific Robustness Evaluation and Enhancement Toolbox (REET) for
computational pathology applications. It provides a suite of algorithmic
strategies for enabling robustness assessment of predictive models with respect
to specialized image transformations such as staining, compression, focusing,
blurring, changes in spatial resolution, brightness variations, geometric
changes as well as pixel-level adversarial perturbations. Furthermore, REET
also enables efficient and robust training of deep learning pipelines in
computational pathology. REET is implemented in Python and is available at the
following URL: https://github.com/alexjfoote/reetoolbox.
</p>
<p>Contact: Fayyaz.minhas@warwick.ac.uk
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR. (arXiv:2201.12329v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12329">
<div class="article-summary-box-inner">
<span><p>We present in this paper a novel query formulation using dynamic anchor boxes
for DETR (DEtection TRansformer) and offer a deeper understanding of the role
of queries in DETR. This new formulation directly uses box coordinates as
queries in Transformer decoders and dynamically updates them layer-by-layer.
Using box coordinates not only helps using explicit positional priors to
improve the query-to-feature similarity and eliminate the slow training
convergence issue in DETR, but also allows us to modulate the positional
attention map using the box width and height information. Such a design makes
it clear that queries in DETR can be implemented as performing soft ROI pooling
layer-by-layer in a cascade manner. As a result, it leads to the best
performance on MS-COCO benchmark among the DETR-like detection models under the
same setting, e.g., AP 45.7\% using ResNet50-DC5 as backbone trained in 50
epochs. We also conducted extensive experiments to confirm our analysis and
verify the effectiveness of our methods. Code is available at
\url{https://github.com/SlongLiu/DAB-DETR}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASMCNN: An Efficient Brain Extraction Using Active Shape Model and Convolutional Neural Networks. (arXiv:1802.01268v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1802.01268">
<div class="article-summary-box-inner">
<span><p>Brain extraction (skull stripping) is a challenging problem in neuroimaging.
It is due to the variability in conditions from data acquisition or
abnormalities in images, making brain morphology and intensity characteristics
changeable and complicated. In this paper, we propose an algorithm for skull
stripping in Magnetic Resonance Imaging (MRI) scans, namely ASMCNN, by
combining the Active Shape Model (ASM) and Convolutional Neural Network (CNN)
for taking full of their advantages to achieve remarkable results. Instead of
working with 3D structures, we process 2D image sequences in the sagittal
plane. First, we divide images into different groups such that, in each group,
shapes and structures of brain boundaries have similar appearances. Second, a
modified version of ASM is used to detect brain boundaries by utilizing prior
knowledge of each group. Finally, CNN and post-processing methods, including
Conditional Random Field (CRF), Gaussian processes, and several special rules
are applied to refine the segmentation contours. Experimental results show that
our proposed method outperforms current state-of-the-art algorithms by a
significant margin in all experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Topological Filter for Learning with Label Noise. (arXiv:2012.04835v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04835">
<div class="article-summary-box-inner">
<span><p>Noisy labels can impair the performance of deep neural networks. To tackle
this problem, in this paper, we propose a new method for filtering label noise.
Unlike most existing methods relying on the posterior probability of a noisy
classifier, we focus on the much richer spatial behavior of data in the latent
representational space. By leveraging the high-order topological information of
data, we are able to collect most of the clean data and train a high-quality
model. Theoretically we prove that this topological approach is guaranteed to
collect the clean data with high probability. Empirical results show that our
method outperforms the state-of-the-arts and is robust to a broad spectrum of
noise types and levels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simplicial Complex Representation Learning. (arXiv:2103.04046v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04046">
<div class="article-summary-box-inner">
<span><p>Simplicial complexes form an important class of topological spaces that are
frequently used in many application areas such as computer-aided design,
computer graphics, and simulation. Representation learning on graphs, which are
just 1-d simplicial complexes, has witnessed a great attention in recent years.
However, there has not been enough effort to extend representation learning to
higher dimensional simplicial objects due to the additional complexity these
objects hold, especially when it comes to entire-simplicial complex
representation learning. In this work, we propose a method for simplicial
complex-level representation learning that embeds a simplicial complex to a
universal embedding space in a way that complex-to-complex proximity is
preserved. Our method uses our novel geometric message passing schemes to learn
an entire simplicial complex representation in an end-to-end fashion. We
demonstrate the proposed model on publicly available mesh dataset. To the best
of our knowledge, this work presents the first method for learning simplicial
complex-level representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Effects of Spectral Dimensionality Reduction on Hyperspectral Pixel Classification: A Case Study. (arXiv:2104.00788v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00788">
<div class="article-summary-box-inner">
<span><p>This paper presents a systematic study of the effects of hyperspectral pixel
dimensionality reduction on the pixel classification task. We use five
dimensionality reduction methods -- PCA, KPCA, ICA, AE, and DAE -- to compress
301-dimensional hyperspectral pixels. Compressed pixels are subsequently used
to perform pixel classifications. Pixel classification accuracies together with
compression method, compression rates, and reconstruction errors provide a new
lens to study the suitability of a compression method for the task of pixel
classification. We use three high-resolution hyperspectral image datasets,
representing three common landscape types (i.e. urban, transitional suburban,
and forests) collected by the Remote Sensing and Spatial Ecosystem Modeling
laboratory of the University of Toronto. We found that PCA, KPCA, and ICA post
greater signal reconstruction capability; however, when compression rates are
more than 90\% these methods show lower classification scores. AE and DAE
methods post better classification accuracy at 95\% compression rate, however
their performance drops as compression rate approaches 97\%. Our results
suggest that both the compression method and the compression rate are important
considerations when designing a hyperspectral pixel classification pipeline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TATL: Task Agnostic Transfer Learning for Skin Attributes Detection. (arXiv:2104.01641v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01641">
<div class="article-summary-box-inner">
<span><p>Existing skin attributes detection methods usually initialize with a
pre-trained Imagenet network and then fine-tune on a medical target task.
However, we argue that such approaches are suboptimal because medical datasets
are largely different from ImageNet and often contain limited training samples.
In this work, we propose \emph{Task Agnostic Transfer Learning (TATL)}, a novel
framework motivated by dermatologists' behaviors in the skincare context. TATL
learns an attribute-agnostic segmenter that detects lesion skin regions and
then transfers this knowledge to a set of attribute-specific classifiers to
detect each particular attribute. Since TATL's attribute-agnostic segmenter
only detects skin attribute regions, it enjoys ample data from all attributes,
allows transferring knowledge among features, and compensates for the lack of
training data from rare attributes. We conduct extensive experiments to
evaluate the proposed TATL transfer learning mechanism with various neural
network architectures on two popular skin attributes detection benchmarks. The
empirical results show that TATL not only works well with multiple
architectures but also can achieve state-of-the-art performances while enjoying
minimal model and computational complexities. We also provide theoretical
insights and explanations for why our transfer learning framework performs well
in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiple Sclerosis Lesion Analysis in Brain Magnetic Resonance Images: Techniques and Clinical Applications. (arXiv:2104.10029v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10029">
<div class="article-summary-box-inner">
<span><p>Multiple sclerosis (MS) is a chronic inflammatory and degenerative disease of
the central nervous system, characterized by the appearance of focal lesions in
the white and gray matter that topographically correlate with an individual
patient's neurological symptoms and signs. Magnetic resonance imaging (MRI)
provides detailed in-vivo structural information, permitting the quantification
and categorization of MS lesions that critically inform disease management.
Traditionally, MS lesions have been manually annotated on 2D MRI slices, a
process that is inefficient and prone to inter-/intra-observer errors.
Recently, automated statistical imaging analysis techniques have been proposed
to detect and segment MS lesions based on MRI voxel intensity. However, their
effectiveness is limited by the heterogeneity of both MRI data acquisition
techniques and the appearance of MS lesions. By learning complex lesion
representations directly from images, deep learning techniques have achieved
remarkable breakthroughs in the MS lesion segmentation task. Here, we provide a
comprehensive review of state-of-the-art automatic statistical and
deep-learning MS segmentation methods and discuss current and future clinical
applications. Further, we review technical strategies, such as domain
adaptation, to enhance MS lesion segmentation in real-world clinical settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Carrying out CNN Channel Pruning in a White Box. (arXiv:2104.11883v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11883">
<div class="article-summary-box-inner">
<span><p>Channel Pruning has been long studied to compress CNNs, which significantly
reduces the overall computation. Prior works implement channel pruning in an
unexplainable manner, which tends to reduce the final classification errors
while failing to consider the internal influence of each channel. In this
paper, we conduct channel pruning in a white box. Through deep visualization of
feature maps activated by different channels, we observe that different
channels have a varying contribution to different categories in image
classification. Inspired by this, we choose to preserve channels contributing
to most categories. Specifically, to model the contribution of each channel to
differentiating categories, we develop a class-wise mask for each channel,
implemented in a dynamic training manner w.r.t. the input image's category. On
the basis of the learned class-wise mask, we perform a global voting mechanism
to remove channels with less category discrimination. Lastly, a fine-tuning
process is conducted to recover the performance of the pruned model. To our
best knowledge, it is the first time that CNN interpretability theory is
considered to guide channel pruning. Extensive experiments on representative
image classification tasks demonstrate the superiority of our White-Box over
many state-of-the-arts. For instance, on CIFAR-10, it reduces 65.23% FLOPs with
even 0.62% accuracy improvement for ResNet-110. On ILSVRC-2012, White-Box
achieves a 45.6% FLOPs reduction with only a small loss of 0.83% in the top-1
accuracy for ResNet-50.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning. (arXiv:2105.04906v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04906">
<div class="article-summary-box-inner">
<span><p>Recent self-supervised methods for image representation learning are based on
maximizing the agreement between embedding vectors from different views of the
same image. A trivial solution is obtained when the encoder outputs constant
vectors. This collapse problem is often avoided through implicit biases in the
learning architecture, that often lack a clear justification or interpretation.
In this paper, we introduce VICReg (Variance-Invariance-Covariance
Regularization), a method that explicitly avoids the collapse problem with a
simple regularization term on the variance of the embeddings along each
dimension individually. VICReg combines the variance term with a decorrelation
mechanism based on redundancy reduction and covariance regularization, and
achieves results on par with the state of the art on several downstream tasks.
In addition, we show that incorporating our new variance term into other
methods helps stabilize the training and leads to performance improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hidden Markov Modeling for Maximum Likelihood Neuron Reconstruction. (arXiv:2106.02701v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02701">
<div class="article-summary-box-inner">
<span><p>Recent advances in brain clearing and imaging have made it possible to image
entire mammalian brains at sub-micron resolution. These images offer the
potential to assemble brain-wide atlases of neuron morphology, but manual
neuron reconstruction remains a bottleneck. Several automatic reconstruction
algorithms exist, but most focus on single neuron images. In this paper, we
present a probabilistic reconstruction method, ViterBrain, which combines a
hidden Markov state process that encodes neuron geometry with a random field
appearance model of neuron fluorescence. Our method utilizes dynamic
programming to compute the global maximizers of what we call the "most
probable" neuron path. Our most probable estimation method models the task of
reconstructing neuronal processes in the presence of other neurons, and thus is
applicable in images with several neurons. Our method operates on image
segmentations in order to leverage cutting edge computer vision technology. We
applied our algorithm to imperfect image segmentations where false negatives
severed neuronal processes, and showed that it can follow axons in the presence
of noise or nearby neurons. Additionally, it creates a framework where users
can intervene to, for example, fit start and endpoints. The code used in this
work is available in our open-source Python package brainlit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional COT-GAN for Video Prediction with Kernel Smoothing. (arXiv:2106.05658v2 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05658">
<div class="article-summary-box-inner">
<span><p>Causal Optimal Transport (COT) results from imposing a temporal causality
constraint on classic optimal transport problems, which naturally generates a
new concept of distances between distributions on path spaces. The first
application of the COT theory for sequential learning was given in Xu et al.
(2020), where COT-GAN was introduced as an adversarial algorithm to train
implicit generative models optimized for producing sequential data. Relying on
(Xu et al., 2020), the contribution of the present paper is twofold. First, we
develop a conditional version of COT-GAN suitable for sequence prediction. This
means that the dataset is now used in order to learn how a sequence will evolve
given the observation of its past evolution. Second, we improve on the
convergence results by working with modifications of the empirical measures via
kernel smoothing due to (Pflug and Pichler (2016)). The resulting kernel
conditional COT-GAN algorithm is illustrated with an application for video
prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Steerable 3D Spherical Neurons. (arXiv:2106.13863v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13863">
<div class="article-summary-box-inner">
<span><p>Emerging from low-level vision theory, steerable filters found their
counterpart in prior work on steerable convolutional neural networks
equivariant to rigid transformations. In our work, we propose a steerable
feed-forward learning-based approach that consists of neurons with spherical
decision surfaces and operates on point clouds. Such spherical neurons are
obtained by conformal embedding of Euclidean space and have recently been
revisited in the context of learning representations of point sets. Focusing on
3D geometry, we exploit the isometry property of spherical neurons and derive a
3D steerability constraint. After training spherical neurons to classify point
clouds in a canonical orientation, we use a tetrahedron basis to quadruplicate
the neurons and construct rotation-equivariant spherical filter banks. We then
apply the derived constraint to interpolate the filter bank outputs and, thus,
obtain a rotation-invariant network. Finally, we use a synthetic point set and
real-world 3D skeleton data to verify our theoretical findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Convolution for Re-ranking in Person Re-identification. (arXiv:2107.02220v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02220">
<div class="article-summary-box-inner">
<span><p>Nowadays, deep learning is widely applied to extract features for similarity
computation in person re-identification (re-ID) and have achieved great
success. However, due to the non-overlapping between training and testing IDs,
the difference between the data used for model training and the testing data
makes the performance of learned feature degraded during testing. Hence,
re-ranking is proposed to mitigate this issue and various algorithms have been
developed. However, most of existing re-ranking methods focus on replacing the
Euclidean distance with sophisticated distance metrics, which are not friendly
to downstream tasks and hard to be used for fast retrieval of massive data in
real applications. In this work, we propose a graph-based re-ranking method to
improve learned features while still keeping Euclidean distance as the
similarity metric. Inspired by graph convolution networks, we develop an
operator to propagate features over an appropriate graph. Since graph is the
essential key for the propagation, two important criteria are considered for
designing the graph, and three different graphs are explored accordingly.
Furthermore, a simple yet effective method is proposed to generate a profile
vector for each tracklet in videos, which helps extend our method to video
re-ID. Extensive experiments on three benchmark data sets, e.g., Market-1501,
Duke, and MARS, demonstrate the effectiveness of our proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few Shots Are All You Need: A Progressive Few Shot Learning Approach for Low Resource Handwriting Recognition. (arXiv:2107.10064v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10064">
<div class="article-summary-box-inner">
<span><p>Handwritten text recognition in low resource scenarios, such as manuscripts
with rare alphabets, is a challenging problem. The main difficulty comes from
the very few annotated data and the limited linguistic information (e.g.
dictionaries and language models). Thus, we propose a few-shot learning-based
handwriting recognition approach that significantly reduces the human labor
annotation process, requiring only few images of each alphabet symbol. The
method consists in detecting all the symbols of a given alphabet in a textline
image and decoding the obtained similarity scores to the final sequence of
transcribed symbols. Our model is first pretrained on synthetic line images
generated from any alphabet, even though different from the target domain. A
second training step is then applied to diminish the gap between the source and
target data. Since this retraining would require annotation of thousands of
handwritten symbols together with their bounding boxes, we propose to avoid
such human effort through an unsupervised progressive learning approach that
automatically assigns pseudo-labels to the non-annotated data. The evaluation
on different manuscript datasets show that our model can lead to competitive
results with a significant reduction in human effort. The code will be publicly
available in this repository: \url{https://github.com/dali92002/HTRbyMatching}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting of Head Pose Estimation by Knowledge Distillation. (arXiv:2108.09183v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09183">
<div class="article-summary-box-inner">
<span><p>We propose a response-based method of knowledge distillation (KD) for the
head pose estimation problem. A student model trained by the proposed KD
achieves results better than a teacher model, which is atypical for the
response-based method. Our method consists of two stages. In the first stage,
we trained the base neural network (NN), which has one regression head and four
regression via classification (RvC) heads. We build the convolutional ensemble
over the base NN using offsets of face bounding boxes over a regular grid. In
the second stage, we perform KD from the convolutional ensemble into the final
NN with one RvC head. The KD improves the results by an average of 7.7\%
compared to base NN. This feature makes it possible to use KD as a booster and
effectively train deeper NNs. NNs trained by our KD method partially improved
the state-of-the-art results. KD-ResNet152 has the best results, and
KD-ResNet18 has a better result on the AFLW2000 dataset than any previous
method.We have made publicly available trained NNs and face bounding boxes for
the 300W-LP, AFLW, AFLW2000, and BIWI datasets.Our method potentially can be
effective for other regression problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KTVQA: Generalized use of External Knowledge to empower Scene Text in Text-VQA. (arXiv:2108.09717v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09717">
<div class="article-summary-box-inner">
<span><p>The open-ended question answering task of Text-VQA requires reading and
reasoning about local, often previously unseen, scene-text content of an image.
We address this zero-shot nature of the problem by proposing the generalized
use of external knowledge to augment our understanding of the said scene-text.
We design a framework to extract, validate, and reason with knowledge using a
standard multimodal transformer for vision language understanding tasks.
Through empirical evidence and qualitative results, we demonstrate how external
knowledge can highlight instance-only cues and thus help deal with training
data bias, improve answer entity type correctness, and detect multiword named
entities. We generate results comparable to the state-of-the-art on three
publicly available datasets, under the constraints of similar upstream OCR
systems and training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks. (arXiv:2108.11845v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11845">
<div class="article-summary-box-inner">
<span><p>This letter is concerned with image classification with deep convolutional
neural networks (CNNs). The focus is on the following question: given a set of
candidate CNN models, how to select the right one with the best generalization
property for the current task? Present model selection methods require access
to a batch of labeled data for computing a pre-specified performance metric,
such as the cross-entropy loss, the classification error rate, the negative
log-likelihood. In many practical cases, labels are not available in time as
labeling itself is a time-consuming and expensive task. To this end, this
letter presents an approach to CNN model selection using only unlabeled data.
This method is developed based on a principle termed consistent relative
confidence. The effectiveness and efficiency of the proposed method are
demonstrated by experiments using benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InSeGAN: A Generative Approach to Segmenting Identical Instances in Depth Images. (arXiv:2108.13865v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13865">
<div class="article-summary-box-inner">
<span><p>In this paper, we present InSeGAN, an unsupervised 3D generative adversarial
network (GAN) for segmenting (nearly) identical instances of rigid objects in
depth images. Using an analysis-by-synthesis approach, we design a novel GAN
architecture to synthesize a multiple-instance depth image with independent
control over each instance. InSeGAN takes in a set of code vectors (e.g.,
random noise vectors), each encoding the 3D pose of an object that is
represented by a learned implicit object template. The generator has two
distinct modules. The first module, the instance feature generator, uses each
encoded pose to transform the implicit template into a feature map
representation of each object instance. The second module, the depth image
renderer, aggregates all of the single-instance feature maps output by the
first module and generates a multiple-instance depth image. A discriminator
distinguishes the generated multiple-instance depth images from the
distribution of true depth images. To use our model for instance segmentation,
we propose an instance pose encoder that learns to take in a generated depth
image and reproduce the pose code vectors for all of the object instances. To
evaluate our approach, we introduce a new synthetic dataset, "Insta-10",
consisting of 100,000 depth images, each with 5 instances of an object from one
of 10 classes. Our experiments on Insta-10, as well as on real-world noisy
depth images, show that InSeGAN achieves state-of-the-art performance, often
outperforming prior methods by large margins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Blood vessel segmentation in en-face OCTA images: a frequency based method. (arXiv:2109.06116v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06116">
<div class="article-summary-box-inner">
<span><p>Optical coherence tomography angiography (OCTA) is a novel noninvasive
imaging modality for visualization of retinal blood flow in the human retina.
Using specific OCTA imaging biomarkers for the identification of pathologies,
automated image segmentations of the blood vessels can improve subsequent
analysis and diagnosis. We present a novel segmentation method for vessel
density identification based on frequency representations of the image, in
particular, using so-called Gabor filter banks. The algorithm is evaluated
qualitatively and quantitatively on an OCTA image in-house data set from $10$
eyes acquired by a Cirrus HD-OCT device. Qualitatively, the segmentation
outcomes received very good visual evaluation feedback by experts.
Quantitatively, we compared the resulting vessel density values with automated
in-built values provided by the device. The results underline the visual
evaluation. For the evaluation of the FAZ identification substep, manual
annotations of $2$ expert graders were used, showing that our results coincide
well in visual and quantitative manners. Lastly, we suggest the computation of
adaptive local vessel density maps that allow straightforward analysis of
retinal blood flow in a local manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modern Evolution Strategies for Creativity: Fitting Concrete Images and Abstract Concepts. (arXiv:2109.08857v2 [cs.NE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08857">
<div class="article-summary-box-inner">
<span><p>Evolutionary algorithms have been used in the digital art scene since the
1970s. A popular application of genetic algorithms is to optimize the
procedural placement of vector graphic primitives to resemble a given painting.
In recent years, deep learning-based approaches have also been proposed to
generate procedural drawings, which can be optimized using gradient descent. In
this work, we revisit the use of evolutionary algorithms for computational
creativity. We find that modern evolution strategies (ES) algorithms, when
tasked with the placement of shapes, offer large improvements in both quality
and efficiency compared to traditional genetic algorithms, and even comparable
to gradient-based methods. We demonstrate that ES is also well suited at
optimizing the placement of shapes to fit the CLIP model, and can produce
diverse, distinct geometric abstractions that are aligned with human
interpretation of language. Videos and demo: https://es-clip.github.io/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DAAS: Differentiable Architecture and Augmentation Policy Search. (arXiv:2109.15273v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.15273">
<div class="article-summary-box-inner">
<span><p>Neural architecture search (NAS) has been an active direction of automatic
machine learning (Auto-ML), aiming to explore efficient network structures. The
searched architecture is evaluated by training on datasets with fixed data
augmentation policies. However, recent works on auto-augmentation show that the
suited augmentation policies can vary over different structures. Therefore,
this work considers the possible coupling between neural architectures and data
augmentation and proposes an effective algorithm jointly searching for them.
Specifically, 1) for the NAS task, we adopt a single-path based differentiable
method with Gumbel-softmax reparameterization strategy due to its memory
efficiency; 2) for the auto-augmentation task, we introduce a novel search
method based on policy gradient algorithm, which can significantly reduce the
computation complexity. Our approach achieves 97.91% accuracy on CIFAR-10 and
76.6% Top-1 accuracy on ImageNet dataset, showing the outstanding performance
of our search algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Thing to Fool them All: Generating Interpretable, Universal, and Physically-Realizable Adversarial Features. (arXiv:2110.03605v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03605">
<div class="article-summary-box-inner">
<span><p>It is well understood that modern deep networks are vulnerable to adversarial
attacks. However, conventional attack methods fail to produce adversarial
perturbations that are intelligible to humans, and they pose limited threats in
the physical world. To study feature-class associations in networks and better
understand their vulnerability to attacks in the real world, we develop
feature-level adversarial perturbations using deep image generators and a novel
optimization objective. We term these feature-fool attacks. We show that they
are versatile and use them to generate targeted feature-level attacks at the
ImageNet scale that are simultaneously interpretable, universal to any source
image, and physically-realizable. These attacks reveal spurious,
semantically-describable feature/class associations that can be exploited by
novel combinations of objects. We use them to guide the design of "copy/paste"
adversaries in which one natural image is pasted into another to cause a
targeted misclassification. Code is available at
https://github.com/thestephencasper/feature_fool.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Roadmap on Signal Processing for Next Generation Measurement Systems. (arXiv:2111.02493v3 [eess.SP] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02493">
<div class="article-summary-box-inner">
<span><p>Signal processing is a fundamental component of almost any sensor-enabled
system, with a wide range of applications across different scientific
disciplines. Time series data, images, and video sequences comprise
representative forms of signals that can be enhanced and analysed for
information extraction and quantification. The recent advances in artificial
intelligence and machine learning are shifting the research attention towards
intelligent, data-driven, signal processing. This roadmap presents a critical
overview of the state-of-the-art methods and applications aiming to highlight
future challenges and research opportunities towards next generation
measurement systems. It covers a broad spectrum of topics ranging from basic to
industrial research, organized in concise thematic sections that reflect the
trends and the impacts of current and future developments per research field.
Furthermore, it offers guidance to researchers and funding agencies in
identifying new prospects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeltaConv: Anisotropic Geometric Deep Learning with Exterior Calculus. (arXiv:2111.08799v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08799">
<div class="article-summary-box-inner">
<span><p>Learning from 3D point-cloud data has rapidly gained momentum, motivated by
the success of deep learning on images and the increased availability of 3D
data. In this paper, we aim to construct anisotropic convolutions that work
directly on the surface derived from a point cloud. This is challenging because
of the lack of a global coordinate system for tangential directions on
surfaces. We introduce a new convolution operator called DeltaConv, which
combines geometric operators from exterior calculus to enable the construction
of anisotropic filters on point clouds. Because these operators are defined on
scalar- and vector-fields, we separate the network into a scalar- and a
vector-stream, which are connected by the operators. The vector stream enables
the network to explicitly represent, evaluate, and process directional
information. Our convolutions are robust and simple to implement and show
improved accuracy compared to state-of-the-art approaches on several
benchmarks, while also speeding up training and inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. (arXiv:2111.08851v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08851">
<div class="article-summary-box-inner">
<span><p>In recent times, deep neural networks achieved outstanding predictive
performance on various classification and pattern recognition tasks. However,
many real-world prediction problems have ordinal response variables, and this
ordering information is ignored by conventional classification losses such as
the multi-category cross-entropy. Ordinal regression methods for deep neural
networks address this. One such method is the CORAL method, which is based on
an earlier binary label extension framework and achieves rank consistency among
its output layer tasks by imposing a weight-sharing constraint. However, while
earlier experiments showed that CORAL's rank consistency is beneficial for
performance, the weight-sharing constraint could severely restrict the
expressiveness of a deep neural network. In this paper, we propose an
alternative method for rank-consistent ordinal regression that does not require
a weight-sharing constraint in a neural network's fully connected output layer.
We achieve this rank consistency by a novel training scheme using conditional
training sets to obtain the unconditional rank probabilities through applying
the chain rule for conditional probability distributions. Experiments on
various datasets demonstrate the efficacy of the proposed method to utilize the
ordinal target information, and the absence of the weight-sharing restriction
improves the performance substantially compared to the CORAL reference
approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hamiltonian Operator Disentanglement of Content and Motion in Image Sequences. (arXiv:2112.01641v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01641">
<div class="article-summary-box-inner">
<span><p>We introduce a deep generative model for image sequences that reliably
factorise the latent space into content and motion variables. To model the
diverse dynamics, we split the motion space into subspaces and introduce a
unique Hamiltonian operator for each subspace. The Hamiltonian formulation
provides reversible dynamics that constrain the evolution of the motion path
along the low-dimensional manifold and conserves learnt invariant properties.
The explicit split of the motion space decomposes the Hamiltonian into symmetry
groups and gives long-term separability of the dynamics. This split also means
we can learn content representations that are easy to interpret and control. We
demonstrate the utility of our model by swapping the motion of two videos,
generating long term sequences of various actions from a given image,
unconditional sequence generation and image rotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Action Units That Constitute Trainable Micro-expressions (and A Large-scale Synthetic Dataset). (arXiv:2112.01730v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01730">
<div class="article-summary-box-inner">
<span><p>Because of the expensive data collection process, micro-expression (MiE)
datasets are generally much smaller in scale than those in other computer
vision fields, rendering large-scale training less feasible. This paper
develops a protocol to automatically synthesize MiE training data that 1) are
of a large scale and 2) allow us to train accurate recognition models for
real-world test data. Specifically, we discover three types of Action Units
(AUs) that can constitute trainable MiEs. These AUs come from real-world MiEs,
early frames of macro-expression videos, and the relationship between AUs and
expression categories defined by human expert knowledge. With these AUs, our
protocol then employs large numbers of face images of various identities and an
off-the-shelf face generator for MiE synthesis, yielding the MiE-X dataset. MiE
recognition models are trained or pre-trained on MiE-X and evaluated on
real-world test sets, where competitive accuracy is obtained. Experimental
results not only validate the effectiveness of these AUs and our MiE-X dataset
but also reveal some critical properties of MiEs: they generalize across faces,
are close to early-stage macro-expressions, and can be manually defined.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Curse of Zero Task Diversity: On the Failure of Transfer Learning to Outperform MAML and their Empirical Equivalence. (arXiv:2112.13121v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13121">
<div class="article-summary-box-inner">
<span><p>Recently, it has been observed that a transfer learning solution might be all
we need to solve many few-shot learning benchmarks -- thus raising important
questions about when and how meta-learning algorithms should be deployed. In
this paper, we seek to clarify these questions by proposing a novel metric --
the diversity coefficient -- to measure the diversity of tasks in a few-shot
learning benchmark. We hypothesize that the diversity coefficient of the
few-shot learning benchmark is predictive of whether meta-learning solutions
will succeed or not. Using the diversity coefficient, we show that the
MiniImagenet benchmark has zero diversity. This novel insight contextualizes
claims that transfer learning solutions are better than meta-learned solutions.
Specifically, we empirically find that a diversity coefficient of zero
correlates with a high similarity between transfer learning and Model-Agnostic
Meta-Learning (MAML) learned solutions in terms of meta-accuracy (at meta-test
time). Therefore, we conjecture meta-learned solutions have the same meta-test
performance as transfer learning when the diversity coefficient is zero. Our
work provides the first test of whether diversity correlates with meta-learning
success.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Block Walsh-Hadamard Transform Based Binary Layers in Deep Neural Networks. (arXiv:2201.02711v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02711">
<div class="article-summary-box-inner">
<span><p>Convolution has been the core operation of modern deep neural networks. It is
well-known that convolutions can be implemented in the Fourier Transform
domain. In this paper, we propose to use binary block Walsh-Hadamard transform
(WHT) instead of the Fourier transform. We use WHT-based binary layers to
replace some of the regular convolution layers in deep neural networks. We
utilize both one-dimensional (1-D) and two-dimensional (2-D) binary WHTs in
this paper. In both 1-D and 2-D layers, we compute the binary WHT of the input
feature map and denoise the WHT domain coefficients using a nonlinearity which
is obtained by combining soft-thresholding with the tanh function. After
denoising, we compute the inverse WHT. We use 1D-WHT to replace the $1\times 1$
convolutional layers, and 2D-WHT layers can replace the 3$\times$3 convolution
layers and Squeeze-and-Excite layers. 2D-WHT layers with trainable weights can
be also inserted before the Global Average Pooling (GAP) layers to assist the
dense layers. In this way, we can reduce the number of trainable parameters
significantly with a slight decrease in trainable parameters. In this paper, we
implement the WHT layers into MobileNet-V2, MobileNet-V3-Large, and ResNet to
reduce the number of parameters significantly with negligible accuracy loss.
Moreover, according to our speed test, the 2D-FWHT layer runs about 24 times as
fast as the regular $3\times 3$ convolution with 19.51\% less RAM usage in an
NVIDIA Jetson Nano experiment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Sneak Attack on Segmentation of Medical Images Using Deep Neural Network Classifiers. (arXiv:2201.02771v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02771">
<div class="article-summary-box-inner">
<span><p>Instead of using current deep-learning segmentation models (like the UNet and
variants), we approach the segmentation problem using trained Convolutional
Neural Network (CNN) classifiers, which automatically extract important
features from images for classification. Those extracted features can be
visualized and formed into heatmaps using Gradient-weighted Class Activation
Mapping (Grad-CAM). This study tested whether the heatmaps could be used to
segment the classified targets. We also proposed an evaluation method for the
heatmaps; that is, to re-train the CNN classifier using images filtered by
heatmaps and examine its performance. We used the mean-Dice coefficient to
evaluate segmentation results. Results from our experiments show that heatmaps
can locate and segment partial tumor areas. But use of only the heatmaps from
CNN classifiers may not be an optimal approach for segmentation. We have
verified that the predictions of CNN classifiers mainly depend on tumor areas,
and dark regions in Grad-CAM's heatmaps also contribute to classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DCNGAN: A Deformable Convolutional-Based GAN with QP Adaptation for Perceptual Quality Enhancement of Compressed Video. (arXiv:2201.08944v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08944">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a deformable convolution-based generative
adversarial network (DCNGAN) for perceptual quality enhancement of compressed
videos. DCNGAN is also adaptive to the quantization parameters (QPs). Compared
with optical flows, deformable convolutions are more effective and efficient to
align frames. Deformable convolutions can operate on multiple frames, thus
leveraging more temporal information, which is beneficial for enhancing the
perceptual quality of compressed videos. Instead of aligning frames in a
pairwise manner, the deformable convolution can process multiple frames
simultaneously, which leads to lower computational complexity. Experimental
results demonstrate that the proposed DCNGAN outperforms other state-of-the-art
compressed video quality enhancement algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReconFormer: Accelerated MRI Reconstruction Using Recurrent Transformer. (arXiv:2201.09376v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09376">
<div class="article-summary-box-inner">
<span><p>Accelerating magnetic resonance image (MRI) reconstruction process is a
challenging ill-posed inverse problem due to the excessive under-sampling
operation in k-space. In this paper, we propose a recurrent transformer model,
namely ReconFormer, for MRI reconstruction which can iteratively reconstruct
high fertility magnetic resonance images from highly under-sampled k-space
data. In particular, the proposed architecture is built upon Recurrent Pyramid
Transformer Layers (RPTL), which jointly exploits intrinsic multi-scale
information at every architecture unit as well as the dependencies of the deep
feature correlation through recurrent states. Moreover, the proposed
ReconFormer is lightweight since it employs the recurrent structure for its
parameter efficiency. We validate the effectiveness of ReconFormer on multiple
datasets with different magnetic resonance sequences and show that it achieves
significant improvements over the state-of-the-art methods with better
parameter efficiency. Implementation code will be available in
https://github.com/guopengf/ReconFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparison of Evaluation Metrics for Landmark Detection in CMR Images. (arXiv:2201.10410v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10410">
<div class="article-summary-box-inner">
<span><p>Cardiac Magnetic Resonance (CMR) images are widely used for cardiac diagnosis
and ventricular assessment. Extracting specific landmarks like the right
ventricular insertion points is of importance for spatial alignment and 3D
modeling. The automatic detection of such landmarks has been tackled by
multiple groups using Deep Learning, but relatively little attention has been
paid to the failure cases of evaluation metrics in this field. In this work, we
extended the public ACDC dataset with additional labels of the right
ventricular insertion points and compare different variants of a heatmap-based
landmark detection pipeline. In this comparison, we demonstrate very likely
pitfalls of apparently simple detection and localisation metrics which
highlights the importance of a clear detection strategy and the definition of
an upper limit for localisation-based metrics. Our preliminary results indicate
that a combination of different metrics is necessary, as they yield different
winners for method comparison. Additionally, they highlight the need of a
comprehensive metric description and evaluation standardisation, especially for
the error cases where no metrics could be computed or where no lower/upper
boundary of a metric exists. Code and labels:
https://github.com/Cardio-AI/rvip_landmark_detection
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Class-Aware Generative Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10737">
<div class="article-summary-box-inner">
<span><p>Transformers have made remarkable progress towards modeling long-range
dependencies within the medical image analysis domain. However, current
transformer-based models suffer from several disadvantages: (1) existing
methods fail to capture the important features of the images due to the naive
tokenization scheme; (2) the models suffer from information loss because they
only consider single-scale feature representations; and (3) the segmentation
label maps generated by the models are not accurate enough without considering
rich semantic contexts and anatomical textures. In this work, we present
CA-GANformer, a novel type of generative adversarial transformers, for medical
image segmentation. First, we take advantage of the pyramid structure to
construct multi-scale representations and handle multi-scale variations. We
then design a novel class-aware transformer module to better learn the
discriminative regions of objects with semantic structures. Lastly, we utilize
an adversarial training strategy that boosts segmentation accuracy and
correspondingly allows a transformer-based discriminator to capture high-level
semantically correlated contents and low-level anatomical features. Our
experiments demonstrate that CA-GANformer dramatically outperforms previous
state-of-the-art transformer-based approaches on three benchmarks, obtaining
2.54%-5.88% absolute improvements in Dice over previous models. Further
qualitative experiments provide a more detailed picture of the model's inner
workings, shed light on the challenges in improved transparency, and
demonstrate that transfer learning can greatly improve performance and reduce
the size of medical image datasets in training, making CA-GANformer a strong
starting point for downstream medical image analysis tasks. Codes and models
will be available to the public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Checklist: Towards Testable Error Analysis of Image Models to Help System Designers Interrogate Model Capabilities. (arXiv:2201.11674v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11674">
<div class="article-summary-box-inner">
<span><p>Using large pre-trained models for image recognition tasks is becoming
increasingly common owing to the well acknowledged success of recent models
like vision transformers and other CNN-based models like VGG and Resnet. The
high accuracy of these models on benchmark tasks has translated into their
practical use across many domains including safety-critical applications like
autonomous driving and medical diagnostics. Despite their widespread use, image
models have been shown to be fragile to changes in the operating environment,
bringing their robustness into question. There is an urgent need for methods
that systematically characterise and quantify the capabilities of these models
to help designers understand and provide guarantees about their safety and
robustness. In this paper, we propose Vision Checklist, a framework aimed at
interrogating the capabilities of a model in order to produce a report that can
be used by a system designer for robustness evaluations. This framework
proposes a set of perturbation operations that can be applied on the underlying
data to generate test samples of different types. The perturbations reflect
potential changes in operating environments, and interrogate various properties
ranging from the strictly quantitative to more qualitative. Our framework is
evaluated on multiple datasets like Tinyimagenet, CIFAR10, CIFAR100 and
Camelyon17 and for models like ViT and Resnet. Our Vision Checklist proposes a
specific set of evaluations that can be integrated into the previously proposed
concept of a model card. Robustness evaluations like our checklist will be
crucial in future safety evaluations of visual perception modules, and be
useful for a wide range of stakeholders including designers, deployers, and
regulators involved in the certification of these systems. Source code of
Vision Checklist would be open for public use.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-01-31 23:07:05.544108391 UTC">2022-01-31 23:07:05 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>