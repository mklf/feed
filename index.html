<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-01-14T01:30:00Z">01-14</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">How Can Graph Neural Networks Help Document Retrieval: A Case Study on CORD19 with Concept Map Generation. (arXiv:2201.04672v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04672">
<div class="article-summary-box-inner">
<span><p>Graph neural networks (GNNs), as a group of powerful tools for representation
learning on irregular data, have manifested superiority in various downstream
tasks. With unstructured texts represented as concept maps, GNNs can be
exploited for tasks like document retrieval. Intrigued by how can GNNs help
document retrieval, we conduct an empirical study on a large-scale
multi-discipline dataset CORD-19. Results show that instead of the complex
structure-oriented GNNs such as GINs and GATs, our proposed semantics-oriented
graph functions achieve better and more stable performance based on the BM25
retrieved candidates. Our insights in this case study can serve as a guideline
for future work to develop effective GNNs with appropriate semantics-oriented
inductive biases for textual reasoning tasks like document retrieval and
classification. All code for this case study is available at
https://github.com/HennyJie/GNN-DocRetrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Evaluation of Conversations is an Open Problem: comparing the sensitivity of various methods for evaluating dialogue agents. (arXiv:2201.04723v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04723">
<div class="article-summary-box-inner">
<span><p>At the heart of improving conversational AI is the open problem of how to
evaluate conversations. Issues with automatic metrics are well known (Liu et
al., 2016, <a href="/abs/1603.08023">arXiv:1603.08023</a>), with human evaluations still considered the gold
standard. Unfortunately, how to perform human evaluations is also an open
problem: differing data collection methods have varying levels of human
agreement and statistical sensitivity, resulting in differing amounts of human
annotation hours and labor costs. In this work we compare five different
crowdworker-based human evaluation methods and find that different methods are
best depending on the types of models compared, with no clear winner across the
board. While this highlights the open problems in the area, our analysis leads
to advice of when to use which one, and possible future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognizing semantic relation in sentence pairs using Tree-RNNs and Typed dependencies. (arXiv:2201.04810v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04810">
<div class="article-summary-box-inner">
<span><p>Recursive neural networks (Tree-RNNs) based on dependency trees are
ubiquitous in modeling sentence meanings as they effectively capture semantic
relationships between non-neighborhood words. However, recognizing semantically
dissimilar sentences with the same words and syntax is still a challenge to
Tree-RNNs. This work proposes an improvement to Dependency Tree-RNN (DT-RNN)
using the grammatical relationship type identified in the dependency parse. Our
experiments on semantic relatedness scoring (SRS) and recognizing textual
entailment (RTE) in sentence pairs using SICK (Sentence Involving Compositional
Knowledge) dataset show encouraging results. The model achieved a 2%
improvement in classification accuracy for the RTE task over the DT-RNN model.
The results show that Pearson's and Spearman's correlation measures between the
model's predicted similarity scores and human ratings are higher than those of
standard DT-RNNs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Document-level Relation Extraction with Context Guided Mention Integration and Inter-pair Reasoning. (arXiv:2201.04826v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04826">
<div class="article-summary-box-inner">
<span><p>Document-level Relation Extraction (DRE) aims to recognize the relations
between two entities. The entity may correspond to multiple mentions that span
beyond sentence boundary. Few previous studies have investigated the mention
integration, which may be problematic because coreferential mentions do not
equally contribute to a specific relation. Moreover, prior efforts mainly focus
on reasoning at entity-level rather than capturing the global interactions
between entity pairs. In this paper, we propose two novel techniques, Context
Guided Mention Integration and Inter-pair Reasoning (CGM2IR), to improve the
DRE. Instead of simply applying average pooling, the contexts are utilized to
guide the integration of coreferential mentions in a weighted sum manner.
Additionally, inter-pair reasoning executes an iterative algorithm on the
entity pair graph, so as to model the interdependency of relations. We evaluate
our CGM2IR model on three widely used benchmark datasets, namely DocRED, CDR,
and GDA. Experimental results show that our model outperforms previous
state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graph Augmented Network Towards Multiview Representation Learning for Aspect-based Sentiment Analysis. (arXiv:2201.04831v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04831">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis (ABSA) is a fine-grained task of sentiment
analysis. To better comprehend long complicated sentences and obtain accurate
aspect-specific information, linguistic and commonsense knowledge are generally
required in this task. However, most methods employ complicated and inefficient
approaches to incorporate external knowledge, e.g., directly searching the
graph nodes. Additionally, the complementarity between external knowledge and
linguistic information has not been thoroughly studied. To this end, we propose
a knowledge graph augmented network (KGAN), which aims to effectively
incorporate external knowledge with explicitly syntactic and contextual
information. In particular, KGAN captures the sentiment feature representations
from multiple different perspectives, i.e., context-, syntax- and
knowledge-based. First, KGAN learns the contextual and syntactic
representations in parallel to fully extract the semantic features. Then, KGAN
integrates the knowledge graphs into the embedding space, based on which the
aspect-specific knowledge representations are further obtained via an attention
mechanism. Last, we propose a hierarchical fusion module to complement these
multiview representations in a local-to-global manner. Extensive experiments on
three popular ABSA benchmarks demonstrate the effectiveness and robustness of
our KGAN. Notably, with the help of the pretrained model of RoBERTa, KGAN
achieves a new record of state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LP-BERT: Multi-task Pre-training Knowledge Graph BERT for Link Prediction. (arXiv:2201.04843v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04843">
<div class="article-summary-box-inner">
<span><p>Link prediction plays an significant role in knowledge graph, which is an
important resource for many artificial intelligence tasks, but it is often
limited by incompleteness. In this paper, we propose knowledge graph BERT for
link prediction, named LP-BERT, which contains two training stages: multi-task
pre-training and knowledge graph fine-tuning. The pre-training strategy not
only uses Mask Language Model (MLM) to learn the knowledge of context corpus,
but also introduces Mask Entity Model (MEM) and Mask Relation Model (MRM),
which can learn the relationship information from triples by predicting
semantic based entity and relation elements. Structured triple relation
information can be transformed into unstructured semantic information, which
can be integrated into the pre-training model together with context corpus
information. In the fine-tuning phase, inspired by contrastive learning, we
carry out a triple-style negative sampling in sample batch, which greatly
increased the proportion of negative sampling while keeping the training time
almost unchanged. Furthermore, we propose a data augmentation method based on
the inverse relationship of triples to further increase the sample diversity.
We achieve state-of-the-art results on WN18RR and UMLS datasets, especially the
Hits@10 indicator improved by 5\% from the previous state-of-the-art result on
WN18RR dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Data Analysis with Next-step Natural Language Query Recommendation. (arXiv:2201.04868v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04868">
<div class="article-summary-box-inner">
<span><p>Natural language interfaces (NLIs) provide users with a convenient way to
interactively analyze data through natural language queries. Nevertheless,
interactive data analysis is a demanding process, especially for novice data
analysts. When exploring large and complex datasets from different domains,
data analysts do not necessarily have sufficient knowledge about data and
application domains. It makes them unable to efficiently elicit a series of
queries and extensively derive desirable data insights. In this paper, we
develop an NLI with a step-wise query recommendation module to assist users in
choosing appropriate next-step exploration actions. The system adopts a
data-driven approach to generate step-wise semantically relevant and
context-aware query suggestions for application domains of users' interest
based on their query logs. Also, the system helps users organize query
histories and results into a dashboard to communicate the discovered data
insights. With a comparative user study, we show that our system can facilitate
a more effective and systematic data analysis process than a baseline without
the recommendation module.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Quadratic 0-1 Programming Approach for Word Sense Disambiguation. (arXiv:2201.04877v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04877">
<div class="article-summary-box-inner">
<span><p>Word Sense Disambiguation (WSD) is the task to determine the sense of an
ambiguous word in a given context. Previous approaches for WSD have focused on
supervised and knowledge-based methods, but inter-sense interactions patterns
or regularities for disambiguation remain to be found. We argue the following
cause as one of the major difficulties behind finding the right patterns: for a
particular context, the intended senses of a sequence of ambiguous words are
dependent on each other, i.e. the choice of one word's sense is associated with
the choice of another word's sense, making WSD a combinatorial optimization
problem.In this work, we approach the interactions between senses of different
target words by a Quadratic 0-1 Integer Programming model (QIP) that maximizes
the objective function consisting of (1) the similarity between candidate
senses of a target word and the word in a context (the sense-word similarity),
and (2) the semantic interactions (relatedness) between senses of all words in
the context (the sense-sense relatedness).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compressing Word Embeddings Using Syllables. (arXiv:2201.04913v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04913">
<div class="article-summary-box-inner">
<span><p>This work examines the possibility of using syllable embeddings, instead of
the often used $n$-gram embeddings, as subword embeddings. We investigate this
for two languages: English and Dutch. To this end, we also translated two
standard English word embedding evaluation datasets, WordSim353 and
SemEval-2017, to Dutch. Furthermore, we provide the research community with
data sets of syllabic decompositions for both languages. We compare our
approach to full word and $n$-gram embeddings. Compared to full word
embeddings, we obtain English models that are 20 to 30 times smaller while
retaining 80% of the performance. For Dutch, models are 15 times smaller for
70% performance retention. Although less accurate than the $n$-gram baseline we
used, our models can be trained in a matter of minutes, as opposed to hours for
the $n$-gram approach. We identify a path toward upgrading performance in
future work. All code is made publicly available, as well as our collected
English and Dutch syllabic decompositions and Dutch evaluation set
translations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Automated Error Analysis: Learning to Characterize Errors. (arXiv:2201.05017v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05017">
<div class="article-summary-box-inner">
<span><p>Characterizing the patterns of errors that a system makes helps researchers
focus future development on increasing its accuracy and robustness. We propose
a novel form of "meta learning" that automatically learns interpretable rules
that characterize the types of errors that a system makes, and demonstrate
these rules' ability to help understand and improve two NLP systems. Our
approach works by collecting error cases on validation data, extracting
meta-features describing these samples, and finally learning rules that
characterize errors using these features. We apply our approach to VilBERT, for
Visual Question Answering, and RoBERTa, for Common Sense Question Answering.
Our system learns interpretable rules that provide insights into systemic
errors these systems make on the given tasks. Using these insights, we are also
able to "close the loop" and modestly improve performance of these systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LARD: Large-scale Artificial Disfluency Generation. (arXiv:2201.05041v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05041">
<div class="article-summary-box-inner">
<span><p>Disfluency detection is a critical task in real-time dialogue systems.
However, despite its importance, it remains a relatively unexplored field,
mainly due to the lack of appropriate datasets. At the same time, existing
datasets suffer from various issues, including class imbalance issues, which
can significantly affect the performance of the model on rare classes, as it is
demonstrated in this paper. To this end, we propose LARD, a method for
generating complex and realistic artificial disfluencies with little effort.
The proposed method can handle three of the most common types of disfluencies:
repetitions, replacements and restarts. In addition, we release a new
large-scale dataset with disfluencies that can be used on four different tasks:
disfluency detection, classification, extraction and correction. Experimental
results on the LARD dataset demonstrate that the data produced by the proposed
method can be effectively used for detecting and removing disfluencies, while
also addressing limitations of existing datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Resources in the Tamasheq Language. (arXiv:2201.05051v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05051">
<div class="article-summary-box-inner">
<span><p>In this paper we present two datasets for Tamasheq, a developing language
mainly spoken in Mali and Niger. These two datasets were made available for the
IWSLT 2022 low-resource speech translation track, and they consist of
collections of radio recordings from the Studio Kalangou (Niger) and Studio
Tamani (Mali) daily broadcast news. We share (i) a massive amount of unlabeled
audio data (671 hours) in five languages: French from Niger, Fulfulde, Hausa,
Tamasheq and Zarma, and (ii) a smaller parallel corpus of audio recordings (17
hours) in Tamasheq, with utterance-level translations in the French language.
All this data is shared under the Creative Commons BY-NC-ND 3.0 license. We
hope these resources will inspire the speech community to develop and benchmark
models using the Tamasheq language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature-rich multiplex lexical networks reveal mental strategies of early language learning. (arXiv:2201.05061v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05061">
<div class="article-summary-box-inner">
<span><p>Knowledge in the human mind exhibits a dualistic vector/network nature.
Modelling words as vectors is key to natural language processing, whereas
networks of word associations can map the nature of semantic memory. We
reconcile these paradigms - fragmented across linguistics, psychology and
computer science - by introducing FEature-Rich MUltiplex LEXical (FERMULEX)
networks. This novel framework merges structural similarities in networks and
vector features of words, which can be combined or explored independently.
Similarities model heterogenous word associations across
semantic/syntactic/phonological aspects of knowledge. Words are enriched with
multi-dimensional feature embeddings including frequency, age of acquisition,
length and polysemy. These aspects enable unprecedented explorations of
cognitive knowledge. Through CHILDES data, we use FERMULEX networks to model
normative language acquisition by 1000 toddlers between 18 and 30 months.
Similarities and embeddings capture word homophily via conformity, which
measures assortative mixing via distance and features. Conformity unearths a
language kernel of frequent/polysemous/short nouns and verbs key for basic
sentence production, supporting recent evidence of children's syntactic
constructs emerging at 30 months. This kernel is invisible to network
core-detection and feature-only clustering: It emerges from the dual
vector/network nature of words. Our quantitative analysis reveals two key
strategies in early word learning. Modelling word acquisition as random walks
on FERMULEX topology, we highlight non-uniform filling of communicative
developmental inventories (CDIs). Conformity-based walkers lead to accurate
(75%), precise (55%) and partially well-recalled (34%) predictions of early
word learning in CDIs, providing quantitative support to previous empirical
findings and developmental theories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grow-and-Clip: Informative-yet-Concise Evidence Distillation for Answer Explanation. (arXiv:2201.05088v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05088">
<div class="article-summary-box-inner">
<span><p>Interpreting the predictions of existing Question Answering (QA) models is
critical to many real-world intelligent applications, such as QA systems for
healthcare, education, and finance. However, existing QA models lack
interpretability and provide no feedback or explanation for end-users to help
them understand why a specific prediction is the answer to a question.In this
research, we argue that the evidences of an answer is critical to enhancing the
interpretability of QA models. Unlike previous research that simply extracts
several sentence(s) in the context as evidence, we are the first to explicitly
define the concept of evidence as the supporting facts in a context which are
informative, concise, and readable. Besides, we provide effective strategies to
quantitatively measure the informativeness, conciseness and readability of
evidence. Furthermore, we propose Grow-and-Clip Evidence Distillation (GCED)
algorithm to extract evidences from the contexts by trade-off informativeness,
conciseness, and readability. We conduct extensive experiments on the SQuAD and
TriviaQA datasets with several baseline models to evaluate the effect of GCED
on interpreting answers to questions. Human evaluation are also carried out to
check the quality of distilled evidences. Experimental results show that
automatic distilled evidences have human-like informativeness, conciseness and
readability, which can enhance the interpretability of the answers to
questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NorDiaChange: Diachronic Semantic Change Dataset for Norwegian. (arXiv:2201.05123v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05123">
<div class="article-summary-box-inner">
<span><p>We describe NorDiaChange: the first diachronic semantic change dataset for
Norwegian. NorDiaChange comprises two novel subsets, covering about 80
Norwegian nouns manually annotated with graded semantic change over time. Both
datasets follow the same annotation procedure and can be used interchangeably
as train and test splits for each other. NorDiaChange covers the time periods
related to pre- and post-war events, oil and gas discovery in Norway, and
technological developments. The annotation was done using the DURel framework
and two large historical Norwegian corpora. NorDiaChange is published in full
under a permissive license, complete with raw annotation data and inferred
diachronic word usage graphs (DWUGs).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When FastText Pays Attention: Efficient Estimation of Word Representations using Constrained Positional Weighting. (arXiv:2104.09691v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09691">
<div class="article-summary-box-inner">
<span><p>In 2018, Mikolov et al. introduced the positional language model, which has
characteristics of attention-based neural machine translation models and which
achieved state-of-the-art performance on the intrinsic word analogy task.
However, the positional model is not practically fast and it has never been
evaluated on qualitative criteria or extrinsic tasks. We propose a constrained
positional model, which adapts the sparse attention mechanism from neural
machine translation to improve the speed of the positional model. We evaluate
the positional and constrained positional models on three novel qualitative
criteria and on language modeling. We show that the positional and constrained
positional models contain interpretable information about the grammatical
properties of words and outperform other shallow models on language modeling.
We also show that our constrained model outperforms the positional model on
language modeling and trains twice as fast.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Ackermannian lower bound for the Petri nets reachability problem. (arXiv:2105.08551v4 [cs.FL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08551">
<div class="article-summary-box-inner">
<span><p>Petri nets, equivalently presentable as vector addition systems with states,
are an established model of concurrency with widespread applications. The
reachability problem, where we ask whether from a given initial configuration
there exists a sequence of valid execution steps reaching a given final
configuration, is the central algorithmic problem for this model. The
complexity of the problem has remained, until recently, one of the hardest open
questions in verification of concurrent systems. A first upper bound has been
provided only in 2015 by Leroux and Schmitz, then refined by the same authors
to non-primitive recursive Ackermannian upper bound in 2019. The exponential
space lower bound, shown by Lipton already in 1976, remained the only known for
over 40 years until a breakthrough non-elementary lower bound by
Czerwi{\'n}ski, Lasota, Lazic, Leroux and Mazowiecki in 2019. Finally, a
matching Ackermannian lower bound announced this year by Czerwi{\'n}ski and
Orlikowski, and independently by Leroux, established the complexity of the
problem.
</p>
<p>Our primary contribution is an improvement of the former construction, making
it conceptually simpler and more direct. On the way we improve the lower bound
for vector addition systems with states in fixed dimension (or, equivalently,
Petri nets with fixed number of places): while Czerwi{\'n}ski and Orlikowski
prove $F_k$-hardness (hardness for $k$th level in Grzegorczyk Hierarchy) in
dimension $6k$, our simplified construction yields $F_k$-hardness already in
dimension $3k+2$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05426">
<div class="article-summary-box-inner">
<span><p>How related are the representations learned by neural language models,
translation models, and language tagging tasks? We answer this question by
adapting an encoder-decoder transfer learning method from computer vision to
investigate the structure among 100 different feature spaces extracted from
hidden representations of various networks trained on language tasks. This
method reveals a low-dimensional structure where language models and
translation models smoothly interpolate between word embeddings, syntactic and
semantic tasks, and future word embeddings. We call this low-dimensional
structure a language representation embedding because it encodes the
relationships between representations needed to process language for a variety
of NLP tasks. We find that this representation embedding can predict how well
each individual feature space maps to human brain responses to natural language
stimuli recorded using fMRI. Additionally, we find that the principal dimension
of this structure can be used to create a metric which highlights the brain's
natural language processing hierarchy. This suggests that the embedding
captures some part of the brain's natural language representation structure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLSRIL-23: Cross Lingual Speech Representations for Indic Languages. (arXiv:2107.07402v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07402">
<div class="article-summary-box-inner">
<span><p>We present a CLSRIL-23, a self supervised learning based audio pre-trained
model which learns cross lingual speech representations from raw audio across
23 Indic languages. It is built on top of wav2vec 2.0 which is solved by
training a contrastive task over masked latent speech representations and
jointly learns the quantization of latents shared across all languages. We
compare the language wise loss during pretraining to compare effects of
monolingual and multilingual pretraining. Performance on some downstream
fine-tuning tasks for speech recognition is also compared and our experiments
show that multilingual pretraining outperforms monolingual training, in terms
of learning speech representations which encodes phonetic similarity of
languages and also in terms of performance on down stream tasks. A decrease of
5% is observed in WER and 9.5% in CER when a multilingual pretrained model is
used for finetuning in Hindi. All the code models are also open sourced.
CLSRIL-23 is a model trained on $23$ languages and almost 10,000 hours of audio
data to facilitate research in speech recognition for Indic languages. We hope
that new state of the art systems will be created using the self supervised
approach, especially for low resources Indic languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Statistical Model of Word Rank Evolution. (arXiv:2107.09948v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09948">
<div class="article-summary-box-inner">
<span><p>The availability of large linguistic data sets enables data-driven approaches
to study linguistic change. The Google Books corpus unigram frequency data set
is used to investigate the word rank dynamics in eight languages. We observed
the rank changes of the unigrams from 1900 to 2008 and compared it to a
Wright-Fisher inspired model that we developed for our analysis. The model
simulates a neutral evolutionary process with the restriction of having no
disappearing and added words. This work explains the mathematical framework of
the model - written as a Markov Chain with multinomial transition probabilities
- to show how frequencies of words change in time. From our observations in the
data and our model, word rank stability shows two types of characteristics: (1)
the increase/decrease in ranks are monotonic, or (2) the rank stays the same.
Based on our model, high-ranked words tend to be more stable while low-ranked
words tend to be more volatile. Some words change in ranks in two ways: (a) by
an accumulation of small increasing/decreasing rank changes in time and (b) by
shocks of increase/decrease in ranks. Most words in all of the languages we
have looked at are rank stable, but not as stable as a neutral model would
predict. The stopwords and Swadesh words are observed to be rank stable across
eight languages indicating linguistic conformity in established languages.
These signatures suggest unigram frequencies in all languages have changed in a
manner inconsistent with a purely neutral evolutionary process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Self-Disclosure In Neural Dialog Models By Candidate Re-ranking. (arXiv:2109.05090v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05090">
<div class="article-summary-box-inner">
<span><p>Neural language modelling has progressed the state-of-the-art in different
downstream Natural Language Processing (NLP) tasks. One such area is of
open-domain dialog modelling, neural dialog models based on GPT-2 such as
DialoGPT have shown promising performance in single-turn conversation. However,
such (neural) dialog models have been criticized for generating responses which
although may have relevance to the previous human response, tend to quickly
dissipate human interest and descend into trivial conversation. One reason for
such performance is the lack of explicit conversation strategy being employed
in human-machine conversation. Humans employ a range of conversation strategies
while engaging in a conversation, one such key social strategies is
Self-disclosure(SD). A phenomenon of revealing information about one-self to
others. Social penetration theory (SPT) proposes that communication between two
people moves from shallow to deeper levels as the relationship progresses
primarily through self-disclosure. Disclosure helps in creating rapport among
the participants engaged in a conversation. In this paper, Self-disclosure
enhancement architecture (SDEA) is introduced utilizing Self-disclosure Topic
Model (SDTM) during inference stage of a neural dialog model to re-rank
response candidates to enhance self-disclosure in single-turn responses from
from the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Direct Simultaneous Speech-to-Speech Translation with Variational Monotonic Multihead Attention. (arXiv:2110.08250v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08250">
<div class="article-summary-box-inner">
<span><p>We present a direct simultaneous speech-to-speech translation (Simul-S2ST)
model, Furthermore, the generation of translation is independent from
intermediate text representations. Our approach leverages recent progress on
direct speech-to-speech translation with discrete units, in which a sequence of
discrete representations, instead of continuous spectrogram features, learned
in an unsupervised manner, are predicted from the model and passed directly to
a vocoder for speech synthesis on-the-fly. We also introduce the variational
monotonic multihead attention (V-MMA), to handle the challenge of inefficient
policy learning in speech simultaneous translation. The simultaneous policy
then operates on source speech features and target discrete units. We carry out
empirical studies to compare cascaded and direct approach on the Fisher
Spanish-English and MuST-C English-Spanish datasets. Direct simultaneous model
is shown to outperform the cascaded model by achieving a better tradeoff
between translation quality and latency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AequeVox: Automated Fairness Testing of Speech Recognition Systems. (arXiv:2110.09843v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09843">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Recognition (ASR) systems have become ubiquitous. They can
be found in a variety of form factors and are increasingly important in our
daily lives. As such, ensuring that these systems are equitable to different
subgroups of the population is crucial. In this paper, we introduce, AequeVox,
an automated testing framework for evaluating the fairness of ASR systems.
AequeVox simulates different environments to assess the effectiveness of ASR
systems for different populations. In addition, we investigate whether the
chosen simulations are comprehensible to humans. We further propose a fault
localization technique capable of identifying words that are not robust to
these varying environments. Both components of AequeVox are able to operate in
the absence of ground truth data.
</p>
<p>We evaluated AequeVox on speech from four different datasets using three
different commercial ASRs. Our experiments reveal that non-native English,
female and Nigerian English speakers generate 109%, 528.5% and 156.9% more
errors, on average than native English, male and UK Midlands speakers,
respectively. Our user study also reveals that 82.9% of the simulations
(employed through speech transformations) had a comprehensibility rating above
seven (out of ten), with the lowest rating being 6.78. This further validates
the fairness violations discovered by AequeVox. Finally, we show that the
non-robust words, as predicted by the fault localization technique embodied in
AequeVox, show 223.8% more errors than the predicted robust words across all
ASRs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SynthBio: A Case Study in Human-AI Collaborative Curation of Text Datasets. (arXiv:2111.06467v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.06467">
<div class="article-summary-box-inner">
<span><p>NLP researchers need more, higher-quality text datasets. Human-labeled
datasets are expensive to collect, while datasets collected via automatic
retrieval from the web such as WikiBio are noisy and can include undesired
biases. Moreover, data sourced from the web is often included in datasets used
to pretrain models, leading to inadvertent cross-contamination of training and
test sets. In this work we introduce a novel method for efficient dataset
curation: we use a large language model to provide seed generations to human
raters, thereby changing dataset authoring from a writing task to an editing
task. We use our method to curate SynthBio - a new evaluation set for WikiBio -
composed of structured attribute lists describing fictional individuals, mapped
to natural language biographies. We show that our dataset of fictional
biographies is less noisy than WikiBio, and also more balanced with respect to
gender and nationality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emojich -- zero-shot emoji generation using Russian language: a technical report. (arXiv:2112.02448v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.02448">
<div class="article-summary-box-inner">
<span><p>This technical report presents a text-to-image neural network "Emojich" that
generates emojis using captions in Russian language as a condition. We aim to
keep the generalization ability of a pretrained big model ruDALL-E Malevich
(XL) 1.3B parameters at the fine-tuning stage, while giving special style to
the images generated. Here are presented some engineering methods, code
realization, all hyper-parameters for reproducing results and a Telegram bot
where everyone can create their own customized sets of stickers. Also, some
newly generated emojis obtained by "Emojich" model are demonstrated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hypers at ComMA@ICON: Modelling Aggressiveness, Gender Bias and Communal Bias Identification. (arXiv:2112.15417v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.15417">
<div class="article-summary-box-inner">
<span><p>Due to the exponentially increasing reach of social media, it is essential to
focus on its negative aspects as it can potentially divide society and incite
people into violence. In this paper, we present our system description of work
on the shared task ComMA@ICON, where we have to classify how aggressive the
sentence is and if the sentence is gender-biased or communal biased. These
three could be the primary reasons to cause significant problems in society. As
team Hypers we have proposed an approach that utilizes different pretrained
models with Attention and mean pooling methods. We were able to get Rank 3 with
0.223 Instance F1 score on Bengali, Rank 2 with 0.322 Instance F1 score on
Multi-lingual set, Rank 4 with 0.129 Instance F1 score on Meitei and Rank 5
with 0.336 Instance F1 score on Hindi. The source code and the pretrained
models of this work can be found here.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards the Next 1000 Languages in Multilingual Machine Translation: Exploring the Synergy Between Supervised and Self-Supervised Learning. (arXiv:2201.03110v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03110">
<div class="article-summary-box-inner">
<span><p>Achieving universal translation between all human language pairs is the
holy-grail of machine translation (MT) research. While recent progress in
massively multilingual MT is one step closer to reaching this goal, it is
becoming evident that extending a multilingual MT system simply by training on
more parallel data is unscalable, since the availability of labeled data for
low-resource and non-English-centric language pairs is forbiddingly limited. To
this end, we present a pragmatic approach towards building a multilingual MT
model that covers hundreds of languages, using a mixture of supervised and
self-supervised objectives, depending on the data availability for different
language pairs. We demonstrate that the synergy between these two training
paradigms enables the model to produce high-quality translations in the
zero-resource setting, even surpassing supervised translation quality for low-
and mid-resource languages. We conduct a wide array of experiments to
understand the effect of the degree of multilingual supervision, domain
mismatches and amounts of parallel and monolingual data on the quality of our
self-supervised multilingual models. To demonstrate the scalability of the
approach, we train models with over 200 languages and demonstrate high
performance on zero-resource translation on several previously under-studied
languages. We hope our findings will serve as a stepping stone towards enabling
translation for the next thousand languages.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Early Diagnosis of Parkinsons Disease by Analyzing Magnetic Resonance Imaging Brain Scans and Patient Characteristics. (arXiv:2201.04631v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04631">
<div class="article-summary-box-inner">
<span><p>Parkinsons disease, PD, is a chronic condition that affects motor skills and
includes symptoms like tremors and rigidity. The current diagnostic procedure
uses patient assessments to evaluate symptoms and sometimes a magnetic
resonance imaging or MRI scan. However, symptom variations cause inaccurate
assessments, and the analysis of MRI scans requires experienced specialists.
This research proposes to accurately diagnose PD severity with deep learning by
combining symptoms data and MRI data from the Parkinsons Progression Markers
Initiative database. A new hybrid model architecture was implemented to fully
utilize both forms of clinical data, and models based on only symptoms and only
MRI scans were also developed. The symptoms based model integrates a fully
connected deep learning neural network, and the MRI scans and hybrid models
integrate transfer learning based convolutional neural networks. Instead of
performing only binary classification, all models diagnose patients into five
severity categories, with stage zero representing healthy patients and stages
four and five representing patients with PD. The symptoms only, MRI scans only,
and hybrid models achieved accuracies of 0.77, 0.68, and 0.94, respectively.
The hybrid model also had high precision and recall scores of 0.94 and 0.95.
Real clinical cases confirm the strong performance of the hybrid, where
patients were classified incorrectly with both other models but correctly by
the hybrid. It is also consistent across the five severity stages, indicating
accurate early detection. This is the first report to combine symptoms data and
MRI scans with a machine learning approach on such a large scale.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uniformer: Unified Transformer for Efficient Spatiotemporal Representation Learning. (arXiv:2201.04676v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04676">
<div class="article-summary-box-inner">
<span><p>It is a challenging task to learn rich and multi-scale spatiotemporal
semantics from high-dimensional videos, due to large local redundancy and
complex global dependency between video frames. The recent advances in this
research have been mainly driven by 3D convolutional neural networks and vision
transformers. Although 3D convolution can efficiently aggregate local context
to suppress local redundancy from a small 3D neighborhood, it lacks the
capability to capture global dependency because of the limited receptive field.
Alternatively, vision transformers can effectively capture long-range
dependency by self-attention mechanism, while having the limitation on reducing
local redundancy with blind similarity comparison among all the tokens in each
layer. Based on these observations, we propose a novel Unified transFormer
(UniFormer) which seamlessly integrates merits of 3D convolution and
spatiotemporal self-attention in a concise transformer format, and achieves a
preferable balance between computation and accuracy. Different from traditional
transformers, our relation aggregator can tackle both spatiotemporal redundancy
and dependency, by learning local and global token affinity respectively in
shallow and deep layers. We conduct extensive experiments on the popular video
benchmarks, e.g., Kinetics-400, Kinetics-600, and Something-Something V1&amp;V2.
With only ImageNet-1K pretraining, our UniFormer achieves 82.9%/84.8% top-1
accuracy on Kinetics-400/Kinetics-600, while requiring 10x fewer GFLOPs than
other state-of-the-art methods. For Something-Something V1 and V2, our
UniFormer achieves new state-of-the-art performances of 60.9% and 71.2% top-1
accuracy respectively. Code is available at
https://github.com/Sense-X/UniFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BigDatasetGAN: Synthesizing ImageNet with Pixel-wise Annotations. (arXiv:2201.04684v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04684">
<div class="article-summary-box-inner">
<span><p>Annotating images with pixel-wise labels is a time-consuming and costly
process. Recently, DatasetGAN showcased a promising alternative - to synthesize
a large labeled dataset via a generative adversarial network (GAN) by
exploiting a small set of manually labeled, GAN-generated images. Here, we
scale DatasetGAN to ImageNet scale of class diversity. We take image samples
from the class-conditional generative model BigGAN trained on ImageNet, and
manually annotate 5 images per class, for all 1k classes. By training an
effective feature segmentation architecture on top of BigGAN, we turn BigGAN
into a labeled dataset generator. We further show that VQGAN can similarly
serve as a dataset generator, leveraging the already annotated data. We create
a new ImageNet benchmark by labeling an additional set of 8k real images and
evaluate segmentation performance in a variety of settings. Through an
extensive ablation study we show big gains in leveraging a large generated
dataset to train different supervised and self-supervised backbone models on
pixel-wise tasks. Furthermore, we demonstrate that using our synthesized
datasets for pre-training leads to improvements over standard ImageNet
pre-training on several downstream datasets, such as PASCAL-VOC, MS-COCO,
Cityscapes and chest X-ray, as well as tasks (detection, segmentation). Our
benchmark will be made public and maintain a leaderboard for this challenging
task. Project Page: https://nv-tlabs.github.io/big-datasetgan/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Labeling of Human Action For Visually Impaired And Blind People Scene Interaction. (arXiv:2201.04706v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04706">
<div class="article-summary-box-inner">
<span><p>The aim of this work is to contribute to the development of a tactile device
for visually impaired and blind persons in order to let them to understand
actions of the surrounding people and to interact with them. First, based on
the state-of-the-art methods of human action recognition from RGB-D sequences,
we use the skeleton information provided by Kinect, with the disentangled and
unified multi-scale Graph Convolutional (MS-G3D) model to recognize the
performed actions. We tested this model on real scenes and found some of
constraints and limitations. Next, we apply a fusion between skeleton modality
with MS-G3D and depth modality with CNN in order to bypass the discussed
limitations. Third, the recognized actions are labeled semantically and will be
mapped into an output device perceivable by the touch sense.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Partial-Attribution Instance Segmentation for Astronomical Source Detection and Deblending. (arXiv:2201.04714v1 [astro-ph.IM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04714">
<div class="article-summary-box-inner">
<span><p>Astronomical source deblending is the process of separating the contribution
of individual stars or galaxies (sources) to an image comprised of multiple,
possibly overlapping sources. Astronomical sources display a wide range of
sizes and brightnesses and may show substantial overlap in images. Astronomical
imaging data can further challenge off-the-shelf computer vision algorithms
owing to its high dynamic range, low signal-to-noise ratio, and unconventional
image format. These challenges make source deblending an open area of
astronomical research, and in this work, we introduce a new approach called
Partial-Attribution Instance Segmentation that enables source detection and
deblending in a manner tractable for deep learning models. We provide a novel
neural network implementation as a demonstration of the method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarially Robust Classification by Conditional Generative Model Inversion. (arXiv:2201.04733v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04733">
<div class="article-summary-box-inner">
<span><p>Most adversarial attack defense methods rely on obfuscating gradients. These
methods are successful in defending against gradient-based attacks; however,
they are easily circumvented by attacks which either do not use the gradient or
by attacks which approximate and use the corrected gradient. Defenses that do
not obfuscate gradients such as adversarial training exist, but these
approaches generally make assumptions about the attack such as its magnitude.
We propose a classification model that does not obfuscate gradients and is
robust by construction without assuming prior knowledge about the attack. Our
method casts classification as an optimization problem where we "invert" a
conditional generator trained on unperturbed, natural images to find the class
that generates the closest sample to the query image. We hypothesize that a
potential source of brittleness against adversarial attacks is the
high-to-low-dimensional nature of feed-forward classifiers which allows an
adversary to find small perturbations in the input space that lead to large
changes in the output space. On the other hand, a generative model is typically
a low-to-high-dimensional mapping. While the method is related to Defense-GAN,
the use of a conditional generative model and inversion in our model instead of
the feed-forward classifier is a critical difference. Unlike Defense-GAN, which
was shown to generate obfuscated gradients that are easily circumvented, we
show that our method does not obfuscate gradients. We demonstrate that our
model is extremely robust against black-box attacks and has improved robustness
against white-box attacks compared to naturally trained, feed-forward
classifiers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial-Temporal Map Vehicle Trajectory Detection Using Dynamic Mode Decomposition and Res-UNet+ Neural Networks. (arXiv:2201.04755v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04755">
<div class="article-summary-box-inner">
<span><p>This paper presents a machine-learning-enhanced longitudinal scanline method
to extract vehicle trajectories from high-angle traffic cameras. The Dynamic
Mode Decomposition (DMD) method is applied to extract vehicle strands by
decomposing the Spatial-Temporal Map (STMap) into the sparse foreground and
low-rank background. A deep neural network named Res-UNet+ was designed for the
semantic segmentation task by adapting two prevalent deep learning
architectures. The Res-UNet+ neural networks significantly improve the
performance of the STMap-based vehicle detection, and the DMD model provides
many interesting insights for understanding the evolution of underlying
spatial-temporal structures preserved by STMap. The model outputs were compared
with the previous image processing model and mainstream semantic segmentation
deep neural networks. After a thorough evaluation, the model is proved to be
accurate and robust against many challenging factors. Last but not least, this
paper fundamentally addressed many quality issues found in NGSIM trajectory
data. The cleaned high-quality trajectory data are published to support future
theoretical and modeling research on traffic flow and microscopic vehicle
control. This method is a reliable solution for video-based trajectory
extraction and has wide applicability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Roadside Lidar Vehicle Detection and Tracking Using Range And Intensity Background Subtraction. (arXiv:2201.04756v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04756">
<div class="article-summary-box-inner">
<span><p>In this paper, we present the solution of roadside LiDAR object detection
using a combination of two unsupervised learning algorithms. The 3D point
clouds data are firstly converted into spherical coordinates and filled into
the azimuth grid matrix using a hash function. After that, the raw LiDAR data
were rearranged into spatial-temporal data structures to store the information
of range, azimuth, and intensity. Dynamic Mode Decomposition method is applied
for decomposing the point cloud data into low-rank backgrounds and sparse
foregrounds based on intensity channel pattern recognition. The Triangle
Algorithm automatically finds the dividing value to separate the moving targets
from static background according to range information. After intensity and
range background subtraction, the foreground moving objects will be detected
using a density-based detector and encoded into the state-space model for
tracking. The output of the proposed model includes vehicle trajectories that
can enable many mobility and safety applications. The method was validated
against a commercial traffic data collection platform and demonstrated to be an
efficient and reliable solution for infrastructure LiDAR object detection. In
contrast to the previous methods that process directly on the scattered and
discrete point clouds, the proposed method can establish the less sophisticated
linear relationship of the 3D measurement data, which captures the
spatial-temporal structure that we often desire.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collision Detection: An Improved Deep Learning Approach Using SENet and ResNext. (arXiv:2201.04766v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04766">
<div class="article-summary-box-inner">
<span><p>In recent days, with increased population and traffic on roadways, vehicle
collision is one of the leading causes of death worldwide. The automotive
industry is motivated on developing techniques to use sensors and advancements
in the field of computer vision to build collision detection and collision
prevention systems to assist drivers. In this article, a deep-learning-based
model comprising of ResNext architecture with SENet blocks is proposed. The
performance of the model is compared to popular deep learning models like
VGG16, VGG19, Resnet50, and stand-alone ResNext. The proposed model outperforms
the existing baseline models achieving a ROC-AUC of 0.91 using a significantly
less proportion of the GTACrash synthetic data for training, thus reducing the
computational overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAg: a simple learning-based patient-level aggregation method for detecting microsatellite instability from whole-slide images. (arXiv:2201.04769v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04769">
<div class="article-summary-box-inner">
<span><p>The prediction of microsatellite instability (MSI) and microsatellite
stability (MSS) is essential in predicting both the treatment response and
prognosis of gastrointestinal cancer. In clinical practice, a universal MSI
testing is recommended, but the accessibility of such a test is limited. Thus,
a more cost-efficient and broadly accessible tool is desired to cover the
traditionally untested patients. In the past few years, deep-learning-based
algorithms have been proposed to predict MSI directly from haematoxylin and
eosin (H&amp;E)-stained whole-slide images (WSIs). Such algorithms can be
summarized as (1) patch-level MSI/MSS prediction, and (2) patient-level
aggregation. Compared with the advanced deep learning approaches that have been
employed for the first stage, only the na\"ive first-order statistics (e.g.,
averaging and counting) were employed in the second stage. In this paper, we
propose a simple yet broadly generalizable patient-level MSI aggregation (MAg)
method to effectively integrate the precious patch-level information. Briefly,
the entire probabilistic distribution in the first stage is modeled as
histogram-based features to be fused as the final outcome with machine learning
(e.g., SVM). The proposed MAg method can be easily used in a plug-and-play
manner, which has been evaluated upon five broadly used deep neural networks:
ResNet, MobileNetV2, EfficientNet, Dpn and ResNext. From the results, the
proposed MAg method consistently improves the accuracy of patient-level
aggregation for two publicly available datasets. It is our hope that the
proposed method could potentially leverage the low-cost H&amp;E based MSI detection
method. The code of our work has been made publicly available at
https://github.com/Calvin-Pang/MAg.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unlocking large-scale crop field delineation in smallholder farming systems with transfer learning and weak supervision. (arXiv:2201.04771v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04771">
<div class="article-summary-box-inner">
<span><p>Crop field boundaries aid in mapping crop types, predicting yields, and
delivering field-scale analytics to farmers. Recent years have seen the
successful application of deep learning to delineating field boundaries in
industrial agricultural systems, but field boundary datasets remain missing in
smallholder systems due to (1) small fields that require high resolution
satellite imagery to delineate and (2) a lack of ground labels for model
training and validation. In this work, we combine transfer learning and weak
supervision to overcome these challenges, and we demonstrate the methods'
success in India where we efficiently generated 10,000 new field labels. Our
best model uses 1.5m resolution Airbus SPOT imagery as input, pre-trains a
state-of-the-art neural network on France field boundaries, and fine-tunes on
India labels to achieve a median Intersection over Union (IoU) of 0.86 in
India. If using 4.8m resolution PlanetScope imagery instead, the best model
achieves a median IoU of 0.72. Experiments also show that pre-training in
France reduces the number of India field labels needed to achieve a given
performance level by as much as $20\times$ when datasets are small. These
findings suggest our method is a scalable approach for delineating crop fields
in regions of the world that currently lack field boundary datasets. We
publicly release the 10,000 labels and delineation model to facilitate the
creation of field boundary maps and new methods by the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Masked Facial Detection Methods and Datasets for Fighting Against COVID-19. (arXiv:2201.04777v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04777">
<div class="article-summary-box-inner">
<span><p>Coronavirus disease 2019 (COVID-19) continues to pose a great challenge to
the world since its outbreak. To fight against the disease, a series of
artificial intelligence (AI) techniques are developed and applied to real-world
scenarios such as safety monitoring, disease diagnosis, infection risk
assessment, lesion segmentation of COVID-19 CT scans,etc. The coronavirus
epidemics have forced people wear masks to counteract the transmission of
virus, which also brings difficulties to monitor large groups of people wearing
masks. In this paper, we primarily focus on the AI techniques of masked facial
detection and related datasets. We survey the recent advances, beginning with
the descriptions of masked facial detection datasets. Thirteen available
datasets are described and discussed in details. Then, the methods are roughly
categorized into two classes: conventional methods and neural network-based
methods. Conventional methods are usually trained by boosting algorithms with
hand-crafted features, which accounts for a small proportion. Neural
network-based methods are further classified as three parts according to the
number of processing stages. Representative algorithms are described in detail,
coupled with some typical techniques that are described briefly. Finally, we
summarize the recent benchmarking results, give the discussions on the
limitations of datasets and methods, and expand future research directions. To
our knowledge, this is the first survey about masked facial detection methods
and datasets. Hopefully our survey could provide some help to fight against
epidemics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI Singapore Trusted Media Challenge Dataset. (arXiv:2201.04788v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04788">
<div class="article-summary-box-inner">
<span><p>The development of powerful deep learning technologies has brought about some
negative effects to both society and individuals. One such issue is the
emergence of fake media. To tackle the issue, we have organized the Trusted
Media Challenge (TMC) to explore how Artificial Intelligence (AI) technologies
could be leveraged to combat fake media.
</p>
<p>Together with the challenge, we have released a challenge dataset which
consists of 4,380 fake and 2,563 real videos. All these videos are accompanied
with audios and different video and/or audio manipulation methods are adopted
to produce different types of fake media. The videos in the dataset have
various durations, background, illumination, a minimum resolution of 360p and
may contain perturbations that mimic transmission errors and bad compression.
</p>
<p>We have also carried out a user study to demonstrate the quality of our
composed dataset. The results show that our dataset has a promising quality and
can fool human participants in many cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EMT-NET: Efficient multitask network for computer-aided diagnosis of breast cancer. (arXiv:2201.04795v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04795">
<div class="article-summary-box-inner">
<span><p>Deep learning-based computer-aided diagnosis has achieved unprecedented
performance in breast cancer detection. However, most approaches are
computationally intensive, which impedes their broader dissemination in
real-world applications. In this work, we propose an efficient and
light-weighted multitask learning architecture to classify and segment breast
tumors simultaneously. We incorporate a segmentation task into a tumor
classification network, which makes the backbone network learn representations
focused on tumor regions. Moreover, we propose a new numerically stable loss
function that easily controls the balance between the sensitivity and
specificity of cancer detection. The proposed approach is evaluated using a
breast ultrasound dataset with 1,511 images. The accuracy, sensitivity, and
specificity of tumor classification is 88.6%, 94.1%, and 85.3%, respectively.
We validate the model using a virtual mobile device, and the average inference
time is 0.35 seconds per image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CFNet: Learning Correlation Functions for One-Stage Panoptic Segmentation. (arXiv:2201.04796v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04796">
<div class="article-summary-box-inner">
<span><p>Recently, there is growing attention on one-stage panoptic segmentation
methods which aim to segment instances and stuff jointly within a fully
convolutional pipeline efficiently. However, most of the existing works
directly feed the backbone features to various segmentation heads ignoring the
demands for semantic and instance segmentation are different: The former needs
semantic-level discriminative features, while the latter requires features to
be distinguishable across instances. To alleviate this, we propose to first
predict semantic-level and instance-level correlations among different
locations that are utilized to enhance the backbone features, and then feed the
improved discriminative features into the corresponding segmentation heads,
respectively. Specifically, we organize the correlations between a given
location and all locations as a continuous sequence and predict it as a whole.
Considering that such a sequence can be extremely complicated, we adopt
Discrete Fourier Transform (DFT), a tool that can approximate an arbitrary
sequence parameterized by amplitudes and phrases. For different tasks, we
generate these parameters from the backbone features in a fully convolutional
way which is optimized implicitly by corresponding tasks. As a result, these
accurate and consistent correlations contribute to producing plausible
discriminative features which meet the requirements of the complicated panoptic
segmentation task. To verify the effectiveness of our methods, we conduct
experiments on several challenging panoptic segmentation datasets and achieve
state-of-the-art performance on MS COCO with $45.1$\% PQ and ADE20k with
$32.6$\% PQ.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable Cluster-Consistency Statistics for Robust Multi-Object Matching. (arXiv:2201.04797v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04797">
<div class="article-summary-box-inner">
<span><p>We develop new statistics for robustly filtering corrupted keypoint matches
in the structure from motion pipeline. The statistics are based on consistency
constraints that arise within the clustered structure of the graph of keypoint
matches. The statistics are designed to give smaller values to corrupted
matches and than uncorrupted matches. These new statistics are combined with an
iterative reweighting scheme to filter keypoints, which can then be fed into
any standard structure from motion pipeline. This filtering method can be
efficiently implemented and scaled to massive datasets as it only requires
sparse matrix multiplication. We demonstrate the efficacy of this method on
synthetic and real structure from motion datasets and show that it achieves
state-of-the-art accuracy and speed in these tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RealGait: Gait Recognition for Person Re-Identification. (arXiv:2201.04806v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04806">
<div class="article-summary-box-inner">
<span><p>Human gait is considered a unique biometric identifier which can be acquired
in a covert manner at a distance. However, models trained on existing public
domain gait datasets which are captured in controlled scenarios lead to drastic
performance decline when applied to real-world unconstrained gait data. On the
other hand, video person re-identification techniques have achieved promising
performance on large-scale publicly available datasets. Given the diversity of
clothing characteristics, clothing cue is not reliable for person recognition
in general. So, it is actually not clear why the state-of-the-art person
re-identification methods work as well as they do. In this paper, we construct
a new gait dataset by extracting silhouettes from an existing video person
re-identification challenge which consists of 1,404 persons walking in an
unconstrained manner. Based on this dataset, a consistent and comparative study
between gait recognition and person re-identification can be carried out. Given
that our experimental results show that current gait recognition approaches
designed under data collected in controlled scenarios are inappropriate for
real surveillance scenarios, we propose a novel gait recognition method, called
RealGait. Our results suggest that recognizing people by their gait in real
surveillance scenarios is feasible and the underlying gait pattern is probably
the true reason why video person re-idenfification works in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional Variational Autoencoder with Balanced Pre-training for Generative Adversarial Networks. (arXiv:2201.04809v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04809">
<div class="article-summary-box-inner">
<span><p>Class imbalance occurs in many real-world applications, including image
classification, where the number of images in each class differs significantly.
With imbalanced data, the generative adversarial networks (GANs) leans to
majority class samples. The two recent methods, Balancing GAN (BAGAN) and
improved BAGAN (BAGAN-GP), are proposed as an augmentation tool to handle this
problem and restore the balance to the data. The former pre-trains the
autoencoder weights in an unsupervised manner. However, it is unstable when the
images from different categories have similar features. The latter is improved
based on BAGAN by facilitating supervised autoencoder training, but the
pre-training is biased towards the majority classes. In this work, we propose a
novel Conditional Variational Autoencoder with Balanced Pre-training for
Generative Adversarial Networks (CAPGAN) as an augmentation tool to generate
realistic synthetic images. In particular, we utilize a conditional
convolutional variational autoencoder with supervised and balanced pre-training
for the GAN initialization and training with gradient penalty. Our proposed
method presents a superior performance of other state-of-the-art methods on the
highly imbalanced version of MNIST, Fashion-MNIST, CIFAR-10, and two medical
imaging datasets. Our method can synthesize high-quality minority samples in
terms of Fr\'echet inception distance, structural similarity index measure and
perceptual quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Domain Adaptation for Cross-Modality Retinal Vessel Segmentation via Disentangling Representation Style Transfer and Collaborative Consistency Learning. (arXiv:2201.04812v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04812">
<div class="article-summary-box-inner">
<span><p>Various deep learning models have been developed to segment anatomical
structures from medical images, but they typically have poor performance when
tested on another target domain with different data distribution. Recently,
unsupervised domain adaptation methods have been proposed to alleviate this
so-called domain shift issue, but most of them are designed for scenarios with
relatively small domain shifts and are likely to fail when encountering a large
domain gap. In this paper, we propose DCDA, a novel cross-modality unsupervised
domain adaptation framework for tasks with large domain shifts, e.g.,
segmenting retinal vessels from OCTA and OCT images. DCDA mainly consists of a
disentangling representation style transfer (DRST) module and a collaborative
consistency learning (CCL) module. DRST decomposes images into content
components and style codes and performs style transfer and image
reconstruction. CCL contains two segmentation models, one for source domain and
the other for target domain. The two models use labeled data (together with the
corresponding transferred images) for supervised learning and perform
collaborative consistency learning on unlabeled data. Each model focuses on the
corresponding single domain and aims to yield an expertized domain-specific
segmentation model. Through extensive experiments on retinal vessel
segmentation, our framework achieves Dice scores close to target-trained oracle
both from OCTA to OCT and from OCT to OCTA, significantly outperforming other
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recursive Least Squares for Training and Pruning Convolutional Neural Networks. (arXiv:2201.04813v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04813">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) have succeeded in many practical
applications. However, their high computation and storage requirements often
make them difficult to deploy on resource-constrained devices. In order to
tackle this issue, many pruning algorithms have been proposed for CNNs, but
most of them can't prune CNNs to a reasonable level. In this paper, we propose
a novel algorithm for training and pruning CNNs based on the recursive least
squares (RLS) optimization. After training a CNN for some epochs, our algorithm
combines inverse input autocorrelation matrices and weight matrices to evaluate
and prune unimportant input channels or nodes layer by layer. Then, our
algorithm will continue to train the pruned network, and won't do the next
pruning until the pruned network recovers the full performance of the old
network. Besides for CNNs, the proposed algorithm can be used for feedforward
neural networks (FNNs). Three experiments on MNIST, CIFAR-10 and SVHN datasets
show that our algorithm can achieve the more reasonable pruning and have higher
learning efficiency than other four popular pruning algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">S$^2$FPR: Crowd Counting via Self-Supervised Coarse to Fine Feature Pyramid Ranking. (arXiv:2201.04819v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04819">
<div class="article-summary-box-inner">
<span><p>Most conventional crowd counting methods utilize a fully-supervised learning
framework to learn a mapping between scene images and crowd density maps. Under
the circumstances of such fully-supervised training settings, a large quantity
of expensive and time-consuming pixel-level annotations are required to
generate density maps as the supervision. One way to reduce costly labeling is
to exploit self-structural information and inner-relations among unlabeled
images. Unlike the previous methods utilizing these relations and structural
information from the original image level, we explore such self-relations from
the latent feature spaces because it can extract more abundant relations and
structural information. Specifically, we propose S$^2$FPR which can extract
structural information and learn partial orders of coarse-to-fine pyramid
features in the latent space for better crowd counting with massive unlabeled
images. In addition, we collect a new unlabeled crowd counting dataset
(FUDAN-UCC) with 4,000 images in total for training. One by-product is that our
proposed S$^2$FPR method can leverage numerous partial orders in the latent
space among unlabeled images to strengthen the model representation capability
and reduce the estimation errors for the crowd counting task. Extensive
experiments on four benchmark datasets, i.e. the UCF-QNRF, the ShanghaiTech
PartA and PartB, and the UCF-CC-50, show the effectiveness of our method
compared with previous semi-supervised methods. The source code and dataset are
available at https://github.com/bridgeqiqi/S2FPR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SnapshotNet: Self-supervised Feature Learning for Point Cloud Data Segmentation Using Minimal Labeled Data. (arXiv:2201.04833v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04833">
<div class="article-summary-box-inner">
<span><p>Manually annotating complex scene point cloud datasets is both costly and
error-prone. To reduce the reliance on labeled data, a new model called
SnapshotNet is proposed as a self-supervised feature learning approach, which
directly works on the unlabeled point cloud data of a complex 3D scene. The
SnapshotNet pipeline includes three stages. In the snapshot capturing stage,
snapshots, which are defined as local collections of points, are sampled from
the point cloud scene. A snapshot could be a view of a local 3D scan directly
captured from the real scene, or a virtual view of such from a large 3D point
cloud dataset. Snapshots could also be sampled at different sampling rates or
fields of view (FOVs), thus multi-FOV snapshots, to capture scale information
from the scene. In the feature learning stage, a new pre-text task called
multi-FOV contrasting is proposed to recognize whether two snapshots are from
the same object or not, within the same FOV or across different FOVs. Snapshots
go through two self-supervised learning steps: the contrastive learning step
with both part and scale contrasting, followed by a snapshot clustering step to
extract higher level semantic features. Then a weakly-supervised segmentation
stage is implemented by first training a standard SVM classifier on the learned
features with a small fraction of labeled snapshots. The trained SVM is used to
predict labels for input snapshots and predicted labels are converted into
point-wise label assignments for semantic segmentation of the entire scene
using a voting procedure. The experiments are conducted on the Semantic3D
dataset and the results have shown that the proposed method is capable of
learning effective features from snapshots of complex scene data without any
labels. Moreover, the proposed method has shown advantages when comparing to
the SOA method on weakly-supervised point cloud semantic segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BridgeFormer: Bridging Video-text Retrieval with Multiple Choice Questions. (arXiv:2201.04850v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04850">
<div class="article-summary-box-inner">
<span><p>Pre-training a model to learn transferable video-text representation for
retrieval has attracted a lot of attention in recent years. Previous dominant
works mainly adopt two separate encoders for efficient retrieval, but ignore
local associations between videos and texts. Another line of research uses a
joint encoder to interact video with texts, but results in low efficiency since
each text-video pair needs to be fed into the model. In this work, we enable
fine-grained video-text interactions while maintaining high efficiency for
retrieval via a novel pretext task, dubbed as Multiple Choice Questions (MCQ),
where a parametric module BridgeFormer is trained to answer the "questions"
constructed by the text features via resorting to the video features.
Specifically, we exploit the rich semantics of text (i.e., nouns and verbs) to
build questions, with which the video encoder can be trained to capture more
regional content and temporal dynamics. In the form of questions and answers,
the semantic associations between local video-text features can be properly
established. BridgeFormer is able to be removed for downstream retrieval,
rendering an efficient and flexible model with only two encoders. Our method
outperforms state-of-the-art methods on the popular text-to-video retrieval
task in five datasets with different experimental setups (i.e., zero-shot and
fine-tune), including HowTo100M (one million videos). We further conduct
zero-shot action recognition, which can be cast as video-to-text retrieval, and
our approach also significantly surpasses its counterparts. As an additional
benefit, our method achieves competitive results with much shorter pre-training
videos on single-modality downstream tasks, e.g., action recognition with
linear evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaDance: Few-shot Dancing Video Retargeting via Temporal-aware Meta-learning. (arXiv:2201.04851v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04851">
<div class="article-summary-box-inner">
<span><p>Dancing video retargeting aims to synthesize a video that transfers the dance
movements from a source video to a target person. Previous work need collect a
several-minute-long video of a target person with thousands of frames to train
a personalized model. However, the trained model can only generate videos of
the same person. To address the limitations, recent work tackled few-shot
dancing video retargeting, which learns to synthesize videos of unseen persons
by leveraging a few frames of them. In practice, given a few frames of a
person, these work simply regarded them as a batch of individual images without
temporal correlations, thus generating temporally incoherent dancing videos of
low visual quality. In this work, we model a few frames of a person as a series
of dancing moves, where each move contains two consecutive frames, to extract
the appearance patterns and the temporal dynamics of this person. We propose
MetaDance, which utilizes temporal-aware meta-learning to optimize the
initialization of a model through the synthesis of dancing moves, such that the
meta-trained model can be efficiently tuned towards enhanced visual quality and
strengthened temporal stability for unseen persons with a few frames. Extensive
evaluations show large superiority of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Scene Text Detection using Deep Reinforcement Learning. (arXiv:2201.04866v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04866">
<div class="article-summary-box-inner">
<span><p>The challenging field of scene text detection requires complex data
annotation, which is time-consuming and expensive. Techniques, such as weak
supervision, can reduce the amount of data needed. In this paper we propose a
weak supervision method for scene text detection, which makes use of
reinforcement learning (RL). The reward received by the RL agent is estimated
by a neural network, instead of being inferred from ground-truth labels. First,
we enhance an existing supervised RL approach to text detection with several
training optimizations, allowing us to close the performance gap to
regression-based algorithms. We then use our proposed system in a weakly- and
semi-supervised training on real-world data. Our results show that training in
a weakly supervised setting is feasible. However, we find that using our model
in a semi-supervised setting , e.g. when combining labeled synthetic data with
unannotated real-world data, produces the best results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VoLux-GAN: A Generative Model for 3D Face Synthesis with HDRI Relighting. (arXiv:2201.04873v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04873">
<div class="article-summary-box-inner">
<span><p>We propose VoLux-GAN, a generative framework to synthesize 3D-aware faces
with convincing relighting. Our main contribution is a volumetric HDRI
relighting method that can efficiently accumulate albedo, diffuse and specular
lighting contributions along each 3D ray for any desired HDR environmental map.
Additionally, we show the importance of supervising the image decomposition
process using multiple discriminators. In particular, we propose a data
augmentation technique that leverages recent advances in single image portrait
relighting to enforce consistent geometry, albedo, diffuse and specular
components. Multiple experiments and comparisons with other generative
frameworks show how our model is a step forward towards photorealistic
relightable 3D generative models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flexible Style Image Super-Resolution using Conditional Objective. (arXiv:2201.04898v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04898">
<div class="article-summary-box-inner">
<span><p>Recent studies have significantly enhanced the performance of single-image
super-resolution (SR) using convolutional neural networks (CNNs). While there
can be many high-resolution (HR) solutions for a given input, most existing
CNN-based methods do not explore alternative solutions during the inference. A
typical approach to obtaining alternative SR results is to train multiple SR
models with different loss weightings and exploit the combination of these
models. Instead of using multiple models, we present a more efficient method to
train a single adjustable SR model on various combinations of losses by taking
advantage of multi-task learning. Specifically, we optimize an SR model with a
conditional objective during training, where the objective is a weighted sum of
multiple perceptual losses at different feature levels. The weights vary
according to given conditions, and the set of weights is defined as a style
controller. Also, we present an architecture appropriate for this training
scheme, which is the Residual-in-Residual Dense Block equipped with spatial
feature transformation layers. At the inference phase, our trained model can
generate locally different outputs conditioned on the style control map.
Extensive experiments show that the proposed SR model produces various
desirable reconstructions without artifacts and yields comparable quantitative
performance to state-of-the-art SR methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hand-Object Interaction Reasoning. (arXiv:2201.04906v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04906">
<div class="article-summary-box-inner">
<span><p>This paper proposes an interaction reasoning network for modelling
spatio-temporal relationships between hands and objects in video. The proposed
interaction unit utilises a Transformer module to reason about each acting
hand, and its spatio-temporal relation to the other hand as well as objects
being interacted with. We show that modelling two-handed interactions are
critical for action recognition in egocentric video, and demonstrate that by
using positionally-encoded trajectories, the network can better recognise
observed interactions. We evaluate our proposal on EPIC-KITCHENS and
Something-Else datasets, with an ablation study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Realistic Endoscopic Image Generation Method Using Virtual-to-real Image-domain Translation. (arXiv:2201.04918v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04918">
<div class="article-summary-box-inner">
<span><p>This paper proposes a realistic image generation method for visualization in
endoscopic simulation systems. Endoscopic diagnosis and treatment are performed
in many hospitals. To reduce complications related to endoscope insertions,
endoscopic simulation systems are used for training or rehearsal of endoscope
insertions. However, current simulation systems generate non-realistic virtual
endoscopic images. To improve the value of the simulation systems, improvement
of reality of their generated images is necessary. We propose a realistic image
generation method for endoscopic simulation systems. Virtual endoscopic images
are generated by using a volume rendering method from a CT volume of a patient.
We improve the reality of the virtual endoscopic images using a virtual-to-real
image-domain translation technique. The image-domain translator is implemented
as a fully convolutional network (FCN). We train the FCN by minimizing a cycle
consistency loss function. The FCN is trained using unpaired virtual and real
endoscopic images. To obtain high quality image-domain translation results, we
perform an image cleansing to the real endoscopic image set. We tested to use
the shallow U-Net, U-Net, deep U-Net, and U-Net having residual units as the
image-domain translator. The deep U-Net and U-Net having residual units
generated quite realistic images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Technical Report for ICCV 2021 Challenge SSLAD-Track3B: Transformers Are Better Continual Learners. (arXiv:2201.04924v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04924">
<div class="article-summary-box-inner">
<span><p>In the SSLAD-Track 3B challenge on continual learning, we propose the method
of COntinual Learning with Transformer (COLT). We find that transformers suffer
less from catastrophic forgetting compared to convolutional neural network. The
major principle of our method is to equip the transformer based feature
extractor with old knowledge distillation and head expanding strategies to
compete catastrophic forgetting. In this report, we first introduce the overall
framework of continual learning for object detection. Then, we analyse the key
elements' effect on withstanding catastrophic forgetting in our solution. Our
method achieves 70.78 mAP on the SSLAD-Track 3B challenge test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Semantic Abstraction of Shape via 3D Region of Interest. (arXiv:2201.04945v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04945">
<div class="article-summary-box-inner">
<span><p>In this paper, we focus on the two tasks of 3D shape abstraction and semantic
analysis. This is in contrast to current methods, which focus solely on either
3D shape abstraction or semantic analysis. In addition, previous methods have
had difficulty producing instance-level semantic results, which has limited
their application. We present a novel method for the joint estimation of a 3D
shape abstraction and semantic analysis. Our approach first generates a number
of 3D semantic candidate regions for a 3D shape; we then employ these
candidates to directly predict the semantic categories and refine the
parameters of the candidate regions simultaneously using a deep convolutional
neural network. Finally, we design an algorithm to fuse the predicted results
and obtain the final semantic abstraction, which is shown to be an improvement
over a standard non maximum suppression. Experimental results demonstrate that
our approach can produce state-of-the-art results. Moreover, we also find that
our results can be easily applied to instance-level semantic part segmentation
and shape matching.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toddler-Guidance Learning: Impacts of Critical Period on Multimodal AI Agents. (arXiv:2201.04990v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04990">
<div class="article-summary-box-inner">
<span><p>Critical periods are phases during which a toddler's brain develops in
spurts. To promote children's cognitive development, proper guidance is
critical in this stage. However, it is not clear whether such a critical period
also exists for the training of AI agents. Similar to human toddlers,
well-timed guidance and multimodal interactions might significantly enhance the
training efficiency of AI agents as well. To validate this hypothesis, we adapt
this notion of critical periods to learning in AI agents and investigate the
critical period in the virtual environment for AI agents. We formalize the
critical period and Toddler-guidance learning in the reinforcement learning
(RL) framework. Then, we built up a toddler-like environment with VECA toolkit
to mimic human toddlers' learning characteristics. We study three discrete
levels of mutual interaction: weak-mentor guidance (sparse reward), moderate
mentor guidance (helper-reward), and mentor demonstration (behavioral cloning).
We also introduce the EAVE dataset consisting of 30,000 real-world images to
fully reflect the toddler's viewpoint. We evaluate the impact of critical
periods on AI agents from two perspectives: how and when they are guided best
in both uni- and multimodal learning. Our experimental results show that both
uni- and multimodal agents with moderate mentor guidance and critical period on
1 million and 2 million training steps show a noticeable improvement. We
validate these results with transfer learning on the EAVE dataset and find the
performance advancement on the same critical period and the guidance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-granularity Association Learning Framework for on-the-fly Fine-Grained Sketch-based Image Retrieval. (arXiv:2201.05007v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05007">
<div class="article-summary-box-inner">
<span><p>Fine-grained sketch-based image retrieval (FG-SBIR) addresses the problem of
retrieving a particular photo in a given query sketch. However, its widespread
applicability is limited by the fact that it is difficult to draw a complete
sketch for most people, and the drawing process often takes time. In this
study, we aim to retrieve the target photo with the least number of strokes
possible (incomplete sketch), named on-the-fly FG-SBIR (Bhunia et al. 2020),
which starts retrieving at each stroke as soon as the drawing begins. We
consider that there is a significant correlation among these incomplete
sketches in the sketch drawing episode of each photo. To learn more efficient
joint embedding space shared between the photo and its incomplete sketches, we
propose a multi-granularity association learning framework that further
optimizes the embedding space of all incomplete sketches. Specifically, based
on the integrity of the sketch, we can divide a complete sketch episode into
several stages, each of which corresponds to a simple linear mapping layer.
Moreover, our framework guides the vector space representation of the current
sketch to approximate that of its later sketches to realize the retrieval
performance of the sketch with fewer strokes to approach that of the sketch
with more strokes. In the experiments, we proposed more realistic challenges,
and our method achieved superior early retrieval efficiency over the
state-of-the-art methods and alternative baselines on two publicly available
fine-grained sketch retrieval datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Sparse Connectivity Learning for Neural Networks. (arXiv:2201.05020v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05020">
<div class="article-summary-box-inner">
<span><p>Since sparse neural networks usually contain many zero weights, these
unnecessary network connections can potentially be eliminated without degrading
network performance. Therefore, well-designed sparse neural networks have the
potential to significantly reduce FLOPs and computational resources. In this
work, we propose a new automatic pruning method - Sparse Connectivity Learning
(SCL). Specifically, a weight is re-parameterized as an element-wise
multiplication of a trainable weight variable and a binary mask. Thus, network
connectivity is fully described by the binary mask, which is modulated by a
unit step function. We theoretically prove the fundamental principle of using a
straight-through estimator (STE) for network pruning. This principle is that
the proxy gradients of STE should be positive, ensuring that mask variables
converge at their minima. After finding Leaky ReLU, Softplus, and Identity STEs
can satisfy this principle, we propose to adopt Identity STE in SCL for
discrete mask relaxation. We find that mask gradients of different features are
very unbalanced, hence, we propose to normalize mask gradients of each feature
to optimize mask variable training. In order to automatically train sparse
masks, we include the total number of network connections as a regularization
term in our objective function. As SCL does not require pruning criteria or
hyper-parameters defined by designers for network layers, the network is
explored in a larger hypothesis space to achieve optimized sparse connectivity
for the best performance. SCL overcomes the limitations of existing automatic
pruning methods. Experimental results demonstrate that SCL can automatically
learn and select important network connections for various baseline network
structures. Deep learning models trained by SCL outperform the SOTA
human-designed and automatic pruning methods in sparsity, accuracy, and FLOPs
reduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-semantic contour adaptation for cross modality brain tumor segmentation. (arXiv:2201.05022v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05022">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation (UDA) between two significantly disparate
domains to learn high-level semantic alignment is a crucial yet challenging
task.~To this end, in this work, we propose exploiting low-level edge
information to facilitate the adaptation as a precursor task, which has a small
cross-domain gap, compared with semantic segmentation.~The precise contour then
provides spatial information to guide the semantic adaptation. More
specifically, we propose a multi-task framework to learn a contouring
adaptation network along with a semantic segmentation adaptation network, which
takes both magnetic resonance imaging (MRI) slice and its initial edge map as
input.~These two networks are jointly trained with source domain labels, and
the feature and edge map level adversarial learning is carried out for
cross-domain alignment. In addition, self-entropy minimization is incorporated
to further enhance segmentation performance. We evaluated our framework on the
BraTS2018 database for cross-modality segmentation of brain tumors, showing the
validity and superiority of our approach, compared with competing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stereo Magnification with Multi-Layer Images. (arXiv:2201.05023v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05023">
<div class="article-summary-box-inner">
<span><p>Representing scenes with multiple semi-transparent colored layers has been a
popular and successful choice for real-time novel view synthesis. Existing
approaches infer colors and transparency values over regularly-spaced layers of
planar or spherical shape. In this work, we introduce a new view synthesis
approach based on multiple semi-transparent layers with scene-adapted geometry.
Our approach infers such representations from stereo pairs in two stages. The
first stage infers the geometry of a small number of data-adaptive layers from
a given pair of views. The second stage infers the color and the transparency
values for these layers producing the final representation for novel view
synthesis. Importantly, both stages are connected through a differentiable
renderer and are trained in an end-to-end manner. In the experiments, we
demonstrate the advantage of the proposed approach over the use of
regularly-spaced layers with no adaptation to scene geometry. Despite being
orders of magnitude faster during rendering, our approach also outperforms a
recently proposed IBRNet system based on implicit geometry representation. See
results at https://samsunglabs.github.io/StereoLayers .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fantastic Data and How to Query Them. (arXiv:2201.05026v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05026">
<div class="article-summary-box-inner">
<span><p>It is commonly acknowledged that the availability of the huge amount of
(training) data is one of the most important factors for many recent advances
in Artificial Intelligence (AI). However, datasets are often designed for
specific tasks in narrow AI sub areas and there is no unified way to manage and
access them. This not only creates unnecessary overheads when training or
deploying Machine Learning models but also limits the understanding of the
data, which is very important for data-centric AI. In this paper, we present
our vision about a unified framework for different datasets so that they can be
integrated and queried easily, e.g., using standard query languages. We
demonstrate this in our ongoing work to create a framework for datasets in
Computer Vision and show its advantages in different scenarios. Our
demonstration is available at https://vision.semkg.org.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransVOD: End-to-end Video Object Detection with Spatial-Temporal Transformers. (arXiv:2201.05047v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05047">
<div class="article-summary-box-inner">
<span><p>Detection Transformer (DETR) and Deformable DETR have been proposed to
eliminate the need for many hand-designed components in object detection while
demonstrating good performance as previous complex hand-crafted detectors.
However, their performance on Video Object Detection (VOD) has not been well
explored. In this paper, we present TransVOD, the first end-to-end video object
detection system based on spatial-temporal Transformer architectures. The first
goal of this paper is to streamline the pipeline of VOD, effectively removing
the need for many hand-crafted components for feature aggregation, e.g.,
optical flow model, relation networks. Besides, benefited from the object query
design in DETR, our method does not need complicated post-processing methods
such as Seq-NMS. In particular, we present a temporal Transformer to aggregate
both the spatial object queries and the feature memories of each frame. Our
temporal transformer consists of two components: Temporal Query Encoder (TQE)
to fuse object queries, and Temporal Deformable Transformer Decoder (TDTD) to
obtain current frame detection results. These designs boost the strong baseline
deformable DETR by a significant margin (3%-4% mAP) on the ImageNet VID
dataset. Then, we present two improved versions of TransVOD including
TransVOD++ and TransVOD Lite. The former fuses object-level information into
object query via dynamic convolution while the latter models the entire video
clips as the output to speed up the inference time. We give detailed analysis
of all three models in the experiment part. In particular, our proposed
TransVOD++ sets a new state-of-the-art record in terms of accuracy on ImageNet
VID with 90.0% mAP. Our proposed TransVOD Lite also achieves the best speed and
accuracy trade-off with 83.7% mAP while running at around 30 FPS on a single
V100 GPU device. Code and models will be available for further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Adversarial Robustness of Trajectory Prediction for Autonomous Vehicles. (arXiv:2201.05057v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05057">
<div class="article-summary-box-inner">
<span><p>Trajectory prediction is a critical component for autonomous vehicles (AVs)
to perform safe planning and navigation. However, few studies have analyzed the
adversarial robustness of trajectory prediction or investigated whether the
worst-case prediction can still lead to safe planning. To bridge this gap, we
study the adversarial robustness of trajectory prediction models by proposing a
new adversarial attack that perturbs normal vehicle trajectories to maximize
the prediction error. Our experiments on three models and three datasets show
that the adversarial prediction increases the prediction error by more than
150%. Our case studies show that if an adversary drives a vehicle close to the
target AV following the adversarial trajectory, the AV may make an inaccurate
prediction and even make unsafe driving decisions. We also explore possible
mitigation techniques via data augmentation and trajectory smoothing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of Neural Networks Defenses and Attacks using NDCG and Reciprocal Rank Metrics. (arXiv:2201.05071v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05071">
<div class="article-summary-box-inner">
<span><p>The problem of attacks on neural networks through input modification (i.e.,
adversarial examples) has attracted much attention recently. Being relatively
easy to generate and hard to detect, these attacks pose a security breach that
many suggested defenses try to mitigate. However, the evaluation of the effect
of attacks and defenses commonly relies on traditional classification metrics,
without adequate adaptation to adversarial scenarios. Most of these metrics are
accuracy-based, and therefore may have a limited scope and low distinctive
power. Other metrics do not consider the unique characteristics of neural
networks functionality, or measure the effect of the attacks indirectly (e.g.,
through the complexity of their generation). In this paper, we present two
metrics which are specifically designed to measure the effect of attacks, or
the recovery effect of defenses, on the output of neural networks in multiclass
classification tasks. Inspired by the normalized discounted cumulative gain and
the reciprocal rank metrics used in information retrieval literature, we treat
the neural network predictions as ranked lists of results. Using additional
information about the probability of the rank enabled us to define novel
metrics that are suited to the task at hand. We evaluate our metrics using
various attacks and defenses on a pretrained VGG19 model and the ImageNet
dataset. Compared to the common classification metrics, our proposed metrics
demonstrate superior informativeness and distinctiveness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLIP-Event: Connecting Text and Images with Event Structures. (arXiv:2201.05078v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05078">
<div class="article-summary-box-inner">
<span><p>Vision-language (V+L) pretraining models have achieved great success in
supporting multimedia applications by understanding the alignments between
images and text. While existing vision-language pretraining models primarily
focus on understanding objects in images or entities in text, they often ignore
the alignment at the level of events and their argument structures. % In this
work, we propose a contrastive learning framework to enforce vision-language
pretraining models to comprehend events and associated argument (participant)
roles. To achieve this, we take advantage of text information extraction
technologies to obtain event structural knowledge, and utilize multiple prompt
functions to contrast difficult negative descriptions by manipulating event
structures. We also design an event graph alignment loss based on optimal
transport to capture event argument structures. In addition, we collect a large
event-rich dataset (106,875 images) for pretraining, which provides a more
challenging image retrieval benchmark to assess the understanding of
complicated lengthy sentences. Experiments show that our zero-shot CLIP-Event
outperforms the state-of-the-art supervised model in argument extraction on
Multimedia Event Extraction, achieving more than 5\% absolute F-score gain in
event extraction, as well as significant improvements on a variety of
downstream tasks under zero-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?. (arXiv:2201.05119v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05119">
<div class="article-summary-box-inner">
<span><p>Despite recent progress made by self-supervised methods in representation
learning with residual networks, they still underperform supervised learning on
the ImageNet classification benchmark, limiting their applicability in
performance-critical settings. Building on prior theoretical insights from
Mitrovic et al., 2021, we propose ReLICv2 which combines an explicit invariance
loss with a contrastive objective over a varied set of appropriately
constructed data views. ReLICv2 achieves 77.1% top-1 classification accuracy on
ImageNet using linear evaluation with a ResNet50 architecture and 80.6% with
larger ResNet models, outperforming previous state-of-the-art self-supervised
approaches by a wide margin. Most notably, ReLICv2 is the first representation
learning method to consistently outperform the supervised baseline in a
like-for-like comparison using a range of standard ResNet architectures.
Finally we show that despite using ResNet encoders, ReLICv2 is comparable to
state-of-the-art self-supervised vision transformers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SeamlessGAN: Self-Supervised Synthesis of Tileable Texture Maps. (arXiv:2201.05120v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05120">
<div class="article-summary-box-inner">
<span><p>We present SeamlessGAN, a method capable of automatically generating tileable
texture maps from a single input exemplar. In contrast to most existing
methods, focused solely on solving the synthesis problem, our work tackles both
problems, synthesis and tileability, simultaneously. Our key idea is to realize
that tiling a latent space within a generative network trained using
adversarial expansion techniques produces outputs with continuity at the seam
intersection that can be then be turned into tileable images by cropping the
central area. Since not every value of the latent space is valid to produce
high-quality outputs, we leverage the discriminator as a perceptual error
metric capable of identifying artifact-free textures during a sampling process.
Further, in contrast to previous work on deep texture synthesis, our model is
designed and optimized to work with multi-layered texture representations,
enabling textures composed of multiple maps such as albedo, normals, etc. We
extensively test our design choices for the network architecture, loss function
and sampling parameters. We show qualitatively and quantitatively that our
approach outperforms previous methods and works for textures of different
types.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">STEdge: Self-training Edge Detection with Multi-layer Teaching and Regularization. (arXiv:2201.05121v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05121">
<div class="article-summary-box-inner">
<span><p>Learning-based edge detection has hereunto been strongly supervised with
pixel-wise annotations which are tedious to obtain manually. We study the
problem of self-training edge detection, leveraging the untapped wealth of
large-scale unlabeled image datasets. We design a self-supervised framework
with multi-layer regularization and self-teaching. In particular, we impose a
consistency regularization which enforces the outputs from each of the multiple
layers to be consistent for the input image and its perturbed counterpart. We
adopt L0-smoothing as the 'perturbation' to encourage edge prediction lying on
salient boundaries following the cluster assumption in self-supervised
learning. Meanwhile, the network is trained with multi-layer supervision by
pseudo labels which are initialized with Canny edges and then iteratively
refined by the network as the training proceeds. The regularization and
self-teaching together attain a good balance of precision and recall, leading
to a significant performance boost over supervised methods, with lightweight
refinement on the target dataset. Furthermore, our method demonstrates strong
cross-dataset generality. For example, it attains 4.8% improvement for ODS and
5.8% for OIS when tested on the unseen BIPED dataset, compared to the
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GradMax: Growing Neural Networks using Gradient Information. (arXiv:2201.05125v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05125">
<div class="article-summary-box-inner">
<span><p>The architecture and the parameters of neural networks are often optimized
independently, which requires costly retraining of the parameters whenever the
architecture is modified. In this work we instead focus on growing the
architecture without requiring costly retraining. We present a method that adds
new neurons during training without impacting what is already learned, while
improving the training dynamics. We achieve the latter by maximizing the
gradients of the new weights and find the optimal initialization efficiently by
means of the singular value decomposition (SVD). We call this technique
Gradient Maximizing Growth (GradMax) and demonstrate its effectiveness in
variety of vision tasks and architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimReg: Regression as a Simple Yet Effective Tool for Self-supervised Knowledge Distillation. (arXiv:2201.05131v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05131">
<div class="article-summary-box-inner">
<span><p>Feature regression is a simple way to distill large neural network models to
smaller ones. We show that with simple changes to the network architecture,
regression can outperform more complex state-of-the-art approaches for
knowledge distillation from self-supervised models. Surprisingly, the addition
of a multi-layer perceptron head to the CNN backbone is beneficial even if used
only during distillation and discarded in the downstream task. Deeper
non-linear projections can thus be used to accurately mimic the teacher without
changing inference architecture and time. Moreover, we utilize independent
projection heads to simultaneously distill multiple teacher networks. We also
find that using the same weakly augmented image as input for both teacher and
student networks aids distillation. Experiments on ImageNet dataset demonstrate
the efficacy of the proposed changes in various self-supervised distillation
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Adaptive Bayesian Algorithm for Data Analysis, FABADA. (arXiv:2201.05145v1 [astro-ph.IM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05145">
<div class="article-summary-box-inner">
<span><p>The aim of this paper is to describe a novel non-parametric noise reduction
technique from the point of view of Bayesian inference that may automatically
improve the signal-to-noise ratio of one- and two-dimensional data, such as
e.g. astronomical images and spectra. The algorithm iteratively evaluates
possible smoothed versions of the data, the smooth models, obtaining an
estimation of the underlying signal that is statistically compatible with the
noisy measurements. Iterations stop based on the evidence and the $\chi^2$
statistic of the last smooth model, and we compute the expected value of the
signal as a weighted average of the whole set of smooth models. In this paper,
we explain the mathematical formalism and numerical implementation of the
algorithm, and we evaluate its performance in terms of the peak signal to noise
ratio, the structural similarity index, and the time payload, using a battery
of real astronomical observations. Our Fully Adaptive Bayesian Algorithm for
Data Analysis (FABADA) yields results that, without any parameter tuning, are
comparable to standard image processing algorithms whose parameters have been
optimized based on the true signal to be recovered, something that is
impossible in a real application. State-of-the-art non-parametric methods, such
as BM3D, offer slightly better performance at high signal-to-noise ratio, while
our algorithm is significantly more accurate for extremely noisy data (higher
than $20-40\%$ relative errors, a situation of particular interest in the field
of astronomy). In this range, the standard deviation of the residuals obtained
by our reconstruction may become more than an order of magnitude lower than
that of the original measurements. The source code needed to reproduce all the
results presented in this report, including the implementation of the method,
is publicly available at https://github.com/PabloMSanAla/fabada
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Simple Meta-Learning: Multi-Purpose Models for Multi-Domain, Active and Continual Few-Shot Learning. (arXiv:2201.05151v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05151">
<div class="article-summary-box-inner">
<span><p>Modern deep learning requires large-scale extensively labelled datasets for
training. Few-shot learning aims to alleviate this issue by learning
effectively from few labelled examples. In previously proposed few-shot visual
classifiers, it is assumed that the feature manifold, where classifier
decisions are made, has uncorrelated feature dimensions and uniform feature
variance. In this work, we focus on addressing the limitations arising from
this assumption by proposing a variance-sensitive class of models that operates
in a low-label regime. The first method, Simple CNAPS, employs a hierarchically
regularized Mahalanobis-distance based classifier combined with a state of the
art neural adaptive feature extractor to achieve strong performance on
Meta-Dataset, mini-ImageNet and tiered-ImageNet benchmarks. We further extend
this approach to a transductive learning setting, proposing Transductive CNAPS.
This transductive method combines a soft k-means parameter refinement procedure
with a two-step task encoder to achieve improved test-time classification
accuracy using unlabelled data. Transductive CNAPS achieves state of the art
performance on Meta-Dataset. Finally, we explore the use of our methods (Simple
and Transductive) for "out of the box" continual and active learning. Extensive
experiments on large scale benchmarks illustrate robustness and versatility of
this, relatively speaking, simple class of models. All trained model
checkpoints and corresponding source codes have been made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unlabeled Data Improves Adversarial Robustness. (arXiv:1905.13736v4 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.13736">
<div class="article-summary-box-inner">
<span><p>We demonstrate, theoretically and empirically, that adversarial robustness
can significantly benefit from semisupervised learning. Theoretically, we
revisit the simple Gaussian model of Schmidt et al. that shows a sample
complexity gap between standard and robust classification. We prove that
unlabeled data bridges this gap: a simple semisupervised learning procedure
(self-training) achieves high robust accuracy using the same number of labels
required for achieving high standard accuracy. Empirically, we augment CIFAR-10
with 500K unlabeled images sourced from 80 Million Tiny Images and use robust
self-training to outperform state-of-the-art robust accuracies by over 5 points
in (i) $\ell_\infty$ robustness against several strong attacks via adversarial
training and (ii) certified $\ell_2$ and $\ell_\infty$ robustness via
randomized smoothing. On SVHN, adding the dataset's own extra training set with
the labels removed provides gains of 4 to 10 points, within 1 point of the gain
from using the extra labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Scene Understanding via Online Semantic Reconstruction. (arXiv:1906.07409v2 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.07409">
<div class="article-summary-box-inner">
<span><p>We propose a novel approach to robot-operated active understanding of unknown
indoor scenes, based on online RGBD reconstruction with semantic segmentation.
In our method, the exploratory robot scanning is both driven by and targeting
at the recognition and segmentation of semantic objects from the scene. Our
algorithm is built on top of the volumetric depth fusion framework (e.g.,
KinectFusion) and performs real-time voxel-based semantic labeling over the
online reconstructed volume. The robot is guided by an online estimated
discrete viewing score field (VSF) parameterized over the 3D space of 2D
location and azimuth rotation. VSF stores for each grid the score of the
corresponding view, which measures how much it reduces the uncertainty
(entropy) of both geometric reconstruction and semantic labeling. Based on VSF,
we select the next best views (NBV) as the target for each time step. We then
jointly optimize the traverse path and camera trajectory between two adjacent
NBVs, through maximizing the integral viewing score (information gain) along
path and trajectory. Through extensive evaluation, we show that our method
achieves efficient and accurate online scene parsing during exploratory
scanning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning spatio-temporal representations with temporal squeeze pooling. (arXiv:2002.04685v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04685">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a new video representation learning method, named
Temporal Squeeze (TS) pooling, which can extract the essential movement
information from a long sequence of video frames and map it into a set of few
images, named Squeezed Images. By embedding the Temporal Squeeze pooling as a
layer into off-the-shelf Convolution Neural Networks (CNN), we design a new
video classification model, named Temporal Squeeze Network (TeSNet). The
resulting Squeezed Images contain the essential movement information from the
video frames, corresponding to the optimization of the video classification
task. We evaluate our architecture on two video classification benchmarks, and
the results achieved are compared to the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fusion-Aware Point Convolution for Online Semantic 3D Scene Segmentation. (arXiv:2003.06233v4 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06233">
<div class="article-summary-box-inner">
<span><p>Online semantic 3D segmentation in company with real-time RGB-D
reconstruction poses special challenges such as how to perform 3D convolution
directly over the progressively fused 3D geometric data, and how to smartly
fuse information from frame to frame. We propose a novel fusion-aware 3D point
convolution which operates directly on the geometric surface being
reconstructed and exploits effectively the inter-frame correlation for high
quality 3D feature learning. This is enabled by a dedicated dynamic data
structure which organizes the online acquired point cloud with global-local
trees. Globally, we compile the online reconstructed 3D points into an
incrementally growing coordinate interval tree, enabling fast point insertion
and neighborhood query. Locally, we maintain the neighborhood information for
each point using an octree whose construction benefits from the fast query of
the global tree.Both levels of trees update dynamically and help the 3D
convolution effectively exploits the temporal coherence for effective
information fusion across RGB-D frames.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-Guided Black-box Adversarial Attacks with Large-Scale Multiobjective Evolutionary Optimization. (arXiv:2101.07512v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07512">
<div class="article-summary-box-inner">
<span><p>Fooling deep neural networks (DNNs) with the black-box optimization has
become a popular adversarial attack fashion, as the structural prior knowledge
of DNNs is always unknown. Nevertheless, recent black-box adversarial attacks
may struggle to balance their attack ability and visual quality of the
generated adversarial examples (AEs) in tackling high-resolution images. In
this paper, we propose an attention-guided black-box adversarial attack based
on the large-scale multiobjective evolutionary optimization, termed as LMOA. By
considering the spatial semantic information of images, we firstly take
advantage of the attention map to determine the perturbed pixels. Instead of
attacking the entire image, reducing the perturbed pixels with the attention
mechanism can help to avoid the notorious curse of dimensionality and thereby
improves the performance of attacking. Secondly, a large-scale multiobjective
evolutionary algorithm is employed to traverse the reduced pixels in the
salient region. Benefiting from its characteristics, the generated AEs have the
potential to fool target DNNs while being imperceptible by the human vision.
Extensive experimental results have verified the effectiveness of the proposed
LMOA on the ImageNet dataset. More importantly, it is more competitive to
generate high-resolution AEs with better visual quality compared with the
existing black-box adversarial attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Fine-Grained Segmentation of 3D Shapes without Part Labels. (arXiv:2103.13030v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13030">
<div class="article-summary-box-inner">
<span><p>Learning-based 3D shape segmentation is usually formulated as a semantic
labeling problem, assuming that all parts of training shapes are annotated with
a given set of tags. This assumption, however, is impractical for learning
fine-grained segmentation. Although most off-the-shelf CAD models are, by
construction, composed of fine-grained parts, they usually miss semantic tags
and labeling those fine-grained parts is extremely tedious. We approach the
problem with deep clustering, where the key idea is to learn part priors from a
shape dataset with fine-grained segmentation but no part labels. Given point
sampled 3D shapes, we model the clustering priors of points with a similarity
matrix and achieve part segmentation through minimizing a novel low rank loss.
To handle highly densely sampled point sets, we adopt a divide-and-conquer
strategy. We partition the large point set into a number of blocks. Each block
is segmented using a deep-clustering-based part prior network trained in a
category-agnostic manner. We then train a graph convolution network to merge
the segments of all blocks to form the final segmentation result. Our method is
evaluated with a challenging benchmark of fine-grained segmentation, showing
state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Busy-Quiet Video Disentangling for Video Classification. (arXiv:2103.15584v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15584">
<div class="article-summary-box-inner">
<span><p>In video data, busy motion details from moving regions are conveyed within a
specific frequency bandwidth in the frequency domain. Meanwhile, the rest of
the frequencies of video data are encoded with quiet information with
substantial redundancy, which causes low processing efficiency in existing
video models that take as input raw RGB frames. In this paper, we consider
allocating intenser computation for the processing of the important busy
information and less computation for that of the quiet information. We design a
trainable Motion Band-Pass Module (MBPM) for separating busy information from
quiet information in raw video data. By embedding the MBPM into a two-pathway
CNN architecture, we define a Busy-Quiet Net (BQN). The efficiency of BQN is
determined by avoiding redundancy in the feature space processed by the two
pathways: one operating on Quiet features of low-resolution, while the other
processes Busy features. The proposed BQN outperforms many recent video
processing models on Something-Something V1, Kinetics400, UCF101 and HMDB51
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Recursive Embedding for High-Dimensional Data. (arXiv:2104.05171v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05171">
<div class="article-summary-box-inner">
<span><p>t-distributed stochastic neighbor embedding (t-SNE) is a well-established
visualization method for complex high-dimensional data. However, the original
t-SNE method is nonparametric, stochastic, and often cannot well prevserve the
global structure of data as it emphasizes local neighborhood. With t-SNE as a
reference, we propose to combine the deep neural network (DNN) with the
mathematical-grounded embedding rules for high-dimensional data embedding. We
first introduce a deep embedding network (DEN) framework, which can learn a
parametric mapping from high-dimensional space to low-dimensional embedding.
DEN has a flexible architecture that can accommodate different input data
(vector, image, or tensor) and loss functions. To improve the embedding
performance, a recursive training strategy is proposed to make use of the
latent representations extracted by DEN. Finally, we propose a two-stage loss
function combining the advantages of two popular embedding methods, namely,
t-SNE and uniform manifold approximation and projection (UMAP), for optimal
visualization effect. We name the proposed method Deep Recursive Embedding
(DRE), which optimizes DEN with a recursive training strategy and two-stage
losse. Our experiments demonstrated the excellent performance of the proposed
DRE method on high-dimensional data embedding, across a variety of public
databases. Remarkably, our comparative results suggested that our proposed DRE
could lead to improved global structure preservation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Class-Balanced Distillation for Long-Tailed Visual Recognition. (arXiv:2104.05279v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05279">
<div class="article-summary-box-inner">
<span><p>Real-world imagery is often characterized by a significant imbalance of the
number of images per class, leading to long-tailed distributions. An effective
and simple approach to long-tailed visual recognition is to learn feature
representations and a classifier separately, with instance and class-balanced
sampling, respectively. In this work, we introduce a new framework, by making
the key observation that a feature representation learned with instance
sampling is far from optimal in a long-tailed setting. Our main contribution is
a new training method, referred to as Class-Balanced Distillation (CBD), that
leverages knowledge distillation to enhance feature representations. CBD allows
the feature representation to evolve in the second training stage, guided by
the teacher learned in the first stage. The second stage uses class-balanced
sampling, in order to focus on under-represented classes. This framework can
naturally accommodate the usage of multiple teachers, unlocking the information
from an ensemble of models to enhance recognition capabilities. Our experiments
show that the proposed technique consistently outperforms the state of the art
on long-tailed recognition benchmarks such as ImageNet-LT, iNaturalist17 and
iNaturalist18.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BADet: Boundary-Aware 3D Object Detection from Point Clouds. (arXiv:2104.10330v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10330">
<div class="article-summary-box-inner">
<span><p>Currently, existing state-of-the-art 3D object detectors are in two-stage
paradigm. These methods typically comprise two steps: 1) Utilize a region
proposal network to propose a handful of high-quality proposals in a bottom-up
fashion. 2) Resize and pool the semantic features from the proposed regions to
summarize RoI-wise representations for further refinement. Note that these
RoI-wise representations in step 2) are considered individually as uncorrelated
entries when fed to following detection headers. Nevertheless, we observe these
proposals generated by step 1) offset from ground truth somehow, emerging in
local neighborhood densely with an underlying probability. Challenges arise in
the case where a proposal largely forsakes its boundary information due to
coordinate offset while existing networks lack corresponding information
compensation mechanism. In this paper, we propose $BADet$ for 3D object
detection from point clouds. Specifically, instead of refining each proposal
independently as previous works do, we represent each proposal as a node for
graph construction within a given cut-off threshold, associating proposals in
the form of local neighborhood graph, with boundary correlations of an object
being explicitly exploited. Besides, we devise a lightweight Region Feature
Aggregation Module to fully exploit voxel-wise, pixel-wise, and point-wise
features with expanding receptive fields for more informative RoI-wise
representations. We validate BADet both on widely used KITTI Dataset and highly
challenging nuScenes Dataset. As of Apr. 17th, 2021, our BADet achieves on par
performance on KITTI 3D detection leaderboard and ranks $1^{st}$ on $Moderate$
difficulty of $Car$ category on KITTI BEV detection leaderboard. The source
code is available at https://github.com/rui-qian/BADet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NURBS-Diff: A Differentiable Programming Module for NURBS. (arXiv:2104.14547v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14547">
<div class="article-summary-box-inner">
<span><p>Boundary representations (B-reps) using Non-Uniform Rational B-splines
(NURBS) are the de facto standard used in CAD, but their utility in deep
learning-based approaches is not well researched. We propose a differentiable
NURBS module to integrate NURBS representations of CAD models with deep
learning methods. We mathematically define the derivatives of the NURBS curves
or surfaces with respect to the input parameters (control points, weights, and
the knot vector). These derivatives are used to define an approximate Jacobian
used for performing the "backward" evaluation to train the deep learning
models. We have implemented our NURBS module using GPU-accelerated algorithms
and integrated it with PyTorch, a popular deep learning framework. We
demonstrate the efficacy of our NURBS module in performing CAD operations such
as curve or surface fitting and surface offsetting. Further, we show its
utility in deep learning for unsupervised point cloud reconstruction and
enforce analysis constraints. These examples show that our module performs
better for certain deep learning frameworks and can be directly integrated with
any deep-learning framework requiring NURBS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An improved LogNNet classifier for IoT application. (arXiv:2105.14412v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14412">
<div class="article-summary-box-inner">
<span><p>In the age of neural networks and Internet of Things (IoT), the search for
new neural network architectures capable of operating on devices with limited
computing power and small memory size is becoming an urgent agenda. Designing
suitable algorithms for IoT applications is an important task. The paper
proposes a feed forward LogNNet neural network, which uses a semi-linear Henon
type discrete chaotic map to classify MNIST-10 dataset. The model is composed
of reservoir part and trainable classifier. The aim of the reservoir part is
transforming the inputs to maximize the classification accuracy using a special
matrix filing method and a time series generated by the chaotic map. The
parameters of the chaotic map are optimized using particle swarm optimization
with random immigrants. As a result, the proposed LogNNet/Henon classifier has
higher accuracy and the same RAM usage, compared to the original version of
LogNNet, and offers promising opportunities for implementation in IoT devices.
In addition, a direct relation between the value of entropy and accuracy of the
classification is demonstrated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rate Distortion Characteristic Modeling for Neural Image Compression. (arXiv:2106.12954v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12954">
<div class="article-summary-box-inner">
<span><p>End-to-end optimized neural image compression (NIC) has obtained superior
lossy compression performance recently. In this paper, we consider the problem
of rate-distortion (R-D) characteristic analysis and modeling for NIC. We make
efforts to formulate the essential mathematical functions to describe the R-D
behavior of NIC using deep networks. Thus arbitrary bit-rate points could be
elegantly realized by leveraging such model via a single trained network. We
propose a plugin-in module to learn the relationship between the target
bit-rate and the binary representation for the latent variable of auto-encoder.
The proposed scheme resolves the problem of training distinct models to reach
different points in the R-D space. Furthermore, we model the rate and
distortion characteristic of NIC as a function of the coding parameter
$\lambda$ respectively. Our experiments show our proposed method is easy to
adopt and realizes state-of-the-art continuous bit-rate coding performance,
which implies that our approach would benefit the practical deployment of NIC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Depth Contribution for Camouflaged Object Detection. (arXiv:2106.13217v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13217">
<div class="article-summary-box-inner">
<span><p>Camouflaged object detection (COD) aims to segment camouflaged objects hiding
in the environment, which is challenging due to the similar appearance of
camouflaged objects and their surroundings. Research in biology suggests depth
can provide useful object localization cues for camouflaged object discovery.
In this paper, we study the depth contribution for camouflaged object
detection, where the depth maps are generated with existing monocular depth
estimation (MDE) methods. Due to the domain gap between the MDE dataset and our
COD dataset, the generated depth maps are not accurate enough to be directly
used. We then introduce two solutions to avoid the noisy depth maps from
dominating the training process. Firstly, we present an auxiliary depth
estimation branch ("ADE"), aiming to regress the depth maps. We find that "ADE"
is especially necessary for our "generated depth" scenario. Secondly, we
introduce a multi-modal confidence-aware loss function via a generative
adversarial network to weigh the contribution of depth for camouflaged object
detection. Our extensive experiments on various camouflaged object detection
datasets explain that the existing "sensor depth" based RGB-D segmentation
techniques work poorly with "generated depth", and our proposed two solutions
work cooperatively, achieving effective depth contribution exploration for
camouflaged object detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Smooth Pose Sequences for Diverse Human Motion Prediction. (arXiv:2108.08422v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08422">
<div class="article-summary-box-inner">
<span><p>Recent progress in stochastic motion prediction, i.e., predicting multiple
possible future human motions given a single past pose sequence, has led to
producing truly diverse future motions and even providing control over the
motion of some body parts. However, to achieve this, the state-of-the-art
method requires learning several mappings for diversity and a dedicated model
for controllable motion prediction. In this paper, we introduce a unified deep
generative network for both diverse and controllable motion prediction. To this
end, we leverage the intuition that realistic human motions consist of smooth
sequences of valid poses, and that, given limited data, learning a pose prior
is much more tractable than a motion one. We therefore design a generator that
predicts the motion of different body parts sequentially, and introduce a
normalizing flow based pose prior, together with a joint angle loss, to achieve
motion realism.Our experiments on two standard benchmark datasets, Human3.6M
and HumanEva-I, demonstrate that our approach outperforms the state-of-the-art
baselines in terms of both sample diversity and accuracy. The code is available
at https://github.com/wei-mao-2019/gsps
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adversarial RetinaNet as a Reference Algorithm for the MItosis DOmain Generalization Challenge. (arXiv:2108.11269v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11269">
<div class="article-summary-box-inner">
<span><p>Assessing the Mitotic Count has a known high degree of intra- and inter-rater
variability. Computer-aided systems have proven to decrease this variability
and reduce labeling time. These systems, however, are generally highly
dependent on their training domain and show poor applicability to unseen
domains. In histopathology, these domain shifts can result from various
sources, including different slide scanning systems used to digitize histologic
samples. The MItosis DOmain Generalization challenge focused on this specific
domain shift for the task of mitotic figure detection. This work presents a
mitotic figure detection algorithm developed as a baseline for the challenge,
based on domain adversarial training. On the challenge's test set, the
algorithm scored an F$_1$ score of 0.7183. The corresponding network weights
and code for implementing the network are made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable Automated Diagnosis of Retinal Disease Using Deep OCT Analysis. (arXiv:2109.02436v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02436">
<div class="article-summary-box-inner">
<span><p>30 million Optical Coherence Tomography (OCT) imaging tests are issued every
year to diagnose various retinal diseases, but accurate diagnosis of OCT scans
requires trained ophthalmologists who are still prone to making errors. With
better systems for diagnosis, many cases of vision loss caused by retinal
disease could be entirely avoided. In this work, we develop a novel deep
learning architecture for explainable, accurate classification of retinal
disease which achieves state-of-the-art accuracy. Furthermore, we place an
emphasis on producing both qualitative and quantitative explanations of the
model's decisions. Our algorithm produces heatmaps indicating the exact regions
in the OCT scan the model focused on when making its decision. In combination
with an OCT segmentation model, this allows us to produce quantitative
breakdowns of the specific retinal layers the model focused on for later review
by an expert. Our work is the first to produce detailed quantitative
explanations of the model's decisions in this way. Our combination of accuracy
and interpretability can be clinically applied for better patient care.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep learning-based person re-identification methods: A survey and outlook of recent works. (arXiv:2110.04764v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04764">
<div class="article-summary-box-inner">
<span><p>In recent years, with the increasing demand for public safety and the rapid
development of intelligent surveillance networks, person re-identification
(Re-ID) has become one of the hot research topics in the computer vision field.
The main research goal of person Re-ID is to retrieve persons with the same
identity from different cameras. However, traditional person Re-ID methods
require manual marking of person targets, which consumes a lot of labor cost.
With the widespread application of deep neural networks, many deep
learning-based person Re-ID methods have emerged. Therefore, this paper is to
facilitate researchers to understand the latest research results and the future
trends in the field. Firstly, we summarize the studies of several recently
published person Re-ID surveys and complement the latest research methods to
systematically classify deep learning-based person Re-ID methods. Secondly, we
propose a multi-dimensional taxonomy that classifies current deep
learning-based person Re-ID methods into four categories according to metric
and representation learning, including methods for deep metric learning, local
feature learning, generative adversarial learning and sequence feature
learning. Furthermore, we subdivide the above four categories according to
their methodologies and motivations, discussing the advantages and limitations
of part subcategories. Finally, we discuss some challenges and possible
research directions for person Re-ID.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Per-Pixel Lung Thickness and Lung Capacity Estimation on Chest X-Rays using Convolutional Neural Networks. (arXiv:2110.12509v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12509">
<div class="article-summary-box-inner">
<span><p>Estimating the lung depth on x-ray images could provide both an accurate
opportunistic lung volume estimation during clinical routine and improve image
contrast in modern structural chest imaging techniques like x-ray dark-field
imaging. We present a method based on a convolutional neural network that
allows a per-pixel lung thickness estimation and subsequent total lung capacity
estimation. The network was trained and validated using 5250 simulated
radiographs generated from 525 real CT scans. Furthermore, we are able to infer
the model trained with simulation data on real radiographs.
</p>
<p>For 45 patients, quantitative and qualitative evaluation was performed on
standard clinical radiographs. The ground-truth for each patient's total lung
volume was defined based on the patients' corresponding CT scan. The
mean-absolute error between the estimated lung volume on the 45 real
radiographs and groundtruth volume was 0.83 liter. When accounting for the
patient diameter, the error decreases to 0.66 liter. Additionaly, we predicted
the lung thicknesses on a synthetic dataset of 131 radiographs, where the
mean-absolute error was 0.21 liter. The results show, that it is possible to
transfer the knowledge obtained in a simulation model to real x-ray images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Learning for Deep Visual Tracking. (arXiv:2110.13259v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13259">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) have been successfully applied to the
single target tracking task in recent years. Generally, training a deep CNN
model requires numerous labeled training samples, and the number and quality of
these samples directly affect the representational capability of the trained
model. However, this approach is restrictive in practice, because manually
labeling such a large number of training samples is time-consuming and
prohibitively expensive. In this paper, we propose an active learning method
for deep visual tracking, which selects and annotates the unlabeled samples to
train the deep CNNs model. Under the guidance of active learning, the tracker
based on the trained deep CNNs model can achieve competitive tracking
performance while reducing the labeling cost. More specifically, to ensure the
diversity of selected samples, we propose an active learning method based on
multi-frame collaboration to select those training samples that should be and
need to be annotated. Meanwhile, considering the representativeness of these
selected samples, we adopt a nearest neighbor discrimination method based on
the average nearest neighbor distance to screen isolated samples and
low-quality samples. Therefore, the training samples subset selected based on
our method requires only a given budget to maintain the diversity and
representativeness of the entire sample set. Furthermore, we adopt a Tversky
loss to improve the bounding box estimation of our tracker, which can ensure
that the tracker achieves more accurate target states. Extensive experimental
results confirm that our active learning-based tracker (ALT) achieves
competitive tracking accuracy and speed compared with state-of-the-art trackers
on the seven most challenging evaluation benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Break Deep Perceptual Hashing: The Use Case NeuralHash. (arXiv:2111.06628v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.06628">
<div class="article-summary-box-inner">
<span><p>Apple recently revealed its deep perceptual hashing system NeuralHash to
detect child sexual abuse material (CSAM) on user devices before files are
uploaded to its iCloud service. Public criticism quickly arose regarding the
protection of user privacy and the system's reliability. In this paper, we
present the first comprehensive empirical analysis of deep perceptual hashing
based on NeuralHash. Specifically, we show that current deep perceptual hashing
may not be robust. An adversary can manipulate the hash values by applying
slight changes in images, either induced by gradient-based approaches or simply
by performing standard image transformations, forcing or preventing hash
collisions. Such attacks permit malicious actors easily to exploit the
detection system: from hiding abusive material to framing innocent users,
everything is possible. Moreover, using the hash values, inferences can still
be made about the data stored on user devices. In our view, based on our
results, deep perceptual hashing in its current form is generally not ready for
robust client-side scanning and should not be used from a privacy perspective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dyadic Human Motion Prediction. (arXiv:2112.00396v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00396">
<div class="article-summary-box-inner">
<span><p>Prior work on human motion forecasting has mostly focused on predicting the
future motion of single subjects in isolation from their past pose sequence. In
the presence of closely interacting people, however, this strategy fails to
account for the dependencies between the different subject's motions. In this
paper, we therefore introduce a motion prediction framework that explicitly
reasons about the interactions of two observed subjects. Specifically, we
achieve this by introducing a pairwise attention mechanism that models the
mutual dependencies in the motion history of the two subjects. This allows us
to preserve the long-term motion dynamics in a more realistic way and more
robustly predict unusual and fast-paced movements, such as the ones occurring
in a dance scenario. To evaluate this, and because no existing motion
prediction datasets depict two closely-interacting subjects, we introduce the
LindyHop600K dance dataset. Our results evidence that our approach outperforms
the state-of-the-art single person motion prediction techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flexible Networks for Learning Physical Dynamics of Deformable Objects. (arXiv:2112.03728v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03728">
<div class="article-summary-box-inner">
<span><p>Learning the physical dynamics of deformable objects with particle-based
representation has been the objective of many computational models in machine
learning. While several state-of-the-art models have achieved this objective in
simulated environments, most existing models impose a precondition, such that
the input is a sequence of ordered point sets. That is, the order of the points
in each point set must be the same across the entire input sequence. This
precondition restrains the model from generalizing to real-world data, which is
considered to be a sequence of unordered point sets. In this paper, we propose
a model named time-wise PointNet (TP-Net) that solves this problem by directly
consuming a sequence of unordered point sets to infer the future state of a
deformable object with particle-based representation. Our model consists of a
shared feature extractor that extracts global features from each input point
set in parallel and a prediction network that aggregates and reasons on these
features for future prediction. The key concept of our approach is that we use
global features rather than local features to achieve invariance to input
permutations and ensure the stability and scalability of our model. Experiments
demonstrate that our model achieves state-of-the-art performance with real-time
prediction speed in both synthetic dataset and real-world dataset. In addition,
we provide quantitative and qualitative analysis on why our approach is more
effective and efficient than existing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finding the Task-Optimal Low-Bit Sub-Distribution in Deep Neural Networks. (arXiv:2112.15139v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.15139">
<div class="article-summary-box-inner">
<span><p>Quantized neural networks typically require smaller memory footprints and
lower computation complexity, which is crucial for efficient deployment.
However, quantization inevitably leads to a distribution divergence from the
original network, which generally degrades the performance. To tackle this
issue, massive efforts have been made, but most existing approaches lack
statistical considerations and depend on several manual configurations. In this
paper, we present an adaptive-mapping quantization method to learn an optimal
latent sub-distribution that is inherent within models and smoothly
approximated with a concrete Gaussian Mixture (GM). In particular, the network
weights are projected in compliance with the GM-approximated sub-distribution.
This sub-distribution evolves along with the weight update in a co-tuning
schema guided by the direct task-objective optimization. Sufficient experiments
on image classification and object detection over various modern architectures
demonstrate the effectiveness, generalization property, and transferability of
the proposed method. Besides, an efficient deployment flow for the mobile CPU
is developed, achieving up to 7.46$\times$ inference acceleration on an
octa-core ARM CPU. Codes have been publicly released on Github
(https://github.com/RunpeiDong/DGMS).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Transformer-Based Siamese Network for Change Detection. (arXiv:2201.01293v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01293">
<div class="article-summary-box-inner">
<span><p>This paper presents a transformer-based Siamese network architecture
(abbreviated by ChangeFormer) for Change Detection (CD) from a pair of
co-registered remote sensing images. Different from recent CD frameworks, which
are based on fully convolutional networks (ConvNets), the proposed method
unifies hierarchically structured transformer encoder with Multi-Layer
Perception (MLP) decoder in a Siamese network architecture to efficiently
render multi-scale long-range details required for accurate CD. Experiments on
two CD datasets show that the proposed end-to-end trainable ChangeFormer
architecture achieves better CD performance than previous counterparts. Our
code is available at https://github.com/wgcban/ChangeFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extending One-Stage Detection with Open-World Proposals. (arXiv:2201.02302v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02302">
<div class="article-summary-box-inner">
<span><p>In many applications, such as autonomous driving, hand manipulation, or robot
navigation, object detection methods must be able to detect objects unseen in
the training set. Open World Detection(OWD) seeks to tackle this problem by
generalizing detection performance to seen and unseen class categories. Recent
works have seen success in the generation of class-agnostic proposals, which we
call Open-World Proposals(OWP), but this comes at the cost of a big drop on the
classification task when both tasks are considered in the detection model.
These works have investigated two-stage Region Proposal Networks (RPN) by
taking advantage of objectness scoring cues; however, for its simplicity,
run-time, and decoupling of localization and classification, we investigate OWP
through the lens of fully convolutional one-stage detection network, such as
FCOS. We show that our architectural and sampling optimizations on FCOS can
increase OWP performance by as much as 6% in recall on novel classes, marking
the first proposal-free one-stage detection network to achieve comparable
performance to RPN-based two-stage networks. Furthermore, we show that the
inherent, decoupled architecture of FCOS has benefits to retaining
classification performance. While two-stage methods worsen by 6% in recall on
novel classes, we show that FCOS only drops 2% when jointly optimizing for OWP
and classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The State of Aerial Surveillance: A Survey. (arXiv:2201.03080v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03080">
<div class="article-summary-box-inner">
<span><p>The rapid emergence of airborne platforms and imaging sensors are enabling
new forms of aerial surveillance due to their unprecedented advantages in
scale, mobility, deployment and covert observation capabilities. This paper
provides a comprehensive overview of human-centric aerial surveillance tasks
from a computer vision and pattern recognition perspective. It aims to provide
readers with an in-depth systematic review and technical analysis of the
current state of aerial surveillance tasks using drones, UAVs and other
airborne platforms. The main object of interest is humans, where single or
multiple subjects are to be detected, identified, tracked, re-identified and
have their behavior analyzed. More specifically, for each of these four tasks,
we first discuss unique challenges in performing these tasks in an aerial
setting compared to a ground-based setting. We then review and analyze the
aerial datasets publicly available for each task, and delve deep into the
approaches in the aerial literature and investigate how they presently address
the aerial challenges. We conclude the paper with discussion on the missing
gaps and open research questions to inform future research avenues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Captcha Attack: Turning Captchas Against Humanity. (arXiv:2201.04014v2 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04014">
<div class="article-summary-box-inner">
<span><p>Nowadays, people generate and share massive content on online platforms
(e.g., social networks, blogs). In 2021, the 1.9 billion daily active Facebook
users posted around 150 thousand photos every minute. Content moderators
constantly monitor these online platforms to prevent the spreading of
inappropriate content (e.g., hate speech, nudity images). Based on deep
learning (DL) advances, Automatic Content Moderators (ACM) help human
moderators handle high data volume. Despite their advantages, attackers can
exploit weaknesses of DL components (e.g., preprocessing, model) to affect
their performance. Therefore, an attacker can leverage such techniques to
spread inappropriate content by evading ACM.
</p>
<p>In this work, we propose CAPtcha Attack (CAPA), an adversarial technique that
allows users to spread inappropriate text online by evading ACM controls. CAPA,
by generating custom textual CAPTCHAs, exploits ACM's careless design
implementations and internal procedures vulnerabilities. We test our attack on
real-world ACM, and the results confirm the ferocity of our simple yet
effective attack, reaching up to a 100% evasion success in most cases. At the
same time, we demonstrate the difficulties in designing CAPA mitigations,
opening new challenges in CAPTCHAs research area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Denoise Raw Mobile UI Layouts for Improving Datasets at Scale. (arXiv:2201.04100v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04100">
<div class="article-summary-box-inner">
<span><p>The layout of a mobile screen is a critical data source for UI design
research and semantic understanding of the screen. However, UI layouts in
existing datasets are often noisy, have mismatches with their visual
representation, or consists of generic or app-specific types that are difficult
to analyze and model. In this paper, we propose the CLAY pipeline that uses a
deep learning approach for denoising UI layouts, allowing us to automatically
improve existing mobile UI layout datasets at scale. Our pipeline takes both
the screenshot and the raw UI layout, and annotates the raw layout by removing
incorrect nodes and assigning a semantically meaningful type to each node. To
experiment with our data-cleaning pipeline, we create the CLAY dataset of
59,555 human-annotated screen layouts, based on screenshots and raw layouts
from Rico, a public mobile UI corpus. Our deep models achieve high accuracy
with F1 scores of 82.7% for detecting layout objects that do not have a valid
visual representation and 85.9% for recognizing object types, which
significantly outperforms a heuristic baseline. Our work lays a foundation for
creating large-scale high quality UI layout datasets for data-driven mobile UI
research and reduces the need of manual labeling efforts that are prohibitively
expensive.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Adversarially Robust Deep Image Denoising. (arXiv:2201.04397v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04397">
<div class="article-summary-box-inner">
<span><p>This work systematically investigates the adversarial robustness of deep
image denoisers (DIDs), i.e, how well DIDs can recover the ground truth from
noisy observations degraded by adversarial perturbations. Firstly, to evaluate
DIDs' robustness, we propose a novel adversarial attack, namely
Observation-based Zero-mean Attack ({\sc ObsAtk}), to craft adversarial
zero-mean perturbations on given noisy images. We find that existing DIDs are
vulnerable to the adversarial noise generated by {\sc ObsAtk}. Secondly, to
robustify DIDs, we propose an adversarial training strategy, hybrid adversarial
training ({\sc HAT}), that jointly trains DIDs with adversarial and
non-adversarial noisy data to ensure that the reconstruction quality is high
and the denoisers around non-adversarial data are locally smooth. The resultant
DIDs can effectively remove various types of synthetic and adversarial noise.
We also uncover that the robustness of DIDs benefits their generalization
capability on unseen real-world noise. Indeed, {\sc HAT}-trained DIDs can
recover high-quality clean images from real-world noise even without training
on real noisy data. Extensive experiments on benchmark datasets, including
Set68, PolyU, and SIDD, corroborate the effectiveness of {\sc ObsAtk} and {\sc
HAT}.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-01-16 23:07:07.541971689 UTC">2022-01-16 23:07:07 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>