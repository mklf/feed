<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-01-11T01:30:00Z">01-11</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02639">
<div class="article-summary-box-inner">
<span><p>As humans, we navigate the world through all our senses, using perceptual
input from each one to correct the others. We introduce MERLOT Reserve, a model
that represents videos jointly over time -- through a new training objective
that learns from audio, subtitles, and video frames. Given a video, we replace
snippets of text and audio with a MASK token; the model learns by choosing the
correct masked-out snippet. Our objective learns faster than alternatives, and
performs well at scale: we pretrain on 20 million YouTube videos.
</p>
<p>Empirical results show that MERLOT Reserve learns strong representations
about videos through all constituent modalities. When finetuned, it sets a new
state-of-the-art on both VCR and TVQA, outperforming prior work by 5% and 7%
respectively. Ablations show that both tasks benefit from audio pretraining --
even VCR, a QA task centered around images (without sound). Moreover, our
objective enables out-of-the-box prediction, revealing strong multimodal
commonsense understanding. In a fully zero-shot setting, our model obtains
competitive results on four video understanding tasks, even outperforming
supervised approaches on the recently proposed Situated Reasoning (STAR)
benchmark.
</p>
<p>We analyze why incorporating audio leads to better vision-language
representations, suggesting significant opportunities for future research. We
conclude by discussing ethical and societal implications of multimodal
pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computational Lens on Cognition: Study Of Autobiographical Versus Imagined Stories With Large-Scale Language Models. (arXiv:2201.02662v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02662">
<div class="article-summary-box-inner">
<span><p>Lifelong experiences and learned knowledge lead to shared expectations about
how common situations tend to unfold. Such knowledge enables people to
interpret story narratives and identify salient events effortlessly. We study
differences in the narrative flow of events in autobiographical versus imagined
stories using GPT-3, one of the largest neural language models created to date.
The diary-like stories were written by crowdworkers about either a recently
experienced event or an imagined event on the same topic. To analyze the
narrative flow of events of these stories, we measured sentence
*sequentiality*, which compares the probability of a sentence with and without
its preceding story context. We found that imagined stories have higher
sequentiality than autobiographical stories, and that the sequentiality of
autobiographical stories is higher when they are retold than when freshly
recalled. Through an annotation of events in story sentences, we found that the
story types contain similar proportions of major salient events, but that the
autobiographical stories are denser in factual minor events. Furthermore, in
comparison to imagined stories, autobiographical stories contain more concrete
words and words related to the first person, cognitive processes, time, space,
numbers, social words, and core drives and needs. Our findings highlight the
opportunity to investigate memory and cognition with large-scale statistical
language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Amharic Speech Emotion Dataset and Classification Benchmark. (arXiv:2201.02710v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02710">
<div class="article-summary-box-inner">
<span><p>In this paper we present the Amharic Speech Emotion Dataset (ASED), which
covers four dialects (Gojjam, Wollo, Shewa and Gonder) and five different
emotions (neutral, fearful, happy, sad and angry). We believe it is the first
Speech Emotion Recognition (SER) dataset for the Amharic language. 65 volunteer
participants, all native speakers, recorded 2,474 sound samples, two to four
seconds in length. Eight judges assigned emotions to the samples with high
agreement level (Fleiss kappa = 0.8). The resulting dataset is freely available
for download. Next, we developed a four-layer variant of the well-known VGG
model which we call VGGb. Three experiments were then carried out using VGGb
for SER, using ASED. First, we investigated whether Mel-spectrogram features or
Mel-frequency Cepstral coefficient (MFCC) features work best for Amharic. This
was done by training two VGGb SER models on ASED, one using Mel-spectrograms
and the other using MFCC. Four forms of training were tried, standard
cross-validation, and three variants based on sentences, dialects and speaker
groups. Thus, a sentence used for training would not be used for testing, and
the same for a dialect and speaker group. The conclusion was that MFCC features
are superior under all four training schemes. MFCC was therefore adopted for
Experiment 2, where VGGb and three other existing models were compared on ASED:
RESNet50, Alex-Net and LSTM. VGGb was found to have very good accuracy (90.73%)
as well as the fastest training time. In Experiment 3, the performance of VGGb
was compared when trained on two existing SER datasets, RAVDESS (English) and
EMO-DB (German) as well as on ASED (Amharic). Results are comparable across
these languages, with ASED being the highest. This suggests that VGGb can be
successfully applied to other languages. We hope that ASED will encourage
researchers to experiment with other models for Amharic SER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Rank Constraints for Fast Inference in Structured Models. (arXiv:2201.02715v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02715">
<div class="article-summary-box-inner">
<span><p>Structured distributions, i.e. distributions over combinatorial spaces, are
commonly used to learn latent probabilistic representations from observed data.
However, scaling these models is bottlenecked by the high computational and
memory complexity with respect to the size of the latent representations.
Common models such as Hidden Markov Models (HMMs) and Probabilistic
Context-Free Grammars (PCFGs) require time and space quadratic and cubic in the
number of hidden states respectively. This work demonstrates a simple approach
to reduce the computational and memory complexity of a large class of
structured models. We show that by viewing the central inference step as a
matrix-vector product and using a low-rank constraint, we can trade off model
expressivity and speed via the rank. Experiments with neural parameterized
structured models for language modeling, polyphonic music modeling,
unsupervised grammar induction, and video modeling show that our approach
matches the accuracy of standard models at large state spaces while providing
practical speedups.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System. (arXiv:2201.02732v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02732">
<div class="article-summary-box-inner">
<span><p>Conversational recommender systems (CRS) aim to recommend suitable items to
users through natural language conversations. For developing effective CRSs, a
major technical issue is how to accurately infer user preference from very
limited conversation context. To address issue, a promising solution is to
incorporate external data for enriching the context information. However, prior
studies mainly focus on designing fusion models tailored for some specific type
of external data, which is not general to model and utilize multi-type external
data.
</p>
<p>To effectively leverage multi-type external data, we propose a novel
coarse-to-fine contrastive learning framework to improve data semantic fusion
for CRS. In our approach, we first extract and represent multi-grained semantic
units from different data signals, and then align the associated multi-type
semantic units in a coarse-to-fine way. To implement this framework, we design
both coarse-grained and fine-grained procedures for modeling user preference,
where the former focuses on more general, coarse-grained semantic fusion and
the latter focuses on more specific, fine-grained semantic fusion. Such an
approach can be extended to incorporate more kinds of external data. Extensive
experiments on two public CRS datasets have demonstrated the effectiveness of
our approach in both recommendation and conversation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Testing the Robustness of a BiLSTM-based Structural Story Classifier. (arXiv:2201.02733v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02733">
<div class="article-summary-box-inner">
<span><p>The growing prevalence of counterfeit stories on the internet has fostered
significant interest towards fast and scalable detection of fake news in the
machine learning community. While several machine learning techniques for this
purpose have emerged, we observe that there is a need to evaluate the impact of
noise on these techniques' performance, where noise constitutes news articles
being mistakenly labeled as fake (or real). This work takes a step in that
direction, where we examine the impact of noise on a state-of-the-art,
structural model based on BiLSTM (Bidirectional Long-Short Term Model) for fake
news detection, Hierarchical Discourse-level Structure for Fake News Detection
by Karimi and Tang (Reference no. 9).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building Human-like Communicative Intelligence: A Grounded Perspective. (arXiv:2201.02734v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02734">
<div class="article-summary-box-inner">
<span><p>Modern Artificial Intelligence (AI) systems excel at diverse tasks, from
image classification to strategy games, even outperforming humans in many of
these domains. After making astounding progress in language learning in the
recent decade, AI systems, however, seem to approach the ceiling that does not
reflect important aspects of human communicative capacities. Unlike human
learners, communicative AI systems often fail to systematically generalize to
new data, suffer from sample inefficiency, fail to capture common-sense
semantic knowledge, and do not translate to real-world communicative
situations. Cognitive Science offers several insights on how AI could move
forward from this point. This paper aims to: (1) suggest that the dominant
cognitively-inspired AI directions, based on nativist and symbolic paradigms,
lack necessary substantiation and concreteness to guide progress in modern AI,
and (2) articulate an alternative, "grounded", perspective on AI advancement,
inspired by Embodied, Embedded, Extended, and Enactive Cognition (4E) research.
I review results on 4E research lines in Cognitive Science to distinguish the
main aspects of naturalistic learning conditions that play causal roles for
human language development. I then use this analysis to propose a list of
concrete, implementable components for building "grounded" linguistic
intelligence. These components include embodying machines in a
perception-action cycle, equipping agents with active exploration mechanisms so
they can build their own curriculum, allowing agents to gradually develop motor
abilities to promote piecemeal language development, and endowing the agents
with adaptive feedback from their physical and social environment. I hope that
these ideas can direct AI research towards building machines that develop
human-like language abilities through their experiences with the world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Deep Learning Approach to Integrate Human-Level Understanding in a Chatbot. (arXiv:2201.02735v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02735">
<div class="article-summary-box-inner">
<span><p>In recent times, a large number of people have been involved in establishing
their own businesses. Unlike humans, chatbots can serve multiple customers at a
time, are available 24/7 and reply in less than a fraction of a second. Though
chatbots perform well in task-oriented activities, in most cases they fail to
understand personalized opinions, statements or even queries which later impact
the organization for poor service management. Lack of understanding
capabilities in bots disinterest humans to continue conversations with them.
Usually, chatbots give absurd responses when they are unable to interpret a
user's text accurately. Extracting the client reviews from conversations by
using chatbots, organizations can reduce the major gap of understanding between
the users and the chatbot and improve their quality of products and
services.Thus, in our research we incorporated all the key elements that are
necessary for a chatbot to analyse and understand an input text precisely and
accurately. We performed sentiment analysis, emotion detection, intent
classification and named-entity recognition using deep learning to develop
chatbots with humanistic understanding and intelligence. The efficiency of our
approach can be demonstrated accordingly by the detailed analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cognitive Computing to Optimize IT Services. (arXiv:2201.02737v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02737">
<div class="article-summary-box-inner">
<span><p>In this paper, the challenges of maintaining a healthy IT operational
environment have been addressed by proactively analyzing IT Service Desk
tickets, customer satisfaction surveys, and social media data. A Cognitive
solution goes beyond the traditional structured data analysis by deep analyses
of both structured and unstructured text. The salient features of the proposed
platform include language identification, translation, hierarchical extraction
of the most frequently occurring topics, entities and their relationships, text
summarization, sentiments, and knowledge extraction from the unstructured text
using Natural Language Processing techniques. Moreover, the insights from
unstructured text combined with structured data allow the development of
various classification, segmentation, and time-series forecasting use-cases on
the incident, problem, and change datasets. Further, the text and predictive
insights together with raw data are used for visualization and exploration of
actionable insights on a rich and interactive dashboard. However, it is hard
not only to find these insights using traditional structured data analysis but
it might also take a very long time to discover them, especially while dealing
with a massive amount of unstructured data. By taking action on these insights,
organizations can benefit from a significant reduction of ticket volume,
reduced operational costs, and increased customer satisfaction. In various
experiments, on average, upto 18-25% of yearly ticket volume has been reduced
using the proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Traffic event description based on Twitter data using Unsupervised Learning Methods for Indian road conditions. (arXiv:2201.02738v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02738">
<div class="article-summary-box-inner">
<span><p>Non-recurrent and unpredictable traffic events directly influence road
traffic conditions. There is a need for dynamic monitoring and prediction of
these unpredictable events to improve road network management. The problem with
the existing traditional methods (flow or speed studies) is that the coverage
of many Indian roads is very sparse and reproducible methods to identify and
describe the events are not available. Addition of some other form of data is
essential to help with this problem. This could be real-time speed monitoring
data like Google Maps, Waze, etc. or social data like Twitter, Facebook, etc.
In this paper, an unsupervised learning model is used to perform effective
tweet classification for enhancing Indian traffic data. The model uses
word-embeddings to calculate semantic similarity and achieves a test score of
94.7%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Beam Search to Enhance On-device Abstractive Summarization. (arXiv:2201.02739v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02739">
<div class="article-summary-box-inner">
<span><p>We receive several essential updates on our smartphones in the form of SMS,
documents, voice messages, etc. that get buried beneath the clutter of content.
We often do not realize the key information without going through the full
content. SMS notifications sometimes help by giving an idea of what the message
is about, however, they merely offer a preview of the beginning content. One
way to solve this is to have a single efficient model that can adapt and
summarize data from varied sources. In this paper, we tackle this issue and for
the first time, propose a novel Adaptive Beam Search to improve the quality of
on-device abstractive summarization that can be applied to SMS, voice messages
and can be extended to documents. To the best of our knowledge, this is the
first on-device abstractive summarization pipeline to be proposed that can
adapt to multiple data sources addressing privacy concerns of users as compared
to the majority of existing summarization systems that send data to a server.
We reduce the model size by 30.9% using knowledge distillation and show that
this model with a 97.6% lesser memory footprint extracts the same or more key
information as compared to BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Best of Both Worlds: A Hybrid Approach for Multi-Hop Explanation with Declarative Facts. (arXiv:2201.02740v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02740">
<div class="article-summary-box-inner">
<span><p>Language-enabled AI systems can answer complex, multi-hop questions to high
accuracy, but supporting answers with evidence is a more challenging task which
is important for the transparency and trustworthiness to users. Prior work in
this area typically makes a trade-off between efficiency and accuracy;
state-of-the-art deep neural network systems are too cumbersome to be useful in
large-scale applications, while the fastest systems lack reliability. In this
work, we integrate fast syntactic methods with powerful semantic methods for
multi-hop explanation generation based on declarative facts. Our best system,
which learns a lightweight operation to simulate multi-hop reasoning over
pieces of evidence and fine-tunes language models to re-rank generated
explanation chains, outperforms a purely syntactic baseline from prior work by
up to 7% in gold explanation retrieval rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Defining maximum acceptable latency of AI-enhanced CAI tools. (arXiv:2201.02792v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02792">
<div class="article-summary-box-inner">
<span><p>Recent years have seen an increasing number of studies around the design of
computer-assisted interpreting tools with integrated automatic speech
processing and their use by trainees and professional interpreters. This paper
discusses the role of system latency of such tools and presents the results of
an experiment designed to investigate the maximum system latency that is
cognitively acceptable for interpreters working in the simultaneous modality.
The results show that interpreters can cope with a system latency of 3 seconds
without any major impact in the rendition of the original text, both in terms
of accuracy and fluency. This value is above the typical latency of available
AI-based CAI tools and paves the way to experiment with larger context-based
language models and higher latencies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Review of Deep Learning for Automated Medical Coding. (arXiv:2201.02797v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02797">
<div class="article-summary-box-inner">
<span><p>Automated medical coding, an essential task for healthcare operation and
delivery, makes unstructured data manageable by predicting medical codes from
clinical documents. Recent advances in deep learning models in natural language
processing have been widely applied to this task. However, it lacks a unified
view of the design of neural network architectures for medical coding. This
review proposes a unified framework to provide a general understanding of the
building blocks of medical coding models and summarizes recent advanced models
under the proposed framework. Our unified framework decomposes medical coding
into four main components, i.e., encoder modules for text feature extraction,
mechanisms for building deep encoder architectures, decoder modules for
transforming hidden representations into medical codes, and the usage of
auxiliary information. Finally, we discuss key research challenges and future
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clustering Text Using Attention. (arXiv:2201.02816v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02816">
<div class="article-summary-box-inner">
<span><p>Clustering Text has been an important problem in the domain of Natural
Language Processing. While there are techniques to cluster text based on using
conventional clustering techniques on top of contextual or non-contextual
vector space representations, it still remains a prevalent area of research
possible to various improvements in performance and implementation of these
techniques. This paper discusses a novel technique to cluster text using
attention mechanisms. Attention Mechanisms have proven to be highly effective
in various NLP tasks in recent times. This paper extends the idea of attention
mechanism in clustering space and sheds some light on a whole new area of
research
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coherence-Based Distributed Document Representation Learning for Scientific Documents. (arXiv:2201.02846v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02846">
<div class="article-summary-box-inner">
<span><p>Distributed document representation is one of the basic problems in natural
language processing. Currently distributed document representation methods
mainly consider the context information of words or sentences. These methods do
not take into account the coherence of the document as a whole, e.g., a
relation between the paper title and abstract, headline and description, or
adjacent bodies in the document. The coherence shows whether a document is
meaningful, both logically and syntactically, especially in scientific
documents (papers or patents, etc.). In this paper, we propose a coupled text
pair embedding (CTPE) model to learn the representation of scientific
documents, which maintains the coherence of the document with coupled text
pairs formed by segmenting the document. First, we divide the document into two
parts (e.g., title and abstract, etc) which construct a coupled text pair.
Then, we adopt negative sampling to construct uncoupled text pairs whose two
parts are from different documents. Finally, we train the model to judge
whether the text pair is coupled or uncoupled and use the obtained embedding of
coupled text pairs as the embedding of documents. We perform experiments on
three datasets for one information retrieval task and two recommendation tasks.
The experimental results verify the effectiveness of the proposed CTPE model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effect of Toxic Review Content on Overall Product Sentiment. (arXiv:2201.02857v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02857">
<div class="article-summary-box-inner">
<span><p>Toxic contents in online product review are a common phenomenon. A content is
perceived to be toxic when it is rude, disrespectful, or unreasonable and make
individuals leave the discussion. Machine learning algorithms helps the sell
side community to identify such toxic patterns and eventually moderate such
inputs. Yet, the extant literature provides fewer information about the
sentiment of a prospective consumer on the perception of a product after being
exposed to such toxic review content. In this study, we collect a balanced data
set of review comments from 18 different players segregated into three
different sectors from google play-store. Then we calculate the sentence-level
sentiment and toxicity score of individual review content. Finally, we use
structural equation modelling to quantitatively study the influence of toxic
content on overall product sentiment. We observe that comment toxicity
negatively influences overall product sentiment but do not exhibit a mediating
effect over reviewer score to influence sector-wise relative rating.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Indian Language Wordnets and their Linkages with Princeton WordNet. (arXiv:2201.02977v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02977">
<div class="article-summary-box-inner">
<span><p>Wordnets are rich lexico-semantic resources. Linked wordnets are extensions
of wordnets, which link similar concepts in wordnets of different languages.
Such resources are extremely useful in many Natural Language Processing (NLP)
applications, primarily those based on knowledge-based approaches. In such
approaches, these resources are considered as gold standard/oracle. Thus, it is
crucial that these resources hold correct information. Thereby, they are
created by human experts. However, human experts in multiple languages are hard
to come by. Thus, the community would benefit from sharing of such manually
created resources. In this paper, we release mappings of 18 Indian language
wordnets linked with Princeton WordNet. We believe that availability of such
resources will have a direct impact on the progress in NLP for these languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethink Stealthy Backdoor Attacks in Natural Language Processing. (arXiv:2201.02993v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02993">
<div class="article-summary-box-inner">
<span><p>Recently, it has been shown that natural language processing (NLP) models are
vulnerable to a kind of security threat called the Backdoor Attack, which
utilizes a `backdoor trigger' paradigm to mislead the models. The most
threatening backdoor attack is the stealthy backdoor, which defines the
triggers as text style or syntactic. Although they have achieved an incredible
high attack success rate (ASR), we find that the principal factor contributing
to their ASR is not the `backdoor trigger' paradigm. Thus the capacity of these
stealthy backdoor attacks is overestimated when categorized as backdoor
attacks. Therefore, to evaluate the real attack power of backdoor attacks, we
propose a new metric called attack successful rate difference (ASRD), which
measures the ASR difference between clean state and poison state models.
Besides, since the defenses against stealthy backdoor attacks are absent, we
propose Trigger Breaker, consisting of two too simple tricks that can defend
against stealthy backdoor attacks effectively. Experiments on text
classification tasks show that our method achieves significantly better
performance than state-of-the-art defense methods against stealthy backdoor
attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot and Few-Shot Classification of Biomedical Articles in Context of the COVID-19 Pandemic. (arXiv:2201.03017v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03017">
<div class="article-summary-box-inner">
<span><p>MeSH (Medical Subject Headings) is a large thesaurus created by the National
Library of Medicine and used for fine-grained indexing of publications in the
biomedical domain. In the context of the COVID-19 pandemic, MeSH descriptors
have emerged in relation to articles published on the corresponding topic.
Zero-shot classification is an adequate response for timely labeling of the
stream of papers with MeSH categories. In this work, we hypothesise that rich
semantic information available in MeSH has potential to improve BioBERT
representations and make them more suitable for zero-shot/few-shot tasks. We
frame the problem as determining if MeSH term definitions, concatenated with
paper abstracts are valid instances or not, and leverage multi-task learning to
induce the MeSH hierarchy in the representations thanks to a seq2seq task.
Results establish a baseline on the MedLine and LitCovid datasets, and probing
shows that the resulting representations convey the hierarchical relations
present in MeSH.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Ensemble Approach to Acronym Extraction using Transformers. (arXiv:2201.03026v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03026">
<div class="article-summary-box-inner">
<span><p>Acronyms are abbreviated units of a phrase constructed by using initial
components of the phrase in a text. Automatic extraction of acronyms from a
text can help various Natural Language Processing tasks like machine
translation, information retrieval, and text summarisation. This paper
discusses an ensemble approach for the task of Acronym Extraction, which
utilises two different methods to extract acronyms and their corresponding long
forms. The first method utilises a multilingual contextual language model and
fine-tunes the model to perform the task. The second method relies on a
convolutional neural network architecture to extract acronyms and append them
to the output of the previous method. We also augment the official training
dataset with additional training samples extracted from several open-access
journals to help improve the task performance. Our dataset analysis also
highlights the noise within the current task dataset. Our approach achieves the
following macro-F1 scores on test data released with the task: Danish (0.74),
English-Legal (0.72), English-Scientific (0.73), French (0.63), Persian (0.57),
Spanish (0.65), Vietnamese (0.65). We release our code and models publicly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medication Error Detection Using Contextual Language Models. (arXiv:2201.03035v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03035">
<div class="article-summary-box-inner">
<span><p>Medication errors most commonly occur at the ordering or prescribing stage,
potentially leading to medical complications and poor health outcomes. While it
is possible to catch these errors using different techniques; the focus of this
work is on textual and contextual analysis of prescription information to
detect and prevent potential medication errors. In this paper, we demonstrate
how to use BERT-based contextual language models to detect anomalies in written
or spoken text based on a data set extracted from real-world medical data of
thousands of patient records. The proposed models are able to learn patterns of
text dependency and predict erroneous output based on contextual information
such as patient data. The experimental results yield accuracy up to 96.63% for
text input and up to 79.55% for speech input, which is satisfactory for most
real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Projection: A Mixed-Initiative Research Process. (arXiv:2201.03107v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03107">
<div class="article-summary-box-inner">
<span><p>Communication of dense information between humans and machines is relatively
low bandwidth. Many modern search and recommender systems operate as machine
learning black boxes, giving little insight as to how they represent
information or why they take certain actions. We present Projection, a
mixed-initiative interface that aims to increase the bandwidth of communication
between humans and machines throughout the research process. The interface
supports adding context to searches and visualizing information in multiple
dimensions with techniques such as hierarchical clustering and spatial
projections. Potential customers have shown interest in the application
integrating their research outlining and search processes, enabling them to
structure their searches in hierarchies, and helping them visualize related
spaces of knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards the Next 1000 Languages in Multilingual Machine Translation: Exploring the Synergy Between Supervised and Self-Supervised Learning. (arXiv:2201.03110v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03110">
<div class="article-summary-box-inner">
<span><p>Achieving universal translation between all human language pairs is the
holy-grail of machine translation (MT) research. While recent progress in
massively multilingual MT is one step closer to reaching this goal, it is
becoming evident that extending a multilingual MT system simply by training on
more parallel data is unscalable, since the availability of labeled data for
low-resource and non-English-centric language pairs is forbiddingly limited. To
this end, we present a pragmatic approach towards building a multilingual MT
model that covers hundreds of languages, using a mixture of supervised and
self-supervised objectives, depending on the data availability for different
language pairs. We demonstrate that the synergy between these two training
paradigms enables the model to produce high-quality translations in the
zero-resource setting, even surpassing supervised translation quality for low-
and mid-resource languages. We conduct a wide array of experiments to
understand the effect of the degree of multilingual supervision, domain
mismatches and amounts of parallel and monolingual data on the quality of our
self-supervised multilingual models. To demonstrate the scalability of the
approach, we train models with over 200 languages and demonstrate high
performance on zero-resource translation on several previously under-studied
languages. We hope our findings will serve as a stepping stone towards enabling
translation for the next thousand languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic and sentiment analysis of selected Bhagavad Gita translations using BERT-based language framework. (arXiv:2201.03115v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03115">
<div class="article-summary-box-inner">
<span><p>It is well known that translations of songs and poems not only breaks rhythm
and rhyming patterns, but also results in loss of semantic information. The
Bhagavad Gita is an ancient Hindu philosophical text originally written in
Sanskrit that features a conversation between Lord Krishna and Arjuna prior to
the Mahabharata war. The Bhagavad Gita is also one of the key sacred texts in
Hinduism and known as the forefront of the Vedic corpus of Hinduism. In the
last two centuries, there has been a lot of interest in Hindu philosophy by
western scholars and hence the Bhagavad Gita has been translated in a number of
languages. However, there is not much work that validates the quality of the
English translations. Recent progress of language models powered by deep
learning has enabled not only translations but better understanding of language
and texts with semantic and sentiment analysis. Our work is motivated by the
recent progress of language models powered by deep learning methods. In this
paper, we compare selected translations (mostly from Sanskrit to English) of
the Bhagavad Gita using semantic and sentiment analyses. We use hand-labelled
sentiment dataset for tuning state-of-art deep learning-based language model
known as \textit{bidirectional encoder representations from transformers}
(BERT). We use novel sentence embedding models to provide semantic analysis for
selected chapters and verses across translations. Finally, we use the
aforementioned models for sentiment and semantic analyses and provide
visualisation of results. Our results show that although the style and
vocabulary in the respective Bhagavad Gita translations vary widely, the
sentiment analysis and semantic similarity shows that the message conveyed are
mostly similar across the translations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantifying Gender Bias in Consumer Culture. (arXiv:2201.03173v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03173">
<div class="article-summary-box-inner">
<span><p>Cultural items like songs have an important impact in creating and
reinforcing stereotypes, biases, and discrimination. But the actual nature of
such items is often less transparent. Take songs, for example. Are lyrics
biased against women? And how have any such biases changed over time? Natural
language processing of a quarter of a million songs over 50 years quantifies
misogyny. Women are less likely to be associated with desirable traits (i.e.,
competence), and while this bias has decreased, it persists. Ancillary analyses
further suggest that song lyrics may help drive shifts in societal stereotypes
towards women, and that lyrical shifts are driven by male artists (as female
artists were less biased to begin with). Overall, these results shed light on
cultural evolution, subtle measures of bias and discrimination, and how natural
language processing and machine learning can provide deeper insight into
stereotypes and cultural change.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Style, Content, and the Success of Ideas. (arXiv:2201.03174v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03174">
<div class="article-summary-box-inner">
<span><p>Why do some things succeed in the marketplace of ideas? While some argue that
content drives success, others suggest that style, or the way ideas are
presented, also plays an important role. To provide a stringent test of style's
importance, we examine it in a context where content should be paramount:
academic research. While scientists often see writing as a disinterested way to
communicate unobstructed truth, a multi-method investigation indicates that
writing style shapes impact. Separating style from content can be difficult as
papers that tend to use certain language may also write about certain topics.
Consequently, we focus on a unique class of words linked to style (i.e.,
function words such as "and," "the," and "on") that are completely devoid of
content. Natural language processing of almost 30,000 articles from a range of
disciplines finds that function words explain 13-27% of language's impact on
citations. Ancillary analyses explore specific categories of function words to
suggest how style matters, highlighting the role of writing simplicity,
personal voice, and temporal perspective. Experiments further underscore the
causal impact of style. The results suggest how to boost communication's impact
and highlight the value of natural language processing for understanding the
success of ideas.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Writing Style Aware Document-level Event Extraction. (arXiv:2201.03188v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03188">
<div class="article-summary-box-inner">
<span><p>Event extraction, the technology that aims to automatically get the
structural information from documents, has attracted more and more attention in
many fields. Most existing works discuss this issue with the token-level
multi-label classification framework by distinguishing the tokens as different
roles while ignoring the writing styles of documents. The writing style is a
special way of content organizing for documents and it is relative fixed in
documents with a special field (e.g. financial, medical documents, etc.). We
argue that the writing style contains important clues for judging the roles for
tokens and the ignorance of such patterns might lead to the performance
degradation for the existing works. To this end, we model the writing style in
documents as a distribution of argument roles, i.e., Role-Rank Distribution,
and propose an event extraction model with the Role-Rank Distribution based
Supervision Mechanism to capture this pattern through the supervised training
process of an event extraction task. We compare our model with state-of-the-art
methods on several real-world datasets. The empirical results show that our
approach outperforms other alternatives with the captured patterns. This
verifies the writing style contains valuable information that could improve the
performance of the event extraction task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully automatic scoring of handwritten descriptive answers in Japanese language tests. (arXiv:2201.03215v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03215">
<div class="article-summary-box-inner">
<span><p>This paper presents an experiment of automatically scoring handwritten
descriptive answers in the trial tests for the new Japanese university entrance
examination, which were made for about 120,000 examinees in 2017 and 2018.
There are about 400,000 answers with more than 20 million characters. Although
all answers have been scored by human examiners, handwritten characters are not
labelled. We present our attempt to adapt deep neural network-based handwriting
recognizers trained on a labelled handwriting dataset into this unlabeled
answer set. Our proposed method combines different training strategies,
ensembles multiple recognizers, and uses a language model built from a large
general corpus to avoid overfitting into specific data. In our experiment, the
proposed method records character accuracy of over 97% using about 2,000
verified labelled answers that account for less than 0.5% of the dataset. Then,
the recognized answers are fed into a pre-trained automatic scoring system
based on the BERT model without correcting misrecognized characters and
providing rubric annotations. The automatic scoring system achieves from 0.84
to 0.98 of Quadratic Weighted Kappa (QWK). As QWK is over 0.8, it represents
acceptable similarity of scoring between the automatic scoring system and the
human examiners. These results are promising for further research on end-to-end
automatic scoring of descriptive answers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empirical study on BlenderBot 2.0 Errors Analysis in terms of Model, Data and User-Centric Approach. (arXiv:2201.03239v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03239">
<div class="article-summary-box-inner">
<span><p>BlenderBot 2.0 is a dialogue model that represents open-domain chatbots by
reflecting real-time information and remembering user information for an
extended period using an internet search module and multi-session. Nonetheless,
the model still has room for improvement. To this end, we examined BlenderBot
2.0 limitations and errors from three perspectives: model, data, and user. From
the data point of view, we highlight the unclear guidelines provided to workers
during the crowdsourcing process, as well as a lack of a process for refining
hate speech in the collected data and verifying the accuracy of internet-based
information. From a user perspective, we identify nine types of problems of
BlenderBot 2.0, and their causes are thoroughly investigated. Furthermore, for
each point of view, practical improvement methods are proposed, and we discuss
several potential future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Planck Radiation and Quantization Scheme for Human Cognition and Language. (arXiv:2201.03306v1 [q-bio.NC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03306">
<div class="article-summary-box-inner">
<span><p>As a result of the identification of 'identity' and 'indistinguishability'
and strong experimental evidence for the presence of the associated
Bose-Einstein statistics in human cognition and language, we argued in previous
work for an extension of the research domain of quantum cognition. In addition
to quantum complex vector spaces and quantum probability models, we showed that
quantization itself, with words as quanta, is relevant and potentially
important to human cognition. In the present work, we build on this result, and
introduce a powerful radiation quantization scheme for human cognition. We show
that the lack of independence of the Bose-Einstein statistics compared to the
Maxwell-Boltzmann statistics can be explained by the presence of a 'meaning
dynamics', which causes words to be attracted to the same words. And so words
clump together in the same states, a phenomenon well known for photons in the
early years of quantum mechanics, leading to fierce disagreements between
Planck and Einstein. Using a simple example, we introduce all the elements to
get a better and detailed view of this 'meaning dynamics', such as micro and
macro states, and Maxwell-Boltzmann, Bose-Einstein and Fermi-Dirac numbers and
weights, and compare this example and its graphs, with the radiation
quantization scheme of a Winnie the Pooh story, also with its graphs. By
connecting a concept directly to human experience, we show that entanglement is
a necessity for preserving the 'meaning dynamics' we identified, and it becomes
clear in what way Fermi-Dirac addresses human memory. There, in spaces with
internal parameters identical words can nevertheless be assigned different
states.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TiltedBERT: Resource Adjustable Version of BERT. (arXiv:2201.03327v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03327">
<div class="article-summary-box-inner">
<span><p>In this paper, we proposed a novel adjustable fine-tuning method that
improves the training and inference time of the BERT model on downstream tasks.
In the proposed method, we first detect more important word vectors in each
layer by our proposed redundancy metric and then eliminate the less important
word vectors with our proposed strategy. In our method, the word vector
elimination rate in each layer is controlled by the Tilt-Rate hyper-parameter,
and the model learns to work with a considerably lower number of Floating Point
Operations (FLOPs) than the original BERT\textsubscript{base} model. Our
proposed method does not need any extra training steps, and also it can be
generalized to other transformer-based models. We perform extensive experiments
that show the word vectors in higher layers have an impressive amount of
redundancy that can be eliminated and decrease the training and inference time.
Experimental results on extensive sentiment analysis, classification and
regression datasets, and benchmarks like IMDB and GLUE showed that our proposed
method is effective in various datasets. By applying our method on the
BERT\textsubscript{base} model, we decrease the inference time up to 5.3 times
with less than 0.85\% accuracy degradation on average. After the fine-tuning
stage, the inference time of our model can be adjusted with our method
offline-tuning property for a wide range of the Tilt-Rate value selections.
Also, we propose a mathematical speedup analysis that can estimate the speedup
of our method accurately. With the help of this analysis, the Tilt-Rate
hyper-parameter can be selected before fine-tuning or while offline-tuning
stages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge Base Population. (arXiv:2201.03335v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03335">
<div class="article-summary-box-inner">
<span><p>We present a new open-source and extensible knowledge extraction toolkit,
called DeepKE (Deep learning based Knowledge Extraction), supporting standard
fully supervised, low-resource few-shot and document-level scenarios. DeepKE
implements various information extraction tasks, including named entity
recognition, relation extraction and attribute extraction. With a unified
framework, DeepKE allows developers and researchers to customize datasets and
models to extract information from unstructured texts according to their
requirements. Specifically, DeepKE not only provides various functional modules
and model implementation for different tasks and scenarios but also organizes
all components by consistent frameworks to maintain sufficient modularity and
extensibility. Besides, we present an online platform in
\url{<a href="http://deepke.zjukg.cn/">this http URL</a>} for real-time extraction of various tasks. DeepKE
has been equipped with Google Colab tutorials and comprehensive documents for
beginners. We release the source code at
\url{https://github.com/zjunlp/DeepKE}, with a demo video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Morphological Analysis of Japanese Hiragana Sentences using the BI-LSTM CRF Model. (arXiv:2201.03366v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03366">
<div class="article-summary-box-inner">
<span><p>This study proposes a method to develop neural models of the morphological
analyzer for Japanese Hiragana sentences using the Bi-LSTM CRF model.
Morphological analysis is a technique that divides text data into words and
assigns information such as parts of speech. This technique plays an essential
role in downstream applications in Japanese natural language processing systems
because the Japanese language does not have word delimiters between words.
Hiragana is a type of Japanese phonogramic characters, which is used for texts
for children or people who cannot read Chinese characters. Morphological
analysis of Hiragana sentences is more difficult than that of ordinary Japanese
sentences because there is less information for dividing. For morphological
analysis of Hiragana sentences, we demonstrated the effectiveness of
fine-tuning using a model based on ordinary Japanese text and examined the
influence of training data on texts of various genres.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Clinical Trial Reports: Extracting Medical Entities and Their Relations. (arXiv:2010.03550v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03550">
<div class="article-summary-box-inner">
<span><p>The best evidence concerning comparative treatment effectiveness comes from
clinical trials, the results of which are reported in unstructured articles.
Medical experts must manually extract information from articles to inform
decision-making, which is time-consuming and expensive. Here we consider the
end-to-end task of both (a) extracting treatments and outcomes from full-text
articles describing clinical trials (entity identification) and, (b) inferring
the reported results for the former with respect to the latter (relation
extraction). We introduce new data for this task, and evaluate models that have
recently achieved state-of-the-art results on similar tasks in Natural Language
Processing. We then propose a new method motivated by how trial results are
typically presented that outperforms these purely data-driven baselines.
Finally, we run a fielded evaluation of the model with a non-profit seeking to
identify existing drugs that might be re-purposed for cancer, showing the
potential utility of end-to-end evidence extraction systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Deep Learning and Explainability for Automatic Report Generation from Medical Images. (arXiv:2010.10563v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10563">
<div class="article-summary-box-inner">
<span><p>Every year physicians face an increasing demand of image-based diagnosis from
patients, a problem that can be addressed with recent artificial intelligence
methods. In this context, we survey works in the area of automatic report
generation from medical images, with emphasis on methods using deep neural
networks, with respect to: (1) Datasets, (2) Architecture Design, (3)
Explainability and (4) Evaluation Metrics. Our survey identifies interesting
developments, but also remaining challenges. Among them, the current evaluation
of generated reports is especially weak, since it mostly relies on traditional
Natural Language Processing (NLP) metrics, which do not accurately capture
medical correctness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Lay Language Summarization of Biomedical Scientific Reviews. (arXiv:2012.12573v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12573">
<div class="article-summary-box-inner">
<span><p>Health literacy has emerged as a crucial factor in making appropriate health
decisions and ensuring treatment outcomes. However, medical jargon and the
complex structure of professional language in this domain make health
information especially hard to interpret. Thus, there is an urgent unmet need
for automated methods to enhance the accessibility of the biomedical literature
to the general population. This problem can be framed as a type of translation
problem between the language of healthcare professionals, and that of the
general public. In this paper, we introduce the novel task of automated
generation of lay language summaries of biomedical scientific reviews, and
construct a dataset to support the development and evaluation of automated
methods through which to enhance the accessibility of the biomedical
literature. We conduct analyses of the various challenges in solving this task,
including not only summarization of the key points but also explanation of
background knowledge and simplification of professional language. We experiment
with state-of-the-art summarization models as well as several data augmentation
techniques, and evaluate their performance using both automated metrics and
human assessment. Results indicate that automatically generated summaries
produced using contemporary neural architectures can achieve promising quality
and readability as compared with reference summaries developed for the lay
public by experts (best ROUGE-L of 50.24 and Flesch-Kincaid readability score
of 13.30). We also discuss the limitations of the current attempt, providing
insights and directions for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding. (arXiv:2012.14740v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14740">
<div class="article-summary-box-inner">
<span><p>Pre-training of text and layout has proved effective in a variety of
visually-rich document understanding tasks due to its effective model
architecture and the advantage of large-scale unlabeled scanned/digital-born
documents. We propose LayoutLMv2 architecture with new pre-training tasks to
model the interaction among text, layout, and image in a single multi-modal
framework. Specifically, with a two-stream multi-modal Transformer encoder,
LayoutLMv2 uses not only the existing masked visual-language modeling task but
also the new text-image alignment and text-image matching tasks, which make it
better capture the cross-modality interaction in the pre-training stage.
Meanwhile, it also integrates a spatial-aware self-attention mechanism into the
Transformer architecture so that the model can fully understand the relative
positional relationship among different text blocks. Experiment results show
that LayoutLMv2 outperforms LayoutLM by a large margin and achieves new
state-of-the-art results on a wide variety of downstream visually-rich document
understanding tasks, including FUNSD (0.7895 $\to$ 0.8420), CORD (0.9493 $\to$
0.9601), SROIE (0.9524 $\to$ 0.9781), Kleister-NDA (0.8340 $\to$ 0.8520),
RVL-CDIP (0.9443 $\to$ 0.9564), and DocVQA (0.7295 $\to$ 0.8672). We made our
model and code publicly available at \url{https://aka.ms/layoutlmv2}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Schema Curation via Causal Association Rule Mining. (arXiv:2104.08811v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08811">
<div class="article-summary-box-inner">
<span><p>Event schemas are structured knowledge sources defining typical real-world
scenarios (e.g., going to an airport). We present a framework for efficient
human-in-the-loop construction of a schema library, based on a novel script
induction system and a well-crafted interface that allows non-experts to
"program" complex event structures. Associated with this work we release a
schema library: a machine readable resource of 232 detailed event schemas, each
of which describe a distinct typical scenario in terms of its relevant
sub-event structure (what happens in the scenario), participants (who plays a
role in the scenario), fine-grained typing of each participant, and the implied
relational constraints between them. We make our schema library and the
SchemaBlocks interface available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Genetic Algorithms For Extractive Summarization. (arXiv:2105.02365v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02365">
<div class="article-summary-box-inner">
<span><p>Most current work in NLP utilizes deep learning, which requires a lot of
training data and computational power. This paper investigates the strengths of
Genetic Algorithms (GAs) for extractive summarization, as we hypothesized that
GAs could construct more efficient solutions for the summarization task due to
their relative customizability relative to deep learning models. This is done
by building a vocabulary set, the words of which are represented as an array of
weights, and optimizing those set of weights with the GA. These weights can be
used to build an overall weighting of a sentence, which can then be passed to
some threshold for extraction. Our results showed that the GA was able to learn
a weight representation that could filter out excessive vocabulary and thus
dictate sentence importance based on common English words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotional Voice Conversion: Theory, Databases and ESD. (arXiv:2105.14762v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14762">
<div class="article-summary-box-inner">
<span><p>In this paper, we first provide a review of the state-of-the-art emotional
voice conversion research, and the existing emotional speech databases. We then
motivate the development of a novel emotional speech database (ESD) that
addresses the increasing research need. With this paper, the ESD database is
now made available to the research community. The ESD database consists of 350
parallel utterances spoken by 10 native English and 10 native Chinese speakers
and covers 5 emotion categories (neutral, happy, angry, sad and surprise). More
than 29 hours of speech data were recorded in a controlled acoustic
environment. The database is suitable for multi-speaker and cross-lingual
emotional voice conversion studies. As case studies, we implement several
state-of-the-art emotional voice conversion systems on the ESD database. This
paper provides a reference study on ESD in conjunction with its release.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMURF: SeMantic and linguistic UndeRstanding Fusion for Caption Evaluation via Typicality Analysis. (arXiv:2106.01444v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01444">
<div class="article-summary-box-inner">
<span><p>The open-ended nature of visual captioning makes it a challenging area for
evaluation. The majority of proposed models rely on specialized training to
improve human-correlation, resulting in limited adoption, generalizability, and
explainabilty. We introduce "typicality", a new formulation of evaluation
rooted in information theory, which is uniquely suited for problems lacking a
definite ground truth. Typicality serves as our framework to develop a novel
semantic comparison, SPARCS, as well as referenceless fluency evaluation
metrics. Over the course of our analysis, two separate dimensions of fluency
naturally emerge: style, captured by metric SPURTS, and grammar, captured in
the form of grammatical outlier penalties. Through extensive experiments and
ablation studies on benchmark datasets, we show how these decomposed dimensions
of semantics and fluency provide greater system-level insight into captioner
differences. Our proposed metrics along with their combination, SMURF, achieve
state-of-the-art correlation with human judgment when compared with other
rule-based evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergent Communication of Generalizations. (arXiv:2106.02668v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02668">
<div class="article-summary-box-inner">
<span><p>To build agents that can collaborate effectively with others, recent research
has trained artificial agents to communicate with each other in Lewis-style
referential games. However, this often leads to successful but uninterpretable
communication. We argue that this is due to the game objective: communicating
about a single object in a shared visual context is prone to overfitting and
does not encourage language useful beyond concrete reference. In contrast,
human language conveys a rich variety of abstract ideas. To promote such
skills, we propose games that require communicating generalizations over sets
of objects representing abstract visual concepts, optionally with separate
contexts for each agent. We find that these games greatly improve systematicity
and interpretability of the learned languages, according to several metrics in
the literature. Finally, we propose a method for identifying logical operations
embedded in the emergent languages by learning an approximate compositional
reconstruction of the language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06965">
<div class="article-summary-box-inner">
<span><p>Recently, chest X-ray report generation, which aims to automatically generate
descriptions of given chest X-ray images, has received growing research
interests. The key challenge of chest X-ray report generation is to accurately
capture and describe the abnormal regions. In most cases, the normal regions
dominate the entire chest X-ray image, and the corresponding descriptions of
these normal regions dominate the final report. Due to such data bias,
learning-based models may fail to attend to abnormal regions. In this work, to
effectively capture and describe abnormal regions, we propose the Contrastive
Attention (CA) model. Instead of solely focusing on the current input image,
the CA model compares the current input image with normal images to distill the
contrastive information. The acquired contrastive information can better
represent the visual features of abnormal regions. According to the experiments
on the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into
several existing models can boost their performance across most metrics. In
addition, according to the analysis, the CA model can help existing models
better attend to the abnormal regions and provide more accurate descriptions
which are crucial for an interpretable diagnosis. Specifically, we achieve the
state-of-the-art results on the two public datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">O2NA: An Object-Oriented Non-Autoregressive Approach for Controllable Video Captioning. (arXiv:2108.02359v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02359">
<div class="article-summary-box-inner">
<span><p>Video captioning combines video understanding and language generation.
Different from image captioning that describes a static image with details of
almost every object, video captioning usually considers a sequence of frames
and biases towards focused objects, e.g., the objects that stay in focus
regardless of the changing background. Therefore, detecting and properly
accommodating focused objects is critical in video captioning. To enforce the
description of focused objects and achieve controllable video captioning, we
propose an Object-Oriented Non-Autoregressive approach (O2NA), which performs
caption generation in three steps: 1) identify the focused objects and predict
their locations in the target caption; 2) generate the related attribute words
and relation words of these focused objects to form a draft caption; and 3)
combine video information to refine the draft caption to a fluent final
caption. Since the focused objects are generated and located ahead of other
words, it is difficult to apply the word-by-word autoregressive generation
process; instead, we adopt a non-autoregressive approach. The experiments on
two benchmark datasets, i.e., MSR-VTT and MSVD, demonstrate the effectiveness
of O2NA, which achieves results competitive with the state-of-the-arts but with
both higher diversity and higher inference speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset. (arXiv:2108.13897v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13897">
<div class="article-summary-box-inner">
<span><p>The MS MARCO ranking dataset has been widely used for training deep learning
models for IR tasks, achieving considerable effectiveness on diverse zero-shot
scenarios. However, this type of resource is scarce in languages other than
English. In this work, we present mMARCO, a multilingual version of the MS
MARCO passage ranking dataset comprising 13 languages that was created using
machine translation. We evaluated mMARCO by fine-tuning monolingual and
multilingual re-ranking models, as well as a dense multilingual model on this
dataset. Experimental results demonstrate that multilingual models fine-tuned
on our translated dataset achieve superior effectiveness to models fine-tuned
on the original English version alone. Our distilled multilingual re-ranker is
competitive with non-distilled models while having 5.4 times fewer parameters.
Lastly, we show a positive correlation between translation quality and
retrieval effectiveness, providing evidence that improvements in translation
methods might lead to improvements in multilingual information retrieval. The
translated datasets and fine-tuned models are available at
https://github.com/unicamp-dl/mMARCO.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence Level Contrastive Learning for Text Summarization. (arXiv:2109.03481v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03481">
<div class="article-summary-box-inner">
<span><p>Contrastive learning models have achieved great success in unsupervised
visual representation learning, which maximize the similarities between feature
representations of different views of the same image, while minimize the
similarities between feature representations of views of different images. In
text summarization, the output summary is a shorter form of the input document
and they have similar meanings. In this paper, we propose a contrastive
learning model for supervised abstractive text summarization, where we view a
document, its gold summary and its model generated summaries as different views
of the same mean representation and maximize the similarities between them
during training. We improve over a strong sequence-to-sequence text generation
model (i.e., BART) on three different summarization datasets. Human evaluation
also shows that our model achieves better faithfulness ratings compared to its
counterpart without contrastive objectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models. (arXiv:2111.02840v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02840">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models have achieved tremendous success
across a wide range of natural language understanding (NLU) tasks, even
surpassing human performance. However, recent studies reveal that the
robustness of these models can be challenged by carefully crafted textual
adversarial examples. While several individual datasets have been proposed to
evaluate model robustness, a principled and comprehensive benchmark is still
missing. In this paper, we present Adversarial GLUE (AdvGLUE), a new multi-task
benchmark to quantitatively and thoroughly explore and evaluate the
vulnerabilities of modern large-scale language models under various types of
adversarial attacks. In particular, we systematically apply 14 textual
adversarial attack methods to GLUE tasks to construct AdvGLUE, which is further
validated by humans for reliable annotations. Our findings are summarized as
follows. (i) Most existing adversarial attack algorithms are prone to
generating invalid or ambiguous adversarial examples, with around 90% of them
either changing the original semantic meanings or misleading human annotators
as well. Therefore, we perform a careful filtering process to curate a
high-quality benchmark. (ii) All the language models and robust training
methods we tested perform poorly on AdvGLUE, with scores lagging far behind the
benign accuracy. We hope our work will motivate the development of new
adversarial attacks that are more stealthy and semantic-preserving, as well as
new robust language models against sophisticated adversarial attacks. AdvGLUE
is available at https://adversarialglue.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probabilistic Impact Score Generation using Ktrain-BERT to Identify Hate Words from Twitter Discussions. (arXiv:2111.12939v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12939">
<div class="article-summary-box-inner">
<span><p>Social media has seen a worrying rise in hate speech in recent times.
Branching to several distinct categories of cyberbullying, gender
discrimination, or racism, the combined label for such derogatory content can
be classified as toxic content in general. This paper presents experimentation
with a Keras wrapped lightweight BERT model to successfully identify hate
speech and predict probabilistic impact score for the same to extract the
hateful words within sentences. The dataset used for this task is the Hate
Speech and Offensive Content Detection (HASOC 2021) data from FIRE 2021 in
English. Our system obtained a validation accuracy of 82.60%, with a maximum
F1-Score of 82.68%. Subsequently, our predictive cases performed significantly
well in generating impact scores for successful identification of the hate
tweets as well as the hateful words from tweet pools.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CO2Sum:Contrastive Learning for Factual-Consistent Abstractive Summarization. (arXiv:2112.01147v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01147">
<div class="article-summary-box-inner">
<span><p>Generating factual-consistent summaries is a challenging task for abstractive
summarization. Previous works mainly encode factual information or perform
post-correct/rank after decoding. In this paper, we provide a
factual-consistent solution from the perspective of contrastive learning, which
is a natural extension of previous works. We propose CO2Sum (Contrastive for
Consistency), a contrastive learning scheme that can be easily applied on
sequence-to-sequence models for factual-consistent abstractive summarization,
proving that the model can be fact-aware without modifying the architecture.
CO2Sum applies contrastive learning on the encoder, which can help the model be
aware of the factual information contained in the input article, or performs
contrastive learning on the decoder, which makes the model to generate
factual-correct output summary. What's more, these two schemes are orthogonal
and can be combined to further improve faithfulness. Comprehensive experiments
on public benchmarks demonstrate that CO2Sum improves the faithfulness on large
pre-trained language models and reaches competitive results compared to other
strong factual-consistent summarization baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JABER and SABER: Junior and Senior Arabic BERt. (arXiv:2112.04329v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04329">
<div class="article-summary-box-inner">
<span><p>Language-specific pre-trained models have proven to be more accurate than
multilingual ones in a monolingual evaluation setting, Arabic is no exception.
However, we found that previously released Arabic BERT models were
significantly under-trained. In this technical report, we present JABER and
SABER, Junior and Senior Arabic BERt respectively, our pre-trained language
model prototypes dedicated for Arabic. We conduct an empirical study to
systematically evaluate the performance of models across a diverse set of
existing Arabic NLU tasks. Experimental results show that JABER and SABER
achieve state-of-the-art performances on ALUE, a new benchmark for Arabic
Language Understanding Evaluation, as well as on a well-established NER
benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A cognitively driven weighted-entropy model for embedding semantic categories in hyperbolic geometry. (arXiv:2112.06876v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06876">
<div class="article-summary-box-inner">
<span><p>In this paper, an unsupervised and cognitively driven weighted-entropy method
for embedding semantic categories in hyperbolic geometry is proposed. The model
is driven by two fields of research in cognitive linguistics: the first is the
statistical learning theory of language acquisition and the proposal of using
high-dimensional networks to represent semantic knowledge in cognition, and the
second is the domain-specific approach to semantic communication. Weighted
conditional entropy of word co-occurrence is proposed as the embedding metric,
and the two weighting parameters are collocation diversity and conditional
probability ranking in the corresponding statistical distribution. The
Boltzmann distribution is then used on the weighted-entropy metric and embedded
into a hyperbolic Poincare disk model. Testing has been in particular performed
in the domains of basic color and kinship words, which belong to the classes
that domain-specificity focused research in cognitive semantics has most
intensively investigated. Results show that this new approach can successfully
model and map the semantic relationships of popularity and similarity for most
of the basic color and kinship words in English and have potential to be
generalized to other semantic domains and different languages. Generally, this
paper contributes to both computational cognitive semantics and the research on
network and geometry-driven language embedding in computational linguistics and
NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Answer Type and Relation Prediction Task (SMART 2021). (arXiv:2112.07606v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07606">
<div class="article-summary-box-inner">
<span><p>Each year the International Semantic Web Conference organizes a set of
Semantic Web Challenges to establish competitions that will advance
state-of-the-art solutions in some problem domains. The Semantic Answer Type
and Relation Prediction Task (SMART) task is one of the ISWC 2021 Semantic Web
challenges. This is the second year of the challenge after a successful SMART
2020 at ISWC 2020. This year's version focuses on two sub-tasks that are very
important to Knowledge Base Question Answering (KBQA): Answer Type Prediction
and Relation Prediction. Question type and answer type prediction can play a
key role in knowledge base question answering systems providing insights about
the expected answer that are helpful to generate correct queries or rank the
answer candidates. More concretely, given a question in natural language, the
first task is, to predict the answer type using a target ontology (e.g.,
DBpedia or Wikidata. Similarly, the second task is to identify relations in the
natural language query and link them to the relations in a target ontology.
This paper discusses the task descriptions, benchmark datasets, and evaluation
metrics. For more information, please visit https://smart-task.github.io/2021/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViNMT: Neural Machine Translation Toolkit. (arXiv:2112.15272v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.15272">
<div class="article-summary-box-inner">
<span><p>We present an open-source toolkit for neural machine translation (NMT). The
new toolkit is mainly based on vaulted Transformer (Vaswani et al., 2017) along
with many other improvements detailed below, in order to create a
self-contained, simple to use, consistent and comprehensive framework for
Machine Translation tasks of various domains. It is tooled to support both
bilingual and multilingual translation tasks, starting from building the model
from respective corpora, to inferring new predictions or packaging the model to
serving-capable JIT format.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hypers at ComMA@ICON: Modelling Aggressiveness, Gender Bias and Communal Bias Identification. (arXiv:2112.15417v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.15417">
<div class="article-summary-box-inner">
<span><p>Due to the exponentially increasing reach of social media, it is essential to
focus on its negative aspects as it can potentially divide society and incite
people into violence. In this paper, we present our system description of work
on the shared task ComMA@ICON, where we have to classify how aggressive the
sentence is and if the sentence is gender-biased or communal biased. These
three could be the primary reasons to cause significant problems in society. As
team Hypers we have proposed an approach that utilizes different pretrained
models with Attention and mean pooling methods. We were able to get Rank 3 with
0.223 Instance F1 score on Bengali, Rank 2 with 0.322 Instance F1 score on
Multi-lingual set, Rank 4 with 0.129 Instance F1 score on Meitei and Rank 5
with 0.336 Instance F1 score on Hindi. The source code and the pretrained
models of this work can be found here.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERN2: an advanced neural biomedical named entity recognition and normalization tool. (arXiv:2201.02080v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02080">
<div class="article-summary-box-inner">
<span><p>In biomedical natural language processing, named entity recognition (NER) and
named entity normalization (NEN) are key tasks that enable the automatic
extraction of biomedical entities (e.g., diseases and chemicals) from the
ever-growing biomedical literature. In this paper, we present BERN2 (Advanced
Biomedical Entity Recognition and Normalization), a tool that improves the
previous neural network-based NER tool (Kim et al., 2019) by employing a
multi-task NER model and neural network-based NEN models to achieve much faster
and more accurate inference. We hope that our tool can help annotate
large-scale biomedical texts more accurately for various tasks such as
biomedical knowledge graph construction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Summarization Based on Video-text Modelling. (arXiv:2201.02494v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02494">
<div class="article-summary-box-inner">
<span><p>Modern video summarization methods are based on deep neural networks which
require a large amount of annotated data for training. However, existing
datasets for video summarization are small-scale, easily leading to
over-fitting of the deep models. Considering that the annotation of large-scale
datasets is time-consuming, we propose a multimodal self-supervised learning
framework to obtain semantic representations of videos, which benefits the
video summarization task. Specifically, we explore the semantic consistency
between the visual information and text information of videos, for the
self-supervised pretraining of a multimodal encoder on a newly-collected
dataset of video-text pairs. Additionally, we introduce a progressive video
summarization method, where the important content in a video is pinpointed
progressively to generate better summaries. Finally, an objective evaluation
framework is proposed to measure the quality of video summaries based on video
classification. Extensive experiments have proved the effectiveness and
superiority of our method in rank correlation coefficients, F-score, and the
proposed objective evaluation compared to the state of the art.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Compressing Models with Few Samples: Mimicking then Replacing. (arXiv:2201.02620v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02620">
<div class="article-summary-box-inner">
<span><p>Few-sample compression aims to compress a big redundant model into a small
compact one with only few samples. If we fine-tune models with these limited
few samples directly, models will be vulnerable to overfit and learn almost
nothing. Hence, previous methods optimize the compressed model layer-by-layer
and try to make every layer have the same outputs as the corresponding layer in
the teacher model, which is cumbersome. In this paper, we propose a new
framework named Mimicking then Replacing (MiR) for few-sample compression,
which firstly urges the pruned model to output the same features as the
teacher's in the penultimate layer, and then replaces teacher's layers before
penultimate with a well-tuned compact one. Unlike previous layer-wise
reconstruction methods, our MiR optimizes the entire network holistically,
which is not only simple and effective, but also unsupervised and general. MiR
outperforms previous methods with large margins. Codes will be available soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Microdosing: Knowledge Distillation for GAN based Compression. (arXiv:2201.02624v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02624">
<div class="article-summary-box-inner">
<span><p>Recently, significant progress has been made in learned image and video
compression. In particular the usage of Generative Adversarial Networks has
lead to impressive results in the low bit rate regime. However, the model size
remains an important issue in current state-of-the-art proposals and existing
solutions require significant computation effort on the decoding side. This
limits their usage in realistic scenarios and the extension to video
compression. In this paper, we demonstrate how to leverage knowledge
distillation to obtain equally capable image decoders at a fraction of the
original number of parameters. We investigate several aspects of our solution
including sequence specialization with side information for image coding.
Finally, we also show how to transfer the obtained benefits into the setting of
video compression. Overall, this allows us to reduce the model size by a factor
of 20 and to achieve 50% reduction in decoding time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FlexHDR: Modelling Alignment and Exposure Uncertainties for Flexible HDR Imaging. (arXiv:2201.02625v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02625">
<div class="article-summary-box-inner">
<span><p>High dynamic range (HDR) imaging is of fundamental importance in modern
digital photography pipelines and used to produce a high-quality photograph
with well exposed regions despite varying illumination across the image. This
is typically achieved by merging multiple low dynamic range (LDR) images taken
at different exposures. However, over-exposed regions and misalignment errors
due to poorly compensated motion result in artefacts such as ghosting. In this
paper, we present a new HDR imaging technique that specifically models
alignment and exposure uncertainties to produce high quality HDR results. We
introduce a strategy that learns to jointly align and assess the alignment and
exposure reliability using an HDR-aware, uncertainty-driven attention map that
robustly merges the frames into a single high quality HDR image. Further, we
introduce a progressive, multi-stage image fusion approach that can flexibly
merge any number of LDR images in a permutation-invariant manner. Experimental
results show our method can produce better quality HDR images with up to 0.8dB
PSNR improvement to the state-of-the-art, and subjective improvements in terms
of better detail, colours, and fewer artefacts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning with less labels in Digital Pathology via Scribble Supervision from natural images. (arXiv:2201.02627v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02627">
<div class="article-summary-box-inner">
<span><p>A critical challenge of training deep learning models in the Digital
Pathology (DP) domain is the high annotation cost by medical experts. One way
to tackle this issue is via transfer learning from the natural image domain
(NI), where the annotation cost is considerably cheaper. Cross-domain transfer
learning from NI to DP is shown to be successful via class
labels~\cite{teh2020learning}. One potential weakness of relying on class
labels is the lack of spatial information, which can be obtained from spatial
labels such as full pixel-wise segmentation labels and scribble labels. We
demonstrate that scribble labels from NI domain can boost the performance of DP
models on two cancer classification datasets (Patch Camelyon Breast Cancer and
Colorectal Cancer dataset). Furthermore, we show that models trained with
scribble labels yield the same performance boost as full pixel-wise
segmentation labels despite being significantly easier and faster to collect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">United adversarial learning for liver tumor segmentation and detection of multi-modality non-contrast MRI. (arXiv:2201.02629v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02629">
<div class="article-summary-box-inner">
<span><p>Simultaneous segmentation and detection of liver tumors (hemangioma and
hepatocellular carcinoma (HCC)) by using multi-modality non-contrast magnetic
resonance imaging (NCMRI) are crucial for the clinical diagnosis. However, it
is still a challenging task due to: (1) the HCC information on NCMRI is
invisible or insufficient makes extraction of liver tumors feature difficult;
(2) diverse imaging characteristics in multi-modality NCMRI causes feature
fusion and selection difficult; (3) no specific information between hemangioma
and HCC on NCMRI cause liver tumors detection difficult. In this study, we
propose a united adversarial learning framework (UAL) for simultaneous liver
tumors segmentation and detection using multi-modality NCMRI. The UAL first
utilizes a multi-view aware encoder to extract multi-modality NCMRI information
for liver tumor segmentation and detection. In this encoder, a novel edge
dissimilarity feature pyramid module is designed to facilitate the
complementary multi-modality feature extraction. Second, the newly designed
fusion and selection channel is used to fuse the multi-modality feature and
make the decision of the feature selection. Then, the proposed mechanism of
coordinate sharing with padding integrates the multi-task of segmentation and
detection so that it enables multi-task to perform united adversarial learning
in one discriminator. Lastly, an innovative multi-phase radiomics guided
discriminator exploits the clear and specific tumor information to improve the
multi-task performance via the adversarial learning strategy. The UAL is
validated in corresponding multi-modality NCMRI (i.e. T1FS pre-contrast MRI,
T2FS MRI, and DWI) and three phases contrast-enhanced MRI of 255 clinical
subjects. The experiments show that UAL has great potential in the clinical
diagnosis of liver tumors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02639">
<div class="article-summary-box-inner">
<span><p>As humans, we navigate the world through all our senses, using perceptual
input from each one to correct the others. We introduce MERLOT Reserve, a model
that represents videos jointly over time -- through a new training objective
that learns from audio, subtitles, and video frames. Given a video, we replace
snippets of text and audio with a MASK token; the model learns by choosing the
correct masked-out snippet. Our objective learns faster than alternatives, and
performs well at scale: we pretrain on 20 million YouTube videos.
</p>
<p>Empirical results show that MERLOT Reserve learns strong representations
about videos through all constituent modalities. When finetuned, it sets a new
state-of-the-art on both VCR and TVQA, outperforming prior work by 5% and 7%
respectively. Ablations show that both tasks benefit from audio pretraining --
even VCR, a QA task centered around images (without sound). Moreover, our
objective enables out-of-the-box prediction, revealing strong multimodal
commonsense understanding. In a fully zero-shot setting, our model obtains
competitive results on four video understanding tasks, even outperforming
supervised approaches on the recently proposed Situated Reasoning (STAR)
benchmark.
</p>
<p>We analyze why incorporating audio leads to better vision-language
representations, suggesting significant opportunities for future research. We
conclude by discussing ethical and societal implications of multimodal
pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPU-Net: Lightweight U-Net with more diverse features. (arXiv:2201.02656v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02656">
<div class="article-summary-box-inner">
<span><p>Image segmentation is an important task in the medical image field and many
convolutional neural networks (CNNs) based methods have been proposed, among
which U-Net and its variants show promising performance. In this paper, we
propose GP-module and GPU-Net based on U-Net, which can learn more diverse
features by introducing Ghost module and atrous spatial pyramid pooling (ASPP).
Our method achieves better performance with more than 4 times fewer parameters
and 2 times fewer FLOPs, which provides a new potential direction for future
research. Our plug-and-play module can also be applied to existing segmentation
methods to further improve their performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Coding for Machines: Partial transmission of SIFT features. (arXiv:2201.02689v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02689">
<div class="article-summary-box-inner">
<span><p>The paper deals with Video Coding for Machines that is a new paradigm in
video coding related to consumption of decoded video by humans and machines.
For such tasks, joint transmission of compressed video and features is
considered. In this paper, we focus our considerations of features on SIFT
keypoints. They can be extracted from the decoded video with losses in number
of keypoints and their parameters as compared to the SIFT keypoints extracted
from the original video. Such losses are studied for HEVC and VVC as functions
of the quantization parameter and the bitrate. In the paper, we propose to
transmit the residual feature data together with the compressed video.
Therefore, even for strongly compressed video, the transmission of whole all
SIFT keypoint information is avoided.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BottleFit: Learning Compressed Representations in Deep Neural Networks for Effective and Efficient Split Computing. (arXiv:2201.02693v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02693">
<div class="article-summary-box-inner">
<span><p>Although mission-critical applications require the use of deep neural
networks (DNNs), their continuous execution at mobile devices results in a
significant increase in energy consumption. While edge offloading can decrease
energy consumption, erratic patterns in channel quality, network and edge
server load can lead to severe disruption of the system's key operations. An
alternative approach, called split computing, generates compressed
representations within the model (called "bottlenecks"), to reduce bandwidth
usage and energy consumption. Prior work has proposed approaches that introduce
additional layers, to the detriment of energy consumption and latency. For this
reason, we propose a new framework called BottleFit, which, in addition to
targeted DNN architecture modifications, includes a novel training strategy to
achieve high accuracy even with strong compression rates. We apply BottleFit on
cutting-edge DNN models in image classification, and show that BottleFit
achieves 77.1% data compression with up to 0.6% accuracy loss on ImageNet
dataset, while state of the art such as SPINN loses up to 6% in accuracy. We
experimentally measure the power consumption and latency of an image
classification application running on an NVIDIA Jetson Nano board (GPU-based)
and a Raspberry PI board (GPU-less). We show that BottleFit decreases power
consumption and latency respectively by up to 49% and 89% with respect to
(w.r.t.) local computing and by 37% and 55% w.r.t. edge offloading. We also
compare BottleFit with state-of-the-art autoencoders-based approaches, and show
that (i) BottleFit reduces power consumption and execution time respectively by
up to 54% and 44% on the Jetson and 40% and 62% on Raspberry PI; (ii) the size
of the head model executed on the mobile device is 83 times smaller. The code
repository will be published for full reproducibility of the results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Development of Automatic Tree Counting Software from UAV Based Aerial Images With Machine Learning. (arXiv:2201.02698v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02698">
<div class="article-summary-box-inner">
<span><p>Unmanned aerial vehicles (UAV) are used successfully in many application
areas such as military, security, monitoring, emergency aid, tourism,
agriculture, and forestry. This study aims to automatically count trees in
designated areas on the Siirt University campus from high-resolution images
obtained by UAV. Images obtained at 30 meters height with 20% overlap were
stitched offline at the ground station using Adobe Photoshop's photo merge
tool. The resulting image was denoised and smoothed by applying the 3x3 median
and mean filter, respectively. After generating the orthophoto map of the
aerial images captured by the UAV in certain regions, the bounding boxes of
different objects on these maps were labeled in the modalities of HSV (Hue
Saturation Value), RGB (Red Green Blue) and Gray. Training, validation, and
test datasets were generated and then have been evaluated for classification
success rates related to tree detection using various machine learning
algorithms. In the last step, a ground truth model was established by obtaining
the actual tree numbers, and then the prediction performance was calculated by
comparing the reference ground truth data with the proposed model. It is
considered that significant success has been achieved for tree count with an
average accuracy rate of 87% obtained using the MLP classifier in predetermined
regions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Block Walsh-Hadamard Transform Based Binary Layers in Deep Neural Networks. (arXiv:2201.02711v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02711">
<div class="article-summary-box-inner">
<span><p>Convolution has been the core operation of modern deep neural networks. It is
well-known that convolutions can be implemented in the Fourier Transform
domain. In this paper, we propose to use binary block Walsh-Hadamard transform
(WHT) instead of the Fourier transform. We use WHT-based binary layers to
replace some of the regular convolution layers in deep neural networks. We
utilize both one-dimensional (1-D) and two-dimensional (2-D) binary WHTs in
this paper. In both 1-D and 2-D layers, we compute the binary WHT of the input
feature map and denoise the WHT domain coefficients using a nonlinearity which
is obtained by combining soft-thresholding with the tanh function. After
denoising, we compute the inverse WHT. We use 1D-WHT to replace the $1\times 1$
convolutional layers, and 2D-WHT layers can replace the 3$\times$3 convolution
layers and Squeeze-and-Excite layers. 2D-WHT layers with trainable weights can
be also inserted before the Global Average Pooling (GAP) layers to assist the
dense layers. In this way, we can reduce the number of trainable parameters
significantly with a slight decrease in trainable parameters. In this paper, we
implement the WHT layers into MobileNet-V2, MobileNet-V3-Large, and ResNet to
reduce the number of parameters significantly with negligible accuracy loss.
Moreover, according to our speed test, the 2D-FWHT layer runs about 24 times as
fast as the regular $3\times 3$ convolution with 19.51\% less RAM usage in an
NVIDIA Jetson Nano experiment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pseudo-labelling and Meta Reweighting Learning for Image Aesthetic Quality Assessment. (arXiv:2201.02714v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02714">
<div class="article-summary-box-inner">
<span><p>In the tasks of image aesthetic quality evaluation, it is difficult to reach
both the high score area and low score area due to the normal distribution of
aesthetic datasets. To reduce the error in labeling and solve the problem of
normal data distribution, we propose a new aesthetic mixed dataset with
classification and regression called AMD-CR, and we train a meta reweighting
network to reweight the loss of training data differently. In addition, we
provide a training strategy acccording to different stages, based on pseudo
labels of the binary classification task, and then we use it for aesthetic
training acccording to different stages in classification and regression tasks.
In the construction of the network structure, we construct an aesthetic
adaptive block (AAB) structure that can adapt to any size of the input images.
Besides, we also use the efficient channel attention (ECA) to strengthen the
feature extracting ability of each task. The experimental result shows that our
method improves 0.1112 compared with the conventional methods in SROCC. The
method can also help to find best aesthetic path planning for unmanned aerial
vehicles (UAV) and vehicles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-time Rail Recognition Based on 3D Point Clouds. (arXiv:2201.02726v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02726">
<div class="article-summary-box-inner">
<span><p>Accurate rail location is a crucial part in the railway support driving
system for safety monitoring. LiDAR can obtain point clouds that carry 3D
information for the railway environment, especially in darkness and terrible
weather conditions. In this paper, a real-time rail recognition method based on
3D point clouds is proposed to solve the challenges, such as disorderly, uneven
density and large volume of the point clouds. A voxel down-sampling method is
first presented for density balanced of railway point clouds, and pyramid
partition is designed to divide the 3D scanning area into the voxels with
different volumes. Then, a feature encoding module is developed to find the
nearest neighbor points and to aggregate their local geometric features for the
center point. Finally, a multi-scale neural network is proposed to generate the
prediction results of each voxel and the rail location. The experiments are
conducted under 9 sequences of 3D point cloud data for the railway. The results
show that the method has good performance in detecting straight, curved and
other complex topologies rails.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Expert Knowledge-guided Geometric Representation Learning for Magnetic Resonance Imaging-based Glioma Grading. (arXiv:2201.02746v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02746">
<div class="article-summary-box-inner">
<span><p>Radiomics and deep learning have shown high popularity in automatic glioma
grading. Radiomics can extract hand-crafted features that quantitatively
describe the expert knowledge of glioma grades, and deep learning is powerful
in extracting a large number of high-throughput features that facilitate the
final classification. However, the performance of existing methods can still be
improved as their complementary strengths have not been sufficiently
investigated and integrated. Furthermore, lesion maps are usually needed for
the final prediction at the testing phase, which is very troublesome. In this
paper, we propose an expert knowledge-guided geometric representation learning
(ENROL) framework . Geometric manifolds of hand-crafted features and learned
features are constructed to mine the implicit relationship between deep
learning and radiomics, and therefore to dig mutual consent and essential
representation for the glioma grades. With a specially designed manifold
discrepancy measurement, the grading model can exploit the input image data and
expert knowledge more effectively in the training phase and get rid of the
requirement of lesion segmentation maps at the testing phase. The proposed
framework is flexible regarding deep learning architectures to be utilized.
Three different architectures have been evaluated and five models have been
compared, which show that our framework can always generate promising results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QuadTree Attention for Vision Transformers. (arXiv:2201.02767v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02767">
<div class="article-summary-box-inner">
<span><p>Transformers have been successful in many vision tasks, thanks to their
capability of capturing long-range dependency. However, their quadratic
computational complexity poses a major obstacle for applying them to vision
tasks requiring dense predictions, such as object detection, feature matching,
stereo, etc. We introduce QuadTree Attention, which reduces the computational
complexity from quadratic to linear. Our quadtree transformer builds token
pyramids and computes attention in a coarse-to-fine manner. At each level, the
top K patches with the highest attention scores are selected, such that at the
next level, attention is only evaluated within the relevant regions
corresponding to these top K patches. We demonstrate that quadtree attention
achieves state-of-the-art performance in various vision tasks, e.g. with 4.0%
improvement in feature matching on ScanNet, about 50% flops reduction in stereo
matching, 0.4-1.5% improvement in top-1 accuracy on ImageNet classification,
1.2-1.8% improvement on COCO object detection, and 0.7-2.4% improvement on
semantic segmentation over previous state-of-the-art transformers. The codes
are available at
https://github.com/Tangshitao/QuadtreeAttention}{https://github.com/Tangshitao/QuadtreeAttention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Sneak Attack on Segmentation of Medical Images Using Deep Neural Network Classifiers. (arXiv:2201.02771v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02771">
<div class="article-summary-box-inner">
<span><p>Instead of using current deep-learning segmentation models (like the UNet and
variants), we approach the segmentation problem using trained Convolutional
Neural Network (CNN) classifiers, which automatically extract important
features from classified targets for image classification. Those extracted
features can be visualized and formed heatmaps using Gradient-weighted Class
Activation Mapping (Grad-CAM). This study tested whether the heatmaps could be
used to segment the classified targets. We also proposed an evaluation method
for the heatmaps; that is, to re-train the CNN classifier using images filtered
by heatmaps and examine its performance. We used the mean-Dice coefficient to
evaluate segmentation results. Results from our experiments show that heatmaps
can locate and segment partial tumor areas. But only use of the heatmaps from
CNN classifiers may not be an optimal approach for segmentation. In addition,
we have verified that the predictions of CNN classifiers mainly depend on tumor
areas, and dark regions in Grad-CAM's heatmaps also contribute to
classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Empirical Study of Vision-Language Pre-trained Model for Supervised Cross-Modal Retrieval. (arXiv:2201.02772v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02772">
<div class="article-summary-box-inner">
<span><p>Cross-Modal Retrieval (CMR) is an important research topic across multimodal
computing and information retrieval, which takes one type of data as the query
to retrieve relevant data of another type, and has been widely used in many
real-world applications. Recently, the vision-language pre-trained model
represented by CLIP has demonstrated its superiority of learning visual and
textual representations and its impressive performance on various vision and
language related tasks. Although CLIP as well as the previous pre-trained
models have shown great performance improvement in unsupervised CMR, the
performance and impact of these pre-trained models on supervised CMR were
rarely explored due to the lack of multimodal class-level associations.
</p>
<p>In this paper, we take CLIP as the current representative vision-language
pre-trained model to conduct a comprehensive empirical study and provide
insights on its performance and impact on supervised CMR. To this end, we first
propose a novel model CLIP4CMR (\textbf{CLIP For} supervised
\textbf{C}ross-\textbf{M}odal \textbf{R}etrieval) that employs pre-trained CLIP
as backbone network to perform supervised CMR. We then revisit the existing
loss function design in CMR, including the most common pair-wise losses,
class-wise losses and hybrid ones, and provide insights on applying CLIP.
Moreover, we investigate several concerned issues in supervised CMR and provide
new perspectives for this field via CLIP4CMR, including the robustness to
modality imbalance and the sensitivity to hyper-parameters. Extensive
experimental results show that the CLIP4CMR achieves SOTA results with
significant improvements on the benchmark datasets Wikipedia, NUS-WIDE,
Pascal-Sentence and XmediaNet. Our data and codes are publicly available at
https://github.com/zhixiongz/CLIP4CMR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Baseline Statistical Method For Robust User-Assisted Multiple Segmentation. (arXiv:2201.02779v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02779">
<div class="article-summary-box-inner">
<span><p>Recently, several image segmentation methods that welcome and leverage
different types of user assistance have been developed. In these methods, the
user inputs can be provided by drawing bounding boxes over image objects,
drawing scribbles or planting seeds that help to differentiate between image
boundaries or by interactively refining the missegmented image regions. Due to
the variety in the types and the amounts of these inputs, relative assessment
of different segmentation methods becomes difficult. As a possible solution, we
propose a simple yet effective, statistical segmentation method that can handle
and utilize different input types and amounts. The proposed method is based on
robust hypothesis testing, specifically the DGL test, and can be implemented
with time complexity that is linear in the number of pixels and quadratic in
the number of image regions. Therefore, it is suitable to be used as a baseline
method for quick benchmarking and assessing the relative performance
improvements of different types of user-assisted segmentation algorithms. We
provide a mathematical analysis on the operation of the proposed method,
discuss its capabilities and limitations, provide design guidelines and present
simulations that validate its operation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relieving Long-tailed Instance Segmentation via Pairwise Class Balance. (arXiv:2201.02784v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02784">
<div class="article-summary-box-inner">
<span><p>Long-tailed instance segmentation is a challenging task due to the extreme
imbalance of training samples among classes. It causes severe biases of the
head classes (with majority samples) against the tailed ones. This renders "how
to appropriately define and alleviate the bias" one of the most important
issues. Prior works mainly use label distribution or mean score information to
indicate a coarse-grained bias. In this paper, we explore to excavate the
confusion matrix, which carries the fine-grained misclassification details, to
relieve the pairwise biases, generalizing the coarse one. To this end, we
propose a novel Pairwise Class Balance (PCB) method, built upon a confusion
matrix which is updated during training to accumulate the ongoing prediction
preferences. PCB generates fightback soft labels for regularization during
training. Besides, an iterative learning paradigm is developed to support a
progressive and smooth regularization in such debiasing. PCB can be plugged and
played to any existing method as a complement. Experimental results on LVIS
demonstrate that our method achieves state-of-the-art performance without bells
and whistles. Superior results across various architectures show the
generalization ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RARA: Zero-shot Sim2Real Visual Navigation with Following Foreground Cues. (arXiv:2201.02798v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02798">
<div class="article-summary-box-inner">
<span><p>The gap between simulation and the real-world restrains many machine learning
breakthroughs in computer vision and reinforcement learning from being
applicable in the real world. In this work, we tackle this gap for the specific
case of camera-based navigation, formulating it as following a visual cue in
the foreground with arbitrary backgrounds. The visual cue in the foreground can
often be simulated realistically, such as a line, gate or cone. The challenge
then lies in coping with the unknown backgrounds and integrating both. As such,
the goal is to train a visual agent on data captured in an empty simulated
environment except for this foreground cue and test this model directly in a
visually diverse real world. In order to bridge this big gap, we show it's
crucial to combine following techniques namely: Randomized augmentation of the
fore- and background, regularization with both deep supervision and triplet
loss and finally abstraction of the dynamics by using waypoints rather than
direct velocity commands. The various techniques are ablated in our
experimental results both qualitatively and quantitatively finally
demonstrating a successful transfer from simulation to the real world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counteracting Dark Web Text-Based CAPTCHA with Generative Adversarial Learning for Proactive Cyber Threat Intelligence. (arXiv:2201.02799v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02799">
<div class="article-summary-box-inner">
<span><p>Automated monitoring of dark web (DW) platforms on a large scale is the first
step toward developing proactive Cyber Threat Intelligence (CTI). While there
are efficient methods for collecting data from the surface web, large-scale
dark web data collection is often hindered by anti-crawling measures. In
particular, text-based CAPTCHA serves as the most prevalent and prohibiting
type of these measures in the dark web. Text-based CAPTCHA identifies and
blocks automated crawlers by forcing the user to enter a combination of
hard-to-recognize alphanumeric characters. In the dark web, CAPTCHA images are
meticulously designed with additional background noise and variable character
length to prevent automated CAPTCHA breaking. Existing automated CAPTCHA
breaking methods have difficulties in overcoming these dark web challenges. As
such, solving dark web text-based CAPTCHA has been relying heavily on human
involvement, which is labor-intensive and time-consuming. In this study, we
propose a novel framework for automated breaking of dark web CAPTCHA to
facilitate dark web data collection. This framework encompasses a novel
generative method to recognize dark web text-based CAPTCHA with noisy
background and variable character length. To eliminate the need for human
involvement, the proposed framework utilizes Generative Adversarial Network
(GAN) to counteract dark web background noise and leverages an enhanced
character segmentation algorithm to handle CAPTCHA images with variable
character length. Our proposed framework, DW-GAN, was systematically evaluated
on multiple dark web CAPTCHA testbeds. DW-GAN significantly outperformed the
state-of-the-art benchmark methods on all datasets, achieving over 94.4%
success rate on a carefully collected real-world dark web dataset...
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyperspectral Image Denoising Using Non-convex Local Low-rank and Sparse Separation with Spatial-Spectral Total Variation Regularization. (arXiv:2201.02812v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02812">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel nonconvex approach to robust principal
component analysis for HSI denoising, which focuses on simultaneously
developing more accurate approximations to both rank and column-wise sparsity
for the low-rank and sparse components, respectively. In particular, the new
method adopts the log-determinant rank approximation and a novel
$\ell_{2,\log}$ norm, to restrict the local low-rank or column-wisely sparse
properties for the component matrices, respectively. For the
$\ell_{2,\log}$-regularized shrinkage problem, we develop an efficient,
closed-form solution, which is named $\ell_{2,\log}$-shrinkage operator. The
new regularization and the corresponding operator can be generally used in
other problems that require column-wise sparsity. Moreover, we impose the
spatial-spectral total variation regularization in the log-based nonconvex RPCA
model, which enhances the global piece-wise smoothness and spectral consistency
from the spatial and spectral views in the recovered HSI. Extensive experiments
on both simulated and real HSIs demonstrate the effectiveness of the proposed
method in denoising HSIs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of Hyperspectral Images by Using Spectral Data and Fully Connected Neural Network. (arXiv:2201.02821v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02821">
<div class="article-summary-box-inner">
<span><p>It is observed that high classification performance is achieved for one- and
two-dimensional signals by using deep learning methods. In this context, most
researchers have tried to classify hyperspectral images by using deep learning
methods and classification success over 90% has been achieved for these images.
Deep neural networks (DNN) actually consist of two parts: i) Convolutional
neural network (CNN) and ii) fully connected neural network (FCNN). While CNN
determines the features, FCNN is used in classification. In classification of
the hyperspectral images, it is observed that almost all of the researchers
used 2D or 3D convolution filters on the spatial data beside spectral data
(features). It is convenient to use convolution filters on images or time
signals. In hyperspectral images, each pixel is represented by a signature
vector which consists of individual features that are independent of each
other. Since the order of the features in the vector can be changed, it doesn't
make sense to use convolution filters on these features as on time signals. At
the same time, since the hyperspectral images do not have a textural structure,
there is no need to use spatial data besides spectral data. In this study,
hyperspectral images of Indian pines, Salinas, Pavia centre, Pavia university
and Botswana are classified by using only fully connected neural network and
the spectral data with one dimensional. An average accuracy of 97.5% is
achieved for the test sets of all hyperspectral images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CrossMoDA 2021 challenge: Benchmark of Cross-Modality Domain Adaptation techniques for Vestibular Schwnannoma and Cochlea Segmentation. (arXiv:2201.02831v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02831">
<div class="article-summary-box-inner">
<span><p>Domain Adaptation (DA) has recently raised strong interests in the medical
imaging community. While a large variety of DA techniques has been proposed for
image segmentation, most of these techniques have been validated either on
private datasets or on small publicly available datasets. Moreover, these
datasets mostly addressed single-class problems. To tackle these limitations,
the Cross-Modality Domain Adaptation (crossMoDA) challenge was organised in
conjunction with the 24th International Conference on Medical Image Computing
and Computer Assisted Intervention (MICCAI 2021). CrossMoDA is the first large
and multi-class benchmark for unsupervised cross-modality DA. The challenge's
goal is to segment two key brain structures involved in the follow-up and
treatment planning of vestibular schwannoma (VS): the VS and the cochleas.
Currently, the diagnosis and surveillance in patients with VS are performed
using contrast-enhanced T1 (ceT1) MRI. However, there is growing interest in
using non-contrast sequences such as high-resolution T2 (hrT2) MRI. Therefore,
we created an unsupervised cross-modality segmentation benchmark. The training
set provides annotated ceT1 (N=105) and unpaired non-annotated hrT2 (N=105).
The aim was to automatically perform unilateral VS and bilateral cochlea
segmentation on hrT2 as provided in the testing set (N=137). A total of 16
teams submitted their algorithm for the evaluation phase. The level of
performance reached by the top-performing teams is strikingly high (best median
Dice - VS:88.4%; Cochleas:85.7%) and close to full supervision (median Dice -
VS:92.5%; Cochleas:87.7%). All top-performing methods made use of an
image-to-image translation approach to transform the source-domain images into
pseudo-target-domain images. A segmentation network was then trained using
these generated images and the manual annotations provided for the source
image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SGUIE-Net: Semantic Attention Guided Underwater Image Enhancement with Multi-Scale Perception. (arXiv:2201.02832v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02832">
<div class="article-summary-box-inner">
<span><p>Due to the wavelength-dependent light attenuation, refraction and scattering,
underwater images usually suffer from color distortion and blurred details.
However, due to the limited number of paired underwater images with undistorted
images as reference, training deep enhancement models for diverse degradation
types is quite difficult. To boost the performance of data-driven approaches,
it is essential to establish more effective learning mechanisms that mine
richer supervised information from limited training sample resources. In this
paper, we propose a novel underwater image enhancement network, called
SGUIE-Net, in which we introduce semantic information as high-level guidance
across different images that share common semantic regions. Accordingly, we
propose semantic region-wise enhancement module to perceive the degradation of
different semantic regions from multiple scales and feed it back to the global
attention features extracted from its original scale. This strategy helps to
achieve robust and visually pleasant enhancements to different semantic
objects, which should thanks to the guidance of semantic information for
differentiated enhancement. More importantly, for those degradation types that
are not common in the training sample distribution, the guidance connects them
with the already well-learned types according to their semantic relevance.
Extensive experiments on the publicly available datasets and our proposed
dataset demonstrated the impressive performance of SGUIE-Net. The code and
proposed dataset are available at: https://trentqq.github.io/SGUIE-Net.html
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weighted Encoding Optimization for Dynamic Single-pixel Imaging and Sensing. (arXiv:2201.02833v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02833">
<div class="article-summary-box-inner">
<span><p>Using single-pixel detection, the end-to-end neural network that jointly
optimizes both encoding and decoding enables high-precision imaging and
high-level semantic sensing. However, for varied sampling rates, the
large-scale network requires retraining that is laboursome and
computation-consuming. In this letter, we report a weighted optimization
technique for dynamic rate-adaptive single-pixel imaging and sensing, which
only needs to train the network for one time that is available for any sampling
rates. Specifically, we introduce a novel weighting scheme in the encoding
process to characterize different patterns' modulation efficiency. While the
network is training at a high sampling rate, the modulation patterns and
corresponding weights are updated iteratively, which produces optimal ranked
encoding series when converged. In the experimental implementation, the optimal
pattern series with the highest weights are employed for light modulation, thus
achieving highly-efficient imaging and sensing. The reported strategy saves the
additional training of another low-rate network required by the existing
dynamic single-pixel networks, which further doubles training efficiency.
Experiments on the MNIST dataset validated that once the network is trained
with a sampling rate of 1, the average imaging PSNR reaches 23.50 dB at 0.1
sampling rate, and the image-free classification accuracy reaches up to 95.00\%
at a sampling rate of 0.03 and 97.91\% at a sampling rate of 0.1.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-aligned Spatial Feature Extraction Network for UAV Vehicle Re-identification. (arXiv:2201.02836v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02836">
<div class="article-summary-box-inner">
<span><p>Compared with existing vehicle re-identification (ReID) tasks conducted with
datasets collected by fixed surveillance cameras, vehicle ReID for unmanned
aerial vehicle (UAV) is still under-explored and could be more challenging.
Vehicles with the same color and type show extremely similar appearance from
the UAV's perspective so that mining fine-grained characteristics becomes
necessary. Recent works tend to extract distinguishing information by regional
features and component features. The former requires input images to be aligned
and the latter entails detailed annotations, both of which are difficult to
meet in UAV application. In order to extract efficient fine-grained features
and avoid tedious annotating work, this letter develops an unsupervised
self-aligned network consisting of three branches. The network introduced a
self-alignment module to convert the input images with variable orientations to
a uniform orientation, which is implemented under the constraint of triple loss
function designed with spatial features. On this basis, spatial features,
obtained by vertical and horizontal segmentation methods, and global features
are integrated to improve the representation ability in embedded space.
Extensive experiments are conducted on UAV-VeID dataset, and our method
achieves the best performance compared with recent ReID works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mushrooms Detection, Localization and 3D Pose Estimation using RGB-D Sensor for Robotic-picking Applications. (arXiv:2201.02837v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02837">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose mushrooms detection, localization and 3D pose
estimation algorithm using RGB-D data acquired from a low-cost consumer RGB-D
sensor. We use the RGB and depth information for different purposes. From RGB
color, we first extract initial contour locations of the mushrooms and then
provide both the initial contour locations and the original image to active
contour for mushrooms segmentation. These segmented mushrooms are then used as
input to a circular Hough transform for each mushroom detection including its
center and radius. Once each mushroom's center position in the RGB image is
known, we then use the depth information to locate it in 3D space i.e. in world
coordinate system. In case of missing depth information at the detected center
of each mushroom, we estimate from the nearest available depth information
within the radius of each mushroom. We also estimate the 3D pose of each
mushroom using a pre-prepared upright mushroom model. We use a global
registration followed by local refine registration approach for this 3D pose
estimation. From the estimated 3D pose, we use only the rotation part expressed
in quaternion as an orientation of each mushroom. These estimated (X,Y,Z)
positions, diameters and orientations of the mushrooms are used for
robotic-picking applications. We carry out extensive experiments on both 3D
printed and real mushrooms which show that our method has an interesting
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Sample Importance for Cross-Scenario Video Temporal Grounding. (arXiv:2201.02848v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02848">
<div class="article-summary-box-inner">
<span><p>The task of temporal grounding aims to locate video moment in an untrimmed
video, with a given sentence query. This paper for the first time investigates
some superficial biases that are specific to the temporal grounding task, and
proposes a novel targeted solution. Most alarmingly, we observe that existing
temporal ground models heavily rely on some biases (e.g., high preference on
frequent concepts or certain temporal intervals) in the visual modal. This
leads to inferior performance when generalizing the model in cross-scenario
test setting. To this end, we propose a novel method called Debiased Temporal
Language Localizer (DebiasTLL) to prevent the model from naively memorizing the
biases and enforce it to ground the query sentence based on true inter-modal
relationship. Debias-TLL simultaneously trains two models. By our design, a
large discrepancy of these two models' predictions when judging a sample
reveals higher probability of being a biased sample. Harnessing the informative
discrepancy, we devise a data re-weighing scheme for mitigating the data
biases. We evaluate the proposed model in cross-scenario temporal grounding,
where the train / test data are heterogeneously sourced. Experiments show
large-margin superiority of the proposed method in comparison with
state-of-the-art competitors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatio-Temporal Tuples Transformer for Skeleton-Based Action Recognition. (arXiv:2201.02849v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02849">
<div class="article-summary-box-inner">
<span><p>Capturing the dependencies between joints is critical in skeleton-based
action recognition task. Transformer shows great potential to model the
correlation of important joints. However, the existing Transformer-based
methods cannot capture the correlation of different joints between frames,
which the correlation is very useful since different body parts (such as the
arms and legs in "long jump") between adjacent frames move together. Focus on
this problem, A novel spatio-temporal tuples Transformer (STTFormer) method is
proposed. The skeleton sequence is divided into several parts, and several
consecutive frames contained in each part are encoded. And then a
spatio-temporal tuples self-attention module is proposed to capture the
relationship of different joints in consecutive frames. In addition, a feature
aggregation module is introduced between non-adjacent frames to enhance the
ability to distinguish similar actions. Compared with the state-of-the-art
methods, our method achieves better performance on two large-scale datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image-based Automatic Dial Meter Reading in Unconstrained Scenarios. (arXiv:2201.02850v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02850">
<div class="article-summary-box-inner">
<span><p>The replacement of analog meters with smart meters is costly, laborious, and
far from complete in developing countries. The Energy Company of Parana (Copel)
(Brazil) performs more than 4 million meter readings (almost entirely of
non-smart devices) per month, and we estimate that 850 thousand of them are
from dial meters. Therefore, an image-based automatic reading system can reduce
human errors, create a proof of reading, and enable the customers to perform
the reading themselves through a mobile application. We propose novel
approaches for Automatic Dial Meter Reading (ADMR) and introduce a new dataset
for ADMR in unconstrained scenarios, called UFPR-ADMR-v2. Our best-performing
method combines YOLOv4 with a novel regression approach (AngReg), and explores
several postprocessing techniques. Compared to previous works, it decreased the
Mean Absolute Error (MAE) from 1,343 to 129 and achieved a meter recognition
rate (MRR) of 98.90% -- with an error tolerance of 1 Kilowatt-hour (kWh).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fake Hilsa Fish Detection Using Machine Vision. (arXiv:2201.02853v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02853">
<div class="article-summary-box-inner">
<span><p>Hilsa is the national fish of Bangladesh. Bangladesh is earning a lot of
foreign currency by exporting this fish. Unfortunately, in recent days, some
unscrupulous businessmen are selling fake Hilsa fishes to gain profit. The
Sardines and Sardinella are the most sold in the market as Hilsa. The
government agency of Bangladesh, namely Bangladesh Food Safety Authority said
that these fake Hilsa fish contain high levels of cadmium and lead which are
detrimental for humans. In this research, we have proposed a method that can
readily identify original Hilsa fish and fake Hilsa fish. Based on the research
available on online literature, we are the first to do research on identifying
original Hilsa fish. We have collected more than 16,000 images of original and
counterfeit Hilsa fish. To classify these images, we have used several deep
learning-based models. Then, the performance has been compared between them.
Among those models, DenseNet201 achieved the highest accuracy of 97.02%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoupling Makes Weakly Supervised Local Feature Better. (arXiv:2201.02861v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02861">
<div class="article-summary-box-inner">
<span><p>Weakly supervised learning can help local feature methods to overcome the
obstacle of acquiring a large-scale dataset with densely labeled
correspondences. However, since weak supervision cannot distinguish the losses
caused by the detection and description steps, directly conducting weakly
supervised learning within a joint describe-then-detect pipeline suffers
limited performance. In this paper, we propose a decoupled describe-then-detect
pipeline tailored for weakly supervised local feature learning. Within our
pipeline, the detection step is decoupled from the description step and
postponed until discriminative and robust descriptors are learned. In addition,
we introduce a line-to-window search strategy to explicitly use the camera pose
information for better descriptor learning. Extensive experiments show that our
method, namely PoSFeat (Camera Pose Supervised Feature), outperforms previous
fully and weakly supervised methods and achieves state-of-the-art performance
on a wide range of downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Generative Modeling for Volume Reconstruction in Cryo-Electron Microscop. (arXiv:2201.02867v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02867">
<div class="article-summary-box-inner">
<span><p>Recent breakthroughs in high resolution imaging of biomolecules in solution
with cryo-electron microscopy (cryo-EM) have unlocked new doors for the
reconstruction of molecular volumes, thereby promising further advances in
biology, chemistry, and pharmacological research amongst others. Despite
significant headway, the immense challenges in cryo-EM data analysis remain
legion and intricately inter-disciplinary in nature, requiring insights from
physicists, structural biologists, computer scientists, statisticians, and
applied mathematicians. Meanwhile, recent next-generation volume reconstruction
algorithms that combine generative modeling with end-to-end unsupervised deep
learning techniques have shown promising results on simulated data, but still
face considerable hurdles when applied to experimental cryo-EM images. In light
of the proliferation of such methods and given the interdisciplinary nature of
the task, we propose here a critical review of recent advances in the field of
deep generative modeling for high resolution cryo-EM volume reconstruction. The
present review aims to (i) compare and contrast these new methods, while (ii)
presenting them from a perspective and using terminology familiar to scientists
in each of the five aforementioned fields with no specific background in
cryo-EM. The review begins with an introduction to the mathematical and
computational challenges of deep generative models for cryo-EM volume
reconstruction, along with an overview of the baseline methodology shared
across this class of algorithms. Having established the common thread weaving
through these different models, we provide a practical comparison of these
state-of-the-art algorithms, highlighting their relative strengths and
weaknesses, along with the assumptions that they rely on. This allows us to
identify bottlenecks in current methods and avenues for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Defocus Deblur Microscopy via feature interactive coarse-to-fine network. (arXiv:2201.02876v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02876">
<div class="article-summary-box-inner">
<span><p>The clarity of microscopic images is vital in biology research and diagnosis.
When taking microscopy images at cell or molecule level, mechanical drift
occurs and could be difficult and expansive to counter. Such a problem could be
overcome by developing an end-to-end deep learning-based workflow capable of
predicting in focused microscopic images from out-of-focused counterparts. In
our model, we adopt a structure of multi-level U-net, each level connected
head-to-tail with corresponding convolution layers from each other. In contrast
to the conventional coarse-to-fine model, our model uses the knowledge
distilled from the coarse network transferred to the finer network. We evaluate
the performance of our model and found our method to be effective and has a
better performance by comparing the results with existing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Agricultural Plant Cataloging and Establishment of a Data Framework from UAV-based Crop Images by Computer Vision. (arXiv:2201.02885v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02885">
<div class="article-summary-box-inner">
<span><p>UAV-based image retrieval in modern agriculture enables gathering large
amounts of spatially referenced crop image data. In large-scale experiments,
however, UAV images suffer from containing a multitudinous amount of crops in a
complex canopy architecture. Especially for the observation of temporal
effects, this complicates the recognition of individual plants over several
images and the extraction of relevant information tremendously. In this work,
we present a hands-on workflow for the automatized temporal and spatial
identification and individualization of crop images from UAVs abbreviated as
"cataloging" based on comprehensible computer vision methods. We evaluate the
workflow on two real-world datasets. One dataset is recorded for observation of
Cercospora leaf spot - a fungal disease - in sugar beet over an entire growing
cycle. The other one deals with harvest prediction of cauliflower plants. The
plant catalog is utilized for the extraction of single plant images seen over
multiple time points. This gathers large-scale spatio-temporal image dataset
that in turn can be applied to train further machine learning models including
various data layers. The presented approach improves analysis and
interpretation of UAV data in agriculture significantly. By validation with
some reference data, our method shows an accuracy that is similar to more
complex deep learning-based recognition techniques. Our workflow is able to
automatize plant cataloging and training image extraction, especially for large
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resolving Camera Position for a Practical Application of Gaze Estimation on Edge Devices. (arXiv:2201.02946v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02946">
<div class="article-summary-box-inner">
<span><p>Most Gaze estimation research only works on a setup condition that a camera
perfectly captures eyes gaze. They have not literarily specified how to set up
a camera correctly for a given position of a person. In this paper, we carry
out a study on gaze estimation with a logical camera setup position. We further
bring our research in a practical application by using inexpensive edge devices
with a realistic scenario. That is, we first set up a shopping environment
where we want to grasp customers gazing behaviors. This setup needs an optimal
camera position in order to maintain estimation accuracy from existing gaze
estimation research. We then apply the state-of-the-art of few-shot learning
gaze estimation to reduce training sampling in the inference phase. In the
experiment, we perform our implemented research on NVIDIA Jetson TX2 and
achieve a reasonable speed, 12 FPS which is faster compared with our reference
work, without much degradation of gaze estimation accuracy. The source code is
released at https://github.com/linh-gist/GazeEstimationTX2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Box2Seg: Learning Semantics of 3D Point Clouds with Box-Level Supervision. (arXiv:2201.02963v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02963">
<div class="article-summary-box-inner">
<span><p>Learning dense point-wise semantics from unstructured 3D point clouds with
fewer labels, although a realistic problem, has been under-explored in
literature. While existing weakly supervised methods can effectively learn
semantics with only a small fraction of point-level annotations, we find that
the vanilla bounding box-level annotation is also informative for semantic
segmentation of large-scale 3D point clouds. In this paper, we introduce a
neural architecture, termed Box2Seg, to learn point-level semantics of 3D point
clouds with bounding box-level supervision. The key to our approach is to
generate accurate pseudo labels by exploring the geometric and topological
structure inside and outside each bounding box. Specifically, an
attention-based self-training (AST) technique and Point Class Activation
Mapping (PCAM) are utilized to estimate pseudo-labels. The network is further
trained and refined with pseudo labels. Experiments on two large-scale
benchmarks including S3DIS and ScanNet demonstrate the competitive performance
of the proposed method. In particular, the proposed network can be trained with
cheap, or even off-the-shelf bounding box-level annotations and subcloud-level
tags.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAXIM: Multi-Axis MLP for Image Processing. (arXiv:2201.02973v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02973">
<div class="article-summary-box-inner">
<span><p>Recent progress on Transformers and multi-layer perceptron (MLP) models
provide new network architectural designs for computer vision tasks. Although
these models proved to be effective in many vision tasks such as image
recognition, there remain challenges in adapting them for low-level vision. The
inflexibility to support high-resolution images and limitations of local
attention are perhaps the main bottlenecks for using Transformers and MLPs in
image restoration. In this work we present a multi-axis MLP based architecture,
called MAXIM, that can serve as an efficient and flexible general-purpose
vision backbone for image processing tasks. MAXIM uses a UNet-shaped
hierarchical structure and supports long-range interactions enabled by
spatially-gated MLPs. Specifically, MAXIM contains two MLP-based building
blocks: a multi-axis gated MLP that allows for efficient and scalable spatial
mixing of local and global visual cues, and a cross-gating block, an
alternative to cross-attention, which accounts for cross-feature mutual
conditioning. Both these modules are exclusively based on MLPs, but also
benefit from being both global and `fully-convolutional', two properties that
are desirable for image processing. Our extensive experimental results show
that the proposed MAXIM model achieves state-of-the-art performance on more
than ten benchmarks across a range of image processing tasks, including
denoising, deblurring, deraining, dehazing, and enhancement while requiring
fewer or comparable numbers of parameters and FLOPs than competitive models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhanced total variation minimization for stable image reconstruction. (arXiv:2201.02979v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02979">
<div class="article-summary-box-inner">
<span><p>The total variation (TV) regularization has phenomenally boosted various
variational models for image processing tasks. We propose combining the
backward diffusion process in the earlier literature of image enhancement with
the TV regularization and show that the resulting enhanced TV minimization
model is particularly effective for reducing the loss of contrast, which is
often encountered by models using the TV regularization. We establish stable
reconstruction guarantees for the enhanced TV model from noisy subsampled
measurements; non-adaptive linear measurements and variable-density sampled
Fourier measurements are considered. In particular, under some weaker
restricted isometry property conditions, the enhanced TV minimization model is
shown to have tighter reconstruction error bounds than various TV-based models
for the scenario where the level of noise is significant and the amount of
measurements is limited. The advantages of the enhanced TV model are also
numerically validated by preliminary experiments on the reconstruction of some
synthetic, natural, and medical images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Invariance encoding in sliced-Wasserstein space for image classification with limited training data. (arXiv:2201.02980v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02980">
<div class="article-summary-box-inner">
<span><p>Deep convolutional neural networks (CNNs) are broadly considered to be
state-of-the-art generic end-to-end image classification systems. However, they
are known to underperform when training data are limited and thus require data
augmentation strategies that render the method computationally expensive and
not always effective. Rather than using a data augmentation strategy to encode
invariances as typically done in machine learning, here we propose to
mathematically augment a nearest subspace classification model in
sliced-Wasserstein space by exploiting certain mathematical properties of the
Radon Cumulative Distribution Transform (R-CDT), a recently introduced image
transform. We demonstrate that for a particular type of learning problem, our
mathematical solution has advantages over data augmentation with deep CNNs in
terms of classification accuracy and computational complexity, and is
particularly effective under a limited training data setting. The method is
simple, effective, computationally efficient, non-iterative, and requires no
parameters to be tuned. Python code implementing our method is available at
https://github.com/rohdelab/mathematical_augmentation. Our method is integrated
as a part of the software package PyTransKit, which is available at
https://github.com/rohdelab/PyTransKit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Face Recognition Systems. (arXiv:2201.02991v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02991">
<div class="article-summary-box-inner">
<span><p>Face Recognition has proven to be one of the most successful technology and
has impacted heterogeneous domains. Deep learning has proven to be the most
successful at computer vision tasks because of its convolution-based
architecture. Since the advent of deep learning, face recognition technology
has had a substantial increase in its accuracy. In this paper, some of the most
impactful face recognition systems were surveyed. Firstly, the paper gives an
overview of a general face recognition system. Secondly, the survey covers
various network architectures and training losses that have had a substantial
impact. Finally, the paper talks about various databases that are used to
evaluate the capabilities of a face recognition system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MaskMTL: Attribute prediction in masked facial images with deep multitask learning. (arXiv:2201.03002v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03002">
<div class="article-summary-box-inner">
<span><p>Predicting attributes in the landmark free facial images is itself a
challenging task which gets further complicated when the face gets occluded due
to the usage of masks. Smart access control gates which utilize identity
verification or the secure login to personal electronic gadgets may utilize
face as a biometric trait. Particularly, the Covid-19 pandemic increasingly
validates the essentiality of hygienic and contactless identity verification.
In such cases, the usage of masks become more inevitable and performing
attribute prediction helps in segregating the target vulnerable groups from
community spread or ensuring social distancing for them in a collaborative
environment. We create a masked face dataset by efficiently overlaying masks of
different shape, size and textures to effectively model variability generated
by wearing mask. This paper presents a deep Multi-Task Learning (MTL) approach
to jointly estimate various heterogeneous attributes from a single masked
facial image. Experimental results on benchmark face attribute UTKFace dataset
demonstrate that the proposed approach supersedes in performance to other
competing techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ThreshNet: An Efficient DenseNet using Threshold Mechanism to Reduce Connections. (arXiv:2201.03013v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03013">
<div class="article-summary-box-inner">
<span><p>With the continuous development of neural networks in computer vision tasks,
more and more network architectures have achieved outstanding success. As one
of the most advanced neural network architectures, DenseNet shortcuts all
feature maps to solve the problem of model depth. Although this network
architecture has excellent accuracy at low MACs (multiplications and
accumulations), it takes excessive inference time. To solve this problem,
HarDNet reduces the connections between feature maps, making the remaining
connections resemble harmonic waves. However, this compression method may
result in decreasing model accuracy and increasing MACs and model size. This
network architecture only reduces the memory access time, its overall
performance still needs to be improved. Therefore, we propose a new network
architecture using threshold mechanism to further optimize the method of
connections. Different numbers of connections for different convolutional
layers are discarded to compress the feature maps in ThreshNet. The proposed
network architecture used three datasets, CIFAR-10, CIFAR-100, and SVHN, to
evaluate the performance for image classifications. Experimental results show
that ThreshNet achieves up to 60% reduction in inference time compared to
DenseNet, and up to 35% faster training speed and 20% reduction in error rate
compared to HarDNet on these datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Glance and Focus Networks for Dynamic Visual Recognition. (arXiv:2201.03014v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03014">
<div class="article-summary-box-inner">
<span><p>Spatial redundancy widely exists in visual recognition tasks, i.e.,
discriminative features in an image or video frame usually correspond to only a
subset of pixels, while the remaining regions are irrelevant to the task at
hand. Therefore, static models which process all the pixels with an equal
amount of computation result in considerable redundancy in terms of time and
space consumption. In this paper, we formulate the image recognition problem as
a sequential coarse-to-fine feature learning process, mimicking the human
visual system. Specifically, the proposed Glance and Focus Network (GFNet)
first extracts a quick global representation of the input image at a low
resolution scale, and then strategically attends to a series of salient (small)
regions to learn finer features. The sequential process naturally facilitates
adaptive inference at test time, as it can be terminated once the model is
sufficiently confident about its prediction, avoiding further redundant
computation. It is worth noting that the problem of locating discriminant
regions in our model is formulated as a reinforcement learning task, thus
requiring no additional manual annotations other than classification labels.
GFNet is general and flexible as it is compatible with any off-the-shelf
backbone models (such as MobileNets, EfficientNets and TSM), which can be
conveniently deployed as the feature extractor. Extensive experiments on a
variety of image classification and video recognition tasks and with various
backbone models demonstrate the remarkable efficiency of our method. For
example, it reduces the average latency of the highly efficient MobileNet-V3 on
an iPhone XS Max by 1.3x without sacrificing accuracy. Code and pre-trained
models are available at https://github.com/blackfeather-wang/GFNet-Pytorch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning class prototypes from Synthetic InSAR with Vision Transformers. (arXiv:2201.03016v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03016">
<div class="article-summary-box-inner">
<span><p>The detection of early signs of volcanic unrest preceding an eruption, in the
form of ground deformation in Interferometric Synthetic Aperture Radar (InSAR)
data is critical for assessing volcanic hazard. In this work we treat this as a
binary classification problem of InSAR images, and propose a novel deep
learning methodology that exploits a rich source of synthetically generated
interferograms to train quality classifiers that perform equally well in real
interferograms. The imbalanced nature of the problem, with orders of magnitude
fewer positive samples, coupled with the lack of a curated database with
labeled InSAR data, sets a challenging task for conventional deep learning
architectures. We propose a new framework for domain adaptation, in which we
learn class prototypes from synthetic data with vision transformers. We report
detection accuracy that surpasses the state of the art on volcanic unrest
detection. Moreover, we built upon this knowledge by learning a new,
non-linear, projection between the learnt representations and prototype space,
using pseudo labels produced by our model from an unlabeled real InSAR dataset.
This leads to the new state of the art with $97.1%$ accuracy on our test set.
We demonstrate the robustness of our approach by training a simple ResNet-18
Convolutional Neural Network on the unlabeled real InSAR dataset with
pseudo-labels generated from our top transformer-prototype model. Our
methodology provides a significant improvement in performance without the need
of manually labeling any sample, opening the road for further exploitation of
synthetic InSAR data in various remote sensing applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Feature Learning from Partial Point Clouds via Pose Disentanglement. (arXiv:2201.03018v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03018">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning on point clouds has gained a lot of attention
recently, since it addresses the label-efficiency and domain-gap problems on
point cloud tasks. In this paper, we propose a novel self-supervised framework
to learn informative representations from partial point clouds. We leverage
partial point clouds scanned by LiDAR that contain both content and pose
attributes, and we show that disentangling such two factors from partial point
clouds enhances feature representation learning. To this end, our framework
consists of three main parts: 1) a completion network to capture holistic
semantics of point clouds; 2) a pose regression network to understand the
viewing angle where partial data is scanned from; 3) a partial reconstruction
network to encourage the model to learn content and pose features. To
demonstrate the robustness of the learnt feature representations, we conduct
several downstream tasks including classification, part segmentation, and
registration, with comparisons against state-of-the-art methods. Our method not
only outperforms existing self-supervised methods, but also shows a better
generalizability across synthetic and real-world datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantics-driven Attentive Few-shot Learning over Clean and Noisy Samples. (arXiv:2201.03043v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03043">
<div class="article-summary-box-inner">
<span><p>Over the last couple of years few-shot learning (FSL) has attracted great
attention towards minimizing the dependency on labeled training examples. An
inherent difficulty in FSL is the handling of ambiguities resulting from having
too few training samples per class. To tackle this fundamental challenge in
FSL, we aim to train meta-learner models that can leverage prior semantic
knowledge about novel classes to guide the classifier synthesis process. In
particular, we propose semantically-conditioned feature attention and sample
attention mechanisms that estimate the importance of representation dimensions
and training instances. We also study the problem of sample noise in FSL,
towards the utilization of meta-learners in more realistic and imperfect
settings. Our experimental results demonstrate the effectiveness of the
proposed semantic FSL model with and without sample noise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Applying Artificial Intelligence for Age Estimation in Digital Forensic Investigations. (arXiv:2201.03045v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03045">
<div class="article-summary-box-inner">
<span><p>The precise age estimation of child sexual abuse and exploitation (CSAE)
victims is one of the most significant digital forensic challenges.
Investigators often need to determine the age of victims by looking at images
and interpreting the sexual development stages and other human characteristics.
The main priority - safeguarding children -- is often negatively impacted by a
huge forensic backlog, cognitive bias and the immense psychological stress that
this work can entail. This paper evaluates existing facial image datasets and
proposes a new dataset tailored to the needs of similar digital forensic
research contributions. This small, diverse dataset of 0 to 20-year-old
individuals contains 245 images and is merged with 82 unique images from the
FG-NET dataset, thus achieving a total of 327 images with high image diversity
and low age range density. The new dataset is tested on the Deep EXpectation
(DEX) algorithm pre-trained on the IMDB-WIKI dataset. The overall results for
young adolescents aged 10 to 15 and older adolescents/adults aged 16 to 20 are
very encouraging -- achieving MAEs as low as 1.79, but also suggest that the
accuracy for children aged 0 to 10 needs further work. In order to determine
the efficacy of the prototype, valuable input of four digital forensic experts,
including two forensic investigators, has been taken into account to improve
age estimation results. Further research is required to extend datasets both
concerning image density and the equal distribution of factors such as gender
and racial diversity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lung infection and normal region segmentation from CT volumes of COVID-19 cases. (arXiv:2201.03050v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03050">
<div class="article-summary-box-inner">
<span><p>This paper proposes an automated segmentation method of infection and normal
regions in the lung from CT volumes of COVID-19 patients. From December 2019,
novel coronavirus disease 2019 (COVID-19) spreads over the world and giving
significant impacts to our economic activities and daily lives. To diagnose the
large number of infected patients, diagnosis assistance by computers is needed.
Chest CT is effective for diagnosis of viral pneumonia including COVID-19. A
quantitative analysis method of condition of the lung from CT volumes by
computers is required for diagnosis assistance of COVID-19. This paper proposes
an automated segmentation method of infection and normal regions in the lung
from CT volumes using a COVID-19 segmentation fully convolutional network
(FCN). In diagnosis of lung diseases including COVID-19, analysis of conditions
of normal and infection regions in the lung is important. Our method recognizes
and segments lung normal and infection regions in CT volumes. To segment
infection regions that have various shapes and sizes, we introduced dense
pooling connections and dilated convolutions in our FCN. We applied the
proposed method to CT volumes of COVID-19 cases. From mild to severe cases of
COVID-19, the proposed method correctly segmented normal and infection regions
in the lung. Dice scores of normal and infection regions were 0.911 and 0.753,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-19 Infection Segmentation from Chest CT Images Based on Scale Uncertainty. (arXiv:2201.03053v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03053">
<div class="article-summary-box-inner">
<span><p>This paper proposes a segmentation method of infection regions in the lung
from CT volumes of COVID-19 patients. COVID-19 spread worldwide, causing many
infected patients and deaths. CT image-based diagnosis of COVID-19 can provide
quick and accurate diagnosis results. An automated segmentation method of
infection regions in the lung provides a quantitative criterion for diagnosis.
Previous methods employ whole 2D image or 3D volume-based processes. Infection
regions have a considerable variation in their sizes. Such processes easily
miss small infection regions. Patch-based process is effective for segmenting
small targets. However, selecting the appropriate patch size is difficult in
infection region segmentation. We utilize the scale uncertainty among various
receptive field sizes of a segmentation FCN to obtain infection regions. The
receptive field sizes can be defined as the patch size and the resolution of
volumes where patches are clipped from. This paper proposes an infection
segmentation network (ISNet) that performs patch-based segmentation and a scale
uncertainty-aware prediction aggregation method that refines the segmentation
result. We design ISNet to segment infection regions that have various
intensity values. ISNet has multiple encoding paths to process patch volumes
normalized by multiple intensity ranges. We collect prediction results
generated by ISNets having various receptive field sizes. Scale uncertainty
among the prediction results is extracted by the prediction aggregation method.
We use an aggregation FCN to generate a refined segmentation result considering
scale uncertainty among the predictions. In our experiments using 199 chest CT
volumes of COVID-19 cases, the prediction aggregation method improved the dice
similarity score from 47.6% to 62.1%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The State of Aerial Surveillance: A Survey. (arXiv:2201.03080v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03080">
<div class="article-summary-box-inner">
<span><p>The rapid emergence of airborne platforms and imaging sensors are enabling
new forms of aerial surveillance due to their unprecedented advantages in
scale, mobility, deployment and covert observation capabilities. This paper
provides a comprehensive overview of human-centric aerial surveillance tasks
from a computer vision and pattern recognition perspective. It aims to provide
readers with an in-depth systematic review and technical analysis of the
current state of aerial surveillance tasks using drones, UAVs and other
airborne platforms. The main object of interest is humans, where single or
multiple subjects are to be detected, identified, tracked, re-identified and
have their behavior analyzed. More specifically, for each of these four tasks,
we first discuss unique challenges in performing these tasks in an aerial
setting compared to a ground-based setting. We then review and analyze the
aerial datasets publicly available for each task, and delve deep into the
approaches in the aerial literature and investigate how they presently address
the aerial challenges. We conclude the paper with discussion on the missing
gaps and open research questions to inform future research avenues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ImageSubject: A Large-scale Dataset for Subject Detection. (arXiv:2201.03101v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03101">
<div class="article-summary-box-inner">
<span><p>Main subjects usually exist in the images or videos, as they are the objects
that the photographer wants to highlight. Human viewers can easily identify
them but algorithms often confuse them with other objects. Detecting the main
subjects is an important technique to help machines understand the content of
images and videos. We present a new dataset with the goal of training models to
understand the layout of the objects and the context of the image then to find
the main subjects among them. This is achieved in three aspects. By gathering
images from movie shots created by directors with professional shooting skills,
we collect the dataset with strong diversity, specifically, it contains
107\,700 images from 21\,540 movie shots. We labeled them with the bounding box
labels for two classes: subject and non-subject foreground object. We present a
detailed analysis of the dataset and compare the task with saliency detection
and object detection. ImageSubject is the first dataset that tries to localize
the subject in an image that the photographer wants to highlight. Moreover, we
find the transformer-based detection model offers the best result among other
popular model architectures. Finally, we discuss the potential applications and
conclude with the importance of the dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Preserving Domain Private Representation via Mutual Information Maximization. (arXiv:2201.03102v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03102">
<div class="article-summary-box-inner">
<span><p>Recent advances in unsupervised domain adaptation have shown that mitigating
the domain divergence by extracting the domain-invariant representation could
significantly improve the generalization of a model to an unlabeled data
domain. Nevertheless, the existing methods fail to effectively preserve the
representation that is private to the label-missing domain, which could
adversely affect the generalization. In this paper, we propose an approach to
preserve such representation so that the latent distribution of the unlabeled
domain could represent both the domain-invariant features and the individual
characteristics that are private to the unlabeled domain. In particular, we
demonstrate that maximizing the mutual information between the unlabeled domain
and its latent space while mitigating the domain divergence can achieve such
preservation. We also theoretically and empirically validate that preserving
the representation that is private to the unlabeled domain is important and of
necessity for the cross-domain generalization. Our approach outperforms
state-of-the-art methods on several public datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Signal Reconstruction from Quantized Noisy Samples of the Discrete Fourier Transform. (arXiv:2201.03114v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03114">
<div class="article-summary-box-inner">
<span><p>In this paper, we present two variations of an algorithm for signal
reconstruction from one-bit or two-bit noisy observations of the discrete
Fourier transform (DFT). The one-bit observations of the DFT correspond to the
sign of its real part, whereas, the two-bit observations of the DFT correspond
to the signs of both the real and imaginary parts of the DFT. We focus on
images for analysis and simulations, thus using the sign of the 2D-DFT. This
choice of the class of signals is inspired by previous works on this problem.
For our algorithm, we show that the expected mean squared error (MSE) in signal
reconstruction is asymptotically proportional to the inverse of the sampling
rate. The samples are affected by additive zero-mean noise of known
distribution. We solve this signal estimation problem by designing an algorithm
that uses contraction mapping, based on the Banach fixed point theorem.
Numerical tests with four benchmark images are provided to show the
effectiveness of our algorithm. Various metrics for image reconstruction
quality assessment such as PSNR, SSIM, ESSIM, and MS-SSIM are employed. On all
four benchmark images, our algorithm outperforms the state-of-the-art in all of
these metrics by a significant margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Systematic biases when using deep neural networks for annotating large catalogs of astronomical images. (arXiv:2201.03131v1 [astro-ph.GA])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03131">
<div class="article-summary-box-inner">
<span><p>Deep convolutional neural networks (DCNNs) have become the most common
solution for automatic image annotation due to their non-parametric nature,
good performance, and their accessibility through libraries such as TensorFlow.
Among other fields, DCNNs are also a common approach to the annotation of large
astronomical image databases acquired by digital sky surveys. One of the main
downsides of DCNNs is the complex non-intuitive rules that make DCNNs act as a
``black box", providing annotations in a manner that is unclear to the user.
Therefore, the user is often not able to know what information is used by the
DCNNs for the classification. Here we demonstrate that the training of a DCNN
is sensitive to the context of the training data such as the location of the
objects in the sky. We show that for basic classification of elliptical and
spiral galaxies, the sky location of the galaxies used for training affects the
behavior of the algorithm, and leads to a small but consistent and
statistically significant bias. That bias exhibits itself in the form of
cosmological-scale anisotropy in the distribution of basic galaxy morphology.
Therefore, while DCNNs are powerful tools for annotating images of extended
sources, the construction of training sets for galaxy morphology should take
into consideration more aspects than the visual appearance of the object. In
any case, catalogs created with deep neural networks that exhibit signs of
cosmological anisotropy should be interpreted with the possibility of
consistent bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Level Attention for Unsupervised Person Re-Identification. (arXiv:2201.03141v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03141">
<div class="article-summary-box-inner">
<span><p>The attention mechanism is widely used in deep learning because of its
excellent performance in neural networks without introducing additional
information. However, in unsupervised person re-identification, the attention
module represented by multi-headed self-attention suffers from attention
spreading in the condition of non-ground truth. To solve this problem, we
design pixel-level attention module to provide constraints for multi-headed
self-attention. Meanwhile, for the trait that the identification targets of
person re-identification data are all pedestrians in the samples, we design
domain-level attention module to provide more comprehensive pedestrian
features. We combine head-level, pixel-level and domain-level attention to
propose multi-level attention block and validate its performance on for large
person re-identification datasets (Market-1501, DukeMTMC-reID and MSMT17 and
PersonX).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Low-Light Images in Real World via Cross-Image Disentanglement. (arXiv:2201.03145v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03145">
<div class="article-summary-box-inner">
<span><p>Images captured in the low-light condition suffer from low visibility and
various imaging artifacts, e.g., real noise. Existing supervised enlightening
algorithms require a large set of pixel-aligned training image pairs, which are
hard to prepare in practice. Though weakly-supervised or unsupervised methods
can alleviate such challenges without using paired training images, some
real-world artifacts inevitably get falsely amplified because of the lack of
corresponded supervision. In this paper, instead of using perfectly aligned
images for training, we creatively employ the misaligned real-world images as
the guidance, which are considerably easier to collect. Specifically, we
propose a Cross-Image Disentanglement Network (CIDN) to separately extract
cross-image brightness and image-specific content features from
low/normal-light images. Based on that, CIDN can simultaneously correct the
brightness and suppress image artifacts in the feature domain, which largely
increases the robustness to the pixel shifts. Furthermore, we collect a new
low-light image enhancement dataset consisting of misaligned training images
with real-world corruptions. Experimental results show that our model achieves
state-of-the-art performances on both the newly proposed dataset and other
popular low-light datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TFS Recognition: Investigating MPH]{Thai Finger Spelling Recognition: Investigating MediaPipe Hands Potentials. (arXiv:2201.03170v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03170">
<div class="article-summary-box-inner">
<span><p>Thai Finger Spelling (TFS) sign recognition could benefit a community of
hearing-difficulty people in bridging to a major hearing population. With a
relatively large number of alphabets, TFS employs multiple signing schemes. Two
schemes of more common signing -- static and dynamic single-hand signing,
widely used in other sign languages -- have been addressed in several previous
works. To complete the TFS sign recognition, the remaining two of quite
distinct signing schemes -- static and dynamic point-on-hand signing -- need to
be sufficiently addressed.
</p>
<p>With the advent of many off-the-shelf hand skeleton prediction models and
that training a model to recognize a sign language from scratch is expensive,
we explore an approach building upon recently launched MediaPipe Hands (MPH).
MPH is a high-precision well-trained model for hand-keypoint detection.
</p>
<p>We have investigated MPH on three TFS schemes: static-single-hand (S1),
simplified dynamic-single-hand (S2) and static-point-on-hand (P1) schemes.
</p>
<p>Our results show that MPH can satisfactorily address single-hand schemes with
accuracy of 84.57% on both S1 and S2.
</p>
<p>However, our finding reveals a shortcoming of MPH in addressing a
point-on-hand scheme, whose accuracy is 23.66% on P1 conferring to 69.19%
obtained from conventional classification trained from scratch. This
shortcoming has been investigated and attributed to self occlusion and
handedness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pedestrian Detection: Domain Generalization, CNNs, Transformers and Beyond. (arXiv:2201.03176v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03176">
<div class="article-summary-box-inner">
<span><p>Pedestrian detection is the cornerstone of many vision based applications,
starting from object tracking to video surveillance and more recently,
autonomous driving. With the rapid development of deep learning in object
detection, pedestrian detection has achieved very good performance in
traditional single-dataset training and evaluation setting. However, in this
study on generalizable pedestrian detectors, we show that, current pedestrian
detectors poorly handle even small domain shifts in cross-dataset evaluation.
We attribute the limited generalization to two main factors, the method and the
current sources of data. Regarding the method, we illustrate that biasness
present in the design choices (e.g anchor settings) of current pedestrian
detectors are the main contributing factor to the limited generalization. Most
modern pedestrian detectors are tailored towards target dataset, where they do
achieve high performance in traditional single training and testing pipeline,
but suffer a degrade in performance when evaluated through cross-dataset
evaluation. Consequently, a general object detector performs better in
cross-dataset evaluation compared with state of the art pedestrian detectors,
due to its generic design. As for the data, we show that the autonomous driving
benchmarks are monotonous in nature, that is, they are not diverse in scenarios
and dense in pedestrians. Therefore, benchmarks curated by crawling the web
(which contain diverse and dense scenarios), are an efficient source of
pre-training for providing a more robust representation. Accordingly, we
propose a progressive fine-tuning strategy which improves generalization. Code
and models cab accessed at https://github.com/hasanirtiza/Pedestron.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Swin transformers make strong contextual encoders for VHR image road extraction. (arXiv:2201.03178v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03178">
<div class="article-summary-box-inner">
<span><p>Significant progress has been made in automatic road extra-ction or
segmentation based on deep learning, but there are still margins to improve in
terms of the completeness and connectivity of the results. This is mainly due
to the challenges of large intra-class variances, ambiguous inter-class
distinctions, and occlusions from shadows, trees, and buildings. Therefore,
being able to perceive global context and model geometric information is
essential to further improve the accuracy of road segmentation. In this paper,
we design a novel dual-branch encoding block CoSwin which exploits the
capability of global context modeling of Swin Transformer and that of local
feature extraction of ResNet. Furthermore, we also propose a context-guided
filter block named CFilter, which can filter out context-independent noisy
features for better reconstructing of the details. We use CoSwin and CFilter in
a U-shaped network architecture. Experiments on Massachusetts and CHN6-CUG
datasets show that the proposed method outperforms other state-of-the-art
methods on the metrics of F1, IoU, and OA. Further analysis reveals that the
improvement in accuracy comes from better integrity and connectivity of
segmented roads.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transfer Learning for Scene Text Recognition in Indian Languages. (arXiv:2201.03180v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03180">
<div class="article-summary-box-inner">
<span><p>Scene text recognition in low-resource Indian languages is challenging
because of complexities like multiple scripts, fonts, text size, and
orientations. In this work, we investigate the power of transfer learning for
all the layers of deep scene text recognition networks from English to two
common Indian languages. We perform experiments on the conventional CRNN model
and STAR-Net to ensure generalisability. To study the effect of change in
different scripts, we initially run our experiments on synthetic word images
rendered using Unicode fonts. We show that the transfer of English models to
simple synthetic datasets of Indian languages is not practical. Instead, we
propose to apply transfer learning techniques among Indian languages due to
similarity in their n-gram distributions and visual features like the vowels
and conjunct characters. We then study the transfer learning among six Indian
languages with varying complexities in fonts and word length statistics. We
also demonstrate that the learned features of the models transferred from other
Indian languages are visually closer (and sometimes even better) to the
individual model features than those transferred from English. We finally set
new benchmarks for scene-text recognition on Hindi, Telugu, and Malayalam
datasets from IIIT-ILST and Bangla dataset from MLT-17 by achieving 6%, 5%, 2%,
and 23% gains in Word Recognition Rates (WRRs) compared to previous works. We
further improve the MLT-17 Bangla results by plugging in a novel correction
BiLSTM into our model. We additionally release a dataset of around 440 scene
images containing 500 Gujarati and 2535 Tamil words. WRRs improve over the
baselines by 8%, 4%, 5%, and 3% on the MLT-19 Hindi and Bangla datasets and the
Gujarati and Tamil datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Boosting the Accuracy of Non-Latin Scene Text Recognition. (arXiv:2201.03185v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03185">
<div class="article-summary-box-inner">
<span><p>Scene-text recognition is remarkably better in Latin languages than the
non-Latin languages due to several factors like multiple fonts, simplistic
vocabulary statistics, updated data generation tools, and writing systems. This
paper examines the possible reasons for low accuracy by comparing English
datasets with non-Latin languages. We compare various features like the size
(width and height) of the word images and word length statistics. Over the last
decade, generating synthetic datasets with powerful deep learning techniques
has tremendously improved scene-text recognition. Several controlled
experiments are performed on English, by varying the number of (i) fonts to
create the synthetic data and (ii) created word images. We discover that these
factors are critical for the scene-text recognition systems. The English
synthetic datasets utilize over 1400 fonts while Arabic and other non-Latin
datasets utilize less than 100 fonts for data generation. Since some of these
languages are a part of different regions, we garner additional fonts through a
region-based search to improve the scene-text recognition models in Arabic and
Devanagari. We improve the Word Recognition Rates (WRRs) on Arabic MLT-17 and
MLT-19 datasets by 24.54% and 2.32% compared to previous works or baselines. We
achieve WRR gains of 7.88% and 3.72% for IIIT-ILST and MLT-19 Devanagari
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MyoPS: A Benchmark of Myocardial Pathology Segmentation Combining Three-Sequence Cardiac Magnetic Resonance Images. (arXiv:2201.03186v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03186">
<div class="article-summary-box-inner">
<span><p>Assessment of myocardial viability is essential in diagnosis and treatment
management of patients suffering from myocardial infarction, and classification
of pathology on myocardium is the key to this assessment. This work defines a
new task of medical image analysis, i.e., to perform myocardial pathology
segmentation (MyoPS) combining three-sequence cardiac magnetic resonance (CMR)
images, which was first proposed in the MyoPS challenge, in conjunction with
MICCAI 2020. The challenge provided 45 paired and pre-aligned CMR images,
allowing algorithms to combine the complementary information from the three CMR
sequences for pathology segmentation. In this article, we provide details of
the challenge, survey the works from fifteen participants and interpret their
methods according to five aspects, i.e., preprocessing, data augmentation,
learning strategy, model architecture and post-processing. In addition, we
analyze the results with respect to different factors, in order to examine the
key obstacles and explore potential of solutions, as well as to provide a
benchmark for future research. We conclude that while promising results have
been reported, the research is still in the early stage, and more in-depth
exploration is needed before a successful application to the clinics. Note that
MyoPS data and evaluation tool continue to be publicly available upon
registration via its homepage
(www.sdspeople.fudan.edu.cn/zhuangxiahai/0/myops20/).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification. (arXiv:2201.03194v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03194">
<div class="article-summary-box-inner">
<span><p>Hierarchical multi-granularity classification (HMC) assigns hierarchical
multi-granularity labels to each object and focuses on encoding the label
hierarchy, e.g., ["Albatross", "Laysan Albatross"] from coarse-to-fine levels.
However, the definition of what is fine-grained is subjective, and the image
quality may affect the identification. Thus, samples could be observed at any
level of the hierarchy, e.g., ["Albatross"] or ["Albatross", "Laysan
Albatross"], and examples discerned at coarse categories are often neglected in
the conventional setting of HMC. In this paper, we study the HMC problem in
which objects are labeled at any level of the hierarchy. The essential designs
of the proposed method are derived from two motivations: (1) learning with
objects labeled at various levels should transfer hierarchical knowledge
between levels; (2) lower-level classes should inherit attributes related to
upper-level superclasses. The proposed combinatorial loss maximizes the
marginal probability of the observed ground truth label by aggregating
information from related labels defined in the tree hierarchy. If the observed
label is at the leaf level, the combinatorial loss further imposes the
multi-class cross-entropy loss to increase the weight of fine-grained
classification loss. Considering the hierarchical feature interaction, we
propose a hierarchical residual network (HRN), in which granularity-specific
features from parent levels acting as residual connections are added to
features of children levels. Experiments on three commonly used datasets
demonstrate the effectiveness of our approach compared to the state-of-the-art
HMC approaches and fine-grained visual classification (FGVC) methods exploiting
the label hierarchy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-end lossless compression of high precision depth maps guided by pseudo-residual. (arXiv:2201.03195v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03195">
<div class="article-summary-box-inner">
<span><p>As a fundamental data format representing spatial information, depth map is
widely used in signal processing and computer vision fields. Massive amount of
high precision depth maps are produced with the rapid development of equipment
like laser scanner or LiDAR. Therefore, it is urgent to explore a new
compression method with better compression ratio for high precision depth maps.
Utilizing the wide spread deep learning environment, we propose an end-to-end
learning-based lossless compression method for high precision depth maps. The
whole process is comprised of two sub-processes, named pre-processing of depth
maps and deep lossless compression of processed depth maps. The deep lossless
compression network consists of two sub-networks, named lossy compression
network and lossless compression network. We leverage the concept of
pseudo-residual to guide the generation of distribution for residual and avoid
introducing context models. Our end-to-end lossless compression network
achieves competitive performance over engineered codecs and has low
computational cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model-Based Image Signal Processors via Learnable Dictionaries. (arXiv:2201.03210v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03210">
<div class="article-summary-box-inner">
<span><p>Digital cameras transform sensor RAW readings into RGB images by means of
their Image Signal Processor (ISP). Computational photography tasks such as
image denoising and colour constancy are commonly performed in the RAW domain,
in part due to the inherent hardware design, but also due to the appealing
simplicity of noise statistics that result from the direct sensor readings.
Despite this, the availability of RAW images is limited in comparison with the
abundance and diversity of available RGB data. Recent approaches have attempted
to bridge this gap by estimating the RGB to RAW mapping: handcrafted
model-based methods that are interpretable and controllable usually require
manual parameter fine-tuning, while end-to-end learnable neural networks
require large amounts of training data, at times with complex training
procedures, and generally lack interpretability and parametric control. Towards
addressing these existing limitations, we present a novel hybrid model-based
and data-driven ISP that builds on canonical ISP operations and is both
learnable and interpretable. Our proposed invertible model, capable of
bidirectional mapping between RAW and RGB domains, employs end-to-end learning
of rich parameter representations, i.e. dictionaries, that are free from direct
parametric supervision and additionally enable simple and plausible data
augmentation. We evidence the value of our data generation process by extensive
experiments under both RAW image reconstruction and RAW image denoising tasks,
obtaining state-of-the-art performance in both. Additionally, we show that our
ISP can learn meaningful mappings from few data samples, and that denoising
models trained with our dictionary-based data augmentation are competitive
despite having only few or zero ground-truth labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why-So-Deep: Towards Boosting Previously Trained Models for Visual Place Recognition. (arXiv:2201.03212v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03212">
<div class="article-summary-box-inner">
<span><p>Deep learning-based image retrieval techniques for the loop closure detection
demonstrate satisfactory performance. However, it is still challenging to
achieve high-level performance based on previously trained models in different
geographical regions. This paper addresses the problem of their deployment with
simultaneous localization and mapping (SLAM) systems in the new environment.
The general baseline approach uses additional information, such as GPS,
sequential keyframes tracking, and re-training the whole environment to enhance
the recall rate. We propose a novel approach for improving image retrieval
based on previously trained models. We present an intelligent method, MAQBOOL,
to amplify the power of pre-trained models for better image recall and its
application to real-time multiagent SLAM systems. We achieve comparable image
retrieval results at a low descriptor dimension (512-D), compared to the high
descriptor dimension (4096-D) of state-of-the-art methods. We use spatial
information to improve the recall rate in image retrieval on pre-trained
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully automatic scoring of handwritten descriptive answers in Japanese language tests. (arXiv:2201.03215v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03215">
<div class="article-summary-box-inner">
<span><p>This paper presents an experiment of automatically scoring handwritten
descriptive answers in the trial tests for the new Japanese university entrance
examination, which were made for about 120,000 examinees in 2017 and 2018.
There are about 400,000 answers with more than 20 million characters. Although
all answers have been scored by human examiners, handwritten characters are not
labelled. We present our attempt to adapt deep neural network-based handwriting
recognizers trained on a labelled handwriting dataset into this unlabeled
answer set. Our proposed method combines different training strategies,
ensembles multiple recognizers, and uses a language model built from a large
general corpus to avoid overfitting into specific data. In our experiment, the
proposed method records character accuracy of over 97% using about 2,000
verified labelled answers that account for less than 0.5% of the dataset. Then,
the recognized answers are fed into a pre-trained automatic scoring system
based on the BERT model without correcting misrecognized characters and
providing rubric annotations. The automatic scoring system achieves from 0.84
to 0.98 of Quadratic Weighted Kappa (QWK). As QWK is over 0.8, it represents
acceptable similarity of scoring between the automatic scoring system and the
human examiners. These results are promising for further research on end-to-end
automatic scoring of descriptive answers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Swin Transformer for Fast MRI. (arXiv:2201.03230v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03230">
<div class="article-summary-box-inner">
<span><p>Magnetic resonance imaging (MRI) is an important non-invasive clinical tool
that can produce high-resolution and reproducible images. However, a long
scanning time is required for high-quality MR images, which leads to exhaustion
and discomfort of patients, inducing more artefacts due to voluntary movements
of the patients and involuntary physiological movements. To accelerate the
scanning process, methods by k-space undersampling and deep learning based
reconstruction have been popularised. This work introduced SwinMR, a novel Swin
transformer based method for fast MRI reconstruction. The whole network
consisted of an input module (IM), a feature extraction module (FEM) and an
output module (OM). The IM and OM were 2D convolutional layers and the FEM was
composed of a cascaded of residual Swin transformer blocks (RSTBs) and 2D
convolutional layers. The RSTB consisted of a series of Swin transformer layers
(STLs). The shifted windows multi-head self-attention (W-MSA/SW-MSA) of STL was
performed in shifted windows rather than the multi-head self-attention (MSA) of
the original transformer in the whole image space. A novel multi-channel loss
was proposed by using the sensitivity maps, which was proved to reserve more
textures and details. We performed a series of comparative studies and ablation
studies in the Calgary-Campinas public brain MR dataset and conducted a
downstream segmentation experiment in the Multi-modal Brain Tumour Segmentation
Challenge 2017 dataset. The results demonstrate our SwinMR achieved
high-quality reconstruction compared with other benchmark methods, and it shows
great robustness with different undersampling masks, under noise interruption
and on different datasets. The code is publicly available at
https://github.com/ayanglab/SwinMR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Small Object Detection using Deep Learning. (arXiv:2201.03243v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03243">
<div class="article-summary-box-inner">
<span><p>Now a days, UAVs such as drones are greatly used for various purposes like
that of capturing and target detection from ariel imagery etc. Easy access of
these small ariel vehicles to public can cause serious security threats. For
instance, critical places may be monitored by spies blended in public using
drones. Study in hand proposes an improved and efficient Deep Learning based
autonomous system which can detect and track very small drones with great
precision. The proposed system consists of a custom deep learning model Tiny
YOLOv3, one of the flavors of very fast object detection model You Look Only
Once (YOLO) is built and used for detection. The object detection algorithm
will efficiently the detect the drones. The proposed architecture has shown
significantly better performance as compared to the previous YOLO version. The
improvement is observed in the terms of resource usage and time complexity. The
performance is measured using the metrics of recall and precision that are 93%
and 91% respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision in adverse weather: Augmentation using CycleGANs with various object detectors for robust perception in autonomous racing. (arXiv:2201.03246v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03246">
<div class="article-summary-box-inner">
<span><p>In an autonomous driving system, perception - identification of features and
objects from the environment - is crucial. In autonomous racing, high speeds
and small margins demand rapid and accurate detection systems. During the race,
the weather can change abruptly, causing significant degradation in perception,
resulting in ineffective manoeuvres. In order to improve detection in adverse
weather, deep-learning-based models typically require extensive datasets
captured in such conditions - the collection of which is a tedious, laborious,
and costly process. However, recent developments in CycleGAN architectures
allow the synthesis of highly realistic scenes in multiple weather conditions.
To this end, we introduce an approach of using synthesised adverse condition
datasets in autonomous racing (generated using CycleGAN) to improve the
performance of four out of five state-of-the-art detectors by an average of
42.7 and 4.4 mAP percentage points in the presence of night-time conditions and
droplets, respectively. Furthermore, we present a comparative analysis of five
object detectors - identifying the optimal pairing of detector and training
data for use during autonomous racing in challenging conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A statistical shape model for radiation-free assessment and classification of craniosynostosis. (arXiv:2201.03288v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03288">
<div class="article-summary-box-inner">
<span><p>The assessment of craniofacial deformities requires patient data which is
sparsely available. Statistical shape models provide realistic and synthetic
data enabling comparisons of existing methods on a common dataset.
</p>
<p>We build the first publicly available statistical 3D head model of
craniosynostosis patients and the first model focusing on infants younger than
1.5 years. For correspondence establishment, we test and evaluate four template
morphing approaches. We further present an original, shape-model-based
classification approach for craniosynostosis on photogrammetric surface scans.
To the best of our knowledge, our study uses the largest dataset of
craniosynostosis patients in a classification study for craniosynostosis and
statistical shape modeling to date.
</p>
<p>We demonstrate that our shape model performs similar to other statistical
shape models of the human head. Craniosynostosis-specific pathologies are
represented in the first eigenmodes of the model. Regarding the automatic
classification of craniosynostis, our classification approach yields an
accuracy of 97.3%, comparable to other state-of-the-art methods using both
computed tomography scans and stereophotogrammetry.
</p>
<p>Our publicly available, craniosynostosis-specific statistical shape model
enables the assessment of craniosynostosis on realistic and synthetic data. We
further present a state-of-the-art shape-model-based classification approach
for a radiation-free diagnosis of craniosynostosis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GhostNets on Heterogeneous Devices via Cheap Operations. (arXiv:2201.03297v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03297">
<div class="article-summary-box-inner">
<span><p>Deploying convolutional neural networks (CNNs) on mobile devices is difficult
due to the limited memory and computation resources. We aim to design efficient
neural networks for heterogeneous devices including CPU and GPU, by exploiting
the redundancy in feature maps, which has rarely been investigated in neural
architecture design. For CPU-like devices, we propose a novel CPU-efficient
Ghost (C-Ghost) module to generate more feature maps from cheap operations.
Based on a set of intrinsic feature maps, we apply a series of linear
transformations with cheap cost to generate many ghost feature maps that could
fully reveal information underlying intrinsic features. The proposed C-Ghost
module can be taken as a plug-and-play component to upgrade existing
convolutional neural networks. C-Ghost bottlenecks are designed to stack
C-Ghost modules, and then the lightweight C-GhostNet can be easily established.
We further consider the efficient networks for GPU devices. Without involving
too many GPU-inefficient operations (e.g.,, depth-wise convolution) in a
building stage, we propose to utilize the stage-wise feature redundancy to
formulate GPU-efficient Ghost (G-Ghost) stage structure. The features in a
stage are split into two parts where the first part is processed using the
original block with fewer output channels for generating intrinsic features,
and the other are generated using cheap operations by exploiting stage-wise
redundancy. Experiments conducted on benchmarks demonstrate the effectiveness
of the proposed C-Ghost module and the G-Ghost stage. C-GhostNet and G-GhostNet
can achieve the optimal trade-off of accuracy and latency for CPU and GPU,
respectively. Code is available at https://github.com/huawei-noah/CV-Backbones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Avoiding Overfitting: A Survey on Regularization Methods for Convolutional Neural Networks. (arXiv:2201.03299v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03299">
<div class="article-summary-box-inner">
<span><p>Several image processing tasks, such as image classification and object
detection, have been significantly improved using Convolutional Neural Networks
(CNN). Like ResNet and EfficientNet, many architectures have achieved
outstanding results in at least one dataset by the time of their creation. A
critical factor in training concerns the network's regularization, which
prevents the structure from overfitting. This work analyzes several
regularization methods developed in the last few years, showing significant
improvements for different CNN models. The works are classified into three main
areas: the first one is called "data augmentation", where all the techniques
focus on performing changes in the input data. The second, named "internal
changes", which aims to describe procedures to modify the feature maps
generated by the neural network or the kernels. The last one, called "label",
concerns transforming the labels of a given input. This work presents two main
differences comparing to other available surveys about regularization: (i) the
first concerns the papers gathered in the manuscript, which are not older than
five years, and (ii) the second distinction is about reproducibility, i.e., all
works refered here have their code available in public repositories or they
have been directly implemented in some framework, such as TensorFlow or Torch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparison of Representation Learning Techniques for Tracking in time resolved 3D Ultrasound. (arXiv:2201.03319v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03319">
<div class="article-summary-box-inner">
<span><p>3D ultrasound (3DUS) becomes more interesting for target tracking in
radiation therapy due to its capability to provide volumetric images in
real-time without using ionizing radiation. It is potentially usable for
tracking without using fiducials. For this, a method for learning meaningful
representations would be useful to recognize anatomical structures in different
time frames in representation space (r-space). In this study, 3DUS patches are
reduced into a 128-dimensional r-space using conventional autoencoder,
variational autoencoder and sliced-wasserstein autoencoder. In the r-space, the
capability of separating different ultrasound patches as well as recognizing
similar patches is investigated and compared based on a dataset of liver
images. Two metrics to evaluate the tracking capability in the r-space are
proposed. It is shown that ultrasound patches with different anatomical
structures can be distinguished and sets of similar patches can be clustered in
r-space. The results indicate that the investigated autoencoders have different
levels of usability for target tracking in 3DUS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gait Recognition Based on Deep Learning: A Survey. (arXiv:2201.03323v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03323">
<div class="article-summary-box-inner">
<span><p>In general, biometry-based control systems may not rely on individual
expected behavior or cooperation to operate appropriately. Instead, such
systems should be aware of malicious procedures for unauthorized access
attempts. Some works available in the literature suggest addressing the problem
through gait recognition approaches. Such methods aim at identifying human
beings through intrinsic perceptible features, despite dressed clothes or
accessories. Although the issue denotes a relatively long-time challenge, most
of the techniques developed to handle the problem present several drawbacks
related to feature extraction and low classification rates, among other issues.
However, deep learning-based approaches recently emerged as a robust set of
tools to deal with virtually any image and computer-vision related problem,
providing paramount results for gait recognition as well. Therefore, this work
provides a surveyed compilation of recent works regarding biometric detection
through gait recognition with a focus on deep learning approaches, emphasizing
their benefits, and exposing their weaknesses. Besides, it also presents
categorized and characterized descriptions of the datasets, approaches, and
architectures employed to tackle associated constraints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COIN: Counterfactual Image Generation for VQA Interpretation. (arXiv:2201.03342v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03342">
<div class="article-summary-box-inner">
<span><p>Due to the significant advancement of Natural Language Processing and
Computer Vision-based models, Visual Question Answering (VQA) systems are
becoming more intelligent and advanced. However, they are still error-prone
when dealing with relatively complex questions. Therefore, it is important to
understand the behaviour of the VQA models before adopting their results. In
this paper, we introduce an interpretability approach for VQA models by
generating counterfactual images. Specifically, the generated image is supposed
to have the minimal possible change to the original image and leads the VQA
model to give a different answer. In addition, our approach ensures that the
generated image is realistic. Since quantitative metrics cannot be employed to
evaluate the interpretability of the model, we carried out a user study to
assess different aspects of our approach. In addition to interpreting the
result of VQA models on single images, the obtained results and the discussion
provides an extensive explanation of VQA models' behaviour.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GMFIM: A Generative Mask-guided Facial Image Manipulation Model for Privacy Preservation. (arXiv:2201.03353v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03353">
<div class="article-summary-box-inner">
<span><p>The use of social media websites and applications has become very popular and
people share their photos on these networks. Automatic recognition and tagging
of people's photos on these networks has raised privacy preservation issues and
users seek methods for hiding their identities from these algorithms.
Generative adversarial networks (GANs) are shown to be very powerful in
generating face images in high diversity and also in editing face images. In
this paper, we propose a Generative Mask-guided Face Image Manipulation (GMFIM)
model based on GANs to apply imperceptible editing to the input face image to
preserve the privacy of the person in the image. Our model consists of three
main components: a) the face mask module to cut the face area out of the input
image and omit the background, b) the GAN-based optimization module for
manipulating the face image and hiding the identity and, c) the merge module
for combining the background of the input image and the manipulated
de-identified face image. Different criteria are considered in the loss
function of the optimization step to produce high-quality images that are as
similar as possible to the input image while they cannot be recognized by AFR
systems. The results of the experiments on different datasets show that our
model can achieve better performance against automated face recognition systems
in comparison to the state-of-the-art methods and it catches a higher attack
success rate in most experiments from a total of 18. Moreover, the generated
images of our proposed model have the highest quality and are more pleasing to
human eyes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-resolution Ecosystem Mapping in Repetitive Environments Using Dual Camera SLAM. (arXiv:2201.03364v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03364">
<div class="article-summary-box-inner">
<span><p>Structure from Motion (SfM) techniques are being increasingly used to create
3D maps from images in many domains including environmental monitoring.
However, SfM techniques are often confounded in visually repetitive
environments as they rely primarily on globally distinct image features.
Simultaneous Localization and Mapping (SLAM) techniques offer a potential
solution in visually repetitive environments since they use local feature
matching, but SLAM approaches work best with wide-angle cameras that are often
unsuitable for documenting the environmental system of interest. We resolve
this issue by proposing a dual-camera SLAM approach that uses a forward facing
wide-angle camera for localization and a downward facing narrower angle,
high-resolution camera for documentation. Video frames acquired by the forward
facing camera video are processed using a standard SLAM approach providing a
trajectory of the imaging system through the environment which is then used to
guide the registration of the documentation camera images. Fragmentary maps,
initially produced from the documentation camera images via monocular SLAM, are
subsequently scaled and aligned with the localization camera trajectory and
finally subjected to a global optimization procedure to produce a unified,
refined map. An experimental comparison with several state-of-the-art SfM
approaches shows the dual-camera SLAM approach to perform better in repetitive
environmental systems based on select samples of ground control point markers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">General Deformations of Point Configurations Viewed By a Pinhole Model Camera. (arXiv:1505.08070v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1505.08070">
<div class="article-summary-box-inner">
<span><p>This paper is a theoretical study of the following Non-Rigid Structure from
Motion problem. What can be computed from a monocular view of a parametrically
deforming set of points? We treat various variations of this problem for affine
and polynomial deformations with calibrated and uncalibrated cameras. We show
that in general at least three images with quasi-identical two deformations are
needed in order to have a finite set of solutions of the points' structure and
calculate some simple examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeoNav: Improving the Generalization of Visual Navigation via Generating Next Expected Observations. (arXiv:1906.07207v4 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.07207">
<div class="article-summary-box-inner">
<span><p>We propose improving the cross-target and cross-scene generalization of
visual navigation through learning an agent that is guided by conceiving the
next observations it expects to see. This is achieved by learning a variational
Bayesian model, called NeoNav, which generates the next expected observations
(NEO) conditioned on the current observations of the agent and the target view.
Our generative model is learned through optimizing a variational objective
encompassing two key designs. First, the latent distribution is conditioned on
current observations and the target view, leading to a model-based,
target-driven navigation. Second, the latent space is modeled with a Mixture of
Gaussians conditioned on the current observation and the next best action. Our
use of mixture-of-posteriors prior effectively alleviates the issue of
over-regularized latent space, thus significantly boosting the model
generalization for new targets and in novel scenes. Moreover, the NEO
generation models the forward dynamics of agent-environment interaction, which
improves the quality of approximate inference and hence benefits data
efficiency. We have conducted extensive evaluations on both real-world and
synthetic benchmarks, and show that our model consistently outperforms the
state-of-the-art models in terms of success rate, data efficiency, and
generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Deep Learning-based Architectures for Semantic Segmentation on 2D images. (arXiv:1912.10230v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.10230">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation is the pixel-wise labelling of an image. Since the
problem is defined at the pixel level, determining image class labels only is
not acceptable, but localising them at the original image pixel resolution is
necessary. Boosted by the extraordinary ability of convolutional neural
networks (CNN) in creating semantic, high level and hierarchical image
features; several deep learning-based 2D semantic segmentation approaches have
been proposed within the last decade. In this survey, we mainly focus on the
recent scientific developments in semantic segmentation, specifically on deep
learning-based methods using 2D images. We started with an analysis of the
public image sets and leaderboards for 2D semantic segmentation, with an
overview of the techniques employed in performance evaluation. In examining the
evolution of the field, we chronologically categorised the approaches into
three main periods, namely pre-and early deep learning era, the fully
convolutional era, and the post-FCN era. We technically analysed the solutions
put forward in terms of solving the fundamental problems of the field, such as
fine-grained localisation and scale invariance. Before drawing our conclusions,
we present a table of methods from all mentioned eras, with a summary of each
approach that explains their contribution to the field. We conclude the survey
by discussing the current challenges of the field and to what extent they have
been solved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">1D Probabilistic Undersampling Pattern Optimization for MR Image Reconstruction. (arXiv:2003.03797v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.03797">
<div class="article-summary-box-inner">
<span><p>Magnetic resonance imaging (MRI) is mainly limited by long scanning time and
vulnerable to human tissue motion artifacts, in 3D clinical scenarios. Thus,
k-space undersampling is used to accelerate the acquisition of MRI while
leading to visually poor MR images. Recently, some studies 1) use effective
undersampling patterns, or 2) design deep neural networks to improve the
quality of resulting images. However, they are considered as two separate
optimization strategies. In this paper, we propose a cross-domain network for
MR image reconstruction, in a retrospective data-driven manner, under limited
sampling rates. Our method can simultaneously obtain the optimal undersampling
pattern (in k-space) and the reconstruction model, which are customized to the
type of training data, by using an end-to-end learning strategy. We propose a
1D probabilistic undersampling layer, to obtain the optimal undersampling
pattern and its probability distribution in a differentiable way. We propose a
1D inverse Fourier transform layer, which connects the Fourier domain and the
image domain during the forward pass and the backpropagation. In addition, by
training 3D fully-sampled k-space data and MR images with the traditional
Euclidean loss, we discover the universal relationship between the probability
distribution of the optimal undersampling pattern and its corresponding
sampling rate. Experiments show that the quantitative and qualitative results
of recovered MR images by our 1D probabilistic undersampling pattern obviously
outperform those of several existing sampling strategies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teaching CNNs to mimic Human Visual Cognitive Process & regularise Texture-Shape bias. (arXiv:2006.14722v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.14722">
<div class="article-summary-box-inner">
<span><p>Recent experiments in computer vision demonstrate texture bias as the primary
reason for supreme results in models employing Convolutional Neural Networks
(CNNs), conflicting with early works claiming that these networks identify
objects using shape. It is believed that the cost function forces the CNN to
take a greedy approach and develop a proclivity for local information like
texture to increase accuracy, thus failing to explore any global statistics. We
propose CognitiveCNN, a new intuitive architecture, inspired from feature
integration theory in psychology to utilise human interpretable feature like
shape, texture, edges etc. to reconstruct, and classify the image. We define
novel metrics to quantify the "relevance" of "abstract information" present in
these modalities using attention maps. We further introduce a regularisation
method which ensures that each modality like shape, texture etc. gets
proportionate influence in a given task, as it does for reconstruction; and
perform experiments to show the resulting boost in accuracy and robustness,
besides imparting explainability to these CNNs for achieving superior
performance in object recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparative study of deep learning methods for the automatic segmentation of lung, lesion and lesion type in CT scans of COVID-19 patients. (arXiv:2007.15546v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15546">
<div class="article-summary-box-inner">
<span><p>Recent research on COVID-19 suggests that CT imaging provides useful
information to assess disease progression and assist diagnosis, in addition to
help understanding the disease. There is an increasing number of studies that
propose to use deep learning to provide fast and accurate quantification of
COVID-19 using chest CT scans. The main tasks of interest are the automatic
segmentation of lung and lung lesions in chest CT scans of confirmed or
suspected COVID-19 patients. In this study, we compare twelve deep learning
algorithms using a multi-center dataset, including both open-source and
in-house developed algorithms. Results show that ensembling different methods
can boost the overall test set performance for lung segmentation, binary lesion
segmentation and multiclass lesion segmentation, resulting in mean Dice scores
of 0.982, 0.724 and 0.469, respectively. The resulting binary lesions were
segmented with a mean absolute volume error of 91.3 ml. In general, the task of
distinguishing different lesion types was more difficult, with a mean absolute
volume difference of 152 ml and mean Dice scores of 0.369 and 0.523 for
consolidation and ground glass opacity, respectively. All methods perform
binary lesion segmentation with an average volume error that is better than
visual assessment by human raters, suggesting these methods are mature enough
for a large-scale evaluation for use in clinical practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving concave point detection to better segment overlapped objects in images. (arXiv:2008.00997v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00997">
<div class="article-summary-box-inner">
<span><p>This paper presents a method that improve state-of-the-art of the concave
point detection methods as a first step to segment overlapping objects on
images. It is based on the analysis of the curvature of the objects contour.
The method has three main steps. First, we pre-process the original image to
obtain the value of the curvature on each contour point. Second, we select
regions with higher curvature and we apply a recursive algorithm to refine the
previous selected regions. Finally, we obtain a concave point from each region
based on the analysis of the relative position of their neighbourhood We
experimentally demonstrated that a better concave points detection implies a
better cluster division. In order to evaluate the quality of the concave point
detection algorithm, we constructed a synthetic dataset to simulate overlapping
objects, providing the position of the concave points as a ground truth. As a
case study, the performance of a well-known application is evaluated, such as
the splitting of overlapped cells in images of peripheral blood smears samples
of patients with sickle cell anaemia. We used the proposed method to detect the
concave points in clusters of cells and then we separate this clusters by
ellipse fitting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Deep Learning and Explainability for Automatic Report Generation from Medical Images. (arXiv:2010.10563v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10563">
<div class="article-summary-box-inner">
<span><p>Every year physicians face an increasing demand of image-based diagnosis from
patients, a problem that can be addressed with recent artificial intelligence
methods. In this context, we survey works in the area of automatic report
generation from medical images, with emphasis on methods using deep neural
networks, with respect to: (1) Datasets, (2) Architecture Design, (3)
Explainability and (4) Evaluation Metrics. Our survey identifies interesting
developments, but also remaining challenges. Among them, the current evaluation
of generated reports is especially weak, since it mostly relies on traditional
Natural Language Processing (NLP) metrics, which do not accurately capture
medical correctness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BIGPrior: Towards Decoupling Learned Prior Hallucination and Data Fidelity in Image Restoration. (arXiv:2011.01406v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01406">
<div class="article-summary-box-inner">
<span><p>Classic image-restoration algorithms use a variety of priors, either
implicitly or explicitly. Their priors are hand-designed and their
corresponding weights are heuristically assigned. Hence, deep learning methods
often produce superior image restoration quality. Deep networks are, however,
capable of inducing strong and hardly predictable hallucinations. Networks
implicitly learn to be jointly faithful to the observed data while learning an
image prior; and the separation of original data and hallucinated data
downstream is then not possible. This limits their wide-spread adoption in
image restoration. Furthermore, it is often the hallucinated part that is
victim to degradation-model overfitting.
</p>
<p>We present an approach with decoupled network-prior based hallucination and
data fidelity terms. We refer to our framework as the Bayesian Integration of a
Generative Prior (BIGPrior). Our method is rooted in a Bayesian framework and
tightly connected to classic restoration methods. In fact, it can be viewed as
a generalization of a large family of classic restoration algorithms. We use
network inversion to extract image prior information from a generative network.
We show that, on image colorization, inpainting and denoising, our framework
consistently improves the inversion results. Our method, though partly reliant
on the quality of the generative network inversion, is competitive with
state-of-the-art supervised and task-specific restoration methods. It also
provides an additional metric that sets forth the degree of prior reliance per
pixel relative to data fidelity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Three-Stage Self-Training Framework for Semi-Supervised Semantic Segmentation. (arXiv:2012.00827v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00827">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation has been widely investigated in the community, in which
the state of the art techniques are based on supervised models. Those models
have reported unprecedented performance at the cost of requiring a large set of
high quality segmentation masks. To obtain such annotations is highly expensive
and time consuming, in particular, in semantic segmentation where pixel-level
annotations are required. In this work, we address this problem by proposing a
holistic solution framed as a three-stage self-training framework for
semi-supervised semantic segmentation. The key idea of our technique is the
extraction of the pseudo-masks statistical information to decrease uncertainty
in the predicted probability whilst enforcing segmentation consistency in a
multi-task fashion. We achieve this through a three-stage solution. Firstly, we
train a segmentation network to produce rough pseudo-masks which predicted
probability is highly uncertain. Secondly, we then decrease the uncertainty of
the pseudo-masks using a multi-task model that enforces consistency whilst
exploiting the rich statistical information of the data. We compare our
approach with existing methods for semi-supervised semantic segmentation and
demonstrate its state-of-the-art performance with extensive experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ACE-Net: Fine-Level Face Alignment through Anchors and Contours Estimation. (arXiv:2012.01461v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01461">
<div class="article-summary-box-inner">
<span><p>We propose a novel facial Anchors and Contours Estimation framework, ACE-Net,
for fine-level face alignment tasks. ACE-Net predicts facial anchors and
contours that are richer than traditional facial landmarks while overcoming
ambiguities and inconsistencies in their definitions. We introduce a weakly
supervised loss enabling ACE-Net to learn from existing facial landmarks
datasets without the need for reannotation. Instead, synthetic data, from which
GT contours can be easily obtained, is used during training to bridge the
density gap between landmarks and true facial contours. We evaluate the face
alignment accuracy of ACE-Net with respect to the HELEN dataset which has 194
annotated facial landmarks, while it is trained with only 68 or 36 landmarks
from the 300-W dataset. We show that ACE-Net generated contours are better than
contours interpolated straight from the 68 GT landmarks and ACE-Net also
outperforms models trained only with full supervision from GT landmarks-based
contours.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Morphology on categorical distributions. (arXiv:2012.07315v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07315">
<div class="article-summary-box-inner">
<span><p>The categorical distribution is a natural representation of uncertainty in
multi-class segmentations. In the two-class case the categorical distribution
reduces to the Bernoulli distribution, for which grayscale morphology provides
a range of useful operations. In the general case, applying morphological
operations on uncertain multi-class segmentations is not straightforward as an
image of categorical distributions is not a complete lattice. Although
morphology on color images has received wide attention, this is not so for
color-coded or categorical images and even less so for images of categorical
distributions. In this work, we establish a set of requirements for morphology
on categorical distributions by combining classic morphology with a
probabilistic view. We then define operators respecting these requirements,
introduce protected operations on categorical distributions and illustrate the
utility of these operators on two example tasks: modeling annotator bias in
brain tumor segmentations and segmenting vesicle instances from the predictions
of a multi-class U-Net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles. (arXiv:2101.06549v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06549">
<div class="article-summary-box-inner">
<span><p>As self-driving systems become better, simulating scenarios where the
autonomy stack may fail becomes more important. Traditionally, those scenarios
are generated for a few scenes with respect to the planning module that takes
ground-truth actor states as input. This does not scale and cannot identify all
possible autonomy failures, such as perception failures due to occlusion. In
this paper, we propose AdvSim, an adversarial framework to generate
safety-critical scenarios for any LiDAR-based autonomy system. Given an initial
traffic scenario, AdvSim modifies the actors' trajectories in a physically
plausible manner and updates the LiDAR sensor data to match the perturbed
world. Importantly, by simulating directly from sensor data, we obtain
adversarial scenarios that are safety-critical for the full autonomy stack. Our
experiments show that our approach is general and can identify thousands of
semantically meaningful safety-critical scenarios for a wide range of modern
self-driving systems. Furthermore, we show that the robustness and safety of
these systems can be further improved by training them with scenarios generated
by AdvSim.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Instance Retrieval: A Survey. (arXiv:2101.11282v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11282">
<div class="article-summary-box-inner">
<span><p>In recent years a vast amount of visual content has been generated and shared
from many fields, such as social media platforms, medical imaging, and
robotics. This abundance of content creation and sharing has introduced new
challenges, particularly that of searching databases for similar
content-Content Based Image Retrieval (CBIR)-a long-established research area
in which improved efficiency and accuracy are needed for real-time retrieval.
Artificial intelligence has made progress in CBIR and has significantly
facilitated the process of instance search. In this survey we review recent
instance retrieval works that are developed based on deep learning algorithms
and techniques, with the survey organized by deep network architecture types,
deep features, feature embedding and aggregation methods, and network
fine-tuning strategies. Our survey considers a wide variety of recent methods,
whereby we identify milestone work, reveal connections among various methods
and present the commonly used benchmarks, evaluation results, common
challenges, and propose promising future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tiny Adversarial Mulit-Objective Oneshot Neural Architecture Search. (arXiv:2103.00363v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00363">
<div class="article-summary-box-inner">
<span><p>Due to limited computational cost and energy consumption, most neural network
models deployed in mobile devices are tiny. However, tiny neural networks are
commonly very vulnerable to attacks. Current research has proved that larger
model size can improve robustness, but little research focuses on how to
enhance the robustness of tiny neural networks. Our work focuses on how to
improve the robustness of tiny neural networks without seriously deteriorating
of clean accuracy under mobile-level resources. To this end, we propose a
multi-objective oneshot network architecture search (NAS) algorithm to obtain
the best trade-off networks in terms of the adversarial accuracy, the clean
accuracy and the model size. Specifically, we design a novel search space based
on new tiny blocks and channels to balance model size and adversarial
performance. Moreover, since the supernet significantly affects the performance
of subnets in our NAS algorithm, we reveal the insights into how the supernet
helps to obtain the best subnet under white-box adversarial attacks.
Concretely, we explore a new adversarial training paradigm by analyzing the
adversarial transferability, the width of the supernet and the difference
between training the subnets from scratch and fine-tuning. Finally, we make a
statistical analysis for the layer-wise combination of certain blocks and
channels on the first non-dominated front, which can serve as a guideline to
design tiny neural network architectures for the resilience of adversarial
perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feedback Refined Local-Global Network for Super-Resolution of Hyperspectral Imagery. (arXiv:2103.04354v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04354">
<div class="article-summary-box-inner">
<span><p>With the development of deep learning technology, multi-spectral image
super-resolution methods based on convolutional neural network have recently
achieved great progress. However, the single hyperspectral image
super-resolution remains a challenging problem due to the high-dimensional and
complex spectral characteristics of hyperspectral data, which make it difficult
to simultaneously capture spatial and spectral information. To deal with this
issue, we propose a novel Feedback Refined Local-Global Network (FRLGN) for the
super-resolution of hyperspectral image. To be specific, we develop a new
Feedback Structure and a Local-Global Spectral Block to alleviate the
difficulty in spatial and spectral feature extraction. The Feedback Structure
can transfer the high-level information to guide the generation process of
low-level feature, which is achieved by a recurrent structure with finite
unfoldings. Furthermore, in order to effectively use the high-level information
passed back, a Local-Global Spectral Block is constructed to handle the
feedback connections. The Local-Global Spectral Block utilizes the feedback
high-level information to correct the low-level feature from local spectral
bands and generates powerful high-level representations among global spectral
bands. By incorporating the Feedback Structure and Local-Global Spectral Block,
the FRLGN can fully exploit spatial-spectral correlations among spectral bands
and gradually reconstruct high-resolution hyperspectral images. The source code
of FRLGN is available at https://github.com/tangzhenjie/FRLGN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reframing Neural Networks: Deep Structure in Overcomplete Representations. (arXiv:2103.05804v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05804">
<div class="article-summary-box-inner">
<span><p>In comparison to classical shallow representation learning techniques, deep
neural networks have achieved superior performance in nearly every application
benchmark. But despite their clear empirical advantages, it is still not well
understood what makes them so effective. To approach this question, we
introduce deep frame approximation: a unifying framework for constrained
representation learning with structured overcomplete frames. While exact
inference requires iterative optimization, it may be approximated by the
operations of a feed-forward deep neural network. We indirectly analyze how
model capacity relates to frame structures induced by architectural
hyperparameters such as depth, width, and skip connections. We quantify these
structural differences with the deep frame potential, a data-independent
measure of coherence linked to representation uniqueness and stability. As a
criterion for model selection, we show correlation with generalization error on
a variety of common deep network architectures and datasets. We also
demonstrate how recurrent networks implementing iterative optimization
algorithms can achieve performance comparable to their feed-forward
approximations while improving adversarial robustness. This connection to the
established theory of overcomplete representations suggests promising new
directions for principled deep network architecture design with less reliance
on ad-hoc engineering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video-Specific Autoencoders for Exploring, Editing and Transmitting Videos. (arXiv:2103.17261v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17261">
<div class="article-summary-box-inner">
<span><p>We study video-specific autoencoders that allow a human user to explore,
edit, and efficiently transmit videos. Prior work has independently looked at
these problems (and sub-problems) and proposed different formulations. In this
work, we train a simple autoencoder (from scratch) on multiple frames of a
specific video. We observe: (1) latent codes learned by a video-specific
autoencoder capture spatial and temporal properties of that video; and (2)
autoencoders can project out-of-sample inputs onto the video-specific manifold.
These two properties allow us to explore, edit, and efficiently transmit a
video using one learned representation. For e.g., linear operations on latent
codes allow users to visualize the contents of a video. Associating latent
codes of a video and manifold projection enables users to make desired edits.
Interpolating latent codes and manifold projection allows the transmission of
sparse low-res frames over a network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust partial Fourier reconstruction for diffusion-weighted imaging using a recurrent convolutional neural network. (arXiv:2105.09378v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09378">
<div class="article-summary-box-inner">
<span><p>Purpose: To develop an algorithm for robust partial Fourier (PF)
reconstruction applicable to diffusion-weighted (DW) images with non-smooth
phase variations.
</p>
<p>Methods: Based on an unrolled proximal splitting algorithm, a neural network
architecture is derived which alternates between data consistency operations
and regularization implemented by recurrent convolutions. In order to exploit
correlations, multiple repetitions of the same slice are jointly reconstructed
under consideration of permutation-equivariance. The algorithm is trained on DW
liver data of 60 volunteers and evaluated on retrospectively and prospectively
sub-sampled data of different anatomies and resolutions.
</p>
<p>Results: The proposed method is able to significantly outperform conventional
PF techniques on retrospectively sub-sampled data in terms of quantitative
measures as well as perceptual image quality. In this context, joint
reconstruction of repetitions as well as the particular type of recurrent
network unrolling are found to be beneficial with respect to reconstruction
quality. On prospectively PF-sampled data, the proposed method enables DW
imaging with higher signal without sacrificing image resolution or introducing
additional artifacts. Alternatively, it can be used to counter the TE increase
in acquisitions with higher resolution. Further, generalizability can be shown
to prospective brain data exhibiting anatomies and contrasts not present in the
training set.
</p>
<p>Conclusion: This work demonstrates that robust PF reconstruction of DW data
is feasible even at strong PF factors in anatomies prone to phase variations.
Since the proposed method does not rely on smoothness priors of the phase but
uses learned recurrent convolutions instead, artifacts of conventional PF
methods can be avoided.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Embracing New Techniques in Deep Learning for Estimating Image Memorability. (arXiv:2105.10598v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10598">
<div class="article-summary-box-inner">
<span><p>Various work has suggested that the memorability of an image is consistent
across people, and thus can be treated as an intrinsic property of an image.
Using computer vision models, we can make specific predictions about what
people will remember or forget. While older work has used now-outdated deep
learning architectures to predict image memorability, innovations in the field
have given us new techniques to apply to this problem. Here, we propose and
evaluate five alternative deep learning models which exploit developments in
the field from the last five years, largely the introduction of residual neural
networks, which are intended to allow the model to use semantic information in
the memorability estimation process. These new models were tested against the
prior state of the art with a combined dataset built to optimize both
within-category and across-category predictions. Our findings suggest that the
key prior memorability network had overstated its generalizability and was
overfit on its training set. Our new models outperform this prior model,
leading us to conclude that Residual Networks outperform simpler convolutional
neural networks in memorability regression. We make our new state-of-the-art
model readily available to the research community, allowing memory researchers
to make predictions about memorability on a wider range of images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMURF: SeMantic and linguistic UndeRstanding Fusion for Caption Evaluation via Typicality Analysis. (arXiv:2106.01444v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01444">
<div class="article-summary-box-inner">
<span><p>The open-ended nature of visual captioning makes it a challenging area for
evaluation. The majority of proposed models rely on specialized training to
improve human-correlation, resulting in limited adoption, generalizability, and
explainabilty. We introduce "typicality", a new formulation of evaluation
rooted in information theory, which is uniquely suited for problems lacking a
definite ground truth. Typicality serves as our framework to develop a novel
semantic comparison, SPARCS, as well as referenceless fluency evaluation
metrics. Over the course of our analysis, two separate dimensions of fluency
naturally emerge: style, captured by metric SPURTS, and grammar, captured in
the form of grammatical outlier penalties. Through extensive experiments and
ablation studies on benchmark datasets, we show how these decomposed dimensions
of semantics and fluency provide greater system-level insight into captioner
differences. Our proposed metrics along with their combination, SMURF, achieve
state-of-the-art correlation with human judgment when compared with other
rule-based evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-Implicit Neural Representation for Fonts. (arXiv:2106.06866v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06866">
<div class="article-summary-box-inner">
<span><p>Fonts are ubiquitous across documents and come in a variety of styles. They
are either represented in a native vector format or rasterized to produce fixed
resolution images. In the first case, the non-standard representation prevents
benefiting from latest network architectures for neural representations; while,
in the latter case, the rasterized representation, when encoded via networks,
results in loss of data fidelity, as font-specific discontinuities like edges
and corners are difficult to represent using neural networks. Based on the
observation that complex fonts can be represented by a superposition of a set
of simpler occupancy functions, we introduce \textit{multi-implicits} to
represent fonts as a permutation-invariant set of learned implict functions,
without losing features (e.g., edges and corners). However, while
multi-implicits locally preserve font features, obtaining supervision in the
form of ground truth multi-channel signals is a problem in itself. Instead, we
propose how to train such a representation with only local supervision, while
the proposed neural architecture directly finds globally consistent
multi-implicits for font families. We extensively evaluate the proposed
representation for various tasks including reconstruction, interpolation, and
synthesis to demonstrate clear advantages with existing alternatives.
Additionally, the representation naturally enables glyph completion, wherein a
single characteristic font is used to synthesize a whole font family in the
target style.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06965">
<div class="article-summary-box-inner">
<span><p>Recently, chest X-ray report generation, which aims to automatically generate
descriptions of given chest X-ray images, has received growing research
interests. The key challenge of chest X-ray report generation is to accurately
capture and describe the abnormal regions. In most cases, the normal regions
dominate the entire chest X-ray image, and the corresponding descriptions of
these normal regions dominate the final report. Due to such data bias,
learning-based models may fail to attend to abnormal regions. In this work, to
effectively capture and describe abnormal regions, we propose the Contrastive
Attention (CA) model. Instead of solely focusing on the current input image,
the CA model compares the current input image with normal images to distill the
contrastive information. The acquired contrastive information can better
represent the visual features of abnormal regions. According to the experiments
on the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into
several existing models can boost their performance across most metrics. In
addition, according to the analysis, the CA model can help existing models
better attend to the abnormal regions and provide more accurate descriptions
which are crucial for an interpretable diagnosis. Specifically, we achieve the
state-of-the-art results on the two public datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v8 [math.OC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08208">
<div class="article-summary-box-inner">
<span><p>Adaptive gradient methods have shown excellent performances for solving many
machine learning problems. Although multiple adaptive gradient methods were
recently studied, they mainly focus on either empirical or theoretical aspects
and also only work for specific problems by using some specific adaptive
learning rates. Thus, it is desired to design a universal framework for
practical algorithms of adaptive gradients with theoretical guarantee to solve
general problems. To fill this gap, we propose a faster and universal framework
of adaptive gradients (i.e., SUPER-ADAM) by introducing a universal adaptive
matrix that includes most existing adaptive gradient forms. Moreover, our
framework can flexibly integrate the momentum and variance reduced techniques.
In particular, our novel framework provides the convergence analysis support
for adaptive gradient methods under the nonconvex setting. In theoretical
analysis, we prove that our SUPER-ADAM algorithm can achieve the best known
gradient (i.e., stochastic first-order oracle (SFO)) complexity of
$\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary point of
nonconvex optimization, which matches the lower bound for stochastic smooth
nonconvex optimization. In numerical experiments, we employ various deep
learning tasks to validate that our algorithm consistently outperforms the
existing adaptive algorithms. Code is available at
https://github.com/LIJUNYI95/SuperAdam
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medical Image Analysis on Left Atrial LGE MRI for Atrial Fibrillation Studies: A Review. (arXiv:2106.09862v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09862">
<div class="article-summary-box-inner">
<span><p>Late gadolinium enhancement magnetic resonance imaging (LGE MRI) is commonly
used to visualize and quantify left atrial (LA) scars. The position and extent
of scars provide important information of the pathophysiology and progression
of atrial fibrillation (AF). Hence, LA scar segmentation and quantification
from LGE MRI can be useful in computer-assisted diagnosis and treatment
stratification of AF patients. Since manual delineation can be time-consuming
and subject to intra- and inter-expert variability, automating this computing
is highly desired, which nevertheless is still challenging and
under-researched.
</p>
<p>This paper aims to provide a systematic review on computing methods for LA
cavity, wall, scar and ablation gap segmentation and quantification from LGE
MRI, and the related literature for AF studies. Specifically, we first
summarize AF-related imaging techniques, particularly LGE MRI. Then, we review
the methodologies of the four computing tasks in detail, and summarize the
validation strategies applied in each task. Finally, the possible future
developments are outlined, with a brief survey on the potential clinical
applications of the aforementioned methods. The review shows that the research
into this topic is still in early stages. Although several methods have been
proposed, especially for LA segmentation, there is still large scope for
further algorithmic developments due to performance issues related to the high
variability of enhancement appearance and differences in image acquisition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Action Transformer: A Self-Attention Model for Short-Time Pose-Based Human Action Recognition. (arXiv:2107.00606v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00606">
<div class="article-summary-box-inner">
<span><p>Deep neural networks based purely on attention have been successful across
several domains, relying on minimal architectural priors from the designer. In
Human Action Recognition (HAR), attention mechanisms have been primarily
adopted on top of standard convolutional or recurrent layers, improving the
overall generalization capability. In this work, we introduce Action
Transformer (AcT), a simple, fully self-attentional architecture that
consistently outperforms more elaborated networks that mix convolutional,
recurrent and attentive layers. In order to limit computational and energy
requests, building on previous human action recognition research, the proposed
approach exploits 2D pose representations over small temporal windows,
providing a low latency solution for accurate and effective real-time
performance. Moreover, we open-source MPOSE2021, a new large-scale dataset, as
an attempt to build a formal training and evaluation benchmark for real-time,
short-time HAR. The proposed methodology was extensively tested on MPOSE2021
and compared to several state-of-the-art architectures, proving the
effectiveness of the AcT model and laying the foundations for future work on
HAR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows. (arXiv:2107.00652v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00652">
<div class="article-summary-box-inner">
<span><p>We present CSWin Transformer, an efficient and effective Transformer-based
backbone for general-purpose vision tasks. A challenging issue in Transformer
design is that global self-attention is very expensive to compute whereas local
self-attention often limits the field of interactions of each token. To address
this issue, we develop the Cross-Shaped Window self-attention mechanism for
computing self-attention in the horizontal and vertical stripes in parallel
that form a cross-shaped window, with each stripe obtained by splitting the
input feature into stripes of equal width. We provide a mathematical analysis
of the effect of the stripe width and vary the stripe width for different
layers of the Transformer network which achieves strong modeling capability
while limiting the computation cost. We also introduce Locally-enhanced
Positional Encoding (LePE), which handles the local positional information
better than existing encoding schemes. LePE naturally supports arbitrary input
resolutions, and is thus especially effective and friendly for downstream
tasks. Incorporated with these designs and a hierarchical structure, CSWin
Transformer demonstrates competitive performance on common vision tasks.
Specifically, it achieves 85.4\% Top-1 accuracy on ImageNet-1K without any
extra training data or label, 53.9 box AP and 46.4 mask AP on the COCO
detection task, and 52.2 mIOU on the ADE20K semantic segmentation task,
surpassing previous state-of-the-art Swin Transformer backbone by +1.2, +2.0,
+1.4, and +2.0 respectively under the similar FLOPs setting. By further
pretraining on the larger dataset ImageNet-21K, we achieve 87.5% Top-1 accuracy
on ImageNet-1K and high segmentation performance on ADE20K with 55.7 mIoU. The
code and models are available at
https://github.com/microsoft/CSWin-Transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Parser: Representing Part-whole Hierarchies with Transformers. (arXiv:2107.05790v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05790">
<div class="article-summary-box-inner">
<span><p>Human vision is able to capture the part-whole hierarchical information from
the entire scene. This paper presents the Visual Parser (ViP) that explicitly
constructs such a hierarchy with transformers. ViP divides visual
representations into two levels, the part level and the whole level.
Information of each part represents a combination of several independent
vectors within the whole. To model the representations of the two levels, we
first encode the information from the whole into part vectors through an
attention mechanism, then decode the global information within the part vectors
back into the whole representation. By iteratively parsing the two levels with
the proposed encoder-decoder interaction, the model can gradually refine the
features on both levels. Experimental results demonstrate that ViP can achieve
very competitive performance on three major tasks e.g. classification,
detection and instance segmentation. In particular, it can surpass the previous
state-of-the-art CNN backbones by a large margin on object detection. The tiny
model of the ViP family with $7.2\times$ fewer parameters and $10.9\times$
fewer FLOPS can perform comparably with the largest model
ResNeXt-101-64$\times$4d of ResNe(X)t family. Visualization results also
demonstrate that the learnt parts are highly informative of the predicting
class, making ViP more explainable than previous fundamental architectures.
Code is available at https://github.com/kevin-ssy/ViP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards explainable artificial intelligence (XAI) for early anticipation of traffic accidents. (arXiv:2108.00273v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00273">
<div class="article-summary-box-inner">
<span><p>Traffic accident anticipation is a vital function of Automated Driving
Systems (ADSs) for providing a safety-guaranteed driving experience. An
accident anticipation model aims to predict accidents promptly and accurately
before they occur. Existing Artificial Intelligence (AI) models of accident
anticipation lack a human-interpretable explanation of their decision-making.
Although these models perform well, they remain a black-box to the ADS users,
thus difficult to get their trust. To this end, this paper presents a Gated
Recurrent Unit (GRU) network that learns spatio-temporal relational features
for the early anticipation of traffic accidents from dashcam video data. A
post-hoc attention mechanism named Grad-CAM is integrated into the network to
generate saliency maps as the visual explanation of the accident anticipation
decision. An eye tracker captures human eye fixation points for generating
human attention maps. The explainability of network-generated saliency maps is
evaluated in comparison to human attention maps. Qualitative and quantitative
results on a public crash dataset confirm that the proposed explainable network
can anticipate an accident on average 4.57 seconds before it occurs, with
94.02% average precision. In further, various post-hoc attention-based XAI
methods are evaluated and compared. It confirms that the Grad-CAM chosen by
this study can generate high-quality, human-interpretable saliency maps (with
1.23 Normalized Scanpath Saliency) for explaining the crash anticipation
decision. Importantly, results confirm that the proposed AI model, with a
human-inspired design, can outperform humans in the accident anticipation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">O2NA: An Object-Oriented Non-Autoregressive Approach for Controllable Video Captioning. (arXiv:2108.02359v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02359">
<div class="article-summary-box-inner">
<span><p>Video captioning combines video understanding and language generation.
Different from image captioning that describes a static image with details of
almost every object, video captioning usually considers a sequence of frames
and biases towards focused objects, e.g., the objects that stay in focus
regardless of the changing background. Therefore, detecting and properly
accommodating focused objects is critical in video captioning. To enforce the
description of focused objects and achieve controllable video captioning, we
propose an Object-Oriented Non-Autoregressive approach (O2NA), which performs
caption generation in three steps: 1) identify the focused objects and predict
their locations in the target caption; 2) generate the related attribute words
and relation words of these focused objects to form a draft caption; and 3)
combine video information to refine the draft caption to a fluent final
caption. Since the focused objects are generated and located ahead of other
words, it is difficult to apply the word-by-word autoregressive generation
process; instead, we adopt a non-autoregressive approach. The experiments on
two benchmark datasets, i.e., MSR-VTT and MSVD, demonstrate the effectiveness
of O2NA, which achieves results competitive with the state-of-the-arts but with
both higher diversity and higher inference speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PVT: Point-Voxel Transformer for Point Cloud Learning. (arXiv:2108.06076v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06076">
<div class="article-summary-box-inner">
<span><p>The recently developed pure Transformer architectures have attained promising
accuracy on point cloud learning benchmarks compared to convolutional neural
networks. However, existing point cloud Transformers are computationally
expensive since they waste a significant amount of time on structuring the
irregular data. To solve this shortcoming, we present Sparse Window Attention
(SWA) module to gather coarse-grained local features from non-empty voxels,
which not only bypasses the expensive irregular data structuring and invalid
empty voxel computation, but also obtains linear computational complexity with
respect to voxel resolution. Meanwhile, to gather fine-grained features about
the global shape, we introduce relative attention (RA) module, a more robust
self-attention variant for rigid transformations of objects. Equipped with the
SWA and RA, we construct our neural architecture called PVT that integrates
both modules into a joint framework for point cloud learning. Compared with
previous Transformer-based and attention-based models, our method attains top
accuracy of 94.0% on classification benchmark and 10x inference speedup on
average. Extensive experiments also valid the effectiveness of PVT on part and
semantic segmentation benchmarks (86.6% and 69.2% mIoU, respectively).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Specificity-preserving RGB-D Saliency Detection. (arXiv:2108.08162v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08162">
<div class="article-summary-box-inner">
<span><p>Salient object detection (SOD) on RGB and depth images has attracted more and
more research interests, due to its effectiveness and the fact that depth cues
can now be conveniently captured. Existing RGB-D SOD models usually adopt
different fusion strategies to learn a shared representation from the two
modalities (\ie, RGB and depth), while few methods explicitly consider how to
preserve modality-specific characteristics. In this study, we propose a novel
framework, termed SPNet} (Specificity-preserving network), which benefits SOD
performance by exploring both the shared information and modality-specific
properties (\eg, specificity). Specifically, we propose to adopt two
modality-specific networks and a shared learning network to generate individual
and shared saliency prediction maps, respectively. To effectively fuse
cross-modal features in the shared learning network, we propose a
cross-enhanced integration module (CIM) and then propagate the fused feature to
the next layer for integrating cross-level information. Moreover, to capture
rich complementary multi-modal information for boosting the SOD performance, we
propose a multi-modal feature aggregation (MFA) module to integrate the
modality-specific features from each individual decoder into the shared
decoder. By using a skip connection, the hierarchical features between the
encoder and decoder layers can be fully combined. Extensive experiments
demonstrate that our~\ours~outperforms cutting-edge approaches on six popular
RGB-D SOD and three camouflaged object detection benchmarks. The project is
publicly available at: https://github.com/taozh2017/SPNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GlassNet: Label Decoupling-based Three-stream Neural Network for Robust Image Glass Detection. (arXiv:2108.11117v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11117">
<div class="article-summary-box-inner">
<span><p>Most of the existing object detection methods generate poor glass detection
results, due to the fact that the transparent glass shares the same appearance
with arbitrary objects behind it in an image. Different from traditional deep
learning-based wisdoms that simply use the object boundary as auxiliary
supervision, we exploit label decoupling to decompose the original labeled
ground-truth (GT) map into an interior-diffusion map and a boundary-diffusion
map. The GT map in collaboration with the two newly generated maps breaks the
imbalanced distribution of the object boundary, leading to improved glass
detection quality. We have three key contributions to solve the transparent
glass detection problem: (1) We propose a three-stream neural network (call
GlassNet for short) to fully absorb beneficial features in the three maps. (2)
We design a multi-scale interactive dilation module to explore a wider range of
contextual information. (3) We develop an attention-based boundary-aware
feature Mosaic module to integrate multi-modal information. Extensive
experiments on the benchmark dataset exhibit clear improvements of our method
over SOTAs, in terms of both the overall glass detection accuracy and boundary
clearness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Graph Convolutional Skeleton Transformer for Action Recognition. (arXiv:2109.02860v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02860">
<div class="article-summary-box-inner">
<span><p>Graph convolutional networks (GCNs) have emerged as dominant methods for
skeleton-based action recognition.
</p>
<p>However, they still suffer from two problems, namely, neighborhood
constraints and entangled spatiotemporal feature representations.
</p>
<p>Most studies have focused on improving the design of graph topology to solve
the first problem but they have yet to fully explore the latter.
</p>
<p>In this work, we design a disentangled spatiotemporal transformer (DSTT)
block to overcome the above limitations of GCNs in three steps: (i) feature
disentanglement for spatiotemporal decomposition;(ii) global spatiotemporal
attention for capturing correlations in the global context; and (iii) local
information enhancement for utilizing more local information.
</p>
<p>Thereon, we propose a novel architecture, named Hierarchical Graph
Convolutional skeleton Transformer (HGCT), to employ the complementary
advantages of GCN (i.e., local topology, temporal dynamics and hierarchy) and
Transformer (i.e., global context and dynamic attention).
</p>
<p>HGCT is lightweight and computationally efficient.
</p>
<p>Quantitative analysis demonstrates the superiority and good interpretability
of HGCT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PQ-Transformer: Jointly Parsing 3D Objects and Layouts from Point Clouds. (arXiv:2109.05566v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05566">
<div class="article-summary-box-inner">
<span><p>3D scene understanding from point clouds plays a vital role for various
robotic applications. Unfortunately, current state-of-the-art methods use
separate neural networks for different tasks like object detection or room
layout estimation. Such a scheme has two limitations: 1) Storing and running
several networks for different tasks are expensive for typical robotic
platforms. 2) The intrinsic structure of separate outputs are ignored and
potentially violated. To this end, we propose the first transformer
architecture that predicts 3D objects and layouts simultaneously, using point
cloud inputs. Unlike existing methods that either estimate layout keypoints or
edges, we directly parameterize room layout as a set of quads. As such, the
proposed architecture is termed as P(oint)Q(uad)-Transformer. Along with the
novel quad representation, we propose a tailored physical constraint loss
function that discourages object-layout interference. The quantitative and
qualitative evaluations on the public benchmark ScanNet show that the proposed
PQ-Transformer succeeds to jointly parse 3D objects and layouts, running at a
quasi-real-time (8.91 FPS) rate without efficiency-oriented optimization.
Moreover, the new physical constraint loss can improve strong baselines, and
the F1-score of the room layout is significantly promoted from 37.9% to 57.9%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Image Decomposition with Phase-Correlation Networks. (arXiv:2110.03473v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03473">
<div class="article-summary-box-inner">
<span><p>The ability to decompose scenes into their object components is a desired
property for autonomous agents, allowing them to reason and act in their
surroundings. Recently, different methods have been proposed to learn
object-centric representations from data in an unsupervised manner. These
methods often rely on latent representations learned by deep neural networks,
hence requiring high computational costs and large amounts of curated data.
Such models are also difficult to interpret. To address these challenges, we
propose the Phase-Correlation Decomposition Network (PCDNet), a novel model
that decomposes a scene into its object components, which are represented as
transformed versions of a set of learned object prototypes. The core building
block in PCDNet is the Phase-Correlation Cell (PC Cell), which exploits the
frequency-domain representation of the images in order to estimate the
transformation between an object prototype and its transformed version in the
image. In our experiments, we show how PCDNet outperforms state-of-the-art
methods for unsupervised object discovery and segmentation on simple benchmark
datasets and on more challenging data, while using a small number of learnable
parameters and being fully interpretable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distinguishing Natural and Computer-Generated Images using Multi-Colorspace fused EfficientNet. (arXiv:2110.09428v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09428">
<div class="article-summary-box-inner">
<span><p>The problem of distinguishing natural images from photo-realistic
computer-generated ones either addresses natural images versus computer
graphics or natural images versus GAN images, at a time. But in a real-world
image forensic scenario, it is highly essential to consider all categories of
image generation, since in most cases image generation is unknown. We, for the
first time, to our best knowledge, approach the problem of distinguishing
natural images from photo-realistic computer-generated images as a three-class
classification task classifying natural, computer graphics, and GAN images. For
the task, we propose a Multi-Colorspace fused EfficientNet model by parallelly
fusing three EfficientNet networks that follow transfer learning methodology
where each network operates in different colorspaces, RGB, LCH, and HSV, chosen
after analyzing the efficacy of various colorspace transformations in this
image forensics problem. Our model outperforms the baselines in terms of
accuracy, robustness towards post-processing, and generalizability towards
other datasets. We conduct psychophysics experiments to understand how
accurately humans can distinguish natural, computer graphics, and GAN images
where we could observe that humans find difficulty in classifying these images,
particularly the computer-generated images, indicating the necessity of
computational algorithms for the task. We also analyze the behavior of our
model through visual explanations to understand salient regions that contribute
to the model's decision making and compare with manual explanations provided by
human participants in the form of region markings, where we could observe
similarities in both the explanations indicating the powerful nature of our
model to take the decisions meaningfully.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video-based fully automatic assessment of open surgery suturing skills. (arXiv:2110.13972v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13972">
<div class="article-summary-box-inner">
<span><p>The goal of this study was to develop new reliable open surgery suturing
simulation system for training medical students in situation where resources
are limited or in the domestic setup. Namely, we developed an algorithm for
tools and hands localization as well as identifying the interactions between
them based on simple webcam video data, calculating motion metrics for
assessment of surgical skill. Twenty-five participants performed multiple
suturing tasks using our simulator. The YOLO network has been modified to a
multi-task network, for the purpose of tool localization and tool-hand
interaction detection. This was accomplished by splitting the YOLO detection
heads so that they supported both tasks with minimal addition to computer
run-time. Furthermore, based on the outcome of the system, motion metrics were
calculated. These metrics included traditional metrics such as time and path
length as well as new metrics assessing the technique participants use for
holding the tools. The dual-task network performance was similar to that of two
networks, while computational load was only slightly bigger than one network.
In addition, the motion metrics showed significant differences between experts
and novices. While video capture is an essential part of minimally invasive
surgery, it is not an integral component of open surgery. Thus, new algorithms,
focusing on the unique challenges open surgery videos present, are required. In
this study, a dual-task network was developed to solve both a localization task
and a hand-tool interaction task. The dual network may be easily expanded to a
multi-task network, which may be useful for images with multiple layers and for
evaluating the interaction between these different layers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FabricFlowNet: Bimanual Cloth Manipulation with a Flow-based Policy. (arXiv:2111.05623v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.05623">
<div class="article-summary-box-inner">
<span><p>We address the problem of goal-directed cloth manipulation, a challenging
task due to the deformability of cloth. Our insight is that optical flow, a
technique normally used for motion estimation in video, can also provide an
effective representation for corresponding cloth poses across observation and
goal images. We introduce FabricFlowNet (FFN), a cloth manipulation policy that
leverages flow as both an input and as an action representation to improve
performance. FabricFlowNet also elegantly switches between bimanual and
single-arm actions based on the desired goal. We show that FabricFlowNet
significantly outperforms state-of-the-art model-free and model-based cloth
manipulation policies that take image input. We also present real-world
experiments on a bimanual system, demonstrating effective sim-to-real transfer.
Finally, we show that our method generalizes when trained on a single square
cloth to other cloth shapes, such as T-shirts and rectangular cloths. Video and
other supplementary materials are available at:
https://sites.google.com/view/fabricflownet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Analysis of the Influence of Transfer Learning When Measuring the Tortuosity of Blood Vessels. (arXiv:2111.10255v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.10255">
<div class="article-summary-box-inner">
<span><p>Characterizing blood vessels in digital images is important for the diagnosis
of many types of diseases as well as for assisting current researches regarding
vascular systems. The automated analysis of blood vessels typically requires
the identification, or segmentation, of the blood vessels in an image or a set
of images, which is usually a challenging task. Convolutional Neural Networks
(CNNs) have been shown to provide excellent results regarding the segmentation
of blood vessels. One important aspect of CNNs is that they can be trained on
large amounts of data and then be made available, for instance, in image
processing software for wide use. The pre-trained CNNs can then be easily
applied in downstream blood vessel characterization tasks such as the
calculation of the length, tortuosity, or caliber of the blood vessels. Yet, it
is still unclear if pre-trained CNNs can provide robust, unbiased, results on
downstream tasks when applied to datasets that they were not trained on. Here,
we focus on measuring the tortuosity of blood vessels and investigate to which
extent CNNs may provide biased tortuosity values even after fine-tuning the
network to the new dataset under study. We show that the tortuosity values
obtained by a CNN trained from scratch on a dataset may not agree with those
obtained by a fine-tuned network that was pre-trained on a dataset having
different tortuosity statistics. In addition, we show that the improvement in
segmentation performance when fine-tuning the network does not necessarily lead
to a respective improvement on the estimation of the tortuosity. To mitigate
the aforementioned issues, we propose the application of specific data
augmentation techniques even in situations where they do not improve
segmentation performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Graph-Convolutional Variational AutoEncoding for Generative Modelling of Human Motion. (arXiv:2111.12602v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12602">
<div class="article-summary-box-inner">
<span><p>Models of human motion commonly focus either on trajectory prediction or
action classification but rarely both. The marked heterogeneity and intricate
compositionality of human motion render each task vulnerable to the data
degradation and distributional shift common to real-world scenarios. A
sufficiently expressive generative model of action could in theory enable data
conditioning and distributional resilience within a unified framework
applicable to both tasks. Here we propose a novel architecture based on
hierarchical variational autoencoders and deep graph convolutional neural
networks for generating a holistic model of action over multiple time-scales.
We show this Hierarchical Graph-convolutional Variational Autoencoder (HG-VAE)
to be capable of generating coherent actions, detecting out-of-distribution
data, and imputing missing data by gradient ascent on the model's posterior.
Trained and evaluated on H3.6M and the largest collection of open source human
motion data, AMASS, we show HG-VAE can facilitate downstream discriminative
learning better than baseline models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PGGANet: Pose Guided Graph Attention Network for Person Re-identification. (arXiv:2111.14411v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.14411">
<div class="article-summary-box-inner">
<span><p>Person re-identification (reID) aims at retrieving a person from images
captured by different cameras. For deep-learning-based reID methods, it has
been proved that using local features together with global feature could help
to give robust representation for person retrieval. Human pose information
could provide the locations of human skeleton to effectively guide the network
to pay more attention on these key areas and could also help to reduce the
noise distractions from background or occlusion. However, methods proposed by
previous pose-based works might not be able to fully exploit the benefits of
pose information and few of them take into consideration the different
contributions of separate local features. In this paper, we propose a pose
guided graph attention network, a multi-branch architecture consisting of one
branch for global feature, one branch for mid-granular body features and one
branch for fine-granular key point features. We use a pre-trained pose
estimator to generate the key-point heatmaps for local feature learning and
carefully design a graph attention convolution layer to re-assign the
contribution weights of extracted local features by modeling the similarities
relations. Experiment results demonstrate the effectiveness of our approach on
discriminative feature learning and we show that our model achieves
state-of-the-art performances on several mainstream evaluation datasets. We
also conduct a plenty of ablation studies and design different kinds of
comparison experiments for our network to prove its effectiveness and
robustness, including occluded experiments and cross-domain tests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiffSDFSim: Differentiable Rigid-Body Dynamics With Implicit Shapes. (arXiv:2111.15318v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.15318">
<div class="article-summary-box-inner">
<span><p>Differentiable physics is a powerful tool in computer vision and robotics for
scene understanding and reasoning about interactions. Existing approaches have
frequently been limited to objects with simple shape or shapes that are known
in advance. In this paper, we propose a novel approach to differentiable
physics with frictional contacts which represents object shapes implicitly
using signed distance fields (SDFs). Our simulation supports contact point
calculation even when the involved shapes are nonconvex. Moreover, we propose
ways for differentiating the dynamics for the object shape to facilitate shape
optimization using gradient-based methods. In our experiments, we demonstrate
that our approach allows for model-based inference of physical parameters such
as friction coefficients, mass, forces or shape parameters from trajectory and
depth image observations in several challenging synthetic scenarios and a real
image sequence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task2Sim : Towards Effective Pre-training and Transfer from Synthetic Data. (arXiv:2112.00054v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00054">
<div class="article-summary-box-inner">
<span><p>Pre-training models on Imagenet or other massive datasets of real images has
led to major advances in computer vision, albeit accompanied with shortcomings
related to curation cost, privacy, usage rights, and ethical issues. In this
paper, for the first time, we study the transferability of pre-trained models
based on synthetic data generated by graphics simulators to downstream tasks
from very different domains. In using such synthetic data for pre-training, we
find that downstream performance on different tasks are favored by different
configurations of simulation parameters (e.g. lighting, object pose,
backgrounds, etc.), and that there is no one-size-fits-all solution. It is thus
better to tailor synthetic pre-training data to a specific downstream task, for
best performance. We introduce Task2Sim, a unified model mapping downstream
task representations to optimal simulation parameters to generate synthetic
pre-training data for them. Task2Sim learns this mapping by training to find
the set of best parameters on a set of "seen" tasks. Once trained, it can then
be used to predict best simulation parameters for novel "unseen" tasks in one
shot, without requiring additional training. Given a budget in number of images
per class, our extensive experiments with 20 diverse downstream tasks show
Task2Sim's task-adaptive pre-training data results in significantly better
downstream performance than non-adaptively choosing simulation parameters on
both seen and unseen tasks. It is even competitive with pre-training on real
images from Imagenet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Spatiotemporal Representation Learning by Exploiting Video Continuity. (arXiv:2112.05883v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.05883">
<div class="article-summary-box-inner">
<span><p>Recent self-supervised video representation learning methods have found
significant success by exploring essential properties of videos, e.g. speed,
temporal order, etc. This work exploits an essential yet under-explored
property of videos, the video continuity, to obtain supervision signals for
self-supervised representation learning. Specifically, we formulate three novel
continuity-related pretext tasks, i.e. continuity justification, discontinuity
localization, and missing section approximation, that jointly supervise a
shared backbone for video representation learning. This self-supervision
approach, termed as Continuity Perception Network (CPNet), solves the three
tasks altogether and encourages the backbone network to learn local and
long-ranged motion and context representations. It outperforms prior arts on
multiple downstream tasks, such as action recognition, video retrieval, and
action localization. Additionally, the video continuity can be complementary to
other coarse-grained video properties for representation learning, and
integrating the proposed pretext task to prior arts can yield much performance
gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SAC-GAN: Structure-Aware Image-to-Image Composition for Self-Driving. (arXiv:2112.06596v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06596">
<div class="article-summary-box-inner">
<span><p>We present a compositional approach to image augmentation for self-driving
applications. It is an end-to-end neural network that is trained to seamlessly
compose an object (e.g., a vehicle or pedestrian) represented as a cropped
patch from an object image, into a background scene image. As our approach
emphasizes more on semantic and structural coherence of the composed images,
rather than their pixel-level RGB accuracies, we tailor the input and output of
our network with structure-aware features and design our network losses
accordingly. Specifically, our network takes the semantic layout features from
the input scene image, features encoded from the edges and silhouette in the
input object patch, as well as a latent code as inputs, and generates a 2D
spatial affine transform defining the translation and scaling of the object
patch. The learned parameters are further fed into a differentiable spatial
transformer network to transform the object patch into the target image, where
our model is trained adversarially using an affine transform discriminator and
a layout discriminator. We evaluate our network, coined SAC-GAN for
structure-aware composition, on prominent self-driving datasets in terms of
quality, composability, and generalizability of the composite images.
Comparisons are made to state-of-the-art alternatives, confirming superiority
of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reconstructing Compact Building Models from Point Clouds Using Deep Implicit Fields. (arXiv:2112.13142v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.13142">
<div class="article-summary-box-inner">
<span><p>Three-dimensional (3D) building models play an increasingly pivotal role in
many real-world applications while obtaining a compact representation of
buildings remains an open problem. In this paper, we present a novel framework
for reconstructing compact, watertight, polygonal building models from point
clouds. Our framework comprises three components: (a) a cell complex is
generated via adaptive space partitioning that provides a polyhedral embedding
as the candidate set; (b) an implicit field is learned by a deep neural network
that facilitates building occupancy estimation; (c) a Markov random field is
formulated to extract the outer surface of a building via combinatorial
optimization. We evaluate and compare our method with state-of-the-art methods
in shape reconstruction, surface approximation, and geometry simplification.
Experiments on both synthetic and real-world point clouds have demonstrated
that, with our neural-guided strategy, high-quality building models can be
obtained with significant advantages in fidelity, compactness, and
computational efficiency. Our method shows robustness to noise and insufficient
measurements, and it can directly generalize from synthetic scans to real-world
measurements. The source code of this work is freely available at
https://github.com/chenzhaiyu/points2poly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">D-Former: A U-shaped Dilated Transformer for 3D Medical Image Segmentation. (arXiv:2201.00462v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.00462">
<div class="article-summary-box-inner">
<span><p>Computer-aided medical image segmentation has been applied widely in
diagnosis and treatment to obtain clinically useful information of shapes and
volumes of target organs and tissues. In the past several years, convolutional
neural network (CNN) based methods (e.g., U-Net) have dominated this area, but
still suffered from inadequate long-range information capturing. Hence, recent
work presented computer vision Transformer variants for medical image
segmentation tasks and obtained promising performances. Such Transformers model
long-range dependency by computing pair-wise patch relations. However, they
incur prohibitive computational costs, especially on 3D medical images (e.g.,
CT and MRI). In this paper, we propose a new method called Dilated Transformer,
which conducts self-attention for pair-wise patch relations captured
alternately in local and global scopes. Inspired by dilated convolution
kernels, we conduct the global self-attention in a dilated manner, enlarging
receptive fields without increasing the patches involved and thus reducing
computational costs. Based on this design of Dilated Transformer, we construct
a U-shaped encoder-decoder hierarchical architecture called D-Former for 3D
medical image segmentation. Experiments on the Synapse and ACDC datasets show
that our D-Former model, trained from scratch, outperforms various competitive
CNN-based or Transformer-based segmentation models at a low computational cost
without time-consuming per-training process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAT-CADNet: Graph Attention Network for Panoptic Symbol Spotting in CAD Drawings. (arXiv:2201.00625v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.00625">
<div class="article-summary-box-inner">
<span><p>Spotting graphical symbols from the computer-aided design (CAD) drawings is
essential to many industrial applications. Different from raster images, CAD
drawings are vector graphics consisting of geometric primitives such as
segments, arcs, and circles. By treating each CAD drawing as a graph, we
propose a novel graph attention network GAT-CADNet to solve the panoptic symbol
spotting problem: vertex features derived from the GAT branch are mapped to
semantic labels, while their attention scores are cascaded and mapped to
instance prediction. Our key contributions are three-fold: 1) the instance
symbol spotting task is formulated as a subgraph detection problem and solved
by predicting the adjacency matrix; 2) a relative spatial encoding (RSE) module
explicitly encodes the relative positional and geometric relation among
vertices to enhance the vertex attention; 3) a cascaded edge encoding (CEE)
module extracts vertex attentions from multiple stages of GAT and treats them
as edge encoding to predict the adjacency matrix. The proposed GAT-CADNet is
intuitive yet effective and manages to solve the panoptic symbol spotting
problem in one consolidated network. Extensive experiments and ablation studies
on the public benchmark show that our graph-based approach surpasses existing
state-of-the-art methods by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HWRCNet: Handwritten Word Recognition in JPEG Compressed Domain using CNN-BiLSTM Network. (arXiv:2201.00947v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.00947">
<div class="article-summary-box-inner">
<span><p>The handwritten word recognition from images using deep learning is an active
research area with promising performance. It practical scenario, it might be
required to process the handwritten images in the compressed domain due to due
to security reasons. However, the utilization of deep learning is still very
limited for the processing of compressed images. Motivated by the need of
processing document images in the compressed domain using recent developments
in deep learning, we propose a HWRCNet model for handwritten word recognition
in JPEG compressed domain. The proposed model combines the Convolutional Neural
Network (CNN) and Bi-Directional Long Short Term Memory (BiLSTM) based
Recurrent Neural Network (RNN). Basically, we train the model using compressed
domain images and observe a very appealing performance with 89.05% word
recognition accuracy and 13.37% character error rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Transformer-Based Siamese Network for Change Detection. (arXiv:2201.01293v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01293">
<div class="article-summary-box-inner">
<span><p>This paper presents a transformer-based Siamese network architecture
(abbreviated by ChangeFormer) for Change Detection (CD) from a pair of
co-registered remote sensing images. Different from recent CD frameworks, which
are based on fully convolutional networks (ConvNets), the proposed method
unifies hierarchically structured transformer encoder with Multi-Layer
Perception (MLP) decoder in a Siamese network architecture to efficiently
render multi-scale long-range details required for accurate CD. Experiments on
two CD datasets show that the proposed end-to-end trainable ChangeFormer
architecture achieves better CD performance than previous counterparts. Our
code is available at https://github.com/wgcban/ChangeFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linear Variational State Space Filtering. (arXiv:2201.01353v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01353">
<div class="article-summary-box-inner">
<span><p>We introduce Variational State-Space Filters (VSSF), a new method for
unsupervised learning, identification, and filtering of latent Markov state
space models from raw pixels. We present a theoretically sound framework for
latent state space inference under heterogeneous sensor configurations. The
resulting model can integrate an arbitrary subset of the sensor measurements
used during training, enabling the learning of semi-supervised state
representations, thus enforcing that certain components of the learned latent
state space to agree with interpretable measurements. From this framework we
derive L-VSSF, an explicit instantiation of this model with linear latent
dynamics and Gaussian distribution parameterizations. We experimentally
demonstrate L-VSSF's ability to filter in latent space beyond the sequence
length of the training dataset across several different test environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aerial Scene Parsing: From Tile-level Scene Classification to Pixel-wise Semantic Labeling. (arXiv:2201.01953v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01953">
<div class="article-summary-box-inner">
<span><p>Given an aerial image, aerial scene parsing (ASP) targets to interpret the
semantic structure of the image content, e.g., by assigning a semantic label to
every pixel of the image. With the popularization of data-driven methods, the
past decades have witnessed promising progress on ASP by approaching the
problem with the schemes of tile-level scene classification or
segmentation-based image analysis, when using high-resolution aerial images.
However, the former scheme often produces results with tile-wise boundaries,
while the latter one needs to handle the complex modeling process from pixels
to semantics, which often requires large-scale and well-annotated image samples
with pixel-wise semantic labels. In this paper, we address these issues in ASP,
with perspectives from tile-level scene classification to pixel-wise semantic
labeling. Specifically, we first revisit aerial image interpretation by a
literature review. We then present a large-scale scene classification dataset
that contains one million aerial images termed Million-AID. With the presented
dataset, we also report benchmarking experiments using classical convolutional
neural networks (CNNs). Finally, we perform ASP by unifying the tile-level
scene classification and object-based image analysis to achieve pixel-wise
semantic labeling. Intensive experiments show that Million-AID is a challenging
yet useful dataset, which can serve as a benchmark for evaluating newly
developed algorithms. When transferring knowledge from Million-AID, fine-tuning
CNN models pretrained on Million-AID perform consistently better than those
pretrained ImageNet for aerial scene classification. Moreover, our designed
hierarchical multi-task learning method achieves the state-of-the-art
pixel-wise classification on the challenging GID, bridging the tile-level scene
classification toward pixel-wise semantic labeling for aerial image
interpretation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effect of Prior-based Losses on Segmentation Performance: A Benchmark. (arXiv:2201.02428v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02428">
<div class="article-summary-box-inner">
<span><p>Today, deep convolutional neural networks (CNNs) have demonstrated
state-of-the-art performance for medical image segmentation, on various imaging
modalities and tasks. Despite early success, segmentation networks may still
generate anatomically aberrant segmentations, with holes or inaccuracies near
the object boundaries. To enforce anatomical plausibility, recent research
studies have focused on incorporating prior knowledge such as object shape or
boundary, as constraints in the loss function. Prior integrated could be
low-level referring to reformulated representations extracted from the
ground-truth segmentations, or high-level representing external medical
information such as the organ's shape or size. Over the past few years,
prior-based losses exhibited a rising interest in the research field since they
allow integration of expert knowledge while still being architecture-agnostic.
However, given the diversity of prior-based losses on different medical imaging
challenges and tasks, it has become hard to identify what loss works best for
which dataset. In this paper, we establish a benchmark of recent prior-based
losses for medical image segmentation. The main objective is to provide
intuition onto which losses to choose given a particular task or dataset. To
this end, four low-level and high-level prior-based losses are selected. The
considered losses are validated on 8 different datasets from a variety of
medical image segmentation challenges including the Decathlon, the ISLES and
the WMH challenge. Results show that whereas low-level prior-based losses can
guarantee an increase in performance over the Dice loss baseline regardless of
the dataset characteristics, high-level prior-based losses can increase
anatomical plausibility as per data characteristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Summarization Based on Video-text Modelling. (arXiv:2201.02494v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02494">
<div class="article-summary-box-inner">
<span><p>Modern video summarization methods are based on deep neural networks which
require a large amount of annotated data for training. However, existing
datasets for video summarization are small-scale, easily leading to
over-fitting of the deep models. Considering that the annotation of large-scale
datasets is time-consuming, we propose a multimodal self-supervised learning
framework to obtain semantic representations of videos, which benefits the
video summarization task. Specifically, we explore the semantic consistency
between the visual information and text information of videos, for the
self-supervised pretraining of a multimodal encoder on a newly-collected
dataset of video-text pairs. Additionally, we introduce a progressive video
summarization method, where the important content in a video is pinpointed
progressively to generate better summaries. Finally, an objective evaluation
framework is proposed to measure the quality of video summaries based on video
classification. Extensive experiments have proved the effectiveness and
superiority of our method in rank correlation coefficients, F-score, and the
proposed objective evaluation compared to the state of the art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Incremental Learning Driven Instance Segmentation Framework to Recognize Highly Cluttered Instances of the Contraband Items. (arXiv:2201.02560v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02560">
<div class="article-summary-box-inner">
<span><p>Screening cluttered and occluded contraband items from baggage X-ray scans is
a cumbersome task even for the expert security staff. This paper presents a
novel strategy that extends a conventional encoder-decoder architecture to
perform instance-aware segmentation and extract merged instances of contraband
items without using any additional sub-network or an object detector. The
encoder-decoder network first performs conventional semantic segmentation and
retrieves cluttered baggage items. The model then incrementally evolves during
training to recognize individual instances using significantly reduced training
batches. To avoid catastrophic forgetting, a novel objective function minimizes
the network loss in each iteration by retaining the previously acquired
knowledge while learning new class representations and resolving their complex
structural inter-dependencies through Bayesian inference. A thorough evaluation
of our framework on two publicly available X-ray datasets shows that it
outperforms state-of-the-art methods, especially within the challenging
cluttered scenarios, while achieving an optimal trade-off between detection
accuracy and efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Twenty-thousand Classes using Image-level Supervision. (arXiv:2201.02605v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02605">
<div class="article-summary-box-inner">
<span><p>Current object detectors are limited in vocabulary size due to the small
scale of detection datasets. Image classifiers, on the other hand, reason about
much larger vocabularies, as their datasets are larger and easier to collect.
We propose Detic, which simply trains the classifiers of a detector on image
classification data and thus expands the vocabulary of detectors to tens of
thousands of concepts. Unlike prior work, Detic does not assign image labels to
boxes based on model predictions, making it much easier to implement and
compatible with a range of detection architectures and backbones. Our results
show that Detic yields excellent detectors even for classes without box
annotations. It outperforms prior work on both open-vocabulary and long-tail
detection benchmarks. Detic provides a gain of 2.4 mAP for all classes and 8.3
mAP for novel classes on the open-vocabulary LVIS benchmark. On the standard
LVIS benchmark, Detic reaches 41.7 mAP for all classes and 41.7 mAP for rare
classes. For the first time, we train a detector with all the
twenty-one-thousand classes of the ImageNet dataset and show that it
generalizes to new datasets without fine-tuning. Code is available at
https://github.com/facebookresearch/Detic.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-01-11 23:08:29.055833264 UTC">2022-01-11 23:08:29 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>