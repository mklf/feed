<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-10T01:30:00Z">09-10</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Powering Comparative Classification with Sentiment Analysis via Domain Adaptive Knowledge Transfer. (arXiv:2109.03819v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03819">
<div class="article-summary-box-inner">
<span><p>We study Comparative Preference Classification (CPC) which aims at predicting
whether a preference comparison exists between two entities in a given sentence
and, if so, which entity is preferred over the other. High-quality CPC models
can significantly benefit applications such as comparative question answering
and review-based recommendations. Among the existing approaches, non-deep
learning methods suffer from inferior performances. The state-of-the-art graph
neural network-based ED-GAT (Ma et al., 2020) only considers syntactic
information while ignoring the critical semantic relations and the sentiments
to the compared entities. We proposed sentiment Analysis Enhanced COmparative
Network (SAECON) which improves CPC ac-curacy with a sentiment analyzer that
learns sentiments to individual entities via domain adaptive knowledge
transfer. Experiments on the CompSent-19 (Panchenko et al., 2019) dataset
present a significant improvement on the F1 scores over the best existing CPC
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge mining of unstructured information: application to cyber-domain. (arXiv:2109.03848v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03848">
<div class="article-summary-box-inner">
<span><p>Cyber intelligence is widely and abundantly available in numerous open online
sources with reports on vulnerabilities and incidents. This constant stream of
noisy information requires new tools and techniques if it is to be used for the
benefit of analysts and investigators in various organizations. In this paper
we present and implement a novel knowledge graph and knowledge mining framework
for extracting relevant information from free-form text about incidents in the
cyber domain. Our framework includes a machine learning based pipeline as well
as crawling methods for generating graphs of entities, attackers and the
related information with our non-technical cyber ontology. We test our
framework on publicly available cyber incident datasets to evaluate the
accuracy of our knowledge mining methods as well as the usefulness of the
framework in the use of cyber analysts. Our results show analyzing the
knowledge graph constructed using the novel framework, an analyst can infer
additional information from the current cyber landscape in terms of risk to
various entities and the propagation of risk between industries and countries.
Expanding the framework to accommodate more technical and operational level
information can increase the accuracy and explainability of trends and risk in
the knowledge graph.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Bayesian Framework for Information-Theoretic Probing. (arXiv:2109.03853v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03853">
<div class="article-summary-box-inner">
<span><p>Pimentel et al. (2020) recently analysed probing from an
information-theoretic perspective. They argue that probing should be seen as
approximating a mutual information. This led to the rather unintuitive
conclusion that representations encode exactly the same information about a
target task as the original sentences. The mutual information, however, assumes
the true probability distribution of a pair of random variables is known,
leading to unintuitive results in settings where it is not. This paper proposes
a new framework to measure what we term Bayesian mutual information, which
analyses information from the perspective of Bayesian agents -- allowing for
more intuitive findings in scenarios with finite data. For instance, under
Bayesian MI we have that data can add information, processing can help, and
information can hurt, which makes it more intuitive for machine learning
applications. Finally, we apply our framework to probing where we believe
Bayesian mutual information naturally operationalises ease of extraction by
explicitly limiting the available background knowledge to solve a task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collecting a Large-Scale Gender Bias Dataset for Coreference Resolution and Machine Translation. (arXiv:2109.03858v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03858">
<div class="article-summary-box-inner">
<span><p>Recent works have found evidence of gender bias in models of machine
translation and coreference resolution using mostly synthetic diagnostic
datasets. While these quantify bias in a controlled experiment, they often do
so on a small scale and consist mostly of artificial, out-of-distribution
sentences. In this work, we find grammatical patterns indicating stereotypical
and non-stereotypical gender-role assignments (e.g., female nurses versus male
dancers) in corpora from three domains, resulting in a first large-scale gender
bias dataset of 108K diverse real-world English sentences. We manually verify
the quality of our corpus and use it to evaluate gender bias in various
coreference resolution and machine translation models. We find that all tested
models tend to over-rely on gender stereotypes when presented with natural
inputs, which may be especially harmful when deployed in commercial systems.
Finally, we show that our dataset lends itself to finetuning a coreference
resolution model, finding it mitigates bias on a held out set. Our dataset and
models are publicly available at www.github.com/SLAB-NLP/BUG. We hope they will
spur future research into gender bias evaluation mitigation techniques in
realistic settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparsity and Sentence Structure in Encoder-Decoder Attention of Summarization Systems. (arXiv:2109.03888v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03888">
<div class="article-summary-box-inner">
<span><p>Transformer models have achieved state-of-the-art results in a wide range of
NLP tasks including summarization. Training and inference using large
transformer models can be computationally expensive. Previous work has focused
on one important bottleneck, the quadratic self-attention mechanism in the
encoder. Modified encoder architectures such as LED or LoBART use local
attention patterns to address this problem for summarization. In contrast, this
work focuses on the transformer's encoder-decoder attention mechanism. The cost
of this attention becomes more significant in inference or training approaches
that require model-generated histories. First, we examine the complexity of the
encoder-decoder attention. We demonstrate empirically that there is a sparse
sentence structure in document summarization that can be exploited by
constraining the attention mechanism to a subset of input sentences, whilst
maintaining system performance. Second, we propose a modified architecture that
selects the subset of sentences to constrain the encoder-decoder attention.
Experiments are carried out on abstractive summarization tasks, including
CNN/DailyMail, XSum, Spotify Podcast, and arXiv.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense in Text Generation Models. (arXiv:2109.03892v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03892">
<div class="article-summary-box-inner">
<span><p>We investigate the use of multimodal information contained in images as an
effective method for enhancing the commonsense of Transformer models for text
generation. We perform experiments using BART and T5 on concept-to-text
generation, specifically the task of generative commonsense reasoning, or
CommonGen. We call our approach VisCTG: Visually Grounded Concept-to-Text
Generation. VisCTG involves captioning images representing appropriate everyday
scenarios, and using these captions to enrich and steer the generation process.
Comprehensive evaluation and analysis demonstrate that VisCTG noticeably
improves model performance while successfully addressing several issues of the
baseline generations, including poor commonsense, fluency, and specificity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ELIT: Emory Language and Information Toolkit. (arXiv:2109.03903v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03903">
<div class="article-summary-box-inner">
<span><p>We introduce ELIT, the Emory Language and Information Toolkit, which is a
comprehensive NLP framework providing transformer-based end-to-end models for
core tasks with a special focus on memory efficiency while maintaining
state-of-the-art accuracy and speed. Compared to existing toolkits, ELIT
features an efficient Multi-Task Learning (MTL) model with many downstream
tasks that include lemmatization, part-of-speech tagging, named entity
recognition, dependency parsing, constituency parsing, semantic role labeling,
and AMR parsing. The backbone of ELIT's MTL framework is a pre-trained
transformer encoder that is shared across tasks to speed up their inference.
ELIT provides pre-trained models developed on a remix of eight datasets. To
scale up its service, ELIT also integrates a RESTful Client/Server combination.
On the server side, ELIT extends its functionality to cover other tasks such as
tokenization and coreference resolution, providing an end user with agile
research experience. All resources including the source codes, documentation,
and pre-trained models are publicly available at
https://github.com/emorynlp/elit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Recipe For Arbitrary Text Style Transfer with Large Language Models. (arXiv:2109.03910v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03910">
<div class="article-summary-box-inner">
<span><p>In this paper, we leverage large language models (LMs) to perform zero-shot
text style transfer. We present a prompting method that we call augmented
zero-shot learning, which frames style transfer as a sentence rewriting task
and requires only a natural language instruction, without model fine-tuning or
exemplars in the target style. Augmented zero-shot learning is simple and
demonstrates promising results not just on standard style transfer tasks such
as sentiment, but also on arbitrary transformations such as "make this
melodramatic" or "insert a metaphor."
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ensemble Fine-tuned mBERT for Translation Quality Estimation. (arXiv:2109.03914v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03914">
<div class="article-summary-box-inner">
<span><p>Quality Estimation (QE) is an important component of the machine translation
workflow as it assesses the quality of the translated output without consulting
reference translations. In this paper, we discuss our submission to the WMT
2021 QE Shared Task. We participate in Task 2 sentence-level sub-task that
challenge participants to predict the HTER score for sentence-level
post-editing effort. Our proposed system is an ensemble of multilingual BERT
(mBERT)-based regression models, which are generated by fine-tuning on
different input settings. It demonstrates comparable performance with respect
to the Pearson's correlation and beats the baseline system in MAE/ RMSE for
several language pairs. In addition, we adapt our system for the zero-shot
setting by exploiting target language-relevant language pairs and
pseudo-reference translations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers in the loop: Polarity in neural models of language. (arXiv:2109.03926v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03926">
<div class="article-summary-box-inner">
<span><p>Representation of linguistic phenomena in computational language models is
typically assessed against the predictions of existing linguistic theories of
these phenomena. Using the notion of polarity as a case study, we show that
this is not always the most adequate set-up. We probe polarity via so-called
'negative polarity items' (in particular, English 'any') in two pre-trained
Transformer-based models (BERT and GPT-2). We show that -- at least for
polarity -- metrics derived from language models are more consistent with data
from psycholinguistic experiments than linguistic theory predictions.
Establishing this allows us to more adequately evaluate the performance of
language models and also to use language models to discover new insights into
natural language grammar beyond existing linguistic theories. Overall, our
results encourage a closer tie between experiments with human subjects and with
language models. We propose methods to enable this closer tie, with language
models as part of experimental pipeline, and show this pipeline at work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What's Hidden in a One-layer Randomly Weighted Transformer?. (arXiv:2109.03939v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03939">
<div class="article-summary-box-inner">
<span><p>We demonstrate that, hidden within one-layer randomly weighted neural
networks, there exist subnetworks that can achieve impressive performance,
without ever modifying the weight initializations, on machine translation
tasks. To find subnetworks for one-layer randomly weighted neural networks, we
apply different binary masks to the same weight matrix to generate different
layers. Hidden within a one-layer randomly weighted Transformer, we find that
subnetworks that can achieve 29.45/17.29 BLEU on IWSLT14/WMT14. Using a fixed
pre-trained embedding layer, the previously found subnetworks are smaller than,
but can match 98%/92% (34.14/25.24 BLEU) of the performance of, a trained
Transformer small/base on IWSLT14/WMT14. Furthermore, we demonstrate the
effectiveness of larger and deeper transformers in this setting, as well as the
impact of different initialization methods. We released the source code at
https://github.com/sIncerass/one_layer_lottery_ticket.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Pre-training with Structured Knowledge for Improving Natural Language Inference. (arXiv:2109.03941v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03941">
<div class="article-summary-box-inner">
<span><p>While recent research on natural language inference has considerably
benefited from large annotated datasets, the amount of inference-related
knowledge (including commonsense) provided in the annotated data is still
rather limited. There have been two lines of approaches that can be used to
further address the limitation: (1) unsupervised pretraining can leverage
knowledge in much larger unstructured text data; (2) structured (often
human-curated) knowledge has started to be considered in neural-network-based
models for NLI. An immediate question is whether these two approaches
complement each other, or how to develop models that can bring together their
advantages. In this paper, we propose models that leverage structured knowledge
in different components of pre-trained models. Our results show that the
proposed models perform better than previous BERT-based state-of-the-art
models. Although our models are proposed for NLI, they can be easily extended
to other sentence or sentence-pair classification problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Formal Description of Sorani Kurdish Morphology. (arXiv:2109.03942v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03942">
<div class="article-summary-box-inner">
<span><p>Sorani Kurdish, also known as Central Kurdish, has a complex morphology,
particularly due to the patterns in which morphemes appear. Although several
aspects of Kurdish morphology have been studied, such as pronominal endoclitics
and Izafa constructions, Sorani Kurdish morphology has received trivial
attention in computational linguistics. Moreover, some morphemes, such as the
emphasis endoclitic =\^i\c{s}, and derivational morphemes have not been
previously studied. To tackle the complex morphology of Sorani, we provide a
thorough description of Sorani Kurdish morphological and morphophonological
constructions in a formal way such that they can be used as finite-state
transducers for morphological analysis and synthesis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Speech Recognition for Low-Resource Indian Languages using Multi-Task conformer. (arXiv:2109.03969v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03969">
<div class="article-summary-box-inner">
<span><p>Transformers have recently become very popular for sequence-to-sequence
applications such as machine translation and speech recognition. In this work,
we propose a multi-task learning-based transformer model for low-resource
multilingual speech recognition for Indian languages. Our proposed model
consists of a conformer [1] encoder and two parallel transformer decoders. We
use a phoneme decoder (PHN-DEC) for the phoneme recognition task and a grapheme
decoder (GRP-DEC) to predict grapheme sequence. We consider the phoneme
recognition task as an auxiliary task for our multi-task learning framework. We
jointly optimize the network for both phoneme and grapheme recognition tasks
using Joint CTC-Attention [2] training. We use a conditional decoding scheme to
inject the language information into the model before predicting the grapheme
sequence. Our experiments show that our proposed approach can obtain
significant improvement over previous approaches [4]. We also show that our
conformer-based dual-decoder approach outperforms both the transformer-based
dual-decoder approach and single decoder approach. Finally, We compare
monolingual ASR models with our proposed multilingual ASR approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Competence-based Curriculum Learning for Multilingual Machine Translation. (arXiv:2109.04002v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04002">
<div class="article-summary-box-inner">
<span><p>Currently, multilingual machine translation is receiving more and more
attention since it brings better performance for low resource languages (LRLs)
and saves more space. However, existing multilingual machine translation models
face a severe challenge: imbalance. As a result, the translation performance of
different languages in multilingual translation models are quite different. We
argue that this imbalance problem stems from the different learning
competencies of different languages. Therefore, we focus on balancing the
learning competencies of different languages and propose Competence-based
Curriculum Learning for Multilingual Machine Translation, named CCL-M.
Specifically, we firstly define two competencies to help schedule the high
resource languages (HRLs) and the low resource languages: 1) Self-evaluated
Competence, evaluating how well the language itself has been learned; and 2)
HRLs-evaluated Competence, evaluating whether an LRL is ready to be learned
according to HRLs' Self-evaluated Competence. Based on the above competencies,
we utilize the proposed CCL-M algorithm to gradually add new languages into the
training set in a curriculum learning manner. Furthermore, we propose a novel
competenceaware dynamic balancing sampling strategy for better selecting
training samples in multilingual training. Experimental results show that our
approach has achieved a steady and significant performance gain compared to the
previous state-of-the-art approach on the TED talks dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Based Network with Contextualized Representations of Turns in Dialogue. (arXiv:2109.04008v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04008">
<div class="article-summary-box-inner">
<span><p>Dialogue-based relation extraction (RE) aims to extract relation(s) between
two arguments that appear in a dialogue. Because dialogues have the
characteristics of high personal pronoun occurrences and low information
density, and since most relational facts in dialogues are not supported by any
single sentence, dialogue-based relation extraction requires a comprehensive
understanding of dialogue. In this paper, we propose the TUrn COntext awaRE
Graph Convolutional Network (TUCORE-GCN) modeled by paying attention to the way
people understand dialogues. In addition, we propose a novel approach which
treats the task of emotion recognition in conversations (ERC) as a
dialogue-based RE. Experiments on a dialogue-based RE dataset and three ERC
datasets demonstrate that our model is very effective in various dialogue-based
natural language understanding tasks. In these experiments, TUCORE-GCN
outperforms the state-of-the-art models on most of the benchmark datasets. Our
code is available at https://github.com/BlackNoodle/TUCORE-GCN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly-Supervised Visual-Retriever-Reader for Knowledge-based Question Answering. (arXiv:2109.04014v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04014">
<div class="article-summary-box-inner">
<span><p>Knowledge-based visual question answering (VQA) requires answering questions
with external knowledge in addition to the content of images. One dataset that
is mostly used in evaluating knowledge-based VQA is OK-VQA, but it lacks a gold
standard knowledge corpus for retrieval. Existing work leverage different
knowledge bases (e.g., ConceptNet and Wikipedia) to obtain external knowledge.
Because of varying knowledge bases, it is hard to fairly compare models'
performance. To address this issue, we collect a natural language knowledge
base that can be used for any VQA system. Moreover, we propose a Visual
Retriever-Reader pipeline to approach knowledge-based VQA. The visual retriever
aims to retrieve relevant knowledge, and the visual reader seeks to predict
answers based on given knowledge. We introduce various ways to retrieve
knowledge using text and images and two reader styles: classification and
extraction. Both the retriever and reader are trained with weak supervision.
Our experimental results show that a good retriever can significantly improve
the reader's performance on the OK-VQA challenge. The code and corpus are
provided in https://github.com/luomancs/retriever\_reader\_for\_okvqa.git
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graphine: A Dataset for Graph-aware Terminology Definition Generation. (arXiv:2109.04018v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04018">
<div class="article-summary-box-inner">
<span><p>Precisely defining the terminology is the first step in scientific
communication. Developing neural text generation models for definition
generation can circumvent the labor-intensity curation, further accelerating
scientific discovery. Unfortunately, the lack of large-scale terminology
definition dataset hinders the process toward definition generation. In this
paper, we present a large-scale terminology definition dataset Graphine
covering 2,010,648 terminology definition pairs, spanning 227 biomedical
subdisciplines. Terminologies in each subdiscipline further form a directed
acyclic graph, opening up new avenues for developing graph-aware text
generation models. We then proposed a novel graph-aware definition generation
model Graphex that integrates transformer with graph neural network. Our model
outperforms existing text generation models by exploiting the graph structure
of terminologies. We further demonstrated how Graphine can be used to evaluate
pretrained language models, compare graph representation learning methods and
predict sentence granularity. We envision Graphine to be a unique resource for
definition generation and many other NLP tasks in biomedicine.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distributionally Robust Multilingual Machine Translation. (arXiv:2109.04020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04020">
<div class="article-summary-box-inner">
<span><p>Multilingual neural machine translation (MNMT) learns to translate multiple
language pairs with a single model, potentially improving both the accuracy and
the memory-efficiency of deployed models. However, the heavy data imbalance
between languages hinders the model from performing uniformly across language
pairs. In this paper, we propose a new learning objective for MNMT based on
distributionally robust optimization, which minimizes the worst-case expected
loss over the set of language pairs. We further show how to practically
optimize this objective for large translation corpora using an iterated best
response scheme, which is both effective and incurs negligible additional
computational cost compared to standard empirical risk minimization. We perform
extensive experiments on three sets of languages from two datasets and show
that our method consistently outperforms strong baseline methods in terms of
average and per-language performance under both many-to-one and one-to-many
translation settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Table-based Fact Verification with Salience-aware Learning. (arXiv:2109.04053v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04053">
<div class="article-summary-box-inner">
<span><p>Tables provide valuable knowledge that can be used to verify textual
statements. While a number of works have considered table-based fact
verification, direct alignments of tabular data with tokens in textual
statements are rarely available. Moreover, training a generalized fact
verification model requires abundant labeled training data. In this paper, we
propose a novel system to address these problems. Inspired by counterfactual
causality, our system identifies token-level salience in the statement with
probing-based salience estimation. Salience estimation allows enhanced learning
of fact verification from two perspectives. From one perspective, our system
conducts masked salient token prediction to enhance the model for alignment and
reasoning between the table and the statement. From the other perspective, our
system applies salience-aware data augmentation to generate a more diverse set
of training instances by replacing non-salient terms. Experimental results on
TabFact show the effective improvement by the proposed salience-aware learning
techniques, leading to the new SOTA performance on the benchmark. Our code is
publicly available at https://github.com/luka-group/Salience-aware-Learning .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhanced Speaker-aware Multi-party Multi-turn Dialogue Comprehension. (arXiv:2109.04066v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04066">
<div class="article-summary-box-inner">
<span><p>Multi-party multi-turn dialogue comprehension brings unprecedented challenges
on handling the complicated scenarios from multiple speakers and criss-crossed
discourse relationship among speaker-aware utterances. Most existing methods
deal with dialogue contexts as plain texts and pay insufficient attention to
the crucial speaker-aware clues. In this work, we propose an enhanced
speaker-aware model with masking attention and heterogeneous graph networks to
comprehensively capture discourse clues from both sides of speaker property and
speaker-aware relationships. With such comprehensive speaker-aware modeling,
experimental results show that our speaker-aware model helps achieves
state-of-the-art performance on the benchmark dataset Molweni. Case analysis
shows that our model enhances the connections between utterances and their own
speakers and captures the speaker-aware discourse relations, which are critical
for dialogue modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Resource Dialogue Summarization with Domain-Agnostic Multi-Source Pretraining. (arXiv:2109.04080v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04080">
<div class="article-summary-box-inner">
<span><p>With the rapid increase in the volume of dialogue data from daily life, there
is a growing demand for dialogue summarization. Unfortunately, training a large
summarization model is generally infeasible due to the inadequacy of dialogue
data with annotated summaries. Most existing works for low-resource dialogue
summarization directly pretrain models in other domains, e.g., the news domain,
but they generally neglect the huge difference between dialogues and
conventional articles. To bridge the gap between out-of-domain pretraining and
in-domain fine-tuning, in this work, we propose a multi-source pretraining
paradigm to better leverage the external summary data. Specifically, we exploit
large-scale in-domain non-summary data to separately pretrain the dialogue
encoder and the summary decoder. The combined encoder-decoder model is then
pretrained on the out-of-domain summary data using adversarial critics, aiming
to facilitate domain-agnostic summarization. The experimental results on two
public datasets show that with only limited training data, our approach
achieves competitive performance and generalizes well in different dialogue
scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thinking Clearly, Talking Fast: Concept-Guided Non-Autoregressive Generation for Open-Domain Dialogue Systems. (arXiv:2109.04084v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04084">
<div class="article-summary-box-inner">
<span><p>Human dialogue contains evolving concepts, and speakers naturally associate
multiple concepts to compose a response. However, current dialogue models with
the seq2seq framework lack the ability to effectively manage concept
transitions and can hardly introduce multiple concepts to responses in a
sequential decoding manner. To facilitate a controllable and coherent dialogue,
in this work, we devise a concept-guided non-autoregressive model (CG-nAR) for
open-domain dialogue generation. The proposed model comprises a multi-concept
planning module that learns to identify multiple associated concepts from a
concept graph and a customized Insertion Transformer that performs
concept-guided non-autoregressive generation to complete a response. The
experimental results on two public datasets show that CG-nAR can produce
diverse and coherent responses, outperforming state-of-the-art baselines in
both automatic and human evaluations with substantially faster inference speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Debiasing Methods in Natural Language Understanding Make Bias More Accessible. (arXiv:2109.04095v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04095">
<div class="article-summary-box-inner">
<span><p>Model robustness to bias is often determined by the generalization on
carefully designed out-of-distribution datasets. Recent debiasing methods in
natural language understanding (NLU) improve performance on such datasets by
pressuring models into making unbiased predictions. An underlying assumption
behind such methods is that this also leads to the discovery of more robust
features in the model's inner representations. We propose a general
probing-based framework that allows for post-hoc interpretation of biases in
language models, and use an information-theoretic approach to measure the
extractability of certain biases from the model's representations. We
experiment with several NLU datasets and known biases, and show that,
counter-intuitively, the more a language model is pushed towards a debiased
regime, the more bias is actually encoded in its inner representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded Dialogue Generation. (arXiv:2109.04096v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04096">
<div class="article-summary-box-inner">
<span><p>Neural conversation models have shown great potentials towards generating
fluent and informative responses by introducing external background knowledge.
Nevertheless, it is laborious to construct such knowledge-grounded dialogues,
and existing models usually perform poorly when transfer to new domains with
limited training samples. Therefore, building a knowledge-grounded dialogue
system under the low-resource setting is a still crucial issue. In this paper,
we propose a novel three-stage learning framework based on weakly supervised
learning which benefits from large scale ungrounded dialogues and unstructured
knowledge base. To better cooperate with this framework, we devise a variant of
Transformer with decoupled decoder which facilitates the disentangled learning
of response generation and knowledge incorporation. Evaluation results on two
benchmarks indicate that our approach can outperform other state-of-the-art
methods with less training data, and even in zero-resource scenario, our
approach still performs well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ARMAN: Pre-training with Semantically Selecting and Reordering of Sentences for Persian Abstractive Summarization. (arXiv:2109.04098v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04098">
<div class="article-summary-box-inner">
<span><p>Abstractive text summarization is one of the areas influenced by the
emergence of pre-trained language models. Current pre-training works in
abstractive summarization give more points to the summaries with more words in
common with the main text and pay less attention to the semantic similarity
between generated sentences and the original document. We propose ARMAN, a
Transformer-based encoder-decoder model pre-trained with three novel objectives
to address this issue. In ARMAN, salient sentences from a document are selected
according to a modified semantic score to be masked and form a pseudo summary.
To summarize more accurately and similar to human writing patterns, we applied
modified sentence reordering. We evaluated our proposed models on six
downstream Persian summarization tasks. Experimental results show that our
proposed model achieves state-of-the-art performance on all six summarization
tasks measured by ROUGE and BERTScore. Our models also outperform prior works
in textual entailment, question paraphrasing, and multiple choice question
answering. Finally, we established a human evaluation and show that using the
semantic score significantly improves summarization results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TimeTraveler: Reinforcement Learning for Temporal Knowledge Graph Forecasting. (arXiv:2109.04101v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04101">
<div class="article-summary-box-inner">
<span><p>Temporal knowledge graph (TKG) reasoning is a crucial task that has gained
increasing research interest in recent years. Most existing methods focus on
reasoning at past timestamps to complete the missing facts, and there are only
a few works of reasoning on known TKGs to forecast future facts. Compared with
the completion task, the forecasting task is more difficult that faces two main
challenges: (1) how to effectively model the time information to handle future
timestamps? (2) how to make inductive inference to handle previously unseen
entities that emerge over time? To address these challenges, we propose the
first reinforcement learning method for forecasting. Specifically, the agent
travels on historical knowledge graph snapshots to search for the answer. Our
method defines a relative time encoding function to capture the timespan
information, and we design a novel time-shaped reward based on Dirichlet
distribution to guide the model learning. Furthermore, we propose a novel
representation method for unseen entities to improve the inductive inference
ability of the model. We evaluate our method for this link prediction task at
future timestamps. Extensive experiments on four benchmark datasets demonstrate
substantial performance improvement meanwhile with higher explainability, less
calculation, and fewer parameters when compared with existing state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MapRE: An Effective Semantic Mapping Approach for Low-resource Relation Extraction. (arXiv:2109.04108v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04108">
<div class="article-summary-box-inner">
<span><p>Neural relation extraction models have shown promising results in recent
years; however, the model performance drops dramatically given only a few
training samples. Recent works try leveraging the advance in few-shot learning
to solve the low resource problem, where they train label-agnostic models to
directly compare the semantic similarities among context sentences in the
embedding space. However, the label-aware information, i.e., the relation label
that contains the semantic knowledge of the relation itself, is often neglected
for prediction. In this work, we propose a framework considering both
label-agnostic and label-aware semantic mapping information for low resource
relation extraction. We show that incorporating the above two types of mapping
information in both pretraining and fine-tuning can significantly improve the
model performance on low-resource relation extraction tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fixing exposure bias with imitation learning needs powerful oracles. (arXiv:2109.04114v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04114">
<div class="article-summary-box-inner">
<span><p>We apply imitation learning (IL) to tackle the NMT exposure bias problem with
error-correcting oracles, and evaluate an SMT lattice-based oracle which,
despite its excellent performance in an unconstrained oracle translation task,
turned out to be too pruned and idiosyncratic to serve as the oracle for IL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Word-Level Coreference Resolution. (arXiv:2109.04127v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04127">
<div class="article-summary-box-inner">
<span><p>Recent coreference resolution models rely heavily on span representations to
find coreference links between word spans. As the number of spans is $O(n^2)$
in the length of text and the number of potential links is $O(n^4)$, various
pruning techniques are necessary to make this approach computationally
feasible. We propose instead to consider coreference links between individual
words rather than word spans and then reconstruct the word spans. This reduces
the complexity of the coreference model to $O(n^2)$ and allows it to consider
all potential mentions without pruning any of them out. We also demonstrate
that, with these changes, SpanBERT for coreference resolution will be
significantly outperformed by RoBERTa. While being highly efficient, our model
performs competitively with recent coreference resolution systems on the
OntoNotes benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fusing task-oriented and open-domain dialogues in conversational agents. (arXiv:2109.04137v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04137">
<div class="article-summary-box-inner">
<span><p>The goal of building intelligent dialogue systems has largely been
\textit{separately} pursued under two paradigms: task-oriented dialogue (TOD)
systems, which perform goal-oriented functions, and open-domain dialogue (ODD)
systems, which focus on non-goal-oriented chitchat. The two dialogue modes can
potentially be intertwined together seamlessly in the same conversation, as
easily done by a friendly human assistant. Such ability is desirable in
conversational agents, as the integration makes them more accessible and
useful. Our paper addresses this problem of fusing TODs and ODDs in multi-turn
dialogues. Based on the popular TOD dataset MultiWOZ, we build a new dataset
FusedChat, by rewriting the existing TOD turns and adding new ODD turns. This
procedure constructs conversation sessions containing exchanges from both
dialogue modes. It features inter-mode contextual dependency, i.e., the
dialogue turns from the two modes depend on each other. Rich dependency
patterns including co-reference and ellipsis are features. The new dataset,
with 60k new human-written ODD turns and 5k re-written TOD turns, offers a
benchmark to test a dialogue model's ability to perform inter-mode
conversations. This is a more challenging task since the model has to determine
the appropriate dialogue mode and generate the response based on the inter-mode
context. But such models would better mimic human-level conversation
capabilities. We evaluate baseline models on this task, including
\textit{classification-based} two-stage models and \textit{two-in-one} fused
models. We publicly release FusedChat and the baselines to propel future work
on inter-mode dialogue systems https://github.com/tomyoung903/FusedChat.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Avoiding Inference Heuristics in Few-shot Prompt-based Finetuning. (arXiv:2109.04144v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04144">
<div class="article-summary-box-inner">
<span><p>Recent prompt-based approaches allow pretrained language models to achieve
strong performances on few-shot finetuning by reformulating downstream tasks as
a language modeling problem. In this work, we demonstrate that, despite its
advantages on low data regimes, finetuned prompt-based models for sentence pair
classification tasks still suffer from a common pitfall of adopting inference
heuristics based on lexical overlap, e.g., models incorrectly assuming a
sentence pair is of the same meaning because they consist of the same set of
words. Interestingly, we find that this particular inference heuristic is
significantly less present in the zero-shot evaluation of the prompt-based
model, indicating how finetuning can be destructive to useful knowledge learned
during the pretraining. We then show that adding a regularization that
preserves pretraining weights is effective in mitigating this destructive
tendency of few-shot finetuning. Our evaluation on three datasets demonstrates
promising improvements on the three corresponding challenge datasets used to
diagnose the inference heuristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lexico-semantic and affective modelling of Spanish poetry: A semi-supervised learning approach. (arXiv:2109.04152v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04152">
<div class="article-summary-box-inner">
<span><p>Text classification tasks have improved substantially during the last years
by the usage of transformers. However, the majority of researches focus on
prose texts, with poetry receiving less attention, specially for Spanish
language. In this paper, we propose a semi-supervised learning approach for
inferring 21 psychological categories evoked by a corpus of 4572 sonnets, along
with 10 affective and lexico-semantic multiclass ones. The subset of poems used
for training an evaluation includes 270 sonnets. With our approach, we achieve
an AUC beyond 0.7 for 76% of the psychological categories, and an AUC over 0.65
for 60% on the multiclass ones. The sonnets are modelled using transformers,
through sentence embeddings, along with lexico-semantic and affective features,
obtained by using external lexicons. Consequently, we see that this approach
provides an AUC increase of up to 0.12, as opposed to using transformers alone.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Nearest Neighbor Language Models. (arXiv:2109.04212v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04212">
<div class="article-summary-box-inner">
<span><p>Non-parametric neural language models (NLMs) learn predictive distributions
of text utilizing an external datastore, which allows them to learn through
explicitly memorizing the training datapoints. While effective, these models
often require retrieval from a large datastore at test time, significantly
increasing the inference overhead and thus limiting the deployment of
non-parametric NLMs in practical applications. In this paper, we take the
recently proposed $k$-nearest neighbors language model (Khandelwal et al.,
2019) as an example, exploring methods to improve its efficiency along various
dimensions. Experiments on the standard WikiText-103 benchmark and
domain-adaptation datasets show that our methods are able to achieve up to a 6x
speed-up in inference speed while retaining comparable performance. The
empirical analysis we present may provide guidelines for future research
seeking to develop or deploy more efficient non-parametric NLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KELM: Knowledge Enhanced Pre-Trained Language Representations with Message Passing on Hierarchical Relational Graphs. (arXiv:2109.04223v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04223">
<div class="article-summary-box-inner">
<span><p>Incorporating factual knowledge into pre-trained language models (PLM) such
as BERT is an emerging trend in recent NLP studies. However, most of the
existing methods combine the external knowledge integration module with a
modified pre-training loss and re-implement the pre-training process on the
large-scale corpus. Re-pretraining these models is usually resource-consuming,
and difficult to adapt to another domain with a different knowledge graph (KG).
Besides, those works either cannot embed knowledge context dynamically
according to textual context or struggle with the knowledge ambiguity issue. In
this paper, we propose a novel knowledge-aware language model framework based
on fine-tuning process, which equips PLM with a unified knowledge-enhanced text
graph that contains both text and multi-relational sub-graphs extracted from
KG. We design a hierarchical relational-graph-based message passing mechanism,
which can allow the representations of injected KG and text to mutually update
each other and can dynamically select ambiguous mentioned entities that share
the same text. Our empirical results show that our model can efficiently
incorporate world knowledge from KGs into existing language models such as
BERT, and achieve significant improvement on the machine reading comprehension
(MRC) task compared with other knowledge-enhanced models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaXT: Meta Cross-Task Transfer between Disparate Label Spaces. (arXiv:2109.04240v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04240">
<div class="article-summary-box-inner">
<span><p>Albeit the universal representational power of pre-trained language models,
adapting them onto a specific NLP task still requires a considerably large
amount of labeled data. Effective task fine-tuning meets challenges when only a
few labeled examples are present for the task. In this paper, we aim to the
address of the problem of few shot task learning by exploiting and transferring
from a different task which admits a related but disparate label space.
Specifically, we devise a label transfer network (LTN) to transform the labels
from source task to the target task of interest for training. Both the LTN and
the model for task prediction are learned via a bi-level optimization
framework, which we term as MetaXT. MetaXT offers a principled solution to best
adapt a pre-trained language model to the target task by transferring knowledge
from the source task. Empirical evaluations on cross-task transfer settings for
four NLP tasks, from two different types of label space disparities,
demonstrate the effectiveness of MetaXT, especially when the labeled data in
the target task is limited.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cartography Active Learning. (arXiv:2109.04282v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04282">
<div class="article-summary-box-inner">
<span><p>We propose Cartography Active Learning (CAL), a novel Active Learning (AL)
algorithm that exploits the behavior of the model on individual instances
during training as a proxy to find the most informative instances for labeling.
CAL is inspired by data maps, which were recently proposed to derive insights
into dataset quality (Swayamdipta et al., 2020). We compare our method on
popular text classification tasks to commonly used AL strategies, which instead
rely on post-training behavior. We demonstrate that CAL is competitive to other
common AL methods, showing that training dynamics derived from small seed data
can be successfully used for AL. We provide insights into our new AL method by
analyzing batch-level statistics utilizing the data maps. Our results further
show that CAL results in a more data-efficient learning strategy, achieving
comparable or better results with considerably less training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalised Unsupervised Domain Adaptation of Neural Machine Translation with Cross-Lingual Data Selection. (arXiv:2109.04292v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04292">
<div class="article-summary-box-inner">
<span><p>This paper considers the unsupervised domain adaptation problem for neural
machine translation (NMT), where we assume the access to only monolingual text
in either the source or target language in the new domain. We propose a
cross-lingual data selection method to extract in-domain sentences in the
missing language side from a large generic monolingual corpus. Our proposed
method trains an adaptive layer on top of multilingual BERT by contrastive
learning to align the representation between the source and target language.
This then enables the transferability of the domain classifier between the
languages in a zero-shot manner. Once the in-domain data is detected by the
classifier, the NMT model is then adapted to the new domain by jointly learning
translation and domain discrimination tasks. We evaluate our cross-lingual data
selection method on NMT across five diverse domains in three language pairs, as
well as a real-world scenario of translation for COVID-19. The results show
that our proposed method outperforms other selection baselines up to +1.5 BLEU
score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MATE: Multi-view Attention for Table Transformer Efficiency. (arXiv:2109.04312v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04312">
<div class="article-summary-box-inner">
<span><p>This work presents a sparse-attention Transformer architecture for modeling
documents that contain large tables. Tables are ubiquitous on the web, and are
rich in information. However, more than 20% of relational tables on the web
have 20 or more rows (Cafarella et al., 2008), and these large tables present a
challenge for current Transformer models, which are typically limited to 512
tokens. Here we propose MATE, a novel Transformer architecture designed to
model the structure of web tables. MATE uses sparse attention in a way that
allows heads to efficiently attend to either rows or columns in a table. This
architecture scales linearly with respect to speed and memory, and can handle
documents containing more than 8000 tokens with current accelerators. MATE also
has a more appropriate inductive bias for tabular data, and sets a new
state-of-the-art for three table reasoning datasets. For HybridQA (Chen et al.,
2020b), a dataset that involves large documents containing tables, we improve
the best prior result by 19 points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variational Latent-State GPT for Semi-supervised Task-Oriented Dialog Systems. (arXiv:2109.04314v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04314">
<div class="article-summary-box-inner">
<span><p>Recently, two approaches, fine-tuning large pre-trained language models and
variational training, have attracted significant interests, separately, for
semi-supervised end-to-end task-oriented dialog (TOD) systems. In this paper,
we propose Variational Latent-State GPT model (VLS-GPT), which is the first to
combine the strengths of the two approaches. Among many options of models, we
propose the generative model and the inference model for variational learning
of the end-to-end TOD system, both as auto-regressive language models based on
GPT-2, which can be further trained over a mix of labeled and unlabeled dialog
data in a semi-supervised manner. We develop the strategy of
sampling-then-forward-computation, which successfully overcomes the memory
explosion issue of using GPT in variational learning and speeds up training.
Semi-supervised TOD experiments are conducted on two benchmark multi-domain
datasets of different languages - MultiWOZ2.1 and CrossWOZ. VLS-GPT is shown to
significantly outperform both supervised-only and semi-supervised baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translate & Fill: Improving Zero-Shot Multilingual Semantic Parsing with Synthetic Data. (arXiv:2109.04319v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04319">
<div class="article-summary-box-inner">
<span><p>While multilingual pretrained language models (LMs) fine-tuned on a single
language have shown substantial cross-lingual task transfer capabilities, there
is still a wide performance gap in semantic parsing tasks when target language
supervision is available. In this paper, we propose a novel Translate-and-Fill
(TaF) method to produce silver training data for a multilingual semantic
parser. This method simplifies the popular Translate-Align-Project (TAP)
pipeline and consists of a sequence-to-sequence filler model that constructs a
full parse conditioned on an utterance and a view of the same parse. Our filler
is trained on English data only but can accurately complete instances in other
languages (i.e., translations of the English training utterances), in a
zero-shot fashion. Experimental results on three multilingual semantic parsing
datasets show that data augmentation with TaF reaches accuracies competitive
with similar systems which rely on traditional alignment techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smoothed Contrastive Learning for Unsupervised Sentence Embedding. (arXiv:2109.04321v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04321">
<div class="article-summary-box-inner">
<span><p>Contrastive learning has been gradually applied to learn high-quality
unsupervised sentence embedding. Among the previous un-supervised methods, the
latest state-of-the-art method, as far as we know, is unsupervised SimCSE
(unsup-SimCSE). Unsup-SimCSE uses the InfoNCE1loss function in the training
stage by pulling semantically similar sentences together and pushing apart
dis-similar ones.Theoretically, we expect to use larger batches in unsup-SimCSE
to get more adequate comparisons among samples and avoid overfitting. However,
increasing the batch size does not always lead to improvements, but instead
even lead to performance degradation when the batch size exceeds a threshold.
Through statistical observation, we find that this is probably due to the
introduction of low-confidence negative pairs after in-creasing the batch size.
To alleviate this problem, we introduce a simple smoothing strategy upon the
InfoNCE loss function, termedGaussian Smoothing InfoNCE
(GS-InfoNCE).Specifically, we add random Gaussian noise vectors as negative
samples, which act asa smoothing of the negative sample space.Though being
simple, the proposed smooth-ing strategy brings substantial improvements to
unsup-SimCSE. We evaluate GS-InfoNCEon the standard semantic text similarity
(STS)task. GS-InfoNCE outperforms the state-of-the-art unsup-SimCSE by an
average Spear-man correlation of 1.38%, 0.72%, 1.17% and0.28% on the base of
BERT-base, BERT-large,RoBERTa-base and RoBERTa-large, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Opinion Summarizers by Selecting Informative Reviews. (arXiv:2109.04325v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04325">
<div class="article-summary-box-inner">
<span><p>Opinion summarization has been traditionally approached with unsupervised,
weakly-supervised and few-shot learning techniques. In this work, we collect a
large dataset of summaries paired with user reviews for over 31,000 products,
enabling supervised training. However, the number of reviews per product is
large (320 on average), making summarization - and especially training a
summarizer - impractical. Moreover, the content of many reviews is not
reflected in the human-written summaries, and, thus, the summarizer trained on
random review subsets hallucinates. In order to deal with both of these
challenges, we formulate the task as jointly learning to select informative
subsets of reviews and summarizing the opinions expressed in these subsets. The
choice of the review subset is treated as a latent variable, predicted by a
small and simple selector. The subset is then fed into a more powerful
summarizer. For joint training, we use amortized variational inference and
policy gradient methods. Our experiments demonstrate the importance of
selecting informative reviews resulting in improved quality of summaries and
reduced hallucinations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PPT: Pre-trained Prompt Tuning for Few-shot Learning. (arXiv:2109.04332v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04332">
<div class="article-summary-box-inner">
<span><p>Prompts for pre-trained language models (PLMs) have shown remarkable
performance by bridging the gap between pre-training tasks and various
downstream tasks. Among these methods, prompt tuning, which freezes PLMs and
only tunes soft prompts, provides an efficient and effective solution for
adapting large-scale PLMs to downstream tasks. However, prompt tuning is yet to
be fully explored. In our pilot experiments, we find that prompt tuning
performs comparably with conventional full-model fine-tuning when downstream
data are sufficient, whereas it performs much worse under few-shot learning
settings, which may hinder the application of prompt tuning in practice. We
attribute this low performance to the manner of initializing soft prompts.
Therefore, in this work, we propose to pre-train prompts by adding soft prompts
into the pre-training stage to obtain a better initialization. We name this
Pre-trained Prompt Tuning framework "PPT". To ensure the generalization of PPT,
we formulate similar classification tasks into a unified task form and
pre-train soft prompts for this unified task. Extensive experiments show that
tuning pre-trained prompts for downstream tasks can reach or even outperform
full-model fine-tuning under both full-data and few-shot settings. Our approach
is effective and efficient for using large-scale PLMs in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty Measures in Neural Belief Tracking and the Effects on Dialogue Policy Performance. (arXiv:2109.04349v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04349">
<div class="article-summary-box-inner">
<span><p>The ability to identify and resolve uncertainty is crucial for the robustness
of a dialogue system. Indeed, this has been confirmed empirically on systems
that utilise Bayesian approaches to dialogue belief tracking. However, such
systems consider only confidence estimates and have difficulty scaling to more
complex settings. Neural dialogue systems, on the other hand, rarely take
uncertainties into account. They are therefore overconfident in their decisions
and less robust. Moreover, the performance of the tracking task is often
evaluated in isolation, without consideration of its effect on the downstream
policy optimisation. We propose the use of different uncertainty measures in
neural belief tracking. The effects of these measures on the downstream task of
policy optimisation are evaluated by adding selected measures of uncertainty to
the feature space of the policy and training policies through interaction with
a user simulator. Both human and simulated user results show that incorporating
these measures leads to improvements both of the performance and of the
robustness of the downstream dialogue policy. This highlights the importance of
developing neural dialogue belief trackers that take uncertainty into account.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-granularity Textual Adversarial Attack with Behavior Cloning. (arXiv:2109.04367v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04367">
<div class="article-summary-box-inner">
<span><p>Recently, the textual adversarial attack models become increasingly popular
due to their successful in estimating the robustness of NLP models. However,
existing works have obvious deficiencies. (1) They usually consider only a
single granularity of modification strategies (e.g. word-level or
sentence-level), which is insufficient to explore the holistic textual space
for generation; (2) They need to query victim models hundreds of times to make
a successful attack, which is highly inefficient in practice. To address such
problems, in this paper we propose MAYA, a Multi-grAnularitY Attack model to
effectively generate high-quality adversarial samples with fewer queries to
victim models. Furthermore, we propose a reinforcement-learning based method to
train a multi-granularity attack agent through behavior cloning with the expert
knowledge from our MAYA algorithm to further reduce the query times.
Additionally, we also adapt the agent to attack black-box models that only
output labels without confidence scores. We conduct comprehensive experiments
to evaluate our attack models by attacking BiLSTM, BERT and RoBERTa in two
different black-box attack settings and three benchmark datasets. Experimental
results show that our models achieve overall better attacking performance and
produce more fluent and grammatical adversarial samples compared to baseline
models. Besides, our adversarial attack agent significantly reduces the query
times in both attack settings. Our codes are released at
https://github.com/Yangyi-Chen/MAYA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tracking Turbulence Through Financial News During COVID-19. (arXiv:2109.04369v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04369">
<div class="article-summary-box-inner">
<span><p>Grave human toll notwithstanding, the COVID-19 pandemic created uniquely
unstable conditions in financial markets. In this work we uncover and discuss
relationships involving sentiment in financial publications during the 2020
pandemic-motivated U.S. financial crash. First, we introduce a set of expert
annotations of financial sentiment for articles from major American financial
news publishers. After an exploratory data analysis, we then describe a
CNN-based architecture to address the task of predicting financial sentiment in
this anomalous, tumultuous setting. Our best performing model achieves a
maximum weighted F1 score of 0.746, establishing a strong performance
benchmark. Using predictions from our top performing model, we close by
conducting a statistical correlation study with real stock market data, finding
interesting and strong relationships between financial news and the S\&amp;P 500
index, trading volume, market volatility, and different single-factor ETFs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ESimCSE: Enhanced Sample Building Method for Contrastive Learning of Unsupervised Sentence Embedding. (arXiv:2109.04380v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04380">
<div class="article-summary-box-inner">
<span><p>Contrastive learning has been attracting much attention for learning
unsupervised sentence embeddings. The current state-of-the-art unsupervised
method is the unsupervised SimCSE (unsup-SimCSE). Unsup-SimCSE takes dropout as
a minimal data augmentation method, and passes the same input sentence to a
pre-trained Transformer encoder (with dropout turned on) twice to obtain the
two corresponding embeddings to build a positive pair. As the length
information of a sentence will generally be encoded into the sentence
embeddings due to the usage of position embedding in Transformer, each positive
pair in unsup-SimCSE actually contains the same length information. And thus
unsup-SimCSE trained with these positive pairs is probably biased, which would
tend to consider that sentences of the same or similar length are more similar
in semantics. Through statistical observations, we find that unsup-SimCSE does
have such a problem. To alleviate it, we apply a simple repetition operation to
modify the input sentence, and then pass the input sentence and its modified
counterpart to the pre-trained Transformer encoder, respectively, to get the
positive pair. Additionally, we draw inspiration from the community of computer
vision and introduce a momentum contrast, enlarging the number of negative
pairs without additional calculations. The proposed two modifications are
applied on positive and negative pairs separately, and build a new sentence
embedding method, termed Enhanced Unsup-SimCSE (ESimCSE). We evaluate the
proposed ESimCSE on several benchmark datasets w.r.t the semantic text
similarity (STS) task. Experimental results show that ESimCSE outperforms the
state-of-the-art unsup-SimCSE by an average Spearman correlation of 2.02% on
BERT-base.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrasting Human- and Machine-Generated Word-Level Adversarial Examples for Text Classification. (arXiv:2109.04385v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04385">
<div class="article-summary-box-inner">
<span><p>Research shows that natural language processing models are generally
considered to be vulnerable to adversarial attacks; but recent work has drawn
attention to the issue of validating these adversarial inputs against certain
criteria (e.g., the preservation of semantics and grammaticality). Enforcing
constraints to uphold such criteria may render attacks unsuccessful, raising
the question of whether valid attacks are actually feasible. In this work, we
investigate this through the lens of human language ability. We report on
crowdsourcing studies in which we task humans with iteratively modifying words
in an input text, while receiving immediate model feedback, with the aim of
causing a sentiment classification model to misclassify the example. Our
findings suggest that humans are capable of generating a substantial amount of
adversarial examples using semantics-preserving word substitutions. We analyze
how human-generated adversarial examples compare to the recently proposed
TextFooler, Genetic, BAE and SememePSO attack algorithms on the dimensions
naturalness, preservation of sentiment, grammaticality and substitution rate.
Our findings suggest that human-generated adversarial examples are not more
able than the best algorithms to generate natural-reading, sentiment-preserving
examples, though they do so by being much more computationally efficient.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual Transfer for Text Classification with Dictionary-based Heterogeneous Graph. (arXiv:2109.04400v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04400">
<div class="article-summary-box-inner">
<span><p>In cross-lingual text classification, it is required that task-specific
training data in high-resource source languages are available, where the task
is identical to that of a low-resource target language. However, collecting
such training data can be infeasible because of the labeling cost, task
characteristics, and privacy concerns. This paper proposes an alternative
solution that uses only task-independent word embeddings of high-resource
languages and bilingual dictionaries. First, we construct a dictionary-based
heterogeneous graph (DHG) from bilingual dictionaries. This opens the
possibility to use graph neural networks for cross-lingual transfer. The
remaining challenge is the heterogeneity of DHG because multiple languages are
considered. To address this challenge, we propose dictionary-based
heterogeneous graph neural network (DHGNet) that effectively handles the
heterogeneity of DHG by two-step aggregations, which are word-level and
language-level aggregations. Experimental results demonstrate that our method
outperforms pretrained models even though it does not access to large corpora.
Furthermore, it can perform well even though dictionaries contain many
incorrect translations. Its robustness allows the usage of a wider range of
dictionaries such as an automatically constructed dictionary and crowdsourced
dictionary, which are convenient for real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">All Bark and No Bite: Rogue Dimensions in Transformer Language Models Obscure Representational Quality. (arXiv:2109.04404v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04404">
<div class="article-summary-box-inner">
<span><p>Similarity measures are a vital tool for understanding how language models
represent and process language. Standard representational similarity measures
such as cosine similarity and Euclidean distance have been successfully used in
static word embedding models to understand how words cluster in semantic space.
Recently, these measures have been applied to embeddings from contextualized
models such as BERT and GPT-2. In this work, we call into question the
informativity of such measures for contextualized language models. We find that
a small number of rogue dimensions, often just 1-3, dominate these measures.
Moreover, we find a striking mismatch between the dimensions that dominate
similarity measures and those which are important to the behavior of the model.
We show that simple postprocessing techniques such as standardization are able
to correct for rogue dimensions and reveal underlying representational quality.
We argue that accounting for rogue dimensions is essential for any
similarity-based analysis of contextual language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from Uneven Training Data: Unlabeled, Single Label, and Multiple Labels. (arXiv:2109.04408v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04408">
<div class="article-summary-box-inner">
<span><p>Training NLP systems typically assumes access to annotated data that has a
single human label per example. Given imperfect labeling from annotators and
inherent ambiguity of language, we hypothesize that single label is not
sufficient to learn the spectrum of language interpretation. We explore new
label annotation distribution schemes, assigning multiple labels per example
for a small subset of training examples. Introducing such multi label examples
at the cost of annotating fewer examples brings clear gains on natural language
inference task and entity typing task, even when we simply first train with a
single label data and then fine tune with multi label examples. Extending a
MixUp data augmentation framework, we propose a learning algorithm that can
learn from uneven training examples (with zero, one, or multiple labels). This
algorithm efficiently combines signals from uneven training data and brings
additional gains in low annotation budget and cross domain settings. Together,
our method achieves consistent gains in both accuracy and label distribution
metrics in two tasks, suggesting training with uneven training data can be
beneficial for many NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-autoregressive End-to-end Speech Translation with Parallel Autoregressive Rescoring. (arXiv:2109.04411v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04411">
<div class="article-summary-box-inner">
<span><p>This article describes an efficient end-to-end speech translation (E2E-ST)
framework based on non-autoregressive (NAR) models. End-to-end speech
translation models have several advantages over traditional cascade systems
such as inference latency reduction. However, conventional AR decoding methods
are not fast enough because each token is generated incrementally. NAR models,
however, can accelerate the decoding speed by generating multiple tokens in
parallel on the basis of the token-wise conditional independence assumption. We
propose a unified NAR E2E-ST framework called Orthros, which has an NAR decoder
and an auxiliary shallow AR decoder on top of the shared encoder. The auxiliary
shallow AR decoder selects the best hypothesis by rescoring multiple candidates
generated from the NAR decoder in parallel (parallel AR rescoring). We adopt
conditional masked language model (CMLM) and a connectionist temporal
classification (CTC)-based model as NAR decoders for Orthros, referred to as
Orthros-CMLM and Orthros-CTC, respectively. We also propose two training
methods to enhance the CMLM decoder. Experimental evaluations on three
benchmark datasets with six language directions demonstrated that Orthros
achieved large improvements in translation quality with a very small overhead
compared with the baseline NAR model. Moreover, the Conformer encoder
architecture enabled large quality improvements, especially for CTC-based
models. Orthros-CTC with the Conformer encoder increased decoding speed by
3.63x on CPU with translation quality comparable to that of an AR model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AStitchInLanguageModels: Dataset and Methods for the Exploration of Idiomaticity in Pre-Trained Language Models. (arXiv:2109.04413v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04413">
<div class="article-summary-box-inner">
<span><p>Despite their success in a variety of NLP tasks, pre-trained language models,
due to their heavy reliance on compositionality, fail in effectively capturing
the meanings of multiword expressions (MWEs), especially idioms. Therefore,
datasets and methods to improve the representation of MWEs are urgently needed.
Existing datasets are limited to providing the degree of idiomaticity of
expressions along with the literal and, where applicable, (a single)
non-literal interpretation of MWEs. This work presents a novel dataset of
naturally occurring sentences containing MWEs manually classified into a
fine-grained set of meanings, spanning both English and Portuguese. We use this
dataset in two tasks designed to test i) a language model's ability to detect
idiom usage, and ii) the effectiveness of a language model in generating
representations of sentences containing idioms. Our experiments demonstrate
that, on the task of detecting idiomatic usage, these models perform reasonably
well in the one-shot and few-shot scenarios, but that there is significant
scope for improvement in the zero-shot scenario. On the task of representing
idiomaticity, we find that pre-training is not always effective, while
fine-tuning could provide a sample efficient method of learning representations
of sentences containing MWEs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TxT: Crossmodal End-to-End Learning with Transformers. (arXiv:2109.04422v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04422">
<div class="article-summary-box-inner">
<span><p>Reasoning over multiple modalities, e.g. in Visual Question Answering (VQA),
requires an alignment of semantic concepts across domains. Despite the
widespread success of end-to-end learning, today's multimodal pipelines by and
large leverage pre-extracted, fixed features from object detectors, typically
Faster R-CNN, as representations of the visual world. The obvious downside is
that the visual representation is not specifically tuned to the multimodal task
at hand. At the same time, while transformer-based object detectors have gained
popularity, they have not been employed in today's multimodal pipelines. We
address both shortcomings with TxT, a transformer-based crossmodal pipeline
that enables fine-tuning both language and visual components on the downstream
task in a fully end-to-end manner. We overcome existing limitations of
transformer-based detectors for multimodal reasoning regarding the integration
of global context and their scalability. Our transformer-based multimodal model
achieves considerable gains from end-to-end learning for multimodal question
answering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HintedBT: Augmenting Back-Translation with Quality and Transliteration Hints. (arXiv:2109.04443v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04443">
<div class="article-summary-box-inner">
<span><p>Back-translation (BT) of target monolingual corpora is a widely used data
augmentation strategy for neural machine translation (NMT), especially for
low-resource language pairs. To improve effectiveness of the available BT data,
we introduce HintedBT -- a family of techniques which provides hints (through
tags) to the encoder and decoder. First, we propose a novel method of using
both high and low quality BT data by providing hints (as source tags on the
encoder) to the model about the quality of each source-target pair. We don't
filter out low quality data but instead show that these hints enable the model
to learn effectively from noisy data. Second, we address the problem of
predicting whether a source token needs to be translated or transliterated to
the target language, which is common in cross-script translation tasks (i.e.,
where source and target do not share the written script). For such cases, we
propose training the model with additional hints (as target tags on the
decoder) that provide information about the operation required on the source
(translation or both translation and transliteration). We conduct experiments
and detailed analyses on standard WMT benchmarks for three cross-script
low/medium-resource language pairs: {Hindi,Gujarati,Tamil}-to-English. Our
methods compare favorably with five strong and well established baselines. We
show that using these hints, both separately and together, significantly
improves translation quality and leads to state-of-the-art performance in all
three language pairs in corresponding bilingual settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers. (arXiv:2109.04448v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04448">
<div class="article-summary-box-inner">
<span><p>Pretrained vision-and-language BERTs aim to learn representations that
combine information from both modalities. We propose a diagnostic method based
on cross-modal input ablation to assess the extent to which these models
actually integrate cross-modal information. This method involves ablating
inputs from one modality, either entirely or selectively based on cross-modal
grounding alignments, and evaluating the model prediction performance on the
other modality. Model performance is measured by modality-specific tasks that
mirror the model pretraining objectives (e.g. masked language modelling for
text). Models that have learned to construct cross-modal representations using
both modalities are expected to perform worse when inputs are missing from a
modality. We find that recently proposed models have much greater relative
difficulty predicting text when visual information is ablated, compared to
predicting visual object categories when text is ablated, indicating that these
models are not symmetrically cross-modal.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysis of Language Change in Collaborative Instruction Following. (arXiv:2109.04452v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04452">
<div class="article-summary-box-inner">
<span><p>We analyze language change over time in a collaborative, goal-oriented
instructional task, where utility-maximizing participants form conventions and
increase their expertise. Prior work studied such scenarios mostly in the
context of reference games, and consistently found that language complexity is
reduced along multiple dimensions, such as utterance length, as conventions are
formed. In contrast, we find that, given the ability to increase instruction
utility, instructors increase language complexity along these previously
studied dimensions to better collaborate with increasingly skilled instruction
followers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization. (arXiv:1911.03437v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.03437">
<div class="article-summary-box-inner">
<span><p>Transfer learning has fundamentally changed the landscape of natural language
processing (NLP) research. Many existing state-of-the-art models are first
pre-trained on a large text corpus and then fine-tuned on downstream tasks.
However, due to limited data resources from downstream tasks and the extremely
large capacity of pre-trained models, aggressive fine-tuning often causes the
adapted model to overfit the data of downstream tasks and forget the knowledge
of the pre-trained model. To address the above issue in a more principled
manner, we propose a new computational framework for robust and efficient
fine-tuning for pre-trained language models. Specifically, our proposed
framework contains two important ingredients: 1. Smoothness-inducing
regularization, which effectively manages the capacity of the model; 2. Bregman
proximal point optimization, which is a class of trust-region methods and can
prevent knowledge forgetting. Our experiments demonstrate that our proposed
method achieves the state-of-the-art performance on multiple NLP benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Linguistic Capacity of Real-Time Counter Automata. (arXiv:2004.06866v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.06866">
<div class="article-summary-box-inner">
<span><p>Counter machines have achieved a newfound relevance to the field of natural
language processing (NLP): recent work suggests some strong-performing
recurrent neural networks utilize their memory as counters. Thus, one potential
way to understand the success of these networks is to revisit the theory of
counter computation. Therefore, we study the abilities of real-time counter
machines as formal grammars, focusing on formal properties that are relevant
for NLP models. We first show that several variants of the counter machine
converge to express the same class of formal languages. We also prove that
counter languages are closed under complement, union, intersection, and many
other common set operations. Next, we show that counter machines cannot
evaluate boolean expressions, even though they can weakly validate their
syntax. This has implications for the interpretability and evaluation of neural
network systems: successfully matching syntactic patterns does not guarantee
that counter memory accurately encodes compositional semantics. Finally, we
consider whether counter languages are semilinear. This work makes general
contributions to the theory of formal languages that are of potential interest
for understanding recurrent neural networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Time-Aware Evidence Ranking for Fact-Checking. (arXiv:2009.06402v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06402">
<div class="article-summary-box-inner">
<span><p>Truth can vary over time. Fact-checking decisions on claim veracity should
therefore take into account temporal information of both the claim and
supporting or refuting evidence. In this work, we investigate the hypothesis
that the timestamp of a Web page is crucial to how it should be ranked for a
given claim. We delineate four temporal ranking methods that constrain evidence
ranking differently and simulate hypothesis-specific evidence rankings given
the evidence timestamps as gold standard. Evidence ranking in three
fact-checking models is ultimately optimized using a learning-to-rank loss
function. Our study reveals that time-aware evidence ranking not only surpasses
relevance assumptions based purely on semantic similarity or position in a
search results list, but also improves veracity predictions of time-sensitive
claims in particular.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Mention Detector-Linker Interaction in Neural Coreference Resolution. (arXiv:2009.09363v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.09363">
<div class="article-summary-box-inner">
<span><p>Despite significant recent progress in coreference resolution, the quality of
current state-of-the-art systems still considerably trails behind human-level
performance. Using the CoNLL-2012 and PreCo datasets, we dissect the best
instantiation of the mainstream end-to-end coreference resolution model that
underlies most current best-performing coreference systems, and empirically
analyze the behavior of its two components: mention detector and mention
linker. While the detector traditionally focuses heavily on recall as a design
decision, we demonstrate the importance of precision, calling for their
balance. However, we point out the difficulty in building a precise detector
due to its inability to make important anaphoricity decisions. We also
highlight the enormous room for improving the linker and show that the rest of
its errors mainly involve pronoun resolution. We propose promising next steps
and hope our findings will help future research in coreference resolution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Cross-Modal Pre-Training: A General Strategy for Small Sample Medical Imaging. (arXiv:2010.03060v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03060">
<div class="article-summary-box-inner">
<span><p>A key challenge in training neural networks for a given medical imaging task
is often the difficulty of obtaining a sufficient number of manually labeled
examples. In contrast, textual imaging reports, which are often readily
available in medical records, contain rich but unstructured interpretations
written by experts as part of standard clinical practice. We propose using
these textual reports as a form of weak supervision to improve the image
interpretation performance of a neural network without requiring additional
manually labeled examples. We use an image-text matching task to train a
feature extractor and then fine-tune it in a transfer learning setting for a
supervised task using a small labeled dataset. The end result is a neural
network that automatically interprets imagery without requiring textual reports
during inference. This approach can be applied to any task for which text-image
pairs are readily available. We evaluate our method on three classification
tasks and find consistent performance improvements, reducing the need for
labeled data by 67%-98%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mathematical Word Problem Generation from Commonsense Knowledge Graph and Equations. (arXiv:2010.06196v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06196">
<div class="article-summary-box-inner">
<span><p>There is an increasing interest in the use of mathematical word problem (MWP)
generation in educational assessment. Different from standard natural question
generation, MWP generation needs to maintain the underlying mathematical
operations between quantities and variables, while at the same time ensuring
the relevance between the output and the given topic. To address above problem,
we develop an end-to-end neural model to generate diverse MWPs in real-world
scenarios from commonsense knowledge graph and equations. The proposed model
(1) learns both representations from edge-enhanced Levi graphs of symbolic
equations and commonsense knowledge; (2) automatically fuses equation and
commonsense knowledge information via a self-planning module when generating
the MWPs. Experiments on an educational gold-standard set and a large-scale
generated MWP set show that our approach is superior on the MWP generation
task, and it outperforms the SOTA models in terms of both automatic evaluation
metrics, i.e., BLEU-4, ROUGE-L, Self-BLEU, and human evaluation metrics, i.e.,
equation relevance, topic relevance, and language coherence. To encourage
reproducible results, we make our code and MWP dataset public available at
\url{https://github.com/tal-ai/MaKE_EMNLP2021}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compositional Generalization via Semantic Tagging. (arXiv:2010.11818v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11818">
<div class="article-summary-box-inner">
<span><p>Although neural sequence-to-sequence models have been successfully applied to
semantic parsing, they fail at compositional generalization, i.e., they are
unable to systematically generalize to unseen compositions of seen components.
Motivated by traditional semantic parsing where compositionality is explicitly
accounted for by symbolic grammars, we propose a new decoding framework that
preserves the expressivity and generality of sequence-to-sequence models while
featuring lexicon-style alignments and disentangled information processing.
Specifically, we decompose decoding into two phases where an input utterance is
first tagged with semantic symbols representing the meaning of individual
words, and then a sequence-to-sequence model is used to predict the final
meaning representation conditioning on the utterance and the predicted tag
sequence. Experimental results on three semantic parsing datasets show that the
proposed approach consistently improves compositional generalization across
model architectures, domains, and semantic formalisms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NUANCED: Natural Utterance Annotation for Nuanced Conversation with Estimated Distributions. (arXiv:2010.12758v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12758">
<div class="article-summary-box-inner">
<span><p>Existing conversational systems are mostly agent-centric, which assumes the
user utterances would closely follow the system ontology (for NLU or dialogue
state tracking). However, in real-world scenarios, it is highly desirable that
the users can speak freely in their own way. It is extremely hard, if not
impossible, for the users to adapt to the unknown system ontology. In this
work, we attempt to build a user-centric dialogue system. As there is no clean
mapping for a user's free form utterance to an ontology, we first model the
user preferences as estimated distributions over the system ontology and map
the users' utterances to such distributions. Learning such a mapping poses new
challenges on reasoning over existing knowledge, ranging from factoid
knowledge, commonsense knowledge to the users' own situations. To this end, we
build a new dataset named NUANCED that focuses on such realistic settings for
conversational recommendation. Collected via dialogue simulation and
paraphrasing, NUANCED contains 5.1k dialogues, 26k turns of high-quality user
responses. We conduct experiments, showing both the usefulness and challenges
of our problem setting. We believe NUANCED can serve as a valuable resource to
push existing research from the agent-centric system to the user-centric
system. The code and data is publicly available at
\url{https://github.com/facebookresearch/nuanced}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Few-Shot Commonsense Knowledge Models. (arXiv:2101.00297v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00297">
<div class="article-summary-box-inner">
<span><p>Providing natural language processing systems with commonsense knowledge is a
critical challenge for achieving language understanding. Recently, commonsense
knowledge models have emerged as a suitable approach for hypothesizing
situation-relevant commonsense knowledge on-demand in natural language
applications. However, these systems are limited by the fixed set of relations
captured by schemas of the knowledge bases on which they're trained.
</p>
<p>To address this limitation, we investigate training commonsense knowledge
models in a few-shot setting with limited tuples per commonsense relation in
the graph. We perform five separate studies on different dimensions of few-shot
commonsense knowledge learning, providing a roadmap on best practices for
training these systems efficiently. Importantly, we find that human quality
ratings for knowledge produced from a few-shot trained system can achieve
performance within 6% of knowledge produced from fully supervised systems. This
few-shot performance enables coverage of a wide breadth of relations in future
commonsense systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Biomedical Question Answering: A Survey of Approaches and Challenges. (arXiv:2102.05281v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05281">
<div class="article-summary-box-inner">
<span><p>Automatic Question Answering (QA) has been successfully applied in various
domains such as search engines and chatbots. Biomedical QA (BQA), as an
emerging QA task, enables innovative applications to effectively perceive,
access and understand complex biomedical knowledge. There have been tremendous
developments of BQA in the past two decades, which we classify into 5
distinctive approaches: classic, information retrieval, machine reading
comprehension, knowledge base and question entailment approaches. In this
survey, we introduce available datasets and representative methods of each BQA
approach in detail. Despite the developments, BQA systems are still immature
and rarely used in real-life settings. We identify and characterize several key
challenges in BQA that might lead to this issue, and discuss some potential
future directions to explore.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Position Information in Transformers: An Overview. (arXiv:2102.11090v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11090">
<div class="article-summary-box-inner">
<span><p>Transformers are arguably the main workhorse in recent Natural Language
Processing research. By definition a Transformer is invariant with respect to
reordering of the input. However, language is inherently sequential and word
order is essential to the semantics and syntax of an utterance. In this
article, we provide an overview and theoretical comparison of existing methods
to incorporate position information into Transformer models. The objectives of
this survey are to (1) showcase that position information in Transformer is a
vibrant and extensive research area; (2) enable the reader to compare existing
methods by providing a unified notation and systematization of different
approaches along important model dimensions; (3) indicate what characteristics
of an application should be taken into account when selecting a position
encoding; (4) provide stimuli for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP. (arXiv:2103.00453v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00453">
<div class="article-summary-box-inner">
<span><p>When trained on large, unfiltered crawls from the internet, language models
pick up and reproduce all kinds of undesirable biases that can be found in the
data: they often generate racist, sexist, violent or otherwise toxic language.
As large models require millions of training examples to achieve good
performance, it is difficult to completely prevent them from being exposed to
such content. In this paper, we first demonstrate a surprising finding:
pretrained language models recognize, to a considerable degree, their
undesirable biases and the toxicity of the content they produce. We refer to
this capability as self-diagnosis. Based on this finding, we then propose a
decoding algorithm that, given only a textual description of the undesired
behavior, reduces the probability of a language model producing problematic
text. We refer to this approach as self-debiasing. Self-debiasing does not rely
on manually curated word lists, nor does it require any training data or
changes to the model's parameters. While we by no means eliminate the issue of
language models generating biased text, we believe our approach to be an
important step in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimal Embedding Calibration for Symbolic Music Similarity. (arXiv:2103.07656v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07656">
<div class="article-summary-box-inner">
<span><p>In natural language processing (NLP), the semantic similarity task requires
large-scale, high-quality human-annotated labels for fine-tuning or evaluation.
By contrast, in cases of music similarity, such labels are expensive to collect
and largely dependent on the annotator's artistic preferences. Recent research
has demonstrated that embedding calibration technique can greatly increase
semantic similarity performance of the pre-trained language model without
fine-tuning. However, it is yet unknown which calibration method is the best
and how much performance improvement can be achieved. To address these issues,
we propose using composer information to construct labels for automatically
evaluating music similarity. Under this paradigm, we discover the optimal
combination of embedding calibration which achieves superior metrics than the
baseline methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating False-Negative Contexts in Multi-document Question Answering with Retrieval Marginalization. (arXiv:2103.12235v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12235">
<div class="article-summary-box-inner">
<span><p>Question Answering (QA) tasks requiring information from multiple documents
often rely on a retrieval model to identify relevant information for reasoning.
The retrieval model is typically trained to maximize the likelihood of the
labeled supporting evidence. However, when retrieving from large text corpora
such as Wikipedia, the correct answer can often be obtained from multiple
evidence candidates. Moreover, not all such candidates are labeled as positive
during annotation, rendering the training signal weak and noisy. This problem
is exacerbated when the questions are unanswerable or when the answers are
Boolean, since the model cannot rely on lexical overlap to make a connection
between the answer and supporting evidence. We develop a new parameterization
of set-valued retrieval that handles unanswerable queries, and we show that
marginalizing over this set during training allows a model to mitigate false
negatives in supporting evidence annotations. We test our method on two
multi-document QA datasets, IIRC and HotpotQA. On IIRC, we show that joint
modeling with marginalization improves model performance by 5.5 F1 points and
achieves a new state-of-the-art performance of 50.5 F1. We also show that
retrieval marginalization results in 4.1 QA F1 improvement over a
non-marginalized baseline on HotpotQA in the fullwiki setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NAREOR: The Narrative Reordering Problem. (arXiv:2104.06669v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06669">
<div class="article-summary-box-inner">
<span><p>Many implicit inferences exist in text depending on how it is structured that
can critically impact the text's interpretation and meaning. One such
structural aspect present in text with chronology is the order of its
presentation. For narratives or stories, this is known as the narrative order.
Reordering a narrative can impact the temporal, causal, event-based, and other
inferences readers draw from it, which in turn can have strong effects both on
its interpretation and interestingness. In this paper, we propose and
investigate the task of Narrative Reordering (NAREOR) which involves rewriting
a given story in a different narrative order while preserving its plot. We
present a dataset, NAREORC, with human rewritings of stories within ROCStories
in non-linear orders, and conduct a detailed analysis of it. Further, we
propose novel task-specific training methods with suitable evaluation metrics.
We perform experiments on NAREORC using state-of-the-art models such as BART
and T5 and conduct extensive automatic and human evaluations. We demonstrate
that although our models can perform decently, NAREOR is a challenging task
with potential for further exploration. We also investigate two applications of
NAREOR: generation of more interesting variations of stories and serving as
adversarial sets for temporal/event-related tasks, besides discussing other
prospective ones, such as for pedagogical setups related to language skills
like essay writing and applications to medicine involving clinical narratives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07650">
<div class="article-summary-box-inner">
<span><p>Recently, prompt-tuning has achieved promising results for certain few-shot
classification tasks. The core idea of prompt-tuning is to insert text pieces
(i.e., templates) into the input and transform a classification task into a
masked language modeling problem. However, for relation extraction, determining
an appropriate prompt template requires domain expertise, and it is cumbersome
and time-consuming to obtain a suitable label word. Furthermore, there exist
abundant semantic knowledge among the entities and relations that cannot be
ignored. To this end, we focus on incorporating knowledge into prompt-tuning
for relation extraction and propose a knowledge-aware prompt-tuning approach
with synergistic optimization (KnowPrompt). Specifically, we inject entity and
relation knowledge into prompt construction with learnable virtual template
words as well as answer words and synergistically optimize their representation
with knowledge constraints. Extensive experimental results on five datasets
with standard and low-resource settings demonstrate the effectiveness of our
approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Train BERT with an Academic Budget. (arXiv:2104.07705v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07705">
<div class="article-summary-box-inner">
<span><p>While large language models a la BERT are used ubiquitously in NLP,
pretraining them is considered a luxury that only a few well-funded industry
labs can afford. How can one train such models with a more modest budget? We
present a recipe for pretraining a masked language model in 24 hours using a
single low-end deep learning server. We demonstrate that through a combination
of software optimizations, design choices, and hyperparameter tuning, it is
possible to produce models that are competitive with BERT-base on GLUE tasks at
a fraction of the original pretraining cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders. (arXiv:2104.08027v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08027">
<div class="article-summary-box-inner">
<span><p>Pretrained Masked Language Models (MLMs) have revolutionised NLP in recent
years. However, previous work has indicated that off-the-shelf MLMs are not
effective as universal lexical or sentence encoders without further
task-specific fine-tuning on NLI, sentence similarity, or paraphrasing tasks
using annotated task data. In this work, we demonstrate that it is possible to
turn MLMs into effective universal lexical and sentence encoders even without
any additional data and without any supervision. We propose an extremely
simple, fast and effective contrastive learning technique, termed Mirror-BERT,
which converts MLMs (e.g., BERT and RoBERTa) into such encoders in 20-30
seconds without any additional external knowledge. Mirror-BERT relies on fully
identical or slightly modified string pairs as positive (i.e., synonymous)
fine-tuning examples, and aims to maximise their similarity during identity
fine-tuning. We report huge gains over off-the-shelf MLMs with Mirror-BERT in
both lexical-level and sentence-level tasks, across different domains and
different languages. Notably, in the standard sentence semantic similarity
(STS) tasks, our self-supervised Mirror-BERT model even matches the performance
of the task-tuned Sentence-BERT models from prior work. Finally, we delve
deeper into the inner workings of MLMs, and suggest some evidence on why this
simple approach can yield effective universal lexical and sentence encoders.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Editing Factual Knowledge in Language Models. (arXiv:2104.08164v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08164">
<div class="article-summary-box-inner">
<span><p>The factual knowledge acquired during pre-training and stored in the
parameters of Language Models (LMs) can be useful in downstream tasks (e.g.,
question answering or textual inference). However, some facts can be
incorrectly induced or become obsolete over time. We present KnowledgeEditor, a
method which can be used to edit this knowledge and, thus, fix 'bugs' or
unexpected predictions without the need for expensive re-training or
fine-tuning. Besides being computationally efficient, KnowledgeEditordoes not
require any modifications in LM pre-training (e.g., the use of meta-learning).
In our approach, we train a hyper-network with constrained optimization to
modify a fact without affecting the rest of the knowledge; the trained
hyper-network is then used to predict the weight update at test time. We show
KnowledgeEditor's efficacy with two popular architectures and
knowledge-intensive tasks: i) a BERT model fine-tuned for fact-checking, and
ii) a sequence-to-sequence BART model for question answering. With our method,
changing a prediction on the specific wording of a query tends to result in a
consistent change in predictions also for its paraphrases. We show that this
can be further encouraged by exploiting (e.g., automatically-generated)
paraphrases during training. Interestingly, our hyper-network can be regarded
as a 'probe' revealing which components need to be changed to manipulate
factual knowledge; our analysis shows that the updates tend to be concentrated
on a small subset of components. Source code available at
https://github.com/nicola-decao/KnowledgeEditor
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$Q^{2}$: Evaluating Factual Consistency in Knowledge-Grounded Dialogues via Question Generation and Question Answering. (arXiv:2104.08202v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08202">
<div class="article-summary-box-inner">
<span><p>Neural knowledge-grounded generative models for dialogue often produce
content that is factually inconsistent with the knowledge they rely on, making
them unreliable and limiting their applicability. Inspired by recent work on
evaluating factual consistency in abstractive summarization, we propose an
automatic evaluation metric for factual consistency in knowledge-grounded
dialogue using automatic question generation and question answering. Our
metric, denoted $Q^2$, compares answer spans using natural language inference
(NLI), instead of token-based matching as done in previous work. To foster
proper evaluation, we curate a novel dataset of dialogue system outputs for the
Wizard-of-Wikipedia dataset, manually annotated for factual consistency. We
perform a thorough meta-evaluation of $Q^2$ against other metrics using this
dataset and two others, where it consistently shows higher correlation with
human judgements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Topic Confusion Task: A Novel Scenario for Authorship Attribution. (arXiv:2104.08530v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08530">
<div class="article-summary-box-inner">
<span><p>Authorship attribution is the problem of identifying the most plausible
author of an anonymous text from a set of candidate authors. Researchers have
investigated same-topic and cross-topic scenarios of authorship attribution,
which differ according to whether new, unseen topics are used in the testing
phase. However, neither scenario allows us to explain whether errors are caused
by a failure to capture authorship writing style or by a topic shift. Motivated
by this, we propose the \emph{topic confusion} task where we switch the
author-topic configuration between the training and testing sets. This setup
allows us to distinguish two types of errors: those caused by the topic shift
and those caused by the features' inability to capture the writing styles. We
show that stylometric features with part-of-speech tags are the least
susceptible to topic variations. We further show that combining them with other
features leads to significantly lower topic confusion and higher attribution
accuracy. Finally, we show that pretrained language models such as BERT and
RoBERTa perform poorly on this task and are surpassed by simple features such
as word-level $n$-grams.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Back-Training excels Self-Training at Unsupervised Domain Adaptation of Question Generation and Passage Retrieval. (arXiv:2104.08801v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08801">
<div class="article-summary-box-inner">
<span><p>In this work, we introduce back-training, an alternative to self-training for
unsupervised domain adaptation (UDA) from source to target domain. While
self-training generates synthetic training data where natural inputs are
aligned with noisy outputs, back-training results in natural outputs aligned
with noisy inputs. This significantly reduces the gap between the target domain
and synthetic data distribution, and reduces model overfitting to the source
domain. We run UDA experiments on question generation and passage retrieval
from the \textit{Natural Questions} domain to machine learning and biomedical
domains. We find that back-training vastly outperforms self-training by a mean
improvement of 7.8 BLEU-4 points on generation, and 17.6\% top-20 retrieval
accuracy across both domains. We further propose consistency filters to remove
low-quality synthetic data before training. We also release a new
domain-adaptation dataset- \textit{MLQuestions} containing 35K unaligned
questions, 50K unaligned passages, and 3K aligned question-passage pairs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistent Accelerated Inference via Confident Adaptive Transformers. (arXiv:2104.08803v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08803">
<div class="article-summary-box-inner">
<span><p>We develop a novel approach for confidently accelerating inference in the
large and expensive multilayer Transformers that are now ubiquitous in natural
language processing (NLP). Amortized or approximate computational methods
increase efficiency, but can come with unpredictable performance costs. In this
work, we present CATs -- Confident Adaptive Transformers -- in which we
simultaneously increase computational efficiency, while guaranteeing a
specifiable degree of consistency with the original model with high confidence.
Our method trains additional prediction heads on top of intermediate layers,
and dynamically decides when to stop allocating computational effort to each
input using a meta consistency classifier. To calibrate our early prediction
stopping rule, we formulate a unique extension of conformal prediction. We
demonstrate the effectiveness of this approach on four classification and
regression tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flexible Generation of Natural Language Deductions. (arXiv:2104.08825v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08825">
<div class="article-summary-box-inner">
<span><p>An interpretable system for open-domain reasoning needs to express its
reasoning process in a transparent form. Natural language is an attractive
representation for this purpose -- it is both highly expressive and easy for
humans to understand. However, manipulating natural language statements in
logically consistent ways is hard: models must cope with variation in how
meaning is expressed while remaining precise. In this paper, we describe
ParaPattern, a method for building models to generate deductive inferences from
diverse natural language inputs without direct human supervision. We train
BART-based models (Lewis et al., 2020) to generate the result of applying a
particular logical operation to one or more premise statements. Crucially, we
develop a largely automated pipeline for constructing suitable training
examples from Wikipedia. We evaluate our models using out-of-domain sentence
compositions from the QASC (Khot et al., 2020) and EntailmentBank (Dalvi et
al., 2021) datasets as well as targeted perturbation sets. Our results show
that our models are substantially more accurate and flexible than baseline
systems. ParaPattern achieves 85% validity on examples of the 'substitution'
operation from EntailmentBank without the use of any in-domain training data,
matching the performance of a model fine-tuned for EntailmentBank. The full
source code for our method is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding. (arXiv:2104.08836v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08836">
<div class="article-summary-box-inner">
<span><p>Multimodal pre-training with text, layout, and image has achieved SOTA
performance for visually-rich document understanding tasks recently, which
demonstrates the great potential for joint learning across different
modalities. In this paper, we present LayoutXLM, a multimodal pre-trained model
for multilingual document understanding, which aims to bridge the language
barriers for visually-rich document understanding. To accurately evaluate
LayoutXLM, we also introduce a multilingual form understanding benchmark
dataset named XFUND, which includes form understanding samples in 7 languages
(Chinese, Japanese, Spanish, French, Italian, German, Portuguese), and
key-value pairs are manually labeled for each language. Experiment results show
that the LayoutXLM model has significantly outperformed the existing SOTA
cross-lingual pre-trained models on the XFUND dataset. The pre-trained
LayoutXLM model and the XFUND dataset are publicly available at
https://aka.ms/layoutxlm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teacher-Student MixIT for Unsupervised and Semi-supervised Speech Separation. (arXiv:2106.07843v3 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07843">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a novel semi-supervised learning framework for
end-to-end speech separation. The proposed method first uses mixtures of
unseparated sources and the mixture invariant training (MixIT) criterion to
train a teacher model. The teacher model then estimates separated sources that
are used to train a student model with standard permutation invariant training
(PIT). The student model can be fine-tuned with supervised data, i.e., paired
artificial mixtures and clean speech sources, and further improved via model
distillation. Experiments with single and multi channel mixtures show that the
teacher-student training resolves the over-separation problem observed in the
original MixIT method. Further, the semisupervised performance is comparable to
a fully-supervised separation system trained using ten times the amount of
supervised data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature. (arXiv:2107.01198v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01198">
<div class="article-summary-box-inner">
<span><p>In this work, we present to the NLP community, and to the wider research
community as a whole, an application for the diachronic analysis of research
corpora. We open source an easy-to-use tool coined: DRIFT, which allows
researchers to track research trends and development over the years. The
analysis methods are collated from well-cited research works, with a few of our
own methods added for good measure. Succinctly put, some of the analysis
methods are: keyword extraction, word clouds, predicting
declining/stagnant/growing trends using Productivity, tracking bi-grams using
Acceleration plots, finding the Semantic Drift of words, tracking trends using
similarity, etc. To demonstrate the utility and efficacy of our tool, we
perform a case study on the cs.CL corpus of the arXiv repository and draw
inferences from the analysis methods. The toolkit and the associated code are
available here: https://github.com/rajaswa/DRIFT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SynCoBERT: Syntax-Guided Multi-Modal Contrastive Pre-Training for Code Representation. (arXiv:2108.04556v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04556">
<div class="article-summary-box-inner">
<span><p>Code representation learning, which aims to encode the semantics of source
code into distributed vectors, plays an important role in recent
deep-learning-based models for code intelligence. Recently, many pre-trained
language models for source code (e.g., CuBERT and CodeBERT) have been proposed
to model the context of code and serve as a basis for downstream code
intelligence tasks such as code search, code clone detection, and program
translation. Current approaches typically consider the source code as a plain
sequence of tokens, or inject the structure information (e.g., AST and
data-flow) into the sequential model pre-training. To further explore the
properties of programming languages, this paper proposes SynCoBERT, a
syntax-guided multi-modal contrastive pre-training approach for better code
representations. Specially, we design two novel pre-training objectives
originating from the symbolic and syntactic properties of source code, i.e.,
Identifier Prediction (IP) and AST Edge Prediction (TEP), which are designed to
predict identifiers, and edges between two nodes of AST, respectively.
Meanwhile, to exploit the complementary information in semantically equivalent
modalities (i.e., code, comment, AST) of the code, we propose a multi-modal
contrastive learning strategy to maximize the mutual information among
different modalities. Extensive experiments on four downstream tasks related to
code intelligence show that SynCoBERT advances the state-of-the-art with the
same pre-training corpus and model size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v7 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12202">
<div class="article-summary-box-inner">
<span><p>In joint entity and relation extraction, existing work either sequentially
encode task-specific features, leading to an imbalance in inter-task feature
interaction where features extracted later have no direct contact with those
that come first. Or they encode entity features and relation features in a
parallel manner, meaning that feature representation learning for each task is
largely independent of each other except for input sharing. We propose a
partition filter network to model two-way interaction between tasks properly,
where feature encoding is decomposed into two steps: partition and filter. In
our encoder, we leverage two gates: entity and relation gate, to segment
neurons into two task partitions and one shared partition. The shared partition
represents inter-task information valuable to both tasks and is evenly shared
across two tasks to ensure proper two-way interaction. The task partitions
represent intra-task information and are formed through concerted efforts of
both gates, making sure that encoding of task-specific features is dependent
upon each other. Experiment results on six public datasets show that our model
performs significantly better than previous approaches. In addition, contrary
to what previous work has claimed, our auxiliary experiments suggest that
relation prediction is contributory to named entity prediction in a
non-negligible way. The source code can be found at
https://github.com/Coopercoppers/PFN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Text Evaluation through the Lens of Wasserstein Barycenters. (arXiv:2108.12463v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12463">
<div class="article-summary-box-inner">
<span><p>A new metric \texttt{BaryScore} to evaluate text generation based on deep
contextualized embeddings e.g., BERT, Roberta, ELMo) is introduced. This metric
is motivated by a new framework relying on optimal transport tools, i.e.,
Wasserstein distance and barycenter. By modelling the layer output of deep
contextualized embeddings as a probability distribution rather than by a vector
embedding; this framework provides a natural way to aggregate the different
outputs through the Wasserstein space topology. In addition, it provides
theoretical grounds to our metric and offers an alternative to available
solutions e.g., MoverScore and BertScore). Numerical evaluation is performed on
four different tasks: machine translation, summarization, data2text generation
and image captioning. Our results show that \texttt{BaryScore} outperforms
other BERT based metrics and exhibits more consistent behaviour in particular
for text summarization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Code-switched inspired losses for generic spoken dialog representations. (arXiv:2108.12465v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12465">
<div class="article-summary-box-inner">
<span><p>Spoken dialog systems need to be able to handle both multiple languages and
multilinguality inside a conversation (\textit{e.g} in case of code-switching).
In this work, we introduce new pretraining losses tailored to learn
multilingual spoken dialog representations. The goal of these losses is to
expose the model to code-switched language. To scale up training, we
automatically build a pretraining corpus composed of multilingual conversations
in five different languages (French, Italian, English, German and Spanish) from
\texttt{OpenSubtitles}, a huge multilingual corpus composed of 24.3G tokens. We
test the generic representations on \texttt{MIAM}, a new benchmark composed of
five dialog act corpora on the same aforementioned languages as well as on two
novel multilingual downstream tasks (\textit{i.e} multilingual mask utterance
retrieval and multilingual inconsistency identification). Our experiments show
that our new code switched-inspired losses achieve a better performance in both
monolingual and multilingual settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiplex Graph Neural Network for Extractive Text Summarization. (arXiv:2108.12870v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12870">
<div class="article-summary-box-inner">
<span><p>Extractive text summarization aims at extracting the most representative
sentences from a given document as its summary. To extract a good summary from
a long text document, sentence embedding plays an important role. Recent
studies have leveraged graph neural networks to capture the inter-sentential
relationship (e.g., the discourse graph) to learn contextual sentence
embedding. However, those approaches neither consider multiple types of
inter-sentential relationships (e.g., semantic similarity &amp; natural
connection), nor model intra-sentential relationships (e.g, semantic &amp;
syntactic relationship among words). To address these problems, we propose a
novel Multiplex Graph Convolutional Network (Multi-GCN) to jointly model
different types of relationships among sentences and words. Based on Multi-GCN,
we propose a Multiplex Graph Summarization (Multi-GraS) model for extractive
text summarization. Finally, we evaluate the proposed models on the
CNN/DailyMail benchmark dataset to demonstrate the effectiveness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LightNER: A Lightweight Generative Framework with Prompt-guided Attention for Low-resource NER. (arXiv:2109.00720v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00720">
<div class="article-summary-box-inner">
<span><p>Most existing NER methods rely on extensive labeled data for model training,
which struggles in the low-resource scenarios with limited training data.
Recently, prompt-tuning methods for pre-trained language models have achieved
remarkable performance in few-shot learning by exploiting prompts as task
guidance to reduce the gap between training progress and downstream tuning.
Inspired by prompt learning, we propose a novel lightweight generative
framework with prompt-guided attention for low-resource NER (LightNER).
Specifically, we construct the semantic-aware answer space of entity categories
for prompt learning to generate the entity span sequence and entity categories
without any label-specific classifiers. We further propose prompt-guided
attention by incorporating continuous prompts into the self-attention layer to
re-modulate the attention and adapt pre-trained weights. Note that we only tune
those continuous prompts with the whole parameter of the pre-trained language
model fixed, thus, making our approach lightweight and flexible for
low-resource scenarios and can better transfer knowledge across domains.
Experimental results show that LightNER can obtain comparable performance in
the standard supervised setting and outperform strong baselines in low-resource
settings by tuning only a small part of the parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Multimodal fusion via Mutual Dependency Maximisation. (arXiv:2109.00922v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00922">
<div class="article-summary-box-inner">
<span><p>Multimodal sentiment analysis is a trending area of research, and the
multimodal fusion is one of its most active topic. Acknowledging humans
communicate through a variety of channels (i.e visual, acoustic, linguistic),
multimodal systems aim at integrating different unimodal representations into a
synthetic one. So far, a consequent effort has been made on developing complex
architectures allowing the fusion of these modalities. However, such systems
are mainly trained by minimising simple losses such as $L_1$ or cross-entropy.
In this work, we investigate unexplored penalties and propose a set of new
objectives that measure the dependency between modalities. We demonstrate that
our new penalties lead to a consistent improvement (up to $4.3$ on accuracy)
across a large variety of state-of-the-art models on two well-known sentiment
analysis datasets: \texttt{CMU-MOSI} and \texttt{CMU-MOSEI}. Our method not
only achieves a new SOTA on both datasets but also produces representations
that are more robust to modality drops. Finally, a by-product of our methods
includes a statistical network which can be used to interpret the high
dimensional representations learnt by the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WhyAct: Identifying Action Reasons in Lifestyle Vlogs. (arXiv:2109.02747v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02747">
<div class="article-summary-box-inner">
<span><p>We aim to automatically identify human action reasons in online videos. We
focus on the widespread genre of lifestyle vlogs, in which people perform
actions while verbally describing them. We introduce and make publicly
available the WhyAct dataset, consisting of 1,077 visual actions manually
annotated with their reasons. We describe a multimodal model that leverages
visual and textual information to automatically infer the reasons corresponding
to an action presented in the video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Idiosyncratic but not Arbitrary: Learning Idiolects in Online Registers Reveals Distinctive yet Consistent Individual Styles. (arXiv:2109.03158v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03158">
<div class="article-summary-box-inner">
<span><p>An individual's variation in writing style is often a function of both social
and personal attributes. While structured social variation has been extensively
studied, e.g., gender based variation, far less is known about how to
characterize individual styles due to their idiosyncratic nature. We introduce
a new approach to studying idiolects through a massive cross-author comparison
to identify and encode stylistic features. The neural model achieves strong
performance at authorship identification on short texts and through an
analogy-based probing task, showing that the learned representations exhibit
surprising regularities that encode qualitative and quantitative shifts of
idiolectal styles. Through text perturbation, we quantify the relative
contributions of different linguistic elements to idiolectal variation.
Furthermore, we provide a description of idiolects through measuring inter- and
intra-author variation, showing that variation in idiolects is often
distinctive yet consistent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How much pretraining data do language models need to learn syntax?. (arXiv:2109.03160v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03160">
<div class="article-summary-box-inner">
<span><p>Transformers-based pretrained language models achieve outstanding results in
many well-known NLU benchmarks. However, while pretraining methods are very
convenient, they are expensive in terms of time and resources. This calls for a
study of the impact of pretraining data size on the knowledge of the models. We
explore this impact on the syntactic capabilities of RoBERTa, using models
trained on incremental sizes of raw text data. First, we use syntactic
structural probes to determine whether models pretrained on more data encode a
higher amount of syntactic information. Second, we perform a targeted syntactic
evaluation to analyze the impact of pretraining data size on the syntactic
generalization performance of the models. Third, we compare the performance of
the different models on three downstream applications: part-of-speech tagging,
dependency parsing and paraphrase identification. We complement our study with
an analysis of the cost-benefit trade-off of training such models. Our
experiments show that while models pretrained on more data encode more
syntactic knowledge and perform better on downstream applications, they do not
always offer a better performance across the different syntactic phenomena and
come at a higher financial and environmental cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">It is AI's Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset. (arXiv:2109.03423v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03423">
<div class="article-summary-box-inner">
<span><p>Existing question answering (QA) datasets are created mainly for the
application of having AI to be able to answer questions asked by humans. But in
educational applications, teachers and parents sometimes may not know what
questions they should ask a child that can maximize their language learning
results. With a newly released book QA dataset (FairytaleQA), which educational
experts labeled on 46 fairytale storybooks for early childhood readers, we
developed an automated QA generation model architecture for this novel
application. Our model (1) extracts candidate answers from a given storybook
passage through carefully designed heuristics based on a pedagogical framework;
(2) generates appropriate questions corresponding to each extracted answer
using a language model; and, (3) uses another QA model to rank top QA-pairs.
Automatic and human evaluations show that our model outperforms baselines. We
also demonstrate that our method can help with the scarcity issue of the
children's book QA dataset via data augmentation on 200 unlabeled storybooks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArchivalQA: A Large-scale Benchmark Dataset for Open Domain Question Answering over Archival News Collections. (arXiv:2109.03438v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03438">
<div class="article-summary-box-inner">
<span><p>In the last few years, open-domain question answering (ODQA) has advanced
rapidly due to the development of deep learning techniques and the availability
of large-scale QA datasets. However, the current datasets are essentially
designed for synchronic document collections (e.g., Wikipedia). Temporal news
collections such as long-term news archives spanning several decades, are
rarely used in training the models despite they are quite valuable for our
society. In order to foster the research in the field of ODQA on such
historical collections, we present ArchivalQA, a large question answering
dataset consisting of 1,067,056 question-answer pairs which is designed for
temporal news QA. In addition, we create four subparts of our dataset based on
the question difficulty levels and the containment of temporal expressions,
which we believe could be useful for training or testing ODQA systems
characterized by different strengths and abilities. The novel QA
dataset-constructing framework that we introduce can be also applied to create
datasets over other types of collections.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">OSSR-PID: One-Shot Symbol Recognition in P&ID Sheets using Path Sampling and GCN. (arXiv:2109.03849v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03849">
<div class="article-summary-box-inner">
<span><p>Piping and Instrumentation Diagrams (P&amp;ID) are ubiquitous in several
manufacturing, oil and gas enterprises for representing engineering schematics
and equipment layout. There is an urgent need to extract and digitize
information from P&amp;IDs without the cost of annotating a varying set of symbols
for each new use case. A robust one-shot learning approach for symbol
recognition i.e., localization followed by classification, would therefore go a
long way towards this goal. Our method works by sampling pixels sequentially
along the different contour boundaries in the image. These sampled points form
paths which are used in the prototypical line diagram to construct a graph that
captures the structure of the contours. Subsequently, the prototypical graphs
are fed into a Dynamic Graph Convolutional Neural Network (DGCNN) which is
trained to classify graphs into one of the given symbol classes. Further, we
append embeddings from a Resnet-34 network which is trained on symbol images
containing sampled points to make the classification network more robust.
Since, many symbols in P&amp;ID are structurally very similar to each other, we
utilize Arcface loss during DGCNN training which helps in maximizing symbol
class separability by producing highly discriminative embeddings. The images
consist of components attached on the pipeline (straight line). The sampled
points segregated around the symbol regions are used for the classification
task. The proposed pipeline, named OSSR-PID, is fast and gives outstanding
performance for recognition of symbols on a synthetic dataset of 100 P&amp;ID
diagrams. We also compare our method against prior-work on a real-world private
dataset of 12 P&amp;ID sheets and obtain comparable/superior results. Remarkably,
it is able to achieve such excellent performance using only one prototypical
example per symbol.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated LoD-2 Model Reconstruction from Very-HighResolution Satellite-derived Digital Surface Model and Orthophoto. (arXiv:2109.03876v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03876">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a model-driven method that reconstructs LoD-2
building models following a "decomposition-optimization-fitting" paradigm. The
proposed method starts building detection results through a deep learning-based
detector and vectorizes individual segments into polygons using a "three-step"
polygon extraction method, followed by a novel grid-based decomposition method
that decomposes the complex and irregularly shaped building polygons to tightly
combined elementary building rectangles ready to fit elementary building
models. We have optionally introduced OpenStreetMap (OSM) and Graph-Cut (GC)
labeling to further refine the orientation of 2D building rectangle. The 3D
modeling step takes building-specific parameters such as hip lines, as well as
non-rigid and regularized transformations to optimize the flexibility for using
a minimal set of elementary models. Finally, roof type of building models s
refined and adjacent building models in one building segment are merged into
the complex polygonal model. Our proposed method has addressed a few technical
caveats over existing methods, resulting in practically high-quality results,
based on our evaluation and comparative study on a diverse set of experimental
datasets of cities with different urban patterns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SORNet: Spatial Object-Centric Representations for Sequential Manipulation. (arXiv:2109.03891v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03891">
<div class="article-summary-box-inner">
<span><p>Sequential manipulation tasks require a robot to perceive the state of an
environment and plan a sequence of actions leading to a desired goal state,
where the ability to reason about spatial relationships among object entities
from raw sensor inputs is crucial. Prior works relying on explicit state
estimation or end-to-end learning struggle with novel objects. In this work, we
propose SORNet (Spatial Object-Centric Representation Network), which extracts
object-centric representations from RGB images conditioned on canonical views
of the objects of interest. We show that the object embeddings learned by
SORNet generalize zero-shot to unseen object entities on three spatial
reasoning tasks: spatial relationship classification, skill precondition
classification and relative direction regression, significantly outperforming
baselines. Further, we present real-world robotic experiments demonstrating the
usage of the learned object embeddings in task planning for sequential
manipulation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Building Segmentation for Off-Nadir Satellite Imagery. (arXiv:2109.03961v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03961">
<div class="article-summary-box-inner">
<span><p>Automatic building segmentation is an important task for satellite imagery
analysis and scene understanding. Most existing segmentation methods focus on
the case where the images are taken from directly overhead (i.e., low
off-nadir/viewing angle). These methods often fail to provide accurate results
on satellite images with larger off-nadir angles due to the higher noise level
and lower spatial resolution. In this paper, we propose a method that is able
to provide accurate building segmentation for satellite imagery captured from a
large range of off-nadir angles. Based on Bayesian deep learning, we explicitly
design our method to learn the data noise via aleatoric and epistemic
uncertainty modeling. Satellite image metadata (e.g., off-nadir angle and
ground sample distance) is also used in our model to further improve the
result. We show that with uncertainty modeling and metadata injection, our
method achieves better performance than the baseline method, especially for
noisy images taken from large off-nadir angles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Deep Metric Learning by Divide and Conquer. (arXiv:2109.04003v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04003">
<div class="article-summary-box-inner">
<span><p>Deep metric learning (DML) is a cornerstone of many computer vision
applications. It aims at learning a mapping from the input domain to an
embedding space, where semantically similar objects are located nearby and
dissimilar objects far from another. The target similarity on the training data
is defined by user in form of ground-truth class labels. However, while the
embedding space learns to mimic the user-provided similarity on the training
data, it should also generalize to novel categories not seen during training.
Besides user-provided groundtruth training labels, a lot of additional visual
factors (such as viewpoint changes or shape peculiarities) exist and imply
different notions of similarity between objects, affecting the generalization
on the images unseen during training. However, existing approaches usually
directly learn a single embedding space on all available training data,
struggling to encode all different types of relationships, and do not
generalize well. We propose to build a more expressive representation by
jointly splitting the embedding space and the data hierarchically into smaller
sub-parts. We successively focus on smaller subsets of the training data,
reducing its variance and learning a different embedding subspace for each data
subset. Moreover, the subspaces are learned jointly to cover not only the
intricacies, but the breadth of the data as well. Only after that, we build the
final embedding from the subspaces in the conquering stage. The proposed
algorithm acts as a transparent wrapper that can be placed around arbitrary
existing DML methods. Our approach significantly improves upon the
state-of-the-art on image retrieval, clustering, and re-identification tasks
evaluated using CUB200-2011, CARS196, Stanford Online Products, In-shop
Clothes, and PKU VehicleID datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modified Supervised Contrastive Learning for Detecting Anomalous Driving Behaviours. (arXiv:2109.04021v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04021">
<div class="article-summary-box-inner">
<span><p>Detecting distracted driving behaviours is important to reduce millions of
deaths and injuries occurring worldwide. Distracted or anomalous driving
behaviours are deviations from the 'normal' driving that need to be identified
correctly to alert the driver. However, these driving behaviours do not
comprise of one specific type of driving style and their distribution can be
different during training and testing phases of a classifier. We formulate this
problem as a supervised contrastive learning approach to learn a visual
representation to detect normal, and seen and unseen anomalous driving
behaviours. We made a change to the standard contrastive loss function to
adjust the similarity of negative pairs to aid the optimization. Normally, the
(self) supervised contrastive framework contains an encoder followed by a
projection head, which is omitted during testing phase as the encoding layers
are considered to contain general visual representative information. However,
we assert that for supervised contrastive learning task, including projection
head will be beneficial. We showed our results on a Driver Anomaly Detection
dataset that contains 783 minutes of video recordings of normal and anomalous
driving behaviours of 31 drivers from various from top and front cameras (both
depth and infrared). We also performed an extra step of fine tuning the labels
in this dataset. Out of 9 video modalities combinations, our modified
contrastive approach improved the ROC AUC on 7 in comparison to the baseline
models (from 3.12% to 8.91% for different modalities); the remaining two models
also had manual labelling. We performed statistical tests that showed evidence
that our modifications perform better than the baseline contrastive models.
Finally, the results showed that the fusion of depth and infrared modalities
from top and front view achieved the best AUC ROC of 0.9738 and AUC PR of
0.9772.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Tensor Network Representation for High-Order Tensor Completion. (arXiv:2109.04022v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04022">
<div class="article-summary-box-inner">
<span><p>This work studies the problem of high-dimensional data (referred to tensors)
completion from partially observed samplings. We consider that a tensor is a
superposition of multiple low-rank components. In particular, each component
can be represented as multilinear connections over several latent factors and
naturally mapped to a specific tensor network (TN) topology. In this paper, we
propose a fundamental tensor decomposition (TD) framework: Multi-Tensor Network
Representation (MTNR), which can be regarded as a linear combination of a range
of TD models, e.g., CANDECOMP/PARAFAC (CP) decomposition, Tensor Train (TT),
and Tensor Ring (TR). Specifically, MTNR represents a high-order tensor as the
addition of multiple TN models, and the topology of each TN is automatically
generated instead of manually pre-designed. For the optimization phase, an
adaptive topology learning (ATL) algorithm is presented to obtain latent
factors of each TN based on a rank incremental strategy and a projection error
measurement strategy. In addition, we theoretically establish the fundamental
multilinear operations for the tensors with TN representation, and reveal the
structural transformation of MTNR to a single TN. Finally, MTNR is applied to a
typical task, tensor completion, and two effective algorithms are proposed for
the exact recovery of incomplete data based on the Alternating Least Squares
(ALS) scheme and Alternating Direction Method of Multiplier (ADMM) framework.
Extensive numerical experiments on synthetic data and real-world datasets
demonstrate the effectiveness of MTNR compared with the start-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ACP++: Action Co-occurrence Priors for Human-Object Interaction Detection. (arXiv:2109.04047v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04047">
<div class="article-summary-box-inner">
<span><p>A common problem in the task of human-object interaction (HOI) detection is
that numerous HOI classes have only a small number of labeled examples,
resulting in training sets with a long-tailed distribution. The lack of
positive labels can lead to low classification accuracy for these classes.
Towards addressing this issue, we observe that there exist natural correlations
and anti-correlations among human-object interactions. In this paper, we model
the correlations as action co-occurrence matrices and present techniques to
learn these priors and leverage them for more effective training, especially on
rare classes. The efficacy of our approach is demonstrated experimentally,
where the performance of our approach consistently improves over the
state-of-the-art methods on both of the two leading HOI detection benchmark
datasets, HICO-Det and V-COCO.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Application of the Singular Spectrum Analysis on electroluminescence images of thin-film photovoltaic modules. (arXiv:2109.04048v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04048">
<div class="article-summary-box-inner">
<span><p>This paper discusses an application of the singular spectrum analysis method
(SSA) in the context of electroluminescence (EL) images of thin-film
photovoltaic (PV) modules. We propose an EL image decomposition as a sum of
three components: global intensity, cell, and aperiodic components. A
parametric model of the extracted signal is used to perform several image
processing tasks. The cell component is used to identify interconnection lines
between PV cells at sub-pixel accuracy, as well as to correct incorrect
stitching of EL images. Furthermore, an explicit expression of the cell
component signal is used to estimate the inverse characteristic length, a
physical parameter related to the resistances in a PV module.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self Supervision to Distillation for Long-Tailed Visual Recognition. (arXiv:2109.04075v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04075">
<div class="article-summary-box-inner">
<span><p>Deep learning has achieved remarkable progress for visual recognition on
large-scale balanced datasets but still performs poorly on real-world
long-tailed data. Previous methods often adopt class re-balanced training
strategies to effectively alleviate the imbalance issue, but might be a risk of
over-fitting tail classes. The recent decoupling method overcomes over-fitting
issues by using a multi-stage training scheme, yet, it is still incapable of
capturing tail class information in the feature learning stage. In this paper,
we show that soft label can serve as a powerful solution to incorporate label
correlation into a multi-stage training scheme for long-tailed recognition. The
intrinsic relation between classes embodied by soft labels turns out to be
helpful for long-tailed recognition by transferring knowledge from head to tail
classes.
</p>
<p>Specifically, we propose a conceptually simple yet particularly effective
multi-stage training scheme, termed as Self Supervised to Distillation (SSD).
This scheme is composed of two parts. First, we introduce a self-distillation
framework for long-tailed recognition, which can mine the label relation
automatically. Second, we present a new distillation label generation module
guided by self-supervision. The distilled labels integrate information from
both label and data domains that can model long-tailed distribution
effectively. We conduct extensive experiments and our method achieves the
state-of-the-art results on three long-tailed recognition benchmarks:
ImageNet-LT, CIFAR100-LT and iNaturalist 2018. Our SSD outperforms the strong
LWS baseline by from $2.7\%$ to $4.5\%$ on various datasets. The code is
available at https://github.com/MCG-NJU/SSD-LT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Cross-Scale Visual Representations for Real-Time Image Geo-Localization. (arXiv:2109.04087v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04087">
<div class="article-summary-box-inner">
<span><p>Robot localization remains a challenging task in GPS denied environments.
State estimation approaches based on local sensors, e.g. cameras or IMUs, are
drifting-prone for long-range missions as error accumulates. In this study, we
aim to address this problem by localizing image observations in a 2D
multi-modal geospatial map. We introduce the cross-scale dataset and a
methodology to produce additional data from cross-modality sources. We propose
a framework that learns cross-scale visual representations without supervision.
Experiments are conducted on data from two different domains, underwater and
aerial. In contrast to existing studies in cross-view image geo-localization,
our approach a) performs better on smaller-scale multi-modal maps; b) is more
computationally efficient for real-time applications; c) can serve directly in
concert with state estimation pipelines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Taming Self-Supervised Learning for Presentation Attack Detection: In-Image De-Folding and Out-of-Image De-Mixing. (arXiv:2109.04100v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04100">
<div class="article-summary-box-inner">
<span><p>Biometric systems are vulnerable to the Presentation Attacks (PA) performed
using various Presentation Attack Instruments (PAIs). Even though there are
numerous Presentation Attack Detection (PAD) techniques based on both deep
learning and hand-crafted features, the generalization of PAD for unknown PAI
is still a challenging problem. The common problem with existing deep
learning-based PAD techniques is that they may struggle with local optima,
resulting in weak generalization against different PAs. In this work, we
propose to use self-supervised learning to find a reasonable initialization
against local trap, so as to improve the generalization ability in detecting
PAs on the biometric system.The proposed method, denoted as IF-OM, is based on
a global-local view coupled with De-Folding and De-Mixing to derive the
task-specific representation for PAD.During De-Folding, the proposed technique
will learn region-specific features to represent samples in a local pattern by
explicitly maximizing cycle consistency. While, De-Mixing drives detectors to
obtain the instance-specific features with global information for more
comprehensive representation by maximizing topological consistency. Extensive
experimental results show that the proposed method can achieve significant
improvements in terms of both face and fingerprint PAD in more complicated and
hybrid datasets, when compared with the state-of-the-art methods. Specifically,
when training in CASIA-FASD and Idiap Replay-Attack, the proposed method can
achieve 18.60% Equal Error Rate (EER) in OULU-NPU and MSU-MFSD, exceeding
baseline performance by 9.54%. Code will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HSMD: An object motion detection algorithm using a Hybrid Spiking Neural Network Architecture. (arXiv:2109.04119v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04119">
<div class="article-summary-box-inner">
<span><p>The detection of moving objects is a trivial task performed by vertebrate
retinas, yet a complex computer vision task. Object-motion-sensitive ganglion
cells (OMS-GC) are specialised cells in the retina that sense moving objects.
OMS-GC take as input continuous signals and produce spike patterns as output,
that are transmitted to the Visual Cortex via the optic nerve. The Hybrid
Sensitive Motion Detector (HSMD) algorithm proposed in this work enhances the
GSOC dynamic background subtraction (DBS) algorithm with a customised 3-layer
spiking neural network (SNN) that outputs spiking responses akin to the OMS-GC.
The algorithm was compared against existing background subtraction (BS)
approaches, available on the OpenCV library, specifically on the 2012 change
detection (CDnet2012) and the 2014 change detection (CDnet2014) benchmark
datasets. The results show that the HSMD was ranked overall first among the
competing approaches and has performed better than all the other algorithms on
four of the categories across all the eight test metrics. Furthermore, the HSMD
proposed in this paper is the first to use an SNN to enhance an existing state
of the art DBS (GSOC) algorithm and the results demonstrate that the SNN
provides near real-time performance in realistic applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tiny CNN for feature point description for document analysis: approach and dataset. (arXiv:2109.04134v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04134">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the problem of feature points description in the
context of document analysis and template matching. Our study shows that the
specific training data is required for the task especially if we are to train a
lightweight neural network that will be usable on devices with limited
computational resources. In this paper, we construct and provide a dataset with
a method of training patches retrieval. We prove the effectiveness of this data
by training a lightweight neural network and show how it performs in both
documents and general patches matching. The training was done on the provided
dataset in comparison with HPatches training dataset and for the testing we use
HPatches testing framework and two publicly available datasets with various
documents pictured on complex backgrounds: MIDV-500 and MIDV-2019.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Audio-Visual Smartphone Dataset And Evaluation. (arXiv:2109.04138v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04138">
<div class="article-summary-box-inner">
<span><p>Smartphones have been employed with biometric-based verification systems to
provide security in highly sensitive applications. Audio-visual biometrics are
getting popular due to the usability and also it will be challenging to spoof
because of multi-modal nature. In this work, we present an audio-visual
smartphone dataset captured in five different recent smartphones. This new
dataset contains 103 subjects captured in three different sessions considering
the different real-world scenarios. Three different languages are acquired in
this dataset to include the problem of language dependency of the speaker
recognition systems. These unique characteristics of this dataset will pave the
way to implement novel state-of-the-art unimodal or audio-visual speaker
recognition systems. We also report the performance of the bench-marked
biometric verification systems on our dataset. The robustness of biometric
algorithms is evaluated towards multiple dependencies like signal noise,
device, language and presentation attacks like replay and synthesized signals
with extensive experiments. The obtained results raised many concerns about the
generalization properties of state-of-the-art biometrics methods in
smartphones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PIMNet: A Parallel, Iterative and Mimicking Network for Scene Text Recognition. (arXiv:2109.04145v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04145">
<div class="article-summary-box-inner">
<span><p>Nowadays, scene text recognition has attracted more and more attention due to
its various applications. Most state-of-the-art methods adopt an
encoder-decoder framework with attention mechanism, which generates text
autoregressively from left to right. Despite the convincing performance, the
speed is limited because of the one-by-one decoding strategy. As opposed to
autoregressive models, non-autoregressive models predict the results in
parallel with a much shorter inference time, but the accuracy falls behind the
autoregressive counterpart considerably. In this paper, we propose a Parallel,
Iterative and Mimicking Network (PIMNet) to balance accuracy and efficiency.
Specifically, PIMNet adopts a parallel attention mechanism to predict the text
faster and an iterative generation mechanism to make the predictions more
accurate. In each iteration, the context information is fully explored. To
improve learning of the hidden layer, we exploit the mimicking learning in the
training phase, where an additional autoregressive decoder is adopted and the
parallel decoder mimics the autoregressive decoder with fitting outputs of the
hidden layer. With the shared backbone between the two decoders, the proposed
PIMNet can be trained end-to-end without pre-training. During inference, the
branch of the autoregressive decoder is removed for a faster speed. Extensive
experiments on public benchmarks demonstrate the effectiveness and efficiency
of PIMNet. Our code will be available at https://github.com/Pay20Y/PIMNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Single Image 3D Object Estimation with Primitive Graph Networks. (arXiv:2109.04153v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04153">
<div class="article-summary-box-inner">
<span><p>Reconstructing 3D object from a single image (RGB or depth) is a fundamental
problem in visual scene understanding and yet remains challenging due to its
ill-posed nature and complexity in real-world scenes. To address those
challenges, we adopt a primitive-based representation for 3D object, and
propose a two-stage graph network for primitive-based 3D object estimation,
which consists of a sequential proposal module and a graph reasoning module.
Given a 2D image, our proposal module first generates a sequence of 3D
primitives from input image with local feature attention. Then the graph
reasoning module performs joint reasoning on a primitive graph to capture the
global shape context for each primitive. Such a framework is capable of taking
into account rich geometry and semantic constraints during 3D structure
recovery, producing 3D objects with more coherent structure even under
challenging viewing conditions. We train the entire graph neural network in a
stage-wise strategy and evaluate it on three benchmarks: Pix3D, ModelNet and
NYU Depth V2. Extensive experiments show that our approach outperforms the
previous state of the arts with a considerable margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Transferable Adversarial Attacks on Vision Transformers. (arXiv:2109.04176v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04176">
<div class="article-summary-box-inner">
<span><p>Vision transformers (ViTs) have demonstrated impressive performance on a
series of computer vision tasks, yet they still suffer from adversarial
examples. In this paper, we posit that adversarial attacks on transformers
should be specially tailored for their architecture, jointly considering both
patches and self-attention, in order to achieve high transferability. More
specifically, we introduce a dual attack framework, which contains a Pay No
Attention (PNA) attack and a PatchOut attack, to improve the transferability of
adversarial samples across different ViTs. We show that skipping the gradients
of attention during backpropagation can generate adversarial examples with high
transferability. In addition, adversarial perturbations generated by optimizing
randomly sampled subsets of patches at each iteration achieve higher attack
success rates than attacks using all patches. We evaluate the transferability
of attacks on state-of-the-art ViTs, CNNs and robustly trained CNNs. The
results of these experiments demonstrate that the proposed dual attack can
greatly boost transferability between ViTs and from ViTs to CNNs. In addition,
the proposed method can easily be combined with existing transfer methods to
boost performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-grained Data Distribution Alignment for Post-Training Quantization. (arXiv:2109.04186v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04186">
<div class="article-summary-box-inner">
<span><p>While post-training quantization receives popularity mostly due to its
evasion in accessing the original complete training dataset, its poor
performance also stems from this limitation. To alleviate this limitation, in
this paper, we leverage the synthetic data introduced by zero-shot quantization
with calibration dataset and we propose a fine-grained data distribution
alignment (FDDA) method to boost the performance of post-training quantization.
The method is based on two important properties of batch normalization
statistics (BNS) we observed in deep layers of the trained network, i.e.,
inter-class separation and intra-class incohesion. To preserve this
fine-grained distribution information: 1) We calculate the per-class BNS of the
calibration dataset as the BNS centers of each class and propose a
BNS-centralized loss to force the synthetic data distributions of different
classes to be close to their own centers. 2) We add Gaussian noise into the
centers to imitate the incohesion and propose a BNS-distorted loss to force the
synthetic data distribution of the same class to be close to the distorted
centers. By introducing these two fine-grained losses, our method shows the
state-of-the-art performance on ImageNet, especially when the first and last
layers are quantized to low-bit as well. Our project is available at
https://github.com/viperit/FDDA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Fully Automated Segmentation of Rat Cardiac MRI by Leveraging Deep Learning Frameworks. (arXiv:2109.04188v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04188">
<div class="article-summary-box-inner">
<span><p>Automated segmentation of human cardiac magnetic resonance datasets has been
steadily improving during recent years. However, these methods are not directly
applicable in preclinical context due to limited datasets and lower image
resolution. Successful application of deep architectures for rat cardiac
segmentation, although of critical importance for preclinical evaluation of
cardiac function, has to our knowledge not yet been reported. We developed
segmentation models that expand on the standard U-Net architecture and
evaluated separate models for systole and diastole phases, 2MSA, and one model
for all timepoints, 1MSA. Furthermore, we calibrated model outputs using a
Gaussian Process (GP)-based prior to improve phase selection. Resulting models
approach human performance in terms of left ventricular segmentation quality
and ejection fraction (EF) estimation in both 1MSA and 2MSA settings
(S{\o}rensen-Dice score 0.91 +/- 0.072 and 0.93 +/- 0.032, respectively). 2MSA
achieved a mean absolute difference between estimated and reference EF of 3.5
+/- 2.5 %, while 1MSA resulted in 4.1 +/- 3.0 %. Applying Gaussian Processes to
1MSA allows to automate the selection of systole and diastole phases. Combined
with a novel cardiac phase selection strategy, our work presents an important
first step towards a fully automated segmentation pipeline in the context of
rat cardiac analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IMG2SMI: Translating Molecular Structure Images to Simplified Molecular-input Line-entry System. (arXiv:2109.04202v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04202">
<div class="article-summary-box-inner">
<span><p>Like many scientific fields, new chemistry literature has grown at a
staggering pace, with thousands of papers released every month. A large portion
of chemistry literature focuses on new molecules and reactions between
molecules. Most vital information is conveyed through 2-D images of molecules,
representing the underlying molecules or reactions described. In order to
ensure reproducible and machine-readable molecule representations, text-based
molecule descriptors like SMILES and SELFIES were created. These text-based
molecule representations provide molecule generation but are unfortunately
rarely present in published literature. In the absence of molecule descriptors,
the generation of molecule descriptors from the 2-D images present in the
literature is necessary to understand chemistry literature at scale. Successful
methods such as Optical Structure Recognition Application (OSRA), and
ChemSchematicResolver are able to extract the locations of molecules structures
in chemistry papers and infer molecular descriptions and reactions. While
effective, existing systems expect chemists to correct outputs, making them
unsuitable for unsupervised large-scale data mining. Leveraging the task
formulation of image captioning introduced by DECIMER, we introduce IMG2SMI, a
model which leverages Deep Residual Networks for image feature extraction and
an encoder-decoder Transformer layers for molecule description generation.
Unlike previous Neural Network-based systems, IMG2SMI builds around the task of
molecule description generation, which enables IMG2SMI to outperform OSRA-based
systems by 163% in molecule similarity prediction as measured by the molecular
MACCS Fingerprint Tanimoto Similarity. Additionally, to facilitate further
research on this task, we release a new molecule prediction dataset. including
81 million molecules for molecule description generation
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IICNet: A Generic Framework for Reversible Image Conversion. (arXiv:2109.04242v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04242">
<div class="article-summary-box-inner">
<span><p>Reversible image conversion (RIC) aims to build a reversible transformation
between specific visual content (e.g., short videos) and an embedding image,
where the original content can be restored from the embedding when necessary.
This work develops Invertible Image Conversion Net (IICNet) as a generic
solution to various RIC tasks due to its strong capacity and task-independent
design. Unlike previous encoder-decoder based methods, IICNet maintains a
highly invertible structure based on invertible neural networks (INNs) to
better preserve the information during conversion. We use a relation module and
a channel squeeze layer to improve the INN nonlinearity to extract cross-image
relations and the network flexibility, respectively. Experimental results
demonstrate that IICNet outperforms the specifically-designed methods on
existing RIC tasks and can generalize well to various newly-explored tasks.
With our generic IICNet, we no longer need to hand-engineer task-specific
embedding networks for rapidly occurring visual content. Our source codes are
available at: https://github.com/felixcheng97/IICNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M5Product: A Multi-modal Pretraining Benchmark for E-commercial Product Downstream Tasks. (arXiv:2109.04275v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04275">
<div class="article-summary-box-inner">
<span><p>In this paper, we aim to advance the research of multi-modal pre-training on
E-commerce and subsequently contribute a large-scale dataset, named M5Product,
which consists of over 6 million multimodal pairs, covering more than 6,000
categories and 5,000 attributes. Generally, existing multi-modal datasets are
either limited in scale or modality diversity. Differently, our M5Product is
featured from the following aspects. First, the M5Product dataset is 500 times
larger than the public multimodal dataset with the same number of modalities
and nearly twice larger compared with the largest available text-image
cross-modal dataset. Second, the dataset contains rich information of multiple
modalities including image, text, table, video and audio, in which each
modality can capture different views of semantic information (e.g. category,
attributes, affordance, brand, preference) and complements the other. Third, to
better accommodate with real-world problems, a few portion of M5Product
contains incomplete modality pairs and noises while having the long-tailed
distribution, which aligns well with real-world scenarios. Finally, we provide
a baseline model M5-MMT that makes the first attempt to integrate the different
modality configuration into an unified model for feature fusion to address the
great challenge for semantic alignment. We also evaluate various multi-model
pre-training state-of-the-arts for benchmarking their capabilities in learning
from unlabeled data under the different number of modalities on the M5Product
dataset. We conduct extensive experiments on four downstream tasks and provide
some interesting findings on these modalities. Our dataset and related code are
available at https://xiaodongsuper.github.io/M5Product_dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robust Cross-domain Image Understanding with Unsupervised Noise Removal. (arXiv:2109.04284v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04284">
<div class="article-summary-box-inner">
<span><p>Deep learning models usually require a large amount of labeled data to
achieve satisfactory performance. In multimedia analysis, domain adaptation
studies the problem of cross-domain knowledge transfer from a label rich source
domain to a label scarce target domain, thus potentially alleviates the
annotation requirement for deep learning models. However, we find that
contemporary domain adaptation methods for cross-domain image understanding
perform poorly when source domain is noisy. Weakly Supervised Domain Adaptation
(WSDA) studies the domain adaptation problem under the scenario where source
data can be noisy. Prior methods on WSDA remove noisy source data and align the
marginal distribution across domains without considering the fine-grained
semantic structure in the embedding space, which have the problem of class
misalignment, e.g., features of cats in the target domain might be mapped near
features of dogs in the source domain. In this paper, we propose a novel
method, termed Noise Tolerant Domain Adaptation, for WSDA. Specifically, we
adopt the cluster assumption and learn cluster discriminatively with class
prototypes in the embedding space. We propose to leverage the location
information of the data points in the embedding space and model the location
information with a Gaussian mixture model to identify noisy source data. We
then design a network which incorporates the Gaussian mixture noise model as a
sub-module for unsupervised noise removal and propose a novel cluster-level
adversarial adaptation method which aligns unlabeled target data with the less
noisy class prototypes for mapping the semantic structure across domains. We
conduct extensive experiments to evaluate the effectiveness of our method on
both general images and medical images from COVID-19 and e-commerce datasets.
The results show that our method significantly outperforms state-of-the-art
WSDA methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Energy-Efficient Mobile Robot Control via Run-time Monitoring of Environmental Complexity and Computing Workload. (arXiv:2109.04285v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04285">
<div class="article-summary-box-inner">
<span><p>We propose an energy-efficient controller to minimize the energy consumption
of a mobile robot by dynamically manipulating the mechanical and computational
actuators of the robot. The mobile robot performs real-time vision-based
applications based on an event-based camera. The actuators of the controller
are CPU voltage/frequency for the computation part and motor voltage for the
mechanical part. We show that independently considering speed control of the
robot and voltage/frequency control of the CPU does not necessarily result in
an energy-efficient solution. In fact, to obtain the highest efficiency, the
computation and mechanical parts should be controlled together in synergy. We
propose a fast hill-climbing optimization algorithm to allow the controller to
find the best CPU/motor configuration at run-time and whenever the mobile robot
is facing a new environment during its travel. Experimental results on a robot
with Brushless DC Motors, Jetson TX2 board as the computing unit, and a
DAVIS-346 event-based camera show that the proposed control algorithm can save
battery energy by an average of 50.5%, 41%, and 30%, in low-complexity,
medium-complexity, and high-complexity environments, over baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Video-Text Retrieval by Multi-Stream Corpus Alignment and Dual Softmax Loss. (arXiv:2109.04290v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04290">
<div class="article-summary-box-inner">
<span><p>Employing large-scale pre-trained model CLIP to conduct video-text retrieval
task (VTR) has become a new trend, which exceeds previous VTR methods. Though,
due to the heterogeneity of structures and contents between video and text,
previous CLIP-based models are prone to overfitting in the training phase,
resulting in relatively poor retrieval performance. In this paper, we propose a
multi-stream Corpus Alignment network with single gate Mixture-of-Experts
(CAMoE) and a novel Dual Softmax Loss (DSL) to solve the two heterogeneity. The
CAMoE employs Mixture-of-Experts (MoE) to extract multi-perspective video
representations, including action, entity, scene, etc., then align them with
the corresponding part of the text. In this stage, we conduct massive
explorations towards the feature extraction module and feature alignment
module. DSL is proposed to avoid the one-way optimum-match which occurs in
previous contrastive methods. Introducing the intrinsic prior of each pair in a
batch, DSL serves as a reviser to correct the similarity matrix and achieves
the dual optimal match. DSL is easy to implement with only one-line code but
improves significantly. The results show that the proposed CAMoE and DSL are of
strong efficiency, and each of them is capable of achieving State-of-The-Art
(SOTA) individually on various benchmarks such as MSR-VTT, MSVD, and LSMDC.
Further, with both of them, the performance is advanced to a big extend,
surpassing the previous SOTA methods for around 4.6\% R@1 in MSR-VTT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Energy Attack: On Transferring Adversarial Examples. (arXiv:2109.04300v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04300">
<div class="article-summary-box-inner">
<span><p>In this work we propose Energy Attack, a transfer-based black-box
$L_\infty$-adversarial attack. The attack is parameter-free and does not
require gradient approximation. In particular, we first obtain white-box
adversarial perturbations of a surrogate model and divide these perturbations
into small patches. Then we extract the unit component vectors and eigenvalues
of these patches with principal component analysis (PCA). Base on the
eigenvalues, we can model the energy distribution of adversarial perturbations.
We then perform black-box attacks by sampling from the perturbation patches
according to their energy distribution, and tiling the sampled patches to form
a full-size adversarial perturbation. This can be done without the available
access to victim models. Extensive experiments well demonstrate that the
proposed Energy Attack achieves state-of-the-art performance in black-box
attacks on various models and several datasets. Moreover, the extracted
distribution is able to transfer among different model architectures and
different datasets, and is therefore intrinsic to vision architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Hough Voting for Robust Global Registration. (arXiv:2109.04310v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04310">
<div class="article-summary-box-inner">
<span><p>Point cloud registration is the task of estimating the rigid transformation
that aligns a pair of point cloud fragments. We present an efficient and robust
framework for pairwise registration of real-world 3D scans, leveraging Hough
voting in the 6D transformation parameter space. First, deep geometric features
are extracted from a point cloud pair to compute putative correspondences. We
then construct a set of triplets of correspondences to cast votes on the 6D
Hough space, representing the transformation parameters in sparse tensors.
Next, a fully convolutional refinement module is applied to refine the noisy
votes. Finally, we identify the consensus among the correspondences from the
Hough space, which we use to predict our final transformation parameters. Our
method outperforms state-of-the-art methods on 3DMatch and 3DLoMatch benchmarks
while achieving comparable performance on KITTI odometry dataset. We further
demonstrate the generalizability of our approach by setting a new
state-of-the-art on ICL-NUIM dataset, where we integrate our module into a
multi-way registration pipeline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuous Event-Line Constraint for Closed-Form Velocity Initialization. (arXiv:2109.04313v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04313">
<div class="article-summary-box-inner">
<span><p>Event cameras trigger events asynchronously and independently upon a
sufficient change of the logarithmic brightness level. The neuromorphic sensor
has several advantages over standard cameras including low latency, absence of
motion blur, and high dynamic range. Event cameras are particularly well suited
to sense motion dynamics in agile scenarios. We propose the continuous
event-line constraint, which relies on a constant-velocity motion assumption as
well as trifocal tensor geometry in order to express a relationship between
line observations given by event clusters as well as first-order camera
dynamics. Our core result is a closed-form solver for up-to-scale linear camera
velocity {with known angular velocity}. Nonlinear optimization is adopted to
improve the performance of the algorithm. The feasibility of the approach is
demonstrated through a careful analysis on both simulated and real data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise Perspective with Transformer. (arXiv:2109.04335v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04335">
<div class="article-summary-box-inner">
<span><p>Most recent semantic segmentation methods adopt a U-Net framework with an
encoder-decoder architecture. It is still challenging for U-Net with a simple
skip connection scheme to model the global multi-scale context: 1) Not each
skip connection setting is effective due to the issue of incompatible feature
sets of encoder and decoder stage, even some skip connection negatively
influence the segmentation performance; 2) The original U-Net is worse than the
one without any skip connection on some datasets. Based on our findings, we
propose a new segmentation framework, named UCTransNet (with a proposed CTrans
module in U-Net), from the channel perspective with attention mechanism.
Specifically, the CTrans module is an alternate of the U-Net skip connections,
which consists of a sub-module to conduct the multi-scale Channel Cross fusion
with Transformer (named CCT) and a sub-module Channel-wise Cross-Attention
(named CCA) to guide the fused multi-scale channel-wise information to
effectively connect to the decoder features for eliminating the ambiguity.
Hence, the proposed connection consisting of the CCT and CCA is able to replace
the original skip connection to solve the semantic gaps for an accurate
automatic medical image segmentation. The experimental results suggest that our
UCTransNet produces more precise segmentation performance and achieves
consistent improvements over the state-of-the-art for semantic segmentation
across different datasets and conventional architectures involving transformer
or U-shaped framework. Code: https://github.com/McGregorWwww/UCTransNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PhysGNN: A Physics-Driven Graph Neural Network Based Model for Predicting Soft Tissue Deformation in Image-Guided Neurosurgery. (arXiv:2109.04352v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04352">
<div class="article-summary-box-inner">
<span><p>Correctly capturing intraoperative brain shift in image-guided neurosurgical
procedures is a critical task for aligning preoperative data with
intraoperative geometry, ensuring effective surgical navigation and optimal
surgical precision. While the finite element method (FEM) is a proven technique
to effectively approximate soft tissue deformation through biomechanical
formulations, their degree of success boils down to a trade-off between
accuracy and speed. To circumvent this problem, the most recent works in this
domain have proposed leveraging data-driven models obtained by training various
machine learning algorithms, e.g. random forests, artificial neural networks
(ANNs), with the results of finite element analysis (FEA) to speed up tissue
deformation approximations by prediction. These methods, however, do not
account for the structure of the finite element (FE) mesh during training that
provides information on node connectivities as well as the distance between
them, which can aid with approximating tissue deformation based on the
proximity of force load points with the rest of the mesh nodes. Therefore, this
work proposes a novel framework, PhysGNN, a data-driven model that approximates
the solution of FEA by leveraging graph neural networks (GNNs), which are
capable of accounting for the mesh structural information and inductive
learning over unstructured grids and complex topological structures.
Empirically, we demonstrate that the proposed architecture, PhysGNN, promises
accurate and fast soft tissue deformation approximations while remaining
computationally feasible, suitable for neurosurgical settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IFBiD: Inference-Free Bias Detection. (arXiv:2109.04374v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04374">
<div class="article-summary-box-inner">
<span><p>This paper is the first to explore an automatic way to detect bias in deep
convolutional neural networks by simply looking at their weights. Furthermore,
it is also a step towards understanding neural networks and how they work. We
show that it is indeed possible to know if a model is biased or not simply by
looking at its weights, without the model inference for an specific input. We
analyze how bias is encoded in the weights of deep networks through a toy
example using the Colored MNIST database and we also provide a realistic case
study in gender detection from face images using state-of-the-art methods and
experimental resources. To do so, we generated two databases with 36K and 48K
biased models each. In the MNIST models we were able to detect whether they
presented a strong or low bias with more than 99% accuracy, and we were also
able to classify between four levels of bias with more than 70% accuracy. For
the face models, we achieved 90% accuracy in distinguishing between models
biased towards Asian, Black, or Caucasian ethnicity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Modeling of Hand-Object Interactions via Tactile Sensing. (arXiv:2109.04378v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04378">
<div class="article-summary-box-inner">
<span><p>Tactile sensing is critical for humans to perform everyday tasks. While
significant progress has been made in analyzing object grasping from vision, it
remains unclear how we can utilize tactile sensing to reason about and model
the dynamics of hand-object interactions. In this work, we employ a
high-resolution tactile glove to perform four different interactive activities
on a diversified set of objects. We build our model on a cross-modal learning
framework and generate the labels using a visual processing pipeline to
supervise the tactile model, which can then be used on its own during the test
time. The tactile model aims to predict the 3d locations of both the hand and
the object purely from the touch data by combining a predictive model and a
contrastive learning module. This framework can reason about the interaction
patterns from the tactile data, hallucinate the changes in the environment,
estimate the uncertainty of the prediction, and generalize to unseen objects.
We also provide detailed ablation studies regarding different system designs as
well as visualizations of the predicted trajectories. This work takes a step on
dynamics modeling in hand-object interactions from dense tactile sensing, which
opens the door for future applications in activity learning, human-computer
interactions, and imitation learning for robotics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Preservational Learning Improves Self-supervised Medical Image Models by Reconstructing Diverse Contexts. (arXiv:2109.04379v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04379">
<div class="article-summary-box-inner">
<span><p>Preserving maximal information is one of principles of designing
self-supervised learning methodologies. To reach this goal, contrastive
learning adopts an implicit way which is contrasting image pairs. However, we
believe it is not fully optimal to simply use the contrastive estimation for
preservation. Moreover, it is necessary and complemental to introduce an
explicit solution to preserve more information. From this perspective, we
introduce Preservational Learning to reconstruct diverse image contexts in
order to preserve more information in learned representations. Together with
the contrastive loss, we present Preservational Contrastive Representation
Learning (PCRL) for learning self-supervised medical representations. PCRL
provides very competitive results under the pretraining-finetuning protocol,
outperforming both self-supervised and supervised counterparts in 5
classification/segmentation tasks substantially.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Copy-Move Image Forgery Detection Based on Evolving Circular Domains Coverage. (arXiv:2109.04381v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04381">
<div class="article-summary-box-inner">
<span><p>The aim of this paper is to improve the accuracy of copy-move forgery
detection (CMFD) in image forensics by proposing a novel scheme. The proposed
scheme integrates both block-based and keypoint-based forgery detection
methods. Firstly, speed-up robust feature (SURF) descriptor in log-polar space
and scale invariant feature transform (SIFT) descriptor are extracted from an
entire forged image. Secondly, generalized 2 nearest neighbor (g2NN) is
employed to get massive matched pairs. Then, random sample consensus (RANSAC)
algorithm is employed to filter out mismatched pairs, thus allowing rough
localization of the counterfeit areas. To present more accurately these forgery
areas more accurately, we propose an efficient and accurate algorithm, evolving
circular domains coverage (ECDC), to cover present them. This algorithm aims to
find satisfactory threshold areas by extracting block features from jointly
evolving circular domains, which are centered on the matched pairs. Finally,
morphological operation is applied to refine the detected forgery areas. The
experimental results indicate that the proposed CMFD scheme can achieve better
detection performance under various attacks compared with other
state-of-the-art CMFD schemes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ErfAct: Non-monotonic smooth trainable Activation Functions. (arXiv:2109.04386v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04386">
<div class="article-summary-box-inner">
<span><p>An activation function is a crucial component of a neural network that
introduces non-linearity in the network. The state-of-the-art performance of a
neural network depends on the perfect choice of an activation function. We
propose two novel non-monotonic smooth trainable activation functions, called
ErfAct-1 and ErfAct-2. Experiments suggest that the proposed functions improve
the network performance significantly compared to the widely used activations
like ReLU, Swish, and Mish. Replacing ReLU by ErfAct-1 and ErfAct-2, we have
5.21% and 5.04% improvement for top-1 accuracy on PreactResNet-34 network in
CIFAR100 dataset, 2.58% and 2.76% improvement for top-1 accuracy on
PreactResNet-34 network in CIFAR10 dataset, 1.0%, and 1.0% improvement on mean
average precision (mAP) on SSD300 model in Pascal VOC dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fair Conformal Predictors for Applications in Medical Imaging. (arXiv:2109.04392v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04392">
<div class="article-summary-box-inner">
<span><p>Deep learning has the potential to augment many components of the clinical
workflow, such as medical image interpretation. However, the translation of
these black box algorithms into clinical practice has been marred by the
relative lack of transparency compared to conventional machine learning
methods, hindering in clinician trust in the systems for critical medical
decision-making. Specifically, common deep learning approaches do not have
intuitive ways of expressing uncertainty with respect to cases that might
require further human review. Furthermore, the possibility of algorithmic bias
has caused hesitancy regarding the use of developed algorithms in clinical
settings. To these ends, we explore how conformal methods can complement deep
learning models by providing both clinically intuitive way (by means of
confidence prediction sets) of expressing model uncertainty as well as
facilitating model transparency in clinical workflows. In this paper, we
conduct a field survey with clinicians to assess clinical use-cases of
conformal predictions. Next, we conduct experiments with a mammographic breast
density and dermatology photography datasets to demonstrate the utility of
conformal predictions in "rule-in" and "rule-out" disease scenarios. Further,
we show that conformal predictors can be used to equalize coverage with respect
to patient demographics such as race and skin tone. We find that a conformal
predictions to be a promising framework with potential to increase clinical
usability and transparency for better collaboration between deep learning
algorithms and clinicians.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural-IMLS: Learning Implicit Moving Least-Squares for Surface Reconstruction from Unoriented Point clouds. (arXiv:2109.04398v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04398">
<div class="article-summary-box-inner">
<span><p>Surface reconstruction from noisy, non-uniformly, and unoriented point clouds
is a fascinating yet difficult problem in computer vision and computer
graphics. In this paper, we propose Neural-IMLS, a novel approach that learning
noise-resistant signed distance function (SDF) for reconstruction. Instead of
explicitly learning priors with the ground-truth signed distance values, our
method learns the SDF from raw point clouds directly in a self-supervised
fashion by minimizing the loss between the couple of SDFs, one obtained by the
implicit moving least-square function (IMLS) and the other by our network.
Finally, a watertight and smooth 2-manifold triangle mesh is yielded by running
Marching Cubes. We conduct extensive experiments on various benchmarks to
demonstrate the performance of Neural-IMLS, especially for point clouds with
noise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reconstructing and grounding narrated instructional videos in 3D. (arXiv:2109.04409v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04409">
<div class="article-summary-box-inner">
<span><p>Narrated instructional videos often show and describe manipulations of
similar objects, e.g., repairing a particular model of a car or laptop. In this
work we aim to reconstruct such objects and to localize associated narrations
in 3D. Contrary to the standard scenario of instance-level 3D reconstruction,
where identical objects or scenes are present in all views, objects in
different instructional videos may have large appearance variations given
varying conditions and versions of the same product. Narrations may also have
large variation in natural language expressions. We address these challenges by
three contributions. First, we propose an approach for correspondence
estimation combining learnt local features and dense flow. Second, we design a
two-step divide and conquer reconstruction approach where the initial 3D
reconstructions of individual videos are combined into a 3D alignment graph.
Finally, we propose an unsupervised approach to ground natural language in
obtained 3D reconstructions. We demonstrate the effectiveness of our approach
for the domain of car maintenance. Given raw instructional videos and no manual
supervision, our method successfully reconstructs engines of different car
models and associates textual descriptions with corresponding objects in 3D.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TxT: Crossmodal End-to-End Learning with Transformers. (arXiv:2109.04422v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04422">
<div class="article-summary-box-inner">
<span><p>Reasoning over multiple modalities, e.g. in Visual Question Answering (VQA),
requires an alignment of semantic concepts across domains. Despite the
widespread success of end-to-end learning, today's multimodal pipelines by and
large leverage pre-extracted, fixed features from object detectors, typically
Faster R-CNN, as representations of the visual world. The obvious downside is
that the visual representation is not specifically tuned to the multimodal task
at hand. At the same time, while transformer-based object detectors have gained
popularity, they have not been employed in today's multimodal pipelines. We
address both shortcomings with TxT, a transformer-based crossmodal pipeline
that enables fine-tuning both language and visual components on the downstream
task in a fully end-to-end manner. We overcome existing limitations of
transformer-based detectors for multimodal reasoning regarding the integration
of global context and their scalability. Our transformer-based multimodal model
achieves considerable gains from end-to-end learning for multimodal question
answering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Talk-to-Edit: Fine-Grained Facial Editing via Dialog. (arXiv:2109.04425v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04425">
<div class="article-summary-box-inner">
<span><p>Facial editing is an important task in vision and graphics with numerous
applications. However, existing works are incapable to deliver a continuous and
fine-grained editing mode (e.g., editing a slightly smiling face to a big
laughing one) with natural interactions with users. In this work, we propose
Talk-to-Edit, an interactive facial editing framework that performs
fine-grained attribute manipulation through dialog between the user and the
system. Our key insight is to model a continual "semantic field" in the GAN
latent space. 1) Unlike previous works that regard the editing as traversing
straight lines in the latent space, here the fine-grained editing is formulated
as finding a curving trajectory that respects fine-grained attribute landscape
on the semantic field. 2) The curvature at each step is location-specific and
determined by the input image as well as the users' language requests. 3) To
engage the users in a meaningful dialog, our system generates language feedback
by considering both the user request and the current state of the semantic
field.
</p>
<p>We also contribute CelebA-Dialog, a visual-language facial editing dataset to
facilitate large-scale study. Specifically, each image has manually annotated
fine-grained attribute annotations as well as template-based textual
descriptions in natural language. Extensive quantitative and qualitative
experiments demonstrate the superiority of our framework in terms of 1) the
smoothness of fine-grained editing, 2) the identity/attribute preservation, and
3) the visual photorealism and dialog fluency. Notably, user study validates
that our overall system is consistently favored by around 80% of the
participants. Our project page is https://www.mmlab-ntu.com/project/talkedit/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers. (arXiv:2109.04448v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04448">
<div class="article-summary-box-inner">
<span><p>Pretrained vision-and-language BERTs aim to learn representations that
combine information from both modalities. We propose a diagnostic method based
on cross-modal input ablation to assess the extent to which these models
actually integrate cross-modal information. This method involves ablating
inputs from one modality, either entirely or selectively based on cross-modal
grounding alignments, and evaluating the model prediction performance on the
other modality. Model performance is measured by modality-specific tasks that
mirror the model pretraining objectives (e.g. masked language modelling for
text). Models that have learned to construct cross-modal representations using
both modalities are expected to perform worse when inputs are missing from a
modality. We find that recently proposed models have much greater relative
difficulty predicting text when visual information is ablated, compared to
predicting visual object categories when text is ablated, indicating that these
models are not symmetrically cross-modal.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConvMLP: Hierarchical Convolutional MLPs for Vision. (arXiv:2109.04454v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04454">
<div class="article-summary-box-inner">
<span><p>MLP-based architectures, which consist of a sequence of consecutive
multi-layer perceptron blocks, have recently been found to reach comparable
results to convolutional and transformer-based methods. However, most adopt
spatial MLPs which take fixed dimension inputs, therefore making it difficult
to apply them to downstream tasks, such as object detection and semantic
segmentation. Moreover, single-stage designs further limit performance in other
computer vision tasks and fully connected layers bear heavy computation. To
tackle these problems, we propose ConvMLP: a hierarchical Convolutional MLP for
visual recognition, which is a light-weight, stage-wise, co-design of
convolution layers, and MLPs. In particular, ConvMLP-S achieves 76.8% top-1
accuracy on ImageNet-1k with 9M parameters and 2.4G MACs (15% and 19% of
MLP-Mixer-B/16, respectively). Experiments on object detection and semantic
segmentation further show that visual representation learned by ConvMLP can be
seamlessly transferred and achieve competitive results with fewer parameters.
Our code and pre-trained models are publicly available at
https://github.com/SHI-Labs/Convolutional-MLPs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NEAT: Neural Attention Fields for End-to-End Autonomous Driving. (arXiv:2109.04456v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04456">
<div class="article-summary-box-inner">
<span><p>Efficient reasoning about the semantic, spatial, and temporal structure of a
scene is a crucial prerequisite for autonomous driving. We present NEural
ATtention fields (NEAT), a novel representation that enables such reasoning for
end-to-end imitation learning models. NEAT is a continuous function which maps
locations in Bird's Eye View (BEV) scene coordinates to waypoints and
semantics, using intermediate attention maps to iteratively compress
high-dimensional 2D image features into a compact representation. This allows
our model to selectively attend to relevant regions in the input while ignoring
information irrelevant to the driving task, effectively associating the images
with the BEV representation. In a new evaluation setting involving adverse
environmental conditions and challenging scenarios, NEAT outperforms several
strong baselines and achieves driving scores on par with the privileged CARLA
expert used to generate its training data. Furthermore, visualizing the
attention maps for models with NEAT intermediate representations provides
improved interpretability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Local Domains for Image-to-Image Translation. (arXiv:2109.04468v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04468">
<div class="article-summary-box-inner">
<span><p>Image-to-image (i2i) networks struggle to capture local changes because they
do not affect the global scene structure. For example, translating from highway
scenes to offroad, i2i networks easily focus on global color features but
ignore obvious traits for humans like the absence of lane markings. In this
paper, we leverage human knowledge about spatial domain characteristics which
we refer to as 'local domains' and demonstrate its benefit for image-to-image
translation. Relying on a simple geometrical guidance, we train a patch-based
GAN on few source data and hallucinate a new unseen domain which subsequently
eases transfer learning to target. We experiment on three tasks ranging from
unstructured environments to adverse weather. Our comprehensive evaluation
setting shows we are able to generate realistic translations, with minimal
priors, and training only on a few images. Furthermore, when trained on our
translations images we show that all tested proxy tasks are significantly
improved, without ever seeing target domain at training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Binary-Ternary Quantization. (arXiv:1909.12205v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.12205">
<div class="article-summary-box-inner">
<span><p>Neural network models are resource hungry. It is difficult to deploy such
deep networks on devices with limited resources, like smart wearables,
cellphones, drones, and autonomous vehicles. Low bit quantization such as
binary and ternary quantization is a common approach to alleviate this resource
requirements. Ternary quantization provides a more flexible model and
outperforms binary quantization in terms of accuracy, however doubles the
memory footprint and increases the computational cost. Contrary to these
approaches, mixed quantized models allow a trade-off between accuracy and
memory footprint. In such models, quantization depth is often chosen manually,
or is tuned using a separate optimization routine. The latter requires training
a quantized network multiple times. Here, we propose an adaptive combination of
binary and ternary quantization, namely Smart Quantization (SQ), in which the
quantization depth is modified directly via a regularization function, so that
the model is trained only once. Our experimental results show that the proposed
method adapts quantization depth successfully while keeping the model accuracy
high on MNIST and CIFAR10 benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">General Partial Label Learning via Dual Bipartite Graph Autoencoder. (arXiv:2001.01290v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.01290">
<div class="article-summary-box-inner">
<span><p>We formulate a practical yet challenging problem: General Partial Label
Learning (GPLL). Compared to the traditional Partial Label Learning (PLL)
problem, GPLL relaxes the supervision assumption from instance-level -- a label
set partially labels an instance -- to group-level: 1) a label set partially
labels a group of instances, where the within-group instance-label link
annotations are missing, and 2) cross-group links are allowed -- instances in a
group may be partially linked to the label set from another group. Such
ambiguous group-level supervision is more practical in real-world scenarios as
additional annotation on the instance-level is no longer required, e.g.,
face-naming in videos where the group consists of faces in a frame, labeled by
a name set in the corresponding caption. In this paper, we propose a novel
graph convolutional network (GCN) called Dual Bipartite Graph Autoencoder
(DB-GAE) to tackle the label ambiguity challenge of GPLL. First, we exploit the
cross-group correlations to represent the instance groups as dual bipartite
graphs: within-group and cross-group, which reciprocally complements each other
to resolve the linking ambiguities. Second, we design a GCN autoencoder to
encode and decode them, where the decodings are considered as the refined
results. It is worth noting that DB-GAE is self-supervised and transductive, as
it only uses the group-level supervision without a separate offline training
stage. Extensive experiments on two real-world datasets demonstrate that DB-GAE
significantly outperforms the best baseline over absolute 0.159 F1-score and
24.8% accuracy. We further offer analysis on various levels of label
ambiguities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sharing Matters for Generalization in Deep Metric Learning. (arXiv:2004.05582v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.05582">
<div class="article-summary-box-inner">
<span><p>Learning the similarity between images constitutes the foundation for
numerous vision tasks. The common paradigm is discriminative metric learning,
which seeks an embedding that separates different training classes. However,
the main challenge is to learn a metric that not only generalizes from training
to novel, but related, test samples. It should also transfer to different
object classes. So what complementary information is missed by the
discriminative paradigm? Besides finding characteristics that separate between
classes, we also need them to likely occur in novel categories, which is
indicated if they are shared across training classes. This work investigates
how to learn such characteristics without the need for extra annotations or
training data. By formulating our approach as a novel triplet sampling
strategy, it can be easily applied on top of recent ranking loss frameworks.
Experiments show that, independent of the underlying network architecture and
the specific ranking loss, our approach significantly improves performance in
deep metric learning, leading to new the state-of-the-art results on various
standard benchmark datasets. Preliminary early access page can be found here:
https://ieeexplore.ieee.org/document/9141449
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Localization Uncertainty Estimation for Anchor-Free Object Detection. (arXiv:2006.15607v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15607">
<div class="article-summary-box-inner">
<span><p>Since many safety-critical systems, such as surgical robots and autonomous
driving cars operate in unstable environments with sensor noise and incomplete
data, it is desirable for object detectors to take the localization uncertainty
into account. However, there are several limitations of the existing
uncertainty estimation methods for anchor-based object detection. 1) They model
the uncertainty of the heterogeneous object properties with different
characteristics and scales, such as location (center point) and scale (width,
height), which could be difficult to estimate. 2) They model box offsets as
Gaussian distributions, which is not compatible with the ground truth bounding
boxes that follow the Dirac delta distribution. 3) Since anchor-based methods
are sensitive to anchor hyperparameters, the localization uncertainty for them
could be also highly sensitive to the choice of hyperparameters as well. To
tackle these limitations, we propose a new localization uncertainty estimation
method called UAD for anchor-free object detection. Our method captures the
uncertainty in four directions of box offsets~(left, right, top, bottom) that
are homogeneous, so that it can tell which direction is uncertain, and provides
a quantitative value of uncertainty in $[0, 1]$. To enable such uncertainty
estimation, we design a new uncertainty loss, negative power log-likelihood
loss, to measure the localization uncertainty by weighting the likelihood loss
by its IoU, which alleviates the model misspecification problem. Furthermore,
we propose an uncertainty-aware focal loss for reflecting the estimated
uncertainty to the classification score. Experimental results on COCO datasets
demonstrate that our method significantly improves FCOS, by up to 1.8 points,
without sacrificing computational efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Cross-Modal Pre-Training: A General Strategy for Small Sample Medical Imaging. (arXiv:2010.03060v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03060">
<div class="article-summary-box-inner">
<span><p>A key challenge in training neural networks for a given medical imaging task
is often the difficulty of obtaining a sufficient number of manually labeled
examples. In contrast, textual imaging reports, which are often readily
available in medical records, contain rich but unstructured interpretations
written by experts as part of standard clinical practice. We propose using
these textual reports as a form of weak supervision to improve the image
interpretation performance of a neural network without requiring additional
manually labeled examples. We use an image-text matching task to train a
feature extractor and then fine-tune it in a transfer learning setting for a
supervised task using a small labeled dataset. The end result is a neural
network that automatically interprets imagery without requiring textual reports
during inference. This approach can be applied to any task for which text-image
pairs are readily available. We evaluate our method on three classification
tasks and find consistent performance improvements, reducing the need for
labeled data by 67%-98%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DSAM: A Distance Shrinking with Angular Marginalizing Loss for High Performance Vehicle Re-identificatio. (arXiv:2011.06228v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06228">
<div class="article-summary-box-inner">
<span><p>Vehicle Re-identification (ReID) is an important yet challenging problem in
computer vision. Compared to other visual objects like faces and persons,
vehicles simultaneously exhibit much larger intraclass viewpoint variations and
interclass visual similarities, making most exiting loss functions designed for
face recognition and person ReID unsuitable for vehicle ReID. To obtain a
high-performance vehicle ReID model, we present a novel Distance Shrinking with
Angular Marginalizing (DSAM) loss function to perform hybrid learning in both
the Original Feature Space (OFS) and the Feature Angular Space (FAS) using the
local verification and the global identification information. Specifically, it
shrinks the distance between samples of the same class locally in the Original
Feature Space while keeps samples of different classes far away in the Feature
Angular Space. The shrinking and marginalizing operations are performed during
each iteration of the training process and are suitable for different SoftMax
based loss functions. We evaluate the DSAM loss function on three large vehicle
ReID datasets with detailed analyses and extensive comparisons with many
competing vehicle ReID methods. Experimental results show that our DSAM loss
enhances the SoftMax loss by a large margin on the PKU-VD1-Large dataset:
10.41% for mAP, 5.29% for cmc1, and 4.60% for cmc5. Moreover, the mAP is
increased by 9.34% on the PKU-VehicleID dataset and 6.13% on the VeRi-776
dataset. Source code will be released to facilitate further studies in this
research direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HoHoNet: 360 Indoor Holistic Understanding with Latent Horizontal Features. (arXiv:2011.11498v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11498">
<div class="article-summary-box-inner">
<span><p>We present HoHoNet, a versatile and efficient framework for holistic
understanding of an indoor 360-degree panorama using a Latent Horizontal
Feature (LHFeat). The compact LHFeat flattens the features along the vertical
direction and has shown success in modeling per-column modality for room layout
reconstruction. HoHoNet advances in two important aspects. First, the deep
architecture is redesigned to run faster with improved accuracy. Second, we
propose a novel horizon-to-dense module, which relaxes the per-column output
shape constraint, allowing per-pixel dense prediction from LHFeat. HoHoNet is
fast: It runs at 52 FPS and 110 FPS with ResNet-50 and ResNet-34 backbones
respectively, for modeling dense modalities from a high-resolution $512 \times
1024$ panorama. HoHoNet is also accurate. On the tasks of layout estimation and
semantic segmentation, HoHoNet achieves results on par with current
state-of-the-art. On dense depth estimation, HoHoNet outperforms all the prior
arts by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Deep Neural Networks via Layer-Peeled Model: Minority Collapse in Imbalanced Training. (arXiv:2101.12699v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12699">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce the \textit{Layer-Peeled Model}, a nonconvex yet
analytically tractable optimization program, in a quest to better understand
deep neural networks that are trained for a sufficiently long time. As the name
suggests, this new model is derived by isolating the topmost layer from the
remainder of the neural network, followed by imposing certain constraints
separately on the two parts of the network. We demonstrate that the
Layer-Peeled Model, albeit simple, inherits many characteristics of
well-trained neural networks, thereby offering an effective tool for explaining
and predicting common empirical patterns of deep learning training. First, when
working on class-balanced datasets, we prove that any solution to this model
forms a simplex equiangular tight frame, which in part explains the recently
discovered phenomenon of neural collapse \cite{papyan2020prevalence}. More
importantly, when moving to the imbalanced case, our analysis of the
Layer-Peeled Model reveals a hitherto unknown phenomenon that we term
\textit{Minority Collapse}, which fundamentally limits the performance of deep
learning models on the minority classes. In addition, we use the Layer-Peeled
Model to gain insights into how to mitigate Minority Collapse. Interestingly,
this phenomenon is first predicted by the Layer-Peeled Model before being
confirmed by our computational experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Just Noticeable Difference for Machine Perception and Generation of Regularized Adversarial Images with Minimal Perturbation. (arXiv:2102.08079v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08079">
<div class="article-summary-box-inner">
<span><p>In this study, we introduce a measure for machine perception, inspired by the
concept of Just Noticeable Difference (JND) of human perception. Based on this
measure, we suggest an adversarial image generation algorithm, which
iteratively distorts an image by an additive noise until the model detects the
change in the image by outputting a false label. The noise added to the
original image is defined as the gradient of the cost function of the model. A
novel cost function is defined to explicitly minimize the amount of
perturbation applied to the input image while enforcing the perceptual
similarity between the adversarial and input images. For this purpose, the cost
function is regularized by the well-known total variation and bounded range
terms to meet the natural appearance of the adversarial image. We evaluate the
adversarial images generated by our algorithm both qualitatively and
quantitatively on CIFAR10, ImageNet, and MS COCO datasets. Our experiments on
image classification and object detection tasks show that adversarial images
generated by our JND method are both more successful in deceiving the
recognition/detection models and less perturbed compared to the images
generated by the state-of-the-art methods, namely, FGV, FSGM, and DeepFool
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ISCL: Interdependent Self-Cooperative Learning for Unpaired Image Denoising. (arXiv:2102.09858v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09858">
<div class="article-summary-box-inner">
<span><p>With the advent of advances in self-supervised learning, paired clean-noisy
data are no longer required in deep learning-based image denoising. However,
existing blind denoising methods still require the assumption with regard to
noise characteristics, such as zero-mean noise distribution and pixel-wise
noise-signal independence; this hinders wide adaptation of the method in the
medical domain. On the other hand, unpaired learning can overcome limitations
related to the assumption on noise characteristics, which makes it more
feasible for collecting the training data in real-world scenarios. In this
paper, we propose a novel image denoising scheme, Interdependent
Self-Cooperative Learning (ISCL), that leverages unpaired learning by combining
cyclic adversarial learning with self-supervised residual learning. Unlike the
existing unpaired image denoising methods relying on matching data
distributions in different domains, the two architectures in ISCL, designed for
different tasks, complement each other and boost the learning process. To
assess the performance of the proposed method, we conducted extensive
experiments in various biomedical image degradation scenarios, such as noise
caused by physical characteristics of electron microscopy (EM) devices (film
and charging noise), and structural noise found in low-dose computer tomography
(CT). We demonstrate that the image quality of our method is superior to
conventional and current state-of-the-art deep learning-based image denoising
methods, including supervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Attacks are Reversible with Natural Supervision. (arXiv:2103.14222v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14222">
<div class="article-summary-box-inner">
<span><p>We find that images contain intrinsic structure that enables the reversal of
many adversarial attacks. Attack vectors cause not only image classifiers to
fail, but also collaterally disrupt incidental structure in the image. We
demonstrate that modifying the attacked image to restore the natural structure
will reverse many types of attacks, providing a defense. Experiments
demonstrate significantly improved robustness for several state-of-the-art
models across the CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets. Our results
show that our defense is still effective even if the attacker is aware of the
defense mechanism. Since our defense is deployed during inference instead of
training, it is compatible with pre-trained networks as well as most other
defenses. Our results suggest deep networks are vulnerable to adversarial
examples partly because their representations do not enforce the natural
structure of images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LightSAL: Lightweight Sign Agnostic Learning for Implicit Surface Representation. (arXiv:2103.14273v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14273">
<div class="article-summary-box-inner">
<span><p>Recently, several works have addressed modeling of 3D shapes using deep
neural networks to learn implicit surface representations. Up to now, the
majority of works have concentrated on reconstruction quality, paying little or
no attention to model size or training time. This work proposes LightSAL, a
novel deep convolutional architecture for learning 3D shapes; the proposed work
concentrates on efficiency both in network training time and resulting model
size. We build on the recent concept of Sign Agnostic Learning for training the
proposed network, relying on signed distance fields, with unsigned distance as
ground truth. In the experimental section of the paper, we demonstrate that the
proposed architecture outperforms previous work in model size and number of
required training iterations, while achieving equivalent accuracy. Experiments
are based on the D-Faust dataset that contains 41k 3D scans of human shapes.
The proposed model has been implemented in PyTorch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Weight Pruning using Pre-trained Lottery Jackpots. (arXiv:2104.08700v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08700">
<div class="article-summary-box-inner">
<span><p>Network pruning is an effective approach to reduce network complexity without
performance compromise. Existing studies achieve the sparsity of neural
networks via time-consuming weight tuning or complex search on networks with
expanded width, which greatly limits the applications of network pruning. In
this paper, we show that high-performing and sparse sub-networks without the
involvement of weight tuning, termed "lottery jackpots", exist in pre-trained
models with unexpanded width. For example, we obtain a lottery jackpot that has
only 10% parameters and still reaches the performance of the original dense
VGGNet-19 without any modifications on the pre-trained weights. Furthermore, we
observe that the sparse masks derived from many existing pruning criteria have
a high overlap with the searched mask of our lottery jackpot, among which, the
magnitude-based pruning results in the most similar mask with ours. Based on
this insight, we initialize our sparse mask using the magnitude pruning,
resulting in at least 3x cost reduction on the lottery jackpot search while
achieves comparable or even better performance. Specifically, our
magnitude-based lottery jackpot removes 90% weights in the ResNet-50, while
easily obtains more than 70% top-1 accuracy using only 10 searching epochs on
ImageNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-Based 3D Seismic Fault Segmentation Training by a Few 2D Slice Labels. (arXiv:2105.03857v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03857">
<div class="article-summary-box-inner">
<span><p>Detection faults in seismic data is a crucial step for seismic structural
interpretation, reservoir characterization and well placement. Some recent
works regard it as an image segmentation task. The task of image segmentation
requires huge labels, especially 3D seismic data, which has a complex structure
and lots of noise. Therefore, its annotation requires expert experience and a
huge workload. In this study, we present lambda-BCE and lambda-smooth L1loss to
effectively train 3D-CNN by some slices from 3D seismic data, so that the model
can learn the segmentation of 3D seismic data from a few 2D slices. In order to
fully extract information from limited data and suppress seismic noise, we
propose an attention module that can be used for active supervision training
and embedded in the network. The attention heatmap label is generated by the
original label, and letting it supervise the attention module using the
lambda-smooth L1loss. The experiment demonstrates the effectiveness of our loss
function, the method can extract 3D seismic features from a few 2D slice
labels. And it also shows the advanced performance of the attention module,
which can significantly suppress the noise in the seismic data while increasing
the model's sensitivity to the foreground. Finally, on the public test set, we
only use the 2D slice labels training that accounts for 3.3% of the 3D volume
label, and achieve similar performance to the 3D volume label training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Cropping on Twitter: Fairness Metrics, their Limitations, and the Importance of Representation, Design, and Agency. (arXiv:2105.08667v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08667">
<div class="article-summary-box-inner">
<span><p>Twitter uses machine learning to crop images, where crops are centered around
the part predicted to be the most salient. In fall 2020, Twitter users raised
concerns that the automated image cropping system on Twitter favored
light-skinned over dark-skinned individuals, as well as concerns that the
system favored cropping woman's bodies instead of their heads. In order to
address these concerns, we conduct an extensive analysis using formalized group
fairness metrics. We find systematic disparities in cropping and identify
contributing factors, including the fact that the cropping based on the single
most salient point can amplify the disparities because of an effect we term
argmax bias. However, we demonstrate that formalized fairness metrics and
quantitative analysis on their own are insufficient for capturing the risk of
representational harm in automatic cropping. We suggest the removal of
saliency-based cropping in favor of a solution that better preserves user
agency. For developing a new solution that sufficiently address concerns
related to representational harm, our critique motivates a combination of
quantitative and qualitative methods that include human-centered design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net. (arXiv:2106.00952v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00952">
<div class="article-summary-box-inner">
<span><p>Information extraction from document images has received a lot of attention
recently, due to the need for digitizing a large volume of unstructured
documents such as invoices, receipts, bank transfers, etc. In this paper, we
propose a novel deep learning architecture for end-to-end information
extraction on the 2D character-grid embedding of the document, namely the
\textit{Multi-Stage Attentional U-Net}. To effectively capture the textual and
spatial relations between 2D elements, our model leverages a specialized
multi-stage encoder-decoders design, in conjunction with efficient uses of the
self-attention mechanism and the box convolution. Experimental results on
different datasets show that our model outperforms the baseline U-Net
architecture by a large margin while using 40\% fewer parameters. Moreover, it
also significantly improved the baseline in erroneous OCR and limited training
data scenario, thus becomes practical for real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Indoor Panorama Planar 3D Reconstruction via Divide and Conquer. (arXiv:2106.14166v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14166">
<div class="article-summary-box-inner">
<span><p>Indoor panorama typically consists of human-made structures parallel or
perpendicular to gravity. We leverage this phenomenon to approximate the scene
in a 360-degree image with (H)orizontal-planes and (V)ertical-planes. To this
end, we propose an effective divide-and-conquer strategy that divides pixels
based on their plane orientation estimation; then, the succeeding instance
segmentation module conquers the task of planes clustering more easily in each
plane orientation group. Besides, parameters of V-planes depend on camera yaw
rotation, but translation-invariant CNNs are less aware of the yaw change. We
thus propose a yaw-invariant V-planar reparameterization for CNNs to learn. We
create a benchmark for indoor panorama planar reconstruction by extending
existing 360 depth datasets with ground truth H\&amp;V-planes (referred to as
PanoH&amp;V dataset) and adopt state-of-the-art planar reconstruction methods to
predict H\&amp;V-planes as our baselines. Our method outperforms the baselines by a
large margin on the proposed dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Superpoint-guided Semi-supervised Semantic Segmentation of 3D Point Clouds. (arXiv:2107.03601v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03601">
<div class="article-summary-box-inner">
<span><p>3D point cloud semantic segmentation is a challenging topic in the computer
vision field. Most of the existing methods in literature require a large amount
of fully labeled training data, but it is extremely time-consuming to obtain
these training data by manually labeling massive point clouds. Addressing this
problem, we propose a superpoint-guided semi-supervised segmentation network
for 3D point clouds, which jointly utilizes a small portion of labeled scene
point clouds and a large number of unlabeled point clouds for network training.
The proposed network is iteratively updated with its predicted pseudo labels,
where a superpoint generation module is introduced for extracting superpoints
from 3D point clouds, and a pseudo-label optimization module is explored for
automatically assigning pseudo labels to the unlabeled points under the
constraint of the extracted superpoints. Additionally, there are some 3D points
without pseudo-label supervision. We propose an edge prediction module to
constrain features of edge points. A superpoint feature aggregation module and
a superpoint feature consistency loss function are introduced to smooth
superpoint features. Extensive experimental results on two 3D public datasets
demonstrate that our method can achieve better performance than several
state-of-the-art point cloud segmentation networks and several popular
semi-supervised segmentation methods with few labeled scenes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer. (arXiv:2108.01390v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01390">
<div class="article-summary-box-inner">
<span><p>Vision transformers (ViTs) have recently received explosive popularity, but
the huge computational cost is still a severe issue. Since the computation
complexity of ViT is quadratic with respect to the input sequence length, a
mainstream paradigm for computation reduction is to reduce the number of
tokens. Existing designs include structured spatial compression that uses a
progressive shrinking pyramid to reduce the computations of large feature maps,
and unstructured token pruning that dynamically drops redundant tokens.
However, the limitation of existing token pruning lies in two folds: 1) the
incomplete spatial structure caused by pruning is not compatible with
structured spatial compression that is commonly used in modern deep-narrow
transformers; 2) it usually requires a time-consuming pre-training procedure.
To tackle the limitations and expand the applicable scenario of token pruning,
we present Evo-ViT, a self-motivated slow-fast token evolution approach for
vision transformers. Specifically, we conduct unstructured instance-wise token
selection by taking advantage of the simple and effective global class
attention that is native to vision transformers. Then, we propose to update the
selected informative tokens and uninformative tokens with different computation
paths, namely, slow-fast updating. Since slow-fast updating mechanism maintains
the spatial structure and information flow, Evo-ViT can accelerate vanilla
transformers of both flat and deep-narrow structures from the very beginning of
the training process. Experimental results demonstrate that our method
significantly reduces the computational cost of vision transformers while
maintaining comparable performance on image classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neighborhood Consensus Contrastive Learning for Backward-Compatible Representation. (arXiv:2108.03372v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03372">
<div class="article-summary-box-inner">
<span><p>In object re-identification (ReID), the development of deep learning
techniques often involves model updates and deployment. It is unbearable to
re-embedding and re-index with the system suspended when deploying new models.
Therefore, backward-compatible representation is proposed to enable "new"
features to be compared with "old" features directly, which means that the
database is active when there are both "new" and "old" features in it. Thus we
can scroll-refresh the database or even do nothing on the database to update.
</p>
<p>The existing backward-compatible methods either require a strong overlap
between old and new training data or simply conduct constraints at the instance
level. Thus they are difficult in handling complicated cluster structures and
are limited in eliminating the impact of outliers in old embeddings, resulting
in a risk of damaging the discriminative capability of new features. In this
work, we propose a Neighborhood Consensus Contrastive Learning (NCCL) method.
With no assumptions about the new training data, we estimate the sub-cluster
structures of old embeddings. A new embedding is constrained with multiple old
embeddings in both embedding space and discrimination space at the sub-class
level. The effect of outliers diminished, as the multiple samples serve as
"mean teachers". Besides, we also propose a scheme to filter the old embeddings
with low credibility, further improving the compatibility robustness. Our
method ensures backward compatibility without impairing the accuracy of the new
model. And it can even improve the new model's accuracy in most scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-Supervised Domain Generalizable Person Re-Identification. (arXiv:2108.05045v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05045">
<div class="article-summary-box-inner">
<span><p>Existing person re-identification (re-id) methods are stuck when deployed to
a new unseen scenario despite the success in cross-camera person matching.
Recent efforts have been substantially devoted to domain adaptive person re-id
where extensive unlabeled data in the new scenario are utilized in a
transductive learning manner. However, for each scenario, it is required to
first collect enough data and then train such a domain adaptive re-id model,
thus restricting their practical application. Instead, we aim to explore
multiple labeled datasets to learn generalized domain-invariant representations
for person re-id, which is expected universally effective for each new-coming
re-id scenario. To pursue practicability in real-world systems, we collect all
the person re-id datasets (20 datasets) in this field and select the three most
frequently used datasets (i.e., Market1501, DukeMTMC, and MSMT17) as unseen
target domains. In addition, we develop DataHunter that collects over 300K+
weak annotated images named YouTube-Human from YouTube street-view videos,
which joins 17 remaining full labeled datasets to form multiple source domains.
On such a large and challenging benchmark called FastHuman (~440K+ labeled
images), we further propose a simple yet effective Semi-Supervised Knowledge
Distillation (SSKD) framework. SSKD effectively exploits the weakly annotated
data by assigning soft pseudo labels to YouTube-Human to improve models'
generalization ability. Experiments on several protocols verify the
effectiveness of the proposed SSKD framework on domain generalizable person
re-id, which is even comparable to supervised learning on the target domains.
Lastly, but most importantly, we hope the proposed benchmark FastHuman could
bring the next development of domain generalizable person re-id algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProAI: An Efficient Embedded AI Hardware for Automotive Applications -- a Benchmark Study. (arXiv:2108.05170v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05170">
<div class="article-summary-box-inner">
<span><p>Development in the field of Single Board Computers (SBC) have been increasing
for several years. They provide a good balance between computing performance
and power consumption which is usually required for mobile platforms, like
application in vehicles for Advanced Driver Assistance Systems (ADAS) and
Autonomous Driving (AD). However, there is an ever-increasing need of more
powerful and efficient SBCs which can run power intensive Deep Neural Networks
(DNNs) in real-time and can also satisfy necessary functional safety
requirements such as Automotive Safety Integrity Level (ASIL). ProAI is being
developed by ZF mainly to run powerful and efficient applications such as
multitask DNNs and on top of that it also has the required safety certification
for AD. In this work, we compare and discuss state of the art SBC on the basis
of power intensive multitask DNN architecture called Multitask-CenterNet with
respect to performance measures such as, FPS and power efficiency. As an
automotive supercomputer, ProAI delivers an excellent combination of
performance and efficiency, managing nearly twice the number of FPS per watt
than a modern workstation laptop and almost four times compared to the Jetson
Nano. Furthermore, it was also shown that there is still power in reserve for
further and more complex tasks on the ProAI, based on the CPU and GPU
utilization during the benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Visual Recognition with Deep Neural Networks: A Survey on Recent Advances and New Directions. (arXiv:2108.13055v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13055">
<div class="article-summary-box-inner">
<span><p>Visual recognition is currently one of the most important and active research
areas in computer vision, pattern recognition, and even the general field of
artificial intelligence. It has great fundamental importance and strong
industrial needs. Deep neural networks (DNNs) have largely boosted their
performances on many concrete tasks, with the help of large amounts of training
data and new powerful computation resources. Though recognition accuracy is
usually the first concern for new progresses, efficiency is actually rather
important and sometimes critical for both academic research and industrial
applications. Moreover, insightful views on the opportunities and challenges of
efficiency are also highly required for the entire community. While general
surveys on the efficiency issue of DNNs have been done from various
perspectives, as far as we are aware, scarcely any of them focused on visual
recognition systematically, and thus it is unclear which progresses are
applicable to it and what else should be concerned. In this paper, we present
the review of the recent advances with our suggestions on the new possible
directions towards improving the efficiency of DNN-related visual recognition
approaches. We investigate not only from the model but also the data point of
view (which is not the case in existing surveys), and focus on three most
studied data types (images, videos and points). This paper attempts to provide
a systematic summary via a comprehensive survey which can serve as a valuable
reference and inspire both researchers and practitioners who work on visual
recognition problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse-MLP: A Fully-MLP Architecture with Conditional Computation. (arXiv:2109.02008v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02008">
<div class="article-summary-box-inner">
<span><p>Mixture-of-Experts (MoE) with sparse conditional computation has been proved
an effective architecture for scaling attention-based models to more parameters
with comparable computation cost. In this paper, we propose Sparse-MLP, scaling
the recent MLP-Mixer model with sparse MoE layers, to achieve a more
computation-efficient architecture. We replace a subset of dense MLP blocks in
the MLP-Mixer model with Sparse blocks. In each Sparse block, we apply two
stages of MoE layers: one with MLP experts mixing information within channels
along image patch dimension, one with MLP experts mixing information within
patches along the channel dimension. Besides, to reduce computational cost in
routing and improve expert capacity, we design Re-represent layers in each
Sparse block. These layers are to re-scale image representations by two simple
but effective linear transformations. When pre-training on ImageNet-1k with
MoCo v3 algorithm, our models can outperform dense MLP models by 2.5\% on
ImageNet Top-1 accuracy with fewer parameters and computational cost. On
small-scale downstream image classification tasks, i.e. Cifar10 and Cifar100,
our Sparse-MLP can still achieve better performance than baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Object-to-Zone Graph for Object Navigation. (arXiv:2109.02066v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02066">
<div class="article-summary-box-inner">
<span><p>The goal of object navigation is to reach the expected objects according to
visual information in the unseen environments. Previous works usually implement
deep models to train an agent to predict actions in real-time. However, in the
unseen environment, when the target object is not in egocentric view, the agent
may not be able to make wise decisions due to the lack of guidance. In this
paper, we propose a hierarchical object-to-zone (HOZ) graph to guide the agent
in a coarse-to-fine manner, and an online-learning mechanism is also proposed
to update HOZ according to the real-time observation in new environments. In
particular, the HOZ graph is composed of scene nodes, zone nodes and object
nodes. With the pre-learned HOZ graph, the real-time observation and the target
goal, the agent can constantly plan an optimal path from zone to zone. In the
estimated path, the next potential zone is regarded as sub-goal, which is also
fed into the deep reinforcement learning model for action prediction. Our
methods are evaluated on the AI2-Thor simulator. In addition to widely used
evaluation metrics SR and SPL, we also propose a new evaluation metric of SAE
that focuses on the effective action rate. Experimental results demonstrate the
effectiveness and efficiency of our proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WhyAct: Identifying Action Reasons in Lifestyle Vlogs. (arXiv:2109.02747v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02747">
<div class="article-summary-box-inner">
<span><p>We aim to automatically identify human action reasons in online videos. We
focus on the widespread genre of lifestyle vlogs, in which people perform
actions while verbally describing them. We introduce and make publicly
available the WhyAct dataset, consisting of 1,077 visual actions manually
annotated with their reasons. We describe a multimodal model that leverages
visual and textual information to automatically infer the reasons corresponding
to an action presented in the video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perceptual Learned Video Compression with Recurrent Conditional GAN. (arXiv:2109.03082v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03082">
<div class="article-summary-box-inner">
<span><p>This paper proposes a Perceptual Learned Video Compression (PLVC) approach
with recurrent conditional generative adversarial network. In our approach, the
recurrent auto-encoder-based generator learns to fully explore the temporal
correlation for compressing video. More importantly, we propose a recurrent
conditional discriminator, which judges raw and compressed video conditioned on
both spatial and temporal information, including the latent representation,
temporal motion and hidden states in recurrent cells. This way, in the
adversarial training, it pushes the generated video to be not only spatially
photo-realistic but also temporally consistent with groundtruth and coherent
among video frames. The experimental results show that the proposed PLVC model
learns to compress video towards good perceptual quality at low bit-rate, and
outperforms the previous traditional and learned approaches on several
perceptual quality metrics. The user study further validates the outstanding
perceptual performance of PLVC in comparison with the latest learned video
compression approaches and the official HEVC test model (HM 16.20). The codes
will be released at https://github.com/RenYang-home/PLVC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">nnFormer: Interleaved Transformer for Volumetric Segmentation. (arXiv:2109.03201v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03201">
<div class="article-summary-box-inner">
<span><p>Transformers, the default model of choices in natural language processing,
have drawn scant attention from the medical imaging community. Given the
ability to exploit long-term dependencies, transformers are promising to help
atypical convolutional neural networks (convnets) to overcome its inherent
shortcomings of spatial inductive bias. However, most of recently proposed
transformer-based segmentation approaches simply treated transformers as
assisted modules to help encode global context into convolutional
representations without investigating how to optimally combine self-attention
(i.e., the core of transformers) with convolution. To address this issue, in
this paper, we introduce nnFormer (i.e., Not-aNother transFormer), a powerful
segmentation model with an interleaved architecture based on empirical
combination of self-attention and convolution. In practice, nnFormer learns
volumetric representations from 3D local volumes. Compared to the naive
voxel-level self-attention implementation, such volume-based operations help to
reduce the computational complexity by approximate 98% and 99.5% on Synapse and
ACDC datasets, respectively. In comparison to prior-art network configurations,
nnFormer achieves tremendous improvements over previous transformer-based
methods on two commonly used datasets Synapse and ACDC. For instance, nnFormer
outperforms Swin-UNet by over 7 percents on Synapse. Even when compared to
nnUNet, currently the best performing fully-convolutional medical segmentation
network, nnFormer still provides slightly better performance on Synapse and
ACDC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MRI Reconstruction Using Deep Energy-Based Model. (arXiv:2109.03237v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03237">
<div class="article-summary-box-inner">
<span><p>Purpose: Although recent deep energy-based generative models (EBMs) have
shown encouraging results in many image generation tasks, how to take advantage
of the self-adversarial cogitation in deep EBMs to boost the performance of
Magnetic Resonance Imaging (MRI) reconstruction is still desired.
</p>
<p>Methods: With the successful application of deep learning in a wide range of
MRI reconstruction, a line of emerging research involves formulating an
optimization-based reconstruction method in the space of a generative model.
Leveraging this, a novel regularization strategy is introduced in this article
which takes advantage of self-adversarial cogitation of the deep energy-based
model. More precisely, we advocate for alternative learning a more powerful
energy-based model with maximum likelihood estimation to obtain the deep
energy-based information, represented as image prior. Simultaneously, implicit
inference with Langevin dynamics is a unique property of re-construction. In
contrast to other generative models for reconstruction, the proposed method
utilizes deep energy-based information as the image prior in reconstruction to
improve the quality of image.
</p>
<p>Results: Experiment results that imply the proposed technique can obtain
remarkable performance in terms of high reconstruction accuracy that is
competitive with state-of-the-art methods, and does not suffer from mode
collapse.
</p>
<p>Conclusion: Algorithmically, an iterative approach was presented to
strengthen EBM training with the gradient of energy network. The robustness and
the reproducibility of the algorithm were also experimentally validated. More
importantly, the proposed reconstruction framework can be generalized for most
MRI reconstruction scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RoadAtlas: Intelligent Platform for Automated Road Defect Detection and Asset Management. (arXiv:2109.03385v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03385">
<div class="article-summary-box-inner">
<span><p>With the rapid development of intelligent detection algorithms based on deep
learning, much progress has been made in automatic road defect recognition and
road marking parsing. This can effectively address the issue of an expensive
and time-consuming process for professional inspectors to review the street
manually. Towards this goal, we present RoadAtlas, a novel end-to-end
integrated system that can support 1) road defect detection, 2) road marking
parsing, 3) a web-based dashboard for presenting and inputting data by users,
and 4) a backend containing a well-structured database and developed APIs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Discriminate Information for Online Action Detection: Analysis and Application. (arXiv:2109.03393v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03393">
<div class="article-summary-box-inner">
<span><p>Online action detection, which aims to identify an ongoing action from a
streaming video, is an important subject in real-world applications. For this
task, previous methods use recurrent neural networks for modeling temporal
relations in an input sequence. However, these methods overlook the fact that
the input image sequence includes not only the action of interest but
background and irrelevant actions. This would induce recurrent units to
accumulate unnecessary information for encoding features on the action of
interest. To overcome this problem, we propose a novel recurrent unit, named
Information Discrimination Unit (IDU), which explicitly discriminates the
information relevancy between an ongoing action and others to decide whether to
accumulate the input information. This enables learning more discriminative
representations for identifying an ongoing action. In this paper, we further
present a new recurrent unit, called Information Integration Unit (IIU), for
action anticipation. Our IIU exploits the outputs from IDU as pseudo action
labels as well as RGB frames to learn enriched features of observed actions
effectively. In experiments on TVSeries and THUMOS-14, the proposed methods
outperform state-of-the-art methods by a significant margin in online action
detection and action anticipation. Moreover, we demonstrate the effectiveness
of the proposed units by conducting comprehensive ablation studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shuffled Patch-Wise Supervision for Presentation Attack Detection. (arXiv:2109.03484v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03484">
<div class="article-summary-box-inner">
<span><p>Face anti-spoofing is essential to prevent false facial verification by using
a photo, video, mask, or a different substitute for an authorized person's
face. Most of the state-of-the-art presentation attack detection (PAD) systems
suffer from overfitting, where they achieve near-perfect scores on a single
dataset but fail on a different dataset with more realistic data. This problem
drives researchers to develop models that perform well under real-world
conditions. This is an especially challenging problem for frame-based
presentation attack detection systems that use convolutional neural networks
(CNN). To this end, we propose a new PAD approach, which combines pixel-wise
binary supervision with patch-based CNN. We believe that training a CNN with
face patches allows the model to distinguish spoofs without learning background
or dataset-specific traces. We tested the proposed method both on the standard
benchmark datasets -- Replay-Mobile, OULU-NPU -- and on a real-world dataset.
The proposed approach shows its superiority on challenging experimental setups.
Namely, it achieves higher performance on OULU-NPU protocol 3, 4 and on
inter-dataset real-world experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label Efficient Visual Abstractions for Autonomous Driving. (arXiv:2005.10091v2 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.10091">
<div class="article-summary-box-inner">
<span><p>It is well known that semantic segmentation can be used as an effective
intermediate representation for learning driving policies. However, the task of
street scene semantic segmentation requires expensive annotations. Furthermore,
segmentation algorithms are often trained irrespective of the actual driving
task, using auxiliary image-space loss functions which are not guaranteed to
maximize driving metrics such as safety or distance traveled per intervention.
In this work, we seek to quantify the impact of reducing segmentation
annotation costs on learned behavior cloning agents. We analyze several
segmentation-based intermediate representations. We use these visual
abstractions to systematically study the trade-off between annotation
efficiency and driving performance, i.e., the types of classes labeled, the
number of image samples used to learn the visual abstraction model, and their
granularity (e.g., object masks vs. 2D bounding boxes). Our analysis uncovers
several practical insights into how segmentation-based visual abstractions can
be exploited in a more label efficient manner. Surprisingly, we find that
state-of-the-art driving performance can be achieved with orders of magnitude
reduction in annotation cost. Beyond label efficiency, we find several
additional training benefits when leveraging visual abstractions, such as a
significant reduction in the variance of the learned policy when compared to
state-of-the-art end-to-end driving models.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-12 23:02:28.786317893 UTC">2021-09-12 23:02:28 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>