<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-11-05T01:30:00Z">11-05</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Athena 2.0: Contextualized Dialogue Management for an Alexa Prize SocialBot. (arXiv:2111.02519v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02519">
<div class="article-summary-box-inner">
<span><p>Athena 2.0 is an Alexa Prize SocialBot that has been a finalist in the last
two Alexa Prize Grand Challenges. One reason for Athena's success is its novel
dialogue management strategy, which allows it to dynamically construct
dialogues and responses from component modules, leading to novel conversations
with every interaction. Here we describe Athena's system design and performance
in the Alexa Prize during the 20/21 competition. A live demo of Athena as well
as video recordings will provoke discussion on the state of the art in
conversational AI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLUES: Few-Shot Learning Evaluation in Natural Language Understanding. (arXiv:2111.02570v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02570">
<div class="article-summary-box-inner">
<span><p>Most recent progress in natural language understanding (NLU) has been driven,
in part, by benchmarks such as GLUE, SuperGLUE, SQuAD, etc. In fact, many NLU
models have now matched or exceeded "human-level" performance on many tasks in
these benchmarks. Most of these benchmarks, however, give models access to
relatively large amounts of labeled data for training. As such, the models are
provided far more data than required by humans to achieve strong performance.
That has motivated a line of work that focuses on improving few-shot learning
performance of NLU models. However, there is a lack of standardized evaluation
benchmarks for few-shot NLU resulting in different experimental settings in
different papers. To help accelerate this line of work, we introduce CLUES
(Constrained Language Understanding Evaluation Standard), a benchmark for
evaluating the few-shot learning capabilities of NLU models. We demonstrate
that while recent models reach human performance when they have access to large
amounts of labeled data, there is a huge gap in performance in the few-shot
setting for most tasks. We also demonstrate differences between alternative
model families and adaptation techniques in the few shot setting. Finally, we
discuss several principles and choices in designing the experimental settings
for evaluating the true few-shot learning performance and suggest a unified
standardized approach to few-shot learning evaluation. We aim to encourage
research on NLU models that can generalize to new tasks with a small number of
examples. Code and data for CLUES are available at
https://github.com/microsoft/CLUES.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Semantic Parsing for Multilingual Task-Oriented Dialogues. (arXiv:2111.02574v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02574">
<div class="article-summary-box-inner">
<span><p>Robust state tracking for task-oriented dialogue systems currently remains
restricted to a few popular languages. This paper shows that given a
large-scale dialogue data set in one language, we can automatically produce an
effective semantic parser for other languages using machine translation. We
propose automatic translation of dialogue datasets with alignment to ensure
faithful translation of slot values and eliminate costly human supervision used
in previous benchmarks. We also propose a new contextual semantic parsing
model, which encodes the formal slots and values, and only the last agent and
user utterances. We show that the succinct representation reduces the
compounding effect of translation errors, without harming the accuracy in
practice.
</p>
<p>We evaluate our approach on several dialogue state tracking benchmarks. On
RiSAWOZ, CrossWOZ, CrossWOZ-EN, and MultiWOZ-ZH datasets we improve the state
of the art by 11%, 17%, 20%, and 0.3% in joint goal accuracy. We present a
comprehensive error analysis for all three datasets showing erroneous
annotations can obscure judgments on the quality of the model.
</p>
<p>Finally, we present RiSAWOZ English and German datasets, created using our
translation methodology. On these datasets, accuracy is within 11% of the
original showing that high-accuracy multilingual dialogue datasets are possible
without relying on expensive human annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Semantic Cognition, Inductive Generalization, and Language Models. (arXiv:2111.02603v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02603">
<div class="article-summary-box-inner">
<span><p>My doctoral research focuses on understanding semantic knowledge in neural
network models trained solely to predict natural language (referred to as
language models, or LMs), by drawing on insights from the study of concepts and
categories grounded in cognitive science. I propose a framework inspired by
'inductive reasoning,' a phenomenon that sheds light on how humans utilize
background knowledge to make inductive leaps and generalize from new pieces of
information about concepts and their properties. Drawing from experiments that
study inductive reasoning, I propose to analyze semantic inductive
generalization in LMs using phenomena observed in human-induction literature,
investigate inductive behavior on tasks such as implicit reasoning and emergent
feature recognition, and analyze and relate induction dynamics to the learned
conceptual representation space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lexically Aware Semi-Supervised Learning for OCR Post-Correction. (arXiv:2111.02622v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02622">
<div class="article-summary-box-inner">
<span><p>Much of the existing linguistic data in many languages of the world is locked
away in non-digitized books and documents. Optical character recognition (OCR)
can be used to produce digitized text, and previous work has demonstrated the
utility of neural post-correction methods that improve the results of
general-purpose OCR systems on recognition of less-well-resourced languages.
However, these methods rely on manually curated post-correction data, which are
relatively scarce compared to the non-annotated raw images that need to be
digitized.
</p>
<p>In this paper, we present a semi-supervised learning method that makes it
possible to utilize these raw images to improve performance, specifically
through the use of self-training, a technique where a model is iteratively
trained on its own outputs. In addition, to enforce consistency in the
recognized vocabulary, we introduce a lexically-aware decoding method that
augments the neural post-correction model with a count-based language model
constructed from the recognized texts, implemented using weighted finite-state
automata (WFSA) for efficient and effective decoding.
</p>
<p>Results on four endangered languages demonstrate the utility of the proposed
method, with relative error reductions of 15-29%, where we find the combination
of self-training and lexically-aware decoding essential for achieving
consistent improvements. Data and code are available at
https://shrutirij.github.io/ocr-el/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Response Generation with Context-Aware Prompt Learning. (arXiv:2111.02643v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02643">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLM) have marked a huge leap in neural dialogue
modeling. While PLMs are pre-trained on large-scale text corpora, they are
usually fine-tuned on scarce dialogue data with specific domain knowledge and
dialogue styles. However, tailoring the language models while fully utilizing
prior knowledge in large pre-trained models remains a challenge. In this paper,
we present a novel approach for pre-trained dialogue modeling that casts the
dialogue generation problem as a prompt-learning task. Instead of fine-tuning
on limited dialogue data, our approach, DialogPrompt, learns continuous prompt
embeddings optimized for dialogue contexts, which appropriately elicit
knowledge from the large pre-trained model. To encourage the model to better
utilize the prompt embeddings, the prompt encoders are designed to be
conditioned on the input dialogue context. Experiments on popular conversation
datasets show that our approach significantly outperforms the fine-tuning
baseline and the generic prompt-learning methods. Furthermore, human
evaluations strongly support the superiority of DialogPrompt in regard to
response generation quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech recognition for air traffic control via feature learning and end-to-end training. (arXiv:2111.02654v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02654">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a new automatic speech recognition (ASR) system
based on feature learning and an end-to-end training procedure for air traffic
control (ATC) systems. The proposed model integrates the feature learning
block, recurrent neural network (RNN), and connectionist temporal
classification loss to build an end-to-end ASR model. Facing the complex
environments of ATC speech, instead of the handcrafted features, a learning
block is designed to extract informative features from raw waveforms for
acoustic modeling. Both the SincNet and 1D convolution blocks are applied to
process the raw waveforms, whose outputs are concatenated to the RNN layers for
the temporal modeling. Thanks to the ability to learn representations from raw
waveforms, the proposed model can be optimized in a complete end-to-end manner,
i.e., from waveform to text. Finally, the multilingual issue in the ATC domain
is also considered to achieve the ASR task by constructing a combined
vocabulary of Chinese characters and English letters. The proposed approach is
validated on a multilingual real-world corpus (ATCSpeech), and the experimental
results demonstrate that the proposed approach outperforms other baselines,
achieving a 6.9\% character error rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Voice Conversion Can Improve ASR in Very Low-Resource Settings. (arXiv:2111.02674v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02674">
<div class="article-summary-box-inner">
<span><p>Voice conversion (VC) has been proposed to improve speech recognition systems
in low-resource languages by using it to augment limited training data. But
until recently, practical issues such as compute speed have limited the use of
VC for this purpose. Moreover, it is still unclear whether a VC model trained
on one well-resourced language can be applied to speech from another
low-resource language for the purpose of data augmentation. In this work we
assess whether a VC system can be used cross-lingually to improve low-resource
speech recognition. Concretely, we combine several recent techniques to design
and train a practical VC system in English, and then use this system to augment
data for training a speech recognition model in several low-resource languages.
We find that when using a sensible amount of augmented data, speech recognition
performance is improved in all four low-resource languages considered.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoreLM: Coreference-aware Language Model Fine-Tuning. (arXiv:2111.02687v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02687">
<div class="article-summary-box-inner">
<span><p>Language Models are the underpin of all modern Natural Language Processing
(NLP) tasks. The introduction of the Transformers architecture has contributed
significantly into making Language Modeling very effective across many NLP
task, leading to significant advancements in the field. However, Transformers
come with a big computational cost, which grows quadratically with respect to
the input length. This presents a challenge as to understand long texts
requires a lot of context. In this paper, we propose a Fine-Tuning framework,
named CoreLM, that extends the architecture of current Pretrained Language
Models so that they incorporate explicit entity information. By introducing
entity representations, we make available information outside the contextual
space of the model, which results in a better Language Model for a fraction of
the computational cost. We implement our approach using GPT2 and compare the
fine-tuned model to the original. Our proposed model achieves a lower
Perplexity in GUMBY and LAMBDADA datasets when compared to GPT2 and a
fine-tuned version of GPT2 without any changes. We also compare the models'
performance in terms of Accuracy in LAMBADA and Children's Book Test, with and
without the use of model-created coreference annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking Multimodal AutoML for Tabular Data with Text Fields. (arXiv:2111.02705v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02705">
<div class="article-summary-box-inner">
<span><p>We consider the use of automated supervised learning systems for data tables
that not only contain numeric/categorical columns, but one or more text fields
as well. Here we assemble 18 multimodal data tables that each contain some text
fields and stem from a real business application. Our publicly-available
benchmark enables researchers to comprehensively evaluate their own methods for
supervised learning with numeric, categorical, and text features. To ensure
that any single modeling strategy which performs well over all 18 datasets will
serve as a practical foundation for multimodal text/tabular AutoML, the diverse
datasets in our benchmark vary greatly in: sample size, problem types (a mix of
classification and regression tasks), number of features (with the number of
text columns ranging from 1 to 28 between datasets), as well as how the
predictive signal is decomposed between text vs. numeric/categorical features
(and predictive interactions thereof). Over this benchmark, we evaluate various
straightforward pipelines to model such data, including standard two-stage
approaches where NLP is used to featurize the text such that AutoML for tabular
data can then be applied. Compared with human data science teams, the fully
automated methodology that performed best on our benchmark (stack ensembling a
multimodal Transformer with various tree models) also manages to rank 1st place
when fit to the raw text/tabular data in two MachineHack prediction
competitions and 2nd place (out of 2380 teams) in Kaggle's Mercari Price
Suggestion Challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Fine-tuned Wav2vec 2.0/HuBERT Benchmark For Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding. (arXiv:2111.02735v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02735">
<div class="article-summary-box-inner">
<span><p>Self-supervised speech representations such as wav2vec 2.0 and HuBERT are
making revolutionary progress in Automatic Speech Recognition (ASR). However,
self-supervised models have not been totally proved to produce better
performance on tasks other than ASR. In this work, we explore partial
fine-tuning and entire fine-tuning on wav2vec 2.0 and HuBERT pre-trained models
for three non-ASR speech tasks : Speech Emotion Recognition, Speaker
Verification and Spoken Language Understanding. We also compare pre-trained
models with/without ASR fine-tuning. With simple down-stream frameworks, the
best scores reach 79.58% weighted accuracy for Speech Emotion Recognition on
IEMOCAP, 2.36% equal error rate for Speaker Verification on VoxCeleb1, 87.51%
accuracy for Intent Classification and 75.32% F1 for Slot Filling on SLURP,
thus setting a new state-of-the-art for these three benchmarks, proving that
fine-tuned wav2vec 2.0 and HuBERT models can better learn prosodic, voice-print
and semantic representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medicines Question Answering System, MeQA. (arXiv:2111.02760v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02760">
<div class="article-summary-box-inner">
<span><p>In this paper we present the first system in Spanish capable of answering
questions about medicines for human use, called MeQA (Medicines Question
Answering), a project created by the Spanish Agency for Medicines and Health
Products (AEMPS, for its acronym in Spanish). Online services that offer
medical help have proliferated considerably, mainly due to the current pandemic
situation due to COVID-19. For example, websites such as Doctoralia, Savia, or
SaludOnNet, offer Doctor Answers type consultations, in which patients or users
can send questions to doctors and specialists, and receive an answer in less
than 24 hours. Many of the questions received are related to medicines for
human use, and most can be answered through the leaflets. Therefore, a system
such as MeQA capable of answering these types of questions automatically could
alleviate the burden on these websites, and it would be of great use to such
patients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Learning to Speak and Hear Through Multi-Agent Communication over a Continuous Acoustic Channel. (arXiv:2111.02827v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02827">
<div class="article-summary-box-inner">
<span><p>While multi-agent reinforcement learning has been used as an effective means
to study emergent communication between agents, existing work has focused
almost exclusively on communication with discrete symbols. Human communication
often takes place (and emerged) over a continuous acoustic channel; human
infants acquire language in large part through continuous signalling with their
caregivers. We therefore ask: Are we able to observe emergent language between
agents with a continuous communication channel trained through reinforcement
learning? And if so, what is the impact of channel characteristics on the
emerging language? We propose an environment and training methodology to serve
as a means to carry out an initial exploration of these questions. We use a
simple messaging environment where a "speaker" agent needs to convey a concept
to a "listener". The Speaker is equipped with a vocoder that maps symbols to a
continuous waveform, this is passed over a lossy continuous channel, and the
Listener needs to map the continuous signal to the concept. Using deep
Q-learning, we show that basic compositionality emerges in the learned language
representations. We find that noise is essential in the communication channel
when conveying unseen concept combinations. And we show that we can ground the
emergent communication by introducing a caregiver predisposed to "hearing" or
"speaking" English. Finally, we describe how our platform serves as a starting
point for future work that uses a combination of deep reinforcement learning
and multi-agent systems to study our questions of continuous signalling in
language learning and emergence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models. (arXiv:2111.02840v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02840">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models have achieved tremendous success
across a wide range of natural language understanding (NLU) tasks, even
surpassing human performance. However, recent studies reveal that the
robustness of these models can be challenged by carefully crafted textual
adversarial examples. While several individual datasets have been proposed to
evaluate model robustness, a principled and comprehensive benchmark is still
missing. In this paper, we present Adversarial GLUE (AdvGLUE), a new multi-task
benchmark to quantitatively and thoroughly explore and evaluate the
vulnerabilities of modern large-scale language models under various types of
adversarial attacks. In particular, we systematically apply 14 textual
adversarial attack methods to GLUE tasks to construct AdvGLUE, which is further
validated by humans for reliable annotations. Our findings are summarized as
follows. (i) Most existing adversarial attack algorithms are prone to
generating invalid or ambiguous adversarial examples, with around 90% of them
either changing the original semantic meanings or misleading human annotators
as well. Therefore, we perform a careful filtering process to curate a
high-quality benchmark. (ii) All the language models and robust training
methods we tested perform poorly on AdvGLUE, with scores lagging far behind the
benign accuracy. We hope our work will motivate the development of new
adversarial attacks that are more stealthy and semantic-preserving, as well as
new robust language models against sophisticated adversarial attacks. AdvGLUE
is available at https://adversarialglue.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A text autoencoder from transformer for fast encoding language representation. (arXiv:2111.02844v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02844">
<div class="article-summary-box-inner">
<span><p>In recent years BERT shows apparent advantages and great potential in natural
language processing tasks. However, both training and applying BERT requires
intensive time and resources for computing contextual language representations,
which hinders its universality and applicability. To overcome this bottleneck,
we propose a deep bidirectional language model by using window masking
mechanism at attention layer. This work computes contextual language
representations without random masking as does in BERT and maintains the deep
bidirectional architecture like BERT. To compute the same sentence
representation, our method shows O(n) complexity less compared to other
transformer-based models with O($n^2$). To further demonstrate its superiority,
computing context language representations on CPU environments is conducted, by
using the embeddings from the proposed method, logistic regression shows much
higher accuracy in terms of SMS classification. Moverover, the proposed method
also achieves significant higher performance in semantic similarity tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised and Distributional Detection of Machine-Generated Text. (arXiv:2111.02878v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02878">
<div class="article-summary-box-inner">
<span><p>The power of natural language generation models has provoked a flurry of
interest in automatic methods to detect if a piece of text is human or
machine-authored. The problem so far has been framed in a standard supervised
way and consists in training a classifier on annotated data to predict the
origin of one given new document. In this paper, we frame the problem in an
unsupervised and distributional way: we assume that we have access to a large
collection of unannotated documents, a big fraction of which is
machine-generated. We propose a method to detect those machine-generated
documents leveraging repeated higher-order n-grams, which we show over-appear
in machine-generated text as compared to human ones. That weak signal is the
starting point of a self-training setting where pseudo-labelled documents are
used to train an ensemble of classifiers. Our experiments show that leveraging
that signal allows us to rank suspicious documents accurately. Precision at
5000 is over 90% for top-k sampling strategies, and over 80% for nucleus
sampling for the largest model we used (GPT2-large). The drop with increased
size of model is small, which could indicate that the results hold for other
current and future large language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing the impact of out of vocabulary words in the translation of natural language questions into SPARQL queries. (arXiv:2111.03000v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03000">
<div class="article-summary-box-inner">
<span><p>Accessing the large volumes of information available in public knowledge
bases might be complicated for those users unfamiliar with the SPARQL query
language. Automatic translation of questions posed in natural language in
SPARQL has the potential of overcoming this problem. Existing systems based on
neural-machine translation are very effective but easily fail in recognizing
words that are Out Of the Vocabulary (OOV) of the training set. This is a
serious issue while querying large ontologies. In this paper, we combine Named
Entity Linking, Named Entity Recognition, and Neural Machine Translation to
perform automatic translation of natural language questions into SPARQL
queries. We demonstrate empirically that our approach is more effective and
resilient to OOV words than existing approaches by running the experiments on
Monument, QALD-9, and LC-QuAD v1, which are well-known datasets for Question
Answering over DBpedia.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting a Knowledge Base of COVID-19 Events from Social Media. (arXiv:2006.02567v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.02567">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a manually annotated corpus of 10,000 tweets
containing public reports of five COVID-19 events, including positive and
negative tests, deaths, denied access to testing, claimed cures and
preventions. We designed slot-filling questions for each event type and
annotated a total of 31 fine-grained slots, such as the location of events,
recent travel, and close contacts. We show that our corpus can support
fine-tuning BERT-based classifiers to automatically extract publicly reported
events and help track the spread of a new disease. We also demonstrate that, by
aggregating events extracted from millions of tweets, we achieve surprisingly
high precision when answering complex queries, such as "Which organizations
have employees that tested positive in Philadelphia?" We will release our
corpus (with user-information removed), automatic extraction models, and the
corresponding knowledge base to the research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ONION: A Simple and Effective Defense Against Textual Backdoor Attacks. (arXiv:2011.10369v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10369">
<div class="article-summary-box-inner">
<span><p>Backdoor attacks are a kind of emergent training-time threat to deep neural
networks (DNNs). They can manipulate the output of DNNs and possess high
insidiousness. In the field of natural language processing, some attack methods
have been proposed and achieve very high attack success rates on multiple
popular models. Nevertheless, there are few studies on defending against
textual backdoor attacks. In this paper, we propose a simple and effective
textual backdoor defense named ONION, which is based on outlier word detection
and, to the best of our knowledge, is the first method that can handle all the
textual backdoor attack situations. Experiments demonstrate the effectiveness
of our model in defending BiLSTM and BERT against five different backdoor
attacks. All the code and data of this paper can be obtained at
https://github.com/thunlp/ONION.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teach Me to Explain: A Review of Datasets for Explainable NLP. (arXiv:2102.12060v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12060">
<div class="article-summary-box-inner">
<span><p>Explainable NLP (ExNLP) has increasingly focused on collecting
human-annotated textual explanations. These explanations are used downstream in
three ways: as data augmentation to improve performance on a predictive task,
as supervision to train models to produce explanations for their predictions,
and as a ground-truth to evaluate model-generated explanations. In this review,
we identify 65 datasets with three predominant classes of textual explanations
(highlights, free-text, and structured), organize the literature on annotating
each type, identify strengths and shortcomings of existing collection
methodologies, and give recommendations for collecting ExNLP datasets in the
future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Hate Speech with GPT-3. (arXiv:2103.12407v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12407">
<div class="article-summary-box-inner">
<span><p>Sophisticated language models such as OpenAI's GPT-3 can generate hateful
text that targets marginalized groups. Given this capacity, we are interested
in whether large language models can be used to identify hate speech and
classify text as sexist or racist? We use GPT-3 to identify sexist and racist
text passages with zero-, one-, and few-shot learning. We find that with zero-
and one-shot learning, GPT-3 can identify sexist or racist text with an
accuracy between 48 per cent and 69 per cent. With few-shot learning and an
instruction included in the prompt, the model's accuracy can be as high as 78
per cent. We conclude that large language models have a role to play in hate
speech detection, and that with further development language models could be
used to counter hate speech and even self-police.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Embodied BERT: A Transformer Model for Embodied, Language-guided Visual Task Completion. (arXiv:2108.04927v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04927">
<div class="article-summary-box-inner">
<span><p>Language-guided robots performing home and office tasks must navigate in and
interact with the world. Grounding language instructions against visual
observations and actions to take in an environment is an open challenge. We
present Embodied BERT (EmBERT), a transformer-based model which can attend to
high-dimensional, multi-modal inputs across long temporal horizons for
language-conditioned task completion. Additionally, we bridge the gap between
successful object-centric navigation models used for non-interactive agents and
the language-guided visual task completion benchmark, ALFRED, by introducing
object navigation targets for EmBERT training. We achieve competitive
performance on the ALFRED benchmark, and EmBERT marks the first
transformer-based model to successfully handle the long-horizon, dense,
multi-modal histories of ALFRED, and the first ALFRED model to utilize
object-centric navigation targets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active learning for reducing labeling effort in text classification tasks. (arXiv:2109.04847v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04847">
<div class="article-summary-box-inner">
<span><p>Labeling data can be an expensive task as it is usually performed manually by
domain experts. This is cumbersome for deep learning, as it is dependent on
large labeled datasets. Active learning (AL) is a paradigm that aims to reduce
labeling effort by only using the data which the used model deems most
informative. Little research has been done on AL in a text classification
setting and next to none has involved the more recent, state-of-the-art Natural
Language Processing (NLP) models. Here, we present an empirical study that
compares different uncertainty-based algorithms with BERT$_{base}$ as the used
classifier. We evaluate the algorithms on two NLP classification datasets:
Stanford Sentiment Treebank and KvK-Frontpages. Additionally, we explore
heuristics that aim to solve presupposed problems of uncertainty-based AL;
namely, that it is unscalable and that it is prone to selecting outliers.
Furthermore, we explore the influence of the query-pool size on the performance
of AL. Whereas it was found that the proposed heuristics for AL did not improve
performance of AL; our results show that using uncertainty-based AL with
BERT$_{base}$ outperforms random sampling of data. This difference in
performance can decrease as the query-pool size gets larger.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CSAGN: Conversational Structure Aware Graph Network for Conversational Semantic Role Labeling. (arXiv:2109.11541v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11541">
<div class="article-summary-box-inner">
<span><p>Conversational semantic role labeling (CSRL) is believed to be a crucial step
towards dialogue understanding. However, it remains a major challenge for
existing CSRL parser to handle conversational structural information. In this
paper, we present a simple and effective architecture for CSRL which aims to
address this problem. Our model is based on a conversational structure-aware
graph network which explicitly encodes the speaker dependent information. We
also propose a multi-task learning method to further improve the model.
Experimental results on benchmark datasets show that our model with our
proposed training objectives significantly outperforms previous baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Who speaks like a style of Vitamin: Towards Syntax-Aware DialogueSummarization using Multi-task Learning. (arXiv:2109.14199v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14199">
<div class="article-summary-box-inner">
<span><p>Abstractive dialogue summarization is a challenging task for several reasons.
First, most of the important pieces of information in a conversation are
scattered across utterances through multi-party interactions with different
textual styles. Second, dialogues are often informal structures, wherein
different individuals express personal perspectives, unlike text summarization,
tasks that usually target formal documents such as news articles. To address
these issues, we focused on the association between utterances from individual
speakers and unique syntactic structures. Speakers have unique textual styles
that can contain linguistic information, such as voiceprint. Therefore, we
constructed a syntax-aware model by leveraging linguistic information (i.e.,
POS tagging), which alleviates the above issues by inherently distinguishing
sentences uttered from individual speakers. We employed multi-task learning of
both syntax-aware information and dialogue summarization. To the best of our
knowledge, our approach is the first method to apply multi-task learning to the
dialogue summarization task. Experiments on a SAMSum corpus (a large-scale
dialogue summarization corpus) demonstrated that our method improved upon the
vanilla model. We further analyze the costs and benefits of our approach
relative to baseline models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HydraSum: Disentangling Stylistic Features in Text Summarization using Multi-Decoder Models. (arXiv:2110.04400v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04400">
<div class="article-summary-box-inner">
<span><p>Existing abstractive summarization models lack explicit control mechanisms
that would allow users to influence the stylistic features of the model
outputs. This results in generating generic summaries that do not cater to the
users needs or preferences. To address this issue we introduce HydraSum, a new
summarization architecture that extends the single decoder framework of current
models, e.g. BART, to a mixture-of-experts version consisting of multiple
decoders. Our proposed model encourages each expert, i.e. decoder, to learn and
generate stylistically-distinct summaries along dimensions such as
abstractiveness, length, specificity, and others. At each time step, HydraSum
employs a gating mechanism that decides the contribution of each individual
decoder to the next token's output probability distribution. Through
experiments on three summarization datasets (CNN, Newsroom, XSum), we
demonstrate that this gating mechanism automatically learns to assign
contrasting summary styles to different HydraSum decoders under the standard
training objective without the need for additional supervision. We further show
that a guided version of the training process can explicitly govern which
summary style is partitioned between decoders, e.g. high abstractiveness vs.
low abstractiveness or high specificity vs. low specificity, and also increase
the stylistic-difference between individual decoders. Finally, our experiments
demonstrate that our decoder framework is highly flexible: during inference, we
can sample from individual decoders or mixtures of different subsets of the
decoders to yield a diverse set of summaries and enforce single- and
multi-style control over summary generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pruning Attention Heads of Transformer Models Using A* Search: A Novel Approach to Compress Big NLP Architectures. (arXiv:2110.15225v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15225">
<div class="article-summary-box-inner">
<span><p>Recent years have seen a growing adoption of Transformer models such as BERT
in Natural Language Processing and even in Computer Vision. However, due to the
size, there has been limited adoption of such models within
resource-constrained computing environments This paper proposes novel pruning
algorithms to compress transformer models by eliminating redundant Attention
Heads. We apply the A* search algorithm to obtain a pruned model with minimal
accuracy guarantees. Our results indicate that the method could eliminate as
much as 40% of the attention heads in the BERT transformer model with almost no
loss in accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying causal associations in tweets using deep learning: Use case on diabetes-related tweets from 2017-2021. (arXiv:2111.01225v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01225">
<div class="article-summary-box-inner">
<span><p>Objective: Leveraging machine learning methods, we aim to extract both
explicit and implicit cause-effect associations in patient-reported,
diabetes-related tweets and provide a tool to better understand opinion,
feelings and observations shared within the diabetes online community from a
causality perspective. Materials and Methods: More than 30 million
diabetes-related tweets in English were collected between April 2017 and
January 2021. Deep learning and natural language processing methods were
applied to focus on tweets with personal and emotional content. A
cause-effect-tweet dataset was manually labeled and used to train 1) a
fine-tuned Bertweet model to detect causal sentences containing a causal
association 2) a CRF model with BERT based features to extract possible
cause-effect associations. Causes and effects were clustered in a
semi-supervised approach and visualised in an interactive cause-effect-network.
Results: Causal sentences were detected with a recall of 68% in an imbalanced
dataset. A CRF model with BERT based features outperformed a fine-tuned BERT
model for cause-effect detection with a macro recall of 68%. This led to 96,676
sentences with cause-effect associations. "Diabetes" was identified as the
central cluster followed by "Death" and "Insulin". Insulin pricing related
causes were frequently associated with "Death". Conclusions: A novel
methodology was developed to detect causal sentences and identify both explicit
and implicit, single and multi-word cause and corresponding effect as expressed
in diabetes-related tweets leveraging BERT-based architectures and visualised
as cause-effect-network. Extracting causal associations on real-life, patient
reported outcomes in social media data provides a useful complementary source
of information in diabetes research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERT-DRE: BERT with Deep Recursive Encoder for Natural Language Sentence Matching. (arXiv:2111.02188v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02188">
<div class="article-summary-box-inner">
<span><p>This paper presents a deep neural architecture, for Natural Language Sentence
Matching (NLSM) by adding a deep recursive encoder to BERT so called BERT with
Deep Recursive Encoder (BERT-DRE). Our analysis of model behavior shows that
BERT still does not capture the full complexity of text, so a deep recursive
encoder is applied on top of BERT. Three Bi-LSTM layers with residual
connection are used to design a recursive encoder and an attention module is
used on top of this encoder. To obtain the final vector, a pooling layer
consisting of average and maximum pooling is used. We experiment our model on
four benchmarks, SNLI, FarsTail, MultiNLI, SciTail, and a novel Persian
religious questions dataset. This paper focuses on improving the BERT results
in the NLSM task. In this regard, comparisons between BERT-DRE and BERT are
conducted, and it is shown that in all cases, BERT-DRE outperforms BERT. The
BERT algorithm on the religious dataset achieved an accuracy of 89.70%, and
BERT-DRE architectures improved to 90.29% using the same dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Case Study and Qualitative Analysis of Simple Cross-Lingual Opinion Mining. (arXiv:2111.02259v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02259">
<div class="article-summary-box-inner">
<span><p>User-generated content from social media is produced in many languages,
making it technically challenging to compare the discussed themes from one
domain across different cultures and regions. It is relevant for domains in a
globalized world, such as market research, where people from two nations and
markets might have different requirements for a product. We propose a simple,
modern, and effective method for building a single topic model with sentiment
analysis capable of covering multiple languages simultanteously, based on a
pre-trained state-of-the-art deep neural network for natural language
understanding. To demonstrate its feasibility, we apply the model to newspaper
articles and user comments of a specific domain, i.e., organic food products
and related consumption behavior. The themes match across languages.
Additionally, we obtain an high proportion of stable and domain-relevant
topics, a meaningful relation between topics and their respective textual
contents, and an interpretable representation for social media documents.
Marketing can potentially benefit from our method, since it provides an
easy-to-use means of addressing specific customer interests from different
market regions around the globe. For reproducibility, we provide the code,
data, and results of our study.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Transparency of Deep Neural Networks for Medical Image Analysis: A Review of Interpretability Methods. (arXiv:2111.02398v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02398">
<div class="article-summary-box-inner">
<span><p>Artificial Intelligence has emerged as a useful aid in numerous clinical
applications for diagnosis and treatment decisions. Deep neural networks have
shown same or better performance than clinicians in many tasks owing to the
rapid increase in the available data and computational power. In order to
conform to the principles of trustworthy AI, it is essential that the AI system
be transparent, robust, fair and ensure accountability. Current deep neural
solutions are referred to as black-boxes due to a lack of understanding of the
specifics concerning the decision making process. Therefore, there is a need to
ensure interpretability of deep neural networks before they can be incorporated
in the routine clinical workflow. In this narrative review, we utilized
systematic keyword searches and domain expertise to identify nine different
types of interpretability methods that have been used for understanding deep
learning models for medical image analysis applications based on the type of
generated explanations and technical similarities. Furthermore, we report the
progress made towards evaluating the explanations produced by various
interpretability methods. Finally we discuss limitations, provide guidelines
for using interpretability methods and future directions concerning the
interpretability of deep neural networks for medical imaging analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Pruned Structure and Weights Simultaneously from Scratch: an Attention based Approach. (arXiv:2111.02399v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02399">
<div class="article-summary-box-inner">
<span><p>As a deep learning model typically contains millions of trainable weights,
there has been a growing demand for a more efficient network structure with
reduced storage space and improved run-time efficiency. Pruning is one of the
most popular network compression techniques. In this paper, we propose a novel
unstructured pruning pipeline, Attention-based Simultaneous sparse structure
and Weight Learning (ASWL). Unlike traditional channel-wise or weight-wise
attention mechanism, ASWL proposed an efficient algorithm to calculate the
pruning ratio through layer-wise attention for each layer, and both weights for
the dense network and the sparse network are tracked so that the pruned
structure is simultaneously learned from randomly initialized weights. Our
experiments on MNIST, Cifar10, and ImageNet show that ASWL achieves superior
pruning results in terms of accuracy, pruning ratio and operating efficiency
when compared with state-of-the-art network pruning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep AUC Maximization for Medical Image Classification: Challenges and Opportunities. (arXiv:2111.02400v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02400">
<div class="article-summary-box-inner">
<span><p>In this extended abstract, we will present and discuss opportunities and
challenges brought about by a new deep learning method by AUC maximization (aka
\underline{\bf D}eep \underline{\bf A}UC \underline{\bf M}aximization or {\bf
DAM}) for medical image classification. Since AUC (aka area under ROC curve) is
a standard performance measure for medical image classification, hence directly
optimizing AUC could achieve a better performance for learning a deep neural
network than minimizing a traditional loss function (e.g., cross-entropy loss).
Recently, there emerges a trend of using deep AUC maximization for large-scale
medical image classification. In this paper, we will discuss these recent
results by highlighting (i) the advancements brought by stochastic non-convex
optimization algorithms for DAM; (ii) the promising results on various medical
image classification problems. Then, we will discuss challenges and
opportunities of DAM for medical image classification from three perspectives,
feature learning, large-scale optimization, and learning trustworthy AI models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skin Cancer Classification using Inception Network and Transfer Learning. (arXiv:2111.02402v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02402">
<div class="article-summary-box-inner">
<span><p>Medical data classification is typically a challenging task due to imbalance
between classes. In this paper, we propose an approach to classify
dermatoscopic images from HAM10000 (Human Against Machine with 10000 training
images) dataset, consisting of seven imbalanced types of skin lesions, with
good precision and low resources requirements. Classification is done by using
a pretrained convolutional neural network. We evaluate the accuracy and
performance of the proposal and illustrate possible extensions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WORD: Revisiting Organs Segmentation in the Whole Abdominal Region. (arXiv:2111.02403v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02403">
<div class="article-summary-box-inner">
<span><p>Whole abdominal organs segmentation plays an important role in abdomen lesion
diagnosis, radiotherapy planning, and follow-up. However, delineating all
abdominal organs by oncologists manually is time-consuming and very expensive.
Recently, deep learning-based medical image segmentation has shown the
potential to reduce manual delineation efforts, but it still requires a
large-scale fine annotated dataset for training. Although many efforts in this
task, there are still few large image datasets covering the whole abdomen
region with accurate and detailed annotations for the whole abdominal organ
segmentation. In this work, we establish a large-scale \textit{W}hole abdominal
\textit{OR}gans \textit{D}ataset (\textit{WORD}) for algorithms research and
clinical applications development. This dataset contains 150 abdominal CT
volumes (30495 slices) and each volume has 16 organs with fine pixel-level
annotations and scribble-based sparse annotation, which may be the largest
dataset with whole abdominal organs annotation. Several state-of-the-art
segmentation methods are evaluated on this dataset. And, we also invited
clinical oncologists to revise the model predictions to measure the gap between
the deep learning method and real oncologists. We further introduce and
evaluate a new scribble-based weakly supervised segmentation on this dataset.
The work provided a new benchmark for the abdominal multi-organ segmentation
task and these experiments can serve as the baseline for future research and
clinical application development. The codebase and dataset will be released at:
https://github.com/HiLab-git/WORD
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Partial supervision for the FeTA challenge 2021. (arXiv:2111.02408v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02408">
<div class="article-summary-box-inner">
<span><p>This paper describes our method for our participation in the FeTA
challenge2021 (team name: TRABIT). The performance of convolutional neural
networks for medical image segmentation is thought to correlate positively with
the number of training data. The FeTA challenge does not restrict participants
to using only the provided training data but also allows for using other
publicly available sources. Yet, open access fetal brain data remains limited.
An advantageous strategy could thus be to expand the training data to cover
broader perinatal brain imaging sources. Perinatal brain MRIs, other than the
FeTA challenge data, that are currently publicly available, span normal and
pathological fetal atlases as well as neonatal scans. However, perinatal brain
MRIs segmented in different datasets typically come with different annotation
protocols. This makes it challenging to combine those datasets to train a deep
neural network. We recently proposed a family of loss functions, the label-set
loss functions, for partially supervised learning. Label-set loss functions
allow to train deep neural networks with partially segmented images, i.e.
segmentations in which some classes may be grouped into super-classes. We
propose to use label-set loss functions to improve the segmentation performance
of a state-of-the-art deep learning pipeline for multi-class fetal brain
segmentation by merging several publicly available datasets. To promote
generalisability, our approach does not introduce any additional
hyper-parameters tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breast Cancer Classification Using: Pixel Interpolation. (arXiv:2111.02409v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02409">
<div class="article-summary-box-inner">
<span><p>Image Processing represents the backbone research area within engineering and
computer science specialization. It is promptly growing technologies today, and
its applications founded in various aspects of biomedical fields especially in
cancer disease. Breast cancer is considered the fatal one of all cancer types
according to recent statistics all over the world. It is the most commonly
cancer in women and the second reason of cancer death between females. About
23% of the total cancer cases in both developing and developed countries. In
this work, an interpolation process was used to classify the breast cancer into
main types, benign and malignant. This scheme dependent on the morphologic
spectrum of mammographic masses. Malignant tumors had irregular shape percent
higher than the benign tumors. By this way the boundary of the tumor will be
interpolated by additional pixels to make the boundary smoothen as possible,
these needed pixels is proportional with irregularity shape of the tumor, so
that the increasing in interpolated pixels meaning the tumor goes toward the
malignant case. The proposed system is implemented using MATLAB programming and
tested over several images taken from the Mammogram Image Analysis Society
(MIAS) image database. The MIAS offers a regular classification for
mammographic studies. The system works faster so that any radiologist can take
a clear decision about the appearance of calcifications by visual inspection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Panoptic 3D Scene Reconstruction From a Single RGB Image. (arXiv:2111.02444v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02444">
<div class="article-summary-box-inner">
<span><p>Understanding 3D scenes from a single image is fundamental to a wide variety
of tasks, such as for robotics, motion planning, or augmented reality. Existing
works in 3D perception from a single RGB image tend to focus on geometric
reconstruction only, or geometric reconstruction with semantic segmentation or
instance segmentation. Inspired by 2D panoptic segmentation, we propose to
unify the tasks of geometric reconstruction, 3D semantic segmentation, and 3D
instance segmentation into the task of panoptic 3D scene reconstruction - from
a single RGB image, predicting the complete geometric reconstruction of the
scene in the camera frustum of the image, along with semantic and instance
segmentations. We thus propose a new approach for holistic 3D scene
understanding from a single RGB image which learns to lift and propagate 2D
features from an input image to a 3D volumetric scene representation. We
demonstrate that this holistic view of joint scene reconstruction, semantic,
and instance segmentation is beneficial over treating the tasks independently,
thus outperforming alternative approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Frequency Bias of Generative Models. (arXiv:2111.02447v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02447">
<div class="article-summary-box-inner">
<span><p>The key objective of Generative Adversarial Networks (GANs) is to generate
new data with the same statistics as the provided training data. However,
multiple recent works show that state-of-the-art architectures yet struggle to
achieve this goal. In particular, they report an elevated amount of high
frequencies in the spectral statistics which makes it straightforward to
distinguish real and generated images. Explanations for this phenomenon are
controversial: While most works attribute the artifacts to the generator, other
works point to the discriminator. We take a sober look at those explanations
and provide insights on what makes proposed measures against high-frequency
artifacts effective. To achieve this, we first independently assess the
architectures of both the generator and discriminator and investigate if they
exhibit a frequency bias that makes learning the distribution of high-frequency
content particularly problematic. Based on these experiments, we make the
following four observations: 1) Different upsampling operations bias the
generator towards different spectral properties. 2) Checkerboard artifacts
introduced by upsampling cannot explain the spectral discrepancies alone as the
generator is able to compensate for these artifacts. 3) The discriminator does
not struggle with detecting high frequencies per se but rather struggles with
frequencies of low magnitude. 4) The downsampling operations in the
discriminator can impair the quality of the training signal it provides. In
light of these findings, we analyze proposed measures against high-frequency
artifacts in state-of-the-art GAN training but find that none of the existing
approaches can fully resolve spectral artifacts yet. Our results suggest that
there is great potential in improving the discriminator and that this could be
key to match the distribution of the training data more closely.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified 3D Mesh Recovery of Humans and Animals by Learning Animal Exercise. (arXiv:2111.02450v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02450">
<div class="article-summary-box-inner">
<span><p>We propose an end-to-end unified 3D mesh recovery of humans and quadruped
animals trained in a weakly-supervised way. Unlike recent work focusing on a
single target class only, we aim to recover 3D mesh of broader classes with a
single multi-task model. However, there exists no dataset that can directly
enable multi-task learning due to the absence of both human and animal
annotations for a single object, e.g., a human image does not have animal pose
annotations; thus, we have to devise a new way to exploit heterogeneous
datasets. To make the unstable disjoint multi-task learning jointly trainable,
we propose to exploit the morphological similarity between humans and animals,
motivated by animal exercise where humans imitate animal poses. We realize the
morphological similarity by semantic correspondences, called sub-keypoint,
which enables joint training of human and animal mesh regression branches.
Besides, we propose class-sensitive regularization methods to avoid a
mean-shape bias and to improve the distinctiveness across multi-classes. Our
method performs favorably against recent uni-modal models on various human and
animal datasets while being far more compact.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Slapping Cats, Bopping Heads, and Oreo Shakes: Understanding Indicators of Virality in TikTok Short Videos. (arXiv:2111.02452v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02452">
<div class="article-summary-box-inner">
<span><p>Short videos have become one of the leading media used by younger generations
to express themselves online and thus a driving force in shaping online
culture. In this context, TikTok has emerged as a platform where viral videos
are often posted first. In this paper, we study what elements of short videos
posted on TikTok contribute to their virality. We apply a mixed-method approach
to develop a codebook and identify important virality features. We do so
vis-\`a-vis three research hypotheses; namely, that: 1) the video content, 2)
TikTok's recommendation algorithm, and 3) the popularity of the video creator
contribute to virality.
</p>
<p>We collect and label a dataset of 400 TikTok videos and train classifiers to
help us identify the features that influence virality the most. While the
number of followers is the most powerful predictor, close-up and medium-shot
scales also play an essential role. So does the lifespan of the video, the
presence of text, and the point of view. Our research highlights the
characteristics that distinguish viral from non-viral TikTok videos, laying the
groundwork for developing additional approaches to create more engaging online
content and proactively identify possibly risky content that is likely to reach
a large audience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic ultrasound vessel segmentation with deep spatiotemporal context learning. (arXiv:2111.02461v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02461">
<div class="article-summary-box-inner">
<span><p>Accurate, real-time segmentation of vessel structures in ultrasound image
sequences can aid in the measurement of lumen diameters and assessment of
vascular diseases. This, however, remains a challenging task, particularly for
extremely small vessels that are difficult to visualize. We propose to leverage
the rich spatiotemporal context available in ultrasound to improve segmentation
of small-scale lower-extremity arterial vasculature. We describe efficient deep
learning methods that incorporate temporal, spatial, and feature-aware
contextual embeddings at multiple resolution scales while jointly utilizing
information from B-mode and Color Doppler signals. Evaluating on femoral and
tibial artery scans performed on healthy subjects by an expert
ultrasonographer, and comparing to consensus expert ground-truth annotations of
inner lumen boundaries, we demonstrate real-time segmentation using the
context-aware models and show that they significantly outperform comparable
baseline approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Roadmap on Signal Processing for Next Generation Measurement Systems. (arXiv:2111.02493v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02493">
<div class="article-summary-box-inner">
<span><p>Signal processing is a fundamental component of almost any sensor-enabled
system, with a wide range of applications across different scientific
disciplines. Time series data, images, and video sequences comprise
representative forms of signals that can be enhanced and analysed for
information extraction and quantification. The recent advances in artificial
intelligence and machine learning are shifting the research attention towards
intelligent, data-driven, signal processing. This roadmap presents a critical
overview of the state-of-the-art methods and applications aiming to highlight
future challenges and research opportunities towards next generation
measurement systems. It covers a broad spectrum of topics ranging from basic to
industrial research, organized in concise thematic sections that reflect the
trends and the impacts of current and future developments per research field.
Furthermore, it offers guidance to researchers and funding agencies in
identifying new prospects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Pose Estimation through Contextual Activity Fusion. (arXiv:2111.02500v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02500">
<div class="article-summary-box-inner">
<span><p>This research presents the idea of activity fusion into existing Pose
Estimation architectures to enhance their predictive ability. This is motivated
by the rise in higher level concepts found in modern machine learning
architectures, and the belief that activity context is a useful piece of
information for the problem of pose estimation. To analyse this concept we take
an existing deep learning architecture and augment it with an additional 1x1
convolution to fuse activity information into the model. We perform evaluation
and comparison on a common pose estimation dataset, and show a performance
improvement over our baseline model, especially in uncommon poses and on
typically difficult joints. Additionally, we perform an ablative analysis to
indicate that the performance improvement does in fact draw from the activity
information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resampling and super-resolution of hexagonally sampled images using deep learning. (arXiv:2111.02520v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02520">
<div class="article-summary-box-inner">
<span><p>Super-resolution (SR) aims to increase the resolution of imagery.
Applications include security, medical imaging, and object recognition. We
propose a deep learning-based SR system that takes a hexagonally sampled
low-resolution image as an input and generates a rectangularly sampled SR image
as an output. For training and testing, we use a realistic observation model
that includes optical degradation from diffraction and sensor degradation from
detector integration. Our SR approach first uses non-uniform interpolation to
partially upsample the observed hexagonal imagery and convert it to a
rectangular grid. We then leverage a state-of-the-art convolutional neural
network (CNN) architecture designed for SR known as Residual Channel Attention
Network (RCAN). In particular, we use RCAN to further upsample and restore the
imagery to produce the final SR image estimate. We demonstrate that this system
is superior to applying RCAN directly to rectangularly sampled LR imagery with
equivalent sample density. The theoretical advantages of hexagonal sampling are
well known. However, to the best of our knowledge, the practical benefit of
hexagonal sampling in light of modern processing techniques such as RCAN SR is
heretofore untested. Our SR system demonstrates a notable advantage of
hexagonally sampled imagery when employing a modified RCAN for hexagonal SR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence-to-Sequence Modeling for Action Identification at High Temporal Resolution. (arXiv:2111.02521v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02521">
<div class="article-summary-box-inner">
<span><p>Automatic action identification from video and kinematic data is an important
machine learning problem with applications ranging from robotics to smart
health. Most existing works focus on identifying coarse actions such as
running, climbing, or cutting a vegetable, which have relatively long
durations. This is an important limitation for applications that require the
identification of subtle motions at high temporal resolution. For example, in
stroke recovery, quantifying rehabilitation dose requires differentiating
motions with sub-second durations. Our goal is to bridge this gap. To this end,
we introduce a large-scale, multimodal dataset, StrokeRehab, as a new
action-recognition benchmark that includes subtle short-duration actions
labeled at a high temporal resolution. These short-duration actions are called
functional primitives, and consist of reaches, transports, repositions,
stabilizations, and idles. The dataset consists of high-quality Inertial
Measurement Unit sensors and video data of 41 stroke-impaired patients
performing activities of daily living like feeding, brushing teeth, etc. We
show that current state-of-the-art models based on segmentation produce noisy
predictions when applied to these data, which often leads to overcounting of
actions. To address this, we propose a novel approach for high-resolution
action identification, inspired by speech-recognition techniques, which is
based on a sequence-to-sequence model that directly predicts the sequence of
actions. This approach outperforms current state-of-the-art methods on the
StrokeRehab dataset, as well as on the standard benchmark datasets 50Salads,
Breakfast, and Jigsaws.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Cross Domain Presentation Attack Detection for Visible Face Recognition. (arXiv:2111.02548v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02548">
<div class="article-summary-box-inner">
<span><p>Face signatures, including size, shape, texture, skin tone, eye color,
appearance, and scars/marks, are widely used as discriminative, biometric
information for access control. Despite recent advancements in facial
recognition systems, presentation attacks on facial recognition systems have
become increasingly sophisticated. The ability to detect presentation attacks
or spoofing attempts is a pressing concern for the integrity, security, and
trust of facial recognition systems. Multi-spectral imaging has been previously
introduced as a way to improve presentation attack detection by utilizing
sensors that are sensitive to different regions of the electromagnetic spectrum
(e.g., visible, near infrared, long-wave infrared). Although multi-spectral
presentation attack detection systems may be discriminative, the need for
additional sensors and computational resources substantially increases
complexity and costs. Instead, we propose a method that exploits information
from infrared imagery during training to increase the discriminability of
visible-based presentation attack detection systems. We introduce (1) a new
cross-domain presentation attack detection framework that increases the
separability of bonafide and presentation attacks using only visible spectrum
imagery, (2) an inverse domain regularization technique for added training
stability when optimizing our cross-domain presentation attack detection
framework, and (3) a dense domain adaptation subnetwork to transform
representations between visible and non-visible domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building Damage Mapping with Self-PositiveUnlabeled Learning. (arXiv:2111.02586v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02586">
<div class="article-summary-box-inner">
<span><p>Humanitarian organizations must have fast and reliable data to respond to
disasters. Deep learning approaches are difficult to implement in real-world
disasters because it might be challenging to collect ground truth data of the
damage situation (training data) soon after the event. The implementation of
recent self-paced positive-unlabeled learning (PU) is demonstrated in this work
by successfully applying to building damage assessment with very limited
labeled data and a large amount of unlabeled data. Self-PU learning is compared
with the supervised baselines and traditional PU learning using different
datasets collected from the 2011 Tohoku earthquake, the 2018 Palu tsunami, and
the 2018 Hurricane Michael. By utilizing only a portion of labeled damaged
samples, we show how models trained with self-PU techniques may achieve
comparable performance as supervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Qimera: Data-free Quantization with Synthetic Boundary Supporting Samples. (arXiv:2111.02625v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02625">
<div class="article-summary-box-inner">
<span><p>Model quantization is known as a promising method to compress deep neural
networks, especially for inferences on lightweight mobile or edge devices.
However, model quantization usually requires access to the original training
data to maintain the accuracy of the full-precision models, which is often
infeasible in real-world scenarios for security and privacy issues. A popular
approach to perform quantization without access to the original data is to use
synthetically generated samples, based on batch-normalization statistics or
adversarial learning. However, the drawback of such approaches is that they
primarily rely on random noise input to the generator to attain diversity of
the synthetic samples. We find that this is often insufficient to capture the
distribution of the original data, especially around the decision boundaries.
To this end, we propose Qimera, a method that uses superposed latent embeddings
to generate synthetic boundary supporting samples. For the superposed
embeddings to better reflect the original distribution, we also propose using
an additional disentanglement mapping layer and extracting information from the
full-precision model. The experimental results show that Qimera achieves
state-of-the-art performances for various settings on data-free quantization.
Code is available at https://github.com/iamkanghyunchoi/qimera.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporal Fusion Based Mutli-scale Semantic Segmentation for Detecting Concealed Baggage Threats. (arXiv:2111.02651v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02651">
<div class="article-summary-box-inner">
<span><p>Detection of illegal and threatening items in baggage is one of the utmost
security concern nowadays. Even for experienced security personnel, manual
detection is a time-consuming and stressful task. Many academics have created
automated frameworks for detecting suspicious and contraband data from X-ray
scans of luggage. However, to our knowledge, no framework exists that utilizes
temporal baggage X-ray imagery to effectively screen highly concealed and
occluded objects which are barely visible even to the naked eye. To address
this, we present a novel temporal fusion driven multi-scale residual fashioned
encoder-decoder that takes series of consecutive scans as input and fuses them
to generate distinct feature representations of the suspicious and
non-suspicious baggage content, leading towards a more accurate extraction of
the contraband data. The proposed methodology has been thoroughly tested using
the publicly accessible GDXray dataset, which is the only dataset containing
temporally linked grayscale X-ray scans showcasing extremely concealed
contraband data. The proposed framework outperforms its competitors on the
GDXray dataset on various metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LVIS Challenge Track Technical Report 1st Place Solution: Distribution Balanced and Boundary Refinement for Large Vocabulary Instance Segmentation. (arXiv:2111.02668v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02668">
<div class="article-summary-box-inner">
<span><p>This report introduces the technical details of the team FuXi-Fresher for
LVIS Challenge 2021. Our method focuses on the problem in following two
aspects: the long-tail distribution and the segmentation quality of mask and
boundary. Based on the advanced HTC instance segmentation algorithm, we connect
transformer backbone(Swin-L) through composite connections inspired by CBNetv2
to enhance the baseline results. To alleviate the problem of long-tail
distribution, we design a Distribution Balanced method which includes dataset
balanced and loss function balaced modules. Further, we use a Mask and Boundary
Refinement method composed with mask scoring and refine-mask algorithms to
improve the segmentation quality. In addition, we are pleasantly surprised to
find that early stopping combined with EMA method can achieve a great
improvement. Finally, by using multi-scale testing and increasing the upper
limit of the number of objects detected per image, we achieved more than 45.4%
boundary AP on the val set of LVIS Challenge 2021. On the test data of LVIS
Challenge 2021, we rank 1st and achieve 48.1% AP. Notably, our APr 47.5% is
very closed to the APf 48.0%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A semi-automatic ultrasound image analysis system for the grading diagnosis of COVID-19 pneumonia. (arXiv:2111.02676v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02676">
<div class="article-summary-box-inner">
<span><p>This paper proposes a semi-automatic system based on quantitative
characterization of the specific image patterns in lung ultrasound (LUS)
images, in order to assess the lung conditions of patients with COVID-19
pneumonia, as well as to differentiate between the severe / and no-severe
cases. Specifically, four parameters are extracted from each LUS image, namely
the thickness (TPL) and roughness (RPL) of the pleural line, and the
accumulated with (AWBL) and acoustic coefficient (ACBL) of B lines. 27 patients
are enrolled in this study, which are grouped into 13 moderate patients, 7
severe patients and 7 critical patients. Furthermore, the severe and critical
patients are regarded as the severe cases, and the moderate patients are
regarded as the non-severe cases. Biomarkers among different groups are
compared. Each single biomarker and a classifier with all the biomarkers as
input are utilized for the binary diagnosis of severe case and non-severe case,
respectively. The classifier achieves the best classification performance among
all the compared methods (area under the receiver operating characteristics
curve = 0.93, sensitivity = 0.93, specificity = 0.85). The proposed image
analysis system could be potentially applied to the grading and prognosis
evaluation of patients with COVID-19 pneumonia.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MixSiam: A Mixture-based Approach to Self-supervised Representation Learning. (arXiv:2111.02679v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02679">
<div class="article-summary-box-inner">
<span><p>Recently contrastive learning has shown significant progress in learning
visual representations from unlabeled data. The core idea is training the
backbone to be invariant to different augmentations of an instance. While most
methods only maximize the feature similarity between two augmented data, we
further generate more challenging training samples and force the model to keep
predicting discriminative representation on these hard samples. In this paper,
we propose MixSiam, a mixture-based approach upon the traditional siamese
network. On the one hand, we input two augmented images of an instance to the
backbone and obtain the discriminative representation by performing an
element-wise maximum of two features. On the other hand, we take the mixture of
these augmented images as input, and expect the model prediction to be close to
the discriminative representation. In this way, the model could access more
variant data samples of an instance and keep predicting invariant
discriminative representations for them. Thus the learned model is more robust
compared to previous contrastive learning methods. Extensive experiments on
large-scale datasets show that MixSiam steadily improves the baseline and
achieves competitive results with state-of-the-art methods. Our code will be
released soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TimeMatch: Unsupervised Cross-Region Adaptation by Temporal Shift Estimation. (arXiv:2111.02682v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02682">
<div class="article-summary-box-inner">
<span><p>The recent developments of deep learning models that capture the complex
temporal patterns of crop phenology have greatly advanced crop classification
of Satellite Image Time Series (SITS). However, when applied to target regions
spatially different from the training region, these models perform poorly
without any target labels due to the temporal shift of crop phenology between
regions. To address this unsupervised cross-region adaptation setting, existing
methods learn domain-invariant features without any target supervision, but not
the temporal shift itself. As a consequence, these techniques provide only
limited benefits for SITS. In this paper, we propose TimeMatch, a new
unsupervised domain adaptation method for SITS that directly accounts for the
temporal shift. TimeMatch consists of two components: 1) temporal shift
estimation, which estimates the temporal shift of the unlabeled target region
with a source-trained model, and 2) TimeMatch learning, which combines temporal
shift estimation with semi-supervised learning to adapt a classifier to an
unlabeled target region. We also introduce an open-access dataset for
cross-region adaptation with SITS from four different regions in Europe. On
this dataset, we demonstrate that TimeMatch outperforms all competing methods
by 11% in F1-score across five different adaptation scenarios, setting a new
state-of-the-art for cross-region adaptation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Smart Monitored AM: Open Source in-Situ Layer-wise 3D Printing Image Anomaly Detection Using Histograms of Oriented Gradients and a Physics-Based Rendering Engine. (arXiv:2111.02703v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02703">
<div class="article-summary-box-inner">
<span><p>This study presents an open source method for detecting 3D printing anomalies
by comparing images of printed layers from a stationary monocular camera with
G-code-based reference images of an ideal process generated with Blender, a
physics rendering engine. Recognition of visual deviations was accomplished by
analyzing the similarity of histograms of oriented gradients (HOG) of local
image areas. The developed technique requires preliminary modeling of the
working environment to achieve the best match for orientation, color rendering,
lighting, and other parameters of the printed part. The output of the algorithm
is a level of mismatch between printed and synthetic reference layers. Twelve
similarity and distance measures were implemented and compared for their
effectiveness at detecting 3D printing errors on six different representative
failure types and their control error-free print images. The results show that
although Kendall tau, Jaccard, and Sorensen similarities are the most
sensitive, Pearson r, Spearman rho, cosine, and Dice similarities produce the
more reliable results. This open source method allows the program to notice
critical errors in the early stages of their occurrence and either pause
manufacturing processes for further investigation by an operator or in the
future AI-controlled automatic error correction. The implementation of this
novel method does not require preliminary data for training, and the greatest
efficiency can be achieved with the mass production of parts by either additive
or subtractive manufacturing of the same geometric shape. It can be concluded
this open source method is a promising means of enabling smart distributed
recycling for additive manufacturing using complex feedstocks as well as other
challenging manufacturing environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards dynamic multi-modal phenotyping using chest radiographs and physiological data. (arXiv:2111.02710v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02710">
<div class="article-summary-box-inner">
<span><p>The healthcare domain is characterized by heterogeneous data modalities, such
as imaging and physiological data. In practice, the variety of medical data
assists clinicians in decision-making. However, most of the current
state-of-the-art deep learning models solely rely upon carefully curated data
of a single modality. In this paper, we propose a dynamic training approach to
learn modality-specific data representations and to integrate auxiliary
features, instead of solely relying on a single modality. Our preliminary
experiments results for a patient phenotyping task using physiological data in
MIMIC-IV &amp; chest radiographs in the MIMIC- CXR dataset show that our proposed
approach achieves the highest area under the receiver operating characteristic
curve (AUROC) (0.764 AUROC) compared to the performance of the benchmark method
in previous work, which only used physiological data (0.740 AUROC). For a set
of five recurring or chronic diseases with periodic acute episodes, including
cardiac dysrhythmia, conduction disorders, and congestive heart failure, the
AUROC improves from 0.747 to 0.798. This illustrates the benefit of leveraging
the chest imaging modality in the phenotyping task and highlights the potential
of multi-modal learning in medical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Facial Emotion Recognition using Deep Residual Networks in Real-World Environments. (arXiv:2111.02717v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02717">
<div class="article-summary-box-inner">
<span><p>Automatic affect recognition using visual cues is an important task towards a
complete interaction between humans and machines. Applications can be found in
tutoring systems and human computer interaction. A critical step towards that
direction is facial feature extraction. In this paper, we propose a facial
feature extractor model trained on an in-the-wild and massively collected video
dataset provided by the RealEyes company. The dataset consists of a million
labelled frames and 2,616 thousand subjects. As temporal information is
important to the emotion recognition domain, we utilise LSTM cells to capture
the temporal dynamics in the data. To show the favourable properties of our
pre-trained model on modelling facial affect, we use the RECOLA database, and
compare with the current state-of-the-art approach. Our model provides the best
results in terms of concordance correlation coefficient.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tea Chrysanthemum Detection under Unstructured Environments Using the TC-YOLO Model. (arXiv:2111.02724v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02724">
<div class="article-summary-box-inner">
<span><p>Tea chrysanthemum detection at its flowering stage is one of the key
components for selective chrysanthemum harvesting robot development. However,
it is a challenge to detect flowering chrysanthemums under unstructured field
environments given the variations on illumination, occlusion and object scale.
In this context, we propose a highly fused and lightweight deep learning
architecture based on YOLO for tea chrysanthemum detection (TC-YOLO). First, in
the backbone component and neck component, the method uses the Cross-Stage
Partially Dense Network (CSPDenseNet) as the main network, and embeds custom
feature fusion modules to guide the gradient flow. In the final head component,
the method combines the recursive feature pyramid (RFP) multiscale fusion
reflow structure and the Atrous Spatial Pyramid Pool (ASPP) module with cavity
convolution to achieve the detection task. The resulting model was tested on
300 field images, showing that under the NVIDIA Tesla P100 GPU environment, if
the inference speed is 47.23 FPS for each image (416 * 416), TC-YOLO can
achieve the average precision (AP) of 92.49% on our own tea chrysanthemum
dataset. In addition, this method (13.6M) can be deployed on a single mobile
GPU, and it could be further developed as a perception system for a selective
chrysanthemum harvesting robot in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Neural Networks Using Different Sensors Create Similar Features. (arXiv:2111.02732v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02732">
<div class="article-summary-box-inner">
<span><p>Multimodal problems are omnipresent in the real world: autonomous driving,
robotic grasping, scene understanding, etc... We draw from the well-developed
analysis of similarity to provide an example of a problem where neural networks
are trained from different sensors, and where the features extracted from these
sensors still carry similar information. More precisely, we demonstrate that
for each sensor, the linear combination of the features from the last layer
that correlates the most with other sensors corresponds to the classification
components of the classification layer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Methods for Daily Wildfire Danger Forecasting. (arXiv:2111.02736v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02736">
<div class="article-summary-box-inner">
<span><p>Wildfire forecasting is of paramount importance for disaster risk reduction
and environmental sustainability. We approach daily fire danger prediction as a
machine learning task, using historical Earth observation data from the last
decade to predict next-day's fire danger. To that end, we collect, pre-process
and harmonize an open-access datacube, featuring a set of covariates that
jointly affect the fire occurrence and spread, such as weather conditions,
satellite-derived products, topography features and variables related to human
activity. We implement a variety of Deep Learning (DL) models to capture the
spatial, temporal or spatio-temporal context and compare them against a Random
Forest (RF) baseline. We find that either spatial or temporal context is enough
to surpass the RF, while a ConvLSTM that exploits the spatio-temporal context
performs best with a test Area Under the Receiver Operating Characteristic of
0.926. Our DL-based proof-of-concept provides national-scale daily fire danger
maps at a much higher spatial resolution than existing operational solutions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-scale 2D Representation Learning for weakly-supervised moment retrieval. (arXiv:2111.02741v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02741">
<div class="article-summary-box-inner">
<span><p>Video moment retrieval aims to search the moment most relevant to a given
language query. However, most existing methods in this community often require
temporal boundary annotations which are expensive and time-consuming to label.
Hence weakly supervised methods have been put forward recently by only using
coarse video-level label. Despite effectiveness, these methods usually process
moment candidates independently, while ignoring a critical issue that the
natural temporal dependencies between candidates in different temporal scales.
To cope with this issue, we propose a Multi-scale 2D Representation Learning
method for weakly supervised video moment retrieval. Specifically, we first
construct a two-dimensional map for each temporal scale to capture the temporal
dependencies between candidates. Two dimensions in this map indicate the start
and end time points of these candidates. Then, we select top-K candidates from
each scale-varied map with a learnable convolutional neural network. With a
newly designed Moments Evaluation Module, we obtain the alignment scores of the
selected candidates. At last, the similarity between captions and language
query is served as supervision for further training the candidates' selector.
Experiments on two benchmark datasets Charades-STA and ActivityNet Captions
demonstrate that our approach achieves superior performance to state-of-the-art
results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FEAFA+: An Extended Well-Annotated Dataset for Facial Expression Analysis and 3D Facial Animation. (arXiv:2111.02751v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02751">
<div class="article-summary-box-inner">
<span><p>Nearly all existing Facial Action Coding System-based datasets that include
facial action unit (AU) intensity information annotate the intensity values
hierarchically using A--E levels. However, facial expressions change
continuously and shift smoothly from one state to another. Therefore, it is
more effective to regress the intensity value of local facial AUs to represent
whole facial expression changes, particularly in the fields of expression
transfer and facial animation. We introduce an extension of FEAFA in
combination with the relabeled DISFA database, which is available at
https://www.iiplab.net/feafa+/ now. Extended FEAFA (FEAFA+) includes 150 video
sequences from FEAFA and DISFA, with a total of 230,184 frames being manually
annotated on floating-point intensity value of 24 redefined AUs using the
Expression Quantitative Tool. We also list crude numerical results for posed
and spontaneous subsets and provide a baseline comparison for the AU intensity
regression task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Continual Learning via Multiple Deep Metric Learning and Uncertainty-guided Episodic Memory Replay -- 3rd Place Solution for ICCV 2021 Workshop SSLAD Track 3A Continual Object Classification. (arXiv:2111.02757v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02757">
<div class="article-summary-box-inner">
<span><p>Online continual learning in the wild is a very difficult task in machine
learning. Non-stationarity in online continual learning potentially brings
about catastrophic forgetting in neural networks. Specifically, online
continual learning for autonomous driving with SODA10M dataset exhibits extra
problems on extremely long-tailed distribution with continuous distribution
shift. To address these problems, we propose multiple deep metric
representation learning via both contrastive and supervised contrastive
learning alongside soft labels distillation to improve model generalization.
Moreover, we exploit modified class-balanced focal loss for sensitive
penalization in class imbalanced and hard-easy samples. We also store some
samples under guidance of uncertainty metric for rehearsal and perform online
and periodical memory updates. Our proposed method achieves considerable
generalization with average mean class accuracy (AMCA) 64.01% on validation and
64.53% AMCA on test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The role of MRI physics in brain segmentation CNNs: achieving acquisition invariance and instructive uncertainties. (arXiv:2111.02771v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02771">
<div class="article-summary-box-inner">
<span><p>Being able to adequately process and combine data arising from different
sites is crucial in neuroimaging, but is difficult, owing to site, sequence and
acquisition-parameter dependent biases. It is important therefore to design
algorithms that are not only robust to images of differing contrasts, but also
be able to generalise well to unseen ones, with a quantifiable measure of
uncertainty. In this paper we demonstrate the efficacy of a physics-informed,
uncertainty-aware, segmentation network that employs augmentation-time MR
simulations and homogeneous batch feature stratification to achieve acquisition
invariance. We show that the proposed approach also accurately extrapolates to
out-of-distribution sequence samples, providing well calibrated volumetric
bounds on these. We demonstrate a significant improvement in terms of
coefficients of variation, backed by uncertainty based volumetric validation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stable and Compact Face Recognition via Unlabeled Data Driven Sparse Representation-Based Classification. (arXiv:2111.02847v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02847">
<div class="article-summary-box-inner">
<span><p>Sparse representation-based classification (SRC) has attracted much attention
by casting the recognition problem as simple linear regression problem. SRC
methods, however, still is limited to enough labeled samples per category,
insufficient use of unlabeled samples, and instability of representation. For
tackling these problems, an unlabeled data driven inverse projection
pseudo-full-space representation-based classification model is proposed with
low-rank sparse constraints. The proposed model aims to mine the hidden
semantic information and intrinsic structure information of all available data,
which is suitable for few labeled samples and proportion imbalance between
labeled samples and unlabeled samples problems in frontal face recognition. The
mixed Gauss-Seidel and Jacobian ADMM algorithm is introduced to solve the
model. The convergence, representation capability and stability of the model
are analyzed. Experiments on three public datasets show that the proposed
LR-S-PFSRC model achieves stable results, especially for proportion imbalance
of samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Testing using Privileged Information by Adapting Features with Statistical Dependence. (arXiv:2111.02865v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02865">
<div class="article-summary-box-inner">
<span><p>Given an imperfect predictor, we exploit additional features at test time to
improve the predictions made, without retraining and without knowledge of the
prediction function. This scenario arises if training labels or data are
proprietary, restricted, or no longer available, or if training itself is
prohibitively expensive. We assume that the additional features are useful if
they exhibit strong statistical dependence to the underlying perfect predictor.
Then, we empirically estimate and strengthen the statistical dependence between
the initial noisy predictor and the additional features via manifold denoising.
As an example, we show that this approach leads to improvement in real-world
visual attribute ranking. Project webpage: <a href="http://www.jamestompkin.com/tupi">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extended Abstract Version: CNN-based Human Detection System for UAVs in Search and Rescue. (arXiv:2111.02870v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02870">
<div class="article-summary-box-inner">
<span><p>This paper proposes an approach for the task of searching and detecting human
using a convolutional neural network and a Quadcopter hardware platform. A
pre-trained CNN model is applied to a Raspberry Pi B and a single camera is
equipped at the bottom of the Quadcopter. The Quadcopter uses
accelerometer-gyroscope sensor and ultrasonic sensor for balancing control.
However, these sensors are susceptible to noise caused by the driving forces
such as the vibration of the motors, thus, noise processing is implemented.
Experiments proved that the system works well on the Raspberry Pi B with a
processing speed of 3 fps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Certainty Volume Prediction for Unsupervised Domain Adaptation. (arXiv:2111.02901v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02901">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation (UDA) deals with the problem of classifying
unlabeled target domain data while labeled data is only available for a
different source domain. Unfortunately, commonly used classification methods
cannot fulfill this task adequately due to the domain gap between the source
and target data. In this paper, we propose a novel uncertainty-aware domain
adaptation setup that models uncertainty as a multivariate Gaussian
distribution in feature space. We show that our proposed uncertainty measure
correlates with other common uncertainty quantifications and relates to
smoothing the classifier's decision boundary, therefore improving the
generalization capabilities. We evaluate our proposed pipeline on challenging
UDA datasets and achieve state-of-the-art results. Code for our method is
available at https://gitlab.com/tringwald/cvp.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Change Detection of Extreme Events Using ML On-Board. (arXiv:2111.02995v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02995">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce RaVAEn, a lightweight, unsupervised approach for
change detection in satellite data based on Variational Auto-Encoders (VAEs)
with the specific purpose of on-board deployment. Applications such as disaster
management enormously benefit from the rapid availability of satellite
observations. Traditionally, data analysis is performed on the ground after all
data is transferred - downlinked - to a ground station. Constraint on the
downlink capabilities therefore affects any downstream application. In
contrast, RaVAEn pre-processes the sampled data directly on the satellite and
flags changed areas to prioritise for downlink, shortening the response time.
We verified the efficacy of our system on a dataset composed of time series of
catastrophic events - which we plan to release alongside this publication -
demonstrating that RaVAEn outperforms pixel-wise baselines. Finally we tested
our approach on resource-limited hardware for assessing computational and
memory limitations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Panoptic 3D Parsing for Single Image in the Wild. (arXiv:2111.03039v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03039">
<div class="article-summary-box-inner">
<span><p>Performing single image holistic understanding and 3D reconstruction is a
central task in computer vision. This paper presents an integrated system that
performs holistic image segmentation, object detection, instance segmentation,
depth estimation, and object instance 3D reconstruction for indoor and outdoor
scenes from a single RGB image. We name our system panoptic 3D parsing in which
panoptic segmentation ("stuff" segmentation and "things"
detection/segmentation) with 3D reconstruction is performed. We design a
stage-wise system where a complete set of annotations is absent. Additionally,
we present an end-to-end pipeline trained on a synthetic dataset with a full
set of annotations. We show results on both indoor (3D-FRONT) and outdoor (COCO
and Cityscapes) scenes. Our proposed panoptic 3D parsing framework points to a
promising direction in computer vision. It can be applied to various
applications, including autonomous driving, mapping, robotics, design, computer
graphics, robotics, human-computer interaction, and augmented reality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Learning of Compositional Energy Concepts. (arXiv:2111.03042v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03042">
<div class="article-summary-box-inner">
<span><p>Humans are able to rapidly understand scenes by utilizing concepts extracted
from prior experience. Such concepts are diverse, and include global scene
descriptors, such as the weather or lighting, as well as local scene
descriptors, such as the color or size of a particular object. So far,
unsupervised discovery of concepts has focused on either modeling the global
scene-level or the local object-level factors of variation, but not both. In
this work, we propose COMET, which discovers and represents concepts as
separate energy functions, enabling us to represent both global concepts as
well as objects under a unified framework. COMET discovers energy functions
through recomposing the input image, which we find captures independent factors
without additional supervision. Sample generation in COMET is formulated as an
optimization process on underlying energy functions, enabling us to generate
images with permuted and composed concepts. Finally, discovered visual concepts
in COMET generalize well, enabling us to compose concepts between separate
modalities of images as well as with other concepts discovered by a separate
instance of COMET trained on a different dataset. Code and data available at
https://energy-based-model.github.io/comet/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A deep ensemble approach to X-ray polarimetry. (arXiv:2111.03047v1 [astro-ph.IM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03047">
<div class="article-summary-box-inner">
<span><p>X-ray polarimetry will soon open a new window on the high energy universe
with the launch of NASA's Imaging X-ray Polarimetry Explorer (IXPE).
Polarimeters are currently limited by their track reconstruction algorithms,
which typically use linear estimators and do not consider individual event
quality. We present a modern deep learning method for maximizing the
sensitivity of X-ray telescopic observations with imaging polarimeters, with a
focus on the gas pixel detectors (GPDs) to be flown on IXPE. We use a weighted
maximum likelihood combination of predictions from a deep ensemble of ResNets,
trained on Monte Carlo event simulations. We derive and apply the optimal event
weighting for maximizing the polarization signal-to-noise ratio (SNR) in track
reconstruction algorithms. For typical power-law source spectra, our method
improves on the current state of the art, providing a ~40% decrease in required
exposure times for a given SNR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bootstrap Your Object Detector via Mixed Training. (arXiv:2111.03056v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03056">
<div class="article-summary-box-inner">
<span><p>We introduce MixTraining, a new training paradigm for object detection that
can improve the performance of existing detectors for free. MixTraining
enhances data augmentation by utilizing augmentations of different strengths
while excluding the strong augmentations of certain training samples that may
be detrimental to training. In addition, it addresses localization noise and
missing labels in human annotations by incorporating pseudo boxes that can
compensate for these errors. Both of these MixTraining capabilities are made
possible through bootstrapping on the detector, which can be used to predict
the difficulty of training on a strong augmentation, as well as to generate
reliable pseudo boxes thanks to the robustness of neural networks to labeling
error. MixTraining is found to bring consistent improvements across various
detectors on the COCO dataset. In particular, the performance of Faster R-CNN
\cite{ren2015faster} with a ResNet-50 \cite{he2016deep} backbone is improved
from 41.7 mAP to 44.0 mAP, and the accuracy of Cascade-RCNN
\cite{cai2018cascade} with a Swin-Small \cite{liu2021swin} backbone is raised
from 50.9 mAP to 52.8 mAP. The code and models will be made publicly available
at \url{https://github.com/MendelXu/MixTraining}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalization in Dexterous Manipulation via Geometry-Aware Multi-Task Learning. (arXiv:2111.03062v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03062">
<div class="article-summary-box-inner">
<span><p>Dexterous manipulation of arbitrary objects, a fundamental daily task for
humans, has been a grand challenge for autonomous robotic systems. Although
data-driven approaches using reinforcement learning can develop specialist
policies that discover behaviors to control a single object, they often exhibit
poor generalization to unseen ones. In this work, we show that policies learned
by existing reinforcement learning algorithms can in fact be generalist when
combined with multi-task learning and a well-chosen object representation. We
show that a single generalist policy can perform in-hand manipulation of over
100 geometrically-diverse real-world objects and generalize to new objects with
unseen shape or size. Interestingly, we find that multi-task learning with
object point cloud representations not only generalizes better but even
outperforms the single-object specialist policies on both training as well as
held-out test objects. Video results at
https://huangwl18.github.io/geometry-dex
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Variational Semi-Supervised Novelty Detection. (arXiv:1911.04971v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.04971">
<div class="article-summary-box-inner">
<span><p>In anomaly detection (AD), one seeks to identify whether a test sample is
abnormal, given a data set of normal samples. A recent and promising approach
to AD relies on deep generative models, such as variational autoencoders
(VAEs), for unsupervised learning of the normal data distribution. In
semi-supervised AD (SSAD), the data also includes a small sample of labeled
anomalies. In this work, we propose two variational methods for training VAEs
for SSAD. The intuitive idea in both methods is to train the encoder to
`separate' between latent vectors for normal and outlier data. We show that
this idea can be derived from principled probabilistic formulations of the
problem, and propose simple and effective algorithms. Our methods can be
applied to various data types, as we demonstrate on SSAD datasets ranging from
natural images to astronomy and medicine, can be combined with any VAE model
architecture, and are naturally compatible with ensembling. When comparing to
state-of-the-art SSAD methods that are not specific to particular data types,
we obtain marked improvement in outlier detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross modal video representations for weakly supervised active speaker localization. (arXiv:2003.04358v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.04358">
<div class="article-summary-box-inner">
<span><p>An objective understanding of media depictions, such as inclusive portrayals
of how much someone is heard and seen on screen such as in film and television,
requires the machines to discern automatically who, when, how, and where
someone is talking, and not. Speaker activity can be automatically discerned
from the rich multimodal information present in the media content. This is
however a challenging problem due to the vast variety and contextual
variability in the media content, and the lack of labeled data. In this work,
we present a cross-modal neural network for learning visual representations,
which have implicit information pertaining to the spatial location of a speaker
in the visual frames. Avoiding the need for manual annotations for active
speakers in visual frames, acquiring of which is very expensive, we present a
weakly supervised system for the task of localizing active speakers in movie
content. We use the learned cross-modal visual representations, and provide
weak supervision from movie subtitles acting as a proxy for voice activity,
thus requiring no manual annotations. We evaluate the performance of the
proposed system on the AVA active speaker dataset and demonstrate the
effectiveness of the cross-modal embeddings for localizing active speakers in
comparison to fully supervised systems. We also demonstrate state-of-the-art
performance for the task of voice activity detection in an audio-visual
framework, especially when speech is accompanied by noise and music.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Texture Memory-Augmented Deep Patch-Based Image Inpainting. (arXiv:2009.13240v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13240">
<div class="article-summary-box-inner">
<span><p>Patch-based methods and deep networks have been employed to tackle image
inpainting problem, with their own strengths and weaknesses. Patch-based
methods are capable of restoring a missing region with high-quality texture
through searching nearest neighbor patches from the unmasked regions. However,
these methods bring problematic contents when recovering large missing regions.
Deep networks, on the other hand, show promising results in completing large
regions. Nonetheless, the results often lack faithful and sharp details that
resemble the surrounding area. By bringing together the best of both paradigms,
we propose a new deep inpainting framework where texture generation is guided
by a texture memory of patch samples extracted from unmasked regions. The
framework has a novel design that allows texture memory retrieval to be trained
end-to-end with the deep inpainting network. In addition, we introduce a patch
distribution loss to encourage high-quality patch synthesis. The proposed
method shows superior performance both qualitatively and quantitatively on
three challenging image benchmarks, i.e., Places, CelebA-HQ, and Paris
Street-View datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Denoising Diffusion Implicit Models. (arXiv:2010.02502v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02502">
<div class="article-summary-box-inner">
<span><p>Denoising diffusion probabilistic models (DDPMs) have achieved high quality
image generation without adversarial training, yet they require simulating a
Markov chain for many steps to produce a sample. To accelerate sampling, we
present denoising diffusion implicit models (DDIMs), a more efficient class of
iterative implicit probabilistic models with the same training procedure as
DDPMs. In DDPMs, the generative process is defined as the reverse of a
Markovian diffusion process. We construct a class of non-Markovian diffusion
processes that lead to the same training objective, but whose reverse process
can be much faster to sample from. We empirically demonstrate that DDIMs can
produce high quality samples $10 \times$ to $50 \times$ faster in terms of
wall-clock time compared to DDPMs, allow us to trade off computation for sample
quality, and can perform semantically meaningful image interpolation directly
in the latent space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Contrastive Learning Approach for Training Variational Autoencoder Priors. (arXiv:2010.02917v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02917">
<div class="article-summary-box-inner">
<span><p>Variational autoencoders (VAEs) are one of the powerful likelihood-based
generative models with applications in many domains. However, they struggle to
generate high-quality images, especially when samples are obtained from the
prior without any tempering. One explanation for VAEs' poor generative quality
is the prior hole problem: the prior distribution fails to match the aggregate
approximate posterior. Due to this mismatch, there exist areas in the latent
space with high density under the prior that do not correspond to any encoded
image. Samples from those areas are decoded to corrupted images. To tackle this
issue, we propose an energy-based prior defined by the product of a base prior
distribution and a reweighting factor, designed to bring the base closer to the
aggregate posterior. We train the reweighting factor by noise contrastive
estimation, and we generalize it to hierarchical VAEs with many latent variable
groups. Our experiments confirm that the proposed noise contrastive priors
improve the generative performance of state-of-the-art VAEs by a large margin
on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ 256 datasets. Our method is
simple and can be applied to a wide variety of VAEs to improve the expressivity
of their prior distribution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why Do Better Loss Functions Lead to Less Transferable Features?. (arXiv:2010.16402v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.16402">
<div class="article-summary-box-inner">
<span><p>Previous work has proposed many new loss functions and regularizers that
improve test accuracy on image classification tasks. However, it is not clear
whether these loss functions learn better representations for downstream tasks.
This paper studies how the choice of training objective affects the
transferability of the hidden representations of convolutional neural networks
trained on ImageNet. We show that many objectives lead to statistically
significant improvements in ImageNet accuracy over vanilla softmax
cross-entropy, but the resulting fixed feature extractors transfer
substantially worse to downstream tasks, and the choice of loss has little
effect when networks are fully fine-tuned on the new tasks. Using centered
kernel alignment to measure similarity between hidden representations of
networks, we find that differences among loss functions are apparent only in
the last few layers of the network. We delve deeper into representations of the
penultimate layer, finding that different objectives and hyperparameter
combinations lead to dramatically different levels of class separation.
Representations with higher class separation obtain higher accuracy on the
original task, but their features are less useful for downstream tasks. Our
results suggest there exists a trade-off between learning invariant features
for the original task and features relevant for transfer tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SFTrack++: A Fast Learnable Spectral Segmentation Approach for Space-Time Consistent Tracking. (arXiv:2011.13843v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13843">
<div class="article-summary-box-inner">
<span><p>We propose an object tracking method, SFTrack++, that smoothly learns to
preserve the tracked object consistency over space and time dimensions by
taking a spectral clustering approach over the graph of pixels from the video,
using a fast 3D filtering formulation for finding the principal eigenvector of
this graph's adjacency matrix. To better capture complex aspects of the tracked
object, we enrich our formulation to multi-channel inputs, which permit
different points of view for the same input. The channel inputs are in our
experiments, the output of multiple tracking methods. After combining them,
instead of relying only on hidden layers representations to predict a good
tracking bounding box, we explicitly learn an intermediate, more refined one,
namely the segmentation map of the tracked object. This prevents the rough
common bounding box approach to introduce noise and distractors in the learning
process. We test our method, SFTrack++, on five tracking benchmarks: OTB, UAV,
NFS, GOT-10k, and TrackingNet, using five top trackers as input. Our
experimental results validate the pre-registered hypothesis. We obtain
consistent and robust results, competitive on the three traditional benchmarks
(OTB, UAV, NFS) and significantly on top of others (by over $1.1\%$ on
accuracy) on GOT-10k and TrackingNet, which are newer, larger, and more varied
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EfficientLPS: Efficient LiDAR Panoptic Segmentation. (arXiv:2102.08009v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08009">
<div class="article-summary-box-inner">
<span><p>Panoptic segmentation of point clouds is a crucial task that enables
autonomous vehicles to comprehend their vicinity using their highly accurate
and reliable LiDAR sensors. Existing top-down approaches tackle this problem by
either combining independent task-specific networks or translating methods from
the image domain ignoring the intricacies of LiDAR data and thus often
resulting in sub-optimal performance. In this paper, we present the novel
top-down Efficient LiDAR Panoptic Segmentation (EfficientLPS) architecture that
addresses multiple challenges in segmenting LiDAR point clouds including
distance-dependent sparsity, severe occlusions, large scale-variations, and
re-projection errors. EfficientLPS comprises of a novel shared backbone that
encodes with strengthened geometric transformation modeling capacity and
aggregates semantically rich range-aware multi-scale features. It incorporates
new scale-invariant semantic and instance segmentation heads along with the
panoptic fusion module which is supervised by our proposed panoptic periphery
loss function. Additionally, we formulate a regularized pseudo labeling
framework to further improve the performance of EfficientLPS by training on
unlabelled data. We benchmark our proposed model on two large-scale LiDAR
datasets: nuScenes, for which we also provide ground truth annotations, and
SemanticKITTI. Notably, EfficientLPS sets the new state-of-the-art on both
these datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Video Prediction for Time Series Forecasting. (arXiv:2102.12061v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12061">
<div class="article-summary-box-inner">
<span><p>Time series forecasting is essential for decision making in many domains. In
this work, we address the challenge of predicting prices evolution among
multiple potentially interacting financial assets. A solution to this problem
has obvious importance for governments, banks, and investors. Statistical
methods such as Auto Regressive Integrated Moving Average (ARIMA) are widely
applied to these problems. In this paper, we propose to approach economic time
series forecasting of multiple financial assets in a novel way via video
prediction. Given past prices of multiple potentially interacting financial
assets, we aim to predict the prices evolution in the future. Instead of
treating the snapshot of prices at each time point as a vector, we spatially
layout these prices in 2D as an image, such that we can harness the power of
CNNs in learning a latent representation for these financial assets. Thus, the
history of these prices becomes a sequence of images, and our goal becomes
predicting future images. We build on a state-of-the-art video prediction
method for forecasting future images. Our experiments involve the prediction
task of the price evolution of nine financial assets traded in U.S. stock
markets. The proposed method outperforms baselines including ARIMA, Prophet,
and variations of the proposed method, demonstrating the benefits of harnessing
the power of CNNs in the problem of economic time series forecasting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised deep convolutional neural network for chest X-ray classification. (arXiv:2103.03055v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03055">
<div class="article-summary-box-inner">
<span><p>Chest radiography is a relatively cheap, widely available medical procedure
that conveys key information for making diagnostic decisions. Chest X-rays are
almost always used in the diagnosis of respiratory diseases such as pneumonia
or the recent COVID-19. In this paper, we propose a self-supervised deep neural
network that is pretrained on an unlabeled chest X-ray dataset. The learned
representations are transferred to downstream task - the classification of
respiratory diseases. The results obtained on four public datasets show that
our approach yields competitive results without requiring large amounts of
labeled training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Mean Teacher for Semi-supervised Chest X-ray Classification. (arXiv:2103.03629v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03629">
<div class="article-summary-box-inner">
<span><p>The training of deep learning models generally requires a large amount of
annotated data for effective convergence and generalisation. However, obtaining
high-quality annotations is a laboursome and expensive process due to the need
of expert radiologists for the labelling task. The study of semi-supervised
learning in medical image analysis is then of crucial importance given that it
is much less expensive to obtain unlabelled images than to acquire images
labelled by expert radiologists. Essentially, semi-supervised methods leverage
large sets of unlabelled data to enable better training convergence and
generalisation than using only the small set of labelled images. In this paper,
we propose Self-supervised Mean Teacher for Semi-supervised (S$^2$MTS$^2$)
learning that combines self-supervised mean-teacher pre-training with
semi-supervised fine-tuning. The main innovation of S$^2$MTS$^2$ is the
self-supervised mean-teacher pre-training based on the joint contrastive
learning, which uses an infinite number of pairs of positive query and key
features to improve the mean-teacher representation. The model is then
fine-tuned using the exponential moving average teacher framework trained with
semi-supervised learning. We validate S$^2$MTS$^2$ on the multi-label
classification problems from Chest X-ray14 and CheXpert, and the multi-class
classification from ISIC2018, where we show that it outperforms the previous
SOTA semi-supervised learning methods by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global canopy height regression and uncertainty estimation from GEDI LIDAR waveforms with deep ensembles. (arXiv:2103.03975v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03975">
<div class="article-summary-box-inner">
<span><p>NASA's Global Ecosystem Dynamics Investigation (GEDI) is a key climate
mission whose goal is to advance our understanding of the role of forests in
the global carbon cycle. While GEDI is the first space-based LIDAR explicitly
optimized to measure vertical forest structure predictive of aboveground
biomass, the accurate interpretation of this vast amount of waveform data
across the broad range of observational and environmental conditions is
challenging. Here, we present a novel supervised machine learning approach to
interpret GEDI waveforms and regress canopy top height globally. We propose a
probabilistic deep learning approach based on an ensemble of deep convolutional
neural networks(CNN) to avoid the explicit modelling of unknown effects, such
as atmospheric noise. The model learns to extract robust features that
generalize to unseen geographical regions and, in addition, yields reliable
estimates of predictive uncertainty. Ultimately, the global canopy top height
estimates produced by our model have an expected RMSE of 2.7 m with low bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scale-aware Neural Network for Semantic Segmentation of Multi-resolution Remote Sensing Images. (arXiv:2103.07935v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07935">
<div class="article-summary-box-inner">
<span><p>Assigning geospatial objects with specific categories at the pixel level is a
fundamental task in remote sensing image analysis. Along with rapid development
in sensor technologies, remotely sensed images can be captured at multiple
spatial resolutions (MSR) with information content manifested at different
scales. Extracting information from these MSR images represents huge
opportunities for enhanced feature representation and characterisation.
However, MSR images suffer from two critical issues: 1) increased scale
variation of geo-objects and 2) loss of detailed information at coarse spatial
resolutions. To bridge these gaps, in this paper, we propose a novel
scale-aware neural network (SaNet) for semantic segmentation of MSR remotely
sensed imagery. SaNet deploys a densely connected feature network (DCFFM)
module to capture high-quality multi-scale context, such that the scale
variation is handled properly and the quality of segmentation is increased for
both large and small objects. A spatial feature recalibration (SFRM) module is
further incorporated into the network to learn intact semantic content with
enhanced spatial relationships, where the negative effects of information loss
are removed. The combination of DCFFM and SFRM allows SaNet to learn
scale-aware feature representation, which outperforms the existing multi-scale
feature representation. Extensive experiments on three semantic segmentation
datasets demonstrated the effectiveness of the proposed SaNet in
cross-resolution segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Whitney extension problem for near isometries and beyond. (arXiv:2103.09748v3 [math.CA] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09748">
<div class="article-summary-box-inner">
<span><p>In this memoir, we develop a general framework which allows for a
simultaneous study of labeled and unlabeled near alignment data problems in
$\mathbb R^D$ and the Whitney near isometry extension problem for discrete and
non-discrete subsets of $\mathbb R^D$ with certain geometries. In addition, we
survey related work of ours on clustering, dimension reduction, manifold
learning, vision as well as minimal energy partitions, discrepancy and min-max
optimization. Numerous open problems in harmonic analysis, computer vision,
manifold learning and signal processing connected to our work are given.
</p>
<p>A significant portion of the work in this memoir is based on joint research
with Charles Fefferman in the papers [48], [49], [50], [51].
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning in Multi-Task Graphs through Iterative Consensus Shift. (arXiv:2103.14417v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14417">
<div class="article-summary-box-inner">
<span><p>The human ability to synchronize the feedback from all their senses inspired
recent works in multi-task and multi-modal learning. While these works rely on
expensive supervision, our multi-task graph requires only pseudo-labels from
expert models. Every graph node represents a task, and each edge learns between
tasks transformations. Once initialized, the graph learns self-supervised,
based on a novel consensus shift algorithm that intelligently exploits the
agreement between graph pathways to generate new pseudo-labels for the next
learning cycle. We demonstrate significant improvement from one unsupervised
learning iteration to the next, outperforming related recent methods in
extensive multi-task learning experiments on two challenging datasets. Our code
is available at https://github.com/bit-ml/cshift.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Neural Operations for Diverse Tasks. (arXiv:2103.15798v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15798">
<div class="article-summary-box-inner">
<span><p>An important goal of AutoML is to automate-away the design of neural networks
on new tasks in under-explored domains. Motivated by this goal, we study the
problem of enabling users to discover the right neural operations given data
from their specific domain. We introduce a search space of operations called
XD-Operations that mimic the inductive bias of standard multi-channel
convolutions while being much more expressive: we prove that it includes many
named operations across multiple application areas. Starting with any standard
backbone such as ResNet, we show how to transform it into a search space over
XD-operations and how to traverse the space using a simple weight-sharing
scheme. On a diverse set of tasks -- solving PDEs, distance prediction for
protein folding, and music modeling -- our approach consistently yields models
with lower error than baseline networks and often even lower error than
expert-designed domain-specific approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Measuring Fairness in AI: the Casual Conversations Dataset. (arXiv:2104.02821v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02821">
<div class="article-summary-box-inner">
<span><p>This paper introduces a novel dataset to help researchers evaluate their
computer vision and audio models for accuracy across a diverse set of age,
genders, apparent skin tones and ambient lighting conditions. Our dataset is
composed of 3,011 subjects and contains over 45,000 videos, with an average of
15 videos per person. The videos were recorded in multiple U.S. states with a
diverse set of adults in various age, gender and apparent skin tone groups. A
key feature is that each subject agreed to participate for their likenesses to
be used. Additionally, our age and gender annotations are provided by the
subjects themselves. A group of trained annotators labeled the subjects'
apparent skin tone using the Fitzpatrick skin type scale. Moreover, annotations
for videos recorded in low ambient lighting are also provided. As an
application to measure robustness of predictions across certain attributes, we
provide a comprehensive study on the top five winners of the DeepFake Detection
Challenge (DFDC). Experimental evaluation shows that the winning models are
less performant on some specific groups of people, such as subjects with darker
skin tones and thus may not generalize to all people. In addition, we also
evaluate the state-of-the-art apparent age and gender classification methods.
Our experiments provides a thorough analysis on these models in terms of fair
treatment of people from various backgrounds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Landmark-Aware and Part-based Ensemble Transfer Learning Network for Facial Expression Recognition from Static images. (arXiv:2104.11274v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11274">
<div class="article-summary-box-inner">
<span><p>Facial Expression Recognition from static images is a challenging problem in
computer vision applications. Convolutional Neural Network (CNN), the
state-of-the-art method for various computer vision tasks, has had limited
success in predicting expressions from faces having extreme poses,
illumination, and occlusion conditions. To mitigate this issue, CNNs are often
accompanied by techniques like transfer, multi-task, or ensemble learning that
often provide high accuracy at the cost of increased computational complexity.
In this work, we propose a Part-based Ensemble Transfer Learning network that
models how humans recognize facial expressions by correlating the spatial
orientation pattern of the facial features with a specific expression. It
consists of 5 sub-networks, and each sub-network performs transfer learning
from one of the five subsets of facial landmarks: eyebrows, eyes, nose, mouth,
or jaw to expression classification. We show that our proposed ensemble network
uses visual patterns emanating from facial muscles' motor movements to predict
expressions and demonstrate the usefulness of transfer learning from Facial
Landmark Localization to Facial Expression Recognition. We test the proposed
network on the CK+, JAFFE, and SFEW datasets, and it outperforms the benchmark
for CK+ and JAFFE datasets by 0.51% and 5.34%, respectively. Additionally, the
proposed ensemble network consists of only 1.65M model parameters, ensuring
computational efficiency during training and real-time deployment. Grad-CAM
visualizations of our proposed ensemble highlight the complementary nature of
its sub-networks, a key design parameter of an effective ensemble network.
Lastly, cross-dataset evaluation results reveal that our proposed ensemble has
a high generalization capacity, making it suitable for real-world usage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relative stability toward diffeomorphisms indicates performance in deep nets. (arXiv:2105.02468v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02468">
<div class="article-summary-box-inner">
<span><p>Understanding why deep nets can classify data in large dimensions remains a
challenge. It has been proposed that they do so by becoming stable to
diffeomorphisms, yet existing empirical measurements support that it is often
not the case. We revisit this question by defining a maximum-entropy
distribution on diffeomorphisms, that allows to study typical diffeomorphisms
of a given norm. We confirm that stability toward diffeomorphisms does not
strongly correlate to performance on benchmark data sets of images. By
contrast, we find that the stability toward diffeomorphisms relative to that of
generic transformations $R_f$ correlates remarkably with the test error
$\epsilon_t$. It is of order unity at initialization but decreases by several
decades during training for state-of-the-art architectures. For CIFAR10 and 15
known architectures, we find $\epsilon_t\approx 0.2\sqrt{R_f}$, suggesting that
obtaining a small $R_f$ is important to achieve good performance. We study how
$R_f$ depends on the size of the training set and compare it to a simple model
of invariant learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predify: Augmenting deep neural networks with brain-inspired predictive coding dynamics. (arXiv:2106.02749v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02749">
<div class="article-summary-box-inner">
<span><p>Deep neural networks excel at image classification, but their performance is
far less robust to input perturbations than human perception. In this work we
explore whether this shortcoming may be partly addressed by incorporating
brain-inspired recurrent dynamics in deep convolutional networks. We take
inspiration from a popular framework in neuroscience: 'predictive coding'. At
each layer of the hierarchical model, generative feedback 'predicts' (i.e.,
reconstructs) the pattern of activity in the previous layer. The reconstruction
errors are used to iteratively update the network's representations across
timesteps, and to optimize the network's feedback weights over the natural
image dataset-a form of unsupervised training. We show that implementing this
strategy into two popular networks, VGG16 and EfficientNetB0, improves their
robustness against various corruptions and adversarial attacks. We hypothesize
that other feedforward networks could similarly benefit from the proposed
framework. To promote research in this direction, we provide an open-sourced
PyTorch-based package called Predify, which can be used to implement and
investigate the impacts of the predictive coding dynamics in any convolutional
neural network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">I Don't Need $\mathbf{u}$: Identifiable Non-Linear ICA Without Side Information. (arXiv:2106.05238v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05238">
<div class="article-summary-box-inner">
<span><p>Recently there has been a renaissance in identifiability results in deep
generative models, not least for non-linear ICA. For i.i.d. data, prior works
have assumed access to a sufficiently-informative auxiliary set of
observations, denoted $\mathbf{u}$. We show here how identifiability can be
obtained in the absence of this side-information. Previous methods have had to
make strong assumptions in order to obtain identifiable models. Here we obtain
empirically identifiable models under a much looser set of constraints. In
particular, we focus on generative models which perform clustering in their
latent space -- a model structure which matches previous identifiable models,
but with the learnt clustering providing a synthetic form of auxiliary
information. We evaluate our proposals, including via statistical tests, and
find that the learned clusterings function effectively: deep generative models
with latent clusterings are empirically identifiable, to the same degree as
models which rely on side information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Contextual Design of Convolutional Neural Network for Steganalysis. (arXiv:2106.10430v2 [cs.MM] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10430">
<div class="article-summary-box-inner">
<span><p>In recent times, deep learning-based steganalysis classifiers became popular
due to their state-of-the-art performance. Most deep steganalysis classifiers
usually extract noise residuals using high-pass filters as preprocessing steps
and feed them to their deep model for classification. It is observed that
recent steganographic embedding does not always restrict their embedding in the
high-frequency zone; instead, they distribute it as per embedding policy.
Therefore, besides noise residual, learning the embedding zone is another
challenging task. In this work, unlike the conventional approaches, the
proposed model first extracts the noise residual using learned denoising
kernels to boost the signal-to-noise ratio. After preprocessing, the sparse
noise residuals are fed to a novel Multi-Contextual Convolutional Neural
Network (M-CNET) that uses heterogeneous context size to learn the sparse and
low-amplitude representation of noise residuals. The model performance is
further improved by incorporating the Self-Attention module to focus on the
areas prone to steganalytic embedding. A set of comprehensive experiments is
performed to show the proposed scheme's efficacy over the prior arts. Besides,
an ablation study is given to justify the contribution of various modules of
the proposed architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are conditional GANs explicitly conditional?. (arXiv:2106.15011v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15011">
<div class="article-summary-box-inner">
<span><p>This paper proposes two important contributions for conditional Generative
Adversarial Networks (cGANs) to improve the wide variety of applications that
exploit this architecture. The first main contribution is an analysis of cGANs
to show that they are not explicitly conditional. In particular, it will be
shown that the discriminator and subsequently the cGAN does not automatically
learn the conditionality between inputs. The second contribution is a new
method, called a contrario cGAN, that explicitly models conditionality for both
parts of the adversarial architecture via a novel a contrario loss that
involves training the discriminator to learn unconditional (adverse) examples.
This leads to a novel type of data augmentation approach for GANs (a contrario
learning) which allows to restrict the search space of the generator to
conditional outputs using adverse examples. Extensive experimentation is
carried out to evaluate the conditionality of the discriminator by proposing a
probability distribution analysis. Comparisons with the cGAN architecture for
different applications show significant improvements in performance on well
known datasets including, semantic image synthesis, image segmentation,
monocular depth prediction and "single label"-to-image using different metrics
including Fr\'echet Inception Distance (FID), mean Intersection over Union
(mIoU), Root Mean Square Error log (RMSE log) and Number of
statistically-Different Bins (NDB).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RCNN-SliceNet: A Slice and Cluster Approach for Nuclei Centroid Detection in Three-Dimensional Fluorescence Microscopy Images. (arXiv:2106.15753v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15753">
<div class="article-summary-box-inner">
<span><p>Robust and accurate nuclei centroid detection is important for the
understanding of biological structures in fluorescence microscopy images.
Existing automated nuclei localization methods face three main challenges: (1)
Most of object detection methods work only on 2D images and are difficult to
extend to 3D volumes; (2) Segmentation-based models can be used on 3D volumes
but it is computational expensive for large microscopy volumes and they have
difficulty distinguishing different instances of objects; (3) Hand annotated
ground truth is limited for 3D microscopy volumes. To address these issues, we
present a scalable approach for nuclei centroid detection of 3D microscopy
volumes. We describe the RCNN-SliceNet to detect 2D nuclei centroids for each
slice of the volume from different directions and 3D agglomerative hierarchical
clustering (AHC) is used to estimate the 3D centroids of nuclei in a volume.
The model was trained with the synthetic microscopy data generated using
Spatially Constrained Cycle-Consistent Adversarial Networks (SpCycleGAN) and
tested on different types of real 3D microscopy data. Extensive experimental
results demonstrate that our proposed method can accurately count and detect
the nuclei centroids in a 3D microscopy volume.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios. (arXiv:2107.00717v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00717">
<div class="article-summary-box-inner">
<span><p>Active learning has proven to be useful for minimizing labeling costs by
selecting the most informative samples. However, existing active learning
methods do not work well in realistic scenarios such as imbalance or rare
classes, out-of-distribution data in the unlabeled set, and redundancy. In this
work, we propose SIMILAR (Submodular Information Measures based actIve
LeARning), a unified active learning framework using recently proposed
submodular information measures (SIM) as acquisition functions. We argue that
SIMILAR not only works in standard active learning, but also easily extends to
the realistic settings considered above and acts as a one-stop solution for
active learning that is scalable to large real-world datasets. Empirically, we
show that SIMILAR significantly outperforms existing active learning algorithms
by as much as ~5% - 18% in the case of rare classes and ~5% - 10% in the case
of out-of-distribution data on several image classification tasks like
CIFAR-10, MNIST, and ImageNet. SIMILAR is available as a part of the DISTIL
toolkit: "https://github.com/decile-team/distil".
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ManiSkill: Generalizable Manipulation Skill Benchmark with Large-Scale Demonstrations. (arXiv:2107.14483v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14483">
<div class="article-summary-box-inner">
<span><p>Object manipulation from 3D visual inputs poses many challenges on building
generalizable perception and policy models. However, 3D assets in existing
benchmarks mostly lack the diversity of 3D shapes that align with real-world
intra-class complexity in topology and geometry. Here we propose SAPIEN
Manipulation Skill Benchmark (ManiSkill) to benchmark manipulation skills over
diverse objects in a full-physics simulator. 3D assets in ManiSkill include
large intra-class topological and geometric variations. Tasks are carefully
chosen to cover distinct types of manipulation challenges. Latest progress in
3D vision also makes us believe that we should customize the benchmark so that
the challenge is inviting to researchers working on 3D deep learning. To this
end, we simulate a moving panoramic camera that returns ego-centric point
clouds or RGB-D images. In addition, we would like ManiSkill to serve a broad
set of researchers interested in manipulation research. Besides supporting the
learning of policies from interactions, we also support
learning-from-demonstrations (LfD) methods, by providing a large number of
high-quality demonstrations (~36,000 successful trajectories, ~1.5M point
cloud/RGB-D frames in total). We provide baselines using 3D deep learning and
LfD algorithms. All code of our benchmark (simulator, environment, SDK, and
baselines) is open-sourced, and a challenge facing interdisciplinary
researchers will be held based on the benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks. (arXiv:2108.03272v4 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03272">
<div class="article-summary-box-inner">
<span><p>Recent research in embodied AI has been boosted by the use of simulation
environments to develop and train robot learning approaches. However, the use
of simulation has skewed the attention to tasks that only require what robotics
simulators can simulate: motion and physical contact. We present iGibson 2.0,
an open-source simulation environment that supports the simulation of a more
diverse set of household tasks through three key innovations. First, iGibson
2.0 supports object states, including temperature, wetness level, cleanliness
level, and toggled and sliced states, necessary to cover a wider range of
tasks. Second, iGibson 2.0 implements a set of predicate logic functions that
map the simulator states to logic states like Cooked or Soaked. Additionally,
given a logic state, iGibson 2.0 can sample valid physical states that satisfy
it. This functionality can generate potentially infinite instances of tasks
with minimal effort from the users. The sampling mechanism allows our scenes to
be more densely populated with small objects in semantically meaningful
locations. Third, iGibson 2.0 includes a virtual reality (VR) interface to
immerse humans in its scenes to collect demonstrations. As a result, we can
collect demonstrations from humans on these new types of tasks, and use them
for imitation learning. We evaluate the new capabilities of iGibson 2.0 to
enable robot learning of novel tasks, in the hope of demonstrating the
potential of this new simulator to support new research in embodied AI. iGibson
2.0 and its new dataset are publicly available at
<a href="http://svl.stanford.edu/igibson/.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Embodied BERT: A Transformer Model for Embodied, Language-guided Visual Task Completion. (arXiv:2108.04927v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04927">
<div class="article-summary-box-inner">
<span><p>Language-guided robots performing home and office tasks must navigate in and
interact with the world. Grounding language instructions against visual
observations and actions to take in an environment is an open challenge. We
present Embodied BERT (EmBERT), a transformer-based model which can attend to
high-dimensional, multi-modal inputs across long temporal horizons for
language-conditioned task completion. Additionally, we bridge the gap between
successful object-centric navigation models used for non-interactive agents and
the language-guided visual task completion benchmark, ALFRED, by introducing
object navigation targets for EmBERT training. We achieve competitive
performance on the ALFRED benchmark, and EmBERT marks the first
transformer-based model to successfully handle the long-horizon, dense,
multi-modal histories of ALFRED, and the first ALFRED model to utilize
object-centric navigation targets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instance-Conditioned GAN. (arXiv:2109.05070v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05070">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GANs) can generate near photo realistic
images in narrow domains such as human faces. Yet, modeling complex
distributions of datasets such as ImageNet and COCO-Stuff remains challenging
in unconditional settings. In this paper, we take inspiration from kernel
density estimation techniques and introduce a non-parametric approach to
modeling distributions of complex datasets. We partition the data manifold into
a mixture of overlapping neighborhoods described by a datapoint and its nearest
neighbors, and introduce a model, called instance-conditioned GAN (IC-GAN),
which learns the distribution around each datapoint. Experimental results on
ImageNet and COCO-Stuff show that IC-GAN significantly improves over
unconditional models and unsupervised data partitioning baselines. Moreover, we
show that IC-GAN can effortlessly transfer to datasets not seen during training
by simply changing the conditioning instances, and still generate realistic
images. Finally, we extend IC-GAN to the class-conditional case and show
semantically controllable generation and competitive quantitative results on
ImageNet; while improving over BigGAN on ImageNet-LT. Code and trained models
to reproduce the reported results are available at
https://github.com/facebookresearch/ic_gan.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UFO-ViT: High Performance Linear Vision Transformer without Softmax. (arXiv:2109.14382v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14382">
<div class="article-summary-box-inner">
<span><p>Vision transformers have become one of the most important models for computer
vision tasks. Although they outperform prior works, they require heavy
computational resources on a scale that is quadratic to $N$. This is a major
drawback of the traditional self-attention (SA) algorithm. Here, we propose the
Unit Force Operated Vision Transformer (UFO-ViT), a novel SA mechanism that has
linear complexity. The main approach of this work is to eliminate nonlinearity
from the original SA. We factorize the matrix multiplication of the SA
mechanism without complicated linear approximation. By modifying only a few
lines of code from the original SA, the proposed models outperform most
transformer-based models on image classification and dense prediction tasks on
most capacity regimes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Unsupervised Domain Adaptive Re-Identification via Source-Guided Selection of Pseudo-Labeling Hyperparameters. (arXiv:2110.07897v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07897">
<div class="article-summary-box-inner">
<span><p>Unsupervised Domain Adaptation (UDA) for re-identification (re-ID) is a
challenging task: to avoid a costly annotation of additional data, it aims at
transferring knowledge from a domain with annotated data to a domain of
interest with only unlabeled data. Pseudo-labeling approaches have proven to be
effective for UDA re-ID. However, the effectiveness of these approaches heavily
depends on the choice of some hyperparameters (HP) that affect the generation
of pseudo-labels by clustering. The lack of annotation in the domain of
interest makes this choice non-trivial. Current approaches simply reuse the
same empirical value for all adaptation tasks and regardless of the target data
representation that changes through pseudo-labeling training phases. As this
simplistic choice may limit their performance, we aim at addressing this issue.
We propose new theoretical grounds on HP selection for clustering UDA re-ID as
well as method of automatic and cyclic HP tuning for pseudo-labeling UDA
clustering: HyPASS. HyPASS consists in incorporating two modules in
pseudo-labeling methods: (i) HP selection based on a labeled source validation
set and (ii) conditional domain alignment of feature discriminativeness to
improve HP selection based on source samples. Experiments on commonly used
person re-ID and vehicle re-ID datasets show that our proposed HyPASS
consistently improves the best state-of-the-art methods in re-ID compared to
the commonly used empirical HP setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental Cross-Domain Adaptation for Robust Retinopathy Screening via Bayesian Deep Learning. (arXiv:2110.09319v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09319">
<div class="article-summary-box-inner">
<span><p>Retinopathy represents a group of retinal diseases that, if not treated
timely, can cause severe visual impairments or even blindness. Many researchers
have developed autonomous systems to recognize retinopathy via fundus and
optical coherence tomography (OCT) imagery. However, most of these frameworks
employ conventional transfer learning and fine-tuning approaches, requiring a
decent amount of well-annotated training data to produce accurate diagnostic
performance. This paper presents a novel incremental cross-domain adaptation
instrument that allows any deep classification model to progressively learn
abnormal retinal pathologies in OCT and fundus imagery via few-shot training.
Furthermore, unlike its competitors, the proposed instrument is driven via a
Bayesian multi-objective function that not only enforces the candidate
classification network to retain its prior learned knowledge during incremental
training but also ensures that the network understands the structural and
semantic relationships between previously learned pathologies and newly added
disease categories to effectively recognize them at the inference stage. The
proposed framework, evaluated on six public datasets acquired with three
different scanners to screen thirteen retinal pathologies, outperforms the
state-of-the-art competitors by achieving an overall accuracy and F1 score of
0.9826 and 0.9846, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Strong Baseline for Semi-Supervised Incremental Few-Shot Learning. (arXiv:2110.11128v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11128">
<div class="article-summary-box-inner">
<span><p>Few-shot learning (FSL) aims to learn models that generalize to novel classes
with limited training samples. Recent works advance FSL towards a scenario
where unlabeled examples are also available and propose semi-supervised FSL
methods. Another line of methods also cares about the performance of base
classes in addition to the novel ones and thus establishes the incremental FSL
scenario. In this paper, we generalize the above two under a more realistic yet
complex setting, named by Semi-Supervised Incremental Few-Shot Learning (S2
I-FSL). To tackle the task, we propose a novel paradigm containing two parts:
(1) a well-designed meta-training algorithm for mitigating ambiguity between
base and novel classes caused by unreliable pseudo labels and (2) a model
adaptation mechanism to learn discriminative features for novel classes while
preserving base knowledge using few labeled and all the unlabeled data.
Extensive experiments on standard FSL, semi-supervised FSL, incremental FSL,
and the firstly built S2 I-FSL benchmarks demonstrate the effectiveness of our
proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ScaleCert: Scalable Certified Defense against Adversarial Patches with Sparse Superficial Layers. (arXiv:2110.14120v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14120">
<div class="article-summary-box-inner">
<span><p>Adversarial patch attacks that craft the pixels in a confined region of the
input images show their powerful attack effectiveness in physical environments
even with noises or deformations. Existing certified defenses towards
adversarial patch attacks work well on small images like MNIST and CIFAR-10
datasets, but achieve very poor certified accuracy on higher-resolution images
like ImageNet. It is urgent to design both robust and effective defenses
against such a practical and harmful attack in industry-level larger images. In
this work, we propose the certified defense methodology that achieves high
provable robustness for high-resolution images and largely improves the
practicality for real adoption of the certified defense. The basic insight of
our work is that the adversarial patch intends to leverage localized
superficial important neurons (SIN) to manipulate the prediction results.
Hence, we leverage the SIN-based DNN compression techniques to significantly
improve the certified accuracy, by reducing the adversarial region searching
overhead and filtering the prediction noises. Our experimental results show
that the certified accuracy is increased from 36.3% (the state-of-the-art
certified detection) to 60.4% on the ImageNet dataset, largely pushing the
certified defenses for practical use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Event-based Spatio-Temporal Feature Descriptors via Local Synaptic Plasticity: A Biologically-realistic Perspective of Computer Vision. (arXiv:2111.00791v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00791">
<div class="article-summary-box-inner">
<span><p>We present an optimization-based theory describing spiking cortical ensembles
equipped with Spike-Timing-Dependent Plasticity (STDP) learning, as empirically
observed in the visual cortex. Using our methods, we build a class of
fully-connected, convolutional and action-based feature descriptors for
event-based camera that we respectively assess on N-MNIST, challenging
CIFAR10-DVS and on the IBM DVS128 gesture dataset. We report significant
accuracy improvements compared to conventional state-of-the-art event-based
feature descriptors (+8% on CIFAR10-DVS). We report large improvements in
accuracy compared to state-of-the-art STDP-based systems (+10% on N-MNIST,
+7.74% on IBM DVS128 Gesture). In addition to ultra-low-power learning in
neuromorphic edge devices, our work helps paving the way towards a
biologically-realistic, optimization-based theory of cortical vision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Egocentric Human Trajectory Forecasting with a Wearable Camera and Multi-Modal Fusion. (arXiv:2111.00993v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00993">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the problem of forecasting the trajectory of an
egocentric camera wearer (ego-person) in crowded spaces. The trajectory
forecasting ability learned from the data of different camera wearers walking
around in the real world can be transferred to assist visually impaired people
in navigation, as well as to instill human navigation behaviours in mobile
robots, enabling better human-robot interactions. To this end, a novel
egocentric human trajectory forecasting dataset was constructed, containing
real trajectories of people navigating in crowded spaces wearing a camera, as
well as extracted rich contextual data. We extract and utilize three different
modalities to forecast the trajectory of the camera wearer, i.e., his/her past
trajectory, the past trajectories of nearby people, and the environment such as
the scene semantics or the depth of the scene. A Transformer-based
encoder-decoder neural network model, integrated with a novel cascaded
cross-attention mechanism that fuses multiple modalities, has been designed to
predict the future trajectory of the camera wearer. Extensive experiments have
been conducted, and the results have shown that our model outperforms the
state-of-the-art methods in egocentric human trajectory forecasting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Eye-in-Hand Camera Calibration from a Single Image. (arXiv:2111.01245v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01245">
<div class="article-summary-box-inner">
<span><p>Eye-in-hand camera calibration is a fundamental and long-studied problem in
robotics. We present a study on using learning-based methods for solving this
problem online from a single RGB image, whilst training our models with
entirely synthetic data. We study three main approaches: one direct regression
model that directly predicts the extrinsic matrix from an image, one sparse
correspondence model that regresses 2D keypoints and then uses PnP, and one
dense correspondence model that uses regressed depth and segmentation maps to
enable ICP pose estimation. In our experiments, we benchmark these methods
against each other and against well-established classical methods, to find the
surprising result that direct regression outperforms other approaches, and we
perform noise-sensitivity analysis to gain further insights into these results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima. (arXiv:2111.01549v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01549">
<div class="article-summary-box-inner">
<span><p>This paper considers incremental few-shot learning, which requires a model to
continually recognize new categories with only a few examples provided. Our
study shows that existing methods severely suffer from catastrophic forgetting,
a well-known problem in incremental learning, which is aggravated due to data
scarcity and imbalance in the few-shot setting. Our analysis further suggests
that to prevent catastrophic forgetting, actions need to be taken in the
primitive stage -- the training of base classes instead of later few-shot
learning sessions. Therefore, we propose to search for flat local minima of the
base training objective function and then fine-tune the model parameters within
the flat region on new tasks. In this way, the model can efficiently learn new
classes while preserving the old ones. Comprehensive experimental results
demonstrate that our approach outperforms all prior state-of-the-art methods
and is very close to the approximate upper bound. The source code is available
at https://github.com/moukamisama/F2M.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-11-05 23:02:36.774440696 UTC">2021-11-05 23:02:36 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.6</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>