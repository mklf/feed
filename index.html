<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-08-31T01:30:00Z">08-31</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.AI updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Why and How Governments Should Monitor AI Development. (arXiv:2108.12427v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12427">
<div class="article-summary-box-inner">
<span><p>In this paper we outline a proposal for improving the governance of
artificial intelligence (AI) by investing in government capacity to
systematically measure and monitor the capabilities and impacts of AI systems.
If adopted, this would give governments greater information about the AI
ecosystem, equipping them to more effectively direct AI development and
deployment in the most societally and economically beneficial directions. It
would also create infrastructure that could rapidly identify potential threats
or harms that could occur as a consequence of changes in the AI ecosystem, such
as the emergence of strategically transformative capabilities, or the
deployment of harmful systems.
</p>
<p>We begin by outlining the problem which motivates this proposal: in brief,
traditional governance approaches struggle to keep pace with the speed of
progress in AI. We then present our proposal for addressing this problem:
governments must invest in measurement and monitoring infrastructure. We
discuss this proposal in detail, outlining what specific things governments
could focus on measuring and monitoring, and the kinds of benefits this would
generate for policymaking. Finally, we outline some potential pilot projects
and some considerations for implementing this in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Text Evaluation through the Lens of Wasserstein Barycenters. (arXiv:2108.12463v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12463">
<div class="article-summary-box-inner">
<span><p>A new metric \texttt{BaryScore} to evaluate text generation based on deep
contextualized embeddings (\textit{e.g.}, BERT, Roberta, ELMo) is introduced.
This metric is motivated by a new framework relying on optimal transport tools,
\textit{i.e.}, Wasserstein distance and barycenter. By modelling the layer
output of deep contextualized embeddings as a probability distribution rather
than by a vector embedding; this framework provides a natural way to aggregate
the different outputs through the Wasserstein space topology. In addition, it
provides theoretical grounds to our metric and offers an alternative to
available solutions (\textit{e.g.}, MoverScore and BertScore). Numerical
evaluation is performed on four different tasks: machine translation,
summarization, data2text generation and image captioning. Our results show that
\texttt{BaryScore} outperforms other BERT based metrics and exhibits more
consistent behaviour in particular for text summarization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Code-switched inspired losses for generic spoken dialog representations. (arXiv:2108.12465v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12465">
<div class="article-summary-box-inner">
<span><p>Spoken dialog systems need to be able to handle both multiple languages and
multilinguality inside a conversation (\textit{e.g} in case of code-switching).
In this work, we introduce new pretraining losses tailored to learn
multilingual spoken dialog representations. The goal of these losses is to
expose the model to code-switched language. To scale up training, we
automatically build a pretraining corpus composed of multilingual conversations
in five different languages (French, Italian, English, German and Spanish) from
\texttt{OpenSubtitles}, a huge multilingual corpus composed of 24.3G tokens. We
test the generic representations on \texttt{MIAM}, a new benchmark composed of
five dialog act corpora on the same aforementioned languages as well as on two
novel multilingual downstream tasks (\textit{i.e} multilingual mask utterance
retrieval and multilingual inconsistency identification). Our experiments show
that our new code switched-inspired losses achieve a better performance in both
monolingual and multilingual settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Inner-Group Relations on Point Clouds. (arXiv:2108.12468v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12468">
<div class="article-summary-box-inner">
<span><p>The prevalence of relation networks in computer vision is in stark contrast
to underexplored point-based methods. In this paper, we explore the
possibilities of local relation operators and survey their feasibility. We
propose a scalable and efficient module, called group relation aggregator. The
module computes a feature of a group based on the aggregation of the features
of the inner-group points weighted by geometric relations and semantic
relations. We adopt this module to design our RPNet. We further verify the
expandability of RPNet, in terms of both depth and width, on the tasks of
classification and segmentation. Surprisingly, empirical results show that
wider RPNet fits for classification, while deeper RPNet works better on
segmentation. RPNet achieves state-of-the-art for classification and
segmentation on challenging benchmarks. We also compare our local aggregator
with PointNet++, with around 30% parameters and 50% computation saving.
Finally, we conduct experiments to reveal the robustness of RPNet with regard
to rigid transformation and noises.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disrupting Adversarial Transferability in Deep Neural Networks. (arXiv:2108.12492v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12492">
<div class="article-summary-box-inner">
<span><p>Adversarial attack transferability is a well-recognized phenomenon in deep
learning. Prior work has partially explained transferability by recognizing
common adversarial subspaces and correlations between decision boundaries, but
we have found little explanation in the literature beyond this. In this paper,
we propose that transferability between seemingly different models is due to a
high linear correlation between features that different deep neural networks
extract. In other words, two models trained on the same task that are seemingly
distant in the parameter space likely extract features in the same fashion,
just with trivial shifts and rotations between the latent spaces. Furthermore,
we show how applying a feature correlation loss, which decorrelates the
extracted features in a latent space, can drastically reduce the
transferability of adversarial attacks between models, suggesting that the
models complete tasks in semantically different ways. Finally, we propose a
Dual Neck Autoencoder (DNA), which leverages this feature correlation loss to
create two meaningfully different encodings of input information with reduced
transferability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StressNAS: Affect State and Stress Detection Using Neural Architecture Search. (arXiv:2108.12502v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12502">
<div class="article-summary-box-inner">
<span><p>Smartwatches have rapidly evolved towards capabilities to accurately capture
physiological signals. As an appealing application, stress detection attracts
many studies due to its potential benefits to human health. It is propitious to
investigate the applicability of deep neural networks (DNN) to enhance human
decision-making through physiological signals. However, manually engineering
DNN proves a tedious task especially in stress detection due to the complex
nature of this phenomenon. To this end, we propose an optimized deep neural
network training scheme using neural architecture search merely using
wrist-worn data from WESAD. Experiments show that our approach outperforms
traditional ML methods by 8.22% and 6.02% in the three-state and two-state
classifiers, respectively, using the combination of WESAD wrist signals.
Moreover, the proposed method can minimize the need for human-design DNN while
improving performance by 4.39% (three-state) and 8.99% (binary).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness Disparities in Commercial Face Detection. (arXiv:2108.12508v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12508">
<div class="article-summary-box-inner">
<span><p>Facial detection and analysis systems have been deployed by large companies
and critiqued by scholars and activists for the past decade. Critiques that
focus on system performance analyze disparity of the system's output, i.e., how
frequently is a face detected for different Fitzpatrick skin types or perceived
genders. However, we focus on the robustness of these system outputs under
noisy natural perturbations. We present the first of its kind detailed
benchmark of the robustness of three such systems: Amazon Rekognition,
Microsoft Azure, and Google Cloud Platform. We use both standard and recently
released academic facial datasets to quantitatively analyze trends in
robustness for each. Across all the datasets and systems, we generally find
that photos of individuals who are older, masculine presenting, of darker skin
type, or have dim lighting are more susceptible to errors than their
counterparts in other identities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining chest X-rays and EHR data using machine learning to diagnose acute respiratory failure. (arXiv:2108.12530v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12530">
<div class="article-summary-box-inner">
<span><p>When patients develop acute respiratory failure, accurately identifying the
underlying etiology is essential for determining the best treatment, but it can
be challenging to differentiate between common diagnoses in clinical practice.
Machine learning models could improve medical diagnosis by augmenting clinical
decision making and play a role in the diagnostic evaluation of patients with
acute respiratory failure. While machine learning models have been developed to
identify common findings on chest radiographs (e.g. pneumonia), augmenting
these approaches by also analyzing clinically relevant data from the electronic
health record (EHR) could aid in the diagnosis of acute respiratory failure.
Machine learning models were trained to predict the cause of acute respiratory
failure (pneumonia, heart failure, and/or COPD) using chest radiographs and EHR
data from patients within an internal cohort using diagnoses based on physician
chart review. Models were also tested on patients in an external cohort using
discharge diagnosis codes. A model combining chest radiographs and EHR data
outperformed models based on each modality alone for pneumonia and COPD. For
pneumonia, the combined model AUROC was 0.79 (0.78-0.79), image model AUROC was
0.73 (0.72-0.75), and EHR model AUROC was 0.73 (0.70-0.76); for COPD, combined:
0.89 (0.83-0.91), image: 0.85 (0.77-0.89), and EHR: 0.80 (0.76-0.84); for heart
failure, combined: 0.80 (0.77-0.84), image: 0.77 (0.71-0.81), and EHR: 0.80
(0.75-0.82). In the external cohort, performance was consistent for heart
failure and COPD, but declined slightly for pneumonia. Overall, machine
learning models combing chest radiographs and EHR data can accurately
differentiate between common causes of acute respiratory failure. Further work
is needed to determine whether these models could aid clinicians in the
diagnosis of acute respiratory failure in clinical settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anytime Stochastic Task and Motion Policies. (arXiv:2108.12537v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12537">
<div class="article-summary-box-inner">
<span><p>In order to solve complex, long-horizon tasks, intelligent robots need to
carry out high-level, abstract planning and reasoning in conjunction with
motion planning. However, abstract models are typically lossy and plans or
policies computed using them can be inexecutable. These problems are
exacerbated in stochastic situations where the robot needs to reason about and
plan for multiple contingencies. We present a new approach for integrated task
and motion planning in stochastic settings. In contrast to prior work in this
direction, we show that our approach can effectively compute integrated task
and motion policies whose branching structures encode agent behaviors that
handle multiple execution-time contingencies. We prove that our algorithm is
probabilistically complete and can compute feasible solution policies in an
anytime fashion so that the probability of encountering an unresolved
contingency decreases over time. Empirical results on a set of challenging
problems show the utility and scope of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AMMASurv: Asymmetrical Multi-Modal Attention for Accurate Survival Analysis with Whole Slide Images and Gene Expression Data. (arXiv:2108.12565v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12565">
<div class="article-summary-box-inner">
<span><p>The use of multi-modal data such as the combination of whole slide images
(WSIs) and gene expression data for survival analysis can lead to more accurate
survival predictions. Previous multi-modal survival models are not able to
efficiently excavate the intrinsic information within each modality. Moreover,
despite experimental results show that WSIs provide more effective information
than gene expression data, previous methods regard the information from
different modalities as similarly important so they cannot flexibly utilize the
potential connection between the modalities. To address the above problems, we
propose a new asymmetrical multi-modal method, termed as AMMASurv.
Specifically, we design an asymmetrical multi-modal attention mechanism (AMMA)
in Transformer encoder for multi-modal data to enable a more flexible
multi-modal information fusion for survival prediction. Different from previous
works, AMMASurv can effectively utilize the intrinsic information within every
modality and flexibly adapts to the modalities of different importance.
Extensive experiments are conducted to validate the effectiveness of the
proposed model. Encouraging results demonstrate the superiority of our method
over other state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling the Knowledge of Large-scale Generative Models into Retrieval Models for Efficient Open-domain Conversation. (arXiv:2108.12582v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12582">
<div class="article-summary-box-inner">
<span><p>Despite the remarkable performance of large-scale generative models in
open-domain conversation, they are known to be less practical for building
real-time conversation systems due to high latency. On the other hand,
retrieval models could return responses with much lower latency but show
inferior performance to the large-scale generative models since the
conversation quality is bounded by the pre-defined response set. To take
advantage of both approaches, we propose a new training method called G2R
(Generative-to-Retrieval distillation) that preserves the efficiency of a
retrieval model while leveraging the conversational ability of a large-scale
generative model by infusing the knowledge of the generative model into the
retrieval model. G2R consists of two distinct techniques of distillation: the
data-level G2R augments the dialogue dataset with additional responses
generated by the large-scale generative model, and the model-level G2R
transfers the response quality score assessed by the generative model to the
score of the retrieval model by the knowledge distillation loss. Through
extensive experiments including human evaluation, we demonstrate that our
retrieval-based conversation system trained with G2R shows a substantially
improved performance compared to the baseline retrieval model while showing
significantly lower inference latency than the large-scale generative models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layer-wise Model Pruning based on Mutual Information. (arXiv:2108.12594v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12594">
<div class="article-summary-box-inner">
<span><p>The proposed pruning strategy offers merits over weight-based pruning
techniques: (1) it avoids irregular memory access since representations and
matrices can be squeezed into their smaller but dense counterparts, leading to
greater speedup; (2) in a manner of top-down pruning, the proposed method
operates from a more global perspective based on training signals in the top
layer, and prunes each layer by propagating the effect of global signals
through layers, leading to better performances at the same sparsity level.
Extensive experiments show that at the same sparsity level, the proposed
strategy offers both greater speedup and higher performances than weight-based
pruning methods (e.g., magnitude pruning, movement pruning).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smoothing Dialogue States for Open Conversational Machine Reading. (arXiv:2108.12599v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12599">
<div class="article-summary-box-inner">
<span><p>Conversational machine reading (CMR) requires machines to communicate with
humans through multi-turn interactions between two salient dialogue states of
decision making and question generation processes. In open CMR settings, as the
more realistic scenario, the retrieved background knowledge would be noisy,
which results in severe challenges in the information transmission. Existing
studies commonly train independent or pipeline systems for the two subtasks.
However, those methods are trivial by using hard-label decisions to activate
question generation, which eventually hinders the model performance. In this
work, we propose an effective gating strategy by smoothing the two dialogue
states in only one decoder and bridge decision making and question generation
to provide a richer dialogue state reference. Experiments on the OR-ShARC
dataset show the effectiveness of our method, which achieves new
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DKM: Differentiable K-Means Clustering Layer for Neural Network Compression. (arXiv:2108.12659v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12659">
<div class="article-summary-box-inner">
<span><p>Deep neural network (DNN) model compression for efficient on-device inference
is becoming increasingly important to reduce memory requirements and keep user
data on-device. To this end, we propose a novel differentiable k-means
clustering layer (DKM) and its application to train-time weight
clustering-based DNN model compression. DKM casts k-means clustering as an
attention problem and enables joint optimization of the parameters and
clustering centroids. Unlike prior works that rely on additional regularizers
and parameters, DKM-based compression keeps the original loss function and
model architecture fixed. We evaluated DKM-based compression on various DNN
models for computer vision and natural language processing (NLP) tasks. Our
results demonstrate that DMK delivers superior compression and accuracy
trade-off on ImageNet1k and GLUE benchmarks. For example, DKM-based compression
can offer 74.5% top-1 ImageNet1k accuracy on ResNet50 DNN model with 3.3MB
model size (29.4x model compression factor). For MobileNet-v1, which is a
challenging DNN to compress, DKM delivers 62.8% top-1 ImageNet1k accuracy with
0.74 MB model size (22.4x model compression factor). This result is 6.8% higher
top-1 accuracy and 33% relatively smaller model size than the current
state-of-the-art DNN compression algorithms. Additionally, DKM enables
compression of DistilBERT model by 11.8x with minimal (1.1%) accuracy loss on
GLUE NLP benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CHAINGE: A Blockchain Solution to Automate Payment Detail Updates to Subscription Services. (arXiv:2108.12705v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12705">
<div class="article-summary-box-inner">
<span><p>The rise of the subscription-based business model has led to a corresponding
increase in the number of subscriptions where a customer needs to manage their
payments. This management of payments for multiple subscriptions has become a
very complicated and insecure task for customers, especially when it comes to
renewing payment details when the card is lost, stolen, or expires. In
addition, this, mostly manual, process is vulnerable to human error, digital
frauds, and data breaches, according to security reports. Thus, in this paper,
we propose a novel approach to automate, manage and simplify the Financial
Supply Chain involved in the process of updating and managing payments to user
subscriptions. This is done by utilising the Hyperledger Sawtooth blockchain
framework, that allows a consumer to enter their payment card details in a
central digital wallet and link their subscriptions to their cards. The card
being updated triggers an event on the blockchain, which allow for the payment
details to be updated on subscription systems automatically. The verification
tests performed on the prototype of the proposed system shows that its current
implementation has been securely achieved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event Extraction as Natural Language Generation. (arXiv:2108.12724v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12724">
<div class="article-summary-box-inner">
<span><p>Event extraction (EE), the task that identifies event triggers and their
arguments in text, is usually formulated as a classification or structured
prediction problem. Such models usually reduce labels to numeric identifiers,
making them unable to take advantage of label semantics (e.g. an event type
named Arrest is related to words like arrest, detain, or apprehend). This
prevents the generalization to new event types. In this work, we formulate EE
as a natural language generation task and propose GenEE, a model that not only
captures complex dependencies within an event but also generalizes well to
unseen or rare event types. Given a passage and an event type, GenEE is trained
to generate a natural sentence following a predefined template for that event
type. The generated output is then decoded into trigger and argument
predictions. The autoregressive generation process naturally models the
dependencies among the predictions -- each new word predicted depends on those
already generated in the output sentence. Using carefully designed input
prompts during generation, GenEE is able to capture label semantics, which
enables the generalization to new event types. Empirical results show that our
model achieves strong performance on event extraction tasks under all
zero-shot, few-shot, and high-resource scenarios. Especially, in the
high-resource setting, GenEE outperforms the state-of-the-art model on argument
extraction and gets competitive results with the current best on end-to-end EE
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Risk-Aware Fine-Grained Access Control in Cyber-Physical Contexts. (arXiv:2108.12739v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12739">
<div class="article-summary-box-inner">
<span><p>Access to resources by users may need to be granted only upon certain
conditions and contexts, perhaps particularly in cyber-physical settings.
Unfortunately, creating and modifying context-sensitive access control
solutions in dynamic environments creates ongoing challenges to manage the
authorization contexts. This paper proposes RASA, a context-sensitive access
authorization approach and mechanism leveraging unsupervised machine learning
to automatically infer risk-based authorization decision boundaries. We explore
RASA in a healthcare usage environment, wherein cyber and physical conditions
create context-specific risks for protecting private health information. The
risk levels are associated with access control decisions recommended by a
security policy. A coupling method is introduced to track coexistence of the
objects within context using frequency and duration of coexistence, and these
are clustered to reveal sets of actions with common risk levels; these are used
to create authorization decision boundaries. In addition, we propose a method
for assessing the risk level and labelling the clusters with respect to their
corresponding risk levels. We evaluate the promise of RASA-generated policies
against a heuristic rule-based policy. By employing three different coupling
features (frequency-based, duration-based, and combined features), the
decisions of the unsupervised method and that of the policy are more than 99%
consistent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TCCT: Tightly-Coupled Convolutional Transformer on Time Series Forecasting. (arXiv:2108.12784v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12784">
<div class="article-summary-box-inner">
<span><p>Time series forecasting is essential for a wide range of real-world
applications. Recent studies have shown the superiority of Transformer in
dealing with such problems, especially long sequence time series input(LSTI)
and long sequence time series forecasting(LSTF) problems. To improve the
efficiency and enhance the locality of Transformer, these studies combine
Transformer with CNN in varying degrees. However, their combinations are
loosely-coupled and do not make full use of CNN. To address this issue, we
propose the concept of tightly-coupled convolutional Transformer(TCCT) and
three TCCT architectures which apply transformed CNN architectures into
Transformer: (1) CSPAttention: through fusing CSPNet with self-attention
mechanism, the computation cost of self-attention mechanism is reduced by 30%
and the memory usage is reduced by 50% while achieving equivalent or beyond
prediction accuracy. (2) Dilated causal convolution: this method is to modify
the distilling operation proposed by Informer through replacing canonical
convolutional layers with dilated causal convolutional layers to gain
exponentially receptive field growth. (3) Passthrough mechanism: the
application of passthrough mechanism to stack of self-attention blocks helps
Transformer-like models get more fine-grained information with negligible extra
computation costs. Our experiments on real-world datasets show that our TCCT
architectures could greatly improve the performance of existing state-of-art
Transformer models on time series forecasting with much lower computation and
memory costs, including canonical Transformer, LogTrans and Informer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Markov Switching Model for Driver Behavior Prediction: Use cases on Smartphones. (arXiv:2108.12801v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12801">
<div class="article-summary-box-inner">
<span><p>Several intelligent transportation systems focus on studying the various
driver behaviors for numerous objectives. This includes the ability to analyze
driver actions, sensitivity, distraction, and response time. As the data
collection is one of the major concerns for learning and validating different
driving situations, we present a driver behavior switching model validated by a
low-cost data collection solution using smartphones. The proposed model is
validated using a real dataset to predict the driver behavior in short duration
periods. A literature survey on motion detection (specifically driving behavior
detection using smartphones) is presented. Multiple Markov Switching Variable
Auto-Regression (MSVAR) models are implemented to achieve a sophisticated
fitting with the collected driver behavior data. This yields more accurate
predictions not only for driver behavior but also for the entire driving
situation. The performance of the presented models together with a suitable
model selection criteria is also presented. The proposed driver behavior
prediction framework can potentially be used in accident prediction and driver
safety systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable Propaganda Detection in News Articles. (arXiv:2108.12802v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12802">
<div class="article-summary-box-inner">
<span><p>Online users today are exposed to misleading and propagandistic news articles
and media posts on a daily basis. To counter thus, a number of approaches have
been designed aiming to achieve a healthier and safer online news and media
consumption. Automatic systems are able to support humans in detecting such
content; yet, a major impediment to their broad adoption is that besides being
accurate, the decisions of such systems need also to be interpretable in order
to be trusted and widely adopted by users. Since misleading and propagandistic
content influences readers through the use of a number of deception techniques,
we propose to detect and to show the use of such techniques as a way to offer
interpretability. In particular, we define qualitatively descriptive features
and we analyze their suitability for detecting deception techniques. We further
show that our interpretable features can be easily combined with pre-trained
language models, yielding state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DropAttack: A Masked Weight Adversarial Training Method to Improve Generalization of Neural Networks. (arXiv:2108.12805v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12805">
<div class="article-summary-box-inner">
<span><p>Adversarial training has been proven to be a powerful regularization method
to improve the generalization of models. However, current adversarial training
methods only attack the original input sample or the embedding vectors, and
their attacks lack coverage and diversity. To further enhance the breadth and
depth of attack, we propose a novel masked weight adversarial training method
called DropAttack, which enhances generalization of model by adding
intentionally worst-case adversarial perturbations to both the input and hidden
layers in different dimensions and minimize the adversarial risks generated by
each layer. DropAttack is a general technique and can be adopt to a wide
variety of neural networks with different architectures. To validate the
effectiveness of the proposed method, we used five public datasets in the
fields of natural language processing (NLP) and computer vision (CV) for
experimental evaluating. We compare the proposed method with other adversarial
training methods and regularization methods, and our method achieves
state-of-the-art on all datasets. In addition, Dropattack can achieve the same
performance when it use only a half training data compared to other standard
training method. Theoretical analysis reveals that DropAttack can perform
gradient regularization at random on some of the input and wight parameters of
the model. Further visualization experiments show that DropAttack can push the
minimum risk of the model to a lower and flatter loss landscapes. Our source
code is publicly available on https://github.com/nishiwen1214/DropAttack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Hybrid Rule-Based and Data-Driven Approach to Driver Modeling through Particle Filtering. (arXiv:2108.12820v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12820">
<div class="article-summary-box-inner">
<span><p>Autonomous vehicles need to model the behavior of surrounding human driven
vehicles to be safe and efficient traffic participants. Existing approaches to
modeling human driving behavior have relied on both data-driven and rule-based
methods. While data-driven models are more expressive, rule-based models are
interpretable, which is an important requirement for safety-critical domains
like driving. However, rule-based models are not sufficiently representative of
data, and data-driven models are yet unable to generate realistic traffic
simulation due to unrealistic driving behavior such as collisions. In this
paper, we propose a methodology that combines rule-based modeling with
data-driven learning. While the rules are governed by interpretable parameters
of the driver model, these parameters are learned online from driving
demonstration data using particle filtering. We perform driver modeling
experiments on the task of highway driving and merging using data from three
real-world driving demonstration datasets. Our results show that driver models
based on our hybrid rule-based and data-driven approach can accurately capture
real-world driving behavior. Further, we assess the realism of the driving
behavior generated by our model by having humans perform a driving Turing test,
where they are asked to distinguish between videos of real driving and those
generated using our driver models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flow-Guided Video Inpainting with Scene Templates. (arXiv:2108.12845v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12845">
<div class="article-summary-box-inner">
<span><p>We consider the problem of filling in missing spatio-temporal regions of a
video. We provide a novel flow-based solution by introducing a generative model
of images in relation to the scene (without missing regions) and mappings from
the scene to images. We use the model to jointly infer the scene template, a 2D
representation of the scene, and the mappings. This ensures consistency of the
frame-to-frame flows generated to the underlying scene, reducing geometric
distortions in flow based inpainting. The template is mapped to the missing
regions in the video by a new L2-L1 interpolation scheme, creating crisp
inpaintings and reducing common blur and distortion artifacts. We show on two
benchmark datasets that our approach out-performs state-of-the-art
quantitatively and in user studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Network Gaussian Processes by Increasing Depth. (arXiv:2108.12862v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12862">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed an increasing interest in the correspondence
between infinitely wide networks and Gaussian processes. Despite the
effectiveness and elegance of the current neural network Gaussian process
theory, to the best of our knowledge, all the neural network Gaussian processes
are essentially induced by increasing width. However, in the era of deep
learning, what concerns us more regarding a neural network is its depth as well
as how depth impacts the behaviors of a network. Inspired by a width-depth
symmetry consideration, we use a shortcut network to show that increasing the
depth of a neural network can also give rise to a Gaussian process, which is a
valuable addition to the existing theory and contributes to revealing the true
picture of deep learning. Beyond the proposed Gaussian process by depth, we
theoretically characterize its uniform tightness property and the smallest
eigenvalue of its associated kernel. These characterizations can not only
enhance our understanding of the proposed depth-induced Gaussian processes, but
also pave the way for future applications. Lastly, we examine the performance
of the proposed Gaussian process by regression experiments on two real-world
data sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Answer Candidates for Quizzes and Answer-Aware Question Generators. (arXiv:2108.12898v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12898">
<div class="article-summary-box-inner">
<span><p>In education, open-ended quiz questions have become an important tool for
assessing the knowledge of students. Yet, manually preparing such questions is
a tedious task, and thus automatic question generation has been proposed as a
possible alternative. So far, the vast majority of research has focused on
generating the question text, relying on question answering datasets with
readily picked answers, and the problem of how to come up with answer
candidates in the first place has been largely ignored. Here, we aim to bridge
this gap. In particular, we propose a model that can generate a specified
number of answer candidates for a given passage of text, which can then be used
by instructors to write questions manually or can be passed as an input to
automatic answer-aware question generators. Our experiments show that our
proposed answer candidate generation model outperforms several baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lipschitz Continuity Guided Knowledge Distillation. (arXiv:2108.12905v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12905">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation has become one of the most important model compression
techniques by distilling knowledge from larger teacher networks to smaller
student ones. Although great success has been achieved by prior distillation
methods via delicately designing various types of knowledge, they overlook the
functional properties of neural networks, which makes the process of applying
those techniques to new tasks unreliable and non-trivial. To alleviate such
problem, in this paper, we initially leverage Lipschitz continuity to better
represent the functional characteristic of neural networks and guide the
knowledge distillation process. In particular, we propose a novel Lipschitz
Continuity Guided Knowledge Distillation framework to faithfully distill
knowledge by minimizing the distance between two neural networks' Lipschitz
constants, which enables teacher networks to better regularize student networks
and improve the corresponding performance. We derive an explainable
approximation algorithm with an explicit theoretical derivation to address the
NP-hard problem of calculating the Lipschitz constant. Experimental results
have shown that our method outperforms other benchmarks over several knowledge
distillation tasks (e.g., classification, segmentation and object detection) on
CIFAR-100, ImageNet, and PASCAL VOC datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KO codes: Inventing Nonlinear Encoding and Decoding for Reliable Wireless Communication via Deep-learning. (arXiv:2108.12920v1 [cs.IT])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12920">
<div class="article-summary-box-inner">
<span><p>Landmark codes underpin reliable physical layer communication, e.g.,
Reed-Muller, BCH, Convolution, Turbo, LDPC and Polar codes: each is a linear
code and represents a mathematical breakthrough. The impact on humanity is
huge: each of these codes has been used in global wireless communication
standards (satellite, WiFi, cellular). Reliability of communication over the
classical additive white Gaussian noise (AWGN) channel enables benchmarking and
ranking of the different codes. In this paper, we construct KO codes, a
computationaly efficient family of deep-learning driven (encoder, decoder)
pairs that outperform the state-of-the-art reliability performance on the
standardized AWGN channel. KO codes beat state-of-the-art Reed-Muller and Polar
codes, under the low-complexity successive cancellation decoding, in the
challenging short-to-medium block length regime on the AWGN channel. We show
that the gains of KO codes are primarily due to the nonlinear mapping of
information bits directly to transmit real symbols (bypassing modulation) and
yet possess an efficient, high performance decoder. The key technical
innovation that renders this possible is design of a novel family of neural
architectures inspired by the computation tree of the {\bf K}ronecker {\bf
O}peration (KO) central to Reed-Muller and Polar codes. These architectures
pave way for the discovery of a much richer class of hitherto unexplored
nonlinear algebraic structures. The code is available at
\href{https://github.com/deepcomm/KOcodes}{https://github.com/deepcomm/KOcodes}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distributed Swarm Collision Avoidance Based on Angular Calculations. (arXiv:2108.12934v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12934">
<div class="article-summary-box-inner">
<span><p>Collision avoidance is one of the most important topics in the robotics
field. The goal is to move the robots from initial locations to target
locations such that they follow shortest non-colliding paths in the shortest
time and with the least amount of energy. In this paper, a distributed and
real-time algorithm for dense and complex 2D and 3D environments is proposed.
This algorithm uses angular calculations to select the optimal direction for
the movement of each robot and it has been shown that these separate
calculations lead to a form of cooperative behavior among agents. We evaluated
the proposed approach on various simulation and experimental scenarios and
compared the results with FMP and ORCA, two important algorithms in this field.
The results show that the proposed approach is at least 25% faster than ORCA
and at least 7% faster than FMP and also more reliable than both methods. The
proposed method is shown to enable fully autonomous navigation of a swarm of
crazyflies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RetroGAN: A Cyclic Post-Specialization System for Improving Out-of-Knowledge and Rare Word Representations. (arXiv:2108.12941v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12941">
<div class="article-summary-box-inner">
<span><p>Retrofitting is a technique used to move word vectors closer together or
further apart in their space to reflect their relationships in a Knowledge Base
(KB). However, retrofitting only works on concepts that are present in that KB.
RetroGAN uses a pair of Generative Adversarial Networks (GANs) to learn a
one-to-one mapping between concepts and their retrofitted counterparts. It
applies that mapping (post-specializes) to handle concepts that do not appear
in the original KB in a manner similar to how some natural language systems
handle out-of-vocabulary entries. We test our system on three word-similarity
benchmarks and a downstream sentence simplification task and achieve the state
of the art (CARD-660). Altogether, our results demonstrate our system's
effectiveness for out-of-knowledge and rare word generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for Two-Stream Models in Multivariate Space for Video Recognition. (arXiv:2108.12957v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12957">
<div class="article-summary-box-inner">
<span><p>Conventional video models rely on a single stream to capture the complex
spatial-temporal features. Recent work on two-stream video models, such as
SlowFast network and AssembleNet, prescribe separate streams to learn
complementary features, and achieve stronger performance. However, manually
designing both streams as well as the in-between fusion blocks is a daunting
task, requiring to explore a tremendously large design space. Such manual
exploration is time-consuming and often ends up with sub-optimal architectures
when computational resources are limited and the exploration is insufficient.
In this work, we present a pragmatic neural architecture search approach, which
is able to search for two-stream video models in giant spaces efficiently. We
design a multivariate search space, including 6 search variables to capture a
wide variety of choices in designing two-stream models. Furthermore, we propose
a progressive search procedure, by searching for the architecture of individual
streams, fusion blocks, and attention blocks one after the other. We
demonstrate two-stream models with significantly better performance can be
automatically discovered in our design space. Our searched two-stream models,
namely Auto-TSNet, consistently outperform other models on standard benchmarks.
On Kinetics, compared with the SlowFast model, our Auto-TSNet-L model reduces
FLOPS by nearly 11 times while achieving the same accuracy 78.9%. On
Something-Something-V2, Auto-TSNet-M improves the accuracy by at least 2% over
other methods which use less than 50 GFLOPS per video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3DStyleNet: Creating 3D Shapes with Geometric and Texture Style Variations. (arXiv:2108.12958v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12958">
<div class="article-summary-box-inner">
<span><p>We propose a method to create plausible geometric and texture style
variations of 3D objects in the quest to democratize 3D content creation. Given
a pair of textured source and target objects, our method predicts a part-aware
affine transformation field that naturally warps the source shape to imitate
the overall geometric style of the target. In addition, the texture style of
the target is transferred to the warped source object with the help of a
multi-view differentiable renderer. Our model, 3DStyleNet, is composed of two
sub-networks trained in two stages. First, the geometric style network is
trained on a large set of untextured 3D shapes. Second, we jointly optimize our
geometric style network and a pre-trained image style transfer network with
losses defined over both the geometry and the rendering of the result. Given a
small set of high-quality textured objects, our method can create many novel
stylized shapes, resulting in effortless 3D content creation and style-ware
data augmentation. We showcase our approach qualitatively on 3D content
stylization, and provide user studies to validate the quality of our results.
In addition, our method can serve as a valuable tool to create 3D data
augmentations for computer vision tasks. Extensive quantitative analysis shows
that 3DStyleNet outperforms alternative data augmentation techniques for the
downstream task of single-image 3D reconstruction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">X2Teeth: 3D Teeth Reconstruction from a Single Panoramic Radiograph. (arXiv:2108.13004v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13004">
<div class="article-summary-box-inner">
<span><p>3D teeth reconstruction from X-ray is important for dental diagnosis and many
clinical operations. However, no existing work has explored the reconstruction
of teeth for a whole cavity from a single panoramic radiograph. Different from
single object reconstruction from photos, this task has the unique challenge of
constructing multiple objects at high resolutions. To conquer this task, we
develop a novel ConvNet X2Teeth that decomposes the task into teeth
localization and single-shape estimation. We also introduce a patch-based
training strategy, such that X2Teeth can be end-to-end trained for optimal
performance. Extensive experiments show that our method can successfully
estimate the 3D structure of the cavity and reflect the details for each tooth.
Moreover, X2Teeth achieves a reconstruction IoU of 0.681, which significantly
outperforms the encoder-decoder method by $1.71X and the retrieval-based method
by $1.52X. Our method can also be promising for other multi-anatomy 3D
reconstruction tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Communication-Computation Efficient Device-Edge Co-Inference via AutoML. (arXiv:2108.13009v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13009">
<div class="article-summary-box-inner">
<span><p>Device-edge co-inference, which partitions a deep neural network between a
resource-constrained mobile device and an edge server, recently emerges as a
promising paradigm to support intelligent mobile applications. To accelerate
the inference process, on-device model sparsification and intermediate feature
compression are regarded as two prominent techniques. However, as the on-device
model sparsity level and intermediate feature compression ratio have direct
impacts on computation workload and communication overhead respectively, and
both of them affect the inference accuracy, finding the optimal values of these
hyper-parameters brings a major challenge due to the large search space. In
this paper, we endeavor to develop an efficient algorithm to determine these
hyper-parameters. By selecting a suitable model split point and a pair of
encoder/decoder for the intermediate feature vector, this problem is casted as
a sequential decision problem, for which, a novel automated machine learning
(AutoML) framework is proposed based on deep reinforcement learning (DRL).
Experiment results on an image classification task demonstrate the
effectiveness of the proposed framework in achieving a better
communication-computation trade-off and significant inference speedup against
various baseline schemes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Temporal Knowledge Graph Completion Method Based on Balanced Timestamp Distribution. (arXiv:2108.13024v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13024">
<div class="article-summary-box-inner">
<span><p>Completion through the embedding representation of the knowledge graph (KGE)
has been a research hotspot in recent years. Realistic knowledge graphs are
mostly related to time, while most of the existing KGE algorithms ignore the
time information. A few existing methods directly or indirectly encode the time
information, ignoring the balance of timestamp distribution, which greatly
limits the performance of temporal knowledge graph completion (KGC). In this
paper, a temporal KGC method is proposed based on the direct encoding time
information framework, and a given time slice is treated as the finest
granularity for balanced timestamp distribution. A large number of experiments
on temporal knowledge graph datasets extracted from the real world demonstrate
the effectiveness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transport-based Counterfactual Models. (arXiv:2108.13025v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13025">
<div class="article-summary-box-inner">
<span><p>Counterfactual frameworks have grown popular in explainable and fair machine
learning, as they offer a natural notion of causation. However,
state-of-the-art models to compute counterfactuals are either unrealistic or
unfeasible. In particular, while Pearl's causal inference provides appealing
rules to calculate counterfactuals, it relies on a model that is unknown and
hard to discover in practice. We address the problem of designing realistic and
feasible counterfactuals in the absence of a causal model. We define
transport-based counterfactual models as collections of joint probability
distributions between observable distributions, and show their connection to
causal counterfactuals. More specifically, we argue that optimal transport
theory defines relevant transport-based counterfactual models, as they are
numerically feasible, statistically-faithful, and can even coincide with causal
counterfactual models. We illustrate the practicality of these models by
defining sharper fairness criteria than typical group fairness conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SurRoL: An Open-source Reinforcement Learning Centered and dVRK Compatible Platform for Surgical Robot Learning. (arXiv:2108.13035v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13035">
<div class="article-summary-box-inner">
<span><p>Autonomous surgical execution relieves tedious routines and surgeon's
fatigue. Recent learning-based methods, especially reinforcement learning (RL)
based methods, achieve promising performance for dexterous manipulation, which
usually requires the simulation to collect data efficiently and reduce the
hardware cost. The existing learning-based simulation platforms for medical
robots suffer from limited scenarios and simplified physical interactions,
which degrades the real-world performance of learned policies. In this work, we
designed SurRoL, an RL-centered simulation platform for surgical robot learning
compatible with the da Vinci Research Kit (dVRK). The designed SurRoL
integrates a user-friendly RL library for algorithm development and a real-time
physics engine, which is able to support more PSM/ECM scenarios and more
realistic physical interactions. Ten learning-based surgical tasks are built in
the platform, which are common in the real autonomous surgical execution. We
evaluate SurRoL using RL algorithms in simulation, provide in-depth analysis,
deploy the trained policies on the real dVRK, and show that our SurRoL achieves
better transferability in the real world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aleatoric Description Logic for Probailistic Reasoning (Long Version). (arXiv:2108.13036v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13036">
<div class="article-summary-box-inner">
<span><p>Description logics are a powerful tool for describing ontological knowledge
bases. That is, they give a factual account of the world in terms of
individuals, concepts and relations. In the presence of uncertainty, such
factual accounts are not feasible, and a subjective or epistemic approach is
required. Aleatoric description logic models uncertainty in the world as
aleatoric events, by the roll of the dice, where an agent has subjective
beliefs about the bias of these dice. This provides a subjective Bayesian
description logic, where propositions and relations are assigned probabilities
according to what a rational agent would bet, given a configuration of possible
individuals and dice. Aleatoric description logic is shown to generalise the
description logic ALC, and can be seen to describe a probability space of
interpretations of a restriction of ALC where all roles are functions. Several
computational problems are considered and model-checking and consistency
checking algorithms are presented. Finally, aleatoric description logic is
shown to be able to model learning, where agents are able to condition their
beliefs on the bias of dice according to observations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrated Decision and Control at Multi-Lane Intersections with Mixed Traffic Flow. (arXiv:2108.13038v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13038">
<div class="article-summary-box-inner">
<span><p>Autonomous driving at intersections is one of the most complicated and
accident-prone traffic scenarios, especially with mixed traffic participants
such as vehicles, bicycles and pedestrians. The driving policy should make safe
decisions to handle the dynamic traffic conditions and meet the requirements of
on-board computation. However, most of the current researches focuses on
simplified intersections considering only the surrounding vehicles and
idealized traffic lights. This paper improves the integrated decision and
control framework and develops a learning-based algorithm to deal with complex
intersections with mixed traffic flows, which can not only take account of
realistic characteristics of traffic lights, but also learn a safe policy under
different safety constraints. We first consider different velocity models for
green and red lights in the training process and use a finite state machine to
handle different modes of light transformation. Then we design different types
of distance constraints for vehicles, traffic lights, pedestrians, bicycles
respectively and formulize the constrained optimal control problems (OCPs) to
be optimized. Finally, reinforcement learning (RL) with value and policy
networks is adopted to solve the series of OCPs. In order to verify the safety
and efficiency of the proposed method, we design a multi-lane intersection with
the existence of large-scale mixed traffic participants and set practical
traffic light phases. The simulation results indicate that the trained decision
and control policy can well balance safety and tracking performance. Compared
with model predictive control (MPC), the computational time is three orders of
magnitude lower.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auto-Split: A General Framework of Collaborative Edge-Cloud AI. (arXiv:2108.13041v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13041">
<div class="article-summary-box-inner">
<span><p>In many industry scale applications, large and resource consuming machine
learning models reside in powerful cloud servers. At the same time, large
amounts of input data are collected at the edge of cloud. The inference results
are also communicated to users or passed to downstream tasks at the edge. The
edge often consists of a large number of low-power devices. It is a big
challenge to design industry products to support sophisticated deep model
deployment and conduct model inference in an efficient manner so that the model
accuracy remains high and the end-to-end latency is kept low. This paper
describes the techniques and engineering practice behind Auto-Split, an
edge-cloud collaborative prototype of Huawei Cloud. This patented technology is
already validated on selected applications, is on its way for broader
systematic edge-cloud application integration, and is being made available for
public use as an automated pipeline service for end-to-end cloud-edge
collaborative intelligence deployment. To the best of our knowledge, there is
no existing industry product that provides the capability of Deep Neural
Network (DNN) splitting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Demystifying Drug Repurposing Domain Comprehension with Knowledge Graph Embedding. (arXiv:2108.13051v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13051">
<div class="article-summary-box-inner">
<span><p>Drug repurposing is more relevant than ever due to drug development's rising
costs and the need to respond to emerging diseases quickly. Knowledge graph
embedding enables drug repurposing using heterogeneous data sources combined
with state-of-the-art machine learning models to predict new drug-disease links
in the knowledge graph. As in many machine learning applications, significant
work is still required to understand the predictive models' behavior. We
propose a structured methodology to understand better machine learning models'
results for drug repurposing, suggesting key elements of the knowledge graph to
improve predictions while saving computational resources. We reduce the
training set of 11.05% and the embedding space by 31.87%, with only a 2%
accuracy reduction, and increase accuracy by 60% on the open ogbl-biokg graph
adding only 1.53% new triples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Satisfiability and Containment of Recursive SHACL. (arXiv:2108.13063v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13063">
<div class="article-summary-box-inner">
<span><p>The Shapes Constraint Language (SHACL) is the recent W3C recommendation
language for validating RDF data, by verifying certain shapes on graphs.
Previous work has largely focused on the validation problem and the standard
decision problems of satisfiability and containment, crucial for design and
optimisation purposes, have only been investigated for simplified versions of
SHACL. Moreover, the SHACL specification does not define the semantics of
recursively-defined constraints, which led to several alternative recursive
semantics being proposed in the literature. The interaction between these
different semantics and important decision problems has not been investigated
yet. In this article we provide a comprehensive study of the different features
of SHACL, by providing a translation to a new first-order language, called SCL,
that precisely captures the semantics of SHACL. We also present MSCL, a
second-order extension of SCL, which allows us to define, in a single formal
logic framework, the main recursive semantics of SHACL. Within this language we
also provide an effective treatment of filter constraints which are often
neglected in the related literature. Using this logic we provide a detailed map
of (un)decidability and complexity results for the satisfiability and
containment decision problems for different SHACL fragments. Notably, we prove
that both problems are undecidable for the full language, but we present
decidable combinations of interesting features, even in the face of recursion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">To tune or not to tune? An Approach for Recommending Important Hyperparameters. (arXiv:2108.13066v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13066">
<div class="article-summary-box-inner">
<span><p>Novel technologies in automated machine learning ease the complexity of
algorithm selection and hyperparameter optimization. Hyperparameters are
important for machine learning models as they significantly influence the
performance of machine learning models. Many optimization techniques have
achieved notable success in hyperparameter tuning and surpassed the performance
of human experts. However, depending on such techniques as blackbox algorithms
can leave machine learning practitioners without insight into the relative
importance of different hyperparameters. In this paper, we consider building
the relationship between the performance of the machine learning models and
their hyperparameters to discover the trend and gain insights, with empirical
results based on six classifiers and 200 datasets. Our results enable users to
decide whether it is worth conducting a possibly time-consuming tuning
strategy, to focus on the most important hyperparameters, and to choose
adequate hyperparameter spaces for tuning. The results of our experiments show
that gradient boosting and Adaboost outperform other classifiers across 200
problems. However, they need tuning to boost their performance. Overall, the
results obtained from this study provide a quantitative basis to focus efforts
toward guided automated hyperparameter optimization and contribute toward the
development of better-automated machine learning frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Introduction to Variational Inference. (arXiv:2108.13083v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13083">
<div class="article-summary-box-inner">
<span><p>Approximating complex probability densities is a core problem in modern
statistics. In this paper, we introduce the concept of Variational Inference
(VI), a popular method in machine learning that uses optimization techniques to
estimate complex probability densities. This property allows VI to converge
faster than classical methods, such as, Markov Chain Monte Carlo sampling.
Conceptually, VI works by choosing a family of probability density functions
and then finding the one closest to the actual probability density -- often
using the Kullback-Leibler (KL) divergence as the optimization metric. We
introduce the Evidence Lower Bound to tractably compute the approximated
probability density and we review the ideas behind mean-field variational
inference. Finally, we discuss the applications of VI to variational
auto-encoders (VAE) and VAE-Generative Adversarial Network (VAE-GAN). With this
paper, we aim to explain the concept of VI and assist in future research with
this approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Vulnerabilities of Deep Neural Policies. (arXiv:2108.13093v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13093">
<div class="article-summary-box-inner">
<span><p>Reinforcement learning policies based on deep neural networks are vulnerable
to imperceptible adversarial perturbations to their inputs, in much the same
way as neural network image classifiers. Recent work has proposed several
methods to improve the robustness of deep reinforcement learning agents to
adversarial perturbations based on training in the presence of these
imperceptible perturbations (i.e. adversarial training). In this paper, we
study the effects of adversarial training on the neural policy learned by the
agent. In particular, we follow two distinct parallel approaches to investigate
the outcomes of adversarial training on deep neural policies based on
worst-case distributional shift and feature sensitivity. For the first
approach, we compare the Fourier spectrum of minimal perturbations computed for
both adversarially trained and vanilla trained neural policies. Via experiments
in the OpenAI Atari environments we show that minimal perturbations computed
for adversarially trained policies are more focused on lower frequencies in the
Fourier domain, indicating a higher sensitivity of these policies to low
frequency perturbations. For the second approach, we propose a novel method to
measure the feature sensitivities of deep neural policies and we compare these
feature sensitivity differences in state-of-the-art adversarially trained deep
neural policies and vanilla trained deep neural policies. We believe our
results can be an initial step towards understanding the relationship between
adversarial training and different notions of robustness for neural policies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Sentiment Analysis Dataset for Trustworthiness Evaluation. (arXiv:2108.13140v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13140">
<div class="article-summary-box-inner">
<span><p>While deep learning models have greatly improved the performance of most
artificial intelligence tasks, they are often criticized to be untrustworthy
due to the black-box problem. Consequently, many works have been proposed to
study the trustworthiness of deep learning. However, as most open datasets are
designed for evaluating the accuracy of model outputs, there is still a lack of
appropriate datasets for evaluating the inner workings of neural networks. The
lack of datasets obviously hinders the development of trustworthiness research.
Therefore, in order to systematically evaluate the factors for building
trustworthy systems, we propose a novel and well-annotated sentiment analysis
dataset to evaluate robustness and interpretability. To evaluate these factors,
our dataset contains diverse annotations about the challenging distribution of
instances, manual adversarial instances and sentiment explanations. Several
evaluation metrics are further proposed for interpretability and robustness.
Based on the dataset and metrics, we conduct comprehensive comparisons for the
trustworthiness of three typical models, and also study the relations between
accuracy, robustness and interpretability. We release this trustworthiness
evaluation dataset at \url{https://github/xyz} and hope our work can facilitate
the progress on building more trustworthy systems for real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enterprise Architecture Model Transformation Engine. (arXiv:2108.13169v1 [cs.DC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13169">
<div class="article-summary-box-inner">
<span><p>With increasing linkage within value chains, the IT systems of different
companies are also being connected with each other. This enables the
integration of services within the movement of Industry 4.0 in order to improve
the quality and performance of the processes. Enterprise architecture models
form the basis for this with a better buisness IT-alignment. However, the
heterogeneity of the modeling frameworks and description languages makes a
concatenation considerably difficult, especially differences in syntax,
semantic and relations. Therefore, this paper presents a transformation engine
to convert enterprise architecture models between several languages. We
developed the first generic translation approach that is free of specific
meta-modeling, which is flexible adaptable to arbitrary modeling languages. The
transformation process is defined by various pattern matching techniques using
a rule-based description language. It uses set theory and first-order logic for
an intuitive description as a basis. The concept is practical evaluated using
an example in the area of a large German IT-service provider. Anyhow, the
approach is applicable between a wide range of enterprise architecture
frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personalized Recommender System for Children's Book Recommendation with A Realtime Interactive Robot. (arXiv:1710.00310v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1710.00310">
<div class="article-summary-box-inner">
<span><p>In this paper we study the personalized book recommender system in a
child-robot interactive environment. Firstly, we propose a novel text search
algorithm using an inverse filtering mechanism that improves the efficiency.
Secondly, we propose a user interest prediction method based on the Bayesian
network and a novel feedback mechanism. According to children's fuzzy language
input, the proposed method gives the predicted interests. Thirdly, the domain
specific synonym association is proposed based on word vectorization, in order
to improve the understanding of user intention. Experimental results show that
the proposed recommender system has an improved performance and it can operate
on embedded consumer devices with limited computational resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inventory Balancing with Online Learning. (arXiv:1810.05640v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1810.05640">
<div class="article-summary-box-inner">
<span><p>We study a general problem of allocating limited resources to heterogeneous
customers over time under model uncertainty. Each type of customer can be
serviced using different actions, each of which stochastically consumes some
combination of resources, and returns different rewards for the resources
consumed. We consider a general model where the resource consumption
distribution associated with each (customer type, action)-combination is not
known, but is consistent and can be learned over time. In addition, the
sequence of customer types to arrive over time is arbitrary and completely
unknown.
</p>
<p>We overcome both the challenges of model uncertainty and customer
heterogeneity by judiciously synthesizing two algorithmic frameworks from the
literature: inventory balancing, which "reserves" a portion of each resource
for high-reward customer types which could later arrive, and online learning,
which shows how to "explore" the resource consumption distributions of each
customer type under different actions. We define an auxiliary problem, which
allows for existing competitive ratio and regret bounds to be seamlessly
integrated. Furthermore, we show that the performance guarantee generated by
our framework is tight, that is, we provide an information-theoretic lower
bound which shows that both the loss from competitive ratio and the loss for
regret are relevant in the combined problem.
</p>
<p>Finally, we demonstrate the efficacy of our algorithms on a publicly
available hotel data set. Our framework is highly practical in that it requires
no historical data (no fitted customer choice models, nor forecasting of
customer arrival patterns) and can be used to initialize allocation strategies
in fast-changing environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deduction Theorem: The Problematic Nature of Common Practice in Game Theory. (arXiv:1908.00409v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.00409">
<div class="article-summary-box-inner">
<span><p>We consider the Deduction Theorem used in the literature of game theory to
run a purported proof by contradiction. In the context of game theory, it is
stated that if we have a proof of $\phi \vdash \varphi$, then we also have a
proof of $\phi \Rightarrow \varphi$. Hence, the proof of $\phi \Rightarrow
\varphi$ is deduced from a previously known statement. However, we argue that
one has to manage to establish that a proof exists for the clauses $\phi$ and
$\varphi$, i.e., they are known true statements in order to show that $\phi
\vdash \varphi$ is provable, and that therefore $\phi \Rightarrow \varphi$ is
provable as well. Thus, we are not allowed to assume that the clause $\phi$ or
$\varphi$ is a true statement. This leads immediately to a wrong conclusion.
Apart from this, we stress to other facts why the Deduction Theorem is not
applicable to run a proof by contradiction. Finally, we present an example from
industrial cooperation where the Deduction Theorem is not correctly applied
with the consequence that the obtained result contradicts the well-known
aggregation issue.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">First return, then explore. (arXiv:2004.12919v4 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.12919">
<div class="article-summary-box-inner">
<span><p>The promise of reinforcement learning is to solve complex sequential decision
problems autonomously by specifying a high-level reward function only. However,
reinforcement learning algorithms struggle when, as is often the case, simple
and intuitive rewards provide sparse and deceptive feedback. Avoiding these
pitfalls requires thoroughly exploring the environment, but creating algorithms
that can do so remains one of the central challenges of the field. We
hypothesise that the main impediment to effective exploration originates from
algorithms forgetting how to reach previously visited states ("detachment") and
from failing to first return to a state before exploring from it
("derailment"). We introduce Go-Explore, a family of algorithms that addresses
these two challenges directly through the simple principles of explicitly
remembering promising states and first returning to such states before
intentionally exploring. Go-Explore solves all heretofore unsolved Atari games
and surpasses the state of the art on all hard-exploration games, with orders
of magnitude improvements on the grand challenges Montezuma's Revenge and
Pitfall. We also demonstrate the practical potential of Go-Explore on a
sparse-reward pick-and-place robotics task. Additionally, we show that adding a
goal-conditioned policy can further improve Go-Explore's exploration efficiency
and enable it to handle stochasticity throughout training. The substantial
performance gains from Go-Explore suggest that the simple principles of
remembering states, returning to them, and exploring from them are a powerful
and general approach to exploration, an insight that may prove critical to the
creation of truly intelligent learning agents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Implementing Agent-Based Systems via Computability Logic CL2. (arXiv:2010.08925v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08925">
<div class="article-summary-box-inner">
<span><p>Computability logic(CoL) is a powerful computational model. In this paper, we
show that CoL naturally supports multi-agent programming models where resources
(coffee for example) are involved. To be specific, we discuss an implementation
of the Starbucks based on CoL (CL2 to be exact).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anonymizing Sensor Data on the Edge: A Representation Learning and Transformation Approach. (arXiv:2011.08315v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08315">
<div class="article-summary-box-inner">
<span><p>The abundance of data collected by sensors in Internet of Things (IoT)
devices, and the success of deep neural networks in uncovering hidden patterns
in time series data have led to mounting privacy concerns. This is because
private and sensitive information can be potentially learned from sensor data
by applications that have access to this data. In this paper, we aim to examine
the tradeoff between utility and privacy loss by learning low-dimensional
representations that are useful for data obfuscation. We propose deterministic
and probabilistic transformations in the latent space of a variational
autoencoder to synthesize time series data such that intrusive inferences are
prevented while desired inferences can still be made with sufficient accuracy.
In the deterministic case, we use a linear transformation to move the
representation of input data in the latent space such that the reconstructed
data is likely to have the same public attribute but a different private
attribute than the original input data. In the probabilistic case, we apply the
linear transformation to the latent representation of input data with some
probability. We compare our technique with autoencoder-based anonymization
techniques and additionally show that it can anonymize data in real time on
resource-constrained edge devices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FairOD: Fairness-aware Outlier Detection. (arXiv:2012.03063v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03063">
<div class="article-summary-box-inner">
<span><p>Fairness and Outlier Detection (OD) are closely related, as it is exactly the
goal of OD to spot rare, minority samples in a given population. However, when
being a minority (as defined by protected variables, such as
race/ethnicity/sex/age) does not reflect positive-class membership (such as
criminal/fraud), OD produces unjust outcomes. Surprisingly, fairness-aware OD
has been almost untouched in prior work, as fair machine learning literature
mainly focuses on supervised settings. Our work aims to bridge this gap.
Specifically, we develop desiderata capturing well-motivated fairness criteria
for OD, and systematically formalize the fair OD problem. Further, guided by
our desiderata, we propose FairOD, a fairness-aware outlier detector that has
the following desirable properties: FairOD (1) exhibits treatment parity at
test time, (2) aims to flag equal proportions of samples from all groups (i.e.
obtain group fairness, via statistical parity), and (3) strives to flag truly
high-risk samples within each group. Extensive experiments on a diverse set of
synthetic and real world datasets show that FairOD produces outcomes that are
fair with respect to protected variables, while performing comparable to (and
in some cases, even better than) fairness-agnostic detectors in terms of
detection performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Layer Distillation with Semantic Calibration. (arXiv:2012.03236v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03236">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation is a technique to enhance the generalization ability
of a student model by exploiting outputs from a teacher model. Recently,
feature-map based variants explore knowledge transfer between manually assigned
teacher-student pairs in intermediate layers for further improvement. However,
layer semantics may vary in different neural networks and semantic mismatch in
manual layer associations will lead to performance degeneration due to negative
regularization. To address this issue, we propose Semantic Calibration for
cross-layer Knowledge Distillation (SemCKD), which automatically assigns proper
target layers of the teacher model for each student layer with an attention
mechanism. With a learned attention distribution, each student layer distills
knowledge contained in multiple teacher layers rather than a specific
intermediate layer for appropriate cross-layer supervision. We further provide
theoretical analysis of the association weights and conduct extensive
experiments to demonstrate the effectiveness of our approach. Code is avaliable
at \url{https://github.com/DefangChen/SemCKD}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Query-free Black-box Adversarial Attacks on Graphs. (arXiv:2012.06757v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06757">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks on graphs have attracted considerable research interests.
Existing works assume the attacker is either (partly) aware of the victim
model, or able to send queries to it. These assumptions are, however,
unrealistic. To bridge the gap between theoretical graph attacks and real-world
scenarios, in this work, we propose a novel and more realistic setting: strict
black-box graph attack, in which the attacker has no knowledge about the victim
model at all and is not allowed to send any queries. To design such an attack
strategy, we first propose a generic graph filter to unify different families
of graph-based models. The strength of attacks can then be quantified by the
change in the graph filter before and after attack. By maximizing this change,
we are able to find an effective attack strategy, regardless of the underlying
model. To solve this optimization problem, we also propose a relaxation
technique and approximation theories to reduce the difficulty as well as the
computational expense. Experiments demonstrate that, even with no exposure to
the model, the Macro-F1 drops 6.4% in node classification and 29.5% in graph
classification, which is a significant result compared with existent works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variance Reduction on General Adaptive Stochastic Mirror Descent. (arXiv:2012.13760v3 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13760">
<div class="article-summary-box-inner">
<span><p>In this work, we investigate the idea of variance reduction by studying its
properties with general adaptive mirror descent algorithms in nonsmooth
nonconvex finite-sum optimization problems. We propose a simple yet generalized
framework for variance reduced adaptive mirror descent algorithms named SVRAMD
and provide its convergence analysis in both the nonsmooth nonconvex problem
and the P-L conditioned problem. We prove that variance reduction reduces the
SFO complexity of adaptive mirror descent algorithms and thus accelerates their
convergence. In particular, our general theory implies that variance reduction
can be applied to algorithms using time-varying step sizes and self-adaptive
algorithms such as AdaGrad and RMSProp. Moreover, the convergence rates of
SVRAMD recover the best existing rates of non-adaptive variance reduced mirror
descent algorithms without complicated algorithmic components. Extensive
experiments in deep learning validate our theoretical findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing bias and increasing utility by federated generative modeling of medical images using a centralized adversary. (arXiv:2101.07235v2 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07235">
<div class="article-summary-box-inner">
<span><p>We introduce FELICIA (FEderated LearnIng with a CentralIzed Adversary) a
generative mechanism enabling collaborative learning. In particular, we show
how a data owner with limited and biased data could benefit from other data
owners while keeping data from all the sources private. This is a common
scenario in medical image analysis where privacy legislation prevents data from
being shared outside local premises. FELICIA works for a large family of
Generative Adversarial Networks (GAN) architectures including vanilla and
conditional GANs as demonstrated in this work. We show that by using the
FELICIA mechanism, a data owner with limited image samples can generate
high-quality synthetic images with high utility while neither data owners has
to provide access to its data. The sharing happens solely through a central
discriminator that has access limited to synthetic data. Here, utility is
defined as classification performance on a real test set. We demonstrate these
benefits on several realistic healthcare scenarions using benchmark image
datasets (MNIST, CIFAR-10) as well as on medical images for the task of skin
lesion classification. With multiple experiments, we show that even in the
worst cases, combining FELICIA with real data gracefully achieves performance
on par with real data while most results significantly improves the utility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast End-to-End Speech Recognition via Non-Autoregressive Models and Cross-Modal Knowledge Transferring from BERT. (arXiv:2102.07594v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07594">
<div class="article-summary-box-inner">
<span><p>Attention-based encoder-decoder (AED) models have achieved promising
performance in speech recognition. However, because the decoder predicts text
tokens (such as characters or words) in an autoregressive manner, it is
difficult for an AED model to predict all tokens in parallel. This makes the
inference speed relatively slow. We believe that because the encoder already
captures the whole speech utterance, which has the token-level relationship
implicitly, we can predict a token without explicitly autoregressive language
modeling. When the prediction of a token does not rely on other tokens, the
parallel prediction of all tokens in the sequence is realizable. Based on this
idea, we propose a non-autoregressive speech recognition model called LASO
(Listen Attentively, and Spell Once). The model consists of an encoder, a
decoder, and a position dependent summarizer (PDS). The three modules are based
on basic attention blocks. The encoder extracts high-level representations from
the speech. The PDS uses positional encodings corresponding to tokens to
convert the acoustic representations into token-level representations. The
decoder further captures token-level relationships with the self-attention
mechanism. At last, the probability distribution on the vocabulary is computed
for each token position. Therefore, speech recognition is re-formulated as a
position-wise classification problem. Further, we propose a cross-modal
transfer learning method to refine semantics from a large-scale pre-trained
language model BERT for improving the performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leading or Following? Dyadic Robot Imitative Interaction Using the Active Inference Framework. (arXiv:2103.02137v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02137">
<div class="article-summary-box-inner">
<span><p>This study investigated how social interaction among robotic agents changes
dynamically depending on the individual belief of action intention. In a set of
simulation studies, we examine dyadic imitative interactions of robots using a
variational recurrent neural network model. The model is based on the free
energy principle such that a pair of interacting robots find themselves in a
loop, attempting to predict and infer each other's actions using active
inference. We examined how regulating the complexity term to minimize free
energy determines the dynamic characteristics of networks and interactions.
When one robot trained with tighter regulation and another trained with looser
regulation interact, the latter tends to lead the interaction by exerting
stronger action intention, while the former tends to follow by adapting to its
observations. The study confirms that the dyadic imitative interaction becomes
successful by achieving a high synchronization rate when a leader and a
follower are determined by developing action intentions with strong belief and
weak belief, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Digital Peter: Dataset, Competition and Handwriting Recognition Methods. (arXiv:2103.09354v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09354">
<div class="article-summary-box-inner">
<span><p>This paper presents a new dataset of Peter the Great's manuscripts and
describes a segmentation procedure that converts initial images of documents
into the lines. The new dataset may be useful for researchers to train
handwriting text recognition models as a benchmark for comparing different
models. It consists of 9 694 images and text files corresponding to lines in
historical documents. The open machine learning competition Digital Peter was
held based on the considered dataset. The baseline solution for this
competition as well as more advanced methods on handwritten text recognition
are described in the article. Full dataset and all code are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In-air Knotting of Rope using Dual-Arm Robot based on Deep Learning. (arXiv:2103.09402v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09402">
<div class="article-summary-box-inner">
<span><p>In this study, we report the successful execution of in-air knotting of rope
using a dual-arm two-finger robot based on deep learning. Owing to its
flexibility, the state of the rope was in constant flux during the operation of
the robot. This required the robot control system to dynamically correspond to
the state of the object at all times. However, a manual description of
appropriate robot motions corresponding to all object states is difficult to be
prepared in advance. To resolve this issue, we constructed a model that
instructed the robot to perform bowknots and overhand knots based on two deep
neural networks trained using the data gathered from its sensorimotor,
including visual and proximity sensors. The resultant model was verified to be
capable of predicting the appropriate robot motions based on the sensory
information available online. In addition, we designed certain task motions
based on the Ian knot method using the dual-arm two-fingers robot. The designed
knotting motions do not require a dedicated workbench or robot hand, thereby
enhancing the versatility of the proposed method. Finally, experiments were
performed to estimate the knotting performance of the real robot while
executing overhand knots and bowknots on rope and its success rate. The
experimental results established the effectiveness and high performance of the
proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07650">
<div class="article-summary-box-inner">
<span><p>Recently, prompt-tuning has achieved promising results on some few-shot
classification tasks. The core idea of prompt-tuning is to insert text pieces,
i.e., templates, into the input and transform a classification task into a
masked language modeling problem. However, as for relation extraction,
determining the appropriate prompt template requires domain expertise. Single
label word handcrafted or auto-searched is cumbersome and time-consuming to
verify their effectiveness in non-few-shot scenarios. Further, there exist
abundant semantic knowledge among the entities and relation labels which cannot
be ignored. To this end, we focus on incorporating knowledge into prompt-tuning
for relation extraction and propose a Knowledge-aware prompt-tuning with
synergistic optimization (KNIGHT) approach. Specifically, we inject entity and
relation knowledge into prompt construction with learnable virtual template
words and answer words and jointly optimize their representation with knowledge
constraints. Extensive experimental results on five datasets with standard and
low-resource settings demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Node Selection Toward Faster Convergence for Federated Learning on Non-IID Data. (arXiv:2105.07066v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07066">
<div class="article-summary-box-inner">
<span><p>Federated Learning (FL) is a distributed learning paradigm that enables a
large number of resource-limited nodes to collaboratively train a model without
data sharing. The non-independent-and-identically-distributed (non-i.i.d.) data
samples invoke discrepancy between global and local objectives, making the FL
model slow to converge. In this paper, we proposed Optimal Aggregation
algorithm for better aggregation, which finds out the optimal subset of local
updates of participating nodes in each global round, by identifying and
excluding the adverse local updates via checking the relationship between the
local gradient and the global gradient. Then, we proposed a Probabilistic Node
Selection framework (FedPNS) to dynamically change the probability for each
node to be selected based on the output of Optimal Aggregation. FedPNS can
preferentially select nodes that propel faster model convergence. The
unbiasedness of the proposed FedPNS design is illustrated and the convergence
rate improvement of FedPNS over the commonly adopted Federated Averaging
(FedAvg) algorithm is analyzed theoretically. Experimental results demonstrate
the effectiveness of FedPNS in accelerating the FL convergence rate, as
compared to FedAvg with random node selection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey and Perspective on Social Emotions in Robotics. (arXiv:2105.09647v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09647">
<div class="article-summary-box-inner">
<span><p>This study reviews research on social emotions in robotics. In robotics, the
study of emotions has been pursued for a long time, including the study of
their recognition, expression, and computational modeling of the basic
mechanisms which underlie them. Research has advanced according to well-known
psychological findings, such as category and dimension theories. Many studies
have been based on these basic theories, addressing only basic emotions.
However, social emotions, also referred to as higher-level emotions, have been
studied in psychology. We believe that these higher-level emotions are worth
pursuing in robotics for next-generation, socially aware robots. In this review
paper, we summarize the findings on social emotions in psychology and
neuroscience, along with a survey of the studies on social emotions in robotics
that have been conducted to date. Thereafter, research directions toward the
implementation of social emotions in robots are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks. (arXiv:2105.12655v2 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12655">
<div class="article-summary-box-inner">
<span><p>Over the last several decades, software has been woven into the fabric of
every aspect of our society. As software development surges and code
infrastructure of enterprise applications ages, it is now more critical than
ever to increase software development productivity and modernize legacy
applications. Advances in deep learning and machine learning algorithms have
enabled numerous breakthroughs, motivating researchers to leverage AI
techniques to improve software development efficiency. Thus, the fast-emerging
research area of AI for Code has garnered new interest and gathered momentum.
In this paper, we present a large-scale dataset CodeNet, consisting of over 14
million code samples and about 500 million lines of code in 55 different
programming languages, which is aimed at teaching AI to code. In addition to
its large scale, CodeNet has a rich set of high-quality annotations to
benchmark and help accelerate research in AI techniques for a variety of
critical coding tasks, including code similarity and classification, code
translation between a large variety of programming languages, and code
performance (runtime and memory) improvement techniques. Additionally, CodeNet
provides sample input and output test sets for 98.5% of the code samples, which
can be used as an oracle for determining code correctness and potentially guide
reinforcement learning for code quality improvements. As a usability feature,
we provide several pre-processing tools in CodeNet to transform source code
into representations that can be readily used as inputs into machine learning
models. Results of code classification and code similarity experiments using
the CodeNet dataset are provided as a reference. We hope that the scale,
diversity and rich, high-quality annotations of CodeNet will offer
unprecedented research opportunities at the intersection of AI and Software
Engineering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Probabilistic Forecast-Driven Strategy for a Risk-Aware Participation in the Capacity Firming Market: extended version. (arXiv:2105.13801v3 [stat.AP] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13801">
<div class="article-summary-box-inner">
<span><p>This paper addresses the energy management of a grid-connected renewable
generation plant coupled with a battery energy storage device in the capacity
firming market, designed to promote renewable power generation facilities in
small non-interconnected grids. The core contribution is to propose a
probabilistic forecast-driven strategy, modeled as a min-max-min robust
optimization problem with recourse. It is solved using a Benders-dual cutting
plane algorithm and a column and constraints generation algorithm in a
tractable manner. A dynamic risk-averse parameters selection strategy based on
the quantile forecasts distribution is proposed to improve the results. A
secondary contribution is to use a recently developed deep learning model known
as normalizing flows to generate quantile forecasts of renewable generation for
the robust optimization problem. This technique provides a general mechanism
for defining expressive probability distributions, only requiring the
specification of a base distribution and a series of bijective transformations.
Overall, the robust approach improves the results over a deterministic approach
with nominal point forecasts by finding a trade-off between conservative and
risk-seeking policies. The case study uses the photovoltaic generation
monitored on-site at the University of Li\`ege (ULi\`ege), Belgium.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiplierless MP-Kernel Machine For Energy-efficient Edge Devices. (arXiv:2106.01958v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01958">
<div class="article-summary-box-inner">
<span><p>We present a novel framework for designing multiplierless kernel machines
that can be used on resource-constrained platforms like intelligent edge
devices. The framework uses a piecewise linear (PWL) approximation based on a
margin propagation (MP) technique and uses only addition/subtraction, shift,
comparison, and register underflow/overflow operations. We propose a
hardware-friendly MP-based inference and online training algorithm that has
been optimized for a Field Programmable Gate Array (FPGA) platform. Our FPGA
implementation eliminates the need for DSP units and reduces the number of
LUTs. By reusing the same hardware for inference and training, we show that the
platform can overcome classification errors and local minima artifacts that
result from the MP approximation. Using the FPGA platform, we also show that
the proposed multiplierless MP-kernel machine demonstrates superior performance
in terms of power, performance, and area compared to other comparable
implementations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Node Classification Meets Link Prediction on Knowledge Graphs. (arXiv:2106.07297v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07297">
<div class="article-summary-box-inner">
<span><p>Node classification and link prediction are widely studied in graph
representation learning. While both transductive node classification and link
prediction operate over a single input graph, they have so far been studied
separately. Node classification models take an input graph with node features
and incomplete node labels, and implicitly assume that the graph is
relationally complete, i.e., no edges are missing. By contrast, link prediction
models are solely motivated by relational incompleteness of the input graphs,
and do not typically leverage node features or classes. We propose a unifying
perspective and study the problems of (i) transductive node classification over
incomplete graphs and (ii) link prediction over graphs with node features,
introduce a new dataset for this setting, WikiAlumni, and conduct an extensive
benchmarking study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hi-Phy: A Benchmark for Hierarchical Physical Reasoning. (arXiv:2106.09692v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09692">
<div class="article-summary-box-inner">
<span><p>Reasoning about the behaviour of physical objects is a key capability of
agents operating in physical worlds. Humans are very experienced in physical
reasoning while it remains a major challenge for AI. To facilitate research
addressing this problem, several benchmarks have been proposed recently.
However, these benchmarks do not enable us to measure an agent's granular
physical reasoning capabilities when solving a complex reasoning task. In this
paper, we propose a new benchmark for physical reasoning that allows us to test
individual physical reasoning capabilities. Inspired by how humans acquire
these capabilities, we propose a general hierarchy of physical reasoning
capabilities with increasing complexity. Our benchmark tests capabilities
according to this hierarchy through generated physical reasoning tasks in the
video game Angry Birds. This benchmark enables us to conduct a comprehensive
agent evaluation by measuring the agent's granular physical reasoning
capabilities. We conduct an evaluation with human players, learning agents, and
heuristic agents and determine their capabilities. Our evaluation shows that
learning agents, with good local generalization ability, still struggle to
learn the underlying physical reasoning capabilities and perform worse than
current state-of-the-art heuristic agents and humans. We believe that this
benchmark will encourage researchers to develop intelligent agents with
advanced, human-like physical reasoning capabilities. URL:
https://github.com/Cheng-Xue/Hi-Phy
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RadGraph: Extracting Clinical Entities and Relations from Radiology Reports. (arXiv:2106.14463v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14463">
<div class="article-summary-box-inner">
<span><p>Extracting structured clinical information from free-text radiology reports
can enable the use of radiology report information for a variety of critical
healthcare applications. In our work, we present RadGraph, a dataset of
entities and relations in full-text chest X-ray radiology reports based on a
novel information extraction schema we designed to structure radiology reports.
We release a development dataset, which contains board-certified radiologist
annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579
entities and 10,889 relations), and a test dataset, which contains two
independent sets of board-certified radiologist annotations for 100 radiology
reports split equally across the MIMIC-CXR and CheXpert datasets. Using these
datasets, we train and test a deep learning model, RadGraph Benchmark, that
achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR
and CheXpert test sets respectively. Additionally, we release an inference
dataset, which contains annotations automatically generated by RadGraph
Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4
million relations) and 500 CheXpert reports (13,783 entities and 9,908
relations) with mappings to associated chest radiographs. Our freely available
dataset can facilitate a wide range of research in medical natural language
processing, as well as computer vision and multi-modal learning when linked to
chest radiographs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Crowdsourcing Evaluation of Saliency-based XAI Methods. (arXiv:2107.00456v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00456">
<div class="article-summary-box-inner">
<span><p>Understanding the reasons behind the predictions made by deep neural networks
is critical for gaining human trust in many important applications, which is
reflected in the increasing demand for explainability in AI (XAI) in recent
years. Saliency-based feature attribution methods, which highlight important
parts of images that contribute to decisions by classifiers, are often used as
XAI methods, especially in the field of computer vision. In order to compare
various saliency-based XAI methods quantitatively, several approaches for
automated evaluation schemes have been proposed; however, there is no guarantee
that such automated evaluation metrics correctly evaluate explainability, and a
high rating by an automated evaluation scheme does not necessarily mean a high
explainability for humans. In this study, instead of the automated evaluation,
we propose a new human-based evaluation scheme using crowdsourcing to evaluate
XAI methods. Our method is inspired by a human computation game, "Peek-a-boom",
and can efficiently compare different XAI methods by exploiting the power of
crowds. We evaluate the saliency maps of various XAI methods on two datasets
with automated and crowd-based evaluation schemes. Our experiments show that
the result of our crowd-based evaluation scheme is different from those of
automated evaluation schemes. In addition, we regard the crowd-based evaluation
results as ground truths and provide a quantitative performance measure to
compare different automated evaluation schemes. We also discuss the impact of
crowd workers on the results and show that the varying ability of crowd workers
does not significantly impact the results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Approximate Search for Sets of Vectors. (arXiv:2107.06817v2 [cs.DS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06817">
<div class="article-summary-box-inner">
<span><p>We consider a similarity measure between two sets $A$ and $B$ of vectors,
that balances the average and maximum cosine distance between pairs of vectors,
one from set $A$ and one from set $B$. As a motivation for this measure, we
present lineage tracking in a database. To practically realize this measure, we
need an approximate search algorithm that given a set of vectors $A$ and sets
of vectors $B_1,...,B_n$, the algorithm quickly locates the set $B_i$ that
maximizes the similarity measure. For the case where all sets are singleton
sets, essentially each is a single vector, there are known efficient
approximate search algorithms, e.g., approximated versions of tree search
algorithms, locality-sensitive hashing (LSH), vector quantization (VQ) and
proximity graph algorithms. In this work, we present approximate search
algorithms for the general case. The underlying idea in these algorithms is
encoding a set of vectors via a "long" single vector. The proposed approximate
approach achieves significant performance gains over an optimized, exact search
on vector sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bi-Bimodal Modality Fusion for Correlation-Controlled Multimodal Sentiment Analysis. (arXiv:2107.13669v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13669">
<div class="article-summary-box-inner">
<span><p>Multimodal sentiment analysis aims to extract and integrate semantic
information collected from multiple modalities to recognize the expressed
emotions and sentiment in multimodal data. This research area's major concern
lies in developing an extraordinary fusion scheme that can extract and
integrate key information from various modalities. However, one issue that may
restrict previous work to achieve a higher level is the lack of proper modeling
for the dynamics of the competition between the independence and relevance
among modalities, which could deteriorate fusion outcomes by causing the
collapse of modality-specific feature space or introducing extra noise. To
mitigate this, we propose the Bi-Bimodal Fusion Network (BBFN), a novel
end-to-end network that performs fusion (relevance increment) and separation
(difference increment) on pairwise modality representations. The two parts are
trained simultaneously such that the combat between them is simulated. The
model takes two bimodal pairs as input due to the known information imbalance
among modalities. In addition, we leverage a gated control mechanism in the
Transformer architecture to further improve the final output. Experimental
results on three datasets (CMU-MOSI, CMU-MOSEI, and UR-FUNNY) verifies that our
model significantly outperforms the SOTA. The implementation of this work is
available at https://github.com/declare-lab/multimodal-deep-learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ManiSkill: Generalizable Manipulation Skill Benchmark with Large-Scale Demonstrations. (arXiv:2107.14483v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14483">
<div class="article-summary-box-inner">
<span><p>Object manipulation from 3D visual inputs poses many challenges on building
generalizable perception and policy models. However, 3D assets in existing
benchmarks mostly lack the diversity of 3D shapes that align with real-world
intra-class complexity in topology and geometry. Here we propose SAPIEN
Manipulation Skill Benchmark (ManiSkill) to benchmark manipulation skills over
diverse objects in a full-physics simulator. 3D assets in ManiSkill include
large intra-class topological and geometric variations. Tasks are carefully
chosen to cover distinct types of manipulation challenges. Latest progress in
3D vision also makes us believe that we should customize the benchmark so that
the challenge is inviting to researchers working on 3D deep learning. To this
end, we simulate a moving panoramic camera that returns ego-centric point
clouds or RGB-D images. In addition, we would like ManiSkill to serve a broad
set of researchers interested in manipulation research. Besides supporting the
learning of policies from interactions, we also support
learning-from-demonstrations (LfD) methods, by providing a large number of
high-quality demonstrations (~36,000 successful trajectories, ~1.5M point
cloud/RGB-D frames in total). We provide baselines using 3D deep learning and
LfD algorithms. All code of our benchmark (simulator, environment, SDK, and
baselines) is open-sourced, and a challenge facing interdisciplinary
researchers will be held based on the benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Driven VRP: A Neural Network Model to Learn Hidden Preferences for VRP. (arXiv:2108.04578v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04578">
<div class="article-summary-box-inner">
<span><p>The traditional Capacitated Vehicle Routing Problem (CVRP) minimizes the
total distance of the routes under the capacity constraints of the vehicles.
But more often, the objective involves multiple criteria including not only the
total distance of the tour but also other factors such as travel costs, travel
time, and fuel consumption.Moreover, in reality, there are numerous implicit
preferences ingrained in the minds of the route planners and the drivers.
Drivers, for instance, have familiarity with certain neighborhoods and
knowledge of the state of roads, and often consider the best places for rest
and lunch breaks. This knowledge is difficult to formulate and balance when
operational routing decisions have to be made. This motivates us to learn the
implicit preferences from past solutions and to incorporate these learned
preferences in the optimization process. These preferences are in the form of
arc probabilities, i.e., the more preferred a route is, the higher is the joint
probability. The novelty of this work is the use of a neural network model to
estimate the arc probabilities, which allows for additional features and
automatic parameter estimation. This first requires identifying suitable
features, neural architectures and loss functions, taking into account that
there is typically few data available. We investigate the difference with a
prior weighted Markov counting approach, and study the applicability of neural
networks in this setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep adversarial attack on target detection systems. (arXiv:2108.05948v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05948">
<div class="article-summary-box-inner">
<span><p>Target detection systems identify targets by localizing their coordinates on
the input image of interest. This is ideally achieved by labeling each pixel in
an image as a background or a potential target pixel. Deep Convolutional Neural
Network (DCNN) classifiers have proven to be successful tools for computer
vision applications. However,prior research confirms that even state of the art
classifier models are susceptible to adversarial attacks. In this paper, we
show how to generate adversarial infrared images by adding small perturbations
to the targets region to deceive a DCNN-based target detector at remarkable
levels. We demonstrate significant progress in developing visually
imperceptible adversarial infrared images where the targets are visually
recognizable by an expert but a DCNN-based target detector cannot detect the
targets in the image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reinforcement Learning for Robot Navigation with Adaptive ExecutionDuration (AED) in a Semi-Markov Model. (arXiv:2108.06161v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06161">
<div class="article-summary-box-inner">
<span><p>Deep reinforcement learning (DRL) algorithms have proven effective in robot
navigation, especially in unknown environments, through directly mapping
perception inputs into robot control commands. Most existing methods adopt
uniform execution duration with robots taking commands at fixed intervals. As
such, the length of execution duration becomes a crucial parameter to the
navigation algorithm. In particular, if the duration is too short, then the
navigation policy would be executed at a high frequency, with increased
training difficulty and high computational cost. Meanwhile, if the duration is
too long, then the policy becomes unable to handle complex situations, like
those with crowded obstacles. It is thus tricky to find the "sweet" duration
range; some duration values may render a DRL model to fail to find a navigation
path. In this paper, we propose to employ adaptive execution duration to
overcome this problem. Specifically, we formulate the navigation task as a
Semi-Markov Decision Process (SMDP) problem to handle adaptive execution
duration. We also improve the distributed proximal policy optimization (DPPO)
algorithm and provide its theoretical guarantee for the specified SMDP problem.
We evaluate our approach both in the simulator and on an actual robot. The
results show that our approach outperforms the other DRL-based method (with
fixed execution duration) by 10.3% in terms of the navigation success rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TFRD: A Benchmark Dataset for Research on Temperature Field Reconstruction of Heat-Source Systems. (arXiv:2108.08298v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08298">
<div class="article-summary-box-inner">
<span><p>Temperature field reconstruction of heat source systems (TFR-HSS) with
limited monitoring sensors occurred in thermal management plays an important
role in real time health detection system of electronic equipment in
engineering. However, prior methods with common interpolations usually cannot
provide accurate reconstruction performance as needed. In addition, there
exists no public dataset for widely research of reconstruction methods to
further boost the reconstruction performance and engineering applications. To
overcome this problem, this work constructs a novel dataset, namely Temperature
Field Reconstruction Dataset (TFRD), for TFR-HSS task with commonly used
methods, including the interpolation methods and the machine learning based
methods, as baselines to advance the research over temperature field
reconstruction. First, the TFR-HSS task is mathematically modelled from
real-world engineering problem and four types of numerically modellings have
been constructed to transform the problem into discrete mapping forms. Besides,
this work selects three typical reconstruction problem over heat-source systems
with different heat-source information and boundary conditions, and generate
the training and testing samples for further research. Finally, a comprehensive
review of the prior methods for TFR-HSS task as well as recent widely used deep
learning methods is given and a performance analysis of typical methods is
provided on TFRD, which can be served as the baseline results on this
benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature-weighted Stacking for Nonseasonal Time Series Forecasts: A Case Study of the COVID-19 Epidemic Curves. (arXiv:2108.08723v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08723">
<div class="article-summary-box-inner">
<span><p>We investigate ensembling techniques in forecasting and examine their
potential for use in nonseasonal time-series similar to those in the early days
of the COVID-19 pandemic. Developing improved forecast methods is essential as
they provide data-driven decisions to organisations and decision-makers during
critical phases. We propose using late data fusion, using a stacked ensemble of
two forecasting models and two meta-features that prove their predictive power
during a preliminary forecasting stage. The final ensembles include a Prophet
and long short term memory (LSTM) neural network as base models. The base
models are combined by a multilayer perceptron (MLP), taking into account
meta-features that indicate the highest correlation with each base model's
forecast accuracy. We further show that the inclusion of meta-features
generally improves the ensemble's forecast accuracy across two forecast
horizons of seven and fourteen days. This research reinforces previous work and
demonstrates the value of combining traditional statistical models with deep
learning models to produce more accurate forecast models for time-series from
different domains and seasonality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Safe Transformative AI via a Windfall Clause. (arXiv:2108.09404v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09404">
<div class="article-summary-box-inner">
<span><p>Society could soon see transformative artificial intelligence (TAI). Models
of competition for TAI show firms face strong competitive pressure to deploy
TAI systems before they are safe. This paper explores a proposed solution to
this problem, a Windfall Clause, where developers commit to donating a
significant portion of any eventual extremely large profits to good causes.
However, a key challenge for a Windfall Clause is that firms must have reason
to join one. Firms must also believe these commitments are credible. We extend
a model of TAI competition with a Windfall Clause to show how firms and
policymakers can design a Windfall Clause which overcomes these challenges.
Encouragingly, firms benefit from joining a Windfall Clause under a wide range
of scenarios. We also find that firms join the Windfall Clause more often when
the competition is more dangerous. Even when firms learn each other's
capabilities, firms rarely wish to withdraw their support for the Windfall
Clause. These three findings strengthen the case for using a Windfall Clause to
promote the safe development of TAI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MS-DARTS: Mean-Shift Based Differentiable Architecture Search. (arXiv:2108.09996v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09996">
<div class="article-summary-box-inner">
<span><p>Differentiable Architecture Search (DARTS) is an effective continuous
relaxation-based network architecture search (NAS) method with low search cost.
It has attracted significant attentions in Auto-ML research and becomes one of
the most useful paradigms in NAS. Although DARTS can produce superior
efficiency over traditional NAS approaches with better control of complex
parameters, oftentimes it suffers from stabilization issues in producing
deteriorating architectures when discretizing the continuous architecture. We
observed considerable loss of validity causing dramatic decline in performance
at this final discretization step of DARTS. To address this issue, we propose a
Mean-Shift based DARTS (MS-DARTS) to improve stability based on sampling and
perturbation. Our approach can improve bot the stability and accuracy of DARTS,
by smoothing the loss landscape and sampling architecture parameters within a
suitable bandwidth. We investigate the convergence of our mean-shift approach,
together with the effects of bandwidth selection that affects stability and
accuracy. Evaluations performed on CIFAR-10, CIFAR-100, and ImageNet show that
MS-DARTS archives higher performance over other state-of-the-art NAS methods
with reduced search cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Social Norm Bias: Residual Harms of Fairness-Aware Algorithms. (arXiv:2108.11056v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11056">
<div class="article-summary-box-inner">
<span><p>Many modern learning algorithms mitigate bias by enforcing fairness across
coarsely-defined groups related to a sensitive attribute like gender or race.
However, the same algorithms seldom account for the within-group biases that
arise due to the heterogeneity of group members. In this work, we characterize
Social Norm Bias (SNoB), a subtle but consequential type of discrimination that
may be exhibited by automated decision-making systems, even when these systems
achieve group fairness objectives. We study this issue through the lens of
gender bias in occupation classification from biographies. We quantify SNoB by
measuring how an algorithm's predictions are associated with conformity to
gender norms, which is measured using a machine learning approach. This
framework reveals that for classification tasks related to male-dominated
occupations, fairness-aware classifiers favor biographies written in ways that
align with masculine gender norms. We compare SNoB across fairness intervention
techniques and show that post-processing interventions do not mitigate this
type of bias at all.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MCML: A Novel Memory-based Contrastive Meta-Learning Method for Few Shot Slot Tagging. (arXiv:2108.11635v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11635">
<div class="article-summary-box-inner">
<span><p>Meta-learning is widely used for few-shot slot tagging in the task of
few-shot learning. The performance of existing methods is, however, seriously
affected by catastrophic forgetting. This phenomenon is common in deep learning
as the training and testing modules fail to take into account historical
information, i.e. previously trained episodes in the metric-based
meta-learning. To overcome this predicament, we propose the Memory-based
Contrastive Meta-learning (MCML) method. Specifically, we propose a
learn-from-memory mechanism that use explicit memory to keep track of the label
representations of previously trained episodes and propose a contrastive
learning method to compare the current label embedded in the few shot episode
with the historic ones stored in the memory, and an adaption-from memory
mechanism to determine the output label based on the contrast between the input
labels embedded in the test episode and the label clusters in the memory.
Experimental results show that MCML is scalable and outperforms metric-based
meta-learning and optimization-based meta-learning on all 1shot, 5-shot,
10-shot, and 20-shot scenarios of the SNIPS dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cleaning Inconsistent Data in Temporal DL-Lite Under Best Repair Semantics. (arXiv:2108.12149v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12149">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the problem of handling inconsistent data in
Temporal Description Logic (TDL) knowledge bases. Considering the data part of
the Knowledge Base as the source of inconsistency over time, we propose an ABox
repair approach. This is the first work handling the repair in TDL Knowledge
bases. To do so, our goal is twofold: 1) detect temporal inconsistencies and 2)
propose a data temporal reparation. For the inconsistency detection, we propose
a reduction approach from TDL to DL which allows to provide a tight NP-complete
upper bound for TDL concept satisfiability and to use highly optimised DL
reasoners that can bring precise explanation (the set of inconsistent data
assertions). Thereafter, from the obtained explanation, we propose a method for
automatically computing the best repair in the temporal setting based on the
allowed rigid predicates and the time order of assertions.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">From Pivots to Graphs: Augmented CycleDensity as a Generalization to One Time InverseConsultation. (arXiv:2108.12459v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12459">
<div class="article-summary-box-inner">
<span><p>This paper describes an approach used to generate new translations using raw
bilingual dictionaries as part of the 4th Task Inference Across Dictionaries
(TIAD 2021) shared task. We propose Augmented Cycle Density (ACD) as a
framework that combines insights from two state of the art methods that require
no sense information and parallel corpora: Cycle Density (CD) and One Time
Inverse Consultation (OTIC). The task results show that across 3 unseen
language pairs, ACD's predictions, has more than double (74%) the coverage of
OTIC at almost the same precision (76%). ACD combines CD's scalability -
leveraging rich multilingual graphs for better predictions, and OTIC's data
efficiency - producing good results with the minimum possible resource of one
pivot language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Text Evaluation through the Lens of Wasserstein Barycenters. (arXiv:2108.12463v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12463">
<div class="article-summary-box-inner">
<span><p>A new metric \texttt{BaryScore} to evaluate text generation based on deep
contextualized embeddings (\textit{e.g.}, BERT, Roberta, ELMo) is introduced.
This metric is motivated by a new framework relying on optimal transport tools,
\textit{i.e.}, Wasserstein distance and barycenter. By modelling the layer
output of deep contextualized embeddings as a probability distribution rather
than by a vector embedding; this framework provides a natural way to aggregate
the different outputs through the Wasserstein space topology. In addition, it
provides theoretical grounds to our metric and offers an alternative to
available solutions (\textit{e.g.}, MoverScore and BertScore). Numerical
evaluation is performed on four different tasks: machine translation,
summarization, data2text generation and image captioning. Our results show that
\texttt{BaryScore} outperforms other BERT based metrics and exhibits more
consistent behaviour in particular for text summarization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Code-switched inspired losses for generic spoken dialog representations. (arXiv:2108.12465v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12465">
<div class="article-summary-box-inner">
<span><p>Spoken dialog systems need to be able to handle both multiple languages and
multilinguality inside a conversation (\textit{e.g} in case of code-switching).
In this work, we introduce new pretraining losses tailored to learn
multilingual spoken dialog representations. The goal of these losses is to
expose the model to code-switched language. To scale up training, we
automatically build a pretraining corpus composed of multilingual conversations
in five different languages (French, Italian, English, German and Spanish) from
\texttt{OpenSubtitles}, a huge multilingual corpus composed of 24.3G tokens. We
test the generic representations on \texttt{MIAM}, a new benchmark composed of
five dialog act corpora on the same aforementioned languages as well as on two
novel multilingual downstream tasks (\textit{i.e} multilingual mask utterance
retrieval and multilingual inconsistency identification). Our experiments show
that our new code switched-inspired losses achieve a better performance in both
monolingual and multilingual settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReGen: Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Models. (arXiv:2108.12472v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12472">
<div class="article-summary-box-inner">
<span><p>Automatic construction of relevant Knowledge Bases (KBs) from text, and
generation of semantically meaningful text from KBs are both long-standing
goals in Machine Learning. In this paper, we present ReGen, a bidirectional
generation of text and graph leveraging Reinforcement Learning (RL) to improve
performance. Graph linearization enables us to re-frame both tasks as a
sequence to sequence generation problem regardless of the generative direction,
which in turn allows the use of Reinforcement Learning for sequence training
where the model itself is employed as its own critic leading to Self-Critical
Sequence Training (SCST). We present an extensive investigation demonstrating
that the use of RL via SCST benefits graph and text generation on WebNLG+ 2020
and TekGen datasets. Our system provides state-of-the-art results on WebNLG+
2020 by significantly improving upon published results from the WebNLG 2020+
Challenge for both text-to-graph and graph-to-text generation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Opinions are Made to be Changed: Temporally Adaptive Stance Classification. (arXiv:2108.12476v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12476">
<div class="article-summary-box-inner">
<span><p>Given the rapidly evolving nature of social media and people's views, word
usage changes over time. Consequently, the performance of a classifier trained
on old textual data can drop dramatically when tested on newer data. While
research in stance classification has advanced in recent years, no effort has
been invested in making these classifiers have persistent performance over
time. To study this phenomenon we introduce two novel large-scale, longitudinal
stance datasets. We then evaluate the performance persistence of stance
classifiers over time and demonstrate how it decays as the temporal gap between
training and testing data increases. We propose a novel approach to mitigate
this performance drop, which is based on temporal adaptation of the word
embeddings used for training the stance classifier. This enables us to make use
of readily available unlabelled data from the current time period instead of
expensive annotation efforts. We propose and compare several approaches to
embedding adaptation and find that the Incremental Temporal Alignment (ITA)
model leads to the best results in reducing performance drop over time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Table-to-Text Generation with Prototype Memory. (arXiv:2108.12516v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12516">
<div class="article-summary-box-inner">
<span><p>Neural table-to-text generation models have achieved remarkable progress on
an array of tasks. However, due to the data-hungry nature of neural models,
their performances strongly rely on large-scale training examples, limiting
their applicability in real-world applications. To address this, we propose a
new framework: Prototype-to-Generate (P2G), for table-to-text generation under
the few-shot scenario. The proposed framework utilizes the retrieved
prototypes, which are jointly selected by an IR system and a novel prototype
selector to help the model bridging the structural gap between tables and
texts. Experimental results on three benchmark datasets with three
state-of-the-art models demonstrate that the proposed framework significantly
improves the model performance across various evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting the Factuality of Reporting of News Media Using Observations About User Attention in Their YouTube Channels. (arXiv:2108.12519v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12519">
<div class="article-summary-box-inner">
<span><p>We propose a novel framework for predicting the factuality of reporting of
news media outlets by studying the user attention cycles in their YouTube
channels. In particular, we design a rich set of features derived from the
temporal evolution of the number of views, likes, dislikes, and comments for a
video, which we then aggregate to the channel level. We develop and release a
dataset for the task, containing observations of user attention on YouTube
channels for 489 news media. Our experiments demonstrate both complementarity
and sizable improvements over state-of-the-art textual representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TweetBLM: A Hate Speech Dataset and Analysis of Black Lives Matter-related Microblogs on Twitter. (arXiv:2108.12521v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12521">
<div class="article-summary-box-inner">
<span><p>In the past few years, there has been a significant rise in toxic and hateful
content on various social media platforms. Recently Black Lives Matter movement
came into the picture, causing an avalanche of user generated responses on the
internet. In this paper, we have proposed a Black Lives Matter related tweet
hate speech dataset TweetBLM. Our dataset comprises 9165 manually annotated
tweets that target the Black Lives Matter movement. We annotated the tweets
into two classes, i.e., HATE and NONHATE based on their content related to
racism erupted from the movement for the black community. In this work, we also
generated useful statistical insights on our dataset and performed a systematic
analysis of various machine learning models such as Random Forest, CNN, LSTM,
BiLSTM, Fasttext, BERTbase, and BERTlarge for the classification task on our
dataset. Through our work, we aim at contributing to the substantial efforts of
the research community for the identification and mitigation of hate speech on
the internet. The dataset is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Energy-Based Approximate Inference Networks for Structured Applications in NLP. (arXiv:2108.12522v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12522">
<div class="article-summary-box-inner">
<span><p>Structured prediction in natural language processing (NLP) has a long
history. The complex models of structured application come at the difficulty of
learning and inference. These difficulties lead researchers to focus more on
models with simple structure components (e.g., local classifier). Deep
representation learning has become increasingly popular in recent years. The
structure components of their method, on the other hand, are usually relatively
simple. We concentrate on complex structured models in this dissertation. We
provide a learning framework for complicated structured models as well as an
inference method with a better speed/accuracy/search error trade-off. The
dissertation begins with a general introduction to energy-based models. In NLP
and other applications, an energy function is comparable to the concept of a
scoring function. In this dissertation, we discuss the concept of the energy
function and structured models with different energy functions. Then, we
propose a method in which we train a neural network to do argmax inference
under a structured energy function, referring to the trained networks as
"inference networks" or "energy-based inference networks". We then develop ways
of jointly learning energy functions and inference networks using an
adversarial learning framework. Despite the inference and learning difficulties
of energy-based models, we present approaches in this thesis that enable
energy-based models more easily to be applied in structured NLP applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Representations and Phoneme Classification for Preserving the Endangered Language of Ladin. (arXiv:2108.12531v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12531">
<div class="article-summary-box-inner">
<span><p>A vast majority of the world's 7,000 spoken languages are predicted to become
extinct within this century, including the endangered language of Ladin from
the Italian Alps. Linguists who work to preserve a language's phonetic and
phonological structure can spend hours transcribing each minute of speech from
native speakers. To address this problem in the context of Ladin, our paper
presents the first analysis of speech representations and machine learning
models for classifying 32 phonemes of Ladin. We experimented with a novel
dataset of the Fascian dialect of Ladin, collected from native speakers in
Italy. We created frame-level and segment-level speech feature extraction
approaches and conducted extensive experiments with 8 different classifiers
trained on 9 different speech representations. Our speech representations
ranged from traditional features (MFCC, LPC) to features learned with deep
neural network models (autoencoders, LSTM autoencoders, and WaveNet). Our
highest-performing classifier, trained on MFCC representations of speech
signals, achieved an 86% average accuracy across all Ladin phonemes. We also
obtained average accuracies above 77% for all Ladin phoneme subgroups examined.
Our findings contribute insights for learning discriminative Ladin phoneme
representations and demonstrate the potential for leveraging machine learning
and speech signal processing to preserve Ladin and other endangered languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QACE: Asking Questions to Evaluate an Image Caption. (arXiv:2108.12560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12560">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose QACE, a new metric based on Question Answering for
Caption Evaluation. QACE generates questions on the evaluated caption and
checks its content by asking the questions on either the reference caption or
the source image. We first develop QACE-Ref that compares the answers of the
evaluated caption to its reference, and report competitive results with the
state-of-the-art metrics. To go further, we propose QACE-Img, which asks the
questions directly on the image, instead of reference. A Visual-QA system is
necessary for QACE-Img. Unfortunately, the standard VQA models are framed as a
classification among only a few thousand categories. Instead, we propose
Visual-T5, an abstractive VQA system. The resulting metric, QACE-Img is
multi-modal, reference-less, and explainable. Our experiments show that
QACE-Img compares favorably w.r.t. other reference-less metrics. We will
release the pre-trained models to compute QACE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Goal-driven text descriptions for images. (arXiv:2108.12575v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12575">
<div class="article-summary-box-inner">
<span><p>A big part of achieving Artificial General Intelligence(AGI) is to build a
machine that can see and listen like humans. Much work has focused on designing
models for image classification, video classification, object detection, pose
estimation, speech recognition, etc., and has achieved significant progress in
recent years thanks to deep learning. However, understanding the world is not
enough. An AI agent also needs to know how to talk, especially how to
communicate with a human. While perception (vision, for example) is more common
across animal species, the use of complicated language is unique to humans and
is one of the most important aspects of intelligence.
</p>
<p>In this thesis, we focus on generating textual output given visual input. In
Chapter 3, we focus on generating the referring expression, a text description
for an object in the image so that a receiver can infer which object is being
described. We use a comprehension machine to directly guide the generated
referring expressions to be more discriminative. In Chapter 4, we introduce a
method that encourages discriminability in image caption generation. We show
that more discriminative captioning models generate more descriptive captions.
In Chapter 5, we study how training objectives and sampling methods affect the
models' ability to generate diverse captions. We find that a popular captioning
training strategy will be detrimental to the diversity of generated captions.
In Chapter 6, we propose a model that can control the length of generated
captions. By changing the desired length, one can influence the style and
descriptiveness of the captions. Finally, in Chapter 7, we rank/generate
informative image tags according to their information utility. The proposed
method better matches what humans think are the most important tags for the
images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling the Knowledge of Large-scale Generative Models into Retrieval Models for Efficient Open-domain Conversation. (arXiv:2108.12582v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12582">
<div class="article-summary-box-inner">
<span><p>Despite the remarkable performance of large-scale generative models in
open-domain conversation, they are known to be less practical for building
real-time conversation systems due to high latency. On the other hand,
retrieval models could return responses with much lower latency but show
inferior performance to the large-scale generative models since the
conversation quality is bounded by the pre-defined response set. To take
advantage of both approaches, we propose a new training method called G2R
(Generative-to-Retrieval distillation) that preserves the efficiency of a
retrieval model while leveraging the conversational ability of a large-scale
generative model by infusing the knowledge of the generative model into the
retrieval model. G2R consists of two distinct techniques of distillation: the
data-level G2R augments the dialogue dataset with additional responses
generated by the large-scale generative model, and the model-level G2R
transfers the response quality score assessed by the generative model to the
score of the retrieval model by the knowledge distillation loss. Through
extensive experiments including human evaluation, we demonstrate that our
retrieval-based conversation system trained with G2R shows a substantially
improved performance compared to the baseline retrieval model while showing
significantly lower inference latency than the large-scale generative models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-training Improves Pre-training for Few-shot Learning in Task-oriented Dialog Systems. (arXiv:2108.12589v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12589">
<div class="article-summary-box-inner">
<span><p>As the labeling cost for different modules in task-oriented dialog (ToD)
systems is expensive, a major challenge is to train different modules with the
least amount of labeled data. Recently, large-scale pre-trained language
models, have shown promising results for few-shot learning in ToD. In this
paper, we devise a self-training approach to utilize the abundant unlabeled
dialog data to further improve state-of-the-art pre-trained models in few-shot
learning scenarios for ToD systems. Specifically, we propose a self-training
approach that iteratively labels the most confident unlabeled data to train a
stronger Student model. Moreover, a new text augmentation technique (GradAug)
is proposed to better train the Student by replacing non-crucial tokens using a
masked language model. We conduct extensive experiments and present analyses on
four downstream tasks in ToD, including intent classification, dialog state
tracking, dialog act prediction, and response selection. Empirical results
demonstrate that the proposed self-training approach consistently improves
state-of-the-art pre-trained models (BERT, ToD-BERT) when only a small number
of labeled data are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layer-wise Model Pruning based on Mutual Information. (arXiv:2108.12594v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12594">
<div class="article-summary-box-inner">
<span><p>The proposed pruning strategy offers merits over weight-based pruning
techniques: (1) it avoids irregular memory access since representations and
matrices can be squeezed into their smaller but dense counterparts, leading to
greater speedup; (2) in a manner of top-down pruning, the proposed method
operates from a more global perspective based on training signals in the top
layer, and prunes each layer by propagating the effect of global signals
through layers, leading to better performances at the same sparsity level.
Extensive experiments show that at the same sparsity level, the proposed
strategy offers both greater speedup and higher performances than weight-based
pruning methods (e.g., magnitude pruning, movement pruning).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smoothing Dialogue States for Open Conversational Machine Reading. (arXiv:2108.12599v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12599">
<div class="article-summary-box-inner">
<span><p>Conversational machine reading (CMR) requires machines to communicate with
humans through multi-turn interactions between two salient dialogue states of
decision making and question generation processes. In open CMR settings, as the
more realistic scenario, the retrieved background knowledge would be noisy,
which results in severe challenges in the information transmission. Existing
studies commonly train independent or pipeline systems for the two subtasks.
However, those methods are trivial by using hard-label decisions to activate
question generation, which eventually hinders the model performance. In this
work, we propose an effective gating strategy by smoothing the two dialogue
states in only one decoder and bridge decision making and question generation
to provide a richer dialogue state reference. Experiments on the OR-ShARC
dataset show the effectiveness of our method, which achieves new
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigation of Diachronic Bias in Fake News Detection Dataset. (arXiv:2108.12601v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12601">
<div class="article-summary-box-inner">
<span><p>Fake news causes significant damage to society.To deal with these fake news,
several studies on building detection models and arranging datasets have been
conducted. Most of the fake news datasets depend on a specific time period.
Consequently, the detection models trained on such a dataset have difficulty
detecting novel fake news generated by political changes and social changes;
they may possibly result in biased output from the input, including specific
person names and organizational names. We refer to this problem as
\textbf{Diachronic Bias} because it is caused by the creation date of news in
each dataset. In this study, we confirm the bias, especially proper nouns
including person names, from the deviation of phrase appearances in each
dataset. Based on these findings, we propose masking methods using Wikidata to
mitigate the influence of person names and validate whether they make fake news
detection models robust through experiments with in-domain and out-of-domain
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WALNUT: A Benchmark on Weakly Supervised Learning for Natural Language Understanding. (arXiv:2108.12603v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12603">
<div class="article-summary-box-inner">
<span><p>Building quality machine learning models for natural language understanding
(NLU) tasks relies heavily on labeled data. Weak supervision has been shown to
provide valuable supervision when large amount of labeled data is unavailable
or expensive to obtain. Existing works studying weak supervision for NLU either
mostly focus on a specific task or simulate weak supervision signals from
ground-truth labels. To date a benchmark for NLU with real world weak
supervision signals for a collection of NLU tasks is still not available. In
this paper, we propose such a benchmark, named WALNUT, to advocate and
facilitate research on weak supervision for NLU. WALNUT consists of NLU tasks
with different types, including both document-level prediction tasks and
token-level prediction tasks and for each task contains weak labels generated
by multiple real-world weak sources. We conduct baseline evaluations on the
benchmark to systematically test the value of weak supervision for NLU tasks,
with various weak supervision methods and model architectures. We demonstrate
the benefits of weak supervision for low-resource NLU tasks and expect WALNUT
to stimulate further research on methodologies to best leverage weak
supervision. The benchmark and code for baselines will be publicly available at
aka.ms/walnut_benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HeadlineCause: A Dataset of News Headlines for Detecting Casualties. (arXiv:2108.12626v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12626">
<div class="article-summary-box-inner">
<span><p>Detecting implicit causal relations in texts is a task that requires both
common sense and world knowledge. Existing datasets are focused either on
commonsense causal reasoning or explicit causal relations. In this work, we
present HeadlineCause, a dataset for detecting implicit causal relations
between pairs of news headlines. The dataset includes over 5000 headline pairs
from English news and over 9000 headline pairs from Russian news labeled
through crowdsourcing. The pairs vary from totally unrelated or belonging to
the same general topic to the ones including causation and refutation
relations. We also present a set of models and experiments that demonstrates
the dataset validity, including a multilingual XLM-RoBERTa based model for
causality detection and a GPT-2 based model for possible effects prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Oh My Mistake!: Toward Realistic Dialogue State Tracking including Turnback Utterances. (arXiv:2108.12637v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12637">
<div class="article-summary-box-inner">
<span><p>The primary purpose of dialogue state tracking (DST), a critical component of
an end-to-end conversational system, is to build a model that responds well to
real-world situations. Although we often change our minds during ordinary
conversations, current benchmark datasets do not adequately reflect such
occurrences and instead consist of over-simplified conversations, in which no
one changes their mind during a conversation. As the main question inspiring
the present study,``Are current benchmark datasets sufficiently diverse to
handle casual conversations in which one changes their mind?'' We found that
the answer is ``No'' because simply injecting template-based turnback
utterances significantly degrades the DST model performance. The test joint
goal accuracy on the MultiWOZ decreased by over 5\%p when the simplest form of
turnback utterance was injected. Moreover, the performance degeneration worsens
when facing more complicated turnback situations. However, we also observed
that the performance rebounds when a turnback is appropriately included in the
training dataset, implying that the problem is not with the DST models but
rather with the construction of the benchmark dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event Extraction as Natural Language Generation. (arXiv:2108.12724v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12724">
<div class="article-summary-box-inner">
<span><p>Event extraction (EE), the task that identifies event triggers and their
arguments in text, is usually formulated as a classification or structured
prediction problem. Such models usually reduce labels to numeric identifiers,
making them unable to take advantage of label semantics (e.g. an event type
named Arrest is related to words like arrest, detain, or apprehend). This
prevents the generalization to new event types. In this work, we formulate EE
as a natural language generation task and propose GenEE, a model that not only
captures complex dependencies within an event but also generalizes well to
unseen or rare event types. Given a passage and an event type, GenEE is trained
to generate a natural sentence following a predefined template for that event
type. The generated output is then decoded into trigger and argument
predictions. The autoregressive generation process naturally models the
dependencies among the predictions -- each new word predicted depends on those
already generated in the output sentence. Using carefully designed input
prompts during generation, GenEE is able to capture label semantics, which
enables the generalization to new event types. Empirical results show that our
model achieves strong performance on event extraction tasks under all
zero-shot, few-shot, and high-resource scenarios. Especially, in the
high-resource setting, GenEE outperforms the state-of-the-art model on argument
extraction and gets competitive results with the current best on end-to-end EE
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$k$Folden: $k$-Fold Ensemble for Out-Of-Distribution Detection. (arXiv:2108.12731v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12731">
<div class="article-summary-box-inner">
<span><p>Out-of-Distribution (OOD) detection is an important problem in natural
language processing (NLP). In this work, we propose a simple yet effective
framework $k$Folden, which mimics the behaviors of OOD detection during
training without the use of any external data. For a task with $k$ training
labels, $k$Folden induces $k$ sub-models, each of which is trained on a subset
with $k-1$ categories with the left category masked unknown to the sub-model.
Exposing an unknown label to the sub-model during training, the model is
encouraged to learn to equally attribute the probability to the seen $k-1$
labels for the unknown label, enabling this framework to simultaneously resolve
in- and out-distribution examples in a natural way via OOD simulations. Taking
text classification as an archetype, we develop benchmarks for OOD detection
using existing text classification datasets. By conducting comprehensive
comparisons and analyses on the developed benchmarks, we demonstrate the
superiority of $k$Folden against current methods in terms of improving OOD
detection performances while maintaining improved in-domain classification
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SummerTime: Text Summarization Toolkit for Non-experts. (arXiv:2108.12738v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12738">
<div class="article-summary-box-inner">
<span><p>Recent advances in summarization provide models that can generate summaries
of higher quality. Such models now exist for a number of summarization tasks,
including query-based summarization, dialogue summarization, and multi-document
summarization. While such models and tasks are rapidly growing in the research
field, it has also become challenging for non-experts to keep track of them. To
make summarization methods more accessible to a wider audience, we develop
SummerTime by rethinking the summarization task from the perspective of an NLP
non-expert. SummerTime is a complete toolkit for text summarization, including
various models, datasets and evaluation metrics, for a full spectrum of
summarization-related tasks. SummerTime integrates with libraries designed for
NLP researchers, and enables users with easy-to-use APIs. With SummerTime,
users can locate pipeline solutions and search for the best model with their
own data, and visualize the differences, all with a few lines of code. We also
provide explanations for models and evaluation metrics to help users understand
the model behaviors and select models that best suit their needs. Our library,
along with a notebook demo, is available at
https://github.com/Yale-LILY/SummerTime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence Structure and Word Relationship Modeling for Emphasis Selection. (arXiv:2108.12750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12750">
<div class="article-summary-box-inner">
<span><p>Emphasis Selection is a newly proposed task which focuses on choosing words
for emphasis in short sentences. Traditional methods only consider the sequence
information of a sentence while ignoring the rich sentence structure and word
relationship information. In this paper, we propose a new framework that
considers sentence structure via a sentence structure graph and word
relationship via a word similarity graph. The sentence structure graph is
derived from the parse tree of a sentence. The word similarity graph allows
nodes to share information with their neighbors since we argue that in emphasis
selection, similar words are more likely to be emphasized together. Graph
neural networks are employed to learn the representation of each node of these
two graphs. Experimental results demonstrate that our framework can achieve
superior performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution. (arXiv:2108.12777v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12777">
<div class="article-summary-box-inner">
<span><p>Recent studies have shown that deep neural networks are vulnerable to
intentionally crafted adversarial examples, and various methods have been
proposed to defend against adversarial word-substitution attacks for neural NLP
models. However, there is a lack of systematic study on comparing different
defense approaches under the same attacking setting. In this paper, we seek to
fill the gap of systematic studies through comprehensive researches on
understanding the behavior of neural text classifiers trained by various
defense methods under representative adversarial attacks. In addition, we
propose an effective method to further improve the robustness of neural text
classifiers against such attacks and achieved the highest accuracy on both
clean and adversarial examples on AGNEWS and IMDB datasets by a significant
margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable Propaganda Detection in News Articles. (arXiv:2108.12802v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12802">
<div class="article-summary-box-inner">
<span><p>Online users today are exposed to misleading and propagandistic news articles
and media posts on a daily basis. To counter thus, a number of approaches have
been designed aiming to achieve a healthier and safer online news and media
consumption. Automatic systems are able to support humans in detecting such
content; yet, a major impediment to their broad adoption is that besides being
accurate, the decisions of such systems need also to be interpretable in order
to be trusted and widely adopted by users. Since misleading and propagandistic
content influences readers through the use of a number of deception techniques,
we propose to detect and to show the use of such techniques as a way to offer
interpretability. In particular, we define qualitatively descriptive features
and we analyze their suitability for detecting deception techniques. We further
show that our interpretable features can be easily combined with pre-trained
language models, yielding state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DropAttack: A Masked Weight Adversarial Training Method to Improve Generalization of Neural Networks. (arXiv:2108.12805v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12805">
<div class="article-summary-box-inner">
<span><p>Adversarial training has been proven to be a powerful regularization method
to improve the generalization of models. However, current adversarial training
methods only attack the original input sample or the embedding vectors, and
their attacks lack coverage and diversity. To further enhance the breadth and
depth of attack, we propose a novel masked weight adversarial training method
called DropAttack, which enhances generalization of model by adding
intentionally worst-case adversarial perturbations to both the input and hidden
layers in different dimensions and minimize the adversarial risks generated by
each layer. DropAttack is a general technique and can be adopt to a wide
variety of neural networks with different architectures. To validate the
effectiveness of the proposed method, we used five public datasets in the
fields of natural language processing (NLP) and computer vision (CV) for
experimental evaluating. We compare the proposed method with other adversarial
training methods and regularization methods, and our method achieves
state-of-the-art on all datasets. In addition, Dropattack can achieve the same
performance when it use only a half training data compared to other standard
training method. Theoretical analysis reveals that DropAttack can perform
gradient regularization at random on some of the input and wight parameters of
the model. Further visualization experiments show that DropAttack can push the
minimum risk of the model to a lower and flatter loss landscapes. Our source
code is publicly available on https://github.com/nishiwen1214/DropAttack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing and Mitigating Interference in Neural Architecture Search. (arXiv:2108.12821v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12821">
<div class="article-summary-box-inner">
<span><p>Weight sharing has become the \textit{de facto} approach to reduce the
training cost of neural architecture search (NAS) by reusing the weights of
shared operators from previously trained child models. However, the estimated
accuracy of those child models has a low rank correlation with the ground truth
accuracy due to the interference among different child models caused by weight
sharing. In this paper, we investigate the interference issue by sampling
different child models and calculating the gradient similarity of shared
operators, and observe that: 1) the interference on a shared operator between
two child models is positively correlated to the number of different operators
between them; 2) the interference is smaller when the inputs and outputs of the
shared operator are more similar. Inspired by these two observations, we
propose two approaches to mitigate the interference: 1) rather than randomly
sampling child models for optimization, we propose a gradual modification
scheme by modifying one operator between adjacent optimization steps to
minimize the interference on the shared operators; 2) forcing the inputs and
outputs of the operator across all child models to be similar to reduce the
interference. Experiments on a BERT search space verify that mitigating
interference via each of our proposed methods improves the rank correlation of
super-pet and combining both methods can achieve better results. Our searched
architecture outperforms RoBERTa$_{\rm base}$ by 1.1 and 0.6 scores and
ELECTRA$_{\rm base}$ by 1.6 and 1.1 scores on the dev and test set of GLUE
benchmark. Extensive results on the BERT compression task, SQuAD datasets and
other search spaces also demonstrate the effectiveness and generality of our
proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extractive and Abstractive Sentence Labelling of Sentiment-bearing Topics. (arXiv:2108.12822v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12822">
<div class="article-summary-box-inner">
<span><p>This paper tackles the problem of automatically labelling sentiment-bearing
topics with descriptive sentence labels. We propose two approaches to the
problem, one extractive and the other abstractive. Both approaches rely on a
novel mechanism to automatically learn the relevance of each sentence in a
corpus to sentiment-bearing topics extracted from that corpus. The extractive
approach uses a sentence ranking algorithm for label selection which for the
first time jointly optimises topic--sentence relevance as well as
aspect--sentiment co-coverage. The abstractive approach instead addresses
aspect--sentiment co-coverage by using sentence fusion to generate a sentential
label that includes relevant content from multiple sentences. To our knowledge,
we are the first to study the problem of labelling sentiment-bearing topics.
Our experimental results on three real-world datasets show that both the
extractive and abstractive approaches outperform four strong baselines in terms
of facilitating topic understanding and interpretation. In addition, when
comparing extractive and abstractive labels, our evaluation shows that our best
performing abstractive method is able to provide more topic information
coverage in fewer words, at the cost of generating less grammatical labels than
the extractive method. We conclude that abstractive methods can effectively
synthesise the rich information contained in sentiment-bearing topics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Behind the Scenes: An Exploration of Trigger Biases Problem in Few-Shot Event Classification. (arXiv:2108.12844v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12844">
<div class="article-summary-box-inner">
<span><p>Few-Shot Event Classification (FSEC) aims at developing a model for event
prediction, which can generalize to new event types with a limited number of
annotated data. Existing FSEC studies have achieved high accuracy on different
benchmarks. However, we find they suffer from trigger biases that signify the
statistical homogeneity between some trigger words and target event types,
which we summarize as trigger overlapping and trigger separability. The biases
can result in context-bypassing problem, i.e., correct classifications can be
gained by looking at only the trigger words while ignoring the entire context.
Therefore, existing models can be weak in generalizing to unseen data in real
scenarios. To further uncover the trigger biases and assess the generalization
ability of the models, we propose two new sampling methods, Trigger-Uniform
Sampling (TUS) and COnfusion Sampling (COS), for the meta tasks construction
during evaluation. Besides, to cope with the context-bypassing problem in FSEC
models, we introduce adversarial training and trigger reconstruction
techniques. Experiments show these techniques help not only improve the
performance, but also enhance the generalization ability of models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Span Fine-tuning for Pre-trained Language Models. (arXiv:2108.12848v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12848">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PrLM) have to carefully manage input units when
training on a very large text with a vocabulary consisting of millions of
words. Previous works have shown that incorporating span-level information over
consecutive words in pre-training could further improve the performance of
PrLMs. However, given that span-level clues are introduced and fixed in
pre-training, previous methods are time-consuming and lack of flexibility. To
alleviate the inconvenience, this paper presents a novel span fine-tuning
method for PrLMs, which facilitates the span setting to be adaptively
determined by specific downstream tasks during the fine-tuning phase. In
detail, any sentences processed by the PrLM will be segmented into multiple
spans according to a pre-sampled dictionary. Then the segmentation information
will be sent through a hierarchical CNN module together with the representation
outputs of the PrLM and ultimately generate a span-enhanced representation.
Experiments on GLUE benchmark show that the proposed span fine-tuning method
significantly enhances the PrLM, and at the same time, offer more flexibility
in an efficient way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiplex Graph Neural Network for Extractive Text Summarization. (arXiv:2108.12870v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12870">
<div class="article-summary-box-inner">
<span><p>Extractive text summarization aims at extracting the most representative
sentences from a given document as its summary. To extract a good summary from
a long text document, sentence embedding plays an important role. Recent
studies have leveraged graph neural networks to capture the inter-sentential
relationship (e.g., the discourse graph) to learn contextual sentence
embedding. However, those approaches neither consider multiple types of
inter-sentential relationships (e.g., semantic similarity &amp; natural
connection), nor model intra-sentential relationships (e.g, semantic &amp;
syntactic relationship among words). To address these problems, we propose a
novel Multiplex Graph Convolutional Network (Multi-GCN) to jointly model
different types of relationships among sentences and words. Based on Multi-GCN,
we propose a Multiplex Graph Summarization (Multi-GraS) model for extractive
text summarization. Finally, we evaluate the proposed models on the
CNN/DailyMail benchmark dataset to demonstrate the effectiveness and
superiority of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigations on Speech Recognition Systems for Low-Resource Dialectal Arabic-English Code-Switching Speech. (arXiv:2108.12881v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12881">
<div class="article-summary-box-inner">
<span><p>Code-switching (CS), defined as the mixing of languages in conversations, has
become a worldwide phenomenon. The prevalence of CS has been recently met with
a growing demand and interest to build CS ASR systems. In this paper, we
present our work on code-switched Egyptian Arabic-English automatic speech
recognition (ASR). We first contribute in filling the huge gap in resources by
collecting, analyzing and publishing our spontaneous CS Egyptian Arabic-English
speech corpus. We build our ASR systems using DNN-based hybrid and
Transformer-based end-to-end models. In this paper, we present a thorough
comparison between both approaches under the setting of a low-resource,
orthographically unstandardized, and morphologically rich language pair. We
show that while both systems give comparable overall recognition results, each
system provides complementary sets of strength points. We show that recognition
can be improved by combining the outputs of both systems. We propose several
effective system combination approaches, where hypotheses of both systems are
merged on sentence- and word-levels. Our approaches result in overall WER
relative improvement of 4.7%, over a baseline performance of 32.1% WER. In the
case of intra-sentential CS sentences, we achieve WER relative improvement of
4.8%. Our best performing system achieves 30.6% WER on ArzEn test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Answer Candidates for Quizzes and Answer-Aware Question Generators. (arXiv:2108.12898v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12898">
<div class="article-summary-box-inner">
<span><p>In education, open-ended quiz questions have become an important tool for
assessing the knowledge of students. Yet, manually preparing such questions is
a tedious task, and thus automatic question generation has been proposed as a
possible alternative. So far, the vast majority of research has focused on
generating the question text, relying on question answering datasets with
readily picked answers, and the problem of how to come up with answer
candidates in the first place has been largely ignored. Here, we aim to bridge
this gap. In particular, we propose a model that can generate a specified
number of answer candidates for a given passage of text, which can then be used
by instructors to write questions manually or can be passed as an input to
automatic answer-aware question generators. Our experiments show that our
proposed answer candidate generation model outperforms several baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-Grained Chemical Entity Typing with Multimodal Knowledge Representation. (arXiv:2108.12899v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12899">
<div class="article-summary-box-inner">
<span><p>Automated knowledge discovery from trending chemical literature is essential
for more efficient biomedical research. How to extract detailed knowledge about
chemical reactions from the core chemistry literature is a new emerging
challenge that has not been well studied. In this paper, we study the new
problem of fine-grained chemical entity typing, which poses interesting new
challenges especially because of the complex name mentions frequently occurring
in chemistry literature and graphic representation of entities. We introduce a
new benchmark data set (CHEMET) to facilitate the study of the new task and
propose a novel multi-modal representation learning framework to solve the
problem of fine-grained chemical entity typing by leveraging external resources
with chemical structures and using cross-modal attention to learn effective
representation of text in the chemistry domain. Experiment results show that
the proposed framework outperforms multiple state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mischievous Nominal Constructions in Universal Dependencies. (arXiv:2108.12928v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12928">
<div class="article-summary-box-inner">
<span><p>While the highly multilingual Universal Dependencies (UD) project provides
extensive guidelines for clausal structure as well as structure within
canonical nominal phrases, a standard treatment is lacking for many
"mischievous" nominal phenomena that break the mold. As a result, numerous
inconsistencies within and across corpora can be found, even in languages with
extensive UD treebanking work, such as English. This paper surveys the kinds of
mischievous nominal expressions attested in English UD corpora and proposes
solutions primarily with English in mind, but which may offer paths to
solutions for a variety of UD languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RetroGAN: A Cyclic Post-Specialization System for Improving Out-of-Knowledge and Rare Word Representations. (arXiv:2108.12941v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12941">
<div class="article-summary-box-inner">
<span><p>Retrofitting is a technique used to move word vectors closer together or
further apart in their space to reflect their relationships in a Knowledge Base
(KB). However, retrofitting only works on concepts that are present in that KB.
RetroGAN uses a pair of Generative Adversarial Networks (GANs) to learn a
one-to-one mapping between concepts and their retrofitted counterparts. It
applies that mapping (post-specializes) to handle concepts that do not appear
in the original KB in a manner similar to how some natural language systems
handle out-of-vocabulary entries. We test our system on three word-similarity
benchmarks and a downstream sentence simplification task and achieve the state
of the art (CARD-660). Altogether, our results demonstrate our system's
effectiveness for out-of-knowledge and rare word generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Selective Differential Privacy for Language Modeling. (arXiv:2108.12944v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12944">
<div class="article-summary-box-inner">
<span><p>With the increasing adoption of language models in applications involving
sensitive data, it has become crucial to protect these models from leaking
private information. Previous work has attempted to tackle this challenge by
training RNN-based language models with differential privacy guarantees.
However, applying classical differential privacy to language models leads to
poor model performance as the underlying privacy notion is over-pessimistic and
provides undifferentiated protection for all tokens of the data. Given that the
private information in natural language is sparse (for example, the bulk of an
email might not carry personally identifiable information), we propose a new
privacy notion, selective differential privacy, to provide rigorous privacy
guarantees on the sensitive portion of the data to improve model utility. To
realize such a new notion, we develop a corresponding privacy mechanism,
Selective-DPSGD, for RNN-based language models. Besides language modeling, we
also apply the method to a more concrete application -- dialog systems.
Experiments on both language modeling and dialog system building show that the
proposed privacy-preserving mechanism achieves better utilities while remaining
safe under various privacy attacks compared to the baselines. The data, code
and models are available at https://github.com/wyshi/lm_privacy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LOT: A Benchmark for Evaluating Chinese Long Text Understanding and Generation. (arXiv:2108.12960v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12960">
<div class="article-summary-box-inner">
<span><p>Standard multi-task benchmarks are essential for driving the progress of
general pretraining models to generalize to various downstream tasks. However,
existing benchmarks such as GLUE and GLGE tend to focus on short text
understanding and generation tasks, without considering long text modeling,
which requires many distinct capabilities such as modeling long-range
commonsense and discourse relations, as well as the coherence and
controllability of generation. The lack of standardized benchmarks makes it
difficult to fully evaluate these capabilities of a model and fairly compare
different models, especially Chinese pretraining models. Therefore, we propose
LOT, a benchmark including two understanding and two generation tasks for
Chinese long text modeling evaluation. We construct the datasets for the tasks
based on various kinds of human-written Chinese stories. Besides, we release an
encoder-decoder Chinese long text pretraining model named LongLM with up to 1
billion parameters. We pretrain LongLM on 120G Chinese novels with two
generative tasks including text infilling and conditional continuation.
Extensive experiments on LOT demonstrate that LongLM matches the performance of
similar-sized pretraining models on the understanding tasks and outperforms
strong baselines substantially on the generation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scheduled Sampling Based on Decoding Steps for Neural Machine Translation. (arXiv:2108.12963v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12963">
<div class="article-summary-box-inner">
<span><p>Scheduled sampling is widely used to mitigate the exposure bias problem for
neural machine translation. Its core motivation is to simulate the inference
scene during training by replacing ground-truth tokens with predicted tokens,
thus bridging the gap between training and inference. However, vanilla
scheduled sampling is merely based on training steps and equally treats all
decoding steps. Namely, it simulates an inference scene with uniform error
rates, which disobeys the real inference scene, where larger decoding steps
usually have higher error rates due to error accumulations. To alleviate the
above discrepancy, we propose scheduled sampling methods based on decoding
steps, increasing the selection chance of predicted tokens with the growth of
decoding steps. Consequently, we can more realistically simulate the inference
scene during training, thus better bridging the gap between training and
inference. Moreover, we investigate scheduled sampling based on both training
steps and decoding steps for further improvements. Experimentally, our
approaches significantly outperform the Transformer baseline and vanilla
scheduled sampling on three large-scale WMT tasks. Additionally, our approaches
also generalize well to the text summarization task on two popular benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HELMHOLTZ: A Verifier for Tezos Smart Contracts Based on Refinement Types. (arXiv:2108.12971v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12971">
<div class="article-summary-box-inner">
<span><p>A smart contract is a program executed on a blockchain, based on which many
cryptocurrencies are implemented, and is being used for automating
transactions. Due to the large amount of money that smart contracts deal with,
there is a surging demand for a method that can statically and formally verify
them.
</p>
<p>This article describes our type-based static verification tool HELMHOLTZ for
Michelson, which is a statically typed stack-based language for writing smart
contracts that are executed on the blockchain platform Tezos. HELMHOLTZ is
designed on top of our extension of Michelson's type system with refinement
types. HELMHOLTZ takes a Michelson program annotated with a user-defined
specification written in the form of a refinement type as input; it then
typechecks the program against the specification based on the refinement type
system, discharging the generated verification conditions with the SMT solver
Z3. We briefly introduce our refinement type system for the core calculus
Mini-Michelson of Michelson, which incorporates the characteristic features
such as compound datatypes (e.g., lists and pairs), higher-order functions, and
invocation of another contract. \HELMHOLTZ{} successfully verifies several
practical Michelson programs, including one that transfers money to an account
and that checks a digital signature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shatter: An Efficient Transformer Encoder with Single-Headed Self-Attention and Relative Sequence Partitioning. (arXiv:2108.13032v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13032">
<div class="article-summary-box-inner">
<span><p>The highly popular Transformer architecture, based on self-attention, is the
foundation of large pretrained models such as BERT, that have become an
enduring paradigm in NLP. While powerful, the computational resources and time
required to pretrain such models can be prohibitive. In this work, we present
an alternative self-attention architecture, Shatter, that more efficiently
encodes sequence information by softly partitioning the space of relative
positions and applying different value matrices to different parts of the
sequence. This mechanism further allows us to simplify the multi-headed
attention in Transformer to single-headed. We conduct extensive experiments
showing that Shatter achieves better performance than BERT, with pretraining
being faster per step (15% on TPU), converging in fewer steps, and offering
considerable memory savings (&gt;50%). Put together, Shatter can be pretrained on
8 V100 GPUs in 7 days, and match the performance of BERT_Base -- making the
cost of pretraining much more affordable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASR-GLUE: A New Multi-task Benchmark for ASR-Robust Natural Language Understanding. (arXiv:2108.13048v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13048">
<div class="article-summary-box-inner">
<span><p>Language understanding in speech-based systems have attracted much attention
in recent years with the growing demand for voice interface applications.
However, the robustness of natural language understanding (NLU) systems to
errors introduced by automatic speech recognition (ASR) is under-examined. %To
facilitate the research on ASR-robust general language understanding, In this
paper, we propose ASR-GLUE benchmark, a new collection of 6 different NLU tasks
for evaluating the performance of models under ASR error across 3 different
levels of background noise and 6 speakers with various voice characteristics.
Based on the proposed benchmark, we systematically investigate the effect of
ASR error on NLU tasks in terms of noise intensity, error type and speaker
variants. We further purpose two ways, correction-based method and data
augmentation-based method to improve robustness of the NLU systems. Extensive
experimental results and analysises show that the proposed methods are
effective to some extent, but still far from human performance, demonstrating
that NLU under ASR error is still very challenging and requires further
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Base Completion Meets Transfer Learning. (arXiv:2108.13073v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13073">
<div class="article-summary-box-inner">
<span><p>The aim of knowledge base completion is to predict unseen facts from existing
facts in knowledge bases. In this work, we introduce the first approach for
transfer of knowledge from one collection of facts to another without the need
for entity or relation matching. The method works for both canonicalized
knowledge bases and uncanonicalized or open knowledge bases, i.e., knowledge
bases where more than one copy of a real-world entity or relation may exist.
Such knowledge bases are a natural output of automated information extraction
tools that extract structured data from unstructured text. Our main
contribution is a method that can make use of a large-scale pre-training on
facts, collected from unstructured text, to improve predictions on structured
data from a specific domain. The introduced method is the most impactful on
small datasets such as ReVerb20K, where we obtained 6% absolute increase of
mean reciprocal rank and 65% relative decrease of mean rank over the previously
best method, despite not relying on large pre-trained models like BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NEREL: A Russian Dataset with Nested Named Entities and Relations. (arXiv:2108.13112v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13112">
<div class="article-summary-box-inner">
<span><p>In this paper, we present NEREL, a Russian dataset for named entity
recognition and relation extraction. NEREL is significantly larger than
existing Russian datasets: to date it contains 56K annotated named entities and
39K annotated relations. Its important difference from previous datasets is
annotation of nested named entities, as well as relations within nested
entities and at the discourse level. NEREL can facilitate development of novel
models that can extract relations between nested named entities, as well as
relations on both sentence and document levels. NEREL also contains the
annotation of events involving named entities and their roles in the events.
The NEREL collection is available via https://github.com/nerel-ds/NEREL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factual Consistency Evaluation for Text Summarization via Counterfactual Estimation. (arXiv:2108.13134v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13134">
<div class="article-summary-box-inner">
<span><p>Despite significant progress has been achieved in text summarization, factual
inconsistency in generated summaries still severely limits its practical
applications. Among the key factors to ensure factual consistency, a reliable
automatic evaluation metric is the first and the most crucial one. However,
existing metrics either neglect the intrinsic cause of the factual
inconsistency or rely on auxiliary tasks, leading to an unsatisfied correlation
with human judgments or increasing the inconvenience of usage in practice. In
light of these challenges, we propose a novel metric to evaluate the factual
consistency in text summarization via counterfactual estimation, which
formulates the causal relationship among the source document, the generated
summary, and the language prior. We remove the effect of language prior, which
can cause factual inconsistency, from the total causal effect on the generated
summary, and provides a simple yet effective way to evaluate consistency
without relying on other auxiliary tasks. We conduct a series of experiments on
three public abstractive text summarization datasets, and demonstrate the
advantages of the proposed metric in both improving the correlation with human
judgments and the convenience of usage. The source code is available at
https://github.com/xieyxclack/factual_coco.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neuron-level Interpretation of Deep NLP Models: A Survey. (arXiv:2108.13138v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13138">
<div class="article-summary-box-inner">
<span><p>The proliferation of deep neural networks in various domains has seen an
increased need for interpretability of these methods. A plethora of research
has been carried out to analyze and understand components of the deep neural
network models. Preliminary work done along these lines and papers that
surveyed such, were focused on a more high-level representation analysis.
However, a recent branch of work has concentrated on interpretability at a more
granular level, analyzing neurons and groups of neurons in these large models.
In this paper, we survey work done on fine-grained neuron analysis including:
i) methods developed to discover and understand neurons in a network, ii) their
limitations and evaluation, iii) major findings including cross architectural
comparison that such analyses unravel and iv) direct applications of neuron
analysis such as model behavior control and domain adaptation along with
potential directions for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CSDS: A Fine-grained Chinese Dataset for Customer Service Dialogue Summarization. (arXiv:2108.13139v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13139">
<div class="article-summary-box-inner">
<span><p>Dialogue summarization has drawn much attention recently. Especially in the
customer service domain, agents could use dialogue summaries to help boost
their works by quickly knowing customers' issues and service progress. These
applications require summaries to contain the perspective of a single speaker
and have a clear topic flow structure. Neither are available in existing
datasets. Therefore, in this paper, we introduce a novel Chinese dataset for
Customer Service Dialogue Summarization (CSDS). CSDS improves the abstractive
summaries in two aspects: (1) In addition to the overall summary for the whole
dialogue, role-oriented summaries are also provided to acquire different
speakers' viewpoints. (2) All the summaries sum up each topic separately, thus
containing the topic-level structure of the dialogue. We define tasks in CSDS
as generating the overall summary and different role-oriented summaries for a
given dialogue. Next, we compare various summarization methods on CSDS, and
experiment results show that existing methods are prone to generate redundant
and incoherent summaries. Besides, the performance becomes much worse when
analyzing the performance on role-oriented summaries and topic structures. We
hope that this study could benchmark Chinese dialogue summarization and benefit
further studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Sentiment Analysis Dataset for Trustworthiness Evaluation. (arXiv:2108.13140v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13140">
<div class="article-summary-box-inner">
<span><p>While deep learning models have greatly improved the performance of most
artificial intelligence tasks, they are often criticized to be untrustworthy
due to the black-box problem. Consequently, many works have been proposed to
study the trustworthiness of deep learning. However, as most open datasets are
designed for evaluating the accuracy of model outputs, there is still a lack of
appropriate datasets for evaluating the inner workings of neural networks. The
lack of datasets obviously hinders the development of trustworthiness research.
Therefore, in order to systematically evaluate the factors for building
trustworthy systems, we propose a novel and well-annotated sentiment analysis
dataset to evaluate robustness and interpretability. To evaluate these factors,
our dataset contains diverse annotations about the challenging distribution of
instances, manual adversarial instances and sentiment explanations. Several
evaluation metrics are further proposed for interpretability and robustness.
Based on the dataset and metrics, we conduct comprehensive comparisons for the
trustworthiness of three typical models, and also study the relations between
accuracy, robustness and interpretability. We release this trustworthiness
evaluation dataset at \url{https://github/xyz} and hope our work can facilitate
the progress on building more trustworthy systems for real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners. (arXiv:2108.13161v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13161">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models have contributed significantly to
natural language processing by demonstrating remarkable abilities as few-shot
learners. However, their effectiveness depends mainly on scaling the model
parameters and prompt design, hindering their implementation in most real-world
applications. This study proposes a novel pluggable, extensible, and efficient
approach named DifferentiAble pRompT (DART), which can convert small language
models into better few-shot learners without any prompt engineering. The main
principle behind this approach involves reformulating potential natural
language processing tasks into the task of a pre-trained language model and
differentially optimizing the prompt template as well as the target label with
backpropagation. Furthermore, the proposed approach can be: (i) Plugged to any
pre-trained language models; (ii) Extended to widespread classification tasks.
A comprehensive evaluation of standard NLP tasks demonstrates that the proposed
approach achieves a better few-shot performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exposure Bias versus Self-Recovery: Are Distortions Really Incremental for Autoregressive Text Generation?. (arXiv:1905.10617v9 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10617">
<div class="article-summary-box-inner">
<span><p>Exposure bias has been regarded as a central problem for auto-regressive
language models (LM). It claims that teacher forcing would cause the test-time
generation to be incrementally distorted due to the training-generation
discrepancy. Although a lot of algorithms have been proposed to avoid teacher
forcing and therefore alleviate exposure bias, there is little work showing how
serious the exposure bias problem actually is. In this work, we focus on the
task of open-ended language generation, propose metrics to quantify the impact
of exposure bias in the aspects of quality, diversity, and consistency. Our key
intuition is that if we feed ground-truth data prefixes (instead of prefixes
generated by the model itself) into the model and ask it to continue the
generation, the performance should become much better because the
training-generation discrepancy in the prefix is removed. Both automatic and
human evaluations are conducted in our experiments. On the contrary to the
popular belief in exposure bias, we find that the the distortion induced by the
prefix discrepancy is limited, and does not seem to be incremental during the
generation. Moreover, our analysis reveals an interesting self-recovery ability
of the LM, which we hypothesize to be countering the harmful effects from
exposure bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Keeping it simple: Implementation and performance of the proto-principle of adaptation and learning in the language sciences. (arXiv:2003.03813v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.03813">
<div class="article-summary-box-inner">
<span><p>In this paper we present the Widrow-Hoff rule and its applications to
language data. After contextualizing the rule historically and placing it in
the chain of neurally inspired artificial learning models, we explain its
rationale and implementational considerations. Using a number of case studies
we illustrate how the Widrow-Hoff rule offers unexpected opportunities for the
computational simulation of a range of language phenomena that make it possible
to approach old problems from a novel perspective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Learning with Common Sense Knowledge Graphs. (arXiv:2006.10713v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10713">
<div class="article-summary-box-inner">
<span><p>Zero-shot learning relies on semantic class representations such as
hand-engineered attributes or learned embeddings to predict classes without any
labeled examples. We propose to learn class representations by embedding nodes
from common sense knowledge graphs in a vector space. Common sense knowledge
graphs are an untapped source of explicit high-level knowledge that requires
little human effort to apply to a range of tasks. To capture the knowledge in
the graph, we introduce ZSL-KG, a general-purpose framework with a novel
transformer graph convolutional network (TrGCN) for generating class
representations. Our proposed TrGCN architecture computes non-linear
combinations of node neighbourhoods. Our results show that ZSL-KG improves over
existing WordNet-based methods on five out of six zero-shot benchmark datasets
in language and vision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Best-First Beam Search. (arXiv:2007.03909v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03909">
<div class="article-summary-box-inner">
<span><p>Decoding for many NLP tasks requires an effective heuristic algorithm for
approximating exact search since the problem of searching the full output space
is often intractable, or impractical in many settings. The default algorithm
for this job is beam search -- a pruned version of breadth-first search. Quite
surprisingly, beam search often returns better results than exact inference due
to beneficial search bias for NLP tasks. In this work, we show that the
standard implementation of beam search can be made up to 10x faster in
practice. Our method assumes that the scoring function is monotonic in the
sequence length, which allows us to safely prune hypotheses that cannot be in
the final set of hypotheses early on. We devise effective monotonic
approximations to popular nonmonontic scoring functions, including length
normalization and mutual information decoding. Lastly, we propose a
memory-reduced variant of Best-First Beam Search, which has a similar
beneficial search bias in terms of downstream performance, but runs in a
fraction of the time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Audiovisual Speech Synthesis using Tacotron2. (arXiv:2008.00620v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00620">
<div class="article-summary-box-inner">
<span><p>Audiovisual speech synthesis is the problem of synthesizing a talking face
while maximizing the coherency of the acoustic and visual speech. In this
paper, we propose and compare two audiovisual speech synthesis systems for 3D
face models. The first system is the AVTacotron2, which is an end-to-end
text-to-audiovisual speech synthesizer based on the Tacotron2 architecture.
AVTacotron2 converts a sequence of phonemes representing the sentence to
synthesize into a sequence of acoustic features and the corresponding
controllers of a face model. The output acoustic features are used to condition
a WaveRNN to reconstruct the speech waveform, and the output facial controllers
are used to generate the corresponding video of the talking face. The second
audiovisual speech synthesis system is modular, where acoustic speech is
synthesized from text using the traditional Tacotron2. The reconstructed
acoustic speech signal is then used to drive the facial controls of the face
model using an independently trained audio-to-facial-animation neural network.
We further condition both the end-to-end and modular approaches on emotion
embeddings that encode the required prosody to generate emotional audiovisual
speech. We analyze the performance of the two systems and compare them to the
ground truth videos using subjective evaluation tests. The end-to-end and
modular systems are able to synthesize close to human-like audiovisual speech
with mean opinion scores (MOS) of 4.1 and 3.9, respectively, compared to a MOS
of 4.1 for the ground truth generated from professionally recorded videos.
While the end-to-end system gives a better overall quality, the modular
approach is more flexible and the quality of acoustic speech and visual speech
synthesis is almost independent of each other.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rank over Class: The Untapped Potential of Ranking in Natural Language Processing. (arXiv:2009.05160v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05160">
<div class="article-summary-box-inner">
<span><p>Text classification has long been a staple within Natural Language Processing
(NLP) with applications spanning across diverse areas such as sentiment
analysis, recommender systems and spam detection. With such a powerful
solution, it is often tempting to use it as the go-to tool for all NLP problems
since when you are holding a hammer, everything looks like a nail. However, we
argue here that many tasks which are currently addressed using classification
are in fact being shoehorned into a classification mould and that if we instead
address them as a ranking problem, we not only improve the model, but we
achieve better performance. We propose a novel end- to-end ranking approach
consisting of a Transformer network responsible for producing representations
for a pair of text sequences, which are in turn passed into a context
aggregating network outputting ranking scores used to determine an ordering to
the sequences based on some notion of relevance. We perform numerous
experiments on publicly-available datasets and investigate the applications of
ranking in problems often solved using classification. In an experiment on a
heavily-skewed sentiment analysis dataset, converting ranking results to
classification labels yields an approximately 22% improvement over
state-of-the-art text classification, demonstrating the efficacy of text
ranking over text classification in certain scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weight Squeezing: Reparameterization for Knowledge Transfer and Model Compression. (arXiv:2010.06993v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06993">
<div class="article-summary-box-inner">
<span><p>In this work, we present a novel approach for simultaneous knowledge transfer
and model compression called Weight Squeezing. With this method, we perform
knowledge transfer from a teacher model by learning the mapping from its
weights to smaller student model weights.
</p>
<p>We applied Weight Squeezing to a pre-trained text classification model based
on BERT-Medium model and compared our method to various other knowledge
transfer and model compression methods on GLUE multitask benchmark. We observed
that our approach produces better results while being significantly faster than
other methods for training student models.
</p>
<p>We also proposed a variant of Weight Squeezing called Gated Weight Squeezing,
for which we combined fine-tuning of BERT-Medium model and learning mapping
from BERT-Base weights. We showed that fine-tuning with Gated Weight Squeezing
outperforms plain fine-tuning of BERT-Medium model as well as other concurrent
SoTA approaches while much being easier to implement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic-Guided Abstractive Text Summarization: a Joint Learning Approach. (arXiv:2010.10323v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10323">
<div class="article-summary-box-inner">
<span><p>We introduce a new approach for abstractive text summarization, Topic-Guided
Abstractive Summarization, which calibrates long-range dependencies from
topic-level features with globally salient content. The idea is to incorporate
neural topic modeling with a Transformer-based sequence-to-sequence (seq2seq)
model in a joint learning framework. This design can learn and preserve the
global semantics of the document, which can provide additional contextual
guidance for capturing important ideas of the document, thereby enhancing the
generation of summary. We conduct extensive experiments on two datasets and the
results show that our proposed model outperforms many extractive and
abstractive systems in terms of both ROUGE measurements and human evaluation.
Our code is available at: https://github.com/chz816/tas.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SlimIPL: Language-Model-Free Iterative Pseudo-Labeling. (arXiv:2010.11524v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11524">
<div class="article-summary-box-inner">
<span><p>Recent results in end-to-end automatic speech recognition have demonstrated
the efficacy of pseudo-labeling for semi-supervised models trained both with
Connectionist Temporal Classification (CTC) and Sequence-to-Sequence (seq2seq)
losses. Iterative Pseudo-Labeling (IPL), which continuously trains a single
model using pseudo-labels iteratively re-generated as the model learns, has
been shown to further improve performance in ASR. We improve upon the IPL
algorithm: as the model learns, we propose to iteratively re-generate
transcriptions with hard labels (the most probable tokens), that is, without a
language model. We call this approach Language-Model-Free IPL (slimIPL) and
give a resultant training setup for low-resource settings with CTC-based
models. slimIPL features a dynamic cache for pseudo-labels which reduces
sensitivity to changes in relabeling hyperparameters and results in improves
training stability. slimIPL is also highly-efficient and requires 3.5-4x fewer
computational resources to converge than other state-of-the-art
semi/self-supervised approaches. With only 10 hours of labeled audio, slimIPL
is competitive with self-supervised approaches, and is state-of-the-art with
100 hours of labeled audio without the use of a language model both at test
time and during pseudo-label generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BanglaBERT: Combating Embedding Barrier in Multilingual Models for Low-Resource Language Understanding. (arXiv:2101.00204v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00204">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce ``Embedding Barrier'', a phenomenon that limits
the monolingual performance of multilingual models on low-resource languages
having unique typologies. We build `BanglaBERT', a Bangla language model
pretrained on 18.6 GB Internet-crawled data and benchmark on five standard NLU
tasks. We discover a significant drop in the performance of the
state-of-the-art multilingual model (XLM-R) from BanglaBERT and attribute this
to the Embedding Barrier through comprehensive experiments. We identify that a
multilingual model's performance on a low-resource language is hurt when its
writing script is not similar to any of the high-resource languages. To tackle
the barrier, we propose a straightforward solution by transcribing languages to
a common script, which can effectively improve the performance of a
multilingual model for the Bangla language. As a bi-product of the standard NLU
benchmarks, we introduce a new downstream dataset on natural language inference
(NLI) and show that BanglaBERT outperforms previous state-of-the-art results on
all tasks by up to 3.5%. We are making the BanglaBERT language model and the
new Bangla NLI dataset publicly available in the hope of advancing the
community. The resources can be found at
\url{https://github.com/csebuetnlp/banglabert}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast End-to-End Speech Recognition via Non-Autoregressive Models and Cross-Modal Knowledge Transferring from BERT. (arXiv:2102.07594v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07594">
<div class="article-summary-box-inner">
<span><p>Attention-based encoder-decoder (AED) models have achieved promising
performance in speech recognition. However, because the decoder predicts text
tokens (such as characters or words) in an autoregressive manner, it is
difficult for an AED model to predict all tokens in parallel. This makes the
inference speed relatively slow. We believe that because the encoder already
captures the whole speech utterance, which has the token-level relationship
implicitly, we can predict a token without explicitly autoregressive language
modeling. When the prediction of a token does not rely on other tokens, the
parallel prediction of all tokens in the sequence is realizable. Based on this
idea, we propose a non-autoregressive speech recognition model called LASO
(Listen Attentively, and Spell Once). The model consists of an encoder, a
decoder, and a position dependent summarizer (PDS). The three modules are based
on basic attention blocks. The encoder extracts high-level representations from
the speech. The PDS uses positional encodings corresponding to tokens to
convert the acoustic representations into token-level representations. The
decoder further captures token-level relationships with the self-attention
mechanism. At last, the probability distribution on the vocabulary is computed
for each token position. Therefore, speech recognition is re-formulated as a
position-wise classification problem. Further, we propose a cross-modal
transfer learning method to refine semantics from a large-scale pre-trained
language model BERT for improving the performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A More Fine-Grained Aspect-Sentiment-Opinion Triplet Extraction Task. (arXiv:2103.15255v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15255">
<div class="article-summary-box-inner">
<span><p>Aspect Sentiment Triplet Extraction (ASTE) aims to extract aspect term,
sentiment and opinion term triplets from sentences and tries to provide a
complete solution for aspect-based sentiment analysis (ABSA). However, some
triplets extracted by ASTE are confusing, since the sentiment in a triplet
extracted by ASTE is the sentiment that the sentence expresses toward the
aspect term rather than the sentiment of the aspect term and opinion term pair.
In this paper, we introduce a more fine-grained Aspect-Sentiment-Opinion
Triplet Extraction (ASOTE) Task. ASOTE also extracts aspect term, sentiment and
opinion term triplets. However, the sentiment in a triplet extracted by ASOTE
is the sentiment of the aspect term and opinion term pair. We build four
datasets for ASOTE based on several popular ABSA benchmarks. We propose a
Position-aware BERT-based Framework (PBF) to address this task. PBF first
extracts aspect terms from sentences. For each extracted aspect term, PBF first
generates aspect term-specific sentence representations considering both the
meaning and the position of the aspect term, then extracts associated opinion
terms and predicts the sentiments of the aspect term and opinion term pairs
based on the sentence representations. Experimental results on the four
datasets show the effectiveness of PBF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting of a Patient's Condition From Clinical Narratives Using Natural Language Representation. (arXiv:2104.03969v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03969">
<div class="article-summary-box-inner">
<span><p>The rapid progress in clinical data management systems and artificial
intelligence approaches enable the era of personalized medicine. Intensive care
units (ICUs) are the ideal clinical research environment for such development
because they collect many clinical data and are highly computerized
environments. We designed a retrospective clinical study on a prospective ICU
database using clinical natural language to help in the early diagnosis of
heart failure in critically ill children. The methodology consisted of
empirical experiments of a learning algorithm to learn the hidden
interpretation and presentation of the French clinical note data. This study
included 1386 patients' clinical notes with 5444 single lines of notes. There
were 1941 positive cases (36 % of total) and 3503 negative cases classified by
two independent physicians using a standardized approach. The multilayer
perceptron neural network outperforms other discriminative and generative
classifiers. Consequently, the proposed framework yields an overall
classification performance with 89 % accuracy, 88 % recall, and 89 % precision.
This study successfully applied learning representation and machine learning
algorithms to detect heart failure from clinical natural language in a single
French institution. Further work is needed to use the same methodology in other
institutions and other languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07650">
<div class="article-summary-box-inner">
<span><p>Recently, prompt-tuning has achieved promising results on some few-shot
classification tasks. The core idea of prompt-tuning is to insert text pieces,
i.e., templates, into the input and transform a classification task into a
masked language modeling problem. However, as for relation extraction,
determining the appropriate prompt template requires domain expertise. Single
label word handcrafted or auto-searched is cumbersome and time-consuming to
verify their effectiveness in non-few-shot scenarios. Further, there exist
abundant semantic knowledge among the entities and relation labels which cannot
be ignored. To this end, we focus on incorporating knowledge into prompt-tuning
for relation extraction and propose a Knowledge-aware prompt-tuning with
synergistic optimization (KNIGHT) approach. Specifically, we inject entity and
relation knowledge into prompt construction with learnable virtual template
words and answer words and jointly optimize their representation with knowledge
constraints. Extensive experimental results on five datasets with standard and
low-resource settings demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cost-effective End-to-end Information Extraction for Semi-structured Document Images. (arXiv:2104.08041v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08041">
<div class="article-summary-box-inner">
<span><p>A real-world information extraction (IE) system for semi-structured document
images often involves a long pipeline of multiple modules, whose complexity
dramatically increases its development and maintenance cost. One can instead
consider an end-to-end model that directly maps the input to the target output
and simplify the entire process. However, such generation approach is known to
lead to unstable performance if not designed carefully. Here we present our
recent effort on transitioning from our existing pipeline-based IE system to an
end-to-end system focusing on practical challenges that are associated with
replacing and deploying the system in real, large-scale production. By
carefully formulating document IE as a sequence generation task, we show that a
single end-to-end IE system can be built and still achieve competent
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Model Evaluation Beyond Perplexity. (arXiv:2106.00085v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00085">
<div class="article-summary-box-inner">
<span><p>We propose an alternate approach to quantifying how well language models
learn natural language: we ask how well they match the statistical tendencies
of natural language. To answer this question, we analyze whether text generated
from language models exhibits the statistical tendencies present in the
human-generated text on which they were trained. We provide a framework--paired
with significance tests--for evaluating the fit of language models to these
trends. We find that neural language models appear to learn only a subset of
the tendencies considered, but align much more closely with empirical trends
than proposed theoretical distributions (when present). Further, the fit to
different distributions is highly-dependent on both model architecture and
generation strategy. As concrete examples, text generated under the nucleus
sampling scheme adheres more closely to the type--token relationship of natural
language than text produced using standard ancestral sampling; text from LSTMs
reflects the natural language distributions over length, stopwords, and symbols
surprisingly well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark. (arXiv:2106.08087v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08087">
<div class="article-summary-box-inner">
<span><p>Artificial Intelligence (AI), along with the recent progress in biomedical
language understanding, is gradually changing medical practice. With the
development of biomedical language understanding benchmarks, AI applications
are widely used in the medical field. However, most benchmarks are limited to
English, which makes it challenging to replicate many of the successes in
English for other languages. To facilitate research in this direction, we
collect real-world biomedical data and present the first Chinese Biomedical
Language Understanding Evaluation (CBLUE) benchmark: a collection of natural
language understanding tasks including named entity recognition, information
extraction, clinical diagnosis normalization, single-sentence/sentence-pair
classification, and an associated online platform for model evaluation,
comparison, and analysis. To establish evaluation on these tasks, we report
empirical results with the current 11 pre-trained Chinese models, and
experimental results show that state-of-the-art neural models perform by far
worse than the human ceiling. Our benchmark is released at
\url{https://tianchi.aliyun.com/dataset/dataDetail?dataId=95414&amp;lang=en-us}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RadGraph: Extracting Clinical Entities and Relations from Radiology Reports. (arXiv:2106.14463v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14463">
<div class="article-summary-box-inner">
<span><p>Extracting structured clinical information from free-text radiology reports
can enable the use of radiology report information for a variety of critical
healthcare applications. In our work, we present RadGraph, a dataset of
entities and relations in full-text chest X-ray radiology reports based on a
novel information extraction schema we designed to structure radiology reports.
We release a development dataset, which contains board-certified radiologist
annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579
entities and 10,889 relations), and a test dataset, which contains two
independent sets of board-certified radiologist annotations for 100 radiology
reports split equally across the MIMIC-CXR and CheXpert datasets. Using these
datasets, we train and test a deep learning model, RadGraph Benchmark, that
achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR
and CheXpert test sets respectively. Additionally, we release an inference
dataset, which contains annotations automatically generated by RadGraph
Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4
million relations) and 500 CheXpert reports (13,783 entities and 9,908
relations) with mappings to associated chest radiographs. Our freely available
dataset can facilitate a wide range of research in medical natural language
processing, as well as computer vision and multi-modal learning when linked to
chest radiographs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis. (arXiv:2107.08264v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08264">
<div class="article-summary-box-inner">
<span><p>Multimodal sentiment analysis aims to recognize people's attitudes from
multiple communication channels such as verbal content (i.e., text), voice, and
facial expressions. It has become a vibrant and important research topic in
natural language processing. Much research focuses on modeling the complex
intra- and inter-modal interactions between different communication channels.
However, current multimodal models with strong performance are often
deep-learning-based techniques and work like black boxes. It is not clear how
models utilize multimodal information for sentiment predictions. Despite recent
advances in techniques for enhancing the explainability of machine learning
models, they often target unimodal scenarios (e.g., images, sentences), and
little research has been done on explaining multimodal models. In this paper,
we present an interactive visual analytics system, M2Lens, to visualize and
explain multimodal models for sentiment analysis. M2Lens provides explanations
on intra- and inter-modal interactions at the global, subset, and local levels.
Specifically, it summarizes the influence of three typical interaction types
(i.e., dominance, complement, and conflict) on the model predictions. Moreover,
M2Lens identifies frequent and influential multimodal features and supports the
multi-faceted exploration of model behaviors from language, acoustic, and
visual modalities. Through two case studies and expert interviews, we
demonstrate our system can help users gain deep insights into the multimodal
models for sentiment analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Detection of COVID-19 Vaccine Misinformation with Graph Link Prediction. (arXiv:2108.02314v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02314">
<div class="article-summary-box-inner">
<span><p>Enormous hope in the efficacy of vaccines became recently a successful
reality in the fight against the COVID-19 pandemic. However, vaccine hesitancy,
fueled by exposure to social media misinformation about COVID-19 vaccines
became a major hurdle. Therefore, it is essential to automatically detect where
misinformation about COVID-19 vaccines on social media is spread and what kind
of misinformation is discussed, such that inoculation interventions can be
delivered at the right time and in the right place, in addition to
interventions designed to address vaccine hesitancy. This paper is addressing
the first step in tackling hesitancy against COVID-19 vaccines, namely the
automatic detection of known misinformation about the vaccines on Twitter, the
social media platform that has the highest volume of conversations about
COVID-19 and its vaccines. We present CoVaxLies, a new dataset of tweets judged
relevant to several misinformation targets about COVID-19 vaccines on which a
novel method of detecting misinformation was developed. Our method organizes
CoVaxLies in a Misinformation Knowledge Graph as it casts misinformation
detection as a graph link prediction problem. The misinformation detection
method detailed in this paper takes advantage of the link scoring functions
provided by several knowledge embedding methods. The experimental results
demonstrate the superiority of this method when compared with
classification-based methods, widely used currently.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing. (arXiv:2108.05542v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05542">
<div class="article-summary-box-inner">
<span><p>Transformer-based pretrained language models (T-PTLMs) have achieved great
success in almost every NLP task. The evolution of these models started with
GPT and BERT. These models are built on the top of transformers,
self-supervised learning and transfer learning. Transformed-based PTLMs learn
universal language representations from large volumes of text data using
self-supervised learning and transfer this knowledge to downstream tasks. These
models provide good background knowledge to downstream tasks which avoids
training of downstream models from scratch. In this comprehensive survey paper,
we initially give a brief overview of self-supervised learning. Next, we
explain various core concepts like pretraining, pretraining methods,
pretraining tasks, embeddings and downstream adaptation methods. Next, we
present a new taxonomy of T-PTLMs and then give brief overview of various
benchmarks including both intrinsic and extrinsic. We present a summary of
various useful libraries to work with T-PTLMs. Finally, we highlight some of
the future research directions which will further improve these models. We
strongly believe that this comprehensive survey paper will serve as a good
reference to learn the core concepts as well as to stay updated with the recent
happenings in T-PTLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation. (arXiv:2108.06712v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06712">
<div class="article-summary-box-inner">
<span><p>Tables are often created with hierarchies, but existing works on table
reasoning mainly focus on flat tables and neglect hierarchical tables.
Hierarchical tables challenge existing methods by hierarchical indexing, as
well as implicit relationships of calculation and semantics. This work presents
HiTab, a free and open dataset to study question answering (QA) and natural
language generation (NLG) over hierarchical tables. HiTab is a cross-domain
dataset constructed from a wealth of statistical reports (analyses) and
Wikipedia pages, and has unique characteristics: (1) nearly all tables are
hierarchical, and (2) both target sentences for NLG and questions for QA are
revised from original, meaningful, and diverse descriptive sentences authored
by analysts and professions of reports. (3) to reveal complex numerical
reasoning in statistical analyses, we provide fine-grained annotations of
entity and quantity alignment. HiTab provides 10,686 QA pairs and descriptive
sentences with well-annotated quantity and entity alignment on 3,597 tables
with broad coverage of table hierarchies and numerical reasoning types.
</p>
<p>Targeting hierarchical structure, we devise a novel hierarchy-aware logical
form for symbolic reasoning over tables, which shows high effectiveness.
Targeting complex numerical reasoning, we propose partially supervised training
given annotations of entity and quantity alignment, which helps models to
largely reduce spurious predictions in the QA task. In the NLG task, we find
that entity and quantity alignment also helps NLG models to generate better
results in a conditional generation setting. Experiment results of
state-of-the-art baselines suggest that this dataset presents a strong
challenge and a valuable benchmark for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fastformer: Additive Attention Can Be All You Need. (arXiv:2108.09084v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09084">
<div class="article-summary-box-inner">
<span><p>Transformer is a powerful model for text understanding. However, it is
inefficient due to its quadratic complexity to input sequence length. Although
there are many methods on Transformer acceleration, they are still either
inefficient on long sequences or not effective enough. In this paper, we
propose Fastformer, which is an efficient Transformer model based on additive
attention. In Fastformer, instead of modeling the pair-wise interactions
between tokens, we first use additive attention mechanism to model global
contexts, and then further transform each token representation based on its
interaction with global context representations. In this way, Fastformer can
achieve effective context modeling with linear complexity. Extensive
experiments on five datasets show that Fastformer is much more efficient than
many existing Transformer models and can meanwhile achieve comparable or even
better long text modeling performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-tuning Pretrained Language Models with Label Attention for Explainable Biomedical Text Classification. (arXiv:2108.11809v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11809">
<div class="article-summary-box-inner">
<span><p>The massive growth of digital biomedical data is making biomedical text
indexing and classification increasingly important. Accordingly, previous
research has devised numerous deep learning techniques focused on using
feedforward, convolutional or recurrent neural architectures. More recently,
fine-tuned transformers-based pretrained models (PTMs) have demonstrated
superior performance compared to such models in many natural language
processing tasks. However, the direct use of PTMs in the biomedical domain is
only limited to the target documents, ignoring the rich semantic information in
the label descriptions. In this paper, we develop an improved label
attention-based architecture to inject semantic label description into the
fine-tuning process of PTMs. Results on two public medical datasets show that
the proposed fine-tuning scheme outperforms the conventionally fine-tuned PTMs
and prior state-of-the-art models. Furthermore, we show that fine-tuning with
the label attention mechanism is interpretable in the interpretability study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12202">
<div class="article-summary-box-inner">
<span><p>In joint entity and relation extraction, existing work either sequentially
encode task-specific features, leading to an imbalance in inter-task feature
interaction where features extracted later have no direct contact with those
that come first. Or they encode entity features and relation features in a
parallel manner, meaning that feature representation learning for each task is
largely independent of each other except for input sharing. We propose a
partition filter network to model two-way interaction between tasks properly,
where feature encoding is decomposed into two steps: partition and filter. In
our encoder, we leverage two gates: entity and relation gate, to segment
neurons into two task partitions and one shared partition. The shared partition
represents inter-task information valuable to both tasks and is evenly shared
across two tasks to ensure proper two-way interaction. The task partitions
represent intra-task information and are formed through concerted efforts of
both gates, making sure that encoding of task-specific features are dependent
upon each other. Experiment results on five public datasets show that our model
performs significantly better than previous approaches. The source code can be
found in https://github.com/Coopercoppers/PFN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProtoInfoMax: Prototypical Networks with Mutual Information Maximization for Out-of-Domain Detection. (arXiv:2108.12229v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12229">
<div class="article-summary-box-inner">
<span><p>The ability to detect Out-of-Domain (OOD) inputs has been a critical
requirement in many real-world NLP applications since the inclusion of
unsupported OOD inputs may lead to catastrophic failure of systems. However, it
remains an empirical question whether current algorithms can tackle such
problem reliably in a realistic scenario where zero OOD training data is
available. In this study, we propose ProtoInfoMax, a new architecture that
extends Prototypical Networks to simultaneously process In-Domain (ID) and OOD
sentences via Mutual Information Maximization (InfoMax) objective. Experimental
results show that our proposed method can substantially improve performance up
to 20% for OOD detection in low resource settings of text classification. We
also show that ProtoInfoMax is less prone to typical over-confidence Error of
Neural Networks, leading to more reliable ID and OOD prediction outcomes.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">High Fidelity Deep Learning-based MRI Reconstruction with Instance-wise Discriminative Feature Matching Loss. (arXiv:2108.12460v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12460">
<div class="article-summary-box-inner">
<span><p>Purpose: To improve reconstruction fidelity of fine structures and textures
in deep learning (DL) based reconstructions.
</p>
<p>Methods: A novel patch-based Unsupervised Feature Loss (UFLoss) is proposed
and incorporated into the training of DL-based reconstruction frameworks in
order to preserve perceptual similarity and high-order statistics. The UFLoss
provides instance-level discrimination by mapping similar instances to similar
low-dimensional feature vectors and is trained without any human annotation. By
adding an additional loss function on the low-dimensional feature space during
training, the reconstruction frameworks from under-sampled or corrupted data
can reproduce more realistic images that are closer to the original with finer
textures, sharper edges, and improved overall image quality. The performance of
the proposed UFLoss is demonstrated on unrolled networks for accelerated 2D and
3D knee MRI reconstruction with retrospective under-sampling. Quantitative
metrics including NRMSE, SSIM, and our proposed UFLoss were used to evaluate
the performance of the proposed method and compare it with others.
</p>
<p>Results: In-vivo experiments indicate that adding the UFLoss encourages
sharper edges and more faithful contrasts compared to traditional and
learning-based methods with pure l2 loss. More detailed textures can be seen in
both 2D and 3D knee MR images. Quantitative results indicate that
reconstruction with UFLoss can provide comparable NRMSE and a higher SSIM while
achieving a much lower UFLoss value.
</p>
<p>Conclusion: We present UFLoss, a patch-based unsupervised learned feature
loss, which allows the training of DL-based reconstruction to obtain more
detailed texture, finer features, and sharper edges with higher overall image
quality under DL-based reconstruction frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Inner-Group Relations on Point Clouds. (arXiv:2108.12468v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12468">
<div class="article-summary-box-inner">
<span><p>The prevalence of relation networks in computer vision is in stark contrast
to underexplored point-based methods. In this paper, we explore the
possibilities of local relation operators and survey their feasibility. We
propose a scalable and efficient module, called group relation aggregator. The
module computes a feature of a group based on the aggregation of the features
of the inner-group points weighted by geometric relations and semantic
relations. We adopt this module to design our RPNet. We further verify the
expandability of RPNet, in terms of both depth and width, on the tasks of
classification and segmentation. Surprisingly, empirical results show that
wider RPNet fits for classification, while deeper RPNet works better on
segmentation. RPNet achieves state-of-the-art for classification and
segmentation on challenging benchmarks. We also compare our local aggregator
with PointNet++, with around 30% parameters and 50% computation saving.
Finally, we conduct experiments to reveal the robustness of RPNet with regard
to rigid transformation and noises.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VisGraphNet: a complex network interpretation of convolutional neural features. (arXiv:2108.12490v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12490">
<div class="article-summary-box-inner">
<span><p>Here we propose and investigate the use of visibility graphs to model the
feature map of a neural network. The model, initially devised for studies on
complex networks, is employed here for the classification of texture images.
The work is motivated by an alternative viewpoint provided by these graphs over
the original data. The performance of the proposed method is verified in the
classification of four benchmark databases, namely, KTHTIPS-2b, FMD, UIUC, and
UMD and in a practical problem, which is the identification of plant species
using scanned images of their leaves. Our method was competitive with other
state-of-the-art approaches, confirming the potential of techniques used for
data analysis in different contexts to give more meaningful interpretation to
the use of neural networks in texture classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fractal measures of image local features: an application to texture recognition. (arXiv:2108.12491v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12491">
<div class="article-summary-box-inner">
<span><p>Here we propose a new method for the classification of texture images
combining fractal measures (fractal dimension, multifractal spectrum and
lacunarity) with local binary patterns. More specifically we compute the box
counting dimension of the local binary codes thresholded at different levels to
compose the feature vector. The proposal is assessed in the classification of
three benchmark databases: KTHTIPS-2b, UMD and UIUC as well as in a real-world
problem, namely the identification of Brazilian plant species (database
1200Tex) using scanned images of their leaves. The proposed method demonstrated
to be competitive with other state-of-the-art solutions reported in the
literature. Such results confirmed the potential of combining a powerful local
coding description with the multiscale information captured by the fractal
dimension for texture classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the impact of using X-ray energy response imagery for object detection via Convolutional Neural Networks. (arXiv:2108.12505v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12505">
<div class="article-summary-box-inner">
<span><p>Automatic detection of prohibited items within complex and cluttered X-ray
security imagery is essential to maintaining transport security, where prior
work on automatic prohibited item detection focus primarily on pseudo-colour
(rgb}) X-ray imagery. In this work we study the impact of variant X-ray
imagery, i.e., X-ray energy response (high, low}) and effective-z compared to
rgb, via the use of deep Convolutional Neural Networks (CNN) for the joint
object detection and segmentation task posed within X-ray baggage security
screening. We evaluate state-of-the-art CNN architectures (Mask R-CNN, YOLACT,
CARAFE and Cascade Mask R-CNN) to explore the transferability of models trained
with such 'raw' variant imagery between the varying X-ray security scanners
that exhibits differing imaging geometries, image resolutions and material
colour profiles. Overall, we observe maximal detection performance using
CARAFE, attributable to training using combination of rgb, high, low, and
effective-z X-ray imagery, obtaining 0.7 mean Average Precision (mAP) for a six
class object detection problem. Our results also exhibit a remarkable degree of
generalisation capability in terms of cross-scanner transferability (AP:
0.835/0.611) for a one class object detection problem by combining rgb, high,
low, and effective-z imagery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Kidney Segmentation by Mask R-CNN in T2-weighted Magnetic Resonance Imaging. (arXiv:2108.12506v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12506">
<div class="article-summary-box-inner">
<span><p>Despite the recent advances of deep learning algorithms in medical imaging,
the automatic segmentation algorithms for kidneys in MRI exams are still
scarce. Automated segmentation of kidneys in Magnetic Resonance Imaging (MRI)
exams are important for enabling radiomics and machine learning analysis of
renal disease. In this work, we propose to use the popular Mask R-CNN for the
automatic segmentation of kidneys in coronal T2-weighted Fast Spin Eco slices
of 100 MRI exams. We propose the morphological operations as post-processing to
further improve the performance of Mask R-CNN for this task. With 5-fold
cross-validation data, the proposed Mask R-CNN is trained and validated on 70
and 10 MRI exams and then evaluated on the remaining 20 exams in each fold. Our
proposed method achieved a dice score of 0.904 and IoU of 0.822.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness Disparities in Commercial Face Detection. (arXiv:2108.12508v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12508">
<div class="article-summary-box-inner">
<span><p>Facial detection and analysis systems have been deployed by large companies
and critiqued by scholars and activists for the past decade. Critiques that
focus on system performance analyze disparity of the system's output, i.e., how
frequently is a face detected for different Fitzpatrick skin types or perceived
genders. However, we focus on the robustness of these system outputs under
noisy natural perturbations. We present the first of its kind detailed
benchmark of the robustness of three such systems: Amazon Rekognition,
Microsoft Azure, and Google Cloud Platform. We use both standard and recently
released academic facial datasets to quantitatively analyze trends in
robustness for each. Across all the datasets and systems, we generally find
that photos of individuals who are older, masculine presenting, of darker skin
type, or have dim lighting are more susceptible to errors than their
counterparts in other identities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SIGN: Spatial-information Incorporated Generative Network for Generalized Zero-shot Semantic Segmentation. (arXiv:2108.12517v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12517">
<div class="article-summary-box-inner">
<span><p>Unlike conventional zero-shot classification, zero-shot semantic segmentation
predicts a class label at the pixel level instead of the image level. When
solving zero-shot semantic segmentation problems, the need for pixel-level
prediction with surrounding context motivates us to incorporate spatial
information using positional encoding. We improve standard positional encoding
by introducing the concept of Relative Positional Encoding, which integrates
spatial information at the feature level and can handle arbitrary image sizes.
Furthermore, while self-training is widely used in zero-shot semantic
segmentation to generate pseudo-labels, we propose a new
knowledge-distillation-inspired self-training strategy, namely Annealed
Self-Training, which can automatically assign different importance to
pseudo-labels to improve performance. We systematically study the proposed
Relative Positional Encoding and Annealed Self-Training in a comprehensive
experimental evaluation, and our empirical results confirm the effectiveness of
our method on three benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining chest X-rays and EHR data using machine learning to diagnose acute respiratory failure. (arXiv:2108.12530v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12530">
<div class="article-summary-box-inner">
<span><p>When patients develop acute respiratory failure, accurately identifying the
underlying etiology is essential for determining the best treatment, but it can
be challenging to differentiate between common diagnoses in clinical practice.
Machine learning models could improve medical diagnosis by augmenting clinical
decision making and play a role in the diagnostic evaluation of patients with
acute respiratory failure. While machine learning models have been developed to
identify common findings on chest radiographs (e.g. pneumonia), augmenting
these approaches by also analyzing clinically relevant data from the electronic
health record (EHR) could aid in the diagnosis of acute respiratory failure.
Machine learning models were trained to predict the cause of acute respiratory
failure (pneumonia, heart failure, and/or COPD) using chest radiographs and EHR
data from patients within an internal cohort using diagnoses based on physician
chart review. Models were also tested on patients in an external cohort using
discharge diagnosis codes. A model combining chest radiographs and EHR data
outperformed models based on each modality alone for pneumonia and COPD. For
pneumonia, the combined model AUROC was 0.79 (0.78-0.79), image model AUROC was
0.73 (0.72-0.75), and EHR model AUROC was 0.73 (0.70-0.76); for COPD, combined:
0.89 (0.83-0.91), image: 0.85 (0.77-0.89), and EHR: 0.80 (0.76-0.84); for heart
failure, combined: 0.80 (0.77-0.84), image: 0.77 (0.71-0.81), and EHR: 0.80
(0.75-0.82). In the external cohort, performance was consistent for heart
failure and COPD, but declined slightly for pneumonia. Overall, machine
learning models combing chest radiographs and EHR data can accurately
differentiate between common causes of acute respiratory failure. Further work
is needed to determine whether these models could aid clinicians in the
diagnosis of acute respiratory failure in clinical settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image-to-Graph Convolutional Network for Deformable Shape Reconstruction from a Single Projection Image. (arXiv:2108.12533v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12533">
<div class="article-summary-box-inner">
<span><p>Shape reconstruction of deformable organs from two-dimensional X-ray images
is a key technology for image-guided intervention. In this paper, we propose an
image-to-graph convolutional network (IGCN) for deformable shape reconstruction
from a single-viewpoint projection image. The IGCN learns relationship between
shape/deformation variability and the deep image features based on a
deformation mapping scheme. In experiments targeted to the respiratory motion
of abdominal organs, we confirmed the proposed framework with a regularized
loss function can reconstruct liver shapes from a single digitally
reconstructed radiograph with a mean distance error of 3.6mm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SeeTheSeams: Localized Detection of Seam Carving based Image Forgery in Satellite Imagery. (arXiv:2108.12534v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12534">
<div class="article-summary-box-inner">
<span><p>Seam carving is a popular technique for content aware image retargeting. It
can be used to deliberately manipulate images, for example, change the GPS
locations of a building or insert/remove roads in a satellite image. This paper
proposes a novel approach for detecting and localizing seams in such images.
While there are methods to detect seam carving based manipulations, this is the
first time that robust localization and detection of seam carving forgery is
made possible. We also propose a seam localization score (SLS) metric to
evaluate the effectiveness of localization. The proposed method is evaluated
extensively on a large collection of images from different sources,
demonstrating a high level of detection and localization performance across
these datasets. The datasets curated during this work will be released to the
public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High performing ensemble of convolutional neural networks for insect pest image detection. (arXiv:2108.12539v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12539">
<div class="article-summary-box-inner">
<span><p>Pest infestation is a major cause of crop damage and lost revenues worldwide.
Automatic identification of invasive insects would greatly speedup the
identification of pests and expedite their removal. In this paper, we generate
ensembles of CNNs based on different topologies (ResNet50, GoogleNet,
ShuffleNet, MobileNetv2, and DenseNet201) altered by random selection from a
simple set of data augmentation methods or optimized with different Adam
variants for pest identification. Two new Adam algorithms for deep network
optimization based on DGrad are proposed that introduce a scaling factor in the
learning rate. Sets of the five CNNs that vary in either data augmentation or
the type of Adam optimization were trained on both the Deng (SMALL) and the
large IP102 pest data sets. Ensembles were compared and evaluated using three
performance indicators. The best performing ensemble, which combined the CNNs
using the different augmentation methods and the two new Adam variants proposed
here, achieved state of the art on both insect data sets: 95.52% on Deng and
73.46% on IP102, a score on Deng that competed with human expert
classifications. Additional tests were performed on data sets for medical
imagery classification that further validated the robustness and power of the
proposed Adam optimization variants. All MATLAB source code is available at
https://github.com/LorisNanni/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Semi-Supervised and Domain-Adaptive Semantic Segmentation with Self-Supervised Depth Estimation. (arXiv:2108.12545v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12545">
<div class="article-summary-box-inner">
<span><p>Training deep networks for semantic segmentation requires large amounts of
labeled training data, which presents a major challenge in practice, as
labeling segmentation masks is a highly labor-intensive process. To address
this issue, we present a framework for semi-supervised and domain-adaptive
semantic segmentation, which is enhanced by self-supervised monocular depth
estimation (SDE) trained only on unlabeled image sequences.
</p>
<p>In particular, we utilize SDE as an auxiliary task comprehensively across the
entire learning framework: First, we automatically select the most useful
samples to be annotated for semantic segmentation based on the correlation of
sample diversity and difficulty between SDE and semantic segmentation. Second,
we implement a strong data augmentation by mixing images and labels using the
geometry of the scene. Third, we transfer knowledge from features learned
during SDE to semantic segmentation by means of transfer and multi-task
learning. And fourth, we exploit additional labeled synthetic data with
Cross-Domain DepthMix and Matching Geometry Sampling to align synthetic and
real data.
</p>
<p>We validate the proposed model on the Cityscapes dataset, where all four
contributions demonstrate significant performance gains, and achieve
state-of-the-art results for semi-supervised semantic segmentation as well as
for semi-supervised domain adaptation. In particular, with only 1/30 of the
Cityscapes labels, our method achieves 92% of the fully-supervised baseline
performance and even 97% when exploiting additional data from GTA. The source
code is available at
https://github.com/lhoyer/improving_segmentation_with_selfsupervised_depth.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QACE: Asking Questions to Evaluate an Image Caption. (arXiv:2108.12560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12560">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose QACE, a new metric based on Question Answering for
Caption Evaluation. QACE generates questions on the evaluated caption and
checks its content by asking the questions on either the reference caption or
the source image. We first develop QACE-Ref that compares the answers of the
evaluated caption to its reference, and report competitive results with the
state-of-the-art metrics. To go further, we propose QACE-Img, which asks the
questions directly on the image, instead of reference. A Visual-QA system is
necessary for QACE-Img. Unfortunately, the standard VQA models are framed as a
classification among only a few thousand categories. Instead, we propose
Visual-T5, an abstractive VQA system. The resulting metric, QACE-Img is
multi-modal, reference-less, and explainable. Our experiments show that
QACE-Img compares favorably w.r.t. other reference-less metrics. We will
release the pre-trained models to compute QACE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AMMASurv: Asymmetrical Multi-Modal Attention for Accurate Survival Analysis with Whole Slide Images and Gene Expression Data. (arXiv:2108.12565v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12565">
<div class="article-summary-box-inner">
<span><p>The use of multi-modal data such as the combination of whole slide images
(WSIs) and gene expression data for survival analysis can lead to more accurate
survival predictions. Previous multi-modal survival models are not able to
efficiently excavate the intrinsic information within each modality. Moreover,
despite experimental results show that WSIs provide more effective information
than gene expression data, previous methods regard the information from
different modalities as similarly important so they cannot flexibly utilize the
potential connection between the modalities. To address the above problems, we
propose a new asymmetrical multi-modal method, termed as AMMASurv.
Specifically, we design an asymmetrical multi-modal attention mechanism (AMMA)
in Transformer encoder for multi-modal data to enable a more flexible
multi-modal information fusion for survival prediction. Different from previous
works, AMMASurv can effectively utilize the intrinsic information within every
modality and flexibly adapts to the modalities of different importance.
Extensive experiments are conducted to validate the effectiveness of the
proposed model. Encouraging results demonstrate the superiority of our method
over other state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An implementation of ROS Autonomous Navigation on Parallax Eddie platform. (arXiv:2108.12571v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12571">
<div class="article-summary-box-inner">
<span><p>This paper presents an implementation of autonomous navigation functionality
based on Robot Operating System (ROS) on a wheeled differential drive mobile
platform called Eddie robot. ROS is a framework that contains many reusable
software stacks as well as visualization and debugging tools that provides an
ideal environment for any robotic project development. The main contribution of
this paper is the description of the customized hardware and software system
setup of Eddie robot to work with an autonomous navigation system in ROS called
Navigation Stack and to implement one application use case for autonomous
navigation. For this paper, photo taking is chosen to demonstrate a use case of
the mobile robot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Goal-driven text descriptions for images. (arXiv:2108.12575v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12575">
<div class="article-summary-box-inner">
<span><p>A big part of achieving Artificial General Intelligence(AGI) is to build a
machine that can see and listen like humans. Much work has focused on designing
models for image classification, video classification, object detection, pose
estimation, speech recognition, etc., and has achieved significant progress in
recent years thanks to deep learning. However, understanding the world is not
enough. An AI agent also needs to know how to talk, especially how to
communicate with a human. While perception (vision, for example) is more common
across animal species, the use of complicated language is unique to humans and
is one of the most important aspects of intelligence.
</p>
<p>In this thesis, we focus on generating textual output given visual input. In
Chapter 3, we focus on generating the referring expression, a text description
for an object in the image so that a receiver can infer which object is being
described. We use a comprehension machine to directly guide the generated
referring expressions to be more discriminative. In Chapter 4, we introduce a
method that encourages discriminability in image caption generation. We show
that more discriminative captioning models generate more descriptive captions.
In Chapter 5, we study how training objectives and sampling methods affect the
models' ability to generate diverse captions. We find that a popular captioning
training strategy will be detrimental to the diversity of generated captions.
In Chapter 6, we propose a model that can control the length of generated
captions. By changing the desired length, one can influence the style and
descriptiveness of the captions. Finally, in Chapter 7, we rank/generate
informative image tags according to their information utility. The proposed
method better matches what humans think are the most important tags for the
images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Significance of Question Encoder Sequence Model in the Out-of-Distribution Performance in Visual Question Answering. (arXiv:2108.12585v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12585">
<div class="article-summary-box-inner">
<span><p>Generalizing beyond the experiences has a significant role in developing
practical AI systems. It has been shown that current Visual Question Answering
(VQA) models are over-dependent on the language-priors (spurious correlations
between question-types and their most frequent answers) from the train set and
pose poor performance on Out-of-Distribution (OOD) test sets. This conduct
limits their generalizability and restricts them from being utilized in
real-world situations. This paper shows that the sequence model architecture
used in the question-encoder has a significant role in the generalizability of
VQA models. To demonstrate this, we performed a detailed analysis of various
existing RNN-based and Transformer-based question-encoders, and along, we
proposed a novel Graph attention network (GAT)-based question-encoder. Our
study found that a better choice of sequence model in the question-encoder
improves the generalizability of VQA models even without using any additional
relatively complex bias-mitigation approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Threshold: Pruning Tool for Densely Connected Convolutional Networks. (arXiv:2108.12604v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12604">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have made significant progress in the field of computer
vision. Recent studies have shown that depth, width and shortcut connections of
neural network architectures play a crucial role in their performance. One of
the most advanced neural network architectures, DenseNet, has achieved
excellent convergence rates through dense connections. However, it still has
obvious shortcomings in the usage of amount of memory. In this paper, we
introduce a new type of pruning tool, threshold, which refers to the principle
of the threshold voltage in MOSFET. This work employs this method to connect
blocks of different depths in different ways to reduce the usage of memory. It
is denoted as ThresholdNet. We compare ThresholdNet with other different
networks for FLOPs and memory usage, and the experiments show that ThresholdNet
is 70% less memory than that of the original DenseNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stagewise Unsupervised Domain Adaptation with Adversarial Self-Training for Road Segmentation of Remote Sensing Images. (arXiv:2108.12611v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12611">
<div class="article-summary-box-inner">
<span><p>Road segmentation from remote sensing images is a challenging task with wide
ranges of application potentials. Deep neural networks have advanced this field
by leveraging the power of large-scale labeled data, which, however, are
extremely expensive and time-consuming to acquire. One solution is to use cheap
available data to train a model and deploy it to directly process the data from
a specific application domain. Nevertheless, the well-known domain shift (DS)
issue prevents the trained model from generalizing well on the target domain.
In this paper, we propose a novel stagewise domain adaptation model called
RoadDA to address the DS issue in this field. In the first stage, RoadDA adapts
the target domain features to align with the source ones via generative
adversarial networks (GAN) based inter-domain adaptation. Specifically, a
feature pyramid fusion module is devised to avoid information loss of long and
thin roads and learn discriminative and robust features. Besides, to address
the intra-domain discrepancy in the target domain, in the second stage, we
propose an adversarial self-training method. We generate the pseudo labels of
target domain using the trained generator and divide it to labeled easy split
and unlabeled hard split based on the road confidence scores. The features of
hard split are adapted to align with the easy ones using adversarial learning
and the intra-domain adaptation process is repeated to progressively improve
the segmentation performance. Experiment results on two benchmarks demonstrate
that RoadDA can efficiently reduce the domain gap and outperforms
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Aware Model Adaptation for Unsupervised Cross-Domain Object Detection. (arXiv:2108.12612v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12612">
<div class="article-summary-box-inner">
<span><p>This work tackles the unsupervised cross-domain object detection problem
which aims to generalize a pre-trained object detector to a new target domain
without labels. We propose an uncertainty-aware model adaptation method, which
is based on two motivations: 1) the estimation and exploitation of model
uncertainty in a new domain is critical for reliable domain adaptation; and 2)
the joint alignment of distributions for inputs (feature alignment) and outputs
(self-training) is needed. To this end, we compose a Bayesian CNN-based
framework for uncertainty estimation in object detection, and propose an
algorithm for generation of uncertainty-aware pseudo-labels. We also devise a
scheme for joint feature alignment and self-training of the object detection
model with uncertainty-aware pseudo-labels. Experiments on multiple
cross-domain object detection benchmarks show that our proposed method achieves
state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AP-10K: A Benchmark for Animal Pose Estimation in the Wild. (arXiv:2108.12617v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12617">
<div class="article-summary-box-inner">
<span><p>Accurate animal pose estimation is an essential step towards understanding
animal behavior, and can potentially benefit many downstream applications, such
as wildlife conservation. Previous works only focus on specific animals while
ignoring the diversity of animal species, limiting the generalization ability.
In this paper, we propose AP-10K, the first large-scale benchmark for general
animal pose estimation, to facilitate the research in animal pose estimation.
AP-10K consists of 10,015 images collected and filtered from 23 animal families
and 60 species following the taxonomic rank and high-quality keypoint
annotations labeled and checked manually. Based on AP-10K, we benchmark
representative pose estimation models on the following three tracks: (1)
supervised learning for animal pose estimation, (2) cross-domain transfer
learning from human pose estimation to animal pose estimation, and (3) intra-
and inter-family domain generalization for unseen animals. The experimental
results provide sound empirical evidence on the superiority of learning from
diverse animals species in terms of both accuracy and generalization ability.
It opens new directions for facilitating future research in animal pose
estimation. AP-10k is publicly available at
https://github.com/AlexTheBad/AP10K.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GroupFormer: Group Activity Recognition with Clustered Spatial-Temporal Transformer. (arXiv:2108.12630v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12630">
<div class="article-summary-box-inner">
<span><p>Group activity recognition is a crucial yet challenging problem, whose core
lies in fully exploring spatial-temporal interactions among individuals and
generating reasonable group representations. However, previous methods either
model spatial and temporal information separately, or directly aggregate
individual features to form group features. To address these issues, we propose
a novel group activity recognition network termed GroupFormer. It captures
spatial-temporal contextual information jointly to augment the individual and
group representations effectively with a clustered spatial-temporal
transformer. Specifically, our GroupFormer has three appealing advantages: (1)
A tailor-modified Transformer, Clustered Spatial-Temporal Transformer, is
proposed to enhance the individual representation and group representation. (2)
It models the spatial and temporal dependencies integrally and utilizes
decoders to build the bridge between the spatial and temporal information. (3)
A clustered attention mechanism is utilized to dynamically divide individuals
into multiple clusters for better learning activity-aware semantic
representations. Moreover, experimental results show that the proposed
framework outperforms state-of-the-art methods on the Volleyball dataset and
Collective Activity dataset. Code is available at
https://github.com/xueyee/GroupFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Neural Networks for Spectral Snapshot Compressive Imaging. (arXiv:2108.12654v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12654">
<div class="article-summary-box-inner">
<span><p>We consider using {\bf\em untrained neural networks} to solve the
reconstruction problem of snapshot compressive imaging (SCI), which uses a
two-dimensional (2D) detector to capture a high-dimensional (usually 3D)
data-cube in a compressed manner. Various SCI systems have been built in recent
years to capture data such as high-speed videos, hyperspectral images, and the
state-of-the-art reconstruction is obtained by the deep neural networks.
However, most of these networks are trained in an end-to-end manner by a large
amount of corpus with sometimes simulated ground truth, measurement pairs. In
this paper, inspired by the untrained neural networks such as deep image priors
(DIP) and deep decoders, we develop a framework by integrating DIP into the
plug-and-play regime, leading to a self-supervised network for spectral SCI
reconstruction. Extensive synthetic and real data results show that the
proposed algorithm without training is capable of achieving competitive results
to the training based networks. Furthermore, by integrating the proposed method
with a pre-trained deep denoising prior, we have achieved state-of-the-art
results. {Our code is available at
\url{https://github.com/mengziyi64/CASSI-Self-Supervised}.}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DenseLiDAR: A Real-Time Pseudo Dense Depth Guided Depth Completion Network. (arXiv:2108.12655v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12655">
<div class="article-summary-box-inner">
<span><p>Depth Completion can produce a dense depth map from a sparse input and
provide a more complete 3D description of the environment. Despite great
progress made in depth completion, the sparsity of the input and low density of
the ground truth still make this problem challenging. In this work, we propose
DenseLiDAR, a novel real-time pseudo-depth guided depth completion neural
network. We exploit dense pseudo-depth map obtained from simple morphological
operations to guide the network in three aspects: (1) Constructing a residual
structure for the output; (2) Rectifying the sparse input data; (3) Providing
dense structural loss for training the network. Thanks to these novel designs,
higher performance of the output could be achieved. In addition, two new
metrics for better evaluating the quality of the predicted depth map are also
presented. Extensive experiments on KITTI depth completion benchmark suggest
that our model is able to achieve the state-of-the-art performance at the
highest frame rate of 50Hz. The predicted dense depth is further evaluated by
several downstream robotic perception or positioning tasks. For the task of 3D
object detection, 3~5 percent performance gains on small objects categories are
achieved on KITTI 3D object detection dataset. For RGB-D SLAM, higher accuracy
on vehicle's trajectory is also obtained in KITTI Odometry dataset. These
promising results not only verify the high quality of our depth prediction, but
also demonstrate the potential of improving the related downstream tasks by
using depth completion results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DKM: Differentiable K-Means Clustering Layer for Neural Network Compression. (arXiv:2108.12659v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12659">
<div class="article-summary-box-inner">
<span><p>Deep neural network (DNN) model compression for efficient on-device inference
is becoming increasingly important to reduce memory requirements and keep user
data on-device. To this end, we propose a novel differentiable k-means
clustering layer (DKM) and its application to train-time weight
clustering-based DNN model compression. DKM casts k-means clustering as an
attention problem and enables joint optimization of the parameters and
clustering centroids. Unlike prior works that rely on additional regularizers
and parameters, DKM-based compression keeps the original loss function and
model architecture fixed. We evaluated DKM-based compression on various DNN
models for computer vision and natural language processing (NLP) tasks. Our
results demonstrate that DMK delivers superior compression and accuracy
trade-off on ImageNet1k and GLUE benchmarks. For example, DKM-based compression
can offer 74.5% top-1 ImageNet1k accuracy on ResNet50 DNN model with 3.3MB
model size (29.4x model compression factor). For MobileNet-v1, which is a
challenging DNN to compress, DKM delivers 62.8% top-1 ImageNet1k accuracy with
0.74 MB model size (22.4x model compression factor). This result is 6.8% higher
top-1 accuracy and 33% relatively smaller model size than the current
state-of-the-art DNN compression algorithms. Additionally, DKM enables
compression of DistilBERT model by 11.8x with minimal (1.1%) accuracy loss on
GLUE NLP benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Track Objects from Unlabeled Videos. (arXiv:2108.12711v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12711">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose to learn an Unsupervised Single Object Tracker
(USOT) from scratch. We identify that three major challenges, i.e., moving
object discovery, rich temporal variation exploitation, and online update, are
the central causes of the performance bottleneck of existing unsupervised
trackers. To narrow the gap between unsupervised trackers and supervised
counterparts, we propose an effective unsupervised learning approach composed
of three stages. First, we sample sequentially moving objects with unsupervised
optical flow and dynamic programming, instead of random cropping. Second, we
train a naive Siamese tracker from scratch using single-frame pairs. Third, we
continue training the tracker with a novel cycle memory learning scheme, which
is conducted in longer temporal spans and also enables our tracker to update
online. Extensive experiments show that the proposed USOT learned from
unlabeled videos performs well over the state-of-the-art unsupervised trackers
by large margins, and on par with recent supervised deep trackers. Code is
available at https://github.com/VISION-SJTU/USOT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepFake Detection with Inconsistent Head Poses: Reproducibility and Analysis. (arXiv:2108.12715v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12715">
<div class="article-summary-box-inner">
<span><p>Applications of deep learning to synthetic media generation allow the
creation of convincing forgeries, called DeepFakes, with limited technical
expertise. DeepFake detection is an increasingly active research area. In this
paper, we analyze an existing DeepFake detection technique based on head pose
estimation, which can be applied when fake images are generated with an
autoencoder-based face swap. Existing literature suggests that this method is
an effective DeepFake detector, and its motivating principles are attractively
simple. With an eye towards using these principles to develop new DeepFake
detectors, we conduct a reproducibility study of the existing method. We
conclude that its merits are dramatically overstated, despite its celebrated
status. By investigating this discrepancy we uncover a number of important and
generalizable insights related to facial landmark detection, identity-agnostic
head pose estimation, and algorithmic bias in DeepFake detectors. Our results
correct the current literature's perception of state of the art performance for
DeepFake detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Dual Adversarial Calibration Framework for Automatic Fetal Brain Biometry. (arXiv:2108.12719v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12719">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel approach to automatic fetal brain biometry
motivated by needs in low- and medium- income countries. Specifically, we
leverage high-end (HE) ultrasound images to build a biometry solution for
low-cost (LC) point-of-care ultrasound images. We propose a novel unsupervised
domain adaptation approach to train deep models to be invariant to significant
image distribution shift between the image types. Our proposed method, which
employs a Dual Adversarial Calibration (DAC) framework, consists of adversarial
pathways which enforce model invariance to; i) adversarial perturbations in the
feature space derived from LC images, and ii) appearance domain discrepancy.
Our Dual Adversarial Calibration method estimates transcerebellar diameter and
head circumference on images from low-cost ultrasound devices with a mean
absolute error (MAE) of 2.43mm and 1.65mm, compared with 7.28 mm and 5.65 mm
respectively for SOTA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variational voxelwise rs-fMRI representation learning: Evaluation of sex, age, and neuropsychiatric signatures. (arXiv:2108.12756v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12756">
<div class="article-summary-box-inner">
<span><p>We propose to apply non-linear representation learning to voxelwise rs-fMRI
data. Learning the non-linear representations is done using a variational
autoencoder (VAE). The VAE is trained on voxelwise rs-fMRI data and performs
non-linear dimensionality reduction that retains meaningful information. The
retention of information in the model's representations is evaluated using
downstream age regression and sex classification tasks. The results on these
tasks are highly encouraging and a linear regressor trained with the
representations of our unsupervised model performs almost as well as a
supervised neural network, trained specifically for age regression on the same
dataset. The model is also evaluated with a schizophrenia diagnosis prediction
task, to assess its feasibility as a dimensionality reduction method for
neuropsychiatric datasets. These results highlight the potential for
pre-training on a larger set of individuals who do not have mental illness, to
improve the downstream neuropsychiatric task results. The pre-trained model is
fine-tuned for a variable number of epochs on a schizophrenia dataset and we
find that fine-tuning for 1 epoch yields the best results. This work therefore
not only opens up non-linear dimensionality reduction for voxelwise rs-fMRI
data but also shows that pre-training a deep learning model on voxelwise
rs-fMRI datasets greatly increases performance even on smaller datasets. It
also opens up the ability to look at the distribution of rs-fMRI time series in
the latent space of the VAE for heterogeneous neuropsychiatric disorders like
schizophrenia in future work. This can be complemented with the generative
aspect of the model that allows us to reconstruct points from the model's
latent space back into brain space and obtain an improved understanding of the
relation that the VAE learns between subjects, timepoints, and a subject's
characteristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrating Class Activation Maps for Long-Tailed Visual Recognition. (arXiv:2108.12757v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12757">
<div class="article-summary-box-inner">
<span><p>Real-world visual recognition problems often exhibit long-tailed
distributions, where the amount of data for learning in different categories
shows significant imbalance. Standard classification models learned on such
data distribution often make biased predictions towards the head classes while
generalizing poorly to the tail classes. In this paper, we present two
effective modifications of CNNs to improve network learning from long-tailed
distribution. First, we present a Class Activation Map Calibration (CAMC)
module to improve the learning and prediction of network classifiers, by
enforcing network prediction based on important image regions. The proposed
CAMC module highlights the correlated image regions across data and reinforces
the representations in these areas to obtain a better global representation for
classification. Furthermore, we investigate the use of normalized classifiers
for representation learning in long-tailed problems. Our empirical study
demonstrates that by simply scaling the outputs of the classifier with an
appropriate scalar, we can effectively improve the classification accuracy on
tail classes without losing the accuracy of head classes. We conduct extensive
experiments to validate the effectiveness of our design and we set new
state-of-the-art performance on five benchmarks, including ImageNet-LT,
Places-LT, iNaturalist 2018, CIFAR10-LT, and CIFAR100-LT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CrossedWires: A Dataset of Syntactically Equivalent but Semantically Disparate Deep Learning Models. (arXiv:2108.12768v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12768">
<div class="article-summary-box-inner">
<span><p>The training of neural networks using different deep learning frameworks may
lead to drastically differing accuracy levels despite the use of the same
neural network architecture and identical training hyperparameters such as
learning rate and choice of optimization algorithms. Currently, our ability to
build standardized deep learning models is limited by the availability of a
suite of neural network and corresponding training hyperparameter benchmarks
that expose differences between existing deep learning frameworks. In this
paper, we present a living dataset of models and hyperparameters, called
CrossedWires, that exposes semantic differences between two popular deep
learning frameworks: PyTorch and Tensorflow. The CrossedWires dataset currently
consists of models trained on CIFAR10 images using three different computer
vision architectures: VGG16, ResNet50 and DenseNet121 across a large
hyperparameter space. Using hyperparameter optimization, each of the three
models was trained on 400 sets of hyperparameters suggested by the HyperSpace
search algorithm. The CrossedWires dataset includes PyTorch and Tensforflow
models with test accuracies as different as 0.681 on syntactically equivalent
models and identical hyperparameter choices. The 340 GB dataset and benchmarks
presented here include the performance statistics, training curves, and model
weights for all 1200 hyperparameter choices, resulting in 2400 total models.
The CrossedWires dataset provides an opportunity to study semantic differences
between syntactically equivalent models across popular deep learning
frameworks. Further, the insights obtained from this study can enable the
development of algorithms and tools that improve reliability and
reproducibility of deep learning frameworks. The dataset is freely available at
https://github.com/maxzvyagin/crossedwires through a Python API and direct
download link.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attentive Rotation Invariant Convolution for Point Cloud-based Large Scale Place Recognition. (arXiv:2108.12790v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12790">
<div class="article-summary-box-inner">
<span><p>Autonomous Driving and Simultaneous Localization and Mapping(SLAM) are
becoming increasingly important in real world, where point cloud-based large
scale place recognition is the spike of them. Previous place recognition
methods have achieved acceptable performances by regarding the task as a point
cloud retrieval problem. However, all of them are suffered from a common
defect: they can't handle the situation when the point clouds are rotated,
which is common, e.g, when viewpoints or motorcycle types are changed. To
tackle this issue, we propose an Attentive Rotation Invariant Convolution
(ARIConv) in this paper. The ARIConv adopts three kind of Rotation Invariant
Features (RIFs): Spherical Signals (SS), Individual-Local Rotation Invariant
Features (ILRIF) and Group-Local Rotation Invariant features (GLRIF) in its
structure to learn rotation invariant convolutional kernels, which are robust
for learning rotation invariant point cloud features. What's more, to highlight
pivotal RIFs, we inject an attentive module in ARIConv to give different RIFs
different importance when learning kernels. Finally, utilizing ARIConv, we
build a DenseNet-like network architecture to learn rotation-insensitive global
descriptors used for retrieving. We experimentally demonstrate that our model
can achieve state-of-the-art performance on large scale place recognition task
when the point cloud scans are rotated and can achieve comparable results with
most of existing methods on the original non-rotated datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Airplane Type Identification Based on Mask RCNN and Drone Images. (arXiv:2108.12811v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12811">
<div class="article-summary-box-inner">
<span><p>For dealing with traffic bottlenecks at airports, aircraft object detection
is insufficient. Every airport generally has a variety of planes with various
physical and technological requirements as well as diverse service
requirements. Detecting the presence of new planes will not address all traffic
congestion issues. Identifying the type of airplane, on the other hand, will
entirely fix the problem because it will offer important information about the
plane's technical specifications (i.e., the time it needs to be served and its
appropriate place in the airport). Several studies have provided various
contributions to address airport traffic jams; however, their ultimate goal was
to determine the existence of airplane objects. This paper provides a practical
approach to identify the type of airplane in airports depending on the results
provided by the airplane detection process using mask region convolution neural
network. The key feature employed to identify the type of airplane is the
surface area calculated based on the results of airplane detection. The surface
area is used to assess the estimated cabin length which is considered as an
additional key feature for identifying the airplane type. The length of any
detected plane may be calculated by measuring the distance between the detected
plane's two furthest points. The suggested approach's performance is assessed
using average accuracies and a confusion matrix. The findings show that this
method is dependable. This method will greatly aid in the management of airport
traffic congestion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Airplane Detection Based on Mask Region Convolution Neural Network. (arXiv:2108.12817v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12817">
<div class="article-summary-box-inner">
<span><p>Addressing airport traffic jams is one of the most crucial and challenging
tasks in the remote sensing field, especially for the busiest airports. Several
solutions have been employed to address this problem depending on the airplane
detection process. The most effective solutions are through the use of
satellite images with deep learning techniques. Such solutions, however, are
significantly costly and require satellites and modern complicated technology
which may not be available in most countries worldwide. This paper provides a
universal, low cost and fast solution for airplane detection in airports. This
paper recommends the use of drones instead of satellites to feed the system
with drone images using a proposed deep learning model. Drone images are
employed as the dataset to train and evaluate a mask region convolution neural
network (RCNN) model. The Mask RCNN model applies faster RCNN as its base
configuration with critical modifications on its head neural network
constructions. The model detects whether or not an airplane is present and
includes mask estimations to approximate surface area and length, which will
help future works identify the airplane type. This solution can be easily
implemented globally as it is a low-cost and fast solution for airplane
detection at airports. The evaluation process reveals promising results
according to Microsoft Common Objects in Context (COCO) metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MEDIC: A Multi-Task Learning Dataset for Disaster Image Classification. (arXiv:2108.12828v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12828">
<div class="article-summary-box-inner">
<span><p>Recent research in disaster informatics demonstrates a practical and
important use case of artificial intelligence to save human lives and
sufferings during post-natural disasters based on social media contents (text
and images). While notable progress has been made using texts, research on
exploiting the images remains relatively under-explored. To advance the
image-based approach, we propose MEDIC (available at:
https://crisisnlp.qcri.org/medic/index.html), which is the largest social media
image classification dataset for humanitarian response consisting of 71,198
images to address four different tasks in a multi-task learning setup. This is
the first dataset of its kind: social media image, disaster response, and
multi-task learning research. An important property of this dataset is its high
potential to contribute research on multi-task learning, which recently
receives much interest from the machine learning community and has shown
remarkable results in terms of memory, inference speed, performance, and
generalization capability. Therefore, the proposed dataset is an important
resource for advancing image-based disaster management and multi-task machine
learning research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Deep Image Prior for Denoising. (arXiv:2108.12841v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12841">
<div class="article-summary-box-inner">
<span><p>Deep image prior (DIP) serves as a good inductive bias for diverse inverse
problems. Among them, denoising is known to be particularly challenging for the
DIP due to noise fitting with the requirement of an early stopping. To address
the issue, we first analyze the DIP by the notion of effective degrees of
freedom (DF) to monitor the optimization progress and propose a principled
stopping criterion before fitting to noise without access of a paired ground
truth image for Gaussian noise. We also propose the `stochastic temporal
ensemble (STE)' method for incorporating techniques to further improve DIP's
performance for denoising. We additionally extend our method to Poisson noise.
Our empirical validations show that given a single noisy image, our method
denoises the image while preserving rich textual details. Further, our approach
outperforms prior arts in LPIPS by large margins with comparable PSNR and SSIM
on seven different datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decentralized Autofocusing System with Hierarchical Agents. (arXiv:2108.12842v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12842">
<div class="article-summary-box-inner">
<span><p>State-of-the-art object detection models are frequently trained offline using
available datasets, such as ImageNet: large and overly diverse data that are
unbalanced and hard to cluster semantically. This kind of training drops the
object detection performance should the change in illumination, in the
environmental conditions (e.g., rain), or in the lens positioning (out-of-focus
blur) occur. We propose a decentralized hierarchical multi-agent deep
reinforcement learning approach for intelligently controlling the camera and
the lens focusing settings, leading to significant improvement to the capacity
of the popular detection models (YOLO, Fast R-CNN, and Retina are considered).
The algorithm relies on the latent representation of the camera's stream and,
thus, it is the first method to allow a completely no-reference tuning of the
camera, where the system trains itself to auto-focus itself.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flow-Guided Video Inpainting with Scene Templates. (arXiv:2108.12845v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12845">
<div class="article-summary-box-inner">
<span><p>We consider the problem of filling in missing spatio-temporal regions of a
video. We provide a novel flow-based solution by introducing a generative model
of images in relation to the scene (without missing regions) and mappings from
the scene to images. We use the model to jointly infer the scene template, a 2D
representation of the scene, and the mappings. This ensures consistency of the
frame-to-frame flows generated to the underlying scene, reducing geometric
distortions in flow based inpainting. The template is mapped to the missing
regions in the video by a new L2-L1 interpolation scheme, creating crisp
inpaintings and reducing common blur and distortion artifacts. We show on two
benchmark datasets that our approach out-performs state-of-the-art
quantitatively and in user studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-Parametric Neural Style Transfer. (arXiv:2108.12847v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12847">
<div class="article-summary-box-inner">
<span><p>It seems easy to imagine a photograph of the Eiffel Tower painted in the
style of Vincent van Gogh's 'The Starry Night', but upon introspection it is
difficult to precisely define what this would entail. What visual elements must
an image contain to represent the 'content' of the Eiffel Tower? What visual
elements of 'The Starry Night' are caused by van Gogh's 'style' rather than his
decision to depict a village under the night sky? Precisely defining 'content'
and 'style' is a central challenge of designing algorithms for artistic style
transfer, algorithms which can recreate photographs using an artwork's style.
My efforts defining these terms, and designing style transfer algorithms
themselves, are the focus of this thesis. I will begin by proposing novel
definitions of style and content based on optimal transport and
self-similarity, and demonstrating how a style transfer algorithm based on
these definitions generates outputs with improved visual quality. Then I will
describe how the traditional texture-based definition of style can be expanded
to include elements of geometry and proportion by jointly optimizing a
keypoint-guided deformation field alongside the stylized output's pixels.
Finally I will describe a framework inspired by both modern neural style
transfer algorithms and traditional patch-based synthesis approaches which is
fast, general, and offers state-of-the-art visual quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Convolution Search for Point Cloud Processing. (arXiv:2108.12856v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12856">
<div class="article-summary-box-inner">
<span><p>Exploiting convolutional neural networks for point cloud processing is quite
challenging, due to the inherent irregular distribution and discrete shape
representation of point clouds. To address these problems, many handcrafted
convolution variants have sprung up in recent years. Though with elaborate
design, these variants could be far from optimal in sufficiently capturing
diverse shapes formed by discrete points. In this paper, we propose
PointSeaConv, i.e., a novel differential convolution search paradigm on point
clouds. It can work in a purely data-driven manner and thus is capable of
auto-creating a group of suitable convolutions for geometric shape modeling. We
also propose a joint optimization framework for simultaneous search of internal
convolution and external architecture, and introduce epsilon-greedy algorithm
to alleviate the effect of discretization error. As a result, PointSeaNet, a
deep network that is sufficient to capture geometric shapes at both convolution
level and architecture level, can be searched out for point cloud processing.
Extensive experiments strongly evidence that our proposed PointSeaNet surpasses
current handcrafted deep models on challenging benchmarks across multiple tasks
with remarkable margins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Edge-Cloud Collaborated Object Detection via Difficult-Case Discriminator. (arXiv:2108.12858v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12858">
<div class="article-summary-box-inner">
<span><p>As one of the basic tasks of computer vision, object detection has been
widely used in many intelligent applications. However, object detection
algorithms are usually heavyweight in computation, hindering their
implementations on resource-constrained edge devices. Current edge-cloud
collaboration methods, such as CNN partition over Edge-cloud devices, are not
suitable for object detection since the huge data size of the intermediate
results will introduce extravagant communication costs. To address this
challenge, we propose a small-big model framework that deploys a big model in
the cloud and a small model on the edge devices. Upon receiving data, the edge
device operates a difficult-case discriminator to classify the images into easy
cases and difficult cases according to the specific semantics of the images.
The easy cases will be processed locally at the edge, and the difficult cases
will be uploaded to the cloud. Experimental results on the VOC, COCO, HELMET
datasets using two different object detection algorithms demonstrate that the
small-big model system can detect 94.01%-97.84% of objects with only about 50%
images uploaded to the cloud when using SSD. In addition, the small-big model
averagely reaches 91.22%- 92.52% end-to-end mAP of the scheme that uploading
all images to the cloud.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MBDF-Net: Multi-Branch Deep Fusion Network for 3D Object Detection. (arXiv:2108.12863v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12863">
<div class="article-summary-box-inner">
<span><p>Point clouds and images could provide complementary information when
representing 3D objects. Fusing the two kinds of data usually helps to improve
the detection results. However, it is challenging to fuse the two data
modalities, due to their different characteristics and the interference from
the non-interest areas. To solve this problem, we propose a Multi-Branch Deep
Fusion Network (MBDF-Net) for 3D object detection. The proposed detector has
two stages. In the first stage, our multi-branch feature extraction network
utilizes Adaptive Attention Fusion (AAF) modules to produce cross-modal fusion
features from single-modal semantic features. In the second stage, we use a
region of interest (RoI) -pooled fusion module to generate enhanced local
features for refinement. A novel attention-based hybrid sampling strategy is
also proposed for selecting key points in the downsampling process. We evaluate
our approach on two widely used benchmark datasets including KITTI and
SUN-RGBD. The experimental results demonstrate the advantages of our method
over state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Partial Domain Adaptation without Domain Alignment. (arXiv:2108.12867v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12867">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation (UDA) aims to transfer knowledge from a
well-labeled source domain to a different but related unlabeled target domain
with identical label space. Currently, the main workhorse for solving UDA is
domain alignment, which has proven successful. However, it is often difficult
to find an appropriate source domain with identical label space. A more
practical scenario is so-called partial domain adaptation (PDA) in which the
source label set or space subsumes the target one. Unfortunately, in PDA, due
to the existence of the irrelevant categories in the source domain, it is quite
hard to obtain a perfect alignment, thus resulting in mode collapse and
negative transfer. Although several efforts have been made by down-weighting
the irrelevant source categories, the strategies used tend to be burdensome and
risky since exactly which irrelevant categories are unknown. These challenges
motivate us to find a relatively simpler alternative to solve PDA. To achieve
this, we first provide a thorough theoretical analysis, which illustrates that
the target risk is bounded by both model smoothness and between-domain
discrepancy. Considering the difficulty of perfect alignment in solving PDA, we
turn to focus on the model smoothness while discard the riskier domain
alignment to enhance the adaptability of the model. Specifically, we
instantiate the model smoothness as a quite simple intra-domain structure
preserving (IDSP). To our best knowledge, this is the first naive attempt to
address the PDA without domain alignment. Finally, our empirical results on
multiple benchmark datasets demonstrate that IDSP is not only superior to the
PDA SOTAs by a significant margin on some benchmarks (e.g., +10% on Cl-&gt;Rw and
+8% on Ar-&gt;Rw ), but also complementary to domain alignment in the standard UDA
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multimodal Framework for Video Ads Understanding. (arXiv:2108.12868v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12868">
<div class="article-summary-box-inner">
<span><p>There is a growing trend in placing video advertisements on social platforms
for online marketing, which demands automatic approaches to understand the
contents of advertisements effectively. Taking the 2021 TAAC competition as an
opportunity, we developed a multimodal system to improve the ability of
structured analysis of advertising video content. In our framework, we break
down the video structuring analysis problem into two tasks, i.e., scene
segmentation and multi-modal tagging. In scene segmentation, we build upon a
temporal convolution module for temporal modeling to predict whether adjacent
frames belong to the same scene. In multi-modal tagging, we first compute
clip-level visual features by aggregating frame-level features with
NeXt-SoftDBoF. The visual features are further complemented with textual
features that are derived using a global-local attention mechanism to extract
useful information from OCR (Optical Character Recognition) and ASR (Audio
Speech Recognition) outputs. Our solution achieved a score of 0.2470 measured
in consideration of localization and prediction accuracy, ranking fourth in the
2021 TAAC final leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solving Viewing Graph Optimization for Simultaneous Position and Rotation Registration. (arXiv:2108.12876v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12876">
<div class="article-summary-box-inner">
<span><p>A viewing graph is a set of unknown camera poses, as the vertices, and the
observed relative motions, as the edges. Solving the viewing graph is an
essential step in a Structure-from-Motion procedure, where a set of relative
motions is obtained from a collection of 2D images. Almost all methods in the
literature solve for the rotations separately, through rotation averaging
process, and use them for solving the positions. Obtaining positions is the
challenging part because the translation observations only tell the direction
of the motions. It becomes more challenging when the set of edges comprises
pairwise translation observations between either near and far cameras. In this
paper an iterative method is proposed that overcomes these issues. Also a
method is proposed which obtains the rotations and positions simultaneously.
Experimental results show the-state-of-the-art performance of the proposed
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layout-to-Image Translation with Double Pooling Generative Adversarial Networks. (arXiv:2108.12900v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12900">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the task of layout-to-image translation, which aims
to translate an input semantic layout to a realistic image. One open challenge
widely observed in existing methods is the lack of effective semantic
constraints during the image translation process, leading to models that cannot
preserve the semantic information and ignore the semantic dependencies within
the same object. To address this issue, we propose a novel Double Pooing GAN
(DPGAN) for generating photo-realistic and semantically-consistent results from
the input layout. We also propose a novel Double Pooling Module (DPM), which
consists of the Square-shape Pooling Module (SPM) and the Rectangle-shape
Pooling Module (RPM). Specifically, SPM aims to capture short-range semantic
dependencies of the input layout with different spatial scales, while RPM aims
to capture long-range semantic dependencies from both horizontal and vertical
directions. We then effectively fuse both outputs of SPM and RPM to further
enlarge the receptive field of our generator. Extensive experiments on five
popular datasets show that the proposed DPGAN achieves better results than
state-of-the-art methods. Finally, both SPM and SPM are general and can be
seamlessly integrated into any GAN-based architectures to strengthen the
feature representation. The code is available at
https://github.com/Ha0Tang/DPGAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lipschitz Continuity Guided Knowledge Distillation. (arXiv:2108.12905v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12905">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation has become one of the most important model compression
techniques by distilling knowledge from larger teacher networks to smaller
student ones. Although great success has been achieved by prior distillation
methods via delicately designing various types of knowledge, they overlook the
functional properties of neural networks, which makes the process of applying
those techniques to new tasks unreliable and non-trivial. To alleviate such
problem, in this paper, we initially leverage Lipschitz continuity to better
represent the functional characteristic of neural networks and guide the
knowledge distillation process. In particular, we propose a novel Lipschitz
Continuity Guided Knowledge Distillation framework to faithfully distill
knowledge by minimizing the distance between two neural networks' Lipschitz
constants, which enables teacher networks to better regularize student networks
and improve the corresponding performance. We derive an explainable
approximation algorithm with an explicit theoretical derivation to address the
NP-hard problem of calculating the Lipschitz constant. Experimental results
have shown that our method outperforms other benchmarks over several knowledge
distillation tasks (e.g., classification, segmentation and object detection) on
CIFAR-100, ImageNet, and PASCAL VOC datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuroCartography: Scalable Automatic Visual Summarization of Concepts in Deep Neural Networks. (arXiv:2108.12931v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12931">
<div class="article-summary-box-inner">
<span><p>Existing research on making sense of deep neural networks often focuses on
neuron-level interpretation, which may not adequately capture the bigger
picture of how concepts are collectively encoded by multiple neurons. We
present NeuroCartography, an interactive system that scalably summarizes and
visualizes concepts learned by neural networks. It automatically discovers and
groups neurons that detect the same concepts, and describes how such neuron
groups interact to form higher-level concepts and the subsequent predictions.
NeuroCartography introduces two scalable summarization techniques: (1) neuron
clustering groups neurons based on the semantic similarity of the concepts
detected by neurons (e.g., neurons detecting "dog faces" of different breeds
are grouped); and (2) neuron embedding encodes the associations between related
concepts based on how often they co-occur (e.g., neurons detecting "dog face"
and "dog tail" are placed closer in the embedding space). Key to our scalable
techniques is the ability to efficiently compute all neuron pairs'
relationships, in time linear to the number of neurons instead of quadratic
time. NeuroCartography scales to large data, such as the ImageNet dataset with
1.2M images. The system's tightly coordinated views integrate the scalable
techniques to visualize the concepts and their relationships, projecting the
concept associations to a 2D space in Neuron Projection View, and summarizing
neuron clusters and their relationships in Graph View. Through a large-scale
human evaluation, we demonstrate that our technique discovers neuron groups
that represent coherent, human-meaningful concepts. And through usage
scenarios, we describe how our approaches enable interesting and surprising
discoveries, such as concept cascades of related and isolated concepts. The
NeuroCartography visualization runs in modern browsers and is open-sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning JPEG Compression Artifacts for Image Manipulation Detection and Localization. (arXiv:2108.12947v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12947">
<div class="article-summary-box-inner">
<span><p>Detecting and localizing image manipulation are necessary to counter
malicious use of image editing techniques. Accordingly, it is essential to
distinguish between authentic and tampered regions by analyzing intrinsic
statistics in an image. We focus on JPEG compression artifacts left during
image acquisition and editing. We propose a convolutional neural network (CNN)
that uses discrete cosine transform (DCT) coefficients, where compression
artifacts remain, to localize image manipulation. Standard CNNs cannot learn
the distribution of DCT coefficients because the convolution throws away the
spatial coordinates, which are essential for DCT coefficients. We illustrate
how to design and train a neural network that can learn the distribution of DCT
coefficients. Furthermore, we introduce Compression Artifact Tracing Network
(CAT-Net) that jointly uses image acquisition artifacts and compression
artifacts. It significantly outperforms traditional and deep neural
network-based methods in detecting and localizing tampered regions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Discover Reflection Symmetry via Polar Matching Convolution. (arXiv:2108.12952v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12952">
<div class="article-summary-box-inner">
<span><p>The task of reflection symmetry detection remains challenging due to
significant variations and ambiguities of symmetry patterns in the wild.
Furthermore, since the local regions are required to match in reflection for
detecting a symmetry pattern, it is hard for standard convolutional networks,
which are not equivariant to rotation and reflection, to learn the task. To
address the issue, we introduce a new convolutional technique, dubbed the polar
matching convolution, which leverages a polar feature pooling, a
self-similarity encoding, and a systematic kernel design for axes of different
angles. The proposed high-dimensional kernel convolution network effectively
learns to discover symmetry patterns from real-world images, overcoming the
limitations of standard convolution. In addition, we present a new dataset and
introduce a self-supervised learning strategy by augmenting the dataset with
synthesizing images. Experiments demonstrate that our method outperforms
state-of-the-art methods in terms of accuracy and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for Two-Stream Models in Multivariate Space for Video Recognition. (arXiv:2108.12957v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12957">
<div class="article-summary-box-inner">
<span><p>Conventional video models rely on a single stream to capture the complex
spatial-temporal features. Recent work on two-stream video models, such as
SlowFast network and AssembleNet, prescribe separate streams to learn
complementary features, and achieve stronger performance. However, manually
designing both streams as well as the in-between fusion blocks is a daunting
task, requiring to explore a tremendously large design space. Such manual
exploration is time-consuming and often ends up with sub-optimal architectures
when computational resources are limited and the exploration is insufficient.
In this work, we present a pragmatic neural architecture search approach, which
is able to search for two-stream video models in giant spaces efficiently. We
design a multivariate search space, including 6 search variables to capture a
wide variety of choices in designing two-stream models. Furthermore, we propose
a progressive search procedure, by searching for the architecture of individual
streams, fusion blocks, and attention blocks one after the other. We
demonstrate two-stream models with significantly better performance can be
automatically discovered in our design space. Our searched two-stream models,
namely Auto-TSNet, consistently outperform other models on standard benchmarks.
On Kinetics, compared with the SlowFast model, our Auto-TSNet-L model reduces
FLOPS by nearly 11 times while achieving the same accuracy 78.9%. On
Something-Something-V2, Auto-TSNet-M improves the accuracy by at least 2% over
other methods which use less than 50 GFLOPS per video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3DStyleNet: Creating 3D Shapes with Geometric and Texture Style Variations. (arXiv:2108.12958v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12958">
<div class="article-summary-box-inner">
<span><p>We propose a method to create plausible geometric and texture style
variations of 3D objects in the quest to democratize 3D content creation. Given
a pair of textured source and target objects, our method predicts a part-aware
affine transformation field that naturally warps the source shape to imitate
the overall geometric style of the target. In addition, the texture style of
the target is transferred to the warped source object with the help of a
multi-view differentiable renderer. Our model, 3DStyleNet, is composed of two
sub-networks trained in two stages. First, the geometric style network is
trained on a large set of untextured 3D shapes. Second, we jointly optimize our
geometric style network and a pre-trained image style transfer network with
losses defined over both the geometry and the rendering of the result. Given a
small set of high-quality textured objects, our method can create many novel
stylized shapes, resulting in effortless 3D content creation and style-ware
data augmentation. We showcase our approach qualitatively on 3D content
stylization, and provide user studies to validate the quality of our results.
In addition, our method can serve as a valuable tool to create 3D data
augmentations for computer vision tasks. Extensive quantitative analysis shows
that 3DStyleNet outperforms alternative data augmentation techniques for the
downstream task of single-image 3D reconstruction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BioFors: A Large Biomedical Image Forensics Dataset. (arXiv:2108.12961v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12961">
<div class="article-summary-box-inner">
<span><p>Research in media forensics has gained traction to combat the spread of
misinformation. However, most of this research has been directed towards
content generated on social media. Biomedical image forensics is a related
problem, where manipulation or misuse of images reported in biomedical research
documents is of serious concern. The problem has failed to gain momentum beyond
an academic discussion due to an absence of benchmark datasets and standardized
tasks. In this paper we present BioFors -- the first dataset for benchmarking
common biomedical image manipulations. BioFors comprises 47,805 images
extracted from 1,031 open-source research papers. Images in BioFors are divided
into four categories -- Microscopy, Blot/Gel, FACS and Macroscopy. We also
propose three tasks for forensic analysis -- external duplication detection,
internal duplication detection and cut/sharp-transition detection. We benchmark
BioFors on all tasks with suitable state-of-the-art algorithms. Our results and
analysis show that existing algorithms developed on common computer vision
datasets are not robust when applied to biomedical images, validating that more
research is required to address the unique challenges of biomedical image
forensics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Font Completion and Manipulation by Cycling Between Multi-Modality Representations. (arXiv:2108.12965v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12965">
<div class="article-summary-box-inner">
<span><p>Generating font glyphs of consistent style from one or a few reference
glyphs, i.e., font completion, is an important task in topographical design. As
the problem is more well-defined than general image style transfer tasks, thus
it has received interest from both vision and machine learning communities.
Existing approaches address this problem as a direct image-to-image translation
task. In this work, we innovate to explore the generation of font glyphs as 2D
graphic objects with the graph as an intermediate representation, so that more
intrinsic graphic properties of font styles can be captured. Specifically, we
formulate a cross-modality cycled image-to-image model structure with a graph
constructor between an image encoder and an image renderer. The novel graph
constructor maps a glyph's latent code to its graph representation that matches
expert knowledge, which is trained to help the translation task. Our model
generates improved results than both image-to-image baseline and previous
state-of-the-art methods for glyph completion. Furthermore, the graph
representation output by our model also provides an intuitive interface for
users to do local editing and manipulation. Our proposed cross-modality cycled
representation learning has the potential to be applied to other domains with
prior knowledge from different data modalities. Our code is available at
https://github.com/VITA-Group/Font_Completion_Graph.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Digging into Uncertainty in Self-supervised Multi-view Stereo. (arXiv:2108.12966v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12966">
<div class="article-summary-box-inner">
<span><p>Self-supervised Multi-view stereo (MVS) with a pretext task of image
reconstruction has achieved significant progress recently. However, previous
methods are built upon intuitions, lacking comprehensive explanations about the
effectiveness of the pretext task in self-supervised MVS. To this end, we
propose to estimate epistemic uncertainty in self-supervised MVS, accounting
for what the model ignores. Specially, the limitations can be categorized into
two types: ambiguious supervision in foreground and invalid supervision in
background. To address these issues, we propose a novel Uncertainty reduction
Multi-view Stereo (UMVS) framework for self-supervised learning. To alleviate
ambiguous supervision in foreground, we involve extra correspondence prior with
a flow-depth consistency loss. The dense 2D correspondence of optical flows is
used to regularize the 3D stereo correspondence in MVS. To handle the invalid
supervision in background, we use Monte-Carlo Dropout to acquire the
uncertainty map and further filter the unreliable supervision signals on
invalid regions. Extensive experiments on DTU and Tank&amp;Temples benchmark show
that our U-MVS framework achieves the best performance among unsupervised MVS
methods, with competitive performance with its supervised opponents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SHIFT15M: Multiobjective Large-Scale Fashion Dataset with Distributional Shifts. (arXiv:2108.12992v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12992">
<div class="article-summary-box-inner">
<span><p>Many machine learning algorithms assume that the training data and the test
data follow the same distribution. However, such assumptions are often violated
in real-world machine learning problems. In this paper, we propose SHIFT15M, a
dataset that can be used to properly evaluate models in situations where the
distribution of data changes between training and testing. The SHIFT15M dataset
has several good properties: (i) Multiobjective. Each instance in the dataset
has several numerical values that can be used as target variables. (ii)
Large-scale. The SHIFT15M dataset consists of 15million fashion images. (iii)
Coverage of types of dataset shifts. SHIFT15M contains multiple dataset shift
problem settings (e.g., covariate shift or target shift). SHIFT15M also enables
the performance evaluation of the model under various magnitudes of dataset
shifts by switching the magnitude. In addition, we provide software to handle
SHIFT15M in a very simple way: https://github.com/st-tech/zozo-shift15m.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pseudo-mask Matters inWeakly-supervised Semantic Segmentation. (arXiv:2108.12995v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12995">
<div class="article-summary-box-inner">
<span><p>Most weakly supervised semantic segmentation (WSSS) methods follow the
pipeline that generates pseudo-masks initially and trains the segmentation
model with the pseudo-masks in fully supervised manner after. However, we find
some matters related to the pseudo-masks, including high quality pseudo-masks
generation from class activation maps (CAMs), and training with noisy
pseudo-mask supervision. For these matters, we propose the following designs to
push the performance to new state-of-art: (i) Coefficient of Variation
Smoothing to smooth the CAMs adaptively; (ii) Proportional Pseudo-mask
Generation to project the expanded CAMs to pseudo-mask based on a new metric
indicating the importance of each class on each location, instead of the scores
trained from binary classifiers. (iii) Pretended Under-Fitting strategy to
suppress the influence of noise in pseudo-mask; (iv) Cyclic Pseudo-mask to
boost the pseudo-masks during training of fully supervised semantic
segmentation (FSSS). Experiments based on our methods achieve new state-of-art
results on two changeling weakly supervised semantic segmentation datasets,
pushing the mIoU to 70.0% and 40.2% on PAS-CAL VOC 2012 and MS COCO 2014
respectively. Codes including segmentation framework are released at
https://github.com/Eli-YiLi/PMM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Battle of Network Structures: An Empirical Study of CNN, Transformer, and MLP. (arXiv:2108.13002v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13002">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNN) are the dominant deep neural network
(DNN) architecture for computer vision. Recently, Transformer and multi-layer
perceptron (MLP)-based models, such as Vision Transformer and MLP-Mixer,
started to lead new trends as they showed promising results in the ImageNet
classification task. In this paper, we conduct empirical studies on these DNN
structures and try to understand their respective pros and cons. To ensure a
fair comparison, we first develop a unified framework called SPACH which adopts
separate modules for spatial and channel processing. Our experiments under the
SPACH framework reveal that all structures can achieve competitive performance
at a moderate scale. However, they demonstrate distinctive behaviors when the
network size scales up. Based on our findings, we propose two hybrid models
using convolution and Transformer modules. The resulting Hybrid-MS-S+ model
achieves 83.9% top-1 accuracy with 63M parameters and 12.3G FLOPS. It is
already on par with the SOTA models with sophisticated designs. The code and
models will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Embedding Novel Views in a Single JPEG Image. (arXiv:2108.13003v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13003">
<div class="article-summary-box-inner">
<span><p>We propose a novel approach for embedding novel views in a single JPEG image
while preserving the perceptual fidelity of the modified JPEG image and the
restored novel views. We adopt the popular novel view synthesis representation
of multiplane images (MPIs). Our model first encodes 32 MPI layers (totally 128
channels) into a 3-channel JPEG image that can be decoded for MPIs to render
novel views, with an embedding capacity of 1024 bits per pixel. We conducted
experiments on public datasets with different novel view synthesis methods, and
the results show that the proposed method can restore high-fidelity novel views
from a slightly modified JPEG image. Furthermore, our method is robust to JPEG
compression, color adjusting, and cropping. Our source code will be publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">X2Teeth: 3D Teeth Reconstruction from a Single Panoramic Radiograph. (arXiv:2108.13004v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13004">
<div class="article-summary-box-inner">
<span><p>3D teeth reconstruction from X-ray is important for dental diagnosis and many
clinical operations. However, no existing work has explored the reconstruction
of teeth for a whole cavity from a single panoramic radiograph. Different from
single object reconstruction from photos, this task has the unique challenge of
constructing multiple objects at high resolutions. To conquer this task, we
develop a novel ConvNet X2Teeth that decomposes the task into teeth
localization and single-shape estimation. We also introduce a patch-based
training strategy, such that X2Teeth can be end-to-end trained for optimal
performance. Extensive experiments show that our method can successfully
estimate the 3D structure of the cavity and reflect the details for each tooth.
Moreover, X2Teeth achieves a reconstruction IoU of 0.681, which significantly
outperforms the encoder-decoder method by $1.71X and the retrieval-based method
by $1.52X. Our method can also be promising for other multi-anatomy 3D
reconstruction tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring and Improving Mobile Level Vision Transformers. (arXiv:2108.13015v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13015">
<div class="article-summary-box-inner">
<span><p>We study the vision transformer structure in the mobile level in this paper,
and find a dramatic performance drop. We analyze the reason behind this
phenomenon, and propose a novel irregular patch embedding module and adaptive
patch fusion module to improve the performance. We conjecture that the vision
transformer blocks (which consist of multi-head attention and feed-forward
network) are more suitable to handle high-level information than low-level
features. The irregular patch embedding module extracts patches that contain
rich high-level information with different receptive fields. The transformer
blocks can obtain the most useful information from these irregular patches.
Then the processed patches pass the adaptive patch merging module to get the
final features for the classifier. With our proposed improvements, the
traditional uniform vision transformer structure can achieve state-of-the-art
results in mobile level. We improve the DeiT baseline by more than 9\% under
the mobile-level settings and surpass other transformer architectures like Swin
and CoaT by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What You Can Learn by Staring at a Blank Wall. (arXiv:2108.13027v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13027">
<div class="article-summary-box-inner">
<span><p>We present a passive non-line-of-sight method that infers the number of
people or activity of a person from the observation of a blank wall in an
unknown room. Our technique analyzes complex imperceptible changes in indirect
illumination in a video of the wall to reveal a signal that is correlated with
motion in the hidden part of a scene. We use this signal to classify between
zero, one, or two moving people, or the activity of a person in the hidden
scene. We train two convolutional neural networks using data collected from 20
different scenes, and achieve an accuracy of $\approx94\%$ for both tasks in
unseen test environments and real-time online settings. Unlike other passive
non-line-of-sight methods, the technique does not rely on known occluders or
controllable light sources, and generalizes to unknown rooms with no
re-calibration. We analyze the generalization and robustness of our method with
both real and synthetic data, and study the effect of the scene parameters on
the signal quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Visual Recognition with Deep Neural Networks: A Survey on Recent Advances and New Directions. (arXiv:2108.13055v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13055">
<div class="article-summary-box-inner">
<span><p>Visual recognition is currently one of the most important and active research
areas in computer vision, pattern recognition, and even the general field of
artificial intelligence. It has great fundamental importance and strong
industrial needs. Deep neural networks (DNNs) have largely boosted their
performances on many concrete tasks, with the help of large amounts of training
data and new powerful computation resources. Though recognition accuracy is
usually the first concern for new progresses, efficiency is actually rather
important and sometimes critical for both academic research and industrial
applications. Moreover, insightful views on the opportunities and challenges of
efficiency are also highly required for the entire community. While general
surveys on the efficiency issue of DNNs have been done from various
perspectives, as far as we are aware, scarcely any of them focused on visual
recognition systematically, and thus it is unclear which progresses are
applicable to it and what else should be concerned. In this paper, we present
the review of the recent advances with our suggestions on the new possible
directions towards improving the efficiency of DNN-related visual recognition
approaches. We investigate not only from the model but also the data point of
view (which is not the case in existing surveys), and focus on three most
studied data types (images, videos and points). This paper attempts to provide
a systematic summary via a comprehensive survey which can serve as a valuable
reference and inspire both researchers and practitioners who work on visual
recognition problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Monocular Depth Perception: Focusing on Moving Objects. (arXiv:2108.13062v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13062">
<div class="article-summary-box-inner">
<span><p>As a flexible passive 3D sensing means, unsupervised learning of depth from
monocular videos is becoming an important research topic. It utilizes the
photometric errors between the target view and the synthesized views from its
adjacent source views as the loss instead of the difference from the ground
truth. Occlusion and scene dynamics in real-world scenes still adversely affect
the learning, despite significant progress made recently. In this paper, we
show that deliberately manipulating photometric errors can efficiently deal
with these difficulties better. We first propose an outlier masking technique
that considers the occluded or dynamic pixels as statistical outliers in the
photometric error map. With the outlier masking, the network learns the depth
of objects that move in the opposite direction to the camera more accurately.
To the best of our knowledge, such cases have not been seriously considered in
the previous works, even though they pose a high risk in applications like
autonomous driving. We also propose an efficient weighted multi-scale scheme to
reduce the artifacts in the predicted depth maps. Extensive experiments on the
KITTI dataset and additional experiments on the Cityscapes dataset have
verified the proposed approach's effectiveness on depth or ego-motion
estimation. Furthermore, for the first time, we evaluate the predicted depth on
the regions of dynamic objects and static background separately for both
supervised and unsupervised methods. The evaluation further verifies the
effectiveness of our proposed technical approach and provides some interesting
observations that might inspire future research in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Vulnerabilities of Deep Neural Policies. (arXiv:2108.13093v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13093">
<div class="article-summary-box-inner">
<span><p>Reinforcement learning policies based on deep neural networks are vulnerable
to imperceptible adversarial perturbations to their inputs, in much the same
way as neural network image classifiers. Recent work has proposed several
methods to improve the robustness of deep reinforcement learning agents to
adversarial perturbations based on training in the presence of these
imperceptible perturbations (i.e. adversarial training). In this paper, we
study the effects of adversarial training on the neural policy learned by the
agent. In particular, we follow two distinct parallel approaches to investigate
the outcomes of adversarial training on deep neural policies based on
worst-case distributional shift and feature sensitivity. For the first
approach, we compare the Fourier spectrum of minimal perturbations computed for
both adversarially trained and vanilla trained neural policies. Via experiments
in the OpenAI Atari environments we show that minimal perturbations computed
for adversarially trained policies are more focused on lower frequencies in the
Fourier domain, indicating a higher sensitivity of these policies to low
frequency perturbations. For the second approach, we propose a novel method to
measure the feature sensitivities of deep neural policies and we compare these
feature sensitivity differences in state-of-the-art adversarially trained deep
neural policies and vanilla trained deep neural policies. We believe our
results can be an initial step towards understanding the relationship between
adversarial training and different notions of robustness for neural policies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object-aware Long-short-range Spatial Alignment for Few-Shot Fine-Grained Image Classification. (arXiv:2108.13098v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13098">
<div class="article-summary-box-inner">
<span><p>The goal of few-shot fine-grained image classification is to recognize rarely
seen fine-grained objects in the query set, given only a few samples of this
class in the support set. Previous works focus on learning discriminative image
features from a limited number of training samples for distinguishing various
fine-grained classes, but ignore one important fact that spatial alignment of
the discriminative semantic features between the query image with arbitrary
changes and the support image, is also critical for computing the semantic
similarity between each support-query pair. In this work, we propose an
object-aware long-short-range spatial alignment approach, which is composed of
a foreground object feature enhancement (FOE) module, a long-range semantic
correspondence (LSC) module and a short-range spatial manipulation (SSM)
module. The FOE is developed to weaken background disturbance and encourage
higher foreground object response. To address the problem of long-range object
feature misalignment between support-query image pairs, the LSC is proposed to
learn the transferable long-range semantic correspondence by a designed feature
similarity metric. Further, the SSM module is developed to refine the
transformed support feature after the long-range step to align short-range
misaligned features (or local details) with the query features. Extensive
experiments have been conducted on four benchmark datasets, and the results
show superior performance over most state-of-the-art methods under both 1-shot
and 5-shot classification scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Densely Semantic Enhancement for Domain Adaptive Region-free Detectors. (arXiv:2108.13101v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13101">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptive object detection aims to adapt a well-trained
detector from its original source domain with rich labeled data to a new target
domain with unlabeled data. Previous works focus on improving the domain
adaptability of region-based detectors, e.g., Faster-RCNN, through matching
cross-domain instance-level features that are explicitly extracted from a
region proposal network (RPN). However, this is unsuitable for region-free
detectors such as single shot detector (SSD), which perform a dense prediction
from all possible locations in an image and do not have the RPN to encode such
instance-level features. As a result, they fail to align important image
regions and crucial instance-level features between the domains of region-free
detectors. In this work, we propose an adversarial module to strengthen the
cross-domain matching of instance-level features for region-free detectors.
Firstly, to emphasize the important regions of image, the DSEM learns to
predict a transferable foreground enhancement mask that can be utilized to
suppress the background disturbance in an image. Secondly, considering that
region-free detectors recognize objects of different scales using multi-scale
feature maps, the DSEM encodes both multi-level semantic representations and
multi-instance spatial-contextual relationships across different domains.
Finally, the DSEM is pluggable into different region-free detectors, ultimately
achieving the densely semantic feature matching via adversarial learning.
Extensive experiments have been conducted on PASCAL VOC, Clipart, Comic,
Watercolor, and FoggyCityscape benchmarks, and their results well demonstrate
that the proposed approach not only improves the domain adaptability of
region-free detectors but also outperforms existing domain adaptive
region-based detectors under various domain shift settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Preprocessing and Ensemble Learning for Low Quality Cell Image Segmentation. (arXiv:2108.13118v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13118">
<div class="article-summary-box-inner">
<span><p>We propose an automatic preprocessing and ensemble learning for segmentation
of cell images with low quality. It is difficult to capture cells with strong
light. Therefore, the microscopic images of cells tend to have low image
quality but these images are not good for semantic segmentation. Here we
propose a method to translate an input image to the images that are easy to
recognize by deep learning. The proposed method consists of two deep neural
networks. The first network is the usual training for semantic segmentation,
and penultimate feature maps of the first network are used as filters to
translate an input image to the images that emphasize each class. This is the
automatic preprocessing and translated cell images are easily classified. The
input cell image with low quality is translated by the feature maps in the
first network, and the translated images are fed into the second network for
semantic segmentation. Since the outputs of the second network are multiple
segmentation results, we conduct the weighted ensemble of those segmentation
images. Two networks are trained by end-to-end manner, and we do not need to
prepare images with high quality for the translation. We confirmed that our
proposed method can translate cell images with low quality to the images that
are easy to segment, and segmentation accuracy has improved using the weighted
ensemble learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tune It or Don't Use It: Benchmarking Data-Efficient Image Classification. (arXiv:2108.13122v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13122">
<div class="article-summary-box-inner">
<span><p>Data-efficient image classification using deep neural networks in settings,
where only small amounts of labeled data are available, has been an active
research area in the recent past. However, an objective comparison between
published methods is difficult, since existing works use different datasets for
evaluation and often compare against untuned baselines with default
hyper-parameters. We design a benchmark for data-efficient image classification
consisting of six diverse datasets spanning various domains (e.g., natural
images, medical imagery, satellite data) and data types (RGB, grayscale,
multispectral). Using this benchmark, we re-evaluate the standard cross-entropy
baseline and eight methods for data-efficient deep learning published between
2017 and 2021 at renowned venues. For a fair and realistic comparison, we
carefully tune the hyper-parameters of all methods on each dataset.
Surprisingly, we find that tuning learning rate, weight decay, and batch size
on a separate validation split results in a highly competitive baseline, which
outperforms all but one specialized method and performs competitively to the
remaining one.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From General to Specific: Informative Scene Graph Generation via Balance Adjustment. (arXiv:2108.13129v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13129">
<div class="article-summary-box-inner">
<span><p>The scene graph generation (SGG) task aims to detect visual relationship
triplets, i.e., subject, predicate, object, in an image, providing a structural
vision layout for scene understanding. However, current models are stuck in
common predicates, e.g., "on" and "at", rather than informative ones, e.g.,
"standing on" and "looking at", resulting in the loss of precise information
and overall performance. If a model only uses "stone on road" rather than
"blocking" to describe an image, it is easy to misunderstand the scene. We
argue that this phenomenon is caused by two key imbalances between informative
predicates and common ones, i.e., semantic space level imbalance and training
sample level imbalance. To tackle this problem, we propose BA-SGG, a simple yet
effective SGG framework based on balance adjustment but not the conventional
distribution fitting. It integrates two components: Semantic Adjustment (SA)
and Balanced Predicate Learning (BPL), respectively for adjusting these
imbalances. Benefited from the model-agnostic process, our method is easily
applied to the state-of-the-art SGG models and significantly improves the SGG
performance. Our method achieves 14.3%, 8.0%, and 6.1% higher Mean Recall (mR)
than that of the Transformer model at three scene graph generation sub-tasks on
Visual Genome, respectively. Codes are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Privacy-Preserving Motion Detection and Object Tracking in Encrypted Streaming Video. (arXiv:2108.13141v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13141">
<div class="article-summary-box-inner">
<span><p>Video privacy leakage is becoming an increasingly severe public problem,
especially in cloud-based video surveillance systems. It leads to the new need
for secure cloud-based video applications, where the video is encrypted for
privacy protection. Despite some methods that have been proposed for encrypted
video moving object detection and tracking, none has robust performance against
complex and dynamic scenes. In this paper, we propose an efficient and robust
privacy-preserving motion detection and multiple object tracking scheme for
encrypted surveillance video bitstreams. By analyzing the properties of the
video codec and format-compliant encryption schemes, we propose a new
compressed-domain feature to capture motion information in complex surveillance
scenarios. Based on this feature, we design an adaptive clustering algorithm
for moving object segmentation with an accuracy of 4x4 pixels. We then propose
a multiple object tracking scheme that uses Kalman filter estimation and
adaptive measurement refinement. The proposed scheme does not require video
decryption or full decompression and has a very low computation load. The
experimental results demonstrate that our scheme achieves the best detection
and tracking performance compared with existing works in the encrypted and
compressed domain. Our scheme can be effectively used in complex surveillance
scenarios with different challenges, such as camera movement/jitter, dynamic
background, and shadows.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LIGAR: Lightweight General-purpose Action Recognition. (arXiv:2108.13153v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13153">
<div class="article-summary-box-inner">
<span><p>Growing amount of different practical tasks in a video understanding problem
has addressed the great challenge aiming to design an universal solution, which
should be available for broad masses and suitable for the demanding
edge-oriented inference. In this paper we are focused on designing a network
architecture and a training pipeline to tackle the mentioned challenges. Our
architecture takes the best from the previous ones and brings the ability to be
successful not only in appearance-based action recognition tasks but in
motion-based problems too. Furthermore, the induced label noise problem is
formulated and Adaptive Clip Selection (ACS) framework is proposed to deal with
it. Together it makes the LIGAR framework the general-purpose action
recognition solution. We also have reported the extensive analysis on the
general and gesture datasets to show the excellent trade-off between the
performance and the accuracy in comparison to the state-of-the-art solutions.
Training code is available at:
https://github.com/openvinotoolkit/training_extensions. For the efficient
edge-oriented inference all trained models can be exported into the OpenVINO
format.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enterprise Architecture Model Transformation Engine. (arXiv:2108.13169v1 [cs.DC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13169">
<div class="article-summary-box-inner">
<span><p>With increasing linkage within value chains, the IT systems of different
companies are also being connected with each other. This enables the
integration of services within the movement of Industry 4.0 in order to improve
the quality and performance of the processes. Enterprise architecture models
form the basis for this with a better buisness IT-alignment. However, the
heterogeneity of the modeling frameworks and description languages makes a
concatenation considerably difficult, especially differences in syntax,
semantic and relations. Therefore, this paper presents a transformation engine
to convert enterprise architecture models between several languages. We
developed the first generic translation approach that is free of specific
meta-modeling, which is flexible adaptable to arbitrary modeling languages. The
transformation process is defined by various pattern matching techniques using
a rule-based description language. It uses set theory and first-order logic for
an intuitive description as a basis. The concept is practical evaluated using
an example in the area of a large German IT-service provider. Anyhow, the
approach is applicable between a wide range of enterprise architecture
frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Domain Randomization. (arXiv:1812.00491v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1812.00491">
<div class="article-summary-box-inner">
<span><p>Domain Randomization (DR) is known to require a significant amount of
training data for good performance. We argue that this is due to DR's strategy
of random data generation using a uniform distribution over simulation
parameters, as a result, DR often generates samples which are uninformative for
the learner. In this work, we theoretically analyze DR using ideas from
multi-source domain adaptation. Based on our findings, we propose Adversarial
Domain Randomization (ADR) as an efficient variant of DR which generates
adversarial samples with respect to the learner during training. We implement
ADR as a policy whose action space is the quantized simulation parameter space.
At each iteration, the policy's action generates labeled data and the reward is
set as negative of learner's loss on this data. As a result, we observe ADR
frequently generates novel samples for the learner like truncated and occluded
objects for object detection and confusing classes for image classification. We
perform evaluations on datasets like CLEVR, Syn2Real, and VIRAT for various
tasks where we demonstrate that ADR outperforms DR by generating fewer data
samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inner-Imaging Networks: Put Lenses into Convolutional Structure. (arXiv:1904.12639v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.12639">
<div class="article-summary-box-inner">
<span><p>Despite the tremendous success in computer vision, deep convolutional
networks suffer from serious computation costs and redundancies. Although
previous works address this issue by enhancing diversities of filters, they
have not considered the complementarity and the completeness of the internal
structure of the convolutional network. To deal with these problems, a novel
Inner-Imaging architecture is proposed in this paper, which allows
relationships between channels to meet the above requirement. Specifically, we
organize the channel signal points in groups using convolutional kernels to
model both the intra-group and inter-group relationships simultaneously. The
convolutional filter is a powerful tool for modeling spatial relations and
organizing grouped signals, so the proposed methods map the channel signals
onto a pseudo-image, like putting a lens into convolution internal structure.
Consequently, not only the diversity of channels is increased, but also the
complementarity and completeness can be explicitly enhanced. The proposed
architecture is lightweight and easy to be implemented. It provides an
efficient self-organization strategy for convolutional networks so as to
improve their efficiency and performance. Extensive experiments are conducted
on multiple benchmark image recognition data sets including CIFAR, SVHN and
ImageNet. Experimental results verify the effectiveness of the Inner-Imaging
mechanism with the most popular convolutional networks as the backbones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Signal2Image Modules in Deep Neural Networks for EEG Classification. (arXiv:1904.13216v6 [eess.SP] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.13216">
<div class="article-summary-box-inner">
<span><p>Deep learning has revolutionized computer vision utilizing the increased
availability of big data and the power of parallel computational units such as
graphical processing units. The vast majority of deep learning research is
conducted using images as training data, however the biomedical domain is rich
in physiological signals that are used for diagnosis and prediction problems.
It is still an open research question how to best utilize signals to train deep
neural networks.
</p>
<p>In this paper we define the term Signal2Image (S2Is) as trainable or
non-trainable prefix modules that convert signals, such as
Electroencephalography (EEG), to image-like representations making them
suitable for training image-based deep neural networks defined as `base
models'. We compare the accuracy and time performance of four S2Is (`signal as
image', spectrogram, one and two layer Convolutional Neural Networks (CNNs))
combined with a set of `base models' (LeNet, AlexNet, VGGnet, ResNet, DenseNet)
along with the depth-wise and 1D variations of the latter. We also provide
empirical evidence that the one layer CNN S2I performs better in eleven out of
fifteen tested models than non-trainable S2Is for classifying EEG signals and
we present visual comparisons of the outputs of the S2Is.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparsely Activated Networks. (arXiv:1907.06592v7 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.06592">
<div class="article-summary-box-inner">
<span><p>Previous literature on unsupervised learning focused on designing structural
priors with the aim of learning meaningful features. However, this was done
without considering the description length of the learned representations which
is a direct and unbiased measure of the model complexity. In this paper, first
we introduce the $\varphi$ metric that evaluates unsupervised models based on
their reconstruction accuracy and the degree of compression of their internal
representations. We then present and define two activation functions (Identity,
ReLU) as base of reference and three sparse activation functions (top-k
absolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize
the previously defined $\varphi$. We lastly present Sparsely Activated Networks
(SANs) that consist of kernels with shared weights that, during encoding, are
convolved with the input and then passed through a sparse activation function.
During decoding, the same weights are convolved with the sparse activation map
and subsequently the partial reconstructions from each weight are summed to
reconstruct the input. We compare SANs using the five previously defined
activation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST,
FMNIST) and show that models that are selected using $\varphi$ have small
description representation length and consist of interpretable kernels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Explanation for Deep Metric Learning. (arXiv:1909.12977v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.12977">
<div class="article-summary-box-inner">
<span><p>This work explores the visual explanation for deep metric learning and its
applications. As an important problem for learning representation, metric
learning has attracted much attention recently, while the interpretation of
such model is not as well studied as classification. To this end, we propose an
intuitive idea to show where contributes the most to the overall similarity of
two input images by decomposing the final activation. Instead of only providing
the overall activation map of each image, we propose to generate point-to-point
activation intensity between two images so that the relationship between
different regions is uncovered. We show that the proposed framework can be
directly deployed to a large range of metric learning applications and provides
valuable information for understanding the model. Furthermore, our experiments
show its effectiveness on two potential applications, i.e. cross-view pattern
discovery and interactive retrieval. The source code is available at
\url{https://github.com/Jeff-Zilence/Explain_Metric_Learning}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Scale Open-Set Deep Logo Detection. (arXiv:1911.07440v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.07440">
<div class="article-summary-box-inner">
<span><p>We present an open-set logo detection (OSLD) system, which can detect
(localize and recognize) any number of unseen logo classes without re-training;
it only requires a small set of canonical logo images for each logo class. We
achieve this using a two-stage approach: (1) Generic logo detection to detect
candidate logo regions in an image. (2) Logo matching for matching the detected
logo regions to a set of canonical logo images to recognize them. We also
introduce a 'simple deep metric learning' (SDML) framework that outperformed
more complicated ensemble and attention models and boosted the logo matching
accuracy. Furthermore, we constructed an open-set logo detection dataset with
12.1k logo classes and released it for research purposes. We demonstrate the
effectiveness of OSLD on our dataset and on the standard Flickr-32 logo
dataset, outperforming the state-of-the-art open-set and closed-set logo
detection methods by a large margin. OSLD is scalable to millions of logo
classes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Learning with Common Sense Knowledge Graphs. (arXiv:2006.10713v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10713">
<div class="article-summary-box-inner">
<span><p>Zero-shot learning relies on semantic class representations such as
hand-engineered attributes or learned embeddings to predict classes without any
labeled examples. We propose to learn class representations by embedding nodes
from common sense knowledge graphs in a vector space. Common sense knowledge
graphs are an untapped source of explicit high-level knowledge that requires
little human effort to apply to a range of tasks. To capture the knowledge in
the graph, we introduce ZSL-KG, a general-purpose framework with a novel
transformer graph convolutional network (TrGCN) for generating class
representations. Our proposed TrGCN architecture computes non-linear
combinations of node neighbourhoods. Our results show that ZSL-KG improves over
existing WordNet-based methods on five out of six zero-shot benchmark datasets
in language and vision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptation without Source Data. (arXiv:2007.01524v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01524">
<div class="article-summary-box-inner">
<span><p>Domain adaptation assumes that samples from source and target domains are
freely accessible during a training phase. However, such an assumption is
rarely plausible in the real-world and possibly causes data-privacy issues,
especially when the label of the source domain can be a sensitive attribute as
an identifier. To avoid accessing source data that may contain sensitive
information, we introduce Source data-Free Domain Adaptation (SFDA). Our key
idea is to leverage a pre-trained model from the source domain and
progressively update the target model in a self-learning manner. We observe
that target samples with lower self-entropy measured by the pre-trained source
model are more likely to be classified correctly. From this, we select the
reliable samples with the self-entropy criterion and define these as class
prototypes. We then assign pseudo labels for every target sample based on the
similarity score with class prototypes. Furthermore, to reduce the uncertainty
from the pseudo labeling process, we propose set-to-set distance-based
filtering which does not require any tunable hyperparameters. Finally, we train
the target model with the filtered pseudo labels with regularization from the
pre-trained source model. Surprisingly, without direct usage of labeled source
samples, our PrDA outperforms conventional domain adaptation methods on
benchmark datasets. Our code is publicly available at
https://github.com/youngryan1993/SFDA-SourceFreeDA
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Video Representations from Textual Web Supervision. (arXiv:2007.14937v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14937">
<div class="article-summary-box-inner">
<span><p>Videos on the Internet are paired with pieces of text, such as titles and
descriptions. This text typically describes the most important content in the
video, such as the objects in the scene and the actions being performed. Based
on this observation, we propose to use text as a method for learning video
representations. To accomplish this, we propose a data collection process and
use it to collect 70M video clips shared publicly on the Internet, and we then
train a model to pair each video with its associated text. We evaluate the
model on several down-stream action recognition tasks, including Kinetics,
HMDB-51, and UCF-101. We find that this approach is an effective method of
pre-training video representations. Specifically, it outperforms all existing
methods for self-supervised and cross-modal video representation learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From noisy point clouds to complete ear shapes: unsupervised pipeline. (arXiv:2008.09831v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.09831">
<div class="article-summary-box-inner">
<span><p>Ears are a particularly difficult region of the human face to model, not only
due to the non-rigid deformations existing between shapes but also to the
challenges in processing the retrieved data. The first step towards obtaining a
good model is to have complete scans in correspondence, but these usually
present a higher amount of occlusions, noise and outliers when compared to most
face regions, thus requiring a specific procedure. Therefore, we propose a
complete pipeline taking as input unordered 3D point clouds with the
aforementioned problems, and producing as output a dataset in correspondence,
with completion of the missing data. We provide a comparison of several
state-of-the-art registration methods and propose a new approach for one of the
steps of the pipeline, with better performance for our data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DPN: Detail-Preserving Network with High Resolution Representation for Efficient Segmentation of Retinal Vessels. (arXiv:2009.12053v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12053">
<div class="article-summary-box-inner">
<span><p>Retinal vessels are important biomarkers for many ophthalmological and
cardiovascular diseases. Hence, it is of great significance to develop
automatic models for computer-aided diagnosis. Existing methods, such as U-Net
follow the encoder-decoder pipeline, where detailed information is lost in the
encoder in order to achieve a large field of view. Although spatial detailed
information could be recovered partly in the decoder, while there is noise in
the high-resolution feature maps of the encoder. And, we argue this
encoder-decoder architecture is inefficient for vessel segmentation. In this
paper, we present the detail-preserving network (DPN), which avoids the
encoder-decoder pipeline. To preserve detailed information and learn structural
information simultaneously, we designed the detail-preserving block (DP-Block).
Further, we stacked eight DP-Blocks together to form the DPN. More importantly,
there are no down-sampling operations among these blocks. Therefore, the DPN
could maintain a high/full resolution during processing, avoiding the loss of
detailed information. To illustrate the effectiveness of DPN, we conducted
experiments over three public datasets. Experimental results show, compared to
state-of-the-art methods, DPN shows competitive/better performance in terms of
segmentation accuracy, segmentation speed, and model size. Specifically, 1) Our
method achieves comparable segmentation performance on the DRIVE, CHASE_DB1,
and HRF datasets. 2) The segmentation speed of DPN is over 20-160 times faster
than other methods on the DRIVE dataset. 3) The number of parameters of DPN is1
around 120k, far less than all comparison methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SeasonDepth: Cross-Season Monocular Depth Prediction Dataset and Benchmark under Multiple Environments. (arXiv:2011.04408v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04408">
<div class="article-summary-box-inner">
<span><p>Different environments pose a great challenge on the outdoor robust visual
perception for long-term autonomous driving and the generalization of
learning-based algorithms on different environmental effects is still an open
problem. Although monocular depth prediction has been well studied recently,
there is few work focusing on the robust learning-based depth prediction across
different environments, e.g., changing illumination and seasons, owing to the
lack of such a multi-environment real-world dataset and benchmark. To this end,
the first cross-season monocular depth prediction dataset and benchmark
SeasonDepth (available on https://seasondepth.github.io) is built based on CMU
Visual Localization dataset. To benchmark the depth estimation performance
under different environments, we investigate representative and recent
state-of-the-art open-source supervised, self-supervised and domain adaptation
depth prediction methods from KITTI benchmark using several newly-formulated
metrics. Through extensive experimental evaluation on the proposed dataset, the
influence of multiple environments on performance and robustness is analyzed
both qualitatively and quantitatively, showing that the long-term monocular
depth prediction is still challenging even with fine-tuning. We further give
promising avenues that self-supervised training and stereo geometry constraint
help to enhance the robustness to changing environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuous Conditional Generative Adversarial Networks: Novel Empirical Losses and Label Input Mechanisms. (arXiv:2011.07466v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07466">
<div class="article-summary-box-inner">
<span><p>This work proposes the continuous conditional generative adversarial network
(CcGAN), the first generative model for image generation conditional on
continuous, scalar conditions (termed regression labels). Existing conditional
GANs (cGANs) are mainly designed for categorical conditions (eg, class labels);
conditioning on regression labels is mathematically distinct and raises two
fundamental problems:(P1) Since there may be very few (even zero) real images
for some regression labels, minimizing existing empirical versions of cGAN
losses (aka empirical cGAN losses) often fails in practice;(P2) Since
regression labels are scalar and infinitely many, conventional label input
methods are not applicable. The proposed CcGAN solves the above problems,
respectively, by (S1) reformulating existing empirical cGAN losses to be
appropriate for the continuous scenario; and (S2) proposing a naive label input
(NLI) method and an improved label input (ILI) method to incorporate regression
labels into the generator and the discriminator. The reformulation in (S1)
leads to two novel empirical discriminator losses, termed the hard vicinal
discriminator loss (HVDL) and the soft vicinal discriminator loss (SVDL)
respectively, and a novel empirical generator loss. The error bounds of a
discriminator trained with HVDL and SVDL are derived under mild assumptions in
this work. Two new benchmark datasets (RC-49 and Cell-200) and a novel
evaluation metric (Sliding Fr\'echet Inception Distance) are also proposed for
this continuous scenario. Our experiments on the Circular 2-D Gaussians, RC-49,
UTKFace, Cell-200, and Steering Angle datasets show that CcGAN is able to
generate diverse, high-quality samples from the image distribution conditional
on a given regression label. Moreover, in these experiments, CcGAN
substantially outperforms cGAN both visually and quantitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Siamese Basis Function Network for Data Efficient Defect Classification in Technical Domains. (arXiv:2012.01338v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01338">
<div class="article-summary-box-inner">
<span><p>Training Deep Learning Models in technical domains often brings the
challenges that although the task is clear, insufficient data for training is
available. In this work we propose a novel approach based on the combination of
Siamese-Networks and Radial-Basis- Function-Networks to perform data-efficient
classification without pre-Training by measuring the distance between images in
semantic space in a data efficient manner. We develop the models using three
technical datasets, the NEU dataset the BSD dataset as well as the TEX dataset.
Additional to the technical domain show the general applicability to classical
datasets (cifar10 and MNIST) as well. The approach is tested against state of
the art models (Resnet50 and Resnet101) by stepwise reducing the number of
samples available for training. The authors show that the proposed approach
outperforms the state of the art models in the low data regime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Layer Distillation with Semantic Calibration. (arXiv:2012.03236v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03236">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation is a technique to enhance the generalization ability
of a student model by exploiting outputs from a teacher model. Recently,
feature-map based variants explore knowledge transfer between manually assigned
teacher-student pairs in intermediate layers for further improvement. However,
layer semantics may vary in different neural networks and semantic mismatch in
manual layer associations will lead to performance degeneration due to negative
regularization. To address this issue, we propose Semantic Calibration for
cross-layer Knowledge Distillation (SemCKD), which automatically assigns proper
target layers of the teacher model for each student layer with an attention
mechanism. With a learned attention distribution, each student layer distills
knowledge contained in multiple teacher layers rather than a specific
intermediate layer for appropriate cross-layer supervision. We further provide
theoretical analysis of the association weights and conduct extensive
experiments to demonstrate the effectiveness of our approach. Code is avaliable
at \url{https://github.com/DefangChen/SemCKD}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Mining Generation of Lung Cancer Malignancy Models from Chest X-ray Images. (arXiv:2012.05447v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05447">
<div class="article-summary-box-inner">
<span><p>Lung cancer is the leading cause of cancer death and morbidity worldwide.
Many studies have shown machine learning models to be effective at detecting
lung nodules from chest X-ray images. However, these techniques have yet to be
embraced by the medical community due to several practical, ethical, and
regulatory constraints stemming from the black-box nature of deep learning
models. Additionally, most lung nodules visible on chest X-ray are benign;
therefore, the narrow task of computer vision-based lung nodule detection
cannot be equated to automated lung cancer detection. Addressing both concerns,
this study introduces a novel hybrid deep learning and decision tree-based
computer vision model which presents lung cancer malignancy predictions as
interpretable decision trees. The deep learning component of this process is
trained using a large publicly available dataset on pathological biomarkers
associated with lung cancer. These models are then used to inference biomarker
scores for chest X-ray images from two, independent data sets for which
malignancy metadata is available. We mine multi-variate predictive models by
fitting shallow decision trees to the malignancy stratified datasets and
interrogate a range of metrics to determine the best model. Our best decision
tree model achieves sensitivity and specificity of 86.7% and 80.0% respectively
with a positive predictive value of 92.9%. Decision trees mined using this
method may be considered as a starting point for refinement into clinically
useful multi-variate lung cancer malignancy models for implementation as a
workflow augmentation tool to improve the efficiency of human radiologists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effect of the regularization hyperparameter on deep learning-based segmentation in LGE-MRI. (arXiv:2012.05661v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05661">
<div class="article-summary-box-inner">
<span><p>The extent to which the arbitrarily selected L2 regularization hyperparameter
value affects the outcome of semantic segmentation with deep learning is
demonstrated. Demonstrations rely on training U-net on small LGE-MRI datasets
using the arbitrarily selected L2 regularization values. The remaining
hyperparameters are to be manually adjusted or tuned only when 10 % of all
epochs are reached before the training validation accuracy reaches 90%.
Semantic segmentation with deep learning outcomes are objectively and
subjectively evaluated against the manual ground truth segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of deep learning-based myocardial infarction quantification using Segment CMR software. (arXiv:2012.09070v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09070">
<div class="article-summary-box-inner">
<span><p>This work evaluates deep learning-based myocardial infarction (MI)
quantification using Segment cardiovascular magnetic resonance (CMR) software.
Segment CMR software incorporates the expectation-maximization, weighted
intensity, a priori information (EWA) algorithm used to generate the infarct
scar volume, infarct scar percentage, and microvascular obstruction percentage.
Also, Segment CMR software segmentation algorithm is updated with accurate
semantic segmentation with U-net for fully automated or deep learning-based MI
quantification. The direct observation of graphs and the number of infarcted
and contoured myocardium are two options used to estimate the relationship
between deep learning-based MI quantification and medical expert-based results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Power Normalizations in Fine-grained Image, Few-shot Image and Graph Classification. (arXiv:2012.13975v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13975">
<div class="article-summary-box-inner">
<span><p>Power Normalizations (PN) are useful non-linear operators which tackle
feature imbalances in classification problems. We study PNs in the deep
learning setup via a novel PN layer pooling feature maps. Our layer combines
the feature vectors and their respective spatial locations in the feature maps
produced by the last convolutional layer of CNN into a positive definite matrix
with second-order statistics to which PN operators are applied, forming
so-called Second-order Pooling (SOP). As the main goal of this paper is to
study Power Normalizations, we investigate the role and meaning of MaxExp and
Gamma, two popular PN functions. To this end, we provide probabilistic
interpretations of such element-wise operators and discover surrogates with
well-behaved derivatives for end-to-end training. Furthermore, we look at the
spectral applicability of MaxExp and Gamma by studying Spectral Power
Normalizations (SPN). We show that SPN on the autocorrelation/covariance matrix
and the Heat Diffusion Process (HDP) on a graph Laplacian matrix are closely
related, thus sharing their properties. Such a finding leads us to the
culmination of our work, a fast spectral MaxExp which is a variant of HDP for
covariances/autocorrelation matrices. We evaluate our ideas on fine-grained
recognition, scene recognition, and material classification, as well as in
few-shot learning and graph classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tensor Representations for Action Recognition. (arXiv:2012.14371v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14371">
<div class="article-summary-box-inner">
<span><p>Human actions in video sequences are characterized by the complex interplay
between spatial features and their temporal dynamics. In this paper, we propose
novel tensor representations for compactly capturing such higher-order
relationships between visual features for the task of action recognition. We
propose two tensor-based feature representations, viz. (i) sequence
compatibility kernel (SCK) and (ii) dynamics compatibility kernel (DCK). SCK
builds on the spatio-temporal correlations between features, whereas DCK
explicitly models the action dynamics of a sequence. We also explore
generalization of SCK, coined SCK(+), that operates on subsequences to capture
the local-global interplay of correlations, which can incorporate multi-modal
inputs e.g., skeleton 3D body-joints and per-frame classifier scores obtained
from deep learning models trained on videos. We introduce linearization of
these kernels that lead to compact and fast descriptors. We provide experiments
on (i) 3D skeleton action sequences, (ii) fine-grained video sequences, and
(iii) standard non-fine-grained videos. As our final representations are
tensors that capture higher-order relationships of features, they relate to
co-occurrences for robust fine-grained recognition. We use higher-order tensors
and so-called Eigenvalue Power Normalization (EPN) which have been long
speculated to perform spectral detection of higher-order occurrences, thus
detecting fine-grained relationships of features rather than merely count
features in action sequences. We prove that a tensor of order r, built from Z*
dimensional features, coupled with EPN indeed detects if at least one
higher-order occurrence is `projected' into one of its binom(Z*,r) subspaces of
dim. r represented by the tensor, thus forming a Tensor Power Normalization
metric endowed with binom(Z*,r) such `detectors'.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mining Data Impressions from Deep Models as Substitute for the Unavailable Training Data. (arXiv:2101.06069v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06069">
<div class="article-summary-box-inner">
<span><p>Pretrained deep models hold their learnt knowledge in the form of model
parameters. These parameters act as "memory" for the trained models and help
them generalize well on unseen data. However, in absence of training data, the
utility of a trained model is merely limited to either inference or better
initialization towards a target task. In this paper, we go further and extract
synthetic data by leveraging the learnt model parameters. We dub them "Data
Impressions", which act as proxy to the training data and can be used to
realize a variety of tasks. These are useful in scenarios where only the
pretrained models are available and the training data is not shared (e.g., due
to privacy or sensitivity concerns). We show the applicability of data
impressions in solving several computer vision tasks such as unsupervised
domain adaptation, continual learning as well as knowledge distillation. We
also study the adversarial robustness of lightweight models trained via
knowledge distillation using these data impressions. Further, we demonstrate
the efficacy of data impressions in generating data-free Universal Adversarial
Perturbations (UAPs) with better fooling rates. Extensive experiments performed
on benchmark datasets demonstrate competitive performance achieved using data
impressions in absence of original training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-driven Self-supervised Bi-channel Networks for Diagnosis of Breast Cancers with Mammography. (arXiv:2101.06228v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06228">
<div class="article-summary-box-inner">
<span><p>Deep learning can promote the mammography-based computer-aided diagnosis
(CAD) for breast cancers, but it generally suffers from the small sample size
problem. Self-supervised learning (SSL) has shown its effectiveness in medical
image analysis with limited training samples. However, the network model
sometimes cannot be well pre-trained in the conventional SSL framework due to
the limitation of the pretext task and fine-tuning mechanism. In this work, a
Task-driven Self-supervised Bi-channel Networks (TSBN) framework is proposed to
improve the performance of classification model the mammography-based CAD. In
particular, a new gray-scale image mapping (GSIM) is designed as the pretext
task, which embeds the class label information of mammograms into the image
restoration task to improve discriminative feature representation. The proposed
TSBN then innovatively integrates different network architecture, including the
image restoration network and the classification network, into a unified SSL
framework. It jointly trains the bi-channel network models and collaboratively
transfers the knowledge from the pretext task network to the downstream task
network with improved diagnostic accuracy. The proposed TSBN is evaluated on a
public INbreast mammogram dataset. The experimental results indicate that it
outperforms the conventional SSL and multi-task learning algorithms for
diagnosis of breast cancers with limited samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Attribution Maps with Disentangled Masked Backpropagation. (arXiv:2101.06773v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06773">
<div class="article-summary-box-inner">
<span><p>Attribution map visualization has arisen as one of the most effective
techniques to understand the underlying inference process of Convolutional
Neural Networks. In this task, the goal is to compute an score for each image
pixel related with its contribution to the final network output. In this paper,
we introduce Disentangled Masked Backpropagation (DMBP), a novel gradient-based
method that leverages on the piecewise linear nature of ReLU networks to
decompose the model function into different linear mappings. This decomposition
aims to disentangle the positive, negative and nuisance factors from the
attribution maps by learning a set of variables masking the contribution of
each filter during back-propagation. A thorough evaluation over standard
architectures (ResNet50 and VGG16) and benchmark datasets (PASCAL VOC and
ImageNet) demonstrates that DMBP generates more visually interpretable
attribution maps than previous approaches. Additionally, we quantitatively show
that the maps produced by our method are more consistent with the true
contribution of each pixel to the final network output.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing bias and increasing utility by federated generative modeling of medical images using a centralized adversary. (arXiv:2101.07235v2 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07235">
<div class="article-summary-box-inner">
<span><p>We introduce FELICIA (FEderated LearnIng with a CentralIzed Adversary) a
generative mechanism enabling collaborative learning. In particular, we show
how a data owner with limited and biased data could benefit from other data
owners while keeping data from all the sources private. This is a common
scenario in medical image analysis where privacy legislation prevents data from
being shared outside local premises. FELICIA works for a large family of
Generative Adversarial Networks (GAN) architectures including vanilla and
conditional GANs as demonstrated in this work. We show that by using the
FELICIA mechanism, a data owner with limited image samples can generate
high-quality synthetic images with high utility while neither data owners has
to provide access to its data. The sharing happens solely through a central
discriminator that has access limited to synthetic data. Here, utility is
defined as classification performance on a real test set. We demonstrate these
benefits on several realistic healthcare scenarions using benchmark image
datasets (MNIST, CIFAR-10) as well as on medical images for the task of skin
lesion classification. With multiple experiments, we show that even in the
worst cases, combining FELICIA with real data gracefully achieves performance
on par with real data while most results significantly improves the utility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive Co-Attention Network for Fine-grained Visual Classification. (arXiv:2101.08527v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08527">
<div class="article-summary-box-inner">
<span><p>Fine-grained visual classification aims to recognize images belonging to
multiple sub-categories within a same category. It is a challenging task due to
the inherently subtle variations among highly-confused categories. Most
existing methods only take an individual image as input, which may limit the
ability of models to recognize contrastive clues from different images. In this
paper, we propose an effective method called progressive co-attention network
(PCA-Net) to tackle this problem. Specifically, we calculate the channel-wise
similarity by encouraging interaction between the feature channels within
same-category image pairs to capture the common discriminative features.
Considering that complementary information is also crucial for recognition, we
erase the prominent areas enhanced by the channel interaction to force the
network to focus on other discriminative regions. The proposed model has
achieved competitive results on three fine-grained visual classification
benchmark datasets: CUB-200-2011, Stanford Cars, and FGVC Aircraft.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Global to Local Double Embedding Method for Multi-person Pose Estimation. (arXiv:2102.07318v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07318">
<div class="article-summary-box-inner">
<span><p>Multi-person pose estimation is a fundamental and challenging problem to many
computer vision tasks. Most existing methods can be broadly categorized into
two classes: top-down and bottom-up methods. Both of the two types of methods
involve two stages, namely, person detection and joints detection.
Conventionally, the two stages are implemented separately without considering
their interactions between them, and this may inevitably cause some issue
intrinsically. In this paper, we present a novel method to simplify the
pipeline by implementing person detection and joints detection simultaneously.
We propose a Double Embedding (DE) method to complete the multi-person pose
estimation task in a global-to-local way. DE consists of Global Embedding (GE)
and Local Embedding (LE). GE encodes different person instances and processes
information covering the whole image and LE encodes the local limbs
information. GE functions for the person detection in top-down strategy while
LE connects the rest joints sequentially which functions for joint grouping and
information processing in A bottom-up strategy. Based on LE, we design the
Mutual Refine Machine (MRM) to reduce the prediction difficulty in complex
scenarios. MRM can effectively realize the information communicating between
keypoints and further improve the accuracy. We achieve the competitive results
on benchmarks MSCOCO, MPII and CrowdPose, demonstrating the effectiveness and
generalization ability of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepCervix: A Deep Learning-based Framework for the Classification of Cervical Cells Using Hybrid Deep Feature Fusion Techniques. (arXiv:2102.12191v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12191">
<div class="article-summary-box-inner">
<span><p>Cervical cancer, one of the most common fatal cancers among women, can be
prevented by regular screening to detect any precancerous lesions at early
stages and treat them. Pap smear test is a widely performed screening technique
for early detection of cervical cancer, whereas this manual screening method
suffers from high false-positive results because of human errors. To improve
the manual screening practice, machine learning (ML) and deep learning (DL)
based computer-aided diagnostic (CAD) systems have been investigated widely to
classify cervical pap cells. Most of the existing researches require
pre-segmented images to obtain good classification results, whereas accurate
cervical cell segmentation is challenging because of cell clustering. Some
studies rely on handcrafted features, which cannot guarantee the classification
stage's optimality. Moreover, DL provides poor performance for a multiclass
classification task when there is an uneven distribution of data, which is
prevalent in the cervical cell dataset. This investigation has addressed those
limitations by proposing DeepCervix, a hybrid deep feature fusion (HDFF)
technique based on DL to classify the cervical cells accurately. Our proposed
method uses various DL models to capture more potential information to enhance
classification performance. Our proposed HDFF method is tested on the publicly
available SIPAKMED dataset and compared the performance with base DL models and
the LF method. For the SIPAKMED dataset, we have obtained the state-of-the-art
classification accuracy of 99.85%, 99.38%, and 99.14% for 2-class, 3-class, and
5-class classification. Moreover, our method is tested on the Herlev dataset
and achieves an accuracy of 98.32% for binary class and 90.32% for 7-class
classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Digital Peter: Dataset, Competition and Handwriting Recognition Methods. (arXiv:2103.09354v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09354">
<div class="article-summary-box-inner">
<span><p>This paper presents a new dataset of Peter the Great's manuscripts and
describes a segmentation procedure that converts initial images of documents
into the lines. The new dataset may be useful for researchers to train
handwriting text recognition models as a benchmark for comparing different
models. It consists of 9 694 images and text files corresponding to lines in
historical documents. The open machine learning competition Digital Peter was
held based on the considered dataset. The baseline solution for this
competition as well as more advanced methods on handwritten text recognition
are described in the article. Full dataset and all code are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Annotated Training Data for 6D Object Pose Estimation in Operational Environments with Minimal User Interaction. (arXiv:2103.09696v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09696">
<div class="article-summary-box-inner">
<span><p>Recently developed deep neural networks achieved state-of-the-art results in
the subject of 6D object pose estimation for robot manipulation. However, those
supervised deep learning methods require expensive annotated training data.
Current methods for reducing those costs frequently use synthetic data from
simulations, but rely on expert knowledge and suffer from the "domain gap" when
shifting to the real world. Here, we present a proof of concept for a novel
approach of autonomously generating annotated training data for 6D object pose
estimation. This approach is designed for learning new objects in operational
environments while requiring little interaction and no expertise on the part of
the user. We evaluate our autonomous data generation approach in two grasping
experiments, where we archive a similar grasping success rate as related work
on a non autonomously generated data set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling Virtual Examples for Long-tailed Recognition. (arXiv:2103.15042v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15042">
<div class="article-summary-box-inner">
<span><p>We tackle the long-tailed visual recognition problem from the knowledge
distillation perspective by proposing a Distill the Virtual Examples (DiVE)
method. Specifically, by treating the predictions of a teacher model as virtual
examples, we prove that distilling from these virtual examples is equivalent to
label distribution learning under certain constraints. We show that when the
virtual example distribution becomes flatter than the original input
distribution, the under-represented tail classes will receive significant
improvements, which is crucial in long-tailed recognition. The proposed DiVE
method can explicitly tune the virtual example distribution to become flat.
Extensive experiments on three benchmark datasets, including the large-scale
iNaturalist ones, justify that the proposed DiVE method can significantly
outperform state-of-the-art methods. Furthermore, additional analyses and
experiments verify the virtual example interpretation, and demonstrate the
effectiveness of tailored designs in DiVE for long-tailed problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Busy-Quiet Video Disentangling for Video Classification. (arXiv:2103.15584v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15584">
<div class="article-summary-box-inner">
<span><p>In video data, busy motion details from moving regions are conveyed within a
specific frequency bandwidth in the frequency domain. Meanwhile, the rest of
the frequencies of video data are encoded with quiet information containing
substantial redundancy, which causes low efficiency for video models that take
as input raw RGB frames. In this paper, we consider that busy and quiet
spatio-temporal regions require different computational resources. We design a
trainable Motion Band-Pass Module (MBPM) for separating busy information from
quiet information in raw video data. By representing the quiet information with
lower resolution, we can increase the efficiency of video data processing. By
embedding the MBPM into a two-pathway CNN architecture, we define a Busy-Quiet
Net (BQN). The efficiency of BQN is determined by avoiding redundancy in the
feature space processed by the two pathways: one operates on quiet features of
low-resolution, while the other operates on busy features. The proposed BQN
outperforms many recent video processing models on Something-Something V1,
Kinetics400, UCF101 and HMDB51.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teacher-Student Adversarial Depth Hallucination to Improve Face Recognition. (arXiv:2104.02424v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02424">
<div class="article-summary-box-inner">
<span><p>We present the Teacher-Student Generative Adversarial Network (TS-GAN) to
generate depth images from single RGB images in order to boost the performance
of face recognition systems. For our method to generalize well across unseen
datasets, we design two components in the architecture, a teacher and a
student. The teacher, which itself consists of a generator and a discriminator,
learns a latent mapping between input RGB and paired depth images in a
supervised fashion. The student, which consists of two generators (one shared
with the teacher) and a discriminator, learns from new RGB data with no
available paired depth information, for improved generalization. The fully
trained shared generator can then be used in runtime to hallucinate depth from
RGB for downstream applications such as face recognition. We perform rigorous
experiments to show the superiority of TS-GAN over other methods in generating
synthetic depth images. Moreover, face recognition experiments demonstrate that
our hallucinated depth along with the input RGB images boosts performance
across various architectures when compared to a single RGB modality by average
values of +1.2%, +2.6%, and +2.6% for IIIT-D, EURECOM, and LFW datasets
respectively. We make our implementation public at:
https://github.com/hardik-uppal/teacher-student-gan.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Shape Generation and Completion through Point-Voxel Diffusion. (arXiv:2104.03670v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03670">
<div class="article-summary-box-inner">
<span><p>We propose a novel approach for probabilistic generative modeling of 3D
shapes. Unlike most existing models that learn to deterministically translate a
latent vector to a shape, our model, Point-Voxel Diffusion (PVD), is a unified,
probabilistic formulation for unconditional shape generation and conditional,
multi-modal shape completion. PVD marries denoising diffusion models with the
hybrid, point-voxel representation of 3D shapes. It can be viewed as a series
of denoising steps, reversing the diffusion process from observed point cloud
data to Gaussian noise, and is trained by optimizing a variational lower bound
to the (conditional) likelihood function. Experiments demonstrate that PVD is
capable of synthesizing high-fidelity shapes, completing partial point clouds,
and generating multiple completion results from single-view depth scans of real
objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geometry-Free View Synthesis: Transformers and no 3D Priors. (arXiv:2104.07652v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07652">
<div class="article-summary-box-inner">
<span><p>Is a geometric model required to synthesize novel views from a single image?
Being bound to local convolutions, CNNs need explicit 3D biases to model
geometric transformations. In contrast, we demonstrate that a transformer-based
model can synthesize entirely novel views without any hand-engineered 3D
biases. This is achieved by (i) a global attention mechanism for implicitly
learning long-range 3D correspondences between source and target views, and
(ii) a probabilistic formulation necessary to capture the ambiguity inherent in
predicting novel views from a single image, thereby overcoming the limitations
of previous approaches that are restricted to relatively small viewpoint
changes. We evaluate various ways to integrate 3D priors into a transformer
architecture. However, our experiments show that no such geometric priors are
required and that the transformer is capable of implicitly learning 3D
relationships between images. Furthermore, this approach outperforms the state
of the art in terms of visual quality while covering the full distribution of
possible realizations. Code is available at https://git.io/JOnwn
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-Resolution Optical Flow from 1D Attention and Correlation. (arXiv:2104.13918v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13918">
<div class="article-summary-box-inner">
<span><p>Optical flow is inherently a 2D search problem, and thus the computational
complexity grows quadratically with respect to the search window, making large
displacements matching infeasible for high-resolution images. In this paper, we
take inspiration from Transformers and propose a new method for high-resolution
optical flow estimation with significantly less computation. Specifically, a 1D
attention operation is first applied in the vertical direction of the target
image, and then a simple 1D correlation in the horizontal direction of the
attended image is able to achieve 2D correspondence modeling effect. The
directions of attention and correlation can also be exchanged, resulting in two
3D cost volumes that are concatenated for optical flow estimation. The novel 1D
formulation empowers our method to scale to very high-resolution input images
while maintaining competitive performance. Extensive experiments on Sintel,
KITTI and real-world 4K ($2160 \times 3840$) resolution images demonstrated the
effectiveness and superiority of our proposed method. Code and models are
available at \url{https://github.com/haofeixu/flow1d}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepMultiCap: Performance Capture of Multiple Characters Using Sparse Multiview Cameras. (arXiv:2105.00261v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00261">
<div class="article-summary-box-inner">
<span><p>We propose DeepMultiCap, a novel method for multi-person performance capture
using sparse multi-view cameras. Our method can capture time varying surface
details without the need of using pre-scanned template models. To tackle with
the serious occlusion challenge for close interacting scenes, we combine a
recently proposed pixel-aligned implicit function with parametric model for
robust reconstruction of the invisible surface areas. An effective
attention-aware module is designed to obtain the fine-grained geometry details
from multi-view images, where high-fidelity results can be generated. In
addition to the spatial attention method, for video inputs, we further propose
a novel temporal fusion method to alleviate the noise and temporal
inconsistencies for moving character reconstruction. For quantitative
evaluation, we contribute a high quality multi-person dataset, MultiHuman,
which consists of 150 static scenes with different levels of occlusions and
ground truth 3D human models. Experimental results demonstrate the
state-of-the-art performance of our method and the well generalization to real
multiview video data, which outperforms the prior works by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Surveilling Surveillance: Estimating the Prevalence of Surveillance Cameras with Street View Data. (arXiv:2105.01764v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01764">
<div class="article-summary-box-inner">
<span><p>The use of video surveillance in public spaces -- both by government agencies
and by private citizens -- has attracted considerable attention in recent
years, particularly in light of rapid advances in face-recognition technology.
But it has been difficult to systematically measure the prevalence and
placement of cameras, hampering efforts to assess the implications of
surveillance on privacy and public safety. Here we present a novel approach for
estimating the spatial distribution of surveillance cameras: applying computer
vision algorithms to large-scale street view image data. Specifically, we build
a camera detection model and apply it to 1.6 million street view images sampled
from 10 large U.S. cities and 6 other major cities around the world, with
positive model detections verified by human experts. After adjusting for the
estimated recall of our model, and accounting for the spatial coverage of our
sampled images, we are able to estimate the density of surveillance cameras
visible from the road. Across the 16 cities we consider, the estimated number
of surveillance cameras per linear kilometer ranges from 0.1 (in Seattle) to
0.9 (in Seoul). In a detailed analysis of the 10 U.S. cities, we find that
cameras are concentrated in commercial, industrial, and mixed zones, and in
neighborhoods with higher shares of non-white residents -- a pattern that
persists even after adjusting for land use. These results help inform ongoing
discussions on the use of surveillance technology, including its potential
disparate impacts on communities of color.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DARNet: Dual-Attention Residual Network for Automatic Diagnosis of COVID-19 via CT Images. (arXiv:2105.06779v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06779">
<div class="article-summary-box-inner">
<span><p>The ongoing global pandemic of Coronavirus Disease 2019 (COVID-19) poses a
serious threat to public health and the economy. Rapid and accurate diagnosis
of COVID-19 is crucial to prevent the further spread of the disease and reduce
its mortality. Chest Computed tomography (CT) is an effective tool for the
early diagnosis of lung diseases including pneumonia. However, detecting
COVID-19 from CT is demanding and prone to human errors as some early-stage
patients may have negative findings on images. Recently, many deep learning
methods have achieved impressive performance in this regard. Despite their
effectiveness, most of these methods underestimate the rich spatial information
preserved in the 3D structure or suffer from the propagation of errors. To
address this problem, we propose a Dual-Attention Residual Network (DARNet) to
automatically identify COVID-19 from other common pneumonia (CP) and healthy
people using 3D chest CT images. Specifically, we design a dual-attention
module consisting of channel-wise attention and depth-wise attention
mechanisms. The former is utilized to enhance channel independence, while the
latter is developed to recalibrate the depth-level features. Then, we integrate
them in a unified manner to extract and refine the features at different levels
to further improve the diagnostic performance. We evaluate DARNet on a large
public CT dataset and obtain superior performance. Besides, the ablation study
and visualization analysis prove the effectiveness and interpretability of the
proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Multi-Modality Registration Network based on Spatially Encoded Gradient Information. (arXiv:2105.07392v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07392">
<div class="article-summary-box-inner">
<span><p>Multi-modality medical images can provide relevant or complementary
information for a target (organ, tumor or tissue). Registering multi-modality
images to a common space can fuse these comprehensive information, and bring
convenience for clinical application. Recently, neural networks have been
widely investigated to boost registration methods. However, it is still
challenging to develop a multi-modality registration network due to the lack of
robust criteria for network training. In this work, we propose a multi-modality
registration network (MMRegNet), which can perform registration between
multi-modality images. Meanwhile, we present spatially encoded gradient
information to train MMRegNet in an unsupervised manner. The proposed network
was evaluated on MM-WHS 2017. Results show that MMRegNet can achieve promising
performance for left ventricle cardiac registration tasks. Meanwhile, to
demonstrate the versatility of MMRegNet, we further evaluate the method with a
liver dataset from CHAOS 2019. Source code will be released
publicly\footnote{https://github.com/NanYoMy/mmregnet} once the manuscript is
accepted.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cherry-Picking Gradients: Learning Low-Rank Embeddings of Visual Data via Differentiable Cross-Approximation. (arXiv:2105.14250v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14250">
<div class="article-summary-box-inner">
<span><p>We propose an end-to-end trainable framework that processes large-scale
visual data tensors by looking at a fraction of their entries only. Our method
combines a neural network encoder with a tensor train decomposition to learn a
low-rank latent encoding, coupled with cross-approximation (CA) to learn the
representation through a subset of the original samples. CA is an adaptive
sampling algorithm that is native to tensor decompositions and avoids working
with the full high-resolution data explicitly. Instead, it actively selects
local representative samples that we fetch out-of-core and on-demand. The
required number of samples grows only logarithmically with the size of the
input. Our implicit representation of the tensor in the network enables
processing large grids that could not be otherwise tractable in their
uncompressed form. The proposed approach is particularly useful for large-scale
multidimensional grid data (e.g., 3D tomography), and for tasks that require
context over a large receptive field (e.g., predicting the medical condition of
entire organs). The code is available at https://github.com/aelphy/c-pic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding and Evaluating Racial Biases in Image Captioning. (arXiv:2106.08503v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08503">
<div class="article-summary-box-inner">
<span><p>Image captioning is an important task for benchmarking visual reasoning and
for enabling accessibility for people with vision impairments. However, as in
many machine learning settings, social biases can influence image captioning in
undesirable ways. In this work, we study bias propagation pathways within image
captioning, focusing specifically on the COCO dataset. Prior work has analyzed
gender bias in captions using automatically-derived gender labels; here we
examine racial and intersectional biases using manual annotations. Our first
contribution is in annotating the perceived gender and skin color of 28,315 of
the depicted people after obtaining IRB approval. Using these annotations, we
compare racial biases present in both manual and automatically-generated image
captions. We demonstrate differences in caption performance, sentiment, and
word choice between images of lighter versus darker-skinned people. Further, we
find the magnitude of these differences to be greater in modern captioning
systems compared to older ones, thus leading to concerns that without proper
consideration and mitigation these differences will only become increasingly
prevalent. Code and data is available at
https://princetonvisualai.github.io/imagecaptioning-bias .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SIFT Matching by Context Exposed. (arXiv:2106.09584v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09584">
<div class="article-summary-box-inner">
<span><p>This paper investigates how to step up local image descriptor matching by
exploiting matching context information. Two main contexts are identified,
originated respectively from the descriptor space and from the keypoint space.
The former is generally used to design the actual matching strategy while the
latter to filter matches according to the local spatial consistency. On this
basis, a new matching strategy and a novel local spatial filter, named
respectively blob matching and Delaunay Triangulation Matching (DTM) are
devised. Blob matching provides a general matching framework by merging
together several strategies, including rank-based pre-filtering as well as
many-to-many and symmetric matching, enabling to achieve a global improvement
upon each individual strategy. DTM alternates between Delaunay triangulation
contractions and expansions to figure out and adjust keypoint neighborhood
consistency. Experimental evaluation shows that DTM is comparable or better
than the state-of-the-art in terms of matching accuracy and robustness.
Evaluation is carried out according to a new benchmark devised for analyzing
the matching pipeline in terms of correct correspondences on both planar and
non-planar scenes, including several state-of-the-art methods as well as the
common SIFT matching approach for reference. This evaluation can be of
assistance for future research in this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Transferability of Adversarial Patches on Face Recognition with Generative Models. (arXiv:2106.15058v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15058">
<div class="article-summary-box-inner">
<span><p>Face recognition is greatly improved by deep convolutional neural networks
(CNNs). Recently, these face recognition models have been used for identity
authentication in security sensitive applications. However, deep CNNs are
vulnerable to adversarial patches, which are physically realizable and
stealthy, raising new security concerns on the real-world applications of these
models. In this paper, we evaluate the robustness of face recognition models
using adversarial patches based on transferability, where the attacker has
limited accessibility to the target models. First, we extend the existing
transfer-based attack techniques to generate transferable adversarial patches.
However, we observe that the transferability is sensitive to initialization and
degrades when the perturbation magnitude is large, indicating the overfitting
to the substitute models. Second, we propose to regularize the adversarial
patches on the low dimensional data manifold. The manifold is represented by
generative models pre-trained on legitimate human face images. Using face-like
features as adversarial perturbations through optimization on the manifold, we
show that the gaps between the responses of substitute models and the target
models dramatically decrease, exhibiting a better transferability. Extensive
digital world experiments are conducted to demonstrate the superiority of the
proposed method in the black-box setting. We apply the proposed method in the
physical world as well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Orthonormal Product Quantization Network for Scalable Face Image Retrieval. (arXiv:2107.00327v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00327">
<div class="article-summary-box-inner">
<span><p>Current deep quantization methods that produce binary code representations
for efficient image retrieval mostly learn codewords from data. They rarely
investigate the effect of their inherent distribution on the quantization and
the learning metrics presently used are insufficient for face image retrieval
task. To address this, this paper integrates product quantization into an
end-to-end deep learning framework to retrieve face images. We propose a novel
scheme that uses predefined orthonormal vectors as codewords, to enhance the
quantization informativeness and reduce redundancy in the codewords. A tailored
loss function maximizes discriminability among identities in each quantization
subspace for both the quantized and original features. An entropy-based
regularization term is imposed to reduce the quantization error. Experiments
were conducted on three commonly-used datasets for both single- and
cross-domain retrieval. The proposed method outperformed all the deep
hashing/quantization methods it was compared with under both settings. We
observe that the proposed orthonormal codewords consistently improved both
models' standard retrieval performance and generalization ability. Therefore,
the proposed method is more suitable for scalable face image retrieval than
deep hashing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Crowdsourcing Evaluation of Saliency-based XAI Methods. (arXiv:2107.00456v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00456">
<div class="article-summary-box-inner">
<span><p>Understanding the reasons behind the predictions made by deep neural networks
is critical for gaining human trust in many important applications, which is
reflected in the increasing demand for explainability in AI (XAI) in recent
years. Saliency-based feature attribution methods, which highlight important
parts of images that contribute to decisions by classifiers, are often used as
XAI methods, especially in the field of computer vision. In order to compare
various saliency-based XAI methods quantitatively, several approaches for
automated evaluation schemes have been proposed; however, there is no guarantee
that such automated evaluation metrics correctly evaluate explainability, and a
high rating by an automated evaluation scheme does not necessarily mean a high
explainability for humans. In this study, instead of the automated evaluation,
we propose a new human-based evaluation scheme using crowdsourcing to evaluate
XAI methods. Our method is inspired by a human computation game, "Peek-a-boom",
and can efficiently compare different XAI methods by exploiting the power of
crowds. We evaluate the saliency maps of various XAI methods on two datasets
with automated and crowd-based evaluation schemes. Our experiments show that
the result of our crowd-based evaluation scheme is different from those of
automated evaluation schemes. In addition, we regard the crowd-based evaluation
results as ground truths and provide a quantitative performance measure to
compare different automated evaluation schemes. We also discuss the impact of
crowd workers on the results and show that the varying ability of crowd workers
does not significantly impact the results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Contrastive Learning with Hard Negative Sampling for Self-supervised Point Cloud Learning. (arXiv:2107.01886v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01886">
<div class="article-summary-box-inner">
<span><p>Point clouds have attracted increasing attention. Significant progress has
been made in methods for point cloud analysis, which often requires costly
human annotation as supervision. To address this issue, we propose a novel
self-contrastive learning for self-supervised point cloud representation
learning, aiming to capture both local geometric patterns and nonlocal semantic
primitives based on the nonlocal self-similarity of point clouds. The
contributions are two-fold: on the one hand, instead of contrasting among
different point clouds as commonly employed in contrastive learning, we exploit
self-similar point cloud patches within a single point cloud as positive
samples and otherwise negative ones to facilitate the task of contrastive
learning. On the other hand, we actively learn hard negative samples that are
close to positive samples for discriminative feature learning. Experimental
results show that the proposed method achieves state-of-the-art performance on
widely used benchmark datasets for self-supervised point cloud segmentation and
transfer learning for classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Sampling Strategies for Unsupervised Person Re-identification. (arXiv:2107.03024v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03024">
<div class="article-summary-box-inner">
<span><p>Unsupervised person re-identification (re-ID) remains a challenging task.
While extensive research has focused on the framework design or loss function,
we show in this paper that sampling strategy plays an equally important role.
We analyze the reasons for differences in performance between various sampling
strategies under the same framework and loss function. We suggest that
deteriorated over-fitting is an important factor causing poor performance, and
enhancing statistical stability can rectify this issue. Inspired by that, a
simple yet effective approach is proposed, known as group sampling, which
gathers groups of samples from the same class into a mini-batch. The model is
thereby trained using normalized group samples, which helps to alleviate the
effects associated with a single sample. Group sampling updates the pipeline of
pseudo label generation by guaranteeing that samples are more efficiently
divided into the correct classes. Group sampling regulates the representation
learning process, which enhances statistical stability for feature
representation in a progressive fashion. Qualitative and quantitative
experiments on Market-1501, DukeMTMC-reID, and MSMT17 show that group sampling
improves upon state-of-the-art methods by between 3.3%~6.1%. Code has been
available at https://github.com/ucas-vg/GroupSampling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A stepped sampling method for video detection using LSTM. (arXiv:2107.08471v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08471">
<div class="article-summary-box-inner">
<span><p>Artificial neural networks that simulate human achieves great successes. From
the perspective of simulating human memory method, we propose a stepped sampler
based on the "repeated input". We repeatedly inputted data to the LSTM model
stepwise in a batch. The stepped sampler is used to strengthen the ability of
fusing the temporal information in LSTM. We tested the stepped sampler on the
LSTM built-in in PyTorch. Compared with the traditional sampler of PyTorch,
such as sequential sampler, batch sampler, the training loss of the proposed
stepped sampler converges faster in the training of the model, and the training
loss after convergence is more stable. Meanwhile, it can maintain a higher test
accuracy. We quantified the algorithm of the stepped sampler. We assume that,
the artificial neural networks have human-like characteristics, and human
learning method could be used for machine learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-binary deep transfer learning for image classification. (arXiv:2107.08585v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08585">
<div class="article-summary-box-inner">
<span><p>The current standard for a variety of computer vision tasks using smaller
numbers of labelled training examples is to fine-tune from weights pre-trained
on a large image classification dataset such as ImageNet. The application of
transfer learning and transfer learning methods tends to be rigidly binary. A
model is either pre-trained or not pre-trained. Pre-training a model either
increases performance or decreases it, the latter being defined as negative
transfer. Application of L2-SP regularisation that decays the weights towards
their pre-trained values is either applied or all weights are decayed towards
0. This paper re-examines these assumptions. Our recommendations are based on
extensive empirical evaluation that demonstrate the application of a non-binary
approach to achieve optimal results. (1) Achieving best performance on each
individual dataset requires careful adjustment of various transfer learning
hyperparameters not usually considered, including number of layers to transfer,
different learning rates for different layers and different combinations of
L2SP and L2 regularization. (2) Best practice can be achieved using a number of
measures of how well the pre-trained weights fit the target dataset to guide
optimal hyperparameters. We present methods for non-binary transfer learning
including combining L2SP and L2 regularization and performing non-traditional
fine-tuning hyperparameter searches. Finally we suggest heuristics for
determining the optimal transfer learning hyperparameters. The benefits of
using a non-binary approach are supported by final results that come close to
or exceed state of the art performance on a variety of tasks that have
traditionally been more difficult for transfer learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rank & Sort Loss for Object Detection and Instance Segmentation. (arXiv:2107.11669v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11669">
<div class="article-summary-box-inner">
<span><p>We propose Rank &amp; Sort (RS) Loss, a ranking-based loss function to train deep
object detection and instance segmentation methods (i.e. visual detectors). RS
Loss supervises the classifier, a sub-network of these methods, to rank each
positive above all negatives as well as to sort positives among themselves with
respect to (wrt.) their localisation qualities (e.g. Intersection-over-Union -
IoU). To tackle the non-differentiable nature of ranking and sorting, we
reformulate the incorporation of error-driven update with backpropagation as
Identity Update, which enables us to model our novel sorting error among
positives. With RS Loss, we significantly simplify training: (i) Thanks to our
sorting objective, the positives are prioritized by the classifier without an
additional auxiliary head (e.g. for centerness, IoU, mask-IoU), (ii) due to its
ranking-based nature, RS Loss is robust to class imbalance, and thus, no
sampling heuristic is required, and (iii) we address the multi-task nature of
visual detectors using tuning-free task-balancing coefficients. Using RS Loss,
we train seven diverse visual detectors only by tuning the learning rate, and
show that it consistently outperforms baselines: e.g. our RS Loss improves (i)
Faster R-CNN by ~ 3 box AP and aLRP Loss (ranking-based baseline) by ~ 2 box AP
on COCO dataset, (ii) Mask R-CNN with repeat factor sampling (RFS) by 3.5 mask
AP (~ 7 AP for rare classes) on LVIS dataset; and also outperforms all
counterparts. Code is available at: https://github.com/kemaloksuz/RankSortLoss
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ManiSkill: Generalizable Manipulation Skill Benchmark with Large-Scale Demonstrations. (arXiv:2107.14483v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14483">
<div class="article-summary-box-inner">
<span><p>Object manipulation from 3D visual inputs poses many challenges on building
generalizable perception and policy models. However, 3D assets in existing
benchmarks mostly lack the diversity of 3D shapes that align with real-world
intra-class complexity in topology and geometry. Here we propose SAPIEN
Manipulation Skill Benchmark (ManiSkill) to benchmark manipulation skills over
diverse objects in a full-physics simulator. 3D assets in ManiSkill include
large intra-class topological and geometric variations. Tasks are carefully
chosen to cover distinct types of manipulation challenges. Latest progress in
3D vision also makes us believe that we should customize the benchmark so that
the challenge is inviting to researchers working on 3D deep learning. To this
end, we simulate a moving panoramic camera that returns ego-centric point
clouds or RGB-D images. In addition, we would like ManiSkill to serve a broad
set of researchers interested in manipulation research. Besides supporting the
learning of policies from interactions, we also support
learning-from-demonstrations (LfD) methods, by providing a large number of
high-quality demonstrations (~36,000 successful trajectories, ~1.5M point
cloud/RGB-D frames in total). We provide baselines using 3D deep learning and
LfD algorithms. All code of our benchmark (simulator, environment, SDK, and
baselines) is open-sourced, and a challenge facing interdisciplinary
researchers will be held based on the benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PSE-Match: A Viewpoint-free Place Recognition Method with Parallel Semantic Embedding. (arXiv:2108.00552v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00552">
<div class="article-summary-box-inner">
<span><p>Accurate localization on autonomous driving cars is essential for autonomy
and driving safety, especially for complex urban streets and search-and-rescue
subterranean environments where high-accurate GPS is not available. However
current odometry estimation may introduce the drifting problems in long-term
navigation without robust global localization. The main challenges involve
scene divergence under the interference of dynamic environments and effective
perception of observation and object layout variance from different viewpoints.
To tackle these challenges, we present PSE-Match, a viewpoint-free place
recognition method based on parallel semantic analysis of isolated semantic
attributes from 3D point-cloud models. Compared with the original point cloud,
the observed variance of semantic attributes is smaller. PSE-Match incorporates
a divergence place learning network to capture different semantic attributes
parallelly through the spherical harmonics domain. Using both existing
benchmark datasets and two in-field collected datasets, our experiments show
that the proposed method achieves above 70% average recall with top one
retrieval and above 95% average recall with top ten retrieval cases. And
PSE-Match has also demonstrated an obvious generalization ability with a
limited training dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GraphFPN: Graph Feature Pyramid Network for Object Detection. (arXiv:2108.00580v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00580">
<div class="article-summary-box-inner">
<span><p>Feature pyramids have been proven powerful in image understanding tasks that
require multi-scale features. State-of-the-art methods for multi-scale feature
learning focus on performing feature interactions across space and scales using
neural networks with a fixed topology. In this paper, we propose graph feature
pyramid networks that are capable of adapting their topological structures to
varying intrinsic image structures and supporting simultaneous feature
interactions across all scales. We first define an image-specific superpixel
hierarchy for each input image to represent its intrinsic image structures. The
graph feature pyramid network inherits its structure from this superpixel
hierarchy. Contextual and hierarchical layers are designed to achieve feature
interactions within the same scale and across different scales. To make these
layers more powerful, we introduce two types of local channel attention for
graph neural networks by generalizing global channel attention for
convolutional neural networks. The proposed graph feature pyramid network can
enhance the multiscale features from a convolutional feature pyramid network.
We evaluate our graph feature pyramid network in the object detection task by
integrating it into the Faster R-CNN algorithm. The modified algorithm
outperforms not only previous state-of-the-art feature pyramid-based methods
with a clear margin but also other popular detection methods on both MS-COCO
2017 validation and test datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Character Recognition using Visual Explanations Derived from the Human Visual System and Deep Networks. (arXiv:2108.04558v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04558">
<div class="article-summary-box-inner">
<span><p>Human observers engage in selective information uptake when classifying
visual patterns. The same is true of deep neural networks, which currently
constitute the best performing artificial vision systems. Our goal is to
examine the congruence, or lack thereof, in the information-gathering
strategies of the two systems. We have operationalized our investigation as a
character recognition task. We have used eye-tracking to assay the spatial
distribution of information hotspots for humans via fixation maps and an
activation mapping technique for obtaining analogous distributions for deep
networks through visualization maps. Qualitative comparison between
visualization maps and fixation maps reveals an interesting correlate of
congruence. The deep learning model considered similar regions in character,
which humans have fixated in the case of correctly classified characters. On
the other hand, when the focused regions are different for humans and deep
nets, the characters are typically misclassified by the latter. Hence, we
propose to use the visual fixation maps obtained from the eye-tracking
experiment as a supervisory input to align the model's focus on relevant
character regions. We find that such supervision improves the model's
performance significantly and does not require any additional parameters. This
approach has the potential to find applications in diverse domains such as
medical analysis and surveillance in which explainability helps to determine
system fidelity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instance-weighted Central Similarity for Multi-label Image Retrieval. (arXiv:2108.05274v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05274">
<div class="article-summary-box-inner">
<span><p>Deep hashing has been widely applied to large-scale image retrieval by
encoding high-dimensional data points into binary codes for efficient
retrieval. Compared with pairwise/triplet similarity based hash learning,
central similarity based hashing can more efficiently capture the global data
distribution. For multi-label image retrieval, however, previous methods only
use multiple hash centers with equal weights to generate one centroid as the
learning target, which ignores the relationship between the weights of hash
centers and the proportion of instance regions in the image. To address the
above issue, we propose a two-step alternative optimization approach,
Instance-weighted Central Similarity (ICS), to automatically learn the center
weight corresponding to a hash code. Firstly, we apply the maximum entropy
regularizer to prevent one hash center from dominating the loss function, and
compute the center weights via projection gradient descent. Secondly, we update
neural network parameters by standard back-propagation with fixed center
weights. More importantly, the learned center weights can well reflect the
proportion of foreground instances in the image. Our method achieves the
state-of-the-art performance on the image retrieval benchmarks, and especially
improves the mAP by 1.6%-6.4% on the MS COCO dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Gaze Analysis: A Survey of Deep Learning based Approaches. (arXiv:2108.05479v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05479">
<div class="article-summary-box-inner">
<span><p>Eye gaze analysis is an important research problem in the field of Computer
Vision and Human-Computer Interaction. Even with notable progress in the last
10 years, automatic gaze analysis still remains challenging due to the
uniqueness of eye appearance, eye-head interplay, occlusion, image quality, and
illumination conditions. There are several open questions including what are
the important cues to interpret gaze direction in an unconstrained environment
without prior knowledge and how to encode them in real-time. We review the
progress across a range of gaze analysis tasks and applications to elucidate
these fundamental questions; identify effective methods in gaze analysis and
provide possible future directions. We analyze recent gaze estimation and
segmentation methods, especially in the unsupervised and weakly supervised
domain, based on their advantages and reported evaluation metrics. Our analysis
shows that the development of a robust and generic gaze analysis method still
needs to address real-world challenges such as unconstrained setup and learning
with less supervision. We conclude by discussing future research directions for
designing a real-world gaze analysis system that can propagate to other domains
including Computer Vision, Augmented Reality (AR), Virtual Reality (VR), and
Human Computer Interaction (HCI). Project Page:
https://github.com/i-am-shreya/EyeGazeSurvey}{https://github.com/i-am-shreya/EyeGazeSurvey
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Modal MRI Reconstruction Assisted with Spatial Alignment Network. (arXiv:2108.05603v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05603">
<div class="article-summary-box-inner">
<span><p>In clinical practice, magnetic resonance imaging (MRI) with multiple
contrasts is usually acquired in a single study to assess different properties
of the same region of interest in human body. The whole acquisition process can
be accelerated by having one or more modalities under-sampled in the $k$-space.
Recent researches demonstrate that, considering the redundancy between
different contrasts or modalities, a target MRI modality under-sampled in the
$k$-space can be more efficiently reconstructed with a fully-sampled MRI
contrast as the reference modality. However, we find that the performance of
the above multi-modal reconstruction can be negatively affected by subtle
spatial misalignment between different contrasts, which is actually common in
clinical practice. In this paper, to compensate for such spatial misalignment,
we integrate the spatial alignment network with multi-modal reconstruction
towards better reconstruction quality of the target modality. First, the
spatial alignment network estimates the spatial misalignment between the
fully-sampled reference and the under-sampled target images, and warps the
reference image accordingly. Then, the aligned fully-sampled reference image
joins the multi-modal reconstruction of the under-sampled target image. Also,
considering the contrast difference between the target and the reference
images, we particularly design the cross-modality-synthesis-based registration
loss, in combination with the reconstruction loss, to jointly train the spatial
alignment network and the reconstruction network. Experiments on both clinical
MRI and multi-coil $k$-space raw data demonstrate the superiority and
robustness of multi-modal MRI reconstruction empowered with our spatial
alignment network. Our code is publicly available at
\url{https://github.com/woxuankai/SpatialAlignmentNetwork}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bi-Temporal Semantic Reasoning for the Semantic Change Detection in HR Remote Sensing Images. (arXiv:2108.06103v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06103">
<div class="article-summary-box-inner">
<span><p>Semantic change detection (SCD) extends the multi-class change detection
(MCD) task to provide not only the change locations but also the detailed
land-cover/land-use (LCLU) categories before and after the observation
intervals. This fine-grained semantic change information is very useful in many
applications. Recent studies indicate that the SCD can be modeled through a
triple-branch Convolutional Neural Network (CNN), which contains two temporal
branches and a change branch. However, in this architecture, the communications
between the temporal branches and the change branch are insufficient. To
overcome the limitations in existing methods, we propose a novel CNN
architecture for the SCD, where the semantic temporal features are merged in a
deep CD unit. Furthermore, we elaborate on this architecture to reason the
bi-temporal semantic correlations. The resulting Bi-temporal Semantic Reasoning
Network (Bi-SRNet) contains two types of semantic reasoning blocks to reason
both single-temporal and cross-temporal semantic correlations, as well as a
novel loss function to improve the semantic consistency of change detection
results. Experimental results on a benchmark dataset show that the proposed
architecture obtains significant accuracy improvements over the existing
approaches, while the added designs in the Bi-SRNet further improves the
segmentation of both semantic categories and the changed areas. The codes in
this paper are accessible at: github.com/ggsDing/Bi-SRNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pruning vs XNOR-Net: A Comprehensive Study of Deep Learning for Audio Classification on Edge-devices. (arXiv:2108.06128v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06128">
<div class="article-summary-box-inner">
<span><p>Deep Learning has celebrated resounding successes in many application areas
of relevance to the Internet-of-Things, for example, computer vision and
machine listening. To fully harness the power of deep leaning for the IoT,
these technologies must ultimately be brought directly to the edge. The obvious
challenge is that deep learning techniques can only be implemented on strictly
resource-constrained edge devices if the models are radically downsized. This
task relies on different model compression techniques, such as network pruning,
quantization, and the recent advancement of XNOR-Net. This paper examines the
suitability of these techniques for audio classification on microcontrollers.
We present an XNOR-Net for end-to-end raw audio classification and a
comprehensive empirical study comparing this approach with
pruning-and-quantization methods. We show that raw audio classification with
XNOR yields comparable performance to regular full precision networks for small
numbers of classes while reducing memory requirements 32-fold and computation
requirements 58-fold. However, as the number of classes increases
significantly, performance degrades, and pruning-and-quantization based
compression techniques take over as the preferred technique being able to
satisfy the same space constraints but requiring about 8x more computation. We
show that these insights are consistent between raw audio classification and
image classification using standard benchmark sets. To the best of our
knowledge, this is the first study applying XNOR to end-to-end audio
classification and evaluating it in the context of alternative techniques. All
code is publicly available on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NPBDREG: A Non-parametric Bayesian Deep-Learning Based Approach for Diffeomorphic Brain MRI Registration. (arXiv:2108.06771v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06771">
<div class="article-summary-box-inner">
<span><p>Quantification of uncertainty in deep-neural-networks (DNN) based image
registration algorithms plays an important role in the safe deployment of
real-world medical applications and research-oriented processing pipelines, and
in improving generalization capabilities. Currently available approaches for
uncertainty estimation, including the variational encoder-decoder architecture
and the inference-time dropout approach, require specific network architectures
and assume parametric distribution of the latent space which may result in
sub-optimal characterization of the posterior distribution for the predicted
deformation-fields. We introduce the NPBDREG, a fully non-parametric Bayesian
framework for unsupervised DNN-based deformable image registration by combining
an \texttt{Adam} optimizer with stochastic gradient Langevin dynamics (SGLD) to
characterize the true posterior distribution through posterior sampling. The
NPBDREG provides a principled non-parametric way to characterize the true
posterior distribution, thus providing improved uncertainty estimates and
confidence measures in a theoretically well-founded and computationally
efficient way. We demonstrated the added-value of NPBDREG, compared to the
baseline probabilistic \texttt{VoxelMorph} unsupervised model (PrVXM), on brain
MRI images registration using $390$ image pairs from four publicly available
databases: MGH10, CMUC12, ISBR18 and LPBA40. The NPBDREG shows a slight
improvement in the registration accuracy compared to PrVXM (Dice score of
$0.73$ vs. $0.68$, $p \ll 0.01$), a better generalization capability for data
corrupted by a mixed structure noise (e.g Dice score of $0.729$ vs. $0.686$ for
$\alpha=0.2$) and last but foremost, a significantly better correlation of the
predicted uncertainty with out-of-distribution data ($r&gt;0.95$ vs. $r&lt;0.5$).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TOOD: Task-aligned One-stage Object Detection. (arXiv:2108.07755v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07755">
<div class="article-summary-box-inner">
<span><p>One-stage object detection is commonly implemented by optimizing two
sub-tasks: object classification and localization, using heads with two
parallel branches, which might lead to a certain level of spatial misalignment
in predictions between the two tasks. In this work, we propose a Task-aligned
One-stage Object Detection (TOOD) that explicitly aligns the two tasks in a
learning-based manner. First, we design a novel Task-aligned Head (T-Head)
which offers a better balance between learning task-interactive and
task-specific features, as well as a greater flexibility to learn the alignment
via a task-aligned predictor. Second, we propose Task Alignment Learning (TAL)
to explicitly pull closer (or even unify) the optimal anchors for the two tasks
during training via a designed sample assignment scheme and a task-aligned
loss. Extensive experiments are conducted on MS-COCO, where TOOD achieves a
51.1 AP at single-model single-scale testing. This surpasses the recent
one-stage detectors by a large margin, such as ATSS (47.7 AP), GFL (48.2 AP),
and PAA (49.0 AP), with fewer parameters and FLOPs. Qualitative results also
demonstrate the effectiveness of TOOD for better aligning the tasks of object
classification and localization. Code is available at
https://github.com/fcjian/TOOD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Salient Object Detection with Transformer-based Asymmetric Bilateral U-Net. (arXiv:2108.07851v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07851">
<div class="article-summary-box-inner">
<span><p>Existing salient object detection (SOD) methods mainly rely on CNN-based
U-shaped structures with skip connections to combine the global contexts and
local spatial details that are crucial for locating salient objects and
refining object details, respectively. Despite great successes, the ability of
CNN in learning global contexts is limited. Recently, the vision transformer
has achieved revolutionary progress in computer vision owing to its powerful
modeling of global dependencies. However, directly applying the transformer to
SOD is suboptimal because the transformer lacks the ability to learn local
spatial representations. To this end, this paper explores the combination of
transformer and CNN to learn both global and local representations for SOD. We
propose a transformer-based Asymmetric Bilateral U-Net (ABiU-Net). The
asymmetric bilateral encoder has a transformer path and a lightweight CNN path,
where the two paths communicate at each encoder stage to learn complementary
global contexts and local spatial details, respectively. The asymmetric
bilateral decoder also consists of two paths to process features from the
transformer and CNN encoder paths, with communication at each decoder stage for
decoding coarse salient object locations and find-grained object details,
respectively. Such communication between the two encoder/decoder paths enables
AbiU-Net to learn complementary global and local representations, taking
advantage of the natural properties of transformer and CNN, respectively.
Hence, ABiU-Net provides a new perspective for transformer-based SOD. Extensive
experiments demonstrate that ABiU-Net performs favorably against previous
state-of-the-art SOD methods. The code will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effect of Parameter Optimization on Classical and Learning-based Image Matching Methods. (arXiv:2108.08179v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08179">
<div class="article-summary-box-inner">
<span><p>Deep learning-based image matching methods are improved significantly during
the recent years. Although these methods are reported to outperform the
classical techniques, the performance of the classical methods is not examined
in detail. In this study, we compare classical and learning-based methods by
employing mutual nearest neighbor search with ratio test and optimizing the
ratio test threshold to achieve the best performance on two different
performance metrics. After a fair comparison, the experimental results on
HPatches dataset reveal that the performance gap between classical and
learning-based methods is not that significant. Throughout the experiments, we
demonstrated that SuperGlue is the state-of-the-art technique for the image
matching problem on HPatches dataset. However, if a single parameter, namely
ratio test threshold, is carefully optimized, a well-known traditional method
SIFT performs quite close to SuperGlue and even outperforms in terms of mean
matching accuracy (MMA) under 1 and 2 pixel thresholds. Moreover, a recent
approach, DFM, which only uses pre-trained VGG features as descriptors and
ratio test, is shown to outperform most of the well-trained learning-based
methods. Therefore, we conclude that the parameters of any classical method
should be analyzed carefully before comparing against a learning-based
technique.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Box-Adapt: Domain-Adaptive Medical Image Segmentation using Bounding BoxSupervision. (arXiv:2108.08432v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08432">
<div class="article-summary-box-inner">
<span><p>Deep learning has achieved remarkable success in medicalimage segmentation,
but it usually requires a large numberof images labeled with fine-grained
segmentation masks, andthe annotation of these masks can be very expensive
andtime-consuming. Therefore, recent methods try to use un-supervised domain
adaptation (UDA) methods to borrow in-formation from labeled data from other
datasets (source do-mains) to a new dataset (target domain). However, due tothe
absence of labels in the target domain, the performance ofUDA methods is much
worse than that of the fully supervisedmethod. In this paper, we propose a
weakly supervised do-main adaptation setting, in which we can partially label
newdatasets with bounding boxes, which are easier and cheaperto obtain than
segmentation masks. Accordingly, we proposea new weakly-supervised domain
adaptation method calledBox-Adapt, which fully explores the fine-grained
segmenta-tion mask in the source domain and the weak bounding boxin the target
domain. Our Box-Adapt is a two-stage methodthat first performs joint training
on the source and target do-mains, and then conducts self-training with the
pseudo-labelsof the target domain. We demonstrate the effectiveness of
ourmethod in the liver segmentation task. Weakly supervised do-main adaptation
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image coding for machines: an end-to-end learned approach. (arXiv:2108.09993v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09993">
<div class="article-summary-box-inner">
<span><p>Over recent years, deep learning-based computer vision systems have been
applied to images at an ever-increasing pace, oftentimes representing the only
type of consumption for those images. Given the dramatic explosion in the
number of images generated per day, a question arises: how much better would an
image codec targeting machine-consumption perform against state-of-the-art
codecs targeting human-consumption? In this paper, we propose an image codec
for machines which is neural network (NN) based and end-to-end learned. In
particular, we propose a set of training strategies that address the delicate
problem of balancing competing loss functions, such as computer vision task
losses, image distortion losses, and rate loss. Our experimental results show
that our NN-based codec outperforms the state-of-the-art Versa-tile Video
Coding (VVC) standard on the object detection and instance segmentation tasks,
achieving -37.87% and -32.90% of BD-rate gain, respectively, while being fast
thanks to its compact size. To the best of our knowledge, this is the first
end-to-end learned machine-targeted image codec.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dense Optical Flow from Event Cameras. (arXiv:2108.10552v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10552">
<div class="article-summary-box-inner">
<span><p>We propose to incorporate feature correlation and sequential processing into
dense optical flow estimation from event cameras. Modern frame-based optical
flow methods heavily rely on matching costs computed from feature correlation.
In contrast, there exists no optical flow method for event cameras that
explicitly computes matching costs. Instead, learning-based approaches using
events usually resort to the U-Net architecture to estimate optical flow
sparsely. Our key finding is that the introduction of correlation features
significantly improves results compared to previous methods that solely rely on
convolution layers. Compared to the state-of-the-art, our proposed approach
computes dense optical flow and reduces the end-point error by 23% on MVSEC.
Furthermore, we show that all existing optical flow methods developed so far
for event cameras have been evaluated on datasets with very small displacement
fields with a maximum flow magnitude of 10 pixels. Based on this observation,
we introduce a new real-world dataset that exhibits displacement fields with
magnitudes up to 210 pixels and 3 times higher camera resolution. Our proposed
approach reduces the end-point error on this dataset by 66%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YOLOP: You Only Look Once for Panoptic Driving Perception. (arXiv:2108.11250v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11250">
<div class="article-summary-box-inner">
<span><p>A panoptic driving perception system is an essential part of autonomous
driving. A high-precision and real-time perception system can assist the
vehicle in making the reasonable decision while driving. We present a panoptic
driving perception network (YOLOP) to perform traffic object detection,
drivable area segmentation and lane detection simultaneously. It is composed of
one encoder for feature extraction and three decoders to handle the specific
tasks. Our model performs extremely well on the challenging BDD100K dataset,
achieving state-of-the-art on all three tasks in terms of accuracy and speed.
Besides, we verify the effectiveness of our multi-task learning model for joint
training via ablative studies. To our best knowledge, this is the first work
that can process these three visual perception tasks simultaneously in
real-time on an embedded device Jetson TX2(23 FPS) and maintain excellent
accuracy. To facilitate further research, the source codes and pre-trained
models will be released at https://github.com/hustvl/YOLOP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Blind Image Decomposition. (arXiv:2108.11364v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11364">
<div class="article-summary-box-inner">
<span><p>We present and study a novel task named Blind Image Decomposition (BID),
which requires separating a superimposed image into constituent underlying
images in a blind setting, that is, both the source components involved in
mixing as well as the mixing mechanism are unknown. For example, rain may
consist of multiple components, such as rain streaks, raindrops, snow, and
haze. Rainy images can be treated as an arbitrary combination of these
components, some of them or all of them. How to decompose superimposed images,
like rainy images, into distinct source components is a crucial step towards
real-world vision systems. To facilitate research on this new task, we
construct three benchmark datasets, including mixed image decomposition across
multiple domains, real-scenario deraining, and joint
shadow/reflection/watermark removal. Moreover, we propose a simple yet general
Blind Image Decomposition Network (BIDeN) to serve as a strong baseline for
future work. Experimental results demonstrate the tenability of our benchmarks
and the effectiveness of BIDeN. Code and project page are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Modulation Network for Audio-Visual Event Localization. (arXiv:2108.11773v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11773">
<div class="article-summary-box-inner">
<span><p>We study the problem of localizing audio-visual events that are both audible
and visible in a video. Existing works focus on encoding and aligning audio and
visual features at the segment level while neglecting informative correlation
between segments of the two modalities and between multi-scale event proposals.
We propose a novel MultiModulation Network (M2N) to learn the above correlation
and leverage it as semantic guidance to modulate the related auditory, visual,
and fused features. In particular, during feature encoding, we propose
cross-modal normalization and intra-modal normalization. The former modulates
the features of two modalities by establishing and exploiting the cross-modal
relationship. The latter modulates the features of a single modality with the
event-relevant semantic guidance of the same modality. In the fusion stage,we
propose a multi-scale proposal modulating module and a multi-alignment segment
modulating module to introduce multi-scale event proposals and enable dense
matching between cross-modal segments. With the auditory, visual, and fused
features modulated by the correlation information regarding audio-visual
events, M2N performs accurate event localization. Extensive experiments
conducted on the AVE dataset demonstrate that our proposed method outperforms
the state of the art in both supervised event localization and cross-modality
localization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">User-Centric Semi-Automated Infographics Authoring and Recommendation. (arXiv:2108.11914v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11914">
<div class="article-summary-box-inner">
<span><p>Designing infographics can be a tedious process for non-experts and
time-consuming even for professional designers. Based on the literature and a
formative study, we propose a flexible framework for automated and
semi-automated infographics design. This framework captures the main design
components in infographics and streamlines the generation workflow into three
steps, allowing users to control and optimize each aspect independently. Based
on the framework, we also propose an interactive tool, \name{}, for assisting
novice designers with creating high-quality infographics from an input in a
markdown format by offering recommendations of different design components of
infographics. Simultaneously, more experienced designers can provide custom
designs and layout ideas to the tool using a canvas to control the automated
generation process partially. As part of our work, we also contribute an
individual visual group (VG) and connection designs dataset (in SVG), along
with a 1k complete infographic image dataset with segmented VGs. This dataset
plays a crucial role in diversifying the infographic designs created by our
framework. We evaluate our approach with a comparison against similar tools, a
user study with novice and expert designers, and a case study. Results confirm
that our framework and \name{} excel in creating customized infographics and
exploring a large variety of designs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Tutorial on Learning Disentangled Representations in the Imaging Domain. (arXiv:2108.12043v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12043">
<div class="article-summary-box-inner">
<span><p>Disentangled representation learning has been proposed as an approach to
learning general representations. This can be done in the absence of, or with
limited, annotations. A good general representation can be readily fine-tuned
for new target tasks using modest amounts of data, or even be used directly in
unseen domains achieving remarkable performance in the corresponding task. This
alleviation of the data and annotation requirements offers tantalising
prospects for tractable and affordable applications in computer vision and
healthcare. Finally, disentangled representations can offer model
explainability and can help us understand the underlying causal relations of
the factors of variation, increasing their suitability for real-world
deployment. In this tutorial paper, we will offer an overview of the
disentangled representation learning, its building blocks and criteria, and
discuss applications in computer vision and medical imaging. We conclude our
tutorial by presenting the identified opportunities for the integration of
recent machine learning advances into disentanglement, as well as the remaining
challenges.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-08-31 23:02:19.811907118 UTC">2021-08-31 23:02:19 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.1</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>