<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-11-01T01:30:00Z">11-01</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">What makes us curious? analysis of a corpus of open-domain questions. (arXiv:2110.15409v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15409">
<div class="article-summary-box-inner">
<span><p>Every day people ask short questions through smart devices or online forums
to seek answers to all kinds of queries. With the increasing number of
questions collected it becomes difficult to provide answers to each of them,
which is one of the reasons behind the growing interest in automated question
answering. Some questions are similar to existing ones that have already been
answered, while others could be answered by an external knowledge source such
as Wikipedia. An important question is what can be revealed by analysing a
large set of questions. In 2017, "We the Curious" science centre in Bristol
started a project to capture the curiosity of Bristolians: the project
collected more than 10,000 questions on various topics. As no rules were given
during collection, the questions are truly open-domain, and ranged across a
variety of topics. One important aim for the science centre was to understand
what concerns its visitors had beyond science, particularly on societal and
cultural issues. We addressed this question by developing an Artificial
Intelligence tool that can be used to perform various processing tasks:
detection of equivalence between questions; detection of topic and type; and
answering of the question. As we focused on the creation of a "generalist"
tool, we trained it with labelled data from different datasets. We called the
resulting model QBERT. This paper describes what information we extracted from
the automated analysis of the WTC corpus of open-domain questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RadBERT-CL: Factually-Aware Contrastive Learning For Radiology Report Classification. (arXiv:2110.15426v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15426">
<div class="article-summary-box-inner">
<span><p>Radiology reports are unstructured and contain the imaging findings and
corresponding diagnoses transcribed by radiologists which include clinical
facts and negated and/or uncertain statements. Extracting pathologic findings
and diagnoses from radiology reports is important for quality control,
population health, and monitoring of disease progress. Existing works,
primarily rely either on rule-based systems or transformer-based pre-trained
model fine-tuning, but could not take the factual and uncertain information
into consideration, and therefore generate false-positive outputs. In this
work, we introduce three sedulous augmentation techniques which retain factual
and critical information while generating augmentations for contrastive
learning. We introduce RadBERT-CL, which fuses these information into BlueBert
via a self-supervised contrastive loss. Our experiments on MIMIC-CXR show
superior performance of RadBERT-CL on fine-tuning for multi-class, multi-label
report classification. We illustrate that when few labeled data are available,
RadBERT-CL outperforms conventional SOTA transformers (BERT/BlueBert) by
significantly larger margins (6-11%). We also show that the representations
learned by RadBERT-CL can capture critical medical information in the latent
space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Noise Robustness of Contrastive Speech Representation Learning with Speech Reconstruction. (arXiv:2110.15430v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15430">
<div class="article-summary-box-inner">
<span><p>Noise robustness is essential for deploying automatic speech recognition
(ASR) systems in real-world environments. One way to reduce the effect of noise
interference is to employ a preprocessing module that conducts speech
enhancement, and then feed the enhanced speech to an ASR backend. In this work,
instead of suppressing background noise with a conventional cascaded pipeline,
we employ a noise-robust representation learned by a refined self-supervised
framework for noisy speech recognition. We propose to combine a reconstruction
module with contrastive learning and perform multi-task continual pre-training
on noisy data. The reconstruction module is used for auxiliary learning to
improve the noise robustness of the learned representation and thus is not
required during inference. Experiments demonstrate the effectiveness of our
proposed method. Our model substantially reduces the word error rate (WER) for
the synthesized noisy LibriSpeech test sets, and yields around 4.1/7.5% WER
reduction on noisy clean/other test sets compared to data augmentation. For the
real-world noisy speech from the CHiME-4 challenge (1-channel track), we have
obtained the state of the art ASR performance without any denoising front-end.
Moreover, we achieve comparable performance to the best supervised approach
reported with only 16% of labeled data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Text Analytics for Health to Get Meaningful Insights from a Corpus of COVID Scientific Papers. (arXiv:2110.15453v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15453">
<div class="article-summary-box-inner">
<span><p>Since the beginning of COVID pandemic, there have been around 700000
scientific papers published on the subject. A human researcher cannot possibly
get acquainted with such a huge text corpus -- and therefore developing
AI-based tools to help navigating this corpus and deriving some useful insights
from it is highly needed. In this paper, we will use Text Analytics for Health
pre-trained service together with some cloud tools to extract some knowledge
from scientific papers, gain insights, and build a tool to help researcher
navigate the paper collection in a meaningful way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Personal Food Preferences via Food Logs Embedding. (arXiv:2110.15498v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15498">
<div class="article-summary-box-inner">
<span><p>Diet management is key to managing chronic diseases such as diabetes.
Automated food recommender systems may be able to assist by providing meal
recommendations that conform to a user's nutrition goals and food preferences.
Current recommendation systems suffer from a lack of accuracy that is in part
due to a lack of knowledge of food preferences, namely foods users like to and
are able to eat frequently. In this work, we propose a method for learning food
preferences from food logs, a comprehensive but noisy source of information
about users' dietary habits. We also introduce accompanying metrics. The method
generates and compares word embeddings to identify the parent food category of
each food entry and then calculates the most popular. Our proposed approach
identifies 82% of a user's ten most frequently eaten foods. Our method is
publicly available on (https://github.com/aametwally/LearningFoodPreferences)
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-training Co-evolutionary Protein Representation via A Pairwise Masked Language Model. (arXiv:2110.15527v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15527">
<div class="article-summary-box-inner">
<span><p>Understanding protein sequences is vital and urgent for biology, healthcare,
and medicine. Labeling approaches are expensive yet time-consuming, while the
amount of unlabeled data is increasing quite faster than that of the labeled
data due to low-cost, high-throughput sequencing methods. In order to extract
knowledge from these unlabeled data, representation learning is of significant
value for protein-related tasks and has great potential for helping us learn
more about protein functions and structures. The key problem in the protein
sequence representation learning is to capture the co-evolutionary information
reflected by the inter-residue co-variation in the sequences. Instead of
leveraging multiple sequence alignment as is usually done, we propose a novel
method to capture this information directly by pre-training via a dedicated
language model, i.e., Pairwise Masked Language Model (PMLM). In a conventional
masked language model, the masked tokens are modeled by conditioning on the
unmasked tokens only, but processed independently to each other. However, our
proposed PMLM takes the dependency among masked tokens into consideration,
i.e., the probability of a token pair is not equal to the product of the
probability of the two tokens. By applying this model, the pre-trained encoder
is able to generate a better representation for protein sequences. Our result
shows that the proposed method can effectively capture the inter-residue
correlations and improves the performance of contact prediction by up to 9%
compared to the MLM baseline under the same setting. The proposed model also
significantly outperforms the MSA baseline by more than 7% on the TAPE contact
prediction benchmark when pre-trained on a subset of the sequence database
which the MSA is generated from, revealing the potential of the sequence
pre-training method to surpass MSA based methods in general.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structure-aware Fine-tuning of Sequence-to-sequence Transformers for Transition-based AMR Parsing. (arXiv:2110.15534v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15534">
<div class="article-summary-box-inner">
<span><p>Predicting linearized Abstract Meaning Representation (AMR) graphs using
pre-trained sequence-to-sequence Transformer models has recently led to large
improvements on AMR parsing benchmarks. These parsers are simple and avoid
explicit modeling of structure but lack desirable properties such as graph
well-formedness guarantees or built-in graph-sentence alignments. In this work
we explore the integration of general pre-trained sequence-to-sequence language
models and a structure-aware transition-based approach. We depart from a
pointer-based transition system and propose a simplified transition set,
designed to better exploit pre-trained language models for structured
fine-tuning. We also explore modeling the parser state within the pre-trained
encoder-decoder architecture and different vocabulary strategies for the same
purpose. We provide a detailed comparison with recent progress in AMR parsing
and show that the proposed parser retains the desirable properties of previous
transition-based approaches, while being simpler and reaching the new parsing
state of the art for AMR 2.0, without the need for graph re-categorization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Hand Sign Recognition: Identify Unusuality through Latent Cognizance. (arXiv:2110.15542v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15542">
<div class="article-summary-box-inner">
<span><p>Sign language is a main communication channel among hearing disability
community. Automatic sign language transcription could facilitate better
communication and understanding between hearing disability community and
hearing majority. As a recent work in automatic sign language transcription has
discussed, effectively handling or identifying a non-sign posture is one of the
key issues. A non-sign posture is a posture unintended for sign reading and
does not belong to any valid sign. A non-sign posture may arise during sign
transition or simply from an unaware posture. Confidence ratio has been
proposed to mitigate the issue. Confidence ratio is simple to compute and
readily available without extra training. However, confidence ratio is reported
to only partially address the problem. In addition, confidence ratio
formulation is susceptible to computational instability. This article proposes
alternative formulations to confidence ratio, investigates an issue of non-sign
identification for Thai Finger Spelling recognition, explores potential
solutions and has found a promising direction. Not only does this finding
address the issue of non-sign identification, it also provide some insight
behind a well-learned inference machine, revealing hidden meaning and new
interpretation of the underlying mechanism. Our proposed methods are evaluated
and shown to be effective for non-sign detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Handshakes AI Research at CASE 2021 Task 1: Exploring different approaches for multilingual tasks. (arXiv:2110.15599v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15599">
<div class="article-summary-box-inner">
<span><p>The aim of the CASE 2021 Shared Task 1 (H\"urriyeto\u{g}lu et al., 2021) was
to detect and classify socio-political and crisis event information at
document, sentence, cross-sentence, and token levels in a multilingual setting,
with each of these subtasks being evaluated separately in each test language.
Our submission contained entries in all of the subtasks, and the scores
obtained validated our research finding: That the multilingual aspect of the
tasks should be embraced, so that modeling and training regimes use the
multilingual nature of the tasks to their mutual benefit, rather than trying to
tackle the different languages separately. Our code is available at
https://github.com/HandshakesByDC/case2021/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare. (arXiv:2110.15621v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15621">
<div class="article-summary-box-inner">
<span><p>Mental health is a critical issue in modern society, and mental disorders
could sometimes turn to suicidal ideation without adequate treatment. Early
detection of mental disorders and suicidal ideation from social content
provides a potential way for effective social intervention. Recent advances in
pretrained contextualized language representations have promoted the
development of several domain-specific pretrained models and facilitated
several downstream applications. However, there are no existing pretrained
language models for mental healthcare. This paper trains and release two
pretrained masked language models, i.e., MentalBERT and MentalRoBERTa, to
benefit machine learning for the mental healthcare research community. Besides,
we evaluate our trained domain-specific models and several variants of
pretrained language models on several mental disorder detection benchmarks and
demonstrate that language representations pretrained in the target domain
improve the performance of mental health detection tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Path-Enhanced Multi-Relational Question Answering with Knowledge Graph Embeddings. (arXiv:2110.15622v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15622">
<div class="article-summary-box-inner">
<span><p>The multi-relational Knowledge Base Question Answering (KBQA) system performs
multi-hop reasoning over the knowledge graph (KG) to achieve the answer. Recent
approaches attempt to introduce the knowledge graph embedding (KGE) technique
to handle the KG incompleteness but only consider the triple facts and neglect
the significant semantic correlation between paths and multi-relational
questions. In this paper, we propose a Path and Knowledge Embedding-Enhanced
multi-relational Question Answering model (PKEEQA), which leverages multi-hop
paths between entities in the KG to evaluate the ambipolar correlation between
a path embedding and a multi-relational question embedding via a customizable
path representation mechanism, benefiting for achieving more accurate answers
from the perspective of both the triple facts and the extra paths. Experimental
results illustrate that PKEEQA improves KBQA models' performance for
multi-relational question answering with explainability to some extent derived
from paths.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Amendable Generation for Dialogue State Tracking. (arXiv:2110.15659v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15659">
<div class="article-summary-box-inner">
<span><p>In task-oriented dialogue systems, recent dialogue state tracking methods
tend to perform one-pass generation of the dialogue state based on the previous
dialogue state. The mistakes of these models made at the current turn are prone
to be carried over to the next turn, causing error propagation. In this paper,
we propose a novel Amendable Generation for Dialogue State Tracking (AG-DST),
which contains a two-pass generation process: (1) generating a primitive
dialogue state based on the dialogue of the current turn and the previous
dialogue state, and (2) amending the primitive dialogue state from the first
pass. With the additional amending generation pass, our model is tasked to
learn more robust dialogue state tracking by amending the errors that still
exist in the primitive dialogue state, which plays the role of reviser in the
double-checking process and alleviates unnecessary error propagation.
Experimental results show that AG-DST significantly outperforms previous works
in two active DST datasets (MultiWOZ 2.2 and WOZ 2.0), achieving new
state-of-the-art performances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overview of ADoBo 2021: Automatic Detection of Unassimilated Borrowings in the Spanish Press. (arXiv:2110.15682v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15682">
<div class="article-summary-box-inner">
<span><p>This paper summarizes the main findings of the ADoBo 2021 shared task,
proposed in the context of IberLef 2021. In this task, we invited participants
to detect lexical borrowings (coming mostly from English) in Spanish newswire
texts. This task was framed as a sequence classification problem using BIO
encoding. We provided participants with an annotated corpus of lexical
borrowings which we split into training, development and test splits. We
received submissions from 4 teams with 9 different system runs overall. The
results, which range from F1 scores of 37 to 85, suggest that this is a
challenging task, especially when out-of-domain or OOV words are considered,
and that traditional methods informed with lexicographic information would
benefit from taking advantage of current NLP trends.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fusing ASR Outputs in Joint Training for Speech Emotion Recognition. (arXiv:2110.15684v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15684">
<div class="article-summary-box-inner">
<span><p>Alongside acoustic information, linguistic features based on speech
transcripts have been proven useful in Speech Emotion Recognition (SER).
However, due to the scarcity of emotion labelled data and the difficulty of
recognizing emotional speech, it is hard to obtain reliable linguistic features
and models in this research area. In this paper, we propose to fuse Automatic
Speech Recognition (ASR) outputs into the pipeline for joint training SER. The
relationship between ASR and SER is understudied, and it is unclear what and
how ASR features benefit SER. By examining various ASR outputs and fusion
methods, our experiments show that in joint ASR-SER training, incorporating
both ASR hidden and text output using a hierarchical co-attention fusion
approach improves the SER performance the most. On the IEMOCAP corpus, our
approach achieves 63.4% weighted accuracy, which is close to the baseline
results achieved by combining ground-truth transcripts. In addition, we also
present novel word error rate analysis on IEMOCAP and layer-difference analysis
of the Wav2vec 2.0 model to better understand the relationship between ASR and
SER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Navigating the Kaleidoscope of COVID-19 Misinformation Using Deep Learning. (arXiv:2110.15703v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15703">
<div class="article-summary-box-inner">
<span><p>Irrespective of the success of the deep learning-based mixed-domain transfer
learning approach for solving various Natural Language Processing tasks, it
does not lend a generalizable solution for detecting misinformation from
COVID-19 social media data. Due to the inherent complexity of this type of
data, caused by its dynamic (context evolves rapidly), nuanced (misinformation
types are often ambiguous), and diverse (skewed, fine-grained, and overlapping
categories) nature, it is imperative for an effective model to capture both the
local and global context of the target domain. By conducting a systematic
investigation, we show that: (i) the deep Transformer-based pre-trained models,
utilized via the mixed-domain transfer learning, are only good at capturing the
local context, thus exhibits poor generalization, and (ii) a combination of
shallow network-based domain-specific models and convolutional neural networks
can efficiently extract local as well as global context directly from the
target data in a hierarchical fashion, enabling it to offer a more
generalizable solution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Influence of ASR and Language Model on Alzheimer's Disease Detection. (arXiv:2110.15704v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15704">
<div class="article-summary-box-inner">
<span><p>Alzheimer's Disease is the most common form of dementia. Automatic detection
from speech could help to identify symptoms at early stages, so that preventive
actions can be carried out. This research is a contribution to the ADReSSo
Challenge, we analyze the usage of a SotA ASR system to transcribe
participant's spoken descriptions from a picture. We analyse the loss of
performance regarding the use of human transcriptions (measured using
transcriptions from the 2020 ADReSS Challenge). Furthermore, we study the
influence of a language model -- which tends to correct non-standard sequences
of words -- with the lack of language model to decode the hypothesis from the
ASR. This aims at studying the language bias and get more meaningful
transcriptions based only on the acoustic information from patients. The
proposed system combines acoustic -- based on prosody and voice quality -- and
lexical features based on the first occurrence of the most common words. The
reported results show the effect of using automatic transcripts with or without
language model. The best fully automatic system achieves up to 76.06 % of
accuracy (without language model), significantly higher, 3 % above, than a
system employing word transcriptions decoded using general purpose language
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling Relation Embeddings from Pre-trained Language Models. (arXiv:2110.15705v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15705">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have been found to capture a surprisingly rich
amount of lexical knowledge, ranging from commonsense properties of everyday
concepts to detailed factual knowledge about named entities. Among others, this
makes it possible to distill high-quality word vectors from pre-trained
language models. However, it is currently unclear to what extent it is possible
to distill relation embeddings, i.e. vectors that characterize the relationship
between two words. Such relation embeddings are appealing because they can, in
principle, encode relational knowledge in a more fine-grained way than is
possible with knowledge graphs. To obtain relation embeddings from a
pre-trained language model, we encode word pairs using a (manually or
automatically generated) prompt, and we fine-tune the language model such that
relationally similar word pairs yield similar output vectors. We find that the
resulting relation embeddings are highly competitive on analogy (unsupervised)
and relation classification (supervised) benchmarks, even without any
task-specific fine-tuning. Source code to reproduce our experimental results
and the model checkpoints are available in the following repository:
https://github.com/asahi417/relbert
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating Deep Event-Level and Script-Level Information for Script Event Prediction. (arXiv:2110.15706v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15706">
<div class="article-summary-box-inner">
<span><p>Scripts are structured sequences of events together with the participants,
which are extracted from the texts.Script event prediction aims to predict the
subsequent event given the historical events in the script. Two kinds of
information facilitate this task, namely, the event-level information and the
script-level information. At the event level, existing studies view an event as
a verb with its participants, while neglecting other useful properties, such as
the state of the participants. At the script level, most existing studies only
consider a single event sequence corresponding to one common protagonist. In
this paper, we propose a Transformer-based model, called MCPredictor, which
integrates deep event-level and script-level information for script event
prediction. At the event level, MCPredictor utilizes the rich information in
the text to obtain more comprehensive event semantic representations. At the
script-level, it considers multiple event sequences corresponding to different
participants of the subsequent event. The experimental results on the
widely-used New York Times corpus demonstrate the effectiveness and superiority
of the proposed model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hidden Markov Based Mathematical Model dedicated to Extract Ingredients from Recipe Text. (arXiv:2110.15707v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15707">
<div class="article-summary-box-inner">
<span><p>Natural Language Processing (NLP) is a branch of artificial intelligence that
gives machines the ability to decode human languages. Partof-speech tagging
(POS tagging) is a pre-processing task that requires an annotated corpus.
Rule-based and stochastic methods showed remarkable results for POS tag
prediction. On this work, I performed a mathematical model based on Hidden
Markov structures and I obtained a high-level accuracy of ingredients extracted
from text recipe with performances greater than what traditional methods could
make without unknown words consideration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural sentence embedding models for semantic similarity estimation in the biomedical domain. (arXiv:2110.15708v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15708">
<div class="article-summary-box-inner">
<span><p>BACKGROUND: In this study, we investigated the efficacy of current
state-of-the-art neural sentence embedding models for semantic similarity
estimation of sentences from biomedical literature. We trained different neural
embedding models on 1.7 million articles from the PubMed Open Access dataset,
and evaluated them based on a biomedical benchmark set containing 100 sentence
pairs annotated by human experts and a smaller contradiction subset derived
from the original benchmark set.
</p>
<p>RESULTS: With a Pearson correlation of 0.819, our best unsupervised model
based on the Paragraph Vector Distributed Memory algorithm outperforms previous
state-of-the-art results achieved on the BIOSSES biomedical benchmark set.
Moreover, our proposed supervised model that combines different string-based
similarity metrics with a neural embedding model surpasses previous
ontology-dependent supervised state-of-the-art approaches in terms of Pearson's
r (r=0.871) on the biomedical benchmark set. In contrast to the promising
results for the original benchmark, we found our best models' performance on
the smaller contradiction subset to be poor.
</p>
<p>CONCLUSIONS: In this study we highlighted the value of neural network-based
models for semantic similarity estimation in the biomedical domain by showing
that they can keep up with and even surpass previous state-of-the-art
approaches for semantic similarity estimation that depend on the availability
of laboriously curated ontologies when evaluated on a biomedical benchmark set.
Capturing contradictions and negations in biomedical sentences, however,
emerged as an essential area for further work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LegalNLP -- Natural Language Processing methods for the Brazilian Legal Language. (arXiv:2110.15709v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15709">
<div class="article-summary-box-inner">
<span><p>We present and make available pre-trained language models (Phraser, Word2Vec,
Doc2Vec, FastText, and BERT) for the Brazilian legal language, a Python package
with functions to facilitate their use, and a set of demonstrations/tutorials
containing some applications involving them. Given that our material is built
upon legal texts coming from several Brazilian courts, this initiative is
extremely helpful for the Brazilian legal field, which lacks other open and
specific tools and language models. Our main objective is to catalyze the use
of natural language processing tools for legal texts analysis by the Brazilian
industry, government, and academia, providing the necessary tools and
accessible material.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of hierarchical text using geometric deep learning: the case of clinical trials corpus. (arXiv:2110.15710v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15710">
<div class="article-summary-box-inner">
<span><p>We consider the hierarchical representation of documents as graphs and use
geometric deep learning to classify them into different categories. While graph
neural networks can efficiently handle the variable structure of hierarchical
documents using the permutation invariant message passing operations, we show
that we can gain extra performance improvements using our proposed selective
graph pooling operation that arises from the fact that some parts of the
hierarchy are invariable across different documents. We applied our model to
classify clinical trial (CT) protocols into completed and terminated
categories. We use bag-of-words based, as well as pre-trained transformer-based
embeddings to featurize the graph nodes, achieving f1-scores around 0.85 on a
publicly available large scale CT registry of around 360K protocols. We further
demonstrate how the selective pooling can add insights into the CT termination
status prediction. We make the source code and dataset splits accessible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysing the Effect of Masking Length Distribution of MLM: An Evaluation Framework and Case Study on Chinese MRC Datasets. (arXiv:2110.15712v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15712">
<div class="article-summary-box-inner">
<span><p>Machine reading comprehension (MRC) is a challenging natural language
processing (NLP) task. Recently, the emergence of pre-trained models (PTM) has
brought this research field into a new era, in which the training objective
plays a key role. The masked language model (MLM) is a self-supervised training
objective that widely used in various PTMs. With the development of training
objectives, many variants of MLM have been proposed, such as whole word
masking, entity masking, phrase masking, span masking, and so on. In different
MLM, the length of the masked tokens is different. Similarly, in different
machine reading comprehension tasks, the length of the answer is also
different, and the answer is often a word, phrase, or sentence. Thus, in MRC
tasks with different answer lengths, whether the length of MLM is related to
performance is a question worth studying. If this hypothesis is true, it can
guide us how to pre-train the MLM model with a relatively suitable mask length
distribution for MRC task. In this paper, we try to uncover how much of MLM's
success in the machine reading comprehension tasks comes from the correlation
between masking length distribution and answer length in MRC dataset. In order
to address this issue, herein, (1) we propose four MRC tasks with different
answer length distributions, namely short span extraction task, long span
extraction task, short multiple-choice cloze task, long multiple-choice cloze
task; (2) four Chinese MRC datasets are created for these tasks; (3) we also
have pre-trained four masked language models according to the answer length
distributions of these datasets; (4) ablation experiments are conducted on the
datasets to verify our hypothesis. The experimental results demonstrate that
our hypothesis is true.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building the Language Resource for a Cebuano-Filipino Neural Machine Translation System. (arXiv:2110.15716v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15716">
<div class="article-summary-box-inner">
<span><p>Parallel corpus is a critical resource in machine learning-based translation.
The task of collecting, extracting, and aligning texts in order to build an
acceptable corpus for doing the translation is very tedious most especially for
low-resource languages. In this paper, we present the efforts made to build a
parallel corpus for Cebuano and Filipino from two different domains: biblical
texts and the web. For the biblical resource, subword unit translation for
verbs and copy-able approach for nouns were applied to correct inconsistencies
in the translation. This correction mechanism was applied as a preprocessing
technique. On the other hand, for Wikipedia being the main web resource,
commonly occurring topic segments were extracted from both the source and the
target languages. These observed topic segments are unique in 4 different
categories. The identification of these topic segments may be used for the
automatic extraction of sentences. A Recurrent Neural Network was used to
implement the translation using OpenNMT sequence modeling tool in TensorFlow.
The two different corpora were then evaluated by using them as two separate
inputs in the neural network. Results have shown a difference in BLEU scores in
both corpora.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LIDSNet: A Lightweight on-device Intent Detection model using Deep Siamese Network. (arXiv:2110.15717v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15717">
<div class="article-summary-box-inner">
<span><p>Intent detection is a crucial task in any Natural Language Understanding
(NLU) system and forms the foundation of a task-oriented dialogue system. To
build high-quality real-world conversational solutions for edge devices, there
is a need for deploying intent detection model on device. This necessitates a
light-weight, fast, and accurate model that can perform efficiently in a
resource-constrained environment. To this end, we propose LIDSNet, a novel
lightweight on-device intent detection model, which accurately predicts the
message intent by utilizing a Deep Siamese Network for learning better sentence
representations. We use character-level features to enrich the sentence-level
representations and empirically demonstrate the advantage of transfer learning
by utilizing pre-trained embeddings. Furthermore, to investigate the efficacy
of the modules in our architecture, we conduct an ablation study and arrive at
our optimal model. Experimental results prove that LIDSNet achieves
state-of-the-art competitive accuracy of 98.00% and 95.97% on SNIPS and ATIS
public datasets respectively, with under 0.59M parameters. We further benchmark
LIDSNet against fine-tuned BERTs and show that our model is at least 41x
lighter and 30x faster during inference than MobileBERT on Samsung Galaxy S20
device, justifying its efficiency on resource-constrained edge devices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep convolutional forest: a dynamic deep ensemble approach for spam detection in text. (arXiv:2110.15718v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15718">
<div class="article-summary-box-inner">
<span><p>The increase in people's use of mobile messaging services has led to the
spread of social engineering attacks like phishing, considering that spam text
is one of the main factors in the dissemination of phishing attacks to steal
sensitive data such as credit cards and passwords. In addition, rumors and
incorrect medical information regarding the COVID-19 pandemic are widely shared
on social media leading to people's fear and confusion. Thus, filtering spam
content is vital to reduce risks and threats. Previous studies relied on
machine learning and deep learning approaches for spam classification, but
these approaches have two limitations. Machine learning models require manual
feature engineering, whereas deep neural networks require a high computational
cost. This paper introduces a dynamic deep ensemble model for spam detection
that adjusts its complexity and extracts features automatically. The proposed
model utilizes convolutional and pooling layers for feature extraction along
with base classifiers such as random forests and extremely randomized trees for
classifying texts into spam or legitimate ones. Moreover, the model employs
ensemble learning procedures like boosting and bagging. As a result, the model
achieved high precision, recall, f1-score and accuracy of 98.38%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Concept Map Generation through Task-Guided Graph Translation. (arXiv:2110.15720v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15720">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the rapid development of concept map generation
techniques due to their advantages in providing well-structured summarization
of knowledge from free texts. Traditional unsupervised methods do not generate
task-oriented concept maps, whereas deep generative models require large
amounts of training data. In this work, we present GT-D2G (Graph Translation
based Document-To-Graph), an automatic concept map generation framework that
leverages generalized NLP pipelines to derive semantic-rich initial graphs, and
translates them into more concise structures under the weak supervision of
document labels. The quality and interpretability of such concept maps are
validated through human evaluation on three real-world corpora, and their
utility in the downstream task is further demonstrated in the controlled
experiments with scarce document labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Paperswithtopic: Topic Identification from Paper Title Only. (arXiv:2110.15721v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15721">
<div class="article-summary-box-inner">
<span><p>The deep learning field is growing rapidly as witnessed by the exponential
growth of papers submitted to journals, conferences, and pre-print servers. To
cope with the sheer number of papers, several text mining tools from natural
language processing (NLP) have been proposed that enable researchers to keep
track of recent findings. In this context, our paper makes two main
contributions: first, we collected and annotated a dataset of papers paired by
title and sub-field from the field of artificial intelligence (AI), and,
second, we present results on how to predict a paper's AI sub-field from a
given paper title only. Importantly, for the latter, short-text classification
task we compare several algorithms from conventional machine learning all the
way up to recent, larger transformer architectures. Finally, for the
transformer models, we also present gradient-based, attention visualizations to
further explain the model's classification process. All code can be found at
\url{https://github.com/1pha/paperswithtopic}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Sequence Tagging Framework for Consumer Event-Cause Extraction. (arXiv:2110.15722v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15722">
<div class="article-summary-box-inner">
<span><p>Consumer Event-Cause Extraction, the task aimed at extracting the potential
causes behind certain events in the text, has gained much attention in recent
years due to its wide applications. The ICDM 2020 conference sets up an
evaluation competition that aims to extract events and the causes of the
extracted events with a specified subject (a brand or product). In this task,
we mainly focus on how to construct an end-to-end model, and extract multiple
event types and event-causes simultaneously. To this end, we introduce a fresh
perspective to revisit the relational event-cause extraction task and propose a
novel sequence tagging framework, instead of extracting event types and
events-causes separately. Experiments show our framework outperforms baseline
methods even when its encoder module uses an initialized pre-trained BERT
encoder, showing the power of the new tagging framework. In this competition,
our team achieved 1st place in the first stage leaderboard, and 3rd place in
the final stage leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SP-GPT2: Semantics Improvement in Vietnamese Poetry Generation. (arXiv:2110.15723v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15723">
<div class="article-summary-box-inner">
<span><p>Automatic text generation has garnered growing attention in recent years as
an essential step towards computer creativity. Generative Pretraining
Transformer 2 (GPT2) is one of the state of the art approaches that have
excellent successes. In this paper, we took the first step to investigate the
power of GPT2 in traditional Vietnamese poetry generation. In the earlier time,
our experiment with base GPT2 was quite good at generating the poem in the
proper template. Though it can learn the patterns, including rhyme and tone
rules, from the training data, like almost all other text generation
approaches, the poems generated still has a topic drift and semantic
inconsistency. To improve the cohesion within the poems, we proposed a new
model SP-GPT2 (semantic poem GPT2) which was built on the top GPT2 model and an
additional loss to constrain context throughout the entire poem. For better
evaluation, we examined the methods by both automatic quantitative evaluation
and human evaluation. Both automatic and human evaluation demonstrated that our
approach can generate poems that have better cohesion without losing the
quality due to additional loss. At the same time, we are the pioneers of this
topic. We released the first computational scoring module for poems generated
in the template containing the style rule dictionary. Additionally, we are the
first to publish a Luc-Bat dataset, including 87609 Luc Bat poems, which is
equivalent to about 2.6 million sentences, combined with about 83579 poems in
other styles was also published for further exploration. The code is available
at https://github.com/fsoft-ailab/Poem-Generator
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Learn End-to-End Goal-Oriented Dialog From Related Dialog Tasks. (arXiv:2110.15724v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15724">
<div class="article-summary-box-inner">
<span><p>For each goal-oriented dialog task of interest, large amounts of data need to
be collected for end-to-end learning of a neural dialog system. Collecting that
data is a costly and time-consuming process. Instead, we show that we can use
only a small amount of data, supplemented with data from a related dialog task.
Naively learning from related data fails to improve performance as the related
data can be inconsistent with the target task. We describe a meta-learning
based method that selectively learns from the related dialog task data. Our
approach leads to significant accuracy improvements in an example dialog task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Batch-Softmax Contrastive Loss for Pairwise Sentence Scoring Tasks. (arXiv:2110.15725v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15725">
<div class="article-summary-box-inner">
<span><p>The use of contrastive loss for representation learning has become prominent
in computer vision, and it is now getting attention in Natural Language
Processing (NLP). Here, we explore the idea of using a batch-softmax
contrastive loss when fine-tuning large-scale pre-trained transformer models to
learn better task-specific sentence embeddings for pairwise sentence scoring
tasks. We introduce and study a number of variations in the calculation of the
loss as well as in the overall training procedure; in particular, we find that
data shuffling can be quite important. Our experimental results show sizable
improvements on a number of datasets and pairwise sentence scoring tasks
including classification, ranking, and regression. Finally, we offer detailed
analysis and discussion, which should be useful for researchers aiming to
explore the utility of contrastive loss in NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Social Media Reveals Urban-Rural Differences in Stress across China. (arXiv:2110.15726v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15726">
<div class="article-summary-box-inner">
<span><p>Modeling differential stress expressions in urban and rural regions in China
can provide a better understanding of the effects of urbanization on
psychological well-being in a country that has rapidly grown economically in
the last two decades. This paper studies linguistic differences in the
experiences and expressions of stress in urban-rural China from Weibo posts
from over 65,000 users across 329 counties using hierarchical mixed-effects
models. We analyzed phrases, topical themes, and psycho-linguistic word choices
in Weibo posts mentioning stress to better understand appraisal differences
surrounding psychological stress in urban and rural communities in China; we
then compared them with large-scale polls from Gallup. After controlling for
socioeconomic and gender differences, we found that rural communities tend to
express stress in emotional and personal themes such as relationships, health,
and opportunity while users in urban areas express stress using relative,
temporal, and external themes such as work, politics, and economics. These
differences exist beyond controlling for GDP and urbanization, indicating a
fundamentally different lifestyle between rural and urban residents in very
specific environments, arguably having different sources of stress. We found
corroborative trends in physical, financial, and social wellness with
urbanization in Gallup polls.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calling to CNN-LSTM for Rumor Detection: A Deep Multi-channel Model for Message Veracity Classification in Microblogs. (arXiv:2110.15727v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15727">
<div class="article-summary-box-inner">
<span><p>Reputed by their low-cost, easy-access, real-time and valuable information,
social media also wildly spread unverified or fake news. Rumors can notably
cause severe damage on individuals and the society. Therefore, rumor detection
on social media has recently attracted tremendous attention. Most rumor
detection approaches focus on rumor feature analysis and social features, i.e.,
metadata in social media. Unfortunately, these features are data-specific and
may not always be available, e.g., when the rumor has just popped up and not
yet propagated. In contrast, post contents (including images or videos) play an
important role and can indicate the diffusion purpose of a rumor. Furthermore,
rumor classification is also closely related to opinion mining and sentiment
analysis. Yet, to the best of our knowledge, exploiting images and sentiments
is little investigated.Considering the available multimodal features from
microblogs, notably, we propose in this paper an end-to-end model called
deepMONITOR that is based on deep neural networks and allows quite accurate
automated rumor verification, by utilizing all three characteristics: post
textual and image contents, as well as sentiment. deepMONITOR concatenates
image features with the joint text and sentiment features to produce a
reliable, fused classification. We conduct extensive experiments on two
large-scale, real-world datasets. The results show that deepMONITOR achieves a
higher accuracy than state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Bias Detection: From Inception to Deployment. (arXiv:2110.15728v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15728">
<div class="article-summary-box-inner">
<span><p>To create a more inclusive workplace, enterprises are actively investing in
identifying and eliminating unconscious bias (e.g., gender, race, age,
disability, elitism and religion) across their various functions. We propose a
deep learning model with a transfer learning based language model to learn from
manually tagged documents for automatically identifying bias in enterprise
content. We first pretrain a deep learning-based language-model using
Wikipedia, then fine tune the model with a large unlabelled data set related
with various types of enterprise content. Finally, a linear layer followed by
softmax layer is added at the end of the language model and the model is
trained on a labelled bias dataset consisting of enterprise content. The
trained model is thoroughly evaluated on independent datasets to ensure a
general application. We present the proposed method and its deployment detail
in a real-world application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decision Attentive Regularization to Improve Simultaneous Speech Translation Systems. (arXiv:2110.15729v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15729">
<div class="article-summary-box-inner">
<span><p>Simultaneous Speech-to-text Translation (SimulST) systems translate source
speech in tandem with the speaker using partial input. Recent works have tried
to leverage the text translation task to improve the performance of Speech
Translation (ST) in the offline domain. Motivated by these improvements, we
propose to add Decision Attentive Regularization (DAR) to Monotonic Multihead
Attention (MMA) based SimulST systems. DAR improves the read/write decisions
for speech using the Simultaneous text Translation (SimulMT) task. We also
extend several techniques from the offline domain to the SimulST task. Our
proposed system achieves significant performance improvements for the MuST-C
English-German (EnDe) SimulST task, where we provide an average BLUE score
improvement of around 4.57 points or 34.17% across different latencies.
Further, the latency-quality tradeoffs establish that the proposed model
achieves better results compared to the baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">E-Commerce Dispute Resolution Prediction. (arXiv:2110.15730v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15730">
<div class="article-summary-box-inner">
<span><p>E-Commerce marketplaces support millions of daily transactions, and some
disagreements between buyers and sellers are unavoidable. Resolving disputes in
an accurate, fast, and fair manner is of great importance for maintaining a
trustworthy platform. Simple cases can be automated, but intricate cases are
not sufficiently addressed by hard-coded rules, and therefore most disputes are
currently resolved by people. In this work we take a first step towards
automatically assisting human agents in dispute resolution at scale. We
construct a large dataset of disputes from the eBay online marketplace, and
identify several interesting behavioral and linguistic patterns. We then train
classifiers to predict dispute outcomes with high accuracy. We explore the
model and the dataset, reporting interesting correlations, important features,
and insights.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CORAA: a large corpus of spontaneous and prepared speech manually validated for speech recognition in Brazilian Portuguese. (arXiv:2110.15731v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15731">
<div class="article-summary-box-inner">
<span><p>Automatic Speech recognition (ASR) is a complex and challenging task. In
recent years, there have been significant advances in the area. In particular,
for the Brazilian Portuguese (BP) language, there were about 376 hours public
available for ASR task until the second half of 2020. With the release of new
datasets in early 2021, this number increased to 574 hours. The existing
resources, however, are composed of audios containing only read and prepared
speech. There is a lack of datasets including spontaneous speech, which are
essential in different ASR applications. This paper presents CORAA (Corpus of
Annotated Audios) v1. with 291 hours, a publicly available dataset for ASR in
BP containing validated pairs (audio-transcription). CORAA also contains
European Portuguese audios (4.69 hours). We also present two public ASR models
based on Wav2Vec 2.0 XLSR-53 and fine-tuned over CORAA. Our best model achieved
a Word Error Rate of 27.35% on CORAA test set and 16.01% on Common Voice test
set. When measuring the Character Error Rate, we obtained 14.26% and 5.45% for
CORAA and Common Voice, respectively. CORAA corpora were assembled to both
improve ASR models in BP with phenomena from spontaneous speech and motivate
young researchers to start their studies on ASR for Portuguese. All the corpora
are publicly available at https://github.com/nilc-nlp/CORAA under the CC
BY-NC-ND 4.0 license.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Named Entity Recognition in Unstructured Medical Text Documents. (arXiv:2110.15732v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15732">
<div class="article-summary-box-inner">
<span><p>Physicians provide expert opinion to legal courts on the medical state of
patients, including determining if a patient is likely to have permanent or
non-permanent injuries or ailments. An independent medical examination (IME)
report summarizes a physicians medical opinion about a patients health status
based on the physicians expertise. IME reports contain private and sensitive
information (Personally Identifiable Information or PII) that needs to be
removed or randomly encoded before further research work can be conducted. In
our study the IME is an orthopedic surgeon from a private practice in the
United States. The goal of this research is to perform named entity recognition
(NER) to identify and subsequently remove/encode PII information from IME
reports prepared by the physician. We apply the NER toolkits of OpenNLP and
spaCy, two freely available natural language processing platforms, and compare
their precision, recall, and f-measure performance at identifying five
categories of PII across trials of randomly selected IME reports using each
models common default parameters. We find that both platforms achieve high
performance (f-measure &gt; 0.9) at de-identification and that a spaCy model
trained with a 70-30 train-test data split is most performant.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Gender Bias in Transformer-based Models: A Case Study on BERT. (arXiv:2110.15733v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15733">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel gender bias detection method by utilizing
attention map for transformer-based models. We 1) give an intuitive gender bias
judgement method by comparing the different relation degree between the genders
and the occupation according to the attention scores, 2) design a gender bias
detector by modifying the attention module, 3) insert the gender bias detector
into different positions of the model to present the internal gender bias flow,
and 4) draw the consistent gender bias conclusion by scanning the entire
Wikipedia, a BERT pretraining dataset. We observe that 1) the attention
matrices, Wq and Wk introduce much more gender bias than other modules
(including the embedding layer) and 2) the bias degree changes periodically
inside of the model (attention matrix Q, K, V, and the remaining part of the
attention layer (including the fully-connected layer, the residual connection,
and the layer normalization module) enhance the gender bias while the averaged
attentions reduces the bias).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Leverage Multimodal EHR Data for Better Medical Predictions?. (arXiv:2110.15763v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15763">
<div class="article-summary-box-inner">
<span><p>Healthcare is becoming a more and more important research topic recently.
With the growing data in the healthcare domain, it offers a great opportunity
for deep learning to improve the quality of medical service. However, the
complexity of electronic health records (EHR) data is a challenge for the
application of deep learning. Specifically, the data produced in the hospital
admissions are monitored by the EHR system, which includes structured data like
daily body temperature, and unstructured data like free text and laboratory
measurements. Although there are some preprocessing frameworks proposed for
specific EHR data, the clinical notes that contain significant clinical value
are beyond the realm of their consideration. Besides, whether these different
data from various views are all beneficial to the medical tasks and how to best
utilize these data remain unclear. Therefore, in this paper, we first extract
the accompanying clinical notes from EHR and propose a method to integrate
these data, we also comprehensively study the different models and the data
leverage methods for better medical task prediction. The results on two medical
prediction tasks show that our fused model with different data outperforms the
state-of-the-art method that without clinical notes, which illustrates the
importance of our fusion method and the value of clinical note features. Our
code is available at https: //github.com/emnlp-mimic/mimic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NxMTransformer: Semi-Structured Sparsification for Natural Language Understanding via ADMM. (arXiv:2110.15766v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15766">
<div class="article-summary-box-inner">
<span><p>Natural Language Processing (NLP) has recently achieved success by using huge
pre-trained Transformer networks. However, these models often contain hundreds
of millions or even billions of parameters, bringing challenges to online
deployment due to latency constraints. Recently, hardware manufacturers have
introduced dedicated hardware for NxM sparsity to provide the flexibility of
unstructured pruning with the runtime efficiency of structured approaches. NxM
sparsity permits arbitrarily selecting M parameters to retain from a contiguous
group of N in the dense representation. However, due to the extremely high
complexity of pre-trained models, the standard sparse fine-tuning techniques
often fail to generalize well on downstream tasks, which have limited data
resources. To address such an issue in a principled manner, we introduce a new
learning framework, called NxMTransformer, to induce NxM semi-structured
sparsity on pretrained language models for natural language understanding to
obtain better performance. In particular, we propose to formulate the NxM
sparsity as a constrained optimization problem and use Alternating Direction
Method of Multipliers (ADMM) to optimize the downstream tasks while taking the
underlying hardware constraints into consideration. ADMM decomposes the NxM
sparsification problem into two sub-problems that can be solved sequentially,
generating sparsified Transformer networks that achieve high accuracy while
being able to effectively execute on newly released hardware. We apply our
approach to a wide range of NLP tasks, and our proposed method is able to
achieve 1.7 points higher accuracy in GLUE score than current practices.
Moreover, we perform detailed analysis on our approach and shed light on how
ADMM affects fine-tuning accuracy for downstream tasks. Finally, we illustrate
how NxMTransformer achieves performance improvement with knowledge
distillation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Machine Learning-Centered Approaches for Forecasting Language Patterns During Frustration in Early Childhood. (arXiv:2110.15778v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15778">
<div class="article-summary-box-inner">
<span><p>When faced with self-regulation challenges, children have been known the use
their language to inhibit their emotions and behaviors. Yet, to date, there has
been a critical lack of evidence regarding what patterns in their speech
children use during these moments of frustration. In this paper, eXtreme
Gradient Boosting, Random Forest, Long Short-Term Memory Recurrent Neural
Networks, and Elastic Net Regression, have all been used to forecast these
language patterns in children. Based on the results of a comparative analysis
between these methods, the study reveals that when dealing with
high-dimensional and dense data, with very irregular and abnormal
distributions, as is the case with self-regulation patterns in children,
decision tree-based algorithms are able to outperform traditional regression
and neural network methods in their shortcomings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Feasibility of Predicting Questions being Forgotten in Stack Overflow. (arXiv:2110.15789v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15789">
<div class="article-summary-box-inner">
<span><p>For their attractiveness, comprehensiveness and dynamic coverage of relevant
topics, community-based question answering sites such as Stack Overflow heavily
rely on the engagement of their communities: Questions on new technologies,
technology features as well as technology versions come up and have to be
answered as technology evolves (and as community members gather experience with
it). At the same time, other questions cease in importance over time, finally
becoming irrelevant to users. Beyond filtering low-quality questions,
"forgetting" questions, which have become redundant, is an important step for
keeping the Stack Overflow content concise and useful. In this work, we study
this managed forgetting task for Stack Overflow. Our work is based on data from
more than a decade (2008 - 2019) - covering 18.1M questions, that are made
publicly available by the site itself. For establishing a deeper understanding,
we first analyze and characterize the set of questions about to be forgotten,
i.e., questions that get a considerable number of views in the current period
but become unattractive in the near future. Subsequently, we examine the
capability of a wide range of features in predicting such forgotten questions
in different categories. We find some categories in which those questions are
more predictable. We also discover that the text-based features are
surprisingly not helpful in this prediction task, while the meta information is
much more predictive.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLAUSEREC: A Clause Recommendation Framework for AI-aided Contract Authoring. (arXiv:2110.15794v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15794">
<div class="article-summary-box-inner">
<span><p>Contracts are a common type of legal document that frequent in several
day-to-day business workflows. However, there has been very limited NLP
research in processing such documents, and even lesser in generating them.
These contracts are made up of clauses, and the unique nature of these clauses
calls for specific methods to understand and generate such documents. In this
paper, we introduce the task of clause recommendation, asa first step to aid
and accelerate the author-ing of contract documents. We propose a two-staged
pipeline to first predict if a specific clause type is relevant to be added in
a contract, and then recommend the top clauses for the given type based on the
contract context. We pretrain BERT on an existing library of clauses with two
additional tasks and use it for our prediction and recommendation. We
experiment with classification methods and similarity-based heuristics for
clause relevance prediction, and generation-based methods for clause
recommendation, and evaluate the results from various methods on several clause
types. We provide analyses on the results, and further outline the advantages
and limitations of the various methods for this line of research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discovering Non-monotonic Autoregressive Orderings with Variational Inference. (arXiv:2110.15797v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15797">
<div class="article-summary-box-inner">
<span><p>The predominant approach for language modeling is to process sequences from
left to right, but this eliminates a source of information: the order by which
the sequence was generated. One strategy to recover this information is to
decode both the content and ordering of tokens. Existing approaches supervise
content and ordering by designing problem-specific loss functions and
pre-training with an ordering pre-selected. Other recent works use iterative
search to discover problem-specific orderings for training, but suffer from
high time complexity and cannot be efficiently parallelized. We address these
limitations with an unsupervised parallelizable learner that discovers
high-quality generation orders purely from training data -- no domain knowledge
required. The learner contains an encoder network and decoder language model
that perform variational inference with autoregressive orders (represented as
permutation matrices) as latent variables. The corresponding ELBO is not
differentiable, so we develop a practical algorithm for end-to-end optimization
using policy gradients. We implement the encoder as a Transformer with
non-causal attention that outputs permutations in one forward pass.
Permutations then serve as target generation orders for training an
insertion-based Transformer language model. Empirical results in language
modeling tasks demonstrate that our method is context-aware and discovers
orderings that are competitive with or even better than fixed orders.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guided Policy Search for Parameterized Skills using Adverbs. (arXiv:2110.15799v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15799">
<div class="article-summary-box-inner">
<span><p>We present a method for using adverb phrases to adjust skill parameters via
learned adverb-skill groundings. These groundings allow an agent to use adverb
feedback provided by a human to directly update a skill policy, in a manner
similar to traditional local policy search methods. We show that our method can
be used as a drop-in replacement for these policy search methods when dense
reward from the environment is not available but human language feedback is. We
demonstrate improved sample efficiency over modern policy search methods in two
experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Application of the Multi-label Residual Convolutional Neural Network text classifier using Content-Based Routing process. (arXiv:2110.15801v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15801">
<div class="article-summary-box-inner">
<span><p>In this article, we will present an NLP application in text classifying
process using the content-based router. The ultimate goal throughout this
article is to predict the event described by a legal ad from the plain text of
the ad. This problem is purely a supervised problem that will involve the use
of NLP techniques and conventional modeling methodologies through the use of
the Multi-label Residual Convolutional Neural Network for text classification.
We will explain the approach put in place to solve the problem of classified
ads, the difficulties encountered and the experimental results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERMo: What can BERT learn from ELMo?. (arXiv:2110.15802v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15802">
<div class="article-summary-box-inner">
<span><p>We propose BERMo, an architectural modification to BERT, which makes
predictions based on a hierarchy of surface, syntactic and semantic language
features. We use linear combination scheme proposed in Embeddings from Language
Models (ELMo) to combine the scaled internal representations from different
network depths. Our approach has two-fold benefits: (1) improved gradient flow
for the downstream task as every layer has a direct connection to the gradients
of the loss function and (2) increased representative power as the model no
longer needs to copy the features learned in the shallower layer which are
necessary for the downstream task. Further, our model has a negligible
parameter overhead as there is a single scalar parameter associated with each
layer in the network. Experiments on the probing task from SentEval dataset
show that our model performs up to $4.65\%$ better in accuracy than the
baseline with an average improvement of $2.67\%$ on the semantic tasks. When
subject to compression techniques, we find that our model enables stable
pruning for compressing small datasets like SST-2, where the BERT model
commonly diverges. We observe that our approach converges $1.67\times$ and
$1.15\times$ faster than the baseline on MNLI and QQP tasks from GLUE dataset.
Moreover, our results show that our approach can obtain better parameter
efficiency for penalty based pruning approaches on QQP task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Language Processing for Smart Healthcare. (arXiv:2110.15803v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15803">
<div class="article-summary-box-inner">
<span><p>Smart healthcare has achieved significant progress in recent years. Emerging
artificial intelligence (AI) technologies enable various smart applications
across various healthcare scenarios. As an essential technology powered by AI,
natural language processing (NLP) plays a key role in smart healthcare due to
its capability of analysing and understanding human language. In this work we
review existing studies that concern NLP for smart healthcare from the
perspectives of technique and application. We focus on feature extraction and
modelling for various NLP tasks encountered in smart healthcare from a
technical point of view. In the context of smart healthcare applications
employing NLP techniques, the elaboration largely attends to representative
smart healthcare scenarios, including clinical practice, hospital management,
personal care, public health, and drug development. We further discuss the
limitations of current works and identify the directions for future works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining Unsupervised and Text Augmented Semi-Supervised Learning for Low Resourced Autoregressive Speech Recognition. (arXiv:2110.15836v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15836">
<div class="article-summary-box-inner">
<span><p>Recent advances in unsupervised representation learning have demonstrated the
impact of pretraining on large amounts of read speech. We adapt these
techniques for domain adaptation in low-resource -- both in terms of data and
compute -- conversational and broadcast domains. Moving beyond CTC, we pretrain
state-of-the-art Conformer models in an unsupervised manner. While the
unsupervised approach outperforms traditional semi-supervised training, the
techniques are complementary. Combining the techniques is a 5% absolute
improvement in WER, averaged over all conditions, compared to semi-supervised
training alone. Additional text data is incorporated through external language
models. By using CTC-based decoding, we are better able to take advantage of
the additional text data. When used as a transcription model, it allows the
Conformer model to better incorporate the knowledge from the language model
through semi-supervised training than shallow fusion. Final performance is an
additional 2% better absolute when using CTC-based decoding for semi-supervised
training compared to shallow fusion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Theories on Styles to their Transfer in Text: Bridging the Gap with a Hierarchical Survey. (arXiv:2110.15871v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15871">
<div class="article-summary-box-inner">
<span><p>Humans are naturally endowed with the ability to write in a particular style.
They can, for instance, rephrase a formal letter in an informal way, convey a
literal message with the use of figures of speech, edit a novel mimicking the
style of some well-known authors. Automating this form of creativity
constitutes the goal of style transfer. As a natural language generation task,
style transfer aims at re-writing existing texts, and specifically, it creates
paraphrases that exhibit some desired stylistic attributes. From a practical
perspective, it envisions beneficial applications, like chat-bots that modulate
their communicative style to appear empathetic, or systems that automatically
simplify technical articles for a non-expert audience.
</p>
<p>Style transfer has been dedicated several style-aware paraphrasing methods. A
handful of surveys give a methodological overview of the field, but they do not
support researchers to focus on specific styles. With this paper, we aim at
providing a comprehensive discussion of the styles that have received attention
in the transfer task. We organize them into a hierarchy, highlighting the
challenges for the definition of each of them, and pointing out gaps in the
current research landscape. The hierarchy comprises two main groups. One
encompasses styles that people modulate arbitrarily, along the lines of
registers and genres. The other group corresponds to unintentionally expressed
styles, due to an author's personal characteristics. Hence, our review shows
how the groups relate to one another, and where specific styles, including some
that have never been explored, belong in the hierarchy. Moreover, we summarize
the methods employed for different stylistic families, hinting researchers
towards those that would be the most fitting for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Ensembles for Sexism Detection. (arXiv:2110.15905v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15905">
<div class="article-summary-box-inner">
<span><p>This document presents in detail the work done for the sexism detection task
at EXIST2021 workshop. Our methodology is built on ensembles of
Transformer-based models which are trained on different background and corpora
and fine-tuned on the provided dataset from the EXIST2021 workshop. We report
accuracy of 0.767 for the binary classification task (task1), and f1 score
0.766, and for the multi-class task (task2) accuracy 0.623 and f1-score 0.535.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Full Constituency Parsing with Neighboring Distribution Divergence. (arXiv:2110.15931v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15931">
<div class="article-summary-box-inner">
<span><p>Unsupervised constituency parsing has been explored much but is still far
from being solved. Conventional unsupervised constituency parser is only able
to capture the unlabeled structure of sentences. Towards unsupervised full
constituency parsing, we propose an unsupervised and training-free labeling
procedure by exploiting the property of a recently introduced metric,
Neighboring Distribution Divergence (NDD), which evaluates semantic similarity
between sentences before and after editions. For implementation, we develop NDD
into Dual POS-NDD (DP-NDD) and build "molds" to detect constituents and their
labels in sentences. We show that DP-NDD not only labels constituents precisely
but also inducts more accurate unlabeled constituency trees than all previous
unsupervised methods with simpler rules. With two frameworks for labeled
constituency trees inference, we set both the new state-of-the-art for
unlabeled F1 and strong baselines for labeled F1. In contrast with the
conventional predicting-and-evaluating scenario, our method acts as an
plausible example to inversely apply evaluating metrics for prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaICL: Learning to Learn In Context. (arXiv:2110.15943v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15943">
<div class="article-summary-box-inner">
<span><p>We introduce MetaICL (Meta-training for In-Context Learning), a new
meta-training framework for few-shot learning where a pretrained language model
is tuned to do in-context learn-ing on a large set of training tasks. This
meta-training enables the model to more effectively learn a new task in context
at test time, by simply conditioning on a few training examples with no
parameter updates or task-specific templates. We experiment on a large, diverse
collection of tasks consisting of 142 NLP datasets including classification,
question answering, natural language inference, paraphrase detection and more,
across seven different meta-training/target splits. MetaICL outperforms a range
of baselines including in-context learning without meta-training and multi-task
learning followed by zero-shot transfer. We find that the gains are
particularly significant for target tasks that have domain shifts from the
meta-training tasks, and that using a diverse set of the meta-training tasks is
key to improvements. We also show that MetaICL approaches (and sometimes beats)
the performance of models fully finetuned on the target task training data, and
outperforms much bigger models with nearly 8x parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Keyword Spotting with Attention. (arXiv:2110.15957v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15957">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider the task of spotting spoken keywords in silent
video sequences -- also known as visual keyword spotting. To this end, we
investigate Transformer-based models that ingest two streams, a visual encoding
of the video and a phonetic encoding of the keyword, and output the temporal
location of the keyword if present. Our contributions are as follows: (1) We
propose a novel architecture, the Transpotter, that uses full cross-modal
attention between the visual and phonetic streams; (2) We show through
extensive evaluations that our model outperforms the prior state-of-the-art
visual keyword spotting and lip reading methods on the challenging LRW, LRS2,
LRS3 datasets by a large margin; (3) We demonstrate the ability of our model to
spot words under the extreme conditions of isolated mouthings in sign language
videos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Daily Dosage from Medication Instructions in EHRs: An Automated Approach and Lessons Learned. (arXiv:2005.10899v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.10899">
<div class="article-summary-box-inner">
<span><p>Medication timelines have been shown to be effective in helping physicians
visualize complex patient medication information. A key feature in many such
designs is a longitudinal representation of a medication's daily dosage and its
changes over time. However, daily dosage as a discrete value is generally not
provided and needs to be derived from free text instructions (Sig). Existing
works in daily dosage extraction are narrow in scope, targeting dosage
extraction for a single drug from clinical notes. Here, we present an automated
approach to calculate daily dosage for all medications, combining deep
learning-based named entity extractor with lexicon dictionaries and regular
expressions, achieving 0.98 precision and 0.95 recall on an expert-generated
dataset of 1,000 Sigs. We also analyze our expert-generated dataset, discuss
the challenges in understanding the complex information contained in Sigs, and
provide insights to guide future work in the general-purpose daily dosage
calculation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FAME: Feature-Based Adversarial Meta-Embeddings for Robust Input Representations. (arXiv:2010.12305v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12305">
<div class="article-summary-box-inner">
<span><p>Combining several embeddings typically improves performance in downstream
tasks as different embeddings encode different information. It has been shown
that even models using embeddings from transformers still benefit from the
inclusion of standard word embeddings. However, the combination of embeddings
of different types and dimensions is challenging. As an alternative to
attention-based meta-embeddings, we propose feature-based adversarial
meta-embeddings (FAME) with an attention function that is guided by features
reflecting word-specific properties, such as shape and frequency, and show that
this is beneficial to handle subword-based embeddings. In addition, FAME uses
adversarial training to optimize the mappings of differently-sized embeddings
to the same space. We demonstrate that FAME works effectively across languages
and domains for sequence labeling and sentence classification, in particular in
low-resource settings. FAME sets the new state of the art for POS tagging in 27
languages, various NER settings and question classification in different
domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Answering Open-Domain Questions of Varying Reasoning Steps from Text. (arXiv:2010.12527v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12527">
<div class="article-summary-box-inner">
<span><p>We develop a unified system to answer directly from text open-domain
questions that may require a varying number of retrieval steps. We employ a
single multi-task transformer model to perform all the necessary subtasks --
retrieving supporting facts, reranking them, and predicting the answer from all
retrieved documents -- in an iterative fashion. We avoid crucial assumptions of
previous work that do not transfer well to real-world settings, including
exploiting knowledge of the fixed number of retrieval steps required to answer
each question or using structured metadata like knowledge bases or web links
that have limited availability. Instead, we design a system that can answer
open-domain questions on any text collection without prior knowledge of
reasoning complexity. To emulate this setting, we construct a new benchmark,
called BeerQA, by combining existing one- and two-step datasets with a new
collection of 530 questions that require three Wikipedia pages to answer,
unifying Wikipedia corpora versions in the process. We show that our model
demonstrates competitive performance on both existing benchmarks and this new
benchmark. We make the new benchmark available at https://beerqa.github.io/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-to-text Generation by Splicing Together Nearest Neighbors. (arXiv:2101.08248v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08248">
<div class="article-summary-box-inner">
<span><p>We propose to tackle data-to-text generation tasks by directly splicing
together retrieved segments of text from "neighbor" source-target pairs. Unlike
recent work that conditions on retrieved neighbors but generates text
token-by-token, left-to-right, we learn a policy that directly manipulates
segments of neighbor text, by inserting or replacing them in partially
constructed generations. Standard techniques for training such a policy require
an oracle derivation for each generation, and we prove that finding the
shortest such derivation can be reduced to parsing under a particular weighted
context-free grammar. We find that policies learned in this way perform on par
with strong baselines in terms of automatic and human evaluation, but allow for
more interpretable and controllable generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">To Share or not to Share: Predicting Sets of Sources for Model Transfer Learning. (arXiv:2104.08078v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08078">
<div class="article-summary-box-inner">
<span><p>In low-resource settings, model transfer can help to overcome a lack of
labeled data for many tasks and domains. However, predicting useful transfer
sources is a challenging problem, as even the most similar sources might lead
to unexpected negative transfer results. Thus, ranking methods based on task
and text similarity -- as suggested in prior work -- may not be sufficient to
identify promising sources. To tackle this problem, we propose a new approach
to automatically determine which and how many sources should be exploited. For
this, we study the effects of model transfer on sequence labeling across
various domains and tasks and show that our methods based on model similarity
and support vector machines are able to predict promising sources, resulting in
performance increases of up to 24 F1 points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Group-based Distinctive Image Captioning with Memory Attention. (arXiv:2108.09151v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09151">
<div class="article-summary-box-inner">
<span><p>Describing images using natural language is widely known as image captioning,
which has made consistent progress due to the development of computer vision
and natural language generation techniques. Though conventional captioning
models achieve high accuracy based on popular metrics, i.e., BLEU, CIDEr, and
SPICE, the ability of captions to distinguish the target image from other
similar images is under-explored. To generate distinctive captions, a few
pioneers employ contrastive learning or re-weighted the ground-truth captions,
which focuses on one single input image. However, the relationships between
objects in a similar image group (e.g., items or properties within the same
album or fine-grained events) are neglected. In this paper, we improve the
distinctiveness of image captions using a Group-based Distinctive Captioning
Model (GdisCap), which compares each image with other images in one similar
group and highlights the uniqueness of each image. In particular, we propose a
group-based memory attention (GMA) module, which stores object features that
are unique among the image group (i.e., with low similarity to objects in other
images). These unique object features are highlighted when generating captions,
resulting in more distinctive captions. Furthermore, the distinctive words in
the ground-truth captions are selected to supervise the language decoder and
GMA. Finally, we propose a new evaluation metric, distinctive word rate
(DisWordRate) to measure the distinctiveness of captions. Quantitative results
indicate that the proposed method significantly improves the distinctiveness of
several baseline models, and achieves the state-of-the-art performance on both
accuracy and distinctiveness. Results of a user study agree with the
quantitative evaluation and demonstrate the rationality of the new metric
DisWordRate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Task Learning with Sentiment, Emotion, and Target Detection to Recognize Hate Speech and Offensive Language. (arXiv:2109.10255v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10255">
<div class="article-summary-box-inner">
<span><p>The recognition of hate speech and offensive language (HOF) is commonly
formulated as a classification task to decide if a text contains HOF. We
investigate whether HOF detection can profit by taking into account the
relationships between HOF and similar concepts: (a) HOF is related to sentiment
analysis because hate speech is typically a negative statement and expresses a
negative opinion; (b) it is related to emotion analysis, as expressed hate
points to the author experiencing (or pretending to experience) anger while the
addressees experience (or are intended to experience) fear. (c) Finally, one
constituting element of HOF is the mention of a targeted person or group. On
this basis, we hypothesize that HOF detection shows improvements when being
modeled jointly with these concepts, in a multi-task learning setup. We base
our experiments on existing data sets for each of these concepts (sentiment,
emotion, target of HOF) and evaluate our models as a participant (as team
IMS-SINAI) in the HASOC FIRE 2021 English Subtask 1A. Based on model-selection
experiments in which we consider multiple available resources and submissions
to the shared task, we find that the combination of the CrowdFlower emotion
corpus, the SemEval 2016 Sentiment Corpus, and the OffensEval 2019 target
detection data leads to an F1 =.79 in a multi-head multi-task learning model
based on BERT, in comparison to .7895 of plain BERT. On the HASOC 2019 test
data, this result is more substantial with an increase by 2pp in F1 and a
considerable increase in recall. Across both data sets (2019, 2021), the recall
is particularly increased for the class of HOF (6pp for the 2019 data and 3pp
for the 2021 data), showing that MTL with emotion, sentiment, and target
identification is an appropriate approach for early warning systems that might
be deployed in social media platforms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Retriever-Ranker for dense text retrieval. (arXiv:2110.03611v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03611">
<div class="article-summary-box-inner">
<span><p>Current dense text retrieval models face two typical challenges. First, it
adopts a siamese dual-encoder architecture to encode query and document
independently for fast indexing and searching, whereas neglecting the
finer-grained term-wise interactions. This results in a sub-optimal recall
performance. Second, it highly relies on a negative sampling technique to build
up the negative documents in its contrastive loss. To address these challenges,
we present Adversarial Retriever-Ranker (AR2), which consists of a dual-encoder
retriever plus a cross-encoder ranker. The two models are jointly optimized
according to a minimax adversarial objective: the retriever learns to retrieve
negative documents to cheat the ranker, while the ranker learns to rank a
collection of candidates including both the ground-truth and the retrieved
ones, as well as providing progressive direct feedback to the dual-encoder
retriever. Through this adversarial game, the retriever gradually produces
harder negative documents to train a better ranker, whereas the cross-encoder
ranker provides progressive feedback to improve retriever. We evaluate AR2 on
three benchmarks. Experimental results show that AR2 consistently and
significantly outperforms existing dense retriever methods and achieves new
state-of-the-art results on all of them. This includes the improvements on
Natural Questions R@5 to 77.9%(+2.1%), TriviaQA R@5 to 78.2%(+1.4), and
MS-MARCO MRR@10 to 39.5%(+1.3%). We will make our code, models, and data
publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing. (arXiv:2110.13900v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13900">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) achieves great success in speech recognition,
while limited exploration has been attempted for other speech processing tasks.
As speech signal contains multi-faceted information including speaker identity,
paralinguistics, spoken content, etc., learning universal representations for
all speech tasks is challenging. In this paper, we propose a new pre-trained
model, WavLM, to solve full-stack downstream speech tasks. WavLM is built based
on the HuBERT framework, with an emphasis on both spoken content modeling and
speaker identity preservation. We first equip the Transformer structure with
gated relative position bias to improve its capability on recognition tasks.
For better speaker discrimination, we propose an utterance mixing training
strategy, where additional overlapped utterances are created unsupervisely and
incorporated during model training. Lastly, we scale up the training dataset
from 60k hours to 94k hours. WavLM Large achieves state-of-the-art performance
on the SUPERB benchmark, and brings significant improvements for various speech
processing tasks on their representative benchmarks. The code and pretrained
models are available at https://aka.ms/wavlm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cognitive network science quantifies feelings expressed in suicide letters and Reddit mental health communities. (arXiv:2110.15269v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15269">
<div class="article-summary-box-inner">
<span><p>Writing messages is key to expressing feelings. This study adopts cognitive
network science to reconstruct how individuals report their feelings in
clinical narratives like suicide notes or mental health posts. We achieve this
by reconstructing syntactic/semantic associations between conceptsin texts as
co-occurrences enriched with affective data. We transform 142 suicide notes and
77,000 Reddit posts from the r/anxiety, r/depression, r/schizophrenia, and
r/do-it-your-own (r/DIY) forums into 5 cognitive networks, each one expressing
meanings and emotions as reported by authors. These networks reconstruct the
semantic frames surrounding 'feel', enabling a quantification of prominent
associations and emotions focused around feelings. We find strong feelings of
sadness across all clinical Reddit boards, added to fear r/depression, and
replaced by joy/anticipation in r/DIY. Semantic communities and topic modelling
both highlight key narrative topics of 'regret', 'unhealthy lifestyle' and 'low
mental well-being'. Importantly, negative associations and emotions co-existed
with trustful/positive language, focused on 'getting better'. This emotional
polarisation provides quantitative evidence that online clinical boards possess
a complex structure, where users mix both positive and negative outlooks. This
dichotomy is absent in the r/DIY reference board and in suicide notes, where
negative emotional associations about regret and pain persist but are
overwhelmed by positive jargon addressing loved ones. Our quantitative
comparisons provide strong evidence that suicide notes encapsulate different
ways of expressing feelings compared to online Reddit boards, the latter acting
more like personal diaries and relief valve. Our findings provide an
interpretable, quantitative aid for supporting psychological inquiries of human
feelings in digital and clinical settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Extraction of Causal Relations from Natural Language Text. (arXiv:2101.06426v1 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06426">
<div class="article-summary-box-inner">
<span><p>As an essential component of human cognition, cause-effect relations appear
frequently in text, and curating cause-effect relations from text helps in
building causal networks for predictive tasks. Existing causality extraction
techniques include knowledge-based, statistical machine learning(ML)-based, and
deep learning-based approaches. Each method has its advantages and weaknesses.
For example, knowledge-based methods are understandable but require extensive
manual domain knowledge and have poor cross-domain applicability. Statistical
machine learning methods are more automated because of natural language
processing (NLP) toolkits. However, feature engineering is labor-intensive, and
toolkits may lead to error propagation. In the past few years, deep learning
techniques attract substantial attention from NLP researchers because of its'
powerful representation learning ability and the rapid increase in
computational resources. Their limitations include high computational costs and
a lack of adequate annotated training data. In this paper, we conduct a
comprehensive survey of causality extraction. We initially introduce primary
forms existing in the causality extraction: explicit intra-sentential
causality, implicit causality, and inter-sentential causality. Next, we list
benchmark datasets and modeling assessment methods for causal relation
extraction. Then, we present a structured overview of the three techniques with
their representative systems. Lastly, we highlight existing open challenges
with their potential directions.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Disparity Refinement for Arbitrary Resolution Stereo. (arXiv:2110.15367v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15367">
<div class="article-summary-box-inner">
<span><p>We introduce a novel architecture for neural disparity refinement aimed at
facilitating deployment of 3D computer vision on cheap and widespread consumer
devices, such as mobile phones. Our approach relies on a continuous formulation
that enables to estimate a refined disparity map at any arbitrary output
resolution. Thereby, it can handle effectively the unbalanced camera setup
typical of nowadays mobile phones, which feature both high and low resolution
RGB sensors within the same device. Moreover, our neural network can process
seamlessly the output of a variety of stereo methods and, by refining the
disparity maps computed by a traditional matching algorithm like SGM, it can
achieve unpaired zero-shot generalization performance compared to
state-of-the-art end-to-end stereo models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">New SAR target recognition based on YOLO and very deep multi-canonical correlation analysis. (arXiv:2110.15383v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15383">
<div class="article-summary-box-inner">
<span><p>Synthetic Aperture Radar (SAR) images are prone to be contaminated by noise,
which makes it very difficult to perform target recognition in SAR images.
Inspired by great success of very deep convolutional neural networks (CNNs),
this paper proposes a robust feature extraction method for SAR image target
classification by adaptively fusing effective features from different CNN
layers. First, YOLOv4 network is fine-tuned to detect the targets from the
respective MF SAR target images. Second, a very deep CNN is trained from
scratch on the moving and stationary target acquisition and recognition (MSTAR)
database by using small filters throughout the whole net to reduce the speckle
noise. Besides, using small-size convolution filters decreases the number of
parameters in each layer and, therefore, reduces computation cost as the CNN
goes deeper. The resulting CNN model is capable of extracting very deep
features from the target images without performing any noise filtering or
pre-processing techniques. Third, our approach proposes to use the
multi-canonical correlation analysis (MCCA) to adaptively learn CNN features
from different layers such that the resulting representations are highly
linearly correlated and therefore can achieve better classification accuracy
even if a simple linear support vector machine is used. Experimental results on
the MSTAR dataset demonstrate that the proposed method outperforms the
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Translation of Rebar Information from GPR Data into As-Built BIM: A Deep Learning-based Approach. (arXiv:2110.15448v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15448">
<div class="article-summary-box-inner">
<span><p>Building Information Modeling (BIM) is increasingly used in the construction
industry, but existing studies often ignore embedded rebars. Ground Penetrating
Radar (GPR) provides a potential solution to develop as-built BIM with surface
elements and rebars. However, automatically translating rebars from GPR into
BIM is challenging since GPR cannot provide any information about the scanned
element. Thus, we propose an approach to link GPR data and BIM according to
Faster R-CNN. A label is attached to each element scanned by GPR for capturing
the labeled images, which are used with other images to build a 3D model.
Meanwhile, Faster R-CNN is introduced to identify the labels, and the
projection relationship between images and the model is used to localize the
scanned elements in the 3D model. Two concrete buildings is selected to
evaluate the proposed approach, and the results reveal that our method could
accurately translate the rebars from GPR data into corresponding elements in
BIM with correct distributions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Foreground Extraction via Deep Region Competition. (arXiv:2110.15497v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15497">
<div class="article-summary-box-inner">
<span><p>We present Deep Region Competition (DRC), an algorithm designed to extract
foreground objects from images in a fully unsupervised manner. Foreground
extraction can be viewed as a special case of generic image segmentation that
focuses on identifying and disentangling objects from the background. In this
work, we rethink the foreground extraction by reconciling energy-based prior
with generative image modeling in the form of Mixture of Experts (MoE), where
we further introduce the learned pixel re-assignment as the essential inductive
bias to capture the regularities of background regions. With this modeling, the
foreground-background partition can be naturally found through
Expectation-Maximization (EM). We show that the proposed method effectively
exploits the interaction between the mixture components during the partitioning
process, which closely connects to region competition, a seminal approach for
generic image segmentation. Experiments demonstrate that DRC exhibits more
competitive performances on complex real-world data and challenging
multi-object scenes compared with prior methods. Moreover, we show empirically
that DRC can potentially generalize to novel foreground objects even from
categories unseen during training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UDIS: Unsupervised Discovery of Bias in Deep Visual Recognition Models. (arXiv:2110.15499v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15499">
<div class="article-summary-box-inner">
<span><p>Deep learning models have been shown to learn spurious correlations from data
that sometimes lead to systematic failures for certain subpopulations. Prior
work has typically diagnosed this by crowdsourcing annotations for various
protected attributes and measuring performance, which is both expensive to
acquire and difficult to scale. In this work, we propose UDIS, an unsupervised
algorithm for surfacing and analyzing such failure modes. UDIS identifies
subpopulations via hierarchical clustering of dataset embeddings and surfaces
systematic failure modes by visualizing low performing clusters along with
their gradient-weighted class-activation maps. We show the effectiveness of
UDIS in identifying failure modes in models trained for image classification on
the CelebA and MSCOCO datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PEDENet: Image Anomaly Localization via Patch Embedding and Density Estimation. (arXiv:2110.15525v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15525">
<div class="article-summary-box-inner">
<span><p>A neural network targeting at unsupervised image anomaly localization, called
the PEDENet, is proposed in this work. PEDENet contains a patch embedding (PE)
network, a density estimation (DE) network, and an auxiliary network called the
location prediction (LP) network. The PE network takes local image patches as
input and performs dimension reduction to get low-dimensional patch embeddings
via a deep encoder structure. Being inspired by the Gaussian Mixture Model
(GMM), the DE network takes those patch embeddings and then predicts the
cluster membership of an embedded patch. The sum of membership probabilities is
used as a loss term to guide the learning process. The LP network is a
Multi-layer Perception (MLP), which takes embeddings from two neighboring
patches as input and predicts their relative location. The performance of the
proposed PEDENet is evaluated extensively and benchmarked with that of
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model Fusion of Heterogeneous Neural Networks via Cross-Layer Alignment. (arXiv:2110.15538v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15538">
<div class="article-summary-box-inner">
<span><p>Layer-wise model fusion via optimal transport, named OTFusion, applies soft
neuron association for unifying different pre-trained networks to save
computational resources. While enjoying its success, OTFusion requires the
input networks to have the same number of layers. To address this issue, we
propose a novel model fusion framework, named CLAFusion, to fuse neural
networks with a different number of layers, which we refer to as heterogeneous
neural networks, via cross-layer alignment. The cross-layer alignment problem,
which is an unbalanced assignment problem, can be solved efficiently using
dynamic programming. Based on the cross-layer alignment, our framework balances
the number of layers of neural networks before applying layer-wise model
fusion. Our synthetic experiments indicate that the fused network from
CLAFusion achieves a more favorable performance compared to the individual
networks trained on heterogeneous data without the need for any retraining.
With an extra fine-tuning process, it improves the accuracy of residual
networks on the CIFAR10 dataset. Finally, we explore its application for model
compression and knowledge distillation when applying to the teacher-student
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Latent Cognizance: What Machine Really Learns. (arXiv:2110.15548v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15548">
<div class="article-summary-box-inner">
<span><p>Despite overwhelming achievements in recognition accuracy, extending an
open-set capability -- ability to identify when the question is out of scope --
remains greatly challenging in a scalable machine learning inference. A recent
research has discovered Latent Cognizance (LC) -- an insight on a recognition
mechanism based on a new probabilistic interpretation, Bayesian theorem, and an
analysis of an internal structure of a commonly-used recognition inference
structure. The new interpretation emphasizes a latent assumption of an
overlooked probabilistic condition on a learned inference model. Viability of
LC has been shown on a task of sign language recognition, but its potential and
implication can reach far beyond a specific domain and can move object
recognition toward a scalable open-set recognition. However, LC new
probabilistic interpretation has not been directly investigated. This article
investigates the new interpretation under a traceable context. Our findings
support the rationale on which LC is based and reveal a hidden mechanism
underlying the learning classification inference. The ramification of these
findings could lead to a simple yet effective solution to an open-set
recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-Powered Semantic Segmentation and Fluid Volume Calculation of Lung CT images in Covid-19 Patients. (arXiv:2110.15558v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15558">
<div class="article-summary-box-inner">
<span><p>COVID-19 pandemic is a deadly disease spreading very fast. People with the
confronted immune system are susceptible to many health conditions. A highly
significant condition is pneumonia, which is found to be the cause of death in
the majority of patients. The main purpose of this study is to find the volume
of GGO and consolidation of a covid-19 patient so that the physicians can
prioritize the patients. Here we used transfer learning techniques for
segmentation of lung CTs with the latest libraries and techniques which reduces
training time and increases the accuracy of the AI Model. This system is
trained with DeepLabV3+ network architecture and model Resnet50 with Imagenet
weights. We used different augmentation techniques like Gaussian Noise,
Horizontal shift, color variation, etc to get to the result. Intersection over
Union(IoU) is used as the performance metrics. The IoU of lung masks is
predicted as 99.78% and that of infected masks is as 89.01%. Our work
effectively measures the volume of infected region by calculating the volume of
infected and lung mask region of the patients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exposing Deepfake with Pixel-wise AR and PPG Correlation from Faint Signals. (arXiv:2110.15561v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15561">
<div class="article-summary-box-inner">
<span><p>Deepfake poses a serious threat to the reliability of judicial evidence and
intellectual property protection. In spite of an urgent need for Deepfake
identification, existing pixel-level detection methods are increasingly unable
to resist the growing realism of fake videos and lack generalization. In this
paper, we propose a scheme to expose Deepfake through faint signals hidden in
face videos. This scheme extracts two types of minute information hidden
between face pixels-photoplethysmography (PPG) features and auto-regressive
(AR) features, which are used as the basis for forensics in the temporal and
spatial domains, respectively. According to the principle of PPG, tracking the
absorption of light by blood cells allows remote estimation of the temporal
domains heart rate (HR) of face video, and irregular HR fluctuations can be
seen as traces of tampering. On the other hand, AR coefficients are able to
reflect the inter-pixel correlation, and can also reflect the traces of
smoothing caused by up-sampling in the process of generating fake faces.
Furthermore, the scheme combines asymmetric convolution block (ACBlock)-based
improved densely connected networks (DenseNets) to achieve face video
authenticity forensics. Its asymmetric convolutional structure enhances the
robustness of network to the input feature image upside-down and left-right
flipping, so that the sequence of feature stitching does not affect detection
results. Simulation results show that our proposed scheme provides more
accurate authenticity detection results on multiple deep forgery datasets and
has better generalization compared to the benchmark strategy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised PET Reconstruction from a Bayesian Perspective. (arXiv:2110.15568v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15568">
<div class="article-summary-box-inner">
<span><p>Positron emission tomography (PET) reconstruction has become an ill-posed
inverse problem due to low-count projection data, and a robust algorithm is
urgently required to improve imaging quality. Recently, the deep image prior
(DIP) has drawn much attention and has been successfully applied in several
image restoration tasks, such as denoising and inpainting, since it does not
need any labels (reference image). However, overfitting is a vital defect of
this framework. Hence, many methods have been proposed to mitigate this
problem, and DeepRED is a typical representation that combines DIP and
regularization by denoising (RED). In this article, we leverage DeepRED from a
Bayesian perspective to reconstruct PET images from a single corrupted sinogram
without any supervised or auxiliary information. In contrast to the
conventional denoisers customarily used in RED, a DnCNN-like denoiser, which
can add an adaptive constraint to DIP and facilitate the computation of
derivation, is employed. Moreover, to further enhance the regularization,
Gaussian noise is injected into the gradient updates, deriving a Markov chain
Monte Carlo (MCMC) sampler. Experimental studies on brain and whole-body
datasets demonstrate that our proposed method can achieve better performance in
terms of qualitative and quantitative results compared to several classic and
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Novel View Synthesis from a Single Image via Unsupervised learning. (arXiv:2110.15569v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15569">
<div class="article-summary-box-inner">
<span><p>View synthesis aims to generate novel views from one or more given source
views. Although existing methods have achieved promising performance, they
usually require paired views of different poses to learn a pixel
transformation. This paper proposes an unsupervised network to learn such a
pixel transformation from a single source viewpoint. In particular, the network
consists of a token transformation module (TTM) that facilities the
transformation of the features extracted from a source viewpoint image into an
intrinsic representation with respect to a pre-defined reference pose and a
view generation module (VGM) that synthesizes an arbitrary view from the
representation. The learned transformation allows us to synthesize a novel view
from any single source viewpoint image of unknown pose. Experiments on the
widely used view synthesis datasets have demonstrated that the proposed network
is able to produce comparable results to the state-of-the-art methods despite
the fact that learning is unsupervised and only a single source viewpoint image
is required for generating a novel view. The code will be available soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ST-ABN: Visual Explanation Taking into Account Spatio-temporal Information for Video Recognition. (arXiv:2110.15574v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15574">
<div class="article-summary-box-inner">
<span><p>It is difficult for people to interpret the decision-making in the inference
process of deep neural networks. Visual explanation is one method for
interpreting the decision-making of deep learning. It analyzes the
decision-making of 2D CNNs by visualizing an attention map that highlights
discriminative regions. Visual explanation for interpreting the decision-making
process in video recognition is more difficult because it is necessary to
consider not only spatial but also temporal information, which is different
from the case of still images. In this paper, we propose a visual explanation
method called spatio-temporal attention branch network (ST-ABN) for video
recognition. It enables visual explanation for both spatial and temporal
information. ST-ABN acquires the importance of spatial and temporal information
during network inference and applies it to recognition processing to improve
recognition performance and visual explainability. Experimental results with
Something-Something datasets V1 \&amp; V2 demonstrated that ST-ABN enables visual
explanation that takes into account spatial and temporal information
simultaneously and improves recognition performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Whole Brain Segmentation with Full Volume Neural Network. (arXiv:2110.15601v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15601">
<div class="article-summary-box-inner">
<span><p>Whole brain segmentation is an important neuroimaging task that segments the
whole brain volume into anatomically labeled regions-of-interest. Convolutional
neural networks have demonstrated good performance in this task. Existing
solutions, usually segment the brain image by classifying the voxels, or
labeling the slices or the sub-volumes separately. Their representation
learning is based on parts of the whole volume whereas their labeling result is
produced by aggregation of partial segmentation. Learning and inference with
incomplete information could lead to sub-optimal final segmentation result. To
address these issues, we propose to adopt a full volume framework, which feeds
the full volume brain image into the segmentation network and directly outputs
the segmentation result for the whole brain volume. The framework makes use of
complete information in each volume and can be implemented easily. An effective
instance in this framework is given subsequently. We adopt the $3$D
high-resolution network (HRNet) for learning spatially fine-grained
representations and the mixed precision training scheme for memory-efficient
training. Extensive experiment results on a publicly available $3$D MRI brain
dataset show that our proposed model advances the state-of-the-art methods in
terms of segmentation performance. Source code is publicly available at
https://github.com/microsoft/VoxHRNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Camouflaged Object Detection with the Uncertainty of Pseudo-edge Labels. (arXiv:2110.15606v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15606">
<div class="article-summary-box-inner">
<span><p>This paper focuses on camouflaged object detection (COD), which is a task to
detect objects hidden in the background. Most of the current COD models aim to
highlight the target object directly while outputting ambiguous camouflaged
boundaries. On the other hand, the performance of the models considering edge
information is not yet satisfactory. To this end, we propose a new framework
that makes full use of multiple visual cues, i.e., saliency as well as edges,
to refine the predicted camouflaged map. This framework consists of three key
components, i.e., a pseudo-edge generator, a pseudo-map generator, and an
uncertainty-aware refinement module. In particular, the pseudo-edge generator
estimates the boundary that outputs the pseudo-edge label, and the conventional
COD method serves as the pseudo-map generator that outputs the pseudo-map
label. Then, we propose an uncertainty-based module to reduce the uncertainty
and noise of such two pseudo labels, which takes both pseudo labels as input
and outputs an edge-accurate camouflaged map. Experiments on various COD
datasets demonstrate the effectiveness of our method with superior performance
to the existing state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Spatio-temporal Relation-enhanced Network for Cross-modal Text-Video Retrieval. (arXiv:2110.15609v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15609">
<div class="article-summary-box-inner">
<span><p>The task of cross-modal retrieval between texts and videos aims to understand
the correspondence between vision and language. Existing studies follow a trend
of measuring text-video similarity on the basis of textual and video
embeddings. In common practice, video representation is constructed by feeding
video frames into 2D/3D-CNN for global visual feature extraction or only
learning simple semantic relations by using local-level fine-grained frame
regions via graph convolutional network. However, these video representations
do not fully exploit spatio-temporal relation among visual components in
learning video representations, resulting in their inability to distinguish
videos with the same visual components but with different relations. To solve
this problem, we propose a Visual Spatio-temporal Relation-enhanced Network
(VSR-Net), a novel cross-modal retrieval framework that enhances visual
representation with spatio-temporal relations among components. Specifically,
visual spatio-temporal relations are encoded using a multi-layer
spatio-temporal transformer to learn visual relational features. We combine
fine-grained local relation and global features in bridging text-video
modalities. Extensive experimental are conducted on both MSR-VTT and MSVD
datasets. The results demonstrate the effectiveness of our proposed model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Person Re-Identification with Wireless Positioning under Weak Scene Labeling. (arXiv:2110.15610v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15610">
<div class="article-summary-box-inner">
<span><p>Existing unsupervised person re-identification methods only rely on visual
clues to match pedestrians under different cameras. Since visual data is
essentially susceptible to occlusion, blur, clothing changes, etc., a promising
solution is to introduce heterogeneous data to make up for the defect of visual
data. Some works based on full-scene labeling introduce wireless positioning to
assist cross-domain person re-identification, but their GPS labeling of entire
monitoring scenes is laborious. To this end, we propose to explore unsupervised
person re-identification with both visual data and wireless positioning
trajectories under weak scene labeling, in which we only need to know the
locations of the cameras. Specifically, we propose a novel unsupervised
multimodal training framework (UMTF), which models the complementarity of
visual data and wireless information. Our UMTF contains a multimodal data
association strategy (MMDA) and a multimodal graph neural network (MMGN). MMDA
explores potential data associations in unlabeled multimodal data, while MMGN
propagates multimodal messages in the video graph based on the adjacency matrix
learned from histogram statistics of wireless data. Thanks to the robustness of
the wireless data to visual noise and the collaboration of various modules,
UMTF is capable of learning a model free of the human label on data. Extensive
experimental results conducted on two challenging datasets, i.e., WP-ReID and
DukeMTMC-VideoReID demonstrate the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attacking Video Recognition Models with Bullet-Screen Comments. (arXiv:2110.15629v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15629">
<div class="article-summary-box-inner">
<span><p>Recent research has demonstrated that Deep Neural Networks (DNNs) are
vulnerable to adversarial patches which introducing perceptible but localized
changes to the input. Nevertheless, existing approaches have focused on
generating adversarial patches on images, their counterparts in videos have
been less explored. Compared with images, attacking videos is much more
challenging as it needs to consider not only spatial cues but also temporal
cues. To close this gap, we introduce a novel adversarial attack in this paper,
the bullet-screen comment (BSC) attack, which attacks video recognition models
with BSCs. Specifically, adversarial BSCs are generated with a Reinforcement
Learning (RL) framework, where the environment is set as the target model and
the agent plays the role of selecting the position and transparency of each
BSC. By continuously querying the target models and receiving feedback, the
agent gradually adjusts its selection strategies in order to achieve a high
fooling rate with non-overlapping BSCs. As BSCs can be regarded as a kind of
meaningful patch, adding it to a clean video will not affect people' s
understanding of the video content, nor will arouse people' s suspicion. We
conduct extensive experiments to verify the effectiveness of the proposed
method. On both UCF-101 and HMDB-51 datasets, our BSC attack method can achieve
about 90\% fooling rate when attack three mainstream video recognition models,
while only occluding \textless 8\% areas in the video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Task and Multi-Modal Learning for RGB Dynamic Gesture Recognition. (arXiv:2110.15639v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15639">
<div class="article-summary-box-inner">
<span><p>Gesture recognition is getting more and more popular due to various
application possibilities in human-machine interaction. Existing multi-modal
gesture recognition systems take multi-modal data as input to improve accuracy,
but such methods require more modality sensors, which will greatly limit their
application scenarios. Therefore we propose an end-to-end multi-task learning
framework in training 2D convolutional neural networks. The framework can use
the depth modality to improve accuracy during training and save costs by using
only RGB modality during inference. Our framework is trained to learn a
representation for multi-task learning: gesture segmentation and gesture
recognition. Depth modality contains the prior information for the location of
the gesture. Therefore it can be used as the supervision for gesture
segmentation. A plug-and-play module named Multi-Scale-Decoder is designed to
realize gesture segmentation, which contains two sub-decoder. It is used in the
lower stage and higher stage respectively, and can help the network pay
attention to key target areas, ignore irrelevant information, and extract more
discriminant features. Additionally, the MSD module and depth modality are only
used in the training stage to improve gesture recognition performance. Only RGB
modality and network without MSD are required during inference. Experimental
results on three public gesture recognition datasets show that our proposed
method provides superior performance compared with existing gesture recognition
frameworks. Moreover, using the proposed plug-and-play MSD in other 2D
CNN-based frameworks also get an excellent accuracy improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gabor filter incorporated CNN for compression. (arXiv:2110.15644v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15644">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) are remarkably successful in many
computer vision tasks. However, the high cost of inference is problematic for
embedded and real-time systems, so there are many studies on compressing the
networks. On the other hand, recent advances in self-attention models showed
that convolution filters are preferable to self-attention in the earlier
layers, which indicates that stronger inductive biases are better in the
earlier layers. As shown in convolutional filters, strong biases can train
specific filters and construct unnecessarily filters to zero. This is analogous
to classical image processing tasks, where choosing the suitable filters makes
a compact dictionary to represent features. We follow this idea and incorporate
Gabor filters in the earlier layers of CNNs for compression. The parameters of
Gabor filters are learned through backpropagation, so the features are
restricted to Gabor filters. We show that the first layer of VGG-16 for
CIFAR-10 has 192 kernels/features, but learning Gabor filters requires an
average of 29.4 kernels. Also, using Gabor filters, an average of 83% and 94%
of kernels in the first and the second layer, respectively, can be removed on
the altered ResNet-20, where the first five layers are exchanged with two
layers of larger kernels for CIFAR-10.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scale-Aware Dynamic Network for Continuous-Scale Super-Resolution. (arXiv:2110.15655v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15655">
<div class="article-summary-box-inner">
<span><p>Single-image super-resolution (SR) with fixed and discrete scale factors has
achieved great progress due to the development of deep learning technology.
However, the continuous-scale SR, which aims to use a single model to process
arbitrary (integer or non-integer) scale factors, is still a challenging task.
The existing SR models generally adopt static convolution to extract features,
and thus unable to effectively perceive the change of scale factor, resulting
in limited generalization performance on multi-scale SR tasks. Moreover, the
existing continuous-scale upsampling modules do not make full use of
multi-scale features and face problems such as checkerboard artifacts in the SR
results and high computational complexity. To address the above problems, we
propose a scale-aware dynamic network (SADN) for continuous-scale SR. First, we
propose a scale-aware dynamic convolutional (SAD-Conv) layer for the feature
learning of multiple SR tasks with various scales. The SAD-Conv layer can
adaptively adjust the attention weights of multiple convolution kernels based
on the scale factor, which enhances the expressive power of the model with a
negligible extra computational cost. Second, we devise a continuous-scale
upsampling module (CSUM) with the multi-bilinear local implicit function
(MBLIF) for any-scale upsampling. The CSUM constructs multiple feature spaces
with gradually increasing scales to approximate the continuous feature
representation of an image, and then the MBLIF makes full use of multi-scale
features to map arbitrary coordinates to RGB values in high-resolution space.
We evaluate our SADN using various benchmarks. The experimental results show
that the CSUM can replace the previous fixed-scale upsampling layers and obtain
a continuous-scale SR network while maintaining performance. Our SADN uses much
fewer parameters and outperforms the state-of-the-art SR methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D-OOCS: Learning Prostate Segmentation with Inductive Bias. (arXiv:2110.15664v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15664">
<div class="article-summary-box-inner">
<span><p>Despite the great success of convolutional neural networks (CNN) in 3D
medical image segmentation tasks, the methods currently in use are still not
robust enough to the different protocols utilized by different scanners, and to
the variety of image properties or artefacts they produce. To this end, we
introduce OOCS-enhanced networks, a novel architecture inspired by the innate
nature of visual processing in the vertebrates. With different 3D U-Net
variants as the base, we add two 3D residual components to the second encoder
blocks: on and off center-surround (OOCS). They generalise the ganglion
pathways in the retina to a 3D setting. The use of 2D-OOCS in any standard CNN
network complements the feedforward framework with sharp edge-detection
inductive biases. The use of 3D-OOCS also helps 3D U-Nets to scrutinise and
delineate anatomical structures present in 3D images with increased accuracy.We
compared the state-of-the-art 3D U-Nets with their 3D-OOCS extensions and
showed the superior accuracy and robustness of the latter in automatic prostate
segmentation from 3D Magnetic Resonance Images (MRIs). For a fair comparison,
we trained and tested all the investigated 3D U-Nets with the same pipeline,
including automatic hyperparameter optimisation and data augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-target tracking for video surveillance using deep affinity network: a brief review. (arXiv:2110.15674v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15674">
<div class="article-summary-box-inner">
<span><p>Deep learning models are known to function like the human brain. Due to their
functional mechanism, they are frequently utilized to accomplish tasks that
require human intelligence. Multi-target tracking (MTT) for video surveillance
is one of the important and challenging tasks, which has attracted the
researcher's attention due to its potential applications in various domains.
Multi-target tracking tasks require locating the objects individually in each
frame, which remains a huge challenge as there are immediate changes in
appearances and extreme occlusions of objects. In addition to that, the
Multitarget tracking framework requires multiple tasks to perform i.e. target
detection, estimating trajectory, associations between frame, and
re-identification. Various methods have been suggested, and some assumptions
are made to constrain the problem in the context of a particular problem. In
this paper, the state-of-the-art MTT models, which leverage from deep learning
representational power are reviewed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Shading-Guided Generative Implicit Model for Shape-Accurate 3D-Aware Image Synthesis. (arXiv:2110.15678v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15678">
<div class="article-summary-box-inner">
<span><p>The advancement of generative radiance fields has pushed the boundary of
3D-aware image synthesis. Motivated by the observation that a 3D object should
look realistic from multiple viewpoints, these methods introduce a multi-view
constraint as regularization to learn valid 3D radiance fields from 2D images.
Despite the progress, they often fall short of capturing accurate 3D shapes due
to the shape-color ambiguity, limiting their applicability in downstream tasks.
In this work, we address this ambiguity by proposing a novel shading-guided
generative implicit model that is able to learn a starkly improved shape
representation. Our key insight is that an accurate 3D shape should also yield
a realistic rendering under different lighting conditions. This multi-lighting
constraint is realized by modeling illumination explicitly and performing
shading with various lighting conditions. Gradients are derived by feeding the
synthesized images to a discriminator. To compensate for the additional
computational burden of calculating surface normals, we further devise an
efficient volume rendering strategy via surface tracking, reducing the training
and inference time by 24% and 48%, respectively. Our experiments on multiple
datasets show that the proposed approach achieves photorealistic 3D-aware image
synthesis while capturing accurate underlying 3D shapes. We demonstrate
improved performance of our approach on 3D shape reconstruction against
existing methods, and show its applicability on image relighting. Our code will
be released at https://github.com/XingangPan/ShadeGAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">False Positive Detection and Prediction Quality Estimation for LiDAR Point Cloud Segmentation. (arXiv:2110.15681v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15681">
<div class="article-summary-box-inner">
<span><p>We present a novel post-processing tool for semantic segmentation of LiDAR
point cloud data, called LidarMetaSeg, which estimates the prediction quality
segmentwise. For this purpose we compute dispersion measures based on network
probability outputs as well as feature measures based on point cloud input
features and aggregate them on segment level. These aggregated measures are
used to train a meta classification model to predict whether a predicted
segment is a false positive or not and a meta regression model to predict the
segmentwise intersection over union. Both models can then be applied to
semantic segmentation inferences without knowing the ground truth. In our
experiments we use different LiDAR segmentation models and datasets and analyze
the power of our method. We show that our results outperform other standard
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Effective Image Restorer: Denoising and Luminance Adjustment for Low-photon-count Imaging. (arXiv:2110.15715v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15715">
<div class="article-summary-box-inner">
<span><p>Imaging under photon-scarce situations introduces challenges to many
applications as the captured images are with low signal-to-noise ratio and poor
luminance. In this paper, we investigate the raw image restoration under
low-photon-count conditions by simulating the imaging of quanta image sensor
(QIS). We develop a lightweight framework, which consists of a multi-level
pyramid denoising network (MPDNet) and a luminance adjustment (LA) module to
achieve separate denoising and luminance enhancement. The main component of our
framework is the multi-skip attention residual block (MARB), which integrates
multi-scale feature fusion and attention mechanism for better feature
representation. Our MPDNet adopts the idea of Laplacian pyramid to learn the
small-scale noise map and larger-scale high-frequency details at different
levels, and feature extractions are conducted on the multi-scale input images
to encode richer contextual information. Our LA module enhances the luminance
of the denoised image by estimating its illumination, which can better avoid
color distortion. Extensive experimental results have demonstrated that our
image restorer can achieve superior performance on the degraded images with
various photon levels by suppressing noise and recovering luminance and color
effectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generational Frameshifts in Technology: Computer Science and Neurosurgery, The VR Use Case. (arXiv:2110.15719v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15719">
<div class="article-summary-box-inner">
<span><p>We are at a unique moment in history where there is a confluence of
technologies which will synergistically come together to transform the practice
of neurosurgery. These technological transformations will be all-encompassing,
including improved tools and methods for intraoperative performance of
neurosurgery, scalable solutions for asynchronous neurosurgical training and
simulation, as well as broad aggregation of operative data allowing fundamental
changes in quality assessment, billing, outcome measures, and dissemination of
surgical best practices. The ability to perform surgery more safely and more
efficiently while capturing the operative details and parsing each component of
the operation will open an entirely new epoch advancing our field and all
surgical specialties. The digitization of all components within the operating
room will allow us to leverage the various fields within computer and
computational science to obtain new insights that will improve care and
delivery of the highest quality neurosurgery regardless of location. The
democratization of neurosurgery is at hand and will be driven by our
development, extraction, and adoption of these tools of the modern world.
Virtual reality provides a good example of how consumer-facing technologies are
finding a clear role in industry and medicine and serves as a notable example
of the confluence of various computer science technologies creating a novel
paradigm for scaling human ability and interactions. The authors describe the
technology ecosystem that has come and highlight a myriad of computational and
data sciences that will be necessary to enable the operating room of the near
future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CVAD: A generic medical anomaly detector based on Cascade VAE. (arXiv:2110.15811v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15811">
<div class="article-summary-box-inner">
<span><p>Detecting out-of-distribution (OOD) samples in medical imaging plays an
important role for downstream medical diagnosis. However, existing OOD
detectors are demonstrated on natural images composed of inter-classes and have
difficulty generalizing to medical images. The key issue is the granularity of
OOD data in the medical domain, where intra-class OOD samples are predominant.
We focus on the generalizability of OOD detection for medical images and
propose a self-supervised Cascade Variational autoencoder-based Anomaly
Detector (CVAD). We use a variational autoencoders' cascade architecture, which
combines latent representation at multiple scales, before being fed to a
discriminator to distinguish the OOD data from the in-distribution (ID) data.
Finally, both the reconstruction error and the OOD probability predicted by the
binary discriminator are used to determine the anomalies. We compare the
performance with the state-of-the-art deep learning models to demonstrate our
model's efficacy on various open-access medical imaging datasets for both
intra- and inter-class OOD. Further extensive results on datasets including
common natural datasets show our model's effectiveness and generalizability.
The code is available at https://github.com/XiaoyuanGuo/CVAD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A GIS Data Realistic Road Generation Approach for Traffic Simulation. (arXiv:2110.15814v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15814">
<div class="article-summary-box-inner">
<span><p>Road networks exist in the form of polylines with attributes within the GIS
databases. Such a representation renders the geographic data impracticable for
3D road traffic simulation. In this work, we propose a method to transform raw
GIS data into a realistic, operational model for real-time road traffic
simulation. For instance, the proposed raw to simulation ready data
transformation is achieved through several curvature estimation,
interpolation/approximation, and clustering schemes. The obtained results show
the performance of our approach and prove its adequacy to real traffic
simulation scenario as can be seen in this video 1 .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-time multiview data fusion for object tracking with RGBD sensors. (arXiv:2110.15815v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15815">
<div class="article-summary-box-inner">
<span><p>This paper presents a new approach to accurately track a moving vehicle with
a multiview setup of red-green-blue depth (RGBD) cameras. We first propose a
correction method to eliminate a shift, which occurs in depth sensors when they
become worn. This issue could not be otherwise corrected with the ordinary
calibration procedure. Next, we present a sensor-wise filtering system to
correct for an unknown vehicle motion. A data fusion algorithm is then used to
optimally merge the sensor-wise estimated trajectories. We implement most parts
of our solution in the graphic processor. Hence, the whole system is able to
operate at up to 25 frames per second with a configuration of five cameras.
Test results show the accuracy we achieved and the robustness of our solution
to overcome uncertainties in the measurements and the modelling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">C-MADA: Unsupervised Cross-Modality Adversarial Domain Adaptation framework for medical Image Segmentation. (arXiv:2110.15823v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15823">
<div class="article-summary-box-inner">
<span><p>Deep learning models have obtained state-of-the-art results for medical image
analysis. However, when these models are tested on an unseen domain there is a
significant performance degradation. In this work, we present an unsupervised
Cross-Modality Adversarial Domain Adaptation (C-MADA) framework for medical
image segmentation. C-MADA implements an image- and feature-level adaptation
method in a sequential manner. First, images from the source domain are
translated to the target domain through an un-paired image-to-image adversarial
translation with cycle-consistency loss. Then, a U-Net network is trained with
the mapped source domain images and target domain images in an adversarial
manner to learn domain-invariant feature representations. Furthermore, to
improve the networks segmentation performance, information about the shape,
texture, and con-tour of the predicted segmentation is included during the
adversarial train-ing. C-MADA is tested on the task of brain MRI segmentation,
obtaining competitive results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Application of 2-D Convolutional Neural Networks for Damage Detection in Steel Frame Structures. (arXiv:2110.15895v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15895">
<div class="article-summary-box-inner">
<span><p>In this paper, we present an application of 2-D convolutional neural networks
(2-D CNNs) designed to perform both feature extraction and classification
stages as a single organism to solve the highlighted problems. The method uses
a network of lighted CNNs instead of deep and takes raw acceleration signals as
input. Using lighted CNNs, in which every one of them is optimized for a
specific element, increases the accuracy and makes the network faster to
perform. Also, a new framework is proposed for decreasing the data required in
the training phase. We verified our method on Qatar University Grandstand
Simulator (QUGS) benchmark data provided by Structural Dynamics Team. The
results showed improved accuracy over other methods, and running time was
adequate for real-time applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Co-segmentation by Segment Swapping for Retrieval and Discovery. (arXiv:2110.15904v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15904">
<div class="article-summary-box-inner">
<span><p>The goal of this work is to efficiently identify visually similar patterns
from a pair of images, e.g. identifying an artwork detail copied between an
engraving and an oil painting, or matching a night-time photograph with its
daytime counterpart. Lack of training data is a key challenge for this
co-segmentation task. We present a simple yet surprisingly effective approach
to overcome this difficulty: we generate synthetic training pairs by selecting
object segments in an image and copy-pasting them into another image. We then
learn to predict the repeated object masks. We find that it is crucial to
predict the correspondences as an auxiliary task and to use Poisson blending
and style transfer on the training pairs to generalize on real data. We analyse
results with two deep architectures relevant to our joint image analysis task:
a transformer-based architecture and Sparse Nc-Net, a recent network designed
to predict coarse correspondences using 4D convolutions.
</p>
<p>We show our approach provides clear improvements for artwork details
retrieval on the Brueghel dataset and achieves competitive performance on two
place recognition benchmarks, Tokyo247 and Pitts30K. We then demonstrate the
potential of our approach by performing object discovery on the Internet object
discovery dataset and the Brueghel dataset. Our code and data are available at
<a href="http://imagine.enpc.fr/~shenx/SegSwap/.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the use of uncertainty in classifying Aedes Albopictus mosquitoes. (arXiv:2110.15912v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15912">
<div class="article-summary-box-inner">
<span><p>The re-emergence of mosquito-borne diseases (MBDs), which kill hundreds of
thousands of people each year, has been attributed to increased human
population, migration, and environmental changes. Convolutional neural networks
(CNNs) have been used by several studies to recognise mosquitoes in images
provided by projects such as Mosquito Alert to assist entomologists in
identifying, monitoring, and managing MBD. Nonetheless, utilising CNNs to
automatically label input samples could involve incorrect predictions, which
may mislead future epidemiological studies. Furthermore, CNNs require large
numbers of manually annotated data. In order to address the mentioned issues,
this paper proposes using the Monte Carlo Dropout method to estimate the
uncertainty scores in order to rank the classified samples to reduce the need
for human supervision in recognising Aedes albopictus mosquitoes. The estimated
uncertainty was also used in an active learning framework, where just a portion
of the data from large training sets was manually labelled. The experimental
results show that the proposed classification method with rejection outperforms
the competing methods by improving overall performance and reducing
entomologist annotation workload. We also provide explainable visualisations of
the different regions that contribute to a set of samples' uncertainty
assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating and Maximizing Mutual Information for Knowledge Distillation. (arXiv:2110.15946v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15946">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation is a widely used general technique to transfer
knowledge from a teacher network to a student network. In this work, we propose
Mutual Information Maximization Knowledge Distillation (MIMKD). Our method uses
a contrastive objective to simultaneously estimate and maximize a lower bound
on the mutual information between intermediate and global feature
representations from the teacher and the student networks. Our method is
flexible, as the proposed mutual information maximization does not impose
significant constraints on the structure of the intermediate features of the
networks. As such, we can distill knowledge from arbitrary teachers to
arbitrary students. Our empirical results show that our method outperforms
competing approaches across a wide range of student-teacher pairs with
different capacities, with different architectures, and when student networks
are with extremely low capacity. We are able to obtain 74.55% accuracy on
CIFAR100 with a ShufflenetV2 from a baseline accuracy of 69.8% by distilling
knowledge from ResNet50.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A deep convolutional neural network for classification of Aedes albopictus mosquitoes. (arXiv:2110.15956v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15956">
<div class="article-summary-box-inner">
<span><p>Monitoring the spread of disease-carrying mosquitoes is a first and necessary
step to control severe diseases such as dengue, chikungunya, Zika or yellow
fever. Previous citizen science projects have been able to obtain large image
datasets with linked geo-tracking information. As the number of international
collaborators grows, the manual annotation by expert entomologists of the large
amount of data gathered by these users becomes too time demanding and
unscalable, posing a strong need for automated classification of mosquito
species from images. We introduce the application of two Deep Convolutional
Neural Networks in a comparative study to automate this classification task. We
use the transfer learning principle to train two state-of-the-art architectures
on the data provided by the Mosquito Alert project, obtaining testing accuracy
of 94%. In addition, we applied explainable models based on the Grad-CAM
algorithm to visualise the most discriminant regions of the classified images,
which coincide with the white band stripes located at the legs, abdomen, and
thorax of mosquitoes of the Aedes albopictus species. The model allows us to
further analyse the classification errors. Visual Grad-CAM models show that
they are linked to poor acquisition conditions and strong image occlusions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Keyword Spotting with Attention. (arXiv:2110.15957v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15957">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider the task of spotting spoken keywords in silent
video sequences -- also known as visual keyword spotting. To this end, we
investigate Transformer-based models that ingest two streams, a visual encoding
of the video and a phonetic encoding of the keyword, and output the temporal
location of the keyword if present. Our contributions are as follows: (1) We
propose a novel architecture, the Transpotter, that uses full cross-modal
attention between the visual and phonetic streams; (2) We show through
extensive evaluations that our model outperforms the prior state-of-the-art
visual keyword spotting and lip reading methods on the challenging LRW, LRS2,
LRS3 datasets by a large margin; (3) We demonstrate the ability of our model to
spot words under the extreme conditions of isolated mouthings in sign language
videos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parabolic Approximation Line Search for DNNs. (arXiv:1903.11991v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.11991">
<div class="article-summary-box-inner">
<span><p>A major challenge in current optimization research for deep learning is to
automatically find optimal step sizes for each update step. The optimal step
size is closely related to the shape of the loss in the update step direction.
However, this shape has not yet been examined in detail. This work shows
empirically that the batch loss over lines in negative gradient direction is
mostly convex locally and well suited for one-dimensional parabolic
approximations. By exploiting this parabolic property we introduce a simple and
robust line search approach, which performs loss-shape dependent update steps.
Our approach combines well-known methods such as parabolic approximation, line
search and conjugate gradient, to perform efficiently. It surpasses other step
size estimating methods and competes with common optimization methods on a
large variety of experiments without the need of hand-designed step size
schedules. Thus, it is of interest for objectives where step-size schedules are
unknown or do not perform well. Our extensive evaluation includes multiple
comprehensive hyperparameter grid searches on several datasets and
architectures. Finally, we provide a general investigation of exact line
searches in the context of batch losses and exact losses, including their
relation to our line search approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Histogram Layers for Texture Analysis. (arXiv:2001.00215v11 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.00215">
<div class="article-summary-box-inner">
<span><p>An essential aspect of texture analysis is the extraction of features that
describe the distribution of values in local, spatial regions. We present a
localized histogram layer for artificial neural networks. Instead of computing
global histograms as done previously, the proposed histogram layer directly
computes the local, spatial distribution of features for texture analysis and
parameters for the layer are estimated during backpropagation. We compare our
method with state-of-the-art texture encoding methods such as the Deep Encoding
Network Pooling, Deep Texture Encoding Network, Fisher Vector convolutional
neural network, and Multi-level Texture Encoding and Representation on three
material/texture datasets: (1) the Describable Texture Dataset; (2) an
extension of the ground terrain in outdoor scenes; (3) and a subset of the
Materials in Context dataset. Results indicate that the inclusion of the
proposed histogram layer improves performance. The source code for the
histogram layer is publicly available:
https://github.com/GatorSense/Histogram_Layer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Renet: An improvement method for remote object detection based on Darknet. (arXiv:2002.03729v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.03729">
<div class="article-summary-box-inner">
<span><p>Recently, when we used this method to identify aircraft targets in remote
sensing images, we found that there are some defects in our own YOLOv2 and
Darknet-19 network. Characteristic in the images we identified are not very
clear,thats why we couldn't get some much more good results. Then we replaced
the maxpooling in the yolov3 network as the global maxpooling.Under the same
test conditions, we got a higher It achieves the processing speed of a single
image is only 0.023 s on a GTX1050TI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Image-generation Enhanced Adaptation for Object Detection in Thermal images. (arXiv:2002.06770v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.06770">
<div class="article-summary-box-inner">
<span><p>Object detection in thermal images is an important computer vision task and
has many applications such as unmanned vehicles, robotics, surveillance and
night vision. Deep learning based detectors have achieved major progress, which
usually need large amount of labelled training data. However, labelled data for
object detection in thermal images is scarce and expensive to collect. How to
take advantage of the large number labelled visible images and adapt them into
thermal image domain, is expected to solve. This paper proposes an unsupervised
image-generation enhanced adaptation method for object detection in thermal
images. To reduce the gap between visible domain and thermal domain, the
proposed method manages to generate simulated fake thermal images that are
similar to the target images, and preserves the annotation information of the
visible source domain. The image generation includes a CycleGAN based
image-to-image translation and an intensity inversion transformation. Generated
fake thermal images are used as renewed source domain. And then the
off-the-shelf Domain Adaptive Faster RCNN is utilized to reduce the gap between
generated intermediate domain and the thermal target domain. Experiments
demonstrate the effectiveness and superiority of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Efficient Performance Estimators of Neural Architectures. (arXiv:2008.03064v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03064">
<div class="article-summary-box-inner">
<span><p>Conducting efficient performance estimations of neural architectures is a
major challenge in neural architecture search (NAS). To reduce the architecture
training costs in NAS, one-shot estimators (OSEs) amortize the architecture
training costs by sharing the parameters of one "supernet" between all
architectures. Recently, zero-shot estimators (ZSEs) that involve no training
are proposed to further reduce the architecture evaluation cost. Despite the
high efficiency of these estimators, the quality of such estimations has not
been thoroughly studied. In this paper, we conduct an extensive and organized
assessment of OSEs and ZSEs on five NAS benchmarks: NAS-Bench-101/201/301, and
NDS ResNet/ResNeXt-A. Specifically, we employ a set of NAS-oriented criteria to
study the behavior of OSEs and ZSEs and reveal that they have certain biases
and variances. After analyzing how and why the OSE estimations are
unsatisfying, we explore how to mitigate the correlation gap of OSEs from
several perspectives. Through our analysis, we give out suggestions for future
application and development of efficient architecture performance estimators.
Furthermore, the analysis framework proposed in our work could be utilized in
future research to give a more comprehensive understanding of newly designed
architecture performance estimators. All codes are available at
https://github.com/walkerning/aw_nas.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Explanation is Not Enough: Structured Attention Graphs for Image Classification. (arXiv:2011.06733v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06733">
<div class="article-summary-box-inner">
<span><p>Attention maps are a popular way of explaining the decisions of convolutional
networks for image classification. Typically, for each image of interest, a
single attention map is produced, which assigns weights to pixels based on
their importance to the classification. A single attention map, however,
provides an incomplete understanding since there are often many other maps that
explain a classification equally well. In this paper, we introduce structured
attention graphs (SAGs), which compactly represent sets of attention maps for
an image by capturing how different combinations of image regions impact a
classifier's confidence. We propose an approach to compute SAGs and a
visualization for SAGs so that deeper insight can be gained into a classifier's
decisions. We conduct a user study comparing the use of SAGs to traditional
attention maps for answering counterfactual questions about image
classifications. Our results show that the users are more correct when
answering comparative counterfactual questions based on SAGs compared to the
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Large-Scale Database for Graph Representation Learning. (arXiv:2011.07682v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07682">
<div class="article-summary-box-inner">
<span><p>With the rapid emergence of graph representation learning, the construction
of new large-scale datasets is necessary to distinguish model capabilities and
accurately assess the strengths and weaknesses of each technique. By carefully
analyzing existing graph databases, we identify 3 critical components important
for advancing the field of graph representation learning: (1) large graphs, (2)
many graphs, and (3) class diversity. To date, no single graph database offers
all these desired properties. We introduce MalNet, the largest public graph
database ever constructed, representing a large-scale ontology of malicious
software function call graphs. MalNet contains over 1.2 million graphs,
averaging over 15k nodes and 35k edges per graph, across a hierarchy of 47
types and 696 families. Compared to the popular REDDIT-12K database, MalNet
offers 105x more graphs, 39x larger graphs on average, and 63x more classes. We
provide a detailed analysis of MalNet, discussing its properties and
provenance, along with the evaluation of state-of-the-art machine learning and
graph neural network techniques. The unprecedented scale and diversity of
MalNet offers exciting opportunities to advance the frontiers of graph
representation learning--enabling new discoveries and research into imbalanced
classification, explainability and the impact of class hardness. The database
is publicly available at www.mal-net.org.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ax-BxP: Approximate Blocked Computation for Precision-Reconfigurable Deep Neural Network Acceleration. (arXiv:2011.13000v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13000">
<div class="article-summary-box-inner">
<span><p>Precision scaling has emerged as a popular technique to optimize the compute
and storage requirements of Deep Neural Networks (DNNs). Efforts toward
creating ultra-low-precision (sub-8-bit) DNNs suggest that the minimum
precision required to achieve a given network-level accuracy varies
considerably across networks, and even across layers within a network,
requiring support for variable precision in DNN hardware. Previous proposals
such as bit-serial hardware incur high overheads, significantly diminishing the
benefits of lower precision. To efficiently support precision
re-configurability in DNN accelerators, we introduce an approximate computing
method wherein DNN computations are performed block-wise (a block is a group of
bits) and re-configurability is supported at the granularity of blocks. Results
of block-wise computations are composed in an approximate manner to enable
efficient re-configurability. We design a DNN accelerator that embodies
approximate blocked computation and propose a method to determine a suitable
approximation configuration for a given DNN. By varying the approximation
configurations across DNNs, we achieve 1.17x-1.73x and 1.02x-2.04x improvement
in system energy and performance respectively, over an 8-bit fixed-point (FxP8)
baseline, with negligible loss in classification accuracy. Further, by varying
the approximation configurations across layers and data-structures within DNNs,
we achieve 1.25x-2.42x and 1.07x-2.95x improvement in system energy and
performance respectively, with negligible accuracy loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event-based Motion Segmentation with Spatio-Temporal Graph Cuts. (arXiv:2012.08730v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08730">
<div class="article-summary-box-inner">
<span><p>Identifying independently moving objects is an essential task for dynamic
scene understanding. However, traditional cameras used in dynamic scenes may
suffer from motion blur or exposure artifacts due to their sampling principle.
By contrast, event-based cameras are novel bio-inspired sensors that offer
advantages to overcome such limitations. They report pixelwise intensity
changes asynchronously, which enables them to acquire visual information at
exactly the same rate as the scene dynamics. We develop a method to identify
independently moving objects acquired with an event-based camera, i.e., to
solve the event-based motion segmentation problem. We cast the problem as an
energy minimization one involving the fitting of multiple motion models. We
jointly solve two subproblems, namely event cluster assignment (labeling) and
motion model fitting, in an iterative manner by exploiting the structure of the
input event data in the form of a spatio-temporal graph. Experiments on
available datasets demonstrate the versatility of the method in scenes with
different motion patterns and number of moving objects. The evaluation shows
state-of-the-art results without having to predetermine the number of expected
moving objects. We release the software and dataset under an open source
licence to foster research in the emerging topic of event-based motion
segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate Object Association and Pose Updating for Semantic SLAM. (arXiv:2012.11368v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11368">
<div class="article-summary-box-inner">
<span><p>Nowadays in the field of semantic SLAM, how to correctly use semantic
information for data association is still a problem worthy of study. The key to
solving this problem is to correctly associate multiple object measurements of
one object landmark, and refine the pose of object landmark. However, different
objects locating closely are prone to be associated as one object landmark, and
it is difficult to pick up a best pose from multiple object measurements
associated with one object landmark. To tackle these problems, we propose a
hierarchical object association strategy by means of multiple object tracking,
through which closing objects will be correctly associated to different object
landmarks, and an approach to refine the pose of object landmark from multiple
object measurements. The proposed method is evaluated on a simulated sequence
and several sequences in the Kitti dataset. Experimental results show a very
impressive improvement with respect to the traditional SLAM and the
state-of-the-art semantic SLAM method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OBoW: Online Bag-of-Visual-Words Generation for Self-Supervised Learning. (arXiv:2012.11552v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11552">
<div class="article-summary-box-inner">
<span><p>Learning image representations without human supervision is an important and
active research field. Several recent approaches have successfully leveraged
the idea of making such a representation invariant under different types of
perturbations, especially via contrastive-based instance discrimination
training. Although effective visual representations should indeed exhibit such
invariances, there are other important characteristics, such as encoding
contextual reasoning skills, for which alternative reconstruction-based
approaches might be better suited.
</p>
<p>With this in mind, we propose a teacher-student scheme to learn
representations by training a convolutional net to reconstruct a
bag-of-visual-words (BoW) representation of an image, given as input a
perturbed version of that same image. Our strategy performs an online training
of both the teacher network (whose role is to generate the BoW targets) and the
student network (whose role is to learn representations), along with an online
update of the visual-words vocabulary (used for the BoW targets). This idea
effectively enables fully online BoW-guided unsupervised learning. Extensive
experiments demonstrate the interest of our BoW-based strategy which surpasses
previous state-of-the-art methods (including contrastive-based ones) in several
applications. For instance, in downstream tasks such Pascal object detection,
Pascal classification and Places205 classification, our method improves over
all prior unsupervised approaches, thus establishing new state-of-the-art
results that are also significantly better even than those of supervised
pre-training. We provide the implementation code at
https://github.com/valeoai/obow.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose. (arXiv:2102.06199v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06199">
<div class="article-summary-box-inner">
<span><p>While deep learning reshaped the classical motion capture pipeline with
feed-forward networks, generative models are required to recover fine alignment
via iterative refinement. Unfortunately, the existing models are usually
hand-crafted or learned in controlled conditions, only applicable to limited
domains. We propose a method to learn a generative neural body model from
unlabelled monocular videos by extending Neural Radiance Fields (NeRFs). We
equip them with a skeleton to apply to time-varying and articulated motion. A
key insight is that implicit models require the inverse of the forward
kinematics used in explicit surface models. Our reparameterization defines
spatial latent variables relative to the pose of body parts and thereby
overcomes ill-posed inverse operations with an overparameterization. This
enables learning volumetric body shape and appearance from scratch while
jointly refining the articulated pose; all without ground truth labels for
appearance, pose, or 3D shape on the input videos. When used for
novel-view-synthesis and motion capture, our neural model improves accuracy on
diverse datasets. Project website: https://lemonatsu.github.io/anerf/ .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hard-Attention for Scalable Image Classification. (arXiv:2102.10212v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10212">
<div class="article-summary-box-inner">
<span><p>Can we leverage high-resolution information without the unsustainable
quadratic complexity to input scale? We propose Traversal Network (TNet), a
novel multi-scale hard-attention architecture, which traverses image
scale-space in a top-down fashion, visiting only the most informative image
regions along the way. TNet offers an adjustable trade-off between accuracy and
complexity, by changing the number of attended image locations. We compare our
model against hard-attention baselines on ImageNet, achieving higher accuracy
with less resources (FLOPs, processing time and memory). We further test our
model on fMoW dataset, where we process satellite images of size up to $896
\times 896$ px, getting up to $2.5$x faster processing compared to baselines
operating on the same resolution, while achieving higher accuracy as well. TNet
is modular, meaning that most classification models could be adopted as its
backbone for feature extraction, making the reported performance gains
orthogonal to benefits offered by existing optimized deep models. Finally,
hard-attention guarantees a degree of interpretability to our model's
predictions, without any extra cost beyond inference. Code is available at
$\href{https://github.com/Tpap/TNet}{github.com/Tpap/TNet}$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Self-supervised Neural Architecture Search. (arXiv:2102.10557v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10557">
<div class="article-summary-box-inner">
<span><p>This paper proposes a novel cell-based neural architecture search algorithm
(NAS), which completely alleviates the expensive costs of data labeling
inherited from supervised learning. Our algorithm capitalizes on the
effectiveness of self-supervised learning for image representations, which is
an increasingly crucial topic of computer vision. First, using only a small
amount of unlabeled train data under contrastive self-supervised learning allow
us to search on a more extensive search space, discovering better neural
architectures without surging the computational resources. Second, we entirely
relieve the cost for labeled data (by contrastive loss) in the search stage
without compromising architectures' final performance in the evaluation phase.
Finally, we tackle the inherent discrete search space of the NAS problem by
sequential model-based optimization via the tree-parzen estimator (SMBO-TPE),
enabling us to reduce the computational expense response surface significantly.
An extensive number of experiments empirically show that our search algorithm
can achieve state-of-the-art results with better efficiency in data labeling
cost, searching time, and accuracy in final validation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cycle Self-Training for Domain Adaptation. (arXiv:2103.03571v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03571">
<div class="article-summary-box-inner">
<span><p>Mainstream approaches for unsupervised domain adaptation (UDA) learn
domain-invariant representations to narrow the domain shift. Recently,
self-training has been gaining momentum in UDA, which exploits unlabeled target
data by training with target pseudo-labels. However, as corroborated in this
work, under distributional shift in UDA, the pseudo-labels can be unreliable in
terms of their large discrepancy from target ground truth. Thereby, we propose
Cycle Self-Training (CST), a principled self-training algorithm that explicitly
enforces pseudo-labels to generalize across domains. CST cycles between a
forward step and a reverse step until convergence. In the forward step, CST
generates target pseudo-labels with a source-trained classifier. In the reverse
step, CST trains a target classifier using target pseudo-labels, and then
updates the shared representations to make the target classifier perform well
on the source data. We introduce the Tsallis entropy as a confidence-friendly
regularization to improve the quality of target pseudo-labels. We analyze CST
theoretically under realistic assumptions, and provide hard cases where CST
recovers target ground truth, while both invariant feature learning and vanilla
self-training fail. Empirical results indicate that CST significantly improves
over the state-of-the-arts on visual recognition and sentiment analysis
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining Morphological and Histogram based Text Line Segmentation in the OCR Context. (arXiv:2103.08922v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08922">
<div class="article-summary-box-inner">
<span><p>Text line segmentation is one of the pre-stages of modern optical character
recognition systems. The algorithmic approach proposed by this paper has been
designed for this exact purpose. Its main characteristic is the combination of
two different techniques, morphological image operations and horizontal
histogram projections. The method was developed to be applied on a historic
data collection that commonly features quality issues, such as degraded paper,
blurred text, or presence of noise. For that reason, the segmenter in question
could be of particular interest for cultural institutions, that want access to
robust line bounding boxes for a given historic document. Because of the
promising segmentation results that are joined by low computational cost, the
algorithm was incorporated into the OCR pipeline of the National Library of
Luxembourg, in the context of the initiative of reprocessing their historic
newspaper collection. The general contribution of this paper is to outline the
approach and to evaluate the gains in terms of accuracy and speed, comparing it
to the segmentation algorithm bundled with the used open source OCR software.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SuctionNet-1Billion: A Large-Scale Benchmark for Suction Grasping. (arXiv:2103.12311v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12311">
<div class="article-summary-box-inner">
<span><p>Suction is an important solution for the longstanding robotic grasping
problem. Compared with other kinds of grasping, suction grasping is easier to
represent and often more reliable in practice. Though preferred in many
scenarios, it is not fully investigated and lacks sufficient training data and
evaluation benchmarks. To address that, firstly, we propose a new physical
model to analytically evaluate seal formation and wrench resistance of a
suction grasping, which are two key aspects of grasp success. Secondly, a
two-step methodology is adopted to generate annotations on a large-scale
dataset collected in real-world cluttered scenarios. Thirdly, a standard online
evaluation system is proposed to evaluate suction poses in continuous operation
space, which can benchmark different algorithms fairly without the need of
exhaustive labeling. Real-robot experiments are conducted to show that our
annotations align well with real world. Meanwhile, we propose a method to
predict numerous suction poses from an RGB-D image of a cluttered scene and
demonstrate our superiority against several previous methods. Result analyses
are further provided to help readers better understand the challenges in this
area. Data and source code are publicly available at www.graspnet.net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DA4Event: towards bridging the Sim-to-Real Gap for Event Cameras using Domain Adaptation. (arXiv:2103.12768v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12768">
<div class="article-summary-box-inner">
<span><p>Event cameras are novel bio-inspired sensors, which asynchronously capture
pixel-level intensity changes in the form of "events". The innovative way they
acquire data presents several advantages over standard devices, especially in
poor lighting and high-speed motion conditions. However, the novelty of these
sensors results in the lack of a large amount of training data capable of fully
unlocking their potential. The most common approach implemented by researchers
to address this issue is to leverage simulated event data. Yet, this approach
comes with an open research question: how well simulated data generalize to
real data? To answer this, we propose to exploit, in the event-based context,
recent Domain Adaptation (DA) advances in traditional computer vision, showing
that DA techniques applied to event data help reduce the sim-to-real gap. To
this purpose, we propose a novel architecture, which we call Multi-View DA4E
(MV-DA4E), that better exploits the peculiarities of frame-based event
representations while also promoting domain invariant characteristics in
features. Through extensive experiments, we prove the effectiveness of DA
methods and MV-DA4E on N-Caltech101. Moreover, we validate their soundness in a
real-world scenario through a cross-domain analysis on the popular RGB-D Object
Dataset (ROD), which we extended to the event modality (RGB-E).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Knowledge Expansion. (arXiv:2103.14431v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14431">
<div class="article-summary-box-inner">
<span><p>The popularity of multimodal sensors and the accessibility of the Internet
have brought us a massive amount of unlabeled multimodal data. Since existing
datasets and well-trained models are primarily unimodal, the modality gap
between a unimodal network and unlabeled multimodal data poses an interesting
problem: how to transfer a pre-trained unimodal network to perform the same
task on unlabeled multimodal data? In this work, we propose multimodal
knowledge expansion (MKE), a knowledge distillation-based framework to
effectively utilize multimodal data without requiring labels. Opposite to
traditional knowledge distillation, where the student is designed to be
lightweight and inferior to the teacher, we observe that a multimodal student
model consistently denoises pseudo labels and generalizes better than its
teacher. Extensive experiments on four tasks and different modalities verify
this finding. Furthermore, we connect the mechanism of MKE to semi-supervised
learning and offer both empirical and theoretical explanations to understand
the denoising capability of a multimodal student.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Fidelity End-to-End Video Encoder Pre-training for Temporal Action Localization. (arXiv:2103.15233v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15233">
<div class="article-summary-box-inner">
<span><p>Temporal action localization (TAL) is a fundamental yet challenging task in
video understanding. Existing TAL methods rely on pre-training a video encoder
through action classification supervision. This results in a task discrepancy
problem for the video encoder -- trained for action classification, but used
for TAL. Intuitively, end-to-end model optimization is a good solution.
However, this is not operable for TAL subject to the GPU memory constraints,
due to the prohibitive computational cost in processing long untrimmed videos.
In this paper, we resolve this challenge by introducing a novel low-fidelity
end-to-end (LoFi) video encoder pre-training method. Instead of always using
the full training configurations for TAL learning, we propose to reduce the
mini-batch composition in terms of temporal, spatial or spatio-temporal
resolution so that end-to-end optimization for the video encoder becomes
operable under the memory conditions of a mid-range hardware budget. Crucially,
this enables the gradient to flow backward through the video encoder from a TAL
loss supervision, favourably solving the task discrepancy problem and providing
more effective feature representations. Extensive experiments show that the
proposed LoFi pre-training approach can significantly enhance the performance
of existing TAL methods. Encouragingly, even with a lightweight ResNet18 based
video encoder in a single RGB stream, our method surpasses two-stream ResNet50
based alternatives with expensive optical flow, often by a good margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph-based Thermal-Inertial SLAM with Probabilistic Neural Networks. (arXiv:2104.07196v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07196">
<div class="article-summary-box-inner">
<span><p>Simultaneous Localization and Mapping (SLAM) system typically employ
vision-based sensors to observe the surrounding environment. However, the
performance of such systems highly depends on the ambient illumination
conditions. In scenarios with adverse visibility or in the presence of airborne
particulates (e.g. smoke, dust, etc.), alternative modalities such as those
based on thermal imaging and inertial sensors are more promising. In this
paper, we propose the first complete thermal-inertial SLAM system which
combines neural abstraction in the SLAM front end with robust pose graph
optimization in the SLAM back end. We model the sensor abstraction in the front
end by employing probabilistic deep learning parameterized by Mixture Density
Networks (MDN). Our key strategies to successfully model this encoding from
thermal imagery are the usage of normalized 14-bit radiometric data, the
incorporation of hallucinated visual (RGB) features, and the inclusion of
feature selection to estimate the MDN parameters. To enable a full SLAM system,
we also design an efficient global image descriptor which is able to detect
loop closures from thermal embedding vectors. We performed extensive
experiments and analysis using three datasets, namely self-collected ground
robot and handheld data taken in indoor environment, and one public dataset
(SubT-tunnel) collected in underground tunnel. Finally, we demonstrate that an
accurate thermal-inertial SLAM system can be realized in conditions of both
benign and adverse visibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-paced Resistance Learning against Overfitting on Noisy Labels. (arXiv:2105.03059v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03059">
<div class="article-summary-box-inner">
<span><p>Noisy labels composed of correct and corrupted ones are pervasive in
practice. They might significantly deteriorate the performance of convolutional
neural networks (CNNs), because CNNs are easily overfitted on corrupted labels.
To address this issue, inspired by an observation, deep neural networks might
first memorize the probably correct-label data and then corrupt-label samples,
we propose a novel yet simple self-paced resistance framework to resist
corrupted labels, without using any clean validation data. The proposed
framework first utilizes the memorization effect of CNNs to learn a curriculum,
which contains confident samples and provides meaningful supervision for other
training samples. Then it adopts selected confident samples and a proposed
resistance loss to update model parameters; the resistance loss tends to smooth
model parameters' update or attain equivalent prediction over each class,
thereby resisting model overfitting on corrupted labels. Finally, we unify
these two modules into a single loss function and optimize it in an alternative
learning. Extensive experiments demonstrate the significantly superior
performance of the proposed framework over recent state-of-the-art methods on
noisy-label data. Source codes of the proposed method are available on
https://github.com/xsshi2015/Self-paced-Resistance-Learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels. (arXiv:2105.04522v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04522">
<div class="article-summary-box-inner">
<span><p>Prior works have found it beneficial to combine provably noise-robust loss
functions e.g., mean absolute error (MAE) with standard categorical loss
function e.g. cross entropy (CE) to improve their learnability. Here, we
propose to use Jensen-Shannon divergence as a noise-robust loss function and
show that it interestingly interpolate between CE and MAE with a controllable
mixing parameter. Furthermore, we make a crucial observation that CE exhibit
lower consistency around noisy data points. Based on this observation, we adopt
a generalized version of the Jensen-Shannon divergence for multiple
distributions to encourage consistency around data points. Using this loss
function, we show state-of-the-art results on both synthetic (CIFAR), and
real-world (e.g., WebVision) noise with varying noise rates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neighborhood-Aware Neural Architecture Search. (arXiv:2105.06369v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06369">
<div class="article-summary-box-inner">
<span><p>Existing neural architecture search (NAS) methods often return an
architecture with good search performance but generalizes poorly to the test
setting. To achieve better generalization, we propose a novel
neighborhood-aware NAS formulation to identify flat-minima architectures in the
search space, with the assumption that flat minima generalize better than sharp
minima. The phrase ``flat-minima architecture'' refers to architectures whose
performance is stable under small perturbations in the architecture (e.g.,
replacing a convolution with a skip connection). Our formulation takes the
``flatness'' of an architecture into account by aggregating the performance
over the neighborhood of this architecture. We demonstrate a principled way to
apply our formulation to existing search algorithms, including sampling-based
algorithms and gradient-based algorithms. To facilitate the application to
gradient-based algorithms, we also propose a differentiable representation for
the neighborhood of architectures. Based on our formulation, we propose
neighborhood-aware random search (NA-RS) and neighborhood-aware differentiable
architecture search (NA-DARTS). Notably, by simply augmenting DARTS with our
formulation, NA-DARTS outperforms DARTS and achieves state-of-the-art
performance on established benchmarks, including CIFAR-10, CIFAR-100 and
ImageNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DOCTOR: A Simple Method for Detecting Misclassification Errors. (arXiv:2106.02395v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02395">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) have shown to perform very well on large scale
object recognition problems and lead to widespread use for real-world
applications, including situations where DNN are implemented as "black boxes".
A promising approach to secure their use is to accept decisions that are likely
to be correct while discarding the others. In this work, we propose DOCTOR, a
simple method that aims to identify whether the prediction of a DNN classifier
should (or should not) be trusted so that, consequently, it would be possible
to accept it or to reject it. Two scenarios are investigated: Totally Black Box
(TBB) where only the soft-predictions are available and Partially Black Box
(PBB) where gradient-propagation to perform input pre-processing is allowed.
Empirically, we show that DOCTOR outperforms all state-of-the-art methods on
various well-known images and sentiment analysis datasets. In particular, we
observe a reduction of up to $4\%$ of the false rejection rate (FRR) in the PBB
scenario. DOCTOR can be applied to any pre-trained model, it does not require
prior information about the underlying dataset and is as simple as the simplest
available methods in the literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Manifold Topology Divergence: a Framework for Comparing Data Manifolds. (arXiv:2106.04024v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04024">
<div class="article-summary-box-inner">
<span><p>We develop a framework for comparing data manifolds, aimed, in particular,
towards the evaluation of deep generative models. We describe a novel tool,
Cross-Barcode(P,Q), that, given a pair of distributions in a high-dimensional
space, tracks multiscale topology spacial discrepancies between manifolds on
which the distributions are concentrated. Based on the Cross-Barcode, we
introduce the Manifold Topology Divergence score (MTop-Divergence) and apply it
to assess the performance of deep generative models in various domains: images,
3D-shapes, time-series, and on different datasets: MNIST, Fashion MNIST, SVHN,
CIFAR10, FFHQ, chest X-ray images, market stock data, ShapeNet. We demonstrate
that the MTop-Divergence accurately detects various degrees of mode-dropping,
intra-mode collapse, mode invention, and image disturbance. Our algorithm
scales well (essentially linearly) with the increase of the dimension of the
ambient high-dimensional space. It is one of the first TDA-based practical
methodologies that can be applied universally to datasets of different sizes
and dimensions, including the ones on which the most recent GANs in the visual
domain are trained. The proposed method is domain agnostic and does not rely on
pre-trained networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. (arXiv:2106.04619v3 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04619">
<div class="article-summary-box-inner">
<span><p>Self-supervised representation learning has shown remarkable success in a
number of domains. A common practice is to perform data augmentation via
hand-crafted transformations intended to leave the semantics of the data
invariant. We seek to understand the empirical success of this approach from a
theoretical perspective. We formulate the augmentation process as a latent
variable model by postulating a partition of the latent representation into a
content component, which is assumed invariant to augmentation, and a style
component, which is allowed to change. Unlike prior work on disentanglement and
independent component analysis, we allow for both nontrivial statistical and
causal dependencies in the latent space. We study the identifiability of the
latent representation based on pairs of views of the observations and prove
sufficient conditions that allow us to identify the invariant content partition
up to an invertible mapping in both generative and discriminative settings. We
find numerical simulations with dependent latent variables are consistent with
our theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,
visually complex images with rich causal dependencies, which we use to study
the effect of data augmentations performed in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Potato Crop Stress Identification in Aerial Images using Deep Learning-based Object Detection. (arXiv:2106.07770v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07770">
<div class="article-summary-box-inner">
<span><p>Recent research on the application of remote sensing and deep learning-based
analysis in precision agriculture demonstrated a potential for improved crop
management and reduced environmental impacts of agricultural production.
Despite the promising results, the practical relevance of these technologies
for field deployment requires novel algorithms that are customized for analysis
of agricultural images and robust to implementation on natural field imagery.
The paper presents an approach for analyzing aerial images of a potato (Solanum
tuberosum L.) crop using deep neural networks. The main objective is to
demonstrate automated spatial recognition of healthy vs. stressed crop at a
plant level. Specifically, we examine premature plant senescence resulting in
drought stress on Russet Burbank potato plants. We propose a novel deep
learning (DL) model for detecting crop stress, named Retina-UNet-Ag. The
proposed architecture is a variant of Retina-UNet and includes connections from
low-level semantic representation maps to the feature pyramid network. The
paper also introduces a dataset of aerial field images acquired with a Parrot
Sequoia camera. The dataset includes manually annotated bounding boxes of
healthy and stressed plant regions. Experimental validation demonstrated the
ability for distinguishing healthy and stressed plants in field images,
achieving an average dice score coefficient (DSC) of 0.74. A comparison to
related state-of-the-art DL models for object detection revealed that the
presented approach is effective for this task. The proposed method is conducive
toward the assessment and recognition of potato crop stress in aerial field
images collected under natural conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Test-Time Personalization with a Transformer for Human Pose Estimation. (arXiv:2107.02133v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02133">
<div class="article-summary-box-inner">
<span><p>We propose to personalize a human pose estimator given a set of test images
of a person without using any manual annotations. While there is a significant
advancement in human pose estimation, it is still very challenging for a model
to generalize to different unknown environments and unseen persons. Instead of
using a fixed model for every test case, we adapt our pose estimator during
test time to exploit person-specific information. We first train our model on
diverse data with both a supervised and a self-supervised pose estimation
objectives jointly. We use a Transformer model to build a transformation
between the self-supervised keypoints and the supervised keypoints. During test
time, we personalize and adapt our model by fine-tuning with the
self-supervised objective. The pose is then improved by transforming the
updated self-supervised keypoints. We experiment with multiple datasets and
show significant improvements on pose estimations with our self-supervised
personalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long Short-Term Transformer for Online Action Detection. (arXiv:2107.03377v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03377">
<div class="article-summary-box-inner">
<span><p>We present Long Short-term TRansformer (LSTR), a temporal modeling algorithm
for online action detection, which employs a long- and short-term memory
mechanism to model prolonged sequence data. It consists of an LSTR encoder that
dynamically leverages coarse-scale historical information from an extended
temporal window (e.g., 2048 frames spanning of up to 8 minutes), together with
an LSTR decoder that focuses on a short time window (e.g., 32 frames spanning 8
seconds) to model the fine-scale characteristics of the data. Compared to prior
work, LSTR provides an effective and efficient method to model long videos with
fewer heuristics, which is validated by extensive empirical analysis. LSTR
achieves state-of-the-art performance on three standard online action detection
benchmarks, THUMOS'14, TVSeries, and HACS Segment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying Layers Susceptible to Adversarial Attacks. (arXiv:2107.04827v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04827">
<div class="article-summary-box-inner">
<span><p>In this paper, we investigate the use of pretraining with adversarial
networks, with the objective of discovering the relationship between network
depth and robustness. For this purpose, we selectively retrain different
portions of VGG and ResNet architectures on CIFAR-10, Imagenette, and ImageNet
using non-adversarial and adversarial data. Experimental results show that
susceptibility to adversarial samples is associated with low-level feature
extraction layers. Therefore, retraining of high-level layers is insufficient
for achieving robustness. Furthermore, adversarial attacks yield outputs from
early layers that differ statistically from features for non-adversarial
samples and do not permit consistent classification by subsequent layers. This
supports common hypotheses regarding the association of robustness with the
feature extractor, insufficiency of deeper layers in providing robustness, and
large differences in adversarial and non-adversarial feature vectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-end Multi-modal Video Temporal Grounding. (arXiv:2107.05624v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05624">
<div class="article-summary-box-inner">
<span><p>We address the problem of text-guided video temporal grounding, which aims to
identify the time interval of a certain event based on a natural language
description. Different from most existing methods that only consider RGB images
as visual features, we propose a multi-modal framework to extract complementary
information from videos. Specifically, we adopt RGB images for appearance,
optical flow for motion, and depth maps for image structure. While RGB images
provide abundant visual cues of certain events, the performance may be affected
by background clutters. Therefore, we use optical flow to focus on large motion
and depth maps to infer the scene configuration when the action is related to
objects recognizable with their shapes. To integrate the three modalities more
effectively and enable inter-modal learning, we design a dynamic fusion scheme
with transformers to model the interactions between modalities. Furthermore, we
apply intra-modal self-supervised learning to enhance feature representations
across videos for each modality, which also facilitates multi-modal learning.
We conduct extensive experiments on the Charades-STA and ActivityNet Captions
datasets, and show that the proposed method performs favorably against
state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Group-based Distinctive Image Captioning with Memory Attention. (arXiv:2108.09151v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09151">
<div class="article-summary-box-inner">
<span><p>Describing images using natural language is widely known as image captioning,
which has made consistent progress due to the development of computer vision
and natural language generation techniques. Though conventional captioning
models achieve high accuracy based on popular metrics, i.e., BLEU, CIDEr, and
SPICE, the ability of captions to distinguish the target image from other
similar images is under-explored. To generate distinctive captions, a few
pioneers employ contrastive learning or re-weighted the ground-truth captions,
which focuses on one single input image. However, the relationships between
objects in a similar image group (e.g., items or properties within the same
album or fine-grained events) are neglected. In this paper, we improve the
distinctiveness of image captions using a Group-based Distinctive Captioning
Model (GdisCap), which compares each image with other images in one similar
group and highlights the uniqueness of each image. In particular, we propose a
group-based memory attention (GMA) module, which stores object features that
are unique among the image group (i.e., with low similarity to objects in other
images). These unique object features are highlighted when generating captions,
resulting in more distinctive captions. Furthermore, the distinctive words in
the ground-truth captions are selected to supervise the language decoder and
GMA. Finally, we propose a new evaluation metric, distinctive word rate
(DisWordRate) to measure the distinctiveness of captions. Quantitative results
indicate that the proposed method significantly improves the distinctiveness of
several baseline models, and achieves the state-of-the-art performance on both
accuracy and distinctiveness. Results of a user study agree with the
quantitative evaluation and demonstrate the rationality of the new metric
DisWordRate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shifted Chunk Transformer for Spatio-Temporal Representational Learning. (arXiv:2108.11575v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11575">
<div class="article-summary-box-inner">
<span><p>Spatio-temporal representational learning has been widely adopted in various
fields such as action recognition, video object segmentation, and action
anticipation. Previous spatio-temporal representational learning approaches
primarily employ ConvNets or sequential models,e.g., LSTM, to learn the
intra-frame and inter-frame features. Recently, Transformer models have
successfully dominated the study of natural language processing (NLP), image
classification, etc. However, the pure-Transformer based spatio-temporal
learning can be prohibitively costly on memory and computation to extract
fine-grained features from a tiny patch. To tackle the training difficulty and
enhance the spatio-temporal learning, we construct a shifted chunk Transformer
with pure self-attention blocks. Leveraging the recent efficient Transformer
design in NLP, this shifted chunk Transformer can learn hierarchical
spatio-temporal features from a local tiny patch to a global video clip. Our
shifted self-attention can also effectively model complicated inter-frame
variances. Furthermore, we build a clip encoder based on Transformer to model
long-term temporal dependencies. We conduct thorough ablation studies to
validate each component and hyper-parameters in our shifted chunk Transformer,
and it outperforms previous state-of-the-art approaches on Kinetics-400,
Kinetics-600, UCF101, and HMDB51.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PAENet: A Progressive Attention-Enhanced Network for 3D to 2D Retinal Vessel Segmentation. (arXiv:2108.11695v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11695">
<div class="article-summary-box-inner">
<span><p>3D to 2D retinal vessel segmentation is a challenging problem in Optical
Coherence Tomography Angiography (OCTA) images. Accurate retinal vessel
segmentation is important for the diagnosis and prevention of ophthalmic
diseases. However, making full use of the 3D data of OCTA volumes is a vital
factor for obtaining satisfactory segmentation results. In this paper, we
propose a Progressive Attention-Enhanced Network (PAENet) based on attention
mechanisms to extract rich feature representation. Specifically, the framework
consists of two main parts, the three-dimensional feature learning path and the
two-dimensional segmentation path. In the three-dimensional feature learning
path, we design a novel Adaptive Pooling Module (APM) and propose a new
Quadruple Attention Module (QAM). The APM captures dependencies along the
projection direction of volumes and learns a series of pooling coefficients for
feature fusion, which efficiently reduces feature dimension. In addition, the
QAM reweights the features by capturing four-group cross-dimension
dependencies, which makes maximum use of 4D feature tensors. In the
two-dimensional segmentation path, to acquire more detailed information, we
propose a Feature Fusion Module (FFM) to inject 3D information into the 2D
path. Meanwhile, we adopt the Polarized Self-Attention (PSA) block to model the
semantic interdependencies in spatial and channel dimensions respectively.
Experimentally, our extensive experiments on the OCTA-500 dataset show that our
proposed algorithm achieves state-of-the-art performance compared with previous
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognition Awareness: An Application of Latent Cognizance to Open-Set Recognition. (arXiv:2108.12115v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12115">
<div class="article-summary-box-inner">
<span><p>This study investigates an application of a new probabilistic interpretation
of a softmax output to Open-Set Recognition (OSR). Softmax is a mechanism
wildly used in classification and object recognition.
</p>
<p>However, a softmax mechanism forces a model to operate under a closed-set
paradigm, i.e., to predict an object class out of a set of pre-defined labels.
</p>
<p>This characteristic contributes to efficacy in classification, but poses a
risk of non-sense prediction in object recognition.
</p>
<p>Object recognition is often operated under a dynamic and diverse condition.
</p>
<p>A foreign object -- an object of any unprepared class -- can be encountered
at any time.
</p>
<p>OSR is intended to address an issue of identifying a foreign object in object
recognition.
</p>
<p>Based on Bayes theorem and the emphasis of conditioning on the context,
softmax inference has been re-interpreted.
</p>
<p>This re-interpretation has led to a new approach to OSR, called Latent
Cognizance (LC). Our investigation employs various scenarios, using Imagenet
2012 dataset as well as fooling and open-set images. The findings support LC
hypothesis and show its effectiveness on OSR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Advancing Self-supervised Monocular Depth Learning with Sparse LiDAR. (arXiv:2109.09628v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09628">
<div class="article-summary-box-inner">
<span><p>Self-supervised monocular depth prediction provides a cost-effective solution
to obtain the 3D location of each pixel. However, the existing approaches
usually lead to unsatisfactory accuracy, which is critical for autonomous
robots. In this paper, we propose a novel two-stage network to advance the
self-supervised monocular dense depth learning by leveraging low-cost sparse
(e.g. 4-beam) LiDAR. Unlike the existing methods that use sparse LiDAR mainly
in a manner of time-consuming iterative post-processing, our model fuses
monocular image features and sparse LiDAR features to predict initial depth
maps. Then, an efficient feed-forward refine network is further designed to
correct the errors in these initial depth maps in pseudo-3D space with
real-time performance. Extensive experiments show that our proposed model
significantly outperforms all the state-of-the-art self-supervised methods, as
well as the sparse-LiDAR-based methods on both self-supervised monocular depth
prediction and completion tasks. With the accurate dense depth prediction, our
model outperforms the state-of-the-art sparse-LiDAR-based method
(Pseudo-LiDAR++) by more than 68% for the downstream task monocular 3D object
detection on the KITTI Leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Context-Aware Network for Abdominal Multi-organ Segmentation. (arXiv:2109.10601v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10601">
<div class="article-summary-box-inner">
<span><p>The contextual information, presented in abdominal CT scan, is relative
consistent. In order to make full use of the overall 3D context, we develop a
whole-volume-based coarse-to-fine framework for efficient and effective
abdominal multi-organ segmentation. We propose a new efficientSegNet network,
which is composed of basic encoder, slim decoder and efficient context block.
For the decoder module, anisotropic convolution with a k*k*1 intra-slice
convolution and a 1*1*k inter-slice convolution, is designed to reduce the
computation burden. For the context block, we propose strip pooling module to
capture anisotropic and long-range contextual information, which exists in
abdominal scene. Quantitative evaluation on the FLARE2021 validation cases,
this method achieves the average dice similarity coefficient (DSC) of 0.895 and
average normalized surface distance (NSD) of 0.775. This method won the 1st
place on the 2021-MICCAI-FLARE challenge. Codes and models are available at
https://github.com/Shanghai-Aitrox-Technology/EfficientSegmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Network Pruning Through Constrained Reinforcement Learning. (arXiv:2110.08558v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08558">
<div class="article-summary-box-inner">
<span><p>Network pruning reduces the size of neural networks by removing (pruning)
neurons such that the performance drop is minimal. Traditional pruning
approaches focus on designing metrics to quantify the usefulness of a neuron
which is often quite tedious and sub-optimal. More recent approaches have
instead focused on training auxiliary networks to automatically learn how
useful each neuron is however, they often do not take computational limitations
into account. In this work, we propose a general methodology for pruning neural
networks. Our proposed methodology can prune neural networks to respect
pre-defined computational budgets on arbitrary, possibly non-differentiable,
functions. Furthermore, we only assume the ability to be able to evaluate these
functions for different inputs, and hence they do not need to be fully
specified beforehand. We achieve this by proposing a novel pruning strategy via
constrained reinforcement learning algorithms. We prove the effectiveness of
our approach via comparison with state-of-the-art methods on standard image
classification datasets. Specifically, we reduce 83-92.90 of total parameters
on various variants of VGG while achieving comparable or better performance
than that of original networks. We also achieved 75.09 reduction in parameters
on ResNet18 without incurring any loss in accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransFusion: Cross-view Fusion with Transformer for 3D Human Pose Estimation. (arXiv:2110.09554v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09554">
<div class="article-summary-box-inner">
<span><p>Estimating the 2D human poses in each view is typically the first step in
calibrated multi-view 3D pose estimation. But the performance of 2D pose
detectors suffers from challenging situations such as occlusions and oblique
viewing angles. To address these challenges, previous works derive
point-to-point correspondences between different views from epipolar geometry
and utilize the correspondences to merge prediction heatmaps or feature
representations. Instead of post-prediction merge/calibration, here we
introduce a transformer framework for multi-view 3D pose estimation, aiming at
directly improving individual 2D predictors by integrating information from
different views. Inspired by previous multi-modal transformers, we design a
unified transformer architecture, named TransFusion, to fuse cues from both
current views and neighboring views. Moreover, we propose the concept of
epipolar field to encode 3D positional information into the transformer model.
The 3D position encoding guided by the epipolar field provides an efficient way
of encoding correspondences between pixels of different views. Experiments on
Human 3.6M and Ski-Pose show that our method is more efficient and has
consistent improvements compared to other fusion methods. Specifically, we
achieve 25.8 mm MPJPE on Human 3.6M with only 5M parameters on 256 x 256
resolution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SOFT: Softmax-free Transformer with Linear Complexity. (arXiv:2110.11945v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11945">
<div class="article-summary-box-inner">
<span><p>Vision transformers (ViTs) have pushed the state-of-the-art for various
visual recognition tasks by patch-wise image tokenization followed by
self-attention. However, the employment of self-attention modules results in a
quadratic complexity in both computation and memory usage. Various attempts on
approximating the self-attention computation with linear complexity have been
made in Natural Language Processing. However, an in-depth analysis in this work
shows that they are either theoretically flawed or empirically ineffective for
visual recognition. We further identify that their limitations are rooted in
keeping the softmax self-attention during approximations. Specifically,
conventional self-attention is computed by normalizing the scaled dot-product
between token feature vectors. Keeping this softmax operation challenges any
subsequent linearization efforts. Based on this insight, for the first time, a
softmax-free transformer or SOFT is proposed. To remove softmax in
self-attention, Gaussian kernel function is used to replace the dot-product
similarity without further normalization. This enables a full self-attention
matrix to be approximated via a low-rank matrix decomposition. The robustness
of the approximation is achieved by calculating its Moore-Penrose inverse using
a Newton-Raphson method. Extensive experiments on ImageNet show that our SOFT
significantly improves the computational efficiency of existing ViT variants.
Crucially, with a linear complexity, much longer token sequences are permitted
in SOFT, resulting in superior trade-off between accuracy and complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MisConv: Convolutional Neural Networks for Missing Data. (arXiv:2110.14010v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14010">
<div class="article-summary-box-inner">
<span><p>Processing of missing data by modern neural networks, such as CNNs, remains a
fundamental, yet unsolved challenge, which naturally arises in many practical
applications, like image inpainting or autonomous vehicles and robots. While
imputation-based techniques are still one of the most popular solutions, they
frequently introduce unreliable information to the data and do not take into
account the uncertainty of estimation, which may be destructive for a machine
learning model. In this paper, we present MisConv, a general mechanism, for
adapting various CNN architectures to process incomplete images. By modeling
the distribution of missing values by the Mixture of Factor Analyzers, we cover
the spectrum of possible replacements and find an analytical formula for the
expected value of convolution operator applied to the incomplete image. The
whole framework is realized by matrix operations, which makes MisConv extremely
efficient in practice. Experiments performed on various image processing tasks
demonstrate that MisConv achieves superior or comparable performance to the
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hand gesture detection in tests performed by older adults. (arXiv:2110.14461v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14461">
<div class="article-summary-box-inner">
<span><p>Our team are developing a new online test that analyses hand movement
features associated with ageing that can be completed remotely from the
research centre. To obtain hand movement features, participants will be asked
to perform a variety of hand gestures using their own computer cameras.
However, it is challenging to collect high quality hand movement video data,
especially for older participants, many of whom have no IT background. During
the data collection process, one of the key steps is to detect whether the
participants are following the test instructions correctly and also to detect
similar gestures from different devices. Furthermore, we need this process to
be automated and accurate as we expect many thousands of participants to
complete the test. We have implemented a hand gesture detector to detect the
gestures in the hand movement tests and our detection mAP is 0.782 which is
better than the state-of-the-art. In this research, we have processed 20,000
images collected from hand movement tests and labelled 6,450 images to detect
different hand gestures in the hand movement tests. This paper has the
following three contributions. Firstly, we compared and analysed the
performance of different network structures for hand gesture detection.
Secondly, we have made many attempts to improve the accuracy of the model and
have succeeded in improving the classification accuracy for similar gestures by
implementing attention layers. Thirdly, we have created two datasets and
included 20 percent of blurred images in the dataset to investigate how
different network structures were impacted by noisy data, our experiments have
also shown our network has better performance on the noisy dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Arbitrary Scale Super-Resolution Approach for 3-Dimensional Magnetic Resonance Image using Implicit Neural Representation. (arXiv:2110.14476v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14476">
<div class="article-summary-box-inner">
<span><p>High Resolution (HR) medical images provide rich anatomical structure details
to facilitate early and accurate diagnosis. In MRI, restricted by hardware
capacity, scan time, and patient cooperation ability, isotropic 3D HR image
acquisition typically requests long scan time and, results in small spatial
coverage and low SNR. Recent studies showed that, with deep convolutional
neural networks, isotropic HR MR images could be recovered from low-resolution
(LR) input via single image super-resolution (SISR) algorithms. However, most
existing SISR methods tend to approach a scale-specific projection between LR
and HR images, thus these methods can only deal with a fixed up-sampling rate.
For achieving different up-sampling rates, multiple SR networks have to be
built up respectively, which is very time-consuming and resource-intensive. In
this paper, we propose ArSSR, an Arbitrary Scale Super-Resolution approach for
recovering 3D HR MR images. In the ArSSR model, the reconstruction of HR images
with different up-scaling rates is defined as learning a continuous implicit
voxel function from the observed LR images. Then the SR task is converted to
represent the implicit voxel function via deep neural networks from a set of
paired HR-LR training examples. The ArSSR model consists of an encoder network
and a decoder network. Specifically, the convolutional encoder network is to
extract feature maps from the LR input images and the fully-connected decoder
network is to approximate the implicit voxel function. Due to the continuity of
the learned function, a single ArSSR model can achieve arbitrary up-sampling
rate reconstruction of HR images from any input LR image after training.
Experimental results on three datasets show that the ArSSR model can achieve
state-of-the-art SR performance for 3D HR MR image reconstruction while using a
single trained model to achieve arbitrary up-sampling scales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">E-ffective: A Visual Analytic System for Exploring the Emotion and Effectiveness of Inspirational Speeches. (arXiv:2110.14908v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.14908">
<div class="article-summary-box-inner">
<span><p>What makes speeches effective has long been a subject for debate, and until
today there is broad controversy among public speaking experts about what
factors make a speech effective as well as the roles of these factors in
speeches. Moreover, there is a lack of quantitative analysis methods to help
understand effective speaking strategies. In this paper, we propose E-ffective,
a visual analytic system allowing speaking experts and novices to analyze both
the role of speech factors and their contribution in effective speeches. From
interviews with domain experts and investigating existing literature, we
identified important factors to consider in inspirational speeches. We obtained
the generated factors from multi-modal data that were then related to
effectiveness data. Our system supports rapid understanding of critical factors
in inspirational speeches, including the influence of emotions by means of
novel visualization methods and interaction. Two novel visualizations include
E-spiral (that shows the emotional shifts in speeches in a visually compact
way) and E-script (that connects speech content with key speech delivery
information). In our evaluation we studied the influence of our system on
experts' domain knowledge about speech factors. We further studied the
usability of the system by speaking novices and experts on assisting analysis
of inspirational speech effectiveness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning Disentangled Group Representation as Feature. (arXiv:2110.15255v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15255">
<div class="article-summary-box-inner">
<span><p>A good visual representation is an inference map from observations (images)
to features (vectors) that faithfully reflects the hidden modularized
generative factors (semantics). In this paper, we formulate the notion of
"good" representation from a group-theoretic view using Higgins' definition of
disentangled representation, and show that existing Self-Supervised Learning
(SSL) only disentangles simple augmentation features such as rotation and
colorization, thus unable to modularize the remaining semantics. To break the
limitation, we propose an iterative SSL algorithm: Iterative Partition-based
Invariant Risk Minimization (IP-IRM), which successfully grounds the abstract
semantics and the group acting on them into concrete contrastive learning. At
each iteration, IP-IRM first partitions the training samples into two subsets
that correspond to an entangled group element. Then, it minimizes a
subset-invariant contrastive loss, where the invariance guarantees to
disentangle the group element. We prove that IP-IRM converges to a fully
disentangled representation and show its effectiveness on various benchmarks.
Codes are available at https://github.com/Wangt-CN/IP-IRM.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-11-01 23:02:56.343591105 UTC">2021-11-01 23:02:56 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.6</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>