<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-14T01:30:00Z">10-14</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">An Introduction to Automatic Differentiation forMachine Learning. (arXiv:2110.06209v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06209">
<div class="article-summary-box-inner">
<span><p>Machine learning and neural network models in particular have been improving
the state of the art performance on many artificial intelligence related tasks.
Neural network models are typically implemented using frameworks that perform
gradient based optimization methods to fit a model to a dataset. These
frameworks use a technique of calculating derivatives called automatic
differentiation (AD) which removes the burden of performing derivative
calculations from the model designer. In this report we describe AD, its
motivations, and different implementation approaches. We briefly describe
dataflow programming as it relates to AD. Lastly, we present example programs
that are implemented with Tensorflow and PyTorch, which are two commonly used
AD frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Effect of Natural Language Explanations on Out-of-Distribution Generalization in Few-shot NLI. (arXiv:2110.06223v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06223">
<div class="article-summary-box-inner">
<span><p>Although neural models have shown strong performance in datasets such as
SNLI, they lack the ability to generalize out-of-distribution (OOD). In this
work, we formulate a few-shot learning setup and examine the effects of natural
language explanations on OOD generalization. We leverage the templates in the
HANS dataset and construct templated natural language explanations for each
template. Although generated explanations show competitive BLEU scores against
groundtruth explanations, they fail to improve prediction performance. We
further show that generated explanations often hallucinate information and miss
key elements that indicate the label.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Summarization using Restricted Self-Attention. (arXiv:2110.06263v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06263">
<div class="article-summary-box-inner">
<span><p>Speech summarization is typically performed by using a cascade of speech
recognition and text summarization models. End-to-end modeling of speech
summarization models is challenging due to memory and compute constraints
arising from long input audio sequences. Recent work in document summarization
has inspired methods to reduce the complexity of self-attentions, which enables
transformer models to handle long sequences. In this work, we introduce a
single model optimized end-to-end for speech summarization. We apply the
restricted self-attention technique from text-based models to speech models to
address the memory and compute constraints. We demonstrate that the proposed
model learns to directly summarize speech for the How-2 corpus of instructional
videos. The proposed end-to-end model outperforms the previously proposed
cascaded model by 3 points absolute on ROUGE. Further, we consider the spoken
language understanding task of predicting concepts from speech inputs and show
that the proposed end-to-end model outperforms the cascade model by 4 points
absolute F-1.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sm{\aa}prat: DialoGPT for Natural Language Generation of Swedish Dialogue by Transfer Learning. (arXiv:2110.06273v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06273">
<div class="article-summary-box-inner">
<span><p>Building open-domain conversational systems (or chatbots) that produce
convincing responses is a recognized challenge. Recent state-of-the-art (SoTA)
transformer-based models for the generation of natural language dialogue have
demonstrated impressive performance in simulating human-like, single-turn
conversations in English. This work investigates, by an empirical study, the
potential for transfer learning of such models to Swedish language. DialoGPT,
an English language pre-trained model, is adapted by training on three
different Swedish language conversational datasets obtained from publicly
available sources. Perplexity score (an automated intrinsic language model
metric) and surveys by human evaluation were used to assess the performances of
the fine-tuned models, with results that indicate that the capacity for
transfer learning can be exploited with considerable success. Human evaluators
asked to score the simulated dialogue judged over 57% of the chatbot responses
to be human-like for the model trained on the largest (Swedish) dataset. We
provide the demos and model checkpoints of our English and Swedish chatbots on
the HuggingFace platform for public use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LiST: Lite Self-training Makes Efficient Few-shot Learners. (arXiv:2110.06274v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06274">
<div class="article-summary-box-inner">
<span><p>We present a new method LiST for efficient fine-tuning of large pre-trained
language models (PLMs) in few-shot learning settings. LiST significantly
improves over recent methods that adopt prompt fine-tuning using two key
techniques. The first one is the use of self-training to leverage large amounts
of unlabeled data for prompt-tuning to significantly boost the model
performance in few-shot settings. We use self-training in conjunction with
meta-learning for re-weighting noisy pseudo-prompt labels. However, traditional
self-training is expensive as it requires updating all the model parameters
repetitively. Therefore, we use a second technique for light-weight fine-tuning
where we introduce a small number of task-specific adapter parameters that are
fine-tuned during self-training while keeping the PLM encoder frozen. This also
significantly reduces the overall model footprint across several tasks that can
now share a common PLM encoder as backbone for inference. Combining the above
techniques, LiST not only improves the model performance for few-shot learning
on target domains but also reduces the model memory footprint. We present a
comprehensive study on six NLU tasks to validate the effectiveness of LiST. The
results show that LiST improves by 35% over classic fine-tuning methods and 6%
over prompt-tuning with 96% reduction in number of trainable parameters when
fine-tuned with no more than 30 labeled examples from each target domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">S3PRL-VC: Open-source Voice Conversion Framework with Self-supervised Speech Representations. (arXiv:2110.06280v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06280">
<div class="article-summary-box-inner">
<span><p>This paper introduces S3PRL-VC, an open-source voice conversion (VC)
framework based on the S3PRL toolkit. In the context of recognition-synthesis
VC, self-supervised speech representation (S3R) is valuable in its potential to
replace the expensive supervised representation adopted by state-of-the-art VC
systems. Moreover, we claim that VC is a good probing task for S3R analysis. In
this work, we provide a series of in-depth analyses by benchmarking on the two
tasks in VCC2020, namely intra-/cross-lingual any-to-one (A2O) VC, as well as
an any-to-any (A2A) setting. We also provide comparisons between not only
different S3Rs but also top systems in VCC2020 with supervised representations.
Systematic objective and subjective evaluation were conducted, and we show that
S3R is comparable with VCC2020 top systems in the A2O setting in terms of
similarity, and achieves state-of-the-art in S3R-based A2A VC. We believe the
extensive analysis, as well as the toolkit itself, contribute to not only the
S3R community but also the VC community. The codebase is now open-sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decision-Theoretic Question Generation for Situated Reference Resolution: An Empirical Study and Computational Model. (arXiv:2110.06288v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06288">
<div class="article-summary-box-inner">
<span><p>Dialogue agents that interact with humans in situated environments need to
manage referential ambiguity across multiple modalities and ask for help as
needed. However, it is not clear what kinds of questions such agents should ask
nor how the answers to such questions can be used to resolve ambiguity. To
address this, we analyzed dialogue data from an interactive study in which
participants controlled a virtual robot tasked with organizing a set of tools
while engaging in dialogue with a live, remote experimenter. We discovered a
number of novel results, including the distribution of question types used to
resolve ambiguity and the influence of dialogue-level factors on the reference
resolution process. Based on these empirical findings we: (1) developed a
computational model for clarification requests using a decision network with an
entropy-based utility assignment method that operates across modalities, (2)
evaluated the model, showing that it outperforms a slot-filling baseline in
environments of varying ambiguity, and (3) interpreted the results to offer
insight into the ways that agents can ask questions to facilitate situated
reference resolution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-grained style control in Transformer-based Text-to-speech Synthesis. (arXiv:2110.06306v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06306">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a novel architecture to realize fine-grained style
control on the transformer-based text-to-speech synthesis (TransformerTTS).
Specifically, we model the speaking style by extracting a time sequence of
local style tokens (LST) from the reference speech. The existing content
encoder in TransformerTTS is then replaced by our designed cross-attention
blocks for fusion and alignment between content and style. As the fusion is
performed along with the skip connection, our cross-attention block provides a
good inductive bias to gradually infuse the phoneme representation with a given
style. Additionally, we prevent the style embedding from encoding linguistic
content by randomly truncating LST during training and using wav2vec 2.0
features. Experiments show that with fine-grained style control, our system
performs better in terms of naturalness, intelligibility, and style
transferability. Our code and samples are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Wav2vec 2.0 fine-tuning for improved speech emotion recognition. (arXiv:2110.06309v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06309">
<div class="article-summary-box-inner">
<span><p>While wav2vec 2.0 has been proposed for speech recognition (ASR), it can also
be used for speech emotion recognition (SER); its performance can be
significantly improved using different fine-tuning strategies. Two baseline
methods, vanilla fine-tuning (V-FT) and task adaptive pretraining (TAPT) are
first presented. We show that V-FT is able to outperform state-of-the-art
models on the IEMOCAP dataset. TAPT, an existing NLP fine-tuning strategy,
further improves the performance on SER. We also introduce a novel fine-tuning
method termed P-TAPT, which modifies the TAPT objective to learn contextualized
emotion representations. Experiments show that P-TAPT performs better than TAPT
especially under low-resource settings. Compared to prior works in this
literature, our top-line system achieved a 7.4% absolute improvement on
unweighted accuracy (UA) over the state-of-the-art performance on IEMOCAP. Our
code is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Compact Metrics for MT. (arXiv:2110.06341v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06341">
<div class="article-summary-box-inner">
<span><p>Recent developments in machine translation and multilingual text generation
have led researchers to adopt trained metrics such as COMET or BLEURT, which
treat evaluation as a regression problem and use representations from
multilingual pre-trained models such as XLM-RoBERTa or mBERT. Yet studies on
related tasks suggest that these models are most efficient when they are large,
which is costly and impractical for evaluation. We investigate the trade-off
between multilinguality and model capacity with RemBERT, a state-of-the-art
multilingual language model, using data from the WMT Metrics Shared Task. We
present a series of experiments which show that model size is indeed a
bottleneck for cross-lingual transfer, then demonstrate how distillation can
help addressing this bottleneck, by leveraging synthetic data generation and
transferring knowledge from one teacher to multiple students trained on related
languages. Our method yields up to 10.5% improvement over vanilla fine-tuning
and reaches 92.6% of RemBERT's performance using only a third of its
parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tell Me How to Survey: Literature Review Made Simple with Automatic Reading Path Generation. (arXiv:2110.06354v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06354">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the dramatic growth of paper volumes with plenty
of new research papers published every day, especially in the area of computer
science. How to glean papers worth reading from the massive literature to do a
quick survey or keep up with the latest advancement about a specific research
topic has become a challenging task. Existing academic search engines such as
Google Scholar return relevant papers by individually calculating the relevance
between each paper and query. However, such systems usually omit the
prerequisite chains of a research topic and cannot form a meaningful reading
path. In this paper, we introduce a new task named Reading Path Generation
(RPG) which aims at automatically producing a path of papers to read for a
given query. To serve as a research benchmark, we further propose SurveyBank, a
dataset consisting of large quantities of survey papers in the field of
computer science as well as their citation relationships. Each survey paper
contains key phrases extracted from its title and multi-level reading lists
inferred from its references. Furthermore, we propose a
graph-optimization-based approach for reading path generation which takes the
relationship between papers into account. Extensive evaluations demonstrate
that our approach outperforms other baselines. A Real-time Reading Path
Generation System (RePaGer) has been also implemented with our designed model.
To the best of our knowledge, we are the first to target this important
research problem. Our source code of RePaGer system and SurveyBank dataset can
be found on here.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Time Masking for Temporal Language Models. (arXiv:2110.06366v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06366">
<div class="article-summary-box-inner">
<span><p>Our world is constantly evolving, and so is the content on the web.
Consequently, our languages, often said to mirror the world, are dynamic in
nature. However, most current contextual language models are static and cannot
adapt to changes over time. In this work, we propose a temporal contextual
language model called TempoBERT, which uses time as an additional context of
texts. Our technique is based on modifying texts with temporal information and
performing time masking - specific masking for the supplementary time
information. We leverage our approach for the tasks of semantic change
detection and sentence time prediction, experimenting on diverse datasets in
terms of time, size, genre, and language. Our extensive evaluation shows that
both tasks benefit from exploiting time masking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ALL Dolphins Are Intelligent and SOME Are Friendly: Probing BERT for Nouns' Semantic Properties and their Prototypicality. (arXiv:2110.06376v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06376">
<div class="article-summary-box-inner">
<span><p>Large scale language models encode rich commonsense knowledge acquired
through exposure to massive data during pre-training, but their understanding
of entities and their semantic properties is unclear. We probe BERT (Devlin et
al., 2019) for the properties of English nouns as expressed by adjectives that
do not restrict the reference scope of the noun they modify (as in "red car"),
but instead emphasise some inherent aspect ("red strawberry"). We base our
study on psycholinguistics datasets that capture the association strength
between nouns and their semantic features. We probe BERT using cloze tasks and
in a classification setting, and show that the model has marginal knowledge of
these features and their prevalence as expressed in these datasets. We discuss
factors that make evaluation challenging and impede drawing general conclusions
about the models' knowledge of noun properties. Finally, we show that when
tested in a fine-tuning setting addressing entailment, BERT successfully
leverages the information needed for reasoning about the meaning of
adjective-noun constructions outperforming previous methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoNLU: Detecting, root-causing, and fixing NLU model errors. (arXiv:2110.06384v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06384">
<div class="article-summary-box-inner">
<span><p>Improving the quality of Natural Language Understanding (NLU) models, and
more specifically, task-oriented semantic parsing models, in production is a
cumbersome task. In this work, we present a system called AutoNLU, which we
designed to scale the NLU quality improvement process. It adds automation to
three key steps: detection, attribution, and correction of model errors, i.e.,
bugs. We detected four times more failed tasks than with random sampling,
finding that even a simple active learning sampling method on an uncalibrated
model is surprisingly effective for this purpose. The AutoNLU tool empowered
linguists to fix ten times more semantic parsing bugs than with prior manual
processes, auto-correcting 65% of all identified bugs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HETFORMER: Heterogeneous Transformer with Sparse Attention for Long-Text Extractive Summarization. (arXiv:2110.06388v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06388">
<div class="article-summary-box-inner">
<span><p>To capture the semantic graph structure from raw text, most existing
summarization approaches are built on GNNs with a pre-trained model. However,
these methods suffer from cumbersome procedures and inefficient computations
for long-text documents. To mitigate these issues, this paper proposes
HETFORMER, a Transformer-based pre-trained model with multi-granularity sparse
attentions for long-text extractive summarization. Specifically, we model
different types of semantic nodes in raw text as a potential heterogeneous
graph and directly learn heterogeneous relationships (edges) among nodes by
Transformer. Extensive experiments on both single- and multi-document
summarization tasks show that HETFORMER achieves state-of-the-art performance
in Rouge F1 while using less memory and fewer parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-guided Generative Models for Extractive Question Answering. (arXiv:2110.06393v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06393">
<div class="article-summary-box-inner">
<span><p>We propose a novel method for applying Transformer models to extractive
question answering (QA) tasks. Recently, pretrained generative
sequence-to-sequence (seq2seq) models have achieved great success in question
answering. Contributing to the success of these models are internal attention
mechanisms such as cross-attention. We propose a simple strategy to obtain an
extractive answer span from the generative model by leveraging the decoder
cross-attention patterns. Viewing cross-attention as an architectural prior, we
apply joint training to further improve QA performance. Empirical results show
that on open-domain question answering datasets like NaturalQuestions and
TriviaQA, our method approaches state-of-the-art performance on both generative
and extractive inference, all while using much fewer parameters. Furthermore,
this strategy allows us to perform hallucination-free inference while
conferring significant improvements to the model's ability to rerank relevant
passages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Overview of Ontologies and Tool Support for COVID-19 Analytics. (arXiv:2110.06397v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06397">
<div class="article-summary-box-inner">
<span><p>The outbreak of the SARS-CoV-2 pandemic of the new COVID-19 disease (COVID-19
for short) demands empowering existing medical, economic, and social emergency
backend systems with data analytics capabilities. An impediment in taking
advantages of data analytics in these systems is the lack of a unified
framework or reference model. Ontologies are highlighted as a promising
solution to bridge this gap by providing a formal representation of COVID-19
concepts such as symptoms, infections rate, contact tracing, and drug
modelling. Ontology-based solutions enable the integration of diverse data
sources that leads to a better understanding of pandemic data, management of
smart lockdowns by identifying pandemic hotspots, and knowledge-driven
inference, reasoning, and recommendations to tackle surrounding issues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Federated Natural Language Generation for Personalized Dialogue System. (arXiv:2110.06419v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06419">
<div class="article-summary-box-inner">
<span><p>Neural conversational models have long suffered from the problem of
inconsistency and lacking coherent personality. To address the issue,
persona-based models capturing individual characteristics have been proposed,
but they still face the dilemma of model adaption and data privacy. To break
this dilemma, we propose a novel Federated Natural Language Generation (FedNLG)
framework, which learns personalized representations from various dataset on
distributed devices, and thus implements the personalized dialogue system
efficiently and safely. FedNLG first pre-trains parameters of standard neural
conversational model over a large dialogue corpus, and then fine-tune the model
parameters and persona embeddings on specific datasets, in a federated manner.
Thus, the model could simultaneously learn the persona embeddings in local
clients and learn shared model parameters by federated aggregation, which
achieves accuracyprivacy balance. By conducting extensive experiments, we
demonstrate the effectiveness of our model by pre-training model over Cornell
Movie-Dialogs Corpus and fine-tuning the model over two TV series dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Graph-based Sentence Ordering with Iteratively Predicted Pairwise Orderings. (arXiv:2110.06446v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06446">
<div class="article-summary-box-inner">
<span><p>Dominant sentence ordering models can be classified into pairwise ordering
models and set-to-sequence models. However, there is little attempt to combine
these two types of models, which inituitively possess complementary advantages.
In this paper, we propose a novel sentence ordering framework which introduces
two classifiers to make better use of pairwise orderings for graph-based
sentence ordering. Specially, given an initial sentence-entity graph, we first
introduce a graph-based classifier to predict pairwise orderings between linked
sentences. Then, in an iterative manner, based on the graph updated by
previously predicted high-confident pairwise orderings, another classifier is
used to predict the remaining uncertain pairwise orderings. At last, we adapt a
GRN-based sentence ordering model on the basis of final graph. Experiments on
five commonly-used datasets demonstrate the effectiveness and generality of our
model. Particularly, when equipped with BERT and FHDecoder, our model achieves
state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fake News Detection in Spanish Using Deep Learning Techniques. (arXiv:2110.06461v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06461">
<div class="article-summary-box-inner">
<span><p>This paper addresses the problem of fake news detection in Spanish using
Machine Learning techniques. It is fundamentally the same problem tackled for
the English language; however, there is not a significant amount of publicly
available and adequately labeled fake news in Spanish to effectively train a
Machine Learning model, similarly to those proposed for the English language.
Therefore, this work explores different training strategies and architectures
to establish a baseline for further research in this area. Four datasets were
used, two in English and two in Spanish, and four experimental schemes were
tested, including a baseline with classical Machine Learning models, trained
and validated using a small dataset in Spanish. The remaining schemes include
state-of-the-art Deep Learning models trained (or fine-tuned) and validated in
English, trained and validated in Spanish, and fitted in English and validated
with automatic translated Spanish sentences. The Deep Learning architectures
were built on top of different pre-trained Word Embedding representations,
including GloVe, ELMo, BERT, and BETO (a BERT version trained on a large corpus
in Spanish). According to the results, the best strategy was a combination of a
pre-trained BETO model and a Recurrent Neural Network based on LSTM layers,
yielding an accuracy of up to 80%; nonetheless, a baseline model using a Random
Forest estimator obtained similar outcomes. Additionally, the translation
strategy did not yield acceptable results because of the propagation error;
there was also observed a significant difference in models performance when
trained in English or Spanish, mainly attributable to the number of samples
available for each language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ActiveEA: Active Learning for Neural Entity Alignment. (arXiv:2110.06474v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06474">
<div class="article-summary-box-inner">
<span><p>Entity Alignment (EA) aims to match equivalent entities across different
Knowledge Graphs (KGs) and is an essential step of KG fusion. Current
mainstream methods -- neural EA models -- rely on training with seed alignment,
i.e., a set of pre-aligned entity pairs which are very costly to annotate. In
this paper, we devise a novel Active Learning (AL) framework for neural EA,
aiming to create highly informative seed alignment to obtain more effective EA
models with less annotation cost. Our framework tackles two main challenges
encountered when applying AL to EA: (1) How to exploit dependencies between
entities within the AL strategy. Most AL strategies assume that the data
instances to sample are independent and identically distributed. However,
entities in KGs are related. To address this challenge, we propose a
structure-aware uncertainty sampling strategy that can measure the uncertainty
of each entity as well as its impact on its neighbour entities in the KG. (2)
How to recognise entities that appear in one KG but not in the other KG (i.e.,
bachelors). Identifying bachelors would likely save annotation budget. To
address this challenge, we devise a bachelor recognizer paying attention to
alleviate the effect of sampling bias. Empirical results show that our proposed
AL strategy can significantly improve sampling quality with good generality
across different datasets, EA models and amount of bachelors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding of Emotion Perception from Art. (arXiv:2110.06486v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06486">
<div class="article-summary-box-inner">
<span><p>Computational modeling of the emotions evoked by art in humans is a
challenging problem because of the subjective and nuanced nature of art and
affective signals. In this paper, we consider the above-mentioned problem of
understanding emotions evoked in viewers by artwork using both text and visual
modalities. Specifically, we analyze images and the accompanying text captions
from the viewers expressing emotions as a multimodal classification task. Our
results show that single-stream multimodal transformer-based models like MMBT
and VisualBERT perform better compared to both image-only models and
dual-stream multimodal models having separate pathways for text and image
modalities. We also observe improvements in performance for extreme positive
and negative emotion classes, when a single-stream model like MMBT is compared
with a text-only transformer model like BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dict-BERT: Enhancing Language Model Pre-training with Dictionary. (arXiv:2110.06490v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06490">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) aim to learn universal language
representations by conducting self-supervised training tasks on large-scale
corpora. Since PLMs capture word semantics in different contexts, the quality
of word representations highly depends on word frequency, which usually follows
a heavy-tailed distributions in the pre-training corpus. Therefore, the
embeddings of rare words on the tail are usually poorly optimized. In this
work, we focus on enhancing language model pre-training by leveraging
definitions of the rare words in dictionaries (e.g., Wiktionary). To
incorporate a rare word definition as a part of input, we fetch its definition
from the dictionary and append it to the end of the input text sequence. In
addition to training with the masked language modeling objective, we propose
two novel self-supervised pre-training tasks on word and sentence-level
alignment between input text sequence and rare word definitions to enhance
language modeling representation with dictionary. We evaluate the proposed
Dict-BERT model on the language understanding benchmark GLUE and eight
specialized domain benchmark datasets. Extensive experiments demonstrate that
Dict-BERT can significantly improve the understanding of rare words and boost
model performance on various NLP downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual COVID-19 Fake News Detection. (arXiv:2110.06495v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06495">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic poses a great threat to global public health.
Meanwhile, there is massive misinformation associated with the pandemic which
advocates unfounded or unscientific claims. Even major social media and news
outlets have made an extra effort in debunking COVID-19 misinformation, most of
the fact-checking information is in English, whereas some unmoderated COVID-19
misinformation is still circulating in other languages, threatening the health
of less-informed people in immigrant communities and developing countries. In
this paper, we make the first attempt to detect COVID-19 misinformation in a
low-resource language (Chinese) only using the fact-checked news in a
high-resource language (English). We start by curating a Chinese real&amp;fake news
dataset according to existing fact-checking information. Then, we propose a
deep learning framework named CrossFake to jointly encode the cross-lingual
news body texts and capture the news content as much as possible. Empirical
results on our dataset demonstrate the effectiveness of CorssFake under the
cross-lingual setting and it also outperforms several monolingual and
cross-lingual fake news detectors. The dataset is available at
https://github.com/YingtongDou/CrossFake.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentially Private Fine-tuning of Language Models. (arXiv:2110.06500v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06500">
<div class="article-summary-box-inner">
<span><p>We give simpler, sparser, and faster algorithms for differentially private
fine-tuning of large-scale pre-trained language models, which achieve the
state-of-the-art privacy versus utility tradeoffs on many standard NLP tasks.
We propose a meta-framework for this problem, inspired by the recent success of
highly parameter-efficient methods for fine-tuning. Our experiments show that
differentially private adaptations of these approaches outperform previous
private algorithms in three important dimensions: utility, privacy, and the
computational and memory cost of private training. On many commonly studied
datasets, the utility of private models approaches that of non-private models.
For example, on the MNLI dataset we achieve an accuracy of $87.8\%$ using
RoBERTa-Large and $83.5\%$ using RoBERTa-Base with a privacy budget of
$\epsilon = 6.7$. In comparison, absent privacy constraints, RoBERTa-Large
achieves an accuracy of $90.2\%$. Our findings are similar for natural language
generation tasks. Privately fine-tuning with DART, GPT-2-Small, GPT-2-Medium,
GPT-2-Large, and GPT-2-XL achieve BLEU scores of 38.5, 42.0, 43.1, and 43.8
respectively (privacy budget of $\epsilon = 6.8,\delta=$ 1e-5) whereas the
non-private baseline is $48.1$. All our experiments suggest that larger models
are better suited for private fine-tuning: while they are well known to achieve
superior accuracy non-privately, we find that they also better maintain their
accuracy when privacy is introduced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient domain adaptation of language models in ASR systems using Prompt-tuning. (arXiv:2110.06502v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06502">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Recognition (ASR) systems have found their use in numerous
industrial applications in very diverse domains. Since domain-specific systems
perform better than their generic counterparts on in-domain evaluation, the
need for memory and compute-efficient domain adaptation is obvious.
Particularly, adapting parameter-heavy transformer-based language models used
for rescoring ASR hypothesis is challenging. In this work, we overcome the
problem using prompt-tuning, a methodology that trains a small number of domain
token embedding parameters to prime a transformer-based LM to a particular
domain. With just a handful of extra parameters per domain, we achieve much
better perplexity scores over the baseline of using an unadapted LM. Despite
being parameter-efficient, these improvements are comparable to those of
fully-fine-tuned models with hundreds of millions of parameters. We replicate
our findings in perplexity numbers to Word Error Rate in a domain-specific ASR
system for one such domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perception Point: Identifying Critical Learning Periods in Speech for Bilingual Networks. (arXiv:2110.06507v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06507">
<div class="article-summary-box-inner">
<span><p>Recent studies in speech perception have been closely linked to fields of
cognitive psychology, phonology, and phonetics in linguistics. During
perceptual attunement, a critical and sensitive developmental trajectory has
been examined in bilingual and monolingual infants where they can best
discriminate common phonemes. In this paper, we compare and identify these
cognitive aspects on deep neural-based visual lip-reading models. We conduct
experiments on the two most extensive public visual speech recognition datasets
for English and Mandarin. Through our experimental results, we observe a strong
correlation between these theories in cognitive psychology and our unique
modeling. We inspect how these computational models develop similar phases in
speech perception and acquisitions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Dawn of Quantum Natural Language Processing. (arXiv:2110.06510v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06510">
<div class="article-summary-box-inner">
<span><p>In this paper, we discuss the initial attempts at boosting understanding
human language based on deep-learning models with quantum computing. We
successfully train a quantum-enhanced Long Short-Term Memory network to perform
the parts-of-speech tagging task via numerical simulations. Moreover, a
quantum-enhanced Transformer is proposed to perform the sentiment analysis
based on the existing dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EventBERT: A Pre-Trained Model for Event Correlation Reasoning. (arXiv:2110.06533v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06533">
<div class="article-summary-box-inner">
<span><p>Event correlation reasoning infers whether a natural language paragraph
containing multiple events conforms to human common sense. For example, "Andrew
was very drowsy, so he took a long nap, and now he is very alert" is sound and
reasonable. In contrast, "Andrew was very drowsy, so he stayed up a long time,
now he is very alert" does not comply with human common sense. Such reasoning
capability is essential for many downstream tasks, such as script reasoning,
abductive reasoning, narrative incoherence, story cloze test, etc. However,
conducting event correlation reasoning is challenging due to a lack of large
amounts of diverse event-based knowledge and difficulty in capturing
correlation among multiple events. In this paper, we propose EventBERT, a
pre-trained model to encapsulate eventuality knowledge from unlabeled text.
Specifically, we collect a large volume of training examples by identifying
natural language paragraphs that describe multiple correlated events and
further extracting event spans in an unsupervised manner. We then propose three
novel event- and correlation-based learning objectives to pre-train an event
correlation model on our created training corpus. Empirical results show
EventBERT outperforms strong baselines on four downstream tasks, and achieves
SoTA results on most of them. Besides, it outperforms existing pre-trained
models by a large margin, e.g., 6.5~23%, in zero-shot learning of these tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Well-classified Examples are Underestimated in Classification with Deep Neural Networks. (arXiv:2110.06537v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06537">
<div class="article-summary-box-inner">
<span><p>The conventional wisdom behind learning deep classification models is to
focus on bad-classified examples and ignore well-classified examples that are
far from the decision boundary. For instance, when training with cross-entropy
loss, examples with higher likelihoods (i.e., well-classified examples)
contribute smaller gradients in back-propagation. However, we theoretically
show that this common practice hinders representation learning, energy
optimization, and the growth of margin. To counteract this deficiency, we
propose to reward well-classified examples with additive bonuses to revive
their contribution to learning. This counterexample theoretically addresses
these three issues. We empirically support this claim by directly verify the
theoretical results or through the significant performance improvement with our
counterexample on diverse tasks, including image classification, graph
classification, and machine translation. Furthermore, this paper shows that
because our idea can solve these three issues, we can deal with complex
scenarios, such as imbalanced classification, OOD detection, and applications
under adversarial attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple or Complex? Complexity-Controllable Question Generation with Soft Templates and Deep Mixture of Experts Model. (arXiv:2110.06560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06560">
<div class="article-summary-box-inner">
<span><p>The ability to generate natural-language questions with controlled complexity
levels is highly desirable as it further expands the applicability of question
generation. In this paper, we propose an end-to-end neural
complexity-controllable question generation model, which incorporates a mixture
of experts (MoE) as the selector of soft templates to improve the accuracy of
complexity control and the quality of generated questions. The soft templates
capture question similarity while avoiding the expensive construction of actual
templates. Our method introduces a novel, cross-domain complexity estimator to
assess the complexity of a question, taking into account the passage, the
question, the answer and their interactions. The experimental results on two
benchmark QA datasets demonstrate that our QG model is superior to
state-of-the-art methods in both automatic and manual evaluation. Moreover, our
complexity estimator is significantly more accurate than the baselines in both
in-domain and out-domain settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better Translators. (arXiv:2110.06609v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06609">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have recently been shown to be able to perform
translation without finetuning via prompting. Inspired by these findings, we
study improving the performance of pre-trained language models on translation
tasks, where training neural machine translation models is the current de facto
approach. We present Multi-Stage Prompting, a simple and lightweight approach
for better adapting pre-trained language models to translation tasks. To make
pre-trained language models better translators, we divide the translation
process via pre-trained language models into three separate stages: the
encoding stage, the re-encoding stage, and the decoding stage. During each
stage, we independently apply different continuous prompts for allowing
pre-trained language models better adapting to translation tasks. We conduct
extensive experiments on low-, medium-, and high-resource translation tasks.
Experiments show that our method can significantly improve the translation
performance of pre-trained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Dense Retrieval for Dialogue Response Selection. (arXiv:2110.06612v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06612">
<div class="article-summary-box-inner">
<span><p>Recent research on dialogue response selection has been mainly focused on
selecting a proper response from a pre-defined small set of candidates using
sophisticated neural models. Due to their heavy computational overhead, they
are unable to select responses from a large candidate pool. In this study, we
present a solution to directly select proper responses from a large corpus or
even a nonparallel corpus that only consists of unpaired sentences, using a
dense retrieval model. We extensively test our proposed approach under two
experiment settings: (i) re-rank experiment that aims to rank a small set of
pre-defined candidates; (ii) full-rank experiment where the target is to
directly select proper responses from a full candidate pool that may contain
millions of candidates. For re-rank setting, the superiority is quite
surprising given its simplicity. For full-rank setting, we can emphasize that
we are the first to do such evaluation. Moreover, human evaluation results show
that increasing the size of nonparallel corpus leads to further improvement of
our model performance\footnote{All our source codes, models and other related
resources are publically available at
\url{https://github.com/gmftbyGMFTBY/SimpleReDial-v1}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Maximizing Efficiency of Language Model Pre-training for Learning Representation. (arXiv:2110.06620v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06620">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models in the past years have shown exponential growth
in model parameters and compute time. ELECTRA is a novel approach for improving
the compute efficiency of pre-trained language models (e.g. BERT) based on
masked language modeling (MLM) by addressing the sample inefficiency problem
with the replaced token detection (RTD) task. Our work proposes adaptive early
exit strategy to maximize the efficiency of the pre-training process by
relieving the model's subsequent layers of the need to process latent features
by leveraging earlier layer representations. Moreover, we evaluate an initial
approach to the problem that has not succeeded in maintaining the accuracy of
the model while showing a promising compute efficiency by thoroughly
investigating the necessity of the generator module of ELECTRA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-end translation of human neural activity to speech with a dual-dual generative adversarial network. (arXiv:2110.06634v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06634">
<div class="article-summary-box-inner">
<span><p>In a recent study of auditory evoked potential (AEP) based brain-computer
interface (BCI), it was shown that, with an encoder-decoder framework, it is
possible to translate human neural activity to speech (T-CAS). However, current
encoder-decoder-based methods achieve T-CAS often with a two-step method where
the information is passed between the encoder and decoder with a shared
dimension reduction vector, which may result in a loss of information. A
potential approach to this problem is to design an end-to-end method by using a
dual generative adversarial network (DualGAN) without dimension reduction of
passing information, but it cannot realize one-to-one signal-to-signal
translation (see Fig.1 (a) and (b)). In this paper, we propose an end-to-end
model to translate human neural activity to speech directly, create a new
electroencephalogram (EEG) datasets for participants with good attention by
design a device to detect participants' attention, and introduce a dual-dual
generative adversarial network (Dual-DualGAN) (see Fig. 1 (c) and (d)) to
address an end-to-end translation of human neural activity to speech (ET-CAS)
problem by group labelling EEG signals and speech signals, inserting a
transition domain to realize cross-domain mapping. In the transition domain,
the transition signals are cascaded by the corresponding EEG and speech signals
in a certain proportion, which can build bridges for EEG and speech signals
without corresponding features, and realize one-to-one cross-domain
EEG-to-speech translation. The proposed method can translate word-length and
sentence-length sequences of neural activity to speech. Experimental evaluation
has been conducted to show that the proposed method significantly outperforms
state-of-the-art methods on both words and sentences of auditory stimulus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MDERank: A Masked Document Embedding Rank Approach for Unsupervised Keyphrase Extraction. (arXiv:2110.06651v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06651">
<div class="article-summary-box-inner">
<span><p>Keyphrases are phrases in a document providing a concise summary of core
content, helping readers to understand what the article is talking about in a
minute. However, existing unsupervised works are not robust enough to handle
various types of documents owing to the mismatch of sequence length for
comparison. In this paper, we propose a novel unsupervised keyword extraction
method by leveraging the BERT-based model to select and rank candidate
keyphrases with a MASK strategy. In addition, we further enhance the model,
denoted as Keyphrases Extraction BERT (KPEBERT), via designing a compatible
self-supervised task and conducting a contrast learning. We conducted extensive
experimental evaluation to demonstrate the superiority and robustness of the
proposed method as well as the effectiveness of KPEBERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Truthful AI: Developing and governing AI that does not lie. (arXiv:2110.06674v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06674">
<div class="article-summary-box-inner">
<span><p>In many contexts, lying -- the use of verbal falsehoods to deceive -- is
harmful. While lying has traditionally been a human affair, AI systems that
make sophisticated verbal statements are becoming increasingly prevalent. This
raises the question of how we should limit the harm caused by AI "lies" (i.e.
falsehoods that are actively selected for). Human truthfulness is governed by
social norms and by laws (against defamation, perjury, and fraud). Differences
between AI and humans present an opportunity to have more precise standards of
truthfulness for AI, and to have these standards rise over time. This could
provide significant benefits to public epistemics and the economy, and mitigate
risks of worst-case AI futures.
</p>
<p>Establishing norms or laws of AI truthfulness will require significant work
to: (1) identify clear truthfulness standards; (2) create institutions that can
judge adherence to those standards; and (3) develop AI systems that are
robustly truthful.
</p>
<p>Our initial proposals for these areas include: (1) a standard of avoiding
"negligent falsehoods" (a generalisation of lies that is easier to assess); (2)
institutions to evaluate AI systems before and after real-world deployment; and
(3) explicitly training AI systems to be truthful via curated datasets and
human interaction.
</p>
<p>A concerning possibility is that evaluation mechanisms for eventual
truthfulness standards could be captured by political interests, leading to
harmful censorship and propaganda. Avoiding this might take careful attention.
And since the scale of AI speech acts might grow dramatically over the coming
decades, early truthfulness standards might be particularly important because
of the precedents they set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese. (arXiv:2110.06696v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06696">
<div class="article-summary-box-inner">
<span><p>Although pre-trained models (PLMs) have achieved remarkable improvements in a
wide range of NLP tasks, they are expensive in terms of time and resources.
This calls for the study of training more efficient models with less
computation but still ensures impressive performance. Instead of pursuing a
larger scale, we are committed to developing lightweight yet more powerful
models trained with equal or less computation and friendly to rapid deployment.
This technical report releases our pre-trained model called Mengzi, which
stands for a family of discriminative, generative, domain-specific, and
multimodal pre-trained model variants, capable of a wide range of language and
vision tasks. Compared with public Chinese PLMs, Mengzi is simple but more
powerful. Our lightweight model has achieved new state-of-the-art results on
the widely-used CLUE benchmark with our optimized pre-training and fine-tuning
techniques. Without modifying the model architecture, our model can be easily
employed as an alternative to existing PLMs. Our sources are available at
https://github.com/Langboat/Mengzi.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Systematic Inequalities in Language Technology Performance across the World's Languages. (arXiv:2110.06733v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06733">
<div class="article-summary-box-inner">
<span><p>Natural language processing (NLP) systems have become a central technology in
communication, education, medicine, artificial intelligence, and many other
domains of research and development. While the performance of NLP methods has
grown enormously over the last decade, this progress has been restricted to a
minuscule subset of the world's 6,500 languages. We introduce a framework for
estimating the global utility of language technologies as revealed in a
comprehensive snapshot of recent publications in NLP. Our analyses involve the
field at large, but also more in-depth studies on both user-facing technologies
(machine translation, language understanding, question answering,
text-to-speech synthesis) as well as more linguistic NLP tasks (dependency
parsing, morphological inflection). In the process, we (1) quantify disparities
in the current state of NLP research, (2) explore some of its associated
societal and academic factors, and (3) produce tailored recommendations for
evidence-based policy making aimed at promoting more global and equitable
language technologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masader: Metadata Sourcing for Arabic Text and Speech Data Resources. (arXiv:2110.06744v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06744">
<div class="article-summary-box-inner">
<span><p>The NLP pipeline has evolved dramatically in the last few years. The first
step in the pipeline is to find suitable annotated datasets to evaluate the
tasks we are trying to solve. Unfortunately, most of the published datasets
lack metadata annotations that describe their attributes. Not to mention, the
absence of a public catalogue that indexes all the publicly available datasets
related to specific regions or languages. When we consider low-resource
dialectical languages, for example, this issue becomes more prominent. In this
paper we create \textit{Masader}, the largest public catalogue for Arabic NLP
datasets, which consists of 200 datasets annotated with 25 attributes.
Furthermore, We develop a metadata annotation strategy that could be extended
to other languages. We also make remarks and highlight some issues about the
current status of Arabic NLP datasets and suggest recommendations to address
them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Automated Unit Tests for Unsupervised Code Translation. (arXiv:2110.06773v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06773">
<div class="article-summary-box-inner">
<span><p>With little to no parallel data available for programming languages,
unsupervised methods are well-suited to source code translation. However, the
majority of unsupervised machine translation approaches rely on
back-translation, a method developed in the context of natural language
translation and one that inherently involves training on noisy inputs.
Unfortunately, source code is highly sensitive to small changes; a single token
can result in compilation failures or erroneous programs, unlike natural
languages where small inaccuracies may not change the meaning of a sentence. To
address this issue, we propose to leverage an automated unit-testing system to
filter out invalid translations, thereby creating a fully tested parallel
corpus. We found that fine-tuning an unsupervised model with this filtered data
set significantly reduces the noise in the translations so-generated,
comfortably outperforming the state-of-the-art for all language pairs studied.
In particular, for Java $\to$ Python and Python $\to$ C++ we outperform the
best previous methods by more than 16% and 24% respectively, reducing the error
rate by more than 35%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue Systems. (arXiv:2110.06800v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06800">
<div class="article-summary-box-inner">
<span><p>Zero/few-shot transfer to unseen services is a critical challenge in
task-oriented dialogue research. The Schema-Guided Dialogue (SGD) dataset
introduced a paradigm for enabling models to support an unlimited number of
services without additional data collection or re-training through the use of
schemas. Schemas describe service APIs in natural language, which models
consume to understand the services they need to support. However, the impact of
the choice of language in these schemas on model performance remains
unexplored. We address this by releasing SGD-X, a benchmark for measuring the
robustness of dialogue systems to linguistic variations in schemas. SGD-X
extends the SGD dataset with crowdsourced variants for every schema, where
variants are semantically similar yet stylistically diverse. We evaluate two
dialogue state tracking models on SGD-X and observe that neither generalizes
well across schema variations, measured by joint goal accuracy and a novel
metric for measuring schema sensitivity. Furthermore, we present a simple
model-agnostic data augmentation method to improve schema robustness and
zero-shot generalization to unseen services.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging redundancy in attention with Reuse Transformers. (arXiv:2110.06821v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06821">
<div class="article-summary-box-inner">
<span><p>Pairwise dot product-based attention allows Transformers to exchange
information between tokens in an input-dependent way, and is key to their
success across diverse applications in language and vision. However, a typical
Transformer model computes such pairwise attention scores repeatedly for the
same sequence, in multiple heads in multiple layers. We systematically analyze
the empirical similarity of these scores across heads and layers and find them
to be considerably redundant, especially adjacent layers showing high
similarity. Motivated by these findings, we propose a novel architecture that
reuses attention scores computed in one layer in multiple subsequent layers.
Experiments on a number of standard benchmarks show that reusing attention
delivers performance equivalent to or better than standard transformers, while
reducing both compute and memory usage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Speaker-Aware Learning Framework for Improving Multi-turn Dialogue Coherence. (arXiv:2110.06823v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06823">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel open-domain dialogue generation framework
emphasizing the differentiation of speakers in multi-turn conversations.
Differing from prior work that solely relies on the content of conversation
history to generate a response, we argue that capturing relative social
relations among utterances (i.e., generated by either the same speaker or
different persons) benefits the machine capturing fine-grained context
information from a conversation history to improve context coherence in the
generated response. Given that, we propose a speaker-aware framework, named
Parallel Hierarchical Attentive Encoder-Decoder (PHAED), that aims to model
each utterance with the awareness of its speaker and contextual associations
with the same speaker's previous messages. Specifically, in a conversation
involving two speakers, we regard the utterances from one speaker as responses
and those from the other as queries. After understanding queries via our
encoder with inner-query and inter-query encodings, our decoder reuses the
hidden states of previously generated responses to generate a new response. Our
empirical results show that PHAED outperforms the state-of-the-art in both
automatic and human evaluations. Furthermore, our ablation study shows that
dialogue models with speaker tokens can generally decrease the possibility of
generating non-coherent responses regarding the conversation context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Language Model Integration for RNN Transducer based Speech Recognition. (arXiv:2110.06841v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06841">
<div class="article-summary-box-inner">
<span><p>The mismatch between an external language model (LM) and the implicitly
learned internal LM (ILM) of RNN-Transducer (RNN-T) can limit the performance
of LM integration such as simple shallow fusion. A Bayesian interpretation
suggests to remove this sequence prior as ILM correction. In this work, we
study various ILM correction-based LM integration methods formulated in a
common RNN-T framework. We provide a decoding interpretation on two major
reasons for performance improvement with ILM correction, which is further
experimentally verified with detailed analysis. We also propose an exact-ILM
training framework by extending the proof given in the hybrid autoregressive
transducer, which enables a theoretical justification for other ILM approaches.
Systematic comparison is conducted for both in-domain and cross-domain
evaluation on the Librispeech and TED-LIUM Release 2 corpora, respectively. Our
proposed exact-ILM training can further improve the best ILM method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compositional Generalization in Dependency Parsing. (arXiv:2110.06843v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06843">
<div class="article-summary-box-inner">
<span><p>Compositionality, or the ability to combine familiar units like words into
novel phrases and sentences, has been the focus of intense interest in
artificial intelligence in recent years. To test compositional generalization
in semantic parsing, Keysers et al. (2020) introduced Compositional Freebase
Queries (CFQ). This dataset maximizes the similarity between the test and train
distributions over primitive units, like words, while maximizing the compound
divergence: the dissimilarity between test and train distributions over larger
structures, like phrases. Dependency parsing, however, lacks a compositional
generalization benchmark. In this work, we introduce a gold-standard set of
dependency parses for CFQ, and use this to analyze the behavior of a
state-of-the art dependency parser (Qi et al., 2020) on the CFQ dataset. We
find that increasing compound divergence degrades dependency parsing
performance, although not as dramatically as semantic parsing performance.
Additionally, we find the performance of the dependency parser does not
uniformly degrade relative to compound divergence, and the parser performs
differently on different splits with the same compound divergence. We explore a
number of hypotheses for what causes the non-uniform degradation in dependency
parsing performance, and identify a number of syntactic structures that drive
the dependency parser's lower performance on the most challenging splits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ousiometrics and Telegnomics: The essence of meaning conforms to a two-dimensional powerful-weak and dangerous-safe framework with diverse corpora presenting a safety bias. (arXiv:2110.06847v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06847">
<div class="article-summary-box-inner">
<span><p>We define `ousiometrics' to be the study of essential meaning in whatever
context that meaningful signals are communicated, and `telegnomics' as the
study of remotely sensed knowledge. From work emerging through the middle of
the 20th century, the essence of meaning has become generally accepted as being
well captured by the three orthogonal dimensions of evaluation, potency, and
activation (EPA). By re-examining first types and then tokens for the English
language, and through the use of automatically annotated histograms --
`ousiograms' -- we find here that: 1. The essence of meaning conveyed by words
is instead best described by a compass-like power-danger (PD) framework, and 2.
Analysis of a disparate collection of large-scale English language corpora --
literature, news, Wikipedia, talk radio, and social media -- shows that natural
language exhibits a systematic bias toward safe, low danger words -- a
reinterpretation of the Pollyanna principle's positivity bias for written
expression. To help justify our choice of dimension names and to help address
the problems with representing observed ousiometric dimensions by bipolar
adjective pairs, we introduce and explore `synousionyms' and `antousionyms' --
ousiometric counterparts of synonyms and antonyms. We further show that the PD
framework revises the circumplex model of affect as a more general model of
state of mind. Finally, we use our findings to construct and test a prototype
`ousiometer', a telegnomic instrument that measures ousiometric time series for
temporal corpora. We contend that our power-danger ousiometric framework
provides a complement for entropy-based measurements, and may be of value for
the study of a wide variety of communication across biological and artificial
life.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Morphosyntactic Tagging with Pre-trained Language Models for Arabic and its Dialects. (arXiv:2110.06852v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06852">
<div class="article-summary-box-inner">
<span><p>We present state-of-the-art results on morphosyntactic tagging across
different varieties of Arabic using fine-tuned pre-trained transformer language
models. Our models consistently outperform existing systems in Modern Standard
Arabic and all the Arabic dialects we study, achieving 2.6% absolute
improvement over the previous state-of-the-art in Modern Standard Arabic, 2.8%
in Gulf, 1.6% in Egyptian, and 7.0% in Levantine. We explore different training
setups for fine-tuning pre-trained transformer language models, including
training data size, the use of external linguistic resources, and the use of
annotated data from other dialects in a low-resource scenario. Our results show
that strategic fine-tuning using datasets from other high-resource dialects is
beneficial for a low-resource dialect. Additionally, we show that high-quality
morphological analyzers as external linguistic resources are beneficial
especially in low-resource settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Role Labeling as Dependency Parsing: Exploring Latent Tree Structures Inside Arguments. (arXiv:2110.06865v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06865">
<div class="article-summary-box-inner">
<span><p>Semantic role labeling is a fundamental yet challenging task in the NLP
community. Recent works of SRL mainly fall into two lines:1) BIO-based and 2)
span-based. Despite effectiveness, they share some intrinsic drawbacks of not
explicitly considering internal argument structures, which may potentially
hinder the model's expressiveness. To remedy this, we propose to reduce SRL to
a dependency parsing task and regard the flat argument spans as latent
subtrees. In particular, we equip our formulation with a novel span-constrained
TreeCRF model to make tree structures span-aware, and further extend it to the
second-order case. Experiments on CoNLL05 and CoNLL12 benchmarks reveal that
the results of our methods outperform all previous works and achieve the
state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Essay Scoring Using Transformer Models. (arXiv:2110.06874v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06874">
<div class="article-summary-box-inner">
<span><p>Automated essay scoring (AES) is gaining increasing attention in the
education sector as it significantly reduces the burden of manual scoring and
allows ad hoc feedback for learners. Natural language processing based on
machine learning has been shown to be particularly suitable for text
classification and AES. While many machine-learning approaches for AES still
rely on a bag-of-words (BOW) approach, we consider a transformer-based approach
in this paper, compare its performance to a logistic regression model based on
the BOW approach and discuss their differences. The analysis is based on 2,088
email responses to a problem-solving task, that were manually labeled in terms
of politeness. Both transformer models considered in that analysis outperformed
without any hyper-parameter tuning the regression-based model. We argue that
for AES tasks such as politeness classification, the transformer-based approach
has significant advantages, while a BOW approach suffers from not taking word
order into account and reducing the words to their stem. Further, we show how
such models can help increase the accuracy of human raters, and we provide a
detailed instruction on how to implement transformer-based models for one's own
purpose.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConditionalQA: A Complex Reading Comprehension Dataset with Conditional Answers. (arXiv:2110.06884v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06884">
<div class="article-summary-box-inner">
<span><p>We describe a Question Answering (QA) dataset that contains complex questions
with conditional answers, i.e. the answers are only applicable when certain
conditions apply. We call this dataset ConditionalQA. In addition to
conditional answers, the dataset also features: (1) long context documents with
information that is related in logically complex ways; (2) multi-hop questions
that require compositional logical reasoning; (3) a combination of extractive
questions, yes/no questions, questions with multiple answers, and
not-answerable questions; (4) questions asked without knowing the answers. We
show that ConditionalQA is challenging for many of the existing QA models,
especially in selecting answer conditions. We believe that this dataset will
motivate further research in answering complex questions over long documents.
Data and leaderboard are publicly available at
\url{https://github.com/haitian-sun/ConditionalQA}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Audio-Visual Scene-Aware Dialog and Reasoning using Audio-Visual Transformers with Joint Student-Teacher Learning. (arXiv:2110.06894v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06894">
<div class="article-summary-box-inner">
<span><p>In previous work, we have proposed the Audio-Visual Scene-Aware Dialog (AVSD)
task, collected an AVSD dataset, developed AVSD technologies, and hosted an
AVSD challenge track at both the 7th and 8th Dialog System Technology
Challenges (DSTC7, DSTC8). In these challenges, the best-performing systems
relied heavily on human-generated descriptions of the video content, which were
available in the datasets but would be unavailable in real-world applications.
To promote further advancements for real-world applications, we proposed a
third AVSD challenge, at DSTC10, with two modifications: 1) the human-created
description is unavailable at inference time, and 2) systems must demonstrate
temporal reasoning by finding evidence from the video to support each answer.
This paper introduces the new task that includes temporal reasoning and our new
extension of the AVSD dataset for DSTC10, for which we collected
human-generated temporal reasoning data. We also introduce a baseline system
built using an AV-transformer, which we released along with the new dataset.
Finally, this paper introduces a new system that extends our baseline system
with attentional multimodal fusion, joint student-teacher learning (JSTL), and
model combination techniques, achieving state-of-the-art performances on the
AVSD datasets for DSTC7, DSTC8, and DSTC10. We also propose two temporal
reasoning methods for AVSD: one attention-based, and one based on a time-domain
region proposal network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teaching Models new APIs: Domain-Agnostic Simulators for Task Oriented Dialogue. (arXiv:2110.06905v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06905">
<div class="article-summary-box-inner">
<span><p>We demonstrate that large language models are able to simulate Task Oriented
Dialogues in novel domains, provided only with an API implementation and a list
of goals. We show these simulations can formulate online, automatic metrics
that correlate well with human evaluations. Furthermore, by checking for
whether the User's goals are met, we can use simulation to repeatedly generate
training data and improve the quality of simulations themselves. With no human
intervention or domain-specific training data, our simulations bootstrap
end-to-end models which achieve a 37\% error reduction in previously unseen
domains. By including as few as 32 domain-specific conversations, bootstrapped
models can match the performance of a fully-supervised model with $10\times$
more data. To our knowledge, this is the first time simulations have been shown
to be effective at bootstrapping models without explicitly requiring any
domain-specific training data, rule-engineering, or humans-in-the-loop.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?. (arXiv:2110.06918v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06918">
<div class="article-summary-box-inner">
<span><p>Despite their recent popularity and well known advantages, dense retrievers
still lag behind sparse methods such as BM25 in their ability to reliably match
salient phrases and rare entities in the query. It has been argued that this is
an inherent limitation of dense models. We disprove this claim by introducing
the Salient Phrase Aware Retriever (SPAR), a dense retriever with the lexical
matching capacity of a sparse model. In particular, we show that a dense
retriever {\Lambda} can be trained to imitate a sparse one, and SPAR is built
by augmenting a standard dense retriever with {\Lambda}. When evaluated on five
open-domain question answering datasets and the MS MARCO passage retrieval
task, SPAR sets a new state of the art for dense and sparse retrievers and can
match or exceed the performance of more complicated dense-sparse hybrid
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantics-aware Attention Improves Neural Machine Translation. (arXiv:2110.06920v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06920">
<div class="article-summary-box-inner">
<span><p>The integration of syntactic structures into Transformer machine translation
has shown positive results, but to our knowledge, no work has attempted to do
so with semantic structures. In this work we propose two novel parameter-free
methods for injecting semantic information into Transformers, both rely on
semantics-aware masking of (some of) the attention heads. One such method
operates on the encoder, through a Scene-Aware Self-Attention (SASA) head.
Another on the decoder, through a Scene-Aware Cross-Attention (SACrA) head. We
show a consistent improvement over the vanilla Transformer and syntax-aware
models for four language pairs. We further show an additional gain when using
both semantic and syntactic structures in some language pairs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Representations for Modeling Variation in Speech. (arXiv:2011.12649v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12649">
<div class="article-summary-box-inner">
<span><p>Variation in speech is often represented and investigated using phonetic
transcriptions, but transcribing speech is time-consuming and error prone. As
an alternative representation, therefore, we investigate the extraction of
acoustic embeddings from several self-supervised neural models. We use these
representations to compute word-based pronunciation differences between
non-native and native speakers of English, and between different dialect
pronunciations, and evaluate these differences by comparing them with available
human native-likeness judgments. We show that Transformer-based speech
representations lead to significant performance gains over the use of phonetic
transcriptions, and find that feature-based use of Transformer models is most
effective with one of the middle layers instead of the final layer. We also
demonstrate that these neural speech representations not only capture segmental
differences, but also intonational and durational differences that cannot be
represented by a set of discrete symbols used in phonetic transcriptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Negation in Cognitive Reasoning. (arXiv:2012.12641v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12641">
<div class="article-summary-box-inner">
<span><p>Negation is both an operation in formal logic and in natural language by
which a proposition is replaced by one stating the opposite, as by the addition
of "not" or another negation cue. Treating negation in an adequate way is
required for cognitive reasoning, which aims at modeling the human ability to
draw meaningful conclusions despite incomplete and inconsistent knowledge. One
task of cognitive reasoning is answering questions given by sentences in
natural language. There are tools based on discourse representation theory to
convert sentences automatically into a formal logic representation, and
additional knowledge can be added using the predicate names in the formula and
knowledge databases. However, the knowledge in logic databases in practice
always is incomplete. Hence, forward reasoning of automated reasoning systems
alone does not suffice to derive answers to questions because, instead of
complete proofs, often only partial positive knowledge can be derived, while
negative knowledge is used only during the reasoning process. In consequence,
we aim at eliminating syntactic negation, strictly speaking, the negated event
or property. In this paper, we describe an effective procedure to determine the
negated event or property in order to replace it by its inverse. This lays the
basis of cognitive reasoning, employing both logic and machine learning for
general question answering. We evaluate our procedure by several benchmarks and
demonstrate its practical usefulness in our cognitive reasoning system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Specifying and Interpreting Reinforcement Learning Policies through Simulatable Machine Learning. (arXiv:2101.07140v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07140">
<div class="article-summary-box-inner">
<span><p>Human-AI collaborative policy synthesis is a procedure in which (1) a human
initializes an autonomous agent's behavior, (2) Reinforcement Learning improves
the human specified behavior, and (3) the agent can explain the final optimized
policy to the user. This paradigm leverages human expertise and facilitates a
greater insight into the learned behaviors of an agent. Existing approaches to
enabling collaborative policy specification involve black box methods which are
unintelligible and are not catered towards non-expert end-users. In this paper,
we develop a novel collaborative framework to enable humans to initialize and
interpret an autonomous agent's behavior, rooted in principles of
human-centered design. Through our framework, we enable humans to specify an
initial behavior model in the form of unstructured, natural language, which we
then convert to lexical decision trees. Next, we are able to leverage these
human-specified policies, to warm-start reinforcement learning and further
allow the agent to optimize the policies through reinforcement learning.
Finally, to close the loop on human-specification, we produce explanations of
the final learned policy, in multiple modalities, to provide the user a final
depiction about the learned policy of the agent. We validate our approach by
showing that our model can produce &gt;80% accuracy, and that human-initialized
policies are able to successfully warm-start RL. We then conduct a novel
human-subjects study quantifying the relative subjective and objective benefits
of varying XAI modalities(e.g., Tree, Language, and Program) for explaining
learned policies to end-users, in terms of usability and interpretability and
identify the circumstances that influence these measures. Our findings
emphasize the need for personalized explainable systems that can facilitate
user-centric policy explanations for a variety of end-users.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smart Proofs via Smart Contracts: Succinct and Informative Mathematical Derivations via Decentralized Markets. (arXiv:2102.03044v4 [cs.GT] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03044">
<div class="article-summary-box-inner">
<span><p>Modern mathematics is built on the idea that proofs should be translatable
into formal proofs, whose validity is an objective question, decidable by a
computer. Yet, in practice, proofs are informal and may omit many details. An
agent considers a proof valid if they trust that it could be expanded into a
machine-verifiable proof. A proof's validity can thus become a subjective
matter and lead to a debate, which may be difficult to settle. Hence, while the
concept of valid proof is well-defined, the process to establish validity is
itself a complex multi-agent problem.
</p>
<p>We introduce the SPRIG protocol. SPRIG allows agents to propose and verify
succinct and informative proofs in a decentralized fashion; the trust is
established by agents being able to request more details in the proof steps;
debates, if they arise, must isolate details of proofs and, if they persist, go
down to machine-level details, where they are automatically settled. A
structure of bounties and stakes is set to incentivize agents to act in good
faith.
</p>
<p>We propose a game-theoretic discussion of SPRIG, showing how agents with
various types of information interact, leading to a proof tree with an
appropriate level of detail and to the invalidation of wrong proofs, and we
discuss resilience against various attacks. We then analyze a simplified model,
characterize its equilibria and compute the agents' level of trust.
</p>
<p>SPRIG is designed to run as a smart contract on a blockchain platform. This
allows anonymous agents to participate in the verification debate, and to
contribute with their information. The smart contract mediates the
interactions, settles debates, and guarantees that bounties and stakes are paid
as specified.
</p>
<p>SPRIG enables new applications, such as the issuance of bounties for open
problems, and the creation of derivatives markets, allowing agents to inject
more information pertaining to proofs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Advances in Multi-turn Dialogue Comprehension: A Survey. (arXiv:2103.03125v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03125">
<div class="article-summary-box-inner">
<span><p>Training machines to understand natural language and interact with humans is
an elusive and essential task of artificial intelligence. A diversity of
dialogue systems has been designed with the rapid development of deep learning
techniques, especially the recent pre-trained language models (PrLMs). Among
these studies, the fundamental yet challenging type of task is dialogue
comprehension whose role is to teach the machines to read and comprehend the
dialogue context before responding. In this paper, we review the previous
methods from the technical perspective of dialogue modeling for the dialogue
comprehension task. We summarize the characteristics and challenges of dialogue
comprehension in contrast to plain-text reading comprehension. Then, we discuss
three typical patterns of dialogue modeling. In addition, we categorize
dialogue-related pre-training techniques which are employed to enhance PrLMs in
dialogue scenarios. Finally, we highlight the technical advances in recent
years and point out the lessons from the empirical analysis and the prospects
towards a new frontier of researches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Back to Square One: Artifact Detection, Training and Commonsense Disentanglement in the Winograd Schema. (arXiv:2104.08161v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08161">
<div class="article-summary-box-inner">
<span><p>The Winograd Schema (WS) has been proposed as a test for measuring
commonsense capabilities of models. Recently, pre-trained language model-based
approaches have boosted performance on some WS benchmarks but the source of
improvement is still not clear. This paper suggests that the apparent progress
on WS may not necessarily reflect progress in commonsense reasoning. To support
this claim, we first show that the current evaluation method of WS is
sub-optimal and propose a modification that uses twin sentences for evaluation.
We also propose two new baselines that indicate the existence of artifacts in
WS benchmarks. We then develop a method for evaluating WS-like sentences in a
zero-shot setting to account for the commonsense reasoning abilities acquired
during the pretraining and observe that popular language models perform
randomly in this setting when using our more strict evaluation. We conclude
that the observed progress is mostly due to the use of supervision in training
WS models, which is not likely to successfully support all the required
commonsense reasoning skills and knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SGG: Learning to Select, Guide, and Generate for Keyphrase Generation. (arXiv:2105.02544v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02544">
<div class="article-summary-box-inner">
<span><p>Keyphrases, that concisely summarize the high-level topics discussed in a
document, can be categorized into present keyphrase which explicitly appears in
the source text, and absent keyphrase which does not match any contiguous
subsequence but is highly semantically related to the source. Most existing
keyphrase generation approaches synchronously generate present and absent
keyphrases without explicitly distinguishing these two categories. In this
paper, a Select-Guide-Generate (SGG) approach is proposed to deal with present
and absent keyphrase generation separately with different mechanisms.
Specifically, SGG is a hierarchical neural network which consists of a
pointing-based selector at low layer concentrated on present keyphrase
generation, a selection-guided generator at high layer dedicated to absent
keyphrase generation, and a guider in the middle to transfer information from
selector to generator. Experimental results on four keyphrase generation
benchmarks demonstrate the effectiveness of our model, which significantly
outperforms the strong baselines for both present and absent keyphrases
generation. Furthermore, we extend SGG to a title generation task which
indicates its extensibility in natural language generation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Natural Language Understanding Pipeline for Bangla Conversational Agents. (arXiv:2107.05541v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05541">
<div class="article-summary-box-inner">
<span><p>Chatbots are intelligent software built to be used as a replacement for human
interaction. Existing studies typically do not provide enough support for
low-resource languages like Bangla. Due to the increasing popularity of social
media, we can also see the rise of interactions in Bangla transliteration
(mostly in English) among the native Bangla speakers. In this paper, we propose
a novel approach to build a Bangla chatbot aimed to be used as a business
assistant which can communicate in low-resource languages like Bangla and
Bangla Transliteration in English with high confidence consistently. Since
annotated data was not available for this purpose, we had to work on the whole
machine learning life cycle (data preparation, machine learning modeling, and
model deployment) using Rasa Open Source Framework, fastText embeddings,
Polyglot embeddings, Flask, and other systems as building blocks. While working
with the skewed annotated dataset, we try out different components and
pipelines to evaluate which works best and provide possible reasoning behind
the observed results. Finally, we present a pipeline for intent classification
and entity extraction which achieves reasonable performance (accuracy: 83.02%,
precision: 80.82%, recall: 83.02%, F1-score: 80%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Answer Similarity for Evaluating Question Answering Models. (arXiv:2108.06130v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06130">
<div class="article-summary-box-inner">
<span><p>The evaluation of question answering models compares ground-truth annotations
with model predictions. However, as of today, this comparison is mostly
lexical-based and therefore misses out on answers that have no lexical overlap
but are still semantically similar, thus treating correct answers as false.
This underestimation of the true performance of models hinders user acceptance
in applications and complicates a fair comparison of different models.
Therefore, there is a need for an evaluation metric that is based on semantics
instead of pure string similarity. In this short paper, we present SAS, a
cross-encoder-based metric for the estimation of semantic answer similarity,
and compare it to seven existing metrics. To this end, we create an English and
a German three-way annotated evaluation dataset containing pairs of answers
along with human judgment of their semantic similarity, which we release along
with an implementation of the SAS metric and the experiments. We find that
semantic similarity metrics based on recent transformer models correlate much
better with human judgment than traditional lexical similarity metrics on our
two newly created datasets and one dataset from related work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Dataset for Answering Time-Sensitive Questions. (arXiv:2108.06314v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06314">
<div class="article-summary-box-inner">
<span><p>Time is an important dimension in our physical world. Lots of facts can
evolve with respect to time. For example, the U.S. President might change every
four years. Therefore, it is important to consider the time dimension and
empower the existing QA models to reason over time. However, the existing QA
datasets contain rather few time-sensitive questions, hence not suitable for
diagnosing or benchmarking the model's temporal reasoning capability. In order
to promote research in this direction, we propose to construct a time-sensitive
QA dataset. The dataset is constructed by 1) mining time-evolving facts from
WikiData and align them to their corresponding Wikipedia page, 2) employing
crowd workers to verify and calibrate these noisy facts, 3) generating
question-answer pairs based on the annotated time-sensitive facts. Our dataset
poses challenges in the aspect of both temporal understanding and temporal
reasoning. We evaluate different SoTA long-document QA systems like BigBird and
FiD on our dataset. The best-performing model FiD can only achieve 46\%
accuracy, still far behind the human performance of 87\%. We demonstrate that
these models are still lacking the ability to perform consistent temporal
reasoning. Therefore, we believe that our dataset could serve as a benchmark to
develop NLP models more sensitive to temporal shift. The dataset and code are
released in~\url{https://github.com/wenhuchen/Time-Sensitive-QA}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic-Based Self-Critical Training For Question Generation. (arXiv:2108.12026v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12026">
<div class="article-summary-box-inner">
<span><p>Question generation is a conditioned language generation task that consists
in generating a context-aware question given a context and the targeted answer.
Train language modelling with a mere likelihood maximization has been widely
used while suffering from exposure bias and the discordance between the
training and the test metrics. In the way of addressing this issue, The
presented work portrays a fully Transformer-based reinforcement learning
generator-evaluation architecture for neural question generation. To edge the
flexibility of the generation, a semantic-based reward score was externally
infused during the training to drive the training of the language model. The
global architecture is laid out in a generator-evaluator fashion optimized
directly to n-gram and semantic-based metrics. Evaluation metrics for language
modelling only based on n-gram overlapping do not consider semantic relations
between reference and candidate sequences. To improve the evaluation step, a
two-fold evaluation was carried out. On the one side, an n-gram overlapping
evaluation using the BLEU score. On the other side, a semantic-based assessment
using BERTScore and NUBIA. The results were corroborated by a binary human
evaluation of the semantic relatedness of the generated question and the ground
truth. The results obtained showed that use a semantic-based REINFORCE
algorithm for the question generation syntactically reshapes the generated
questions while preserving their underlying semantic meaning. Many downstream
applications can be drawn from a successful question generation including the
enlargement of question answering datasets, the improvement of conversational
systems, the enhancement of autonomous educational assessment systems, and so
forth.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NumGPT: Improving Numeracy Ability of Generative Pre-trained Models. (arXiv:2109.03137v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03137">
<div class="article-summary-box-inner">
<span><p>Existing generative pre-trained language models (e.g., GPT) focus on modeling
the language structure and semantics of general texts. However, those models do
not consider the numerical properties of numbers and cannot perform robustly on
numerical reasoning tasks (e.g., math word problems and measurement
estimation). In this paper, we propose NumGPT, a generative pre-trained model
that explicitly models the numerical properties of numbers in texts.
Specifically, it leverages a prototype-based numeral embedding to encode the
mantissa of the number and an individual embedding to encode the exponent of
the number. A numeral-aware loss function is designed to integrate numerals
into the pre-training objective of NumGPT. We conduct extensive experiments on
four different datasets to evaluate the numeracy ability of NumGPT. The
experiment results show that NumGPT outperforms baseline models (e.g., GPT and
GPT with DICE) on a range of numerical reasoning tasks such as measurement
estimation, number comparison, math word problems, and magnitude
classification. Ablation studies are also conducted to evaluate the impact of
pre-training and model hyperparameters on the performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings. (arXiv:2109.07833v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07833">
<div class="article-summary-box-inner">
<span><p>Natural language inference (NLI) requires models to learn and apply
commonsense knowledge. These reasoning abilities are particularly important for
explainable NLI systems that generate a natural language explanation in
addition to their label prediction. The integration of external knowledge has
been shown to improve NLI systems, here we investigate whether it can also
improve their explanation capabilities. For this, we investigate different
sources of external knowledge and evaluate the performance of our models on
in-domain data as well as on special transfer datasets that are designed to
assess fine-grained reasoning capabilities. We find that different sources of
knowledge have a different effect on reasoning abilities, for example, implicit
knowledge stored in language models can hinder reasoning on numbers and
negations. Finally, we conduct the largest and most fine-grained explainable
NLI crowdsourcing study to date. It reveals that even large differences in
automatic performance scores do neither reflect in human ratings of label,
explanation, commonsense nor grammar correctness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Task Learning with Sentiment, Emotion, and Target Detection to Recognize Hate Speech and Offensive Language. (arXiv:2109.10255v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10255">
<div class="article-summary-box-inner">
<span><p>The recognition of hate speech and offensive language (HOF) is commonly
formulated as a classification task to decide if a text contains HOF. We
investigate whether HOF detection can profit by taking into account the
relationships between HOF and similar concepts: (a) HOF is related to sentiment
analysis because hate speech is typically a negative statement and expresses a
negative opinion; (b) it is related to emotion analysis, as expressed hate
points to the author experiencing (or pretending to experience) anger while the
addressees experience (or are intended to experience) fear. (c) Finally, one
constituting element of HOF is the mention of a targeted person or group. On
this basis, we hypothesize that HOF detection shows improvements when being
modeled jointly with these concepts, in a multi-task learning setup. We base
our experiments on existing data sets for each of these concepts (sentiment,
emotion, target of HOF) and evaluate our models as a participant (as team
IMS-SINAI) in the HASOC FIRE 2021 English Subtask 1A. Based on model-selection
experiments in which we consider multiple available resources and submissions
to the shared task, we find that the combination of the CrowdFlower emotion
corpus, the SemEval 2016 Sentiment Corpus, and the OffensEval 2019 target
detection data leads to an F1 =.79 in a multi-head multi-task learning model
based on BERT, in comparison to .7895 of plain BERT. On the HASOC 2019 test
data, this result is more substantial with an increase by 2pp in F1 and a
considerable increase in recall. Across both data sets (2019, 2021), the recall
is particularly increased for the class of HOF (6pp for the 2019 data and 3pp
for the 2021 data), showing that MTL with emotion, sentiment, and target
identification is an appropriate approach for early warning systems that might
be deployed in social media platforms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepPSL: End-to-end perception and reasoning with applications to zero shot learning. (arXiv:2109.13662v3 [eess.SY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13662">
<div class="article-summary-box-inner">
<span><p>We introduce DeepPSL a variant of Probabilistic Soft Logic (PSL) to produce
an end-to-end trainable system that integrates reasoning and perception. PSL
represents first-order logic in terms of a convex graphical model -- Hinge Loss
Markov random fields (HL-MRFs). PSL stands out among probabilistic logic
frameworks due to its tractability having been applied to systems of more than
1 billion ground rules. The key to our approach is to represent predicates in
first-order logic using deep neural networks and then to approximately
back-propagate through the HL-MRF and thus train every aspect of the
first-order system being represented. We believe that this approach represents
an interesting direction for the integration of deep learning and reasoning
techniques with applications to knowledge base learning, multi-task learning,
and explainability. We evaluate DeepPSL on a zero shot learning problem in
image classification. State of the art results demonstrate the utility and
flexibility of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LexGLUE: A Benchmark Dataset for Legal Language Understanding in English. (arXiv:2110.00976v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00976">
<div class="article-summary-box-inner">
<span><p>Law, interpretations of law, legal arguments, agreements, etc. are typically
expressed in writing, leading to the production of vast corpora of legal text.
Their analysis, which is at the center of legal practice, becomes increasingly
elaborate as these collections grow in size. Natural language understanding
(NLU) technologies can be a valuable tool to support legal practitioners in
these endeavors. Their usefulness, however, largely depends on whether current
state-of-the-art models can generalize across various tasks in the legal
domain. To answer this currently open question, we introduce the Legal General
Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets
for evaluating model performance across a diverse set of legal NLU tasks in a
standardized way. We also provide an evaluation and analysis of several generic
and legal-oriented models demonstrating that the latter consistently offer
performance improvements across multiple tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QTN-VQC: An End-to-End Learning framework for Quantum Neural Networks. (arXiv:2110.03861v2 [quant-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03861">
<div class="article-summary-box-inner">
<span><p>The advent of noisy intermediate-scale quantum (NISQ) computers raises a
crucial challenge to design quantum neural networks for fully quantum learning
tasks. To bridge the gap, this work proposes an end-to-end learning framework
named QTN-VQC, by introducing a trainable quantum tensor network (QTN) for
quantum embedding on a variational quantum circuit (VQC). The architecture of
QTN is composed of a parametric tensor-train network for feature extraction and
a tensor product encoding for quantum encoding. We highlight the QTN for
quantum embedding in terms of two perspectives: (1) we theoretically
characterize QTN by analyzing its representation power of input features; (2)
QTN enables an end-to-end parametric model pipeline, namely QTN-VQC, from the
generation of quantum embedding to the output measurement. Our experiments on
the MNIST dataset demonstrate the advantages of QTN for quantum embedding over
other quantum embedding approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. (arXiv:2110.03888v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03888">
<div class="article-summary-box-inner">
<span><p>Recent expeditious developments in deep learning algorithms, distributed
training, and even hardware design for large models have enabled training
extreme-scale models, say GPT-3 and Switch Transformer possessing hundreds of
billions or even trillions of parameters. However, under limited resources,
extreme-scale model training that requires enormous amounts of computes and
memory footprint suffers from frustratingly low efficiency in model
convergence. In this paper, we propose a simple training strategy called
"Pseudo-to-Real" for high-memory-footprint-required large models.
Pseudo-to-Real is compatible with large models with architecture of sequential
layers. We demonstrate a practice of pretraining unprecedented
10-trillion-parameter model, an order of magnitude larger than the
state-of-the-art, on solely 512 GPUs within 10 days. Besides demonstrating the
application of Pseudo-to-Real, we also provide a technique, Granular CPU
offloading, to manage CPU memory for training large model and maintain high GPU
utilities. Fast training of extreme-scale models on a decent amount of
resources can bring much smaller carbon footprint and contribute to greener AI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HydraSum -- Disentangling Stylistic Features in Text Summarization using Multi-Decoder Models. (arXiv:2110.04400v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04400">
<div class="article-summary-box-inner">
<span><p>Existing abstractive summarization models lack explicit control mechanisms
that would allow users to influence the stylistic features of the model
outputs. This results in generating generic summaries that do not cater to the
users needs or preferences. To address this issue we introduce HydraSum, a new
summarization architecture that extends the single decoder framework of current
models, e.g. BART, to a mixture-of-experts version consisting of multiple
decoders. Our proposed model encourages each expert, i.e. decoder, to learn and
generate stylistically-distinct summaries along dimensions such as
abstractiveness, length, specificity, and others. At each time step, HydraSum
employs a gating mechanism that decides the contribution of each individual
decoder to the next token's output probability distribution. Through
experiments on three summarization datasets (CNN, Newsroom, XSum), we
demonstrate that this gating mechanism automatically learns to assign
contrasting summary styles to different HydraSum decoders under the standard
training objective without the need for additional supervision. We further show
that a guided version of the training process can explicitly govern which
summary style is partitioned between decoders, e.g. high abstractiveness vs.
low abstractiveness or high specificity vs. low specificity, and also increase
the stylistic-difference between individual decoders. Finally, our experiments
demonstrate that our decoder framework is highly flexible: during inference, we
can sample from individual decoders or mixtures of different subsets of the
decoders to yield a diverse set of summaries and enforce single- and
multi-style control over summary generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SEPP: Similarity Estimation of Predicted Probabilities for Defending and Detecting Adversarial Text. (arXiv:2110.05748v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05748">
<div class="article-summary-box-inner">
<span><p>There are two cases describing how a classifier processes input text, namely,
misclassification and correct classification. In terms of misclassified texts,
a classifier handles the texts with both incorrect predictions and adversarial
texts, which are generated to fool the classifier, which is called a victim.
Both types are misunderstood by the victim, but they can still be recognized by
other classifiers. This induces large gaps in predicted probabilities between
the victim and the other classifiers. In contrast, text correctly classified by
the victim is often successfully predicted by the others and induces small
gaps. In this paper, we propose an ensemble model based on similarity
estimation of predicted probabilities (SEPP) to exploit the large gaps in the
misclassified predictions in contrast to small gaps in the correct
classification. SEPP then corrects the incorrect predictions of the
misclassified texts. We demonstrate the resilience of SEPP in defending and
detecting adversarial texts through different types of victim classifiers,
classification tasks, and adversarial attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LaoPLM: Pre-trained Language Models for Lao. (arXiv:2110.05896v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05896">
<div class="article-summary-box-inner">
<span><p>Trained on the large corpus, pre-trained language models (PLMs) can capture
different levels of concepts in context and hence generate universal language
representations. They can benefit multiple downstream natural language
processing (NLP) tasks. Although PTMs have been widely used in most NLP
applications, especially for high-resource languages such as English, it is
under-represented in Lao NLP research. Previous work on Lao has been hampered
by the lack of annotated datasets and the sparsity of language resources. In
this work, we construct a text classification dataset to alleviate the
resource-scare situation of the Lao language. We additionally present the first
transformer-based PTMs for Lao with four versions: BERT-small, BERT-base,
ELECTRA-small and ELECTRA-base, and evaluate it over two downstream tasks:
part-of-speech tagging and text classification. Experiments demonstrate the
effectiveness of our Lao models. We will release our models and datasets to the
community, hoping to facilitate the future development of Lao NLP applications.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Real Image Inversion via Segments. (arXiv:2110.06269v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06269">
<div class="article-summary-box-inner">
<span><p>In this short report, we present a simple, yet effective approach to editing
real images via generative adversarial networks (GAN). Unlike previous
techniques, that treat all editing tasks as an operation that affects pixel
values in the entire image in our approach we cut up the image into a set of
smaller segments. For those segments corresponding latent codes of a generative
network can be estimated with greater accuracy due to the lower number of
constraints. When codes are altered by the user the content in the image is
manipulated locally while the rest of it remains unaffected. Thanks to this
property the final edited image better retains the original structures and thus
helps to preserve natural look.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-Time Learning from An Expert in Deep Recommendation Systems with Marginal Distance Probability Distribution. (arXiv:2110.06287v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06287">
<div class="article-summary-box-inner">
<span><p>Recommendation systems play an important role in today's digital world. They
have found applications in various applications such as music platforms, e.g.,
Spotify, and movie streaming services, e.g., Netflix. Less research effort has
been devoted to physical exercise recommendation systems. Sedentary lifestyles
have become the major driver of several diseases as well as healthcare costs.
In this paper, we develop a recommendation system for daily exercise activities
to users based on their history, profile and similar users. The developed
recommendation system uses a deep recurrent neural network with user-profile
attention and temporal attention mechanisms.
</p>
<p>Moreover, exercise recommendation systems are significantly different from
streaming recommendation systems in that we are not able to collect click
feedback from the participants in exercise recommendation systems. Thus, we
propose a real-time, expert-in-the-loop active learning procedure. The active
learners calculate the uncertainty of the recommender at each time step for
each user and ask an expert for a recommendation when the certainty is low. In
this paper, we derive the probability distribution function of marginal
distance, and use it to determine when to ask experts for feedback. Our
experimental results on a mHealth dataset show improved accuracy after
incorporating the real-time active learner with the recommendation system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Localized Persistent Homologies for more Effective Deep Learning. (arXiv:2110.06295v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06295">
<div class="article-summary-box-inner">
<span><p>Persistent Homologies have been successfully used to increase the performance
of deep networks trained to detect curvilinear structures and to improve the
topological quality of the results. However, existing methods are very global
and ignore the location of topological features. In this paper, we introduce an
approach that relies on a new filtration function to account for location
during network training. We demonstrate experimentally on 2D images of roads
and 3D image stacks of neuronal processes that networks trained in this manner
are better at recovering the topology of the curvilinear structures they
extract.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Content Based Image Retrieval for Highly Imbalanced Melanoma Data using Style Transfer, Semantic Image Segmentation and Ensemble Learning. (arXiv:2110.06331v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06331">
<div class="article-summary-box-inner">
<span><p>Lesion images are frequently taken in open-set settings. Because of this, the
image data generated is extremely varied in nature.It is difficult for a
convolutional neural network to find proper features and generalise well, as a
result content based image retrieval (CBIR) system for lesion images are
difficult to build. This paper explores this domain and proposes multiple
similarity measures which uses Style Loss and Dice Coefficient via a novel
similarity measure called I1-Score. Out of the CBIR similarity measures
proposed, pure style loss approach achieves a remarkable accuracy increase over
traditional approaches like Euclidean Distance and Cosine Similarity. The
I1-Scores using style loss performed better than traditional approaches by a
small margin, whereas, I1-Scores with dice-coefficient faired very poorly. The
model used is trained using ensemble learning for better generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A novel framework based on deep learning and ANOVA feature selection method for diagnosis of COVID-19 cases from chest X-ray Images. (arXiv:2110.06340v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06340">
<div class="article-summary-box-inner">
<span><p>The new coronavirus (known as COVID-19) was first identified in Wuhan and
quickly spread worldwide, wreaking havoc on the economy and people's everyday
lives. Fever, cough, sore throat, headache, exhaustion, muscular aches, and
difficulty breathing are all typical symptoms of COVID-19. A reliable detection
technique is needed to identify affected individuals and care for them in the
early stages of COVID-19 and reduce the virus's transmission. The most
accessible method for COVID-19 identification is RT-PCR; however, due to its
time commitment and false-negative results, alternative options must be sought.
Indeed, compared to RT-PCR, chest CT scans and chest X-ray images provide
superior results. Because of the scarcity and high cost of CT scan equipment,
X-ray images are preferable for screening. In this paper, a pre-trained
network, DenseNet169, was employed to extract features from X-ray images.
Features were chosen by a feature selection method (ANOVA) to reduce
computations and time complexity while overcoming the curse of dimensionality
to improve predictive accuracy. Finally, selected features were classified by
XGBoost. The ChestX-ray8 dataset, which was employed to train and evaluate the
proposed method. This method reached 98.72% accuracy for two-class
classification (COVID-19, healthy) and 92% accuracy for three-class
classification (COVID-19, healthy, pneumonia).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Voice-assisted Image Labelling for Endoscopic Ultrasound Classification using Neural Networks. (arXiv:2110.06367v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06367">
<div class="article-summary-box-inner">
<span><p>Ultrasound imaging is a commonly used technology for visualising patient
anatomy in real-time during diagnostic and therapeutic procedures. High
operator dependency and low reproducibility make ultrasound imaging and
interpretation challenging with a steep learning curve. Automatic image
classification using deep learning has the potential to overcome some of these
challenges by supporting ultrasound training in novices, as well as aiding
ultrasound image interpretation in patient with complex pathology for more
experienced practitioners. However, the use of deep learning methods requires a
large amount of data in order to provide accurate results. Labelling large
ultrasound datasets is a challenging task because labels are retrospectively
assigned to 2D images without the 3D spatial context available in vivo or that
would be inferred while visually tracking structures between frames during the
procedure. In this work, we propose a multi-modal convolutional neural network
(CNN) architecture that labels endoscopic ultrasound (EUS) images from raw
verbal comments provided by a clinician during the procedure. We use a CNN
composed of two branches, one for voice data and another for image data, which
are joined to predict image labels from the spoken names of anatomical
landmarks. The network was trained using recorded verbal comments from expert
operators. Our results show a prediction accuracy of 76% at image level on a
dataset with 5 different labels. We conclude that the addition of spoken
commentaries can increase the performance of ultrasound image classification,
and eliminate the burden of manually labelling large EUS datasets necessary for
deep learning applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Open Source User Activity Traces with Applications to User Mobility Characterization and Modeling. (arXiv:2110.06382v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06382">
<div class="article-summary-box-inner">
<span><p>The current state-of-the-art in user mobility research has extensively relied
on open-source mobility traces captured from pedestrian and vehicular activity
through a variety of communication technologies as users engage in a wide-range
of applications, including connected healthcare, localization, social media,
e-commerce, etc. Most of these traces are feature-rich and diverse, not only in
the information they provide, but also in how they can be used and leveraged.
This diversity poses two main challenges for researchers and practitioners who
wish to make use of available mobility datasets. First, it is quite difficult
to get a bird's eye view of the available traces without spending considerable
time looking them up. Second, once they have found the traces, they still need
to figure out whether the traces are adequate to their needs.
</p>
<p>The purpose of this survey is three-fold. It proposes a taxonomy to classify
open-source mobility traces including their mobility mode, data source and
collection technology. It then uses the proposed taxonomy to classify existing
open-source mobility traces and finally, highlights three case studies using
popular publicly available datasets to showcase how our taxonomy can tease out
feature sets in traces to help determine their applicability to specific
use-cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CovXR: Automated Detection of COVID-19 Pneumonia in Chest X-Rays through Machine Learning. (arXiv:2110.06398v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06398">
<div class="article-summary-box-inner">
<span><p>Coronavirus disease 2019 (COVID-19) is the highly contagious illness caused
by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The standard
diagnostic testing procedure for COVID-19 is testing a nasopharyngeal swab for
SARS-CoV-2 nucleic acid using a real-time polymerase chain reaction (PCR),
which can take multiple days to provide a diagnosis. Another widespread form of
testing is rapid antigen testing, which has a low sensitivity compared to PCR,
but is favored for its quick diagnosis time of usually 15-30 minutes. Patients
who test positive for COVID-19 demonstrate diffuse alveolar damage in 87% of
cases. Machine learning has proven to have advantages in image classification
problems with radiology. In this work, we introduce CovXR as a machine learning
model designed to detect COVID-19 pneumonia in chest X-rays (CXR). CovXR is a
convolutional neural network (CNN) trained on over 4,300 chest X-rays. The
performance of the model is measured through accuracy, F1 score, sensitivity,
and specificity. The model achieves an accuracy of 95.5% and an F1 score of
0.954. The sensitivity is 93.5% and specificity is 97.5%. With accuracy above
95% and F1 score above 0.95, CovXR is highly accurate in predicting COVID-19
pneumonia on CXRs. The model achieves better accuracy than prior work and uses
a unique approach to identify COVID-19 pneumonia. CovXR is highly accurate in
identifying COVID-19 on CXRs of patients with a PCR confirmed positive
diagnosis and provides much faster results than PCR tests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Inference with Neural Interpreters. (arXiv:2110.06399v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06399">
<div class="article-summary-box-inner">
<span><p>Modern neural network architectures can leverage large amounts of data to
generalize well within the training distribution. However, they are less
capable of systematic generalization to data drawn from unseen but related
distributions, a feat that is hypothesized to require compositional reasoning
and reuse of knowledge. In this work, we present Neural Interpreters, an
architecture that factorizes inference in a self-attention network as a system
of modules, which we call \emph{functions}. Inputs to the model are routed
through a sequence of functions in a way that is end-to-end learned. The
proposed architecture can flexibly compose computation along width and depth,
and lends itself well to capacity extension after training. To demonstrate the
versatility of Neural Interpreters, we evaluate it in two distinct settings:
image classification and visual abstract reasoning on Raven Progressive
Matrices. In the former, we show that Neural Interpreters perform on par with
the vision transformer using fewer parameters, while being transferrable to a
new task in a sample efficient manner. In the latter, we find that Neural
Interpreters are competitive with respect to the state-of-the-art in terms of
systematic generalization
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CyTran: Cycle-Consistent Transformers for Non-Contrast to Contrast CT Translation. (arXiv:2110.06400v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06400">
<div class="article-summary-box-inner">
<span><p>We propose a novel approach to translate unpaired contrast computed
tomography (CT) scans to non-contrast CT scans and the other way around.
Solving this task has two important applications: (i) to automatically generate
contrast CT scans for patients for whom injecting contrast substance is not an
option, and (ii) to enhance alignment between contrast and non-contrast CT by
reducing the differences induced by the contrast substance before registration.
Our approach is based on cycle-consistent generative adversarial convolutional
transformers, for short, CyTran. Our neural model can be trained on unpaired
images, due to the integration of a cycle-consistency loss. To deal with
high-resolution images, we design a hybrid architecture based on convolutional
and multi-head attention layers. In addition, we introduce a novel data set,
Coltea-Lung-CT-100W, containing 3D triphasic lung CT scans (with a total of
37,290 images) collected from 100 female patients. Each scan contains three
phases (non-contrast, early portal venous, and late arterial), allowing us to
perform experiments to compare our novel approach with state-of-the-art methods
for image style transfer. Our empirical results show that CyTran outperforms
all competing methods. Moreover, we show that CyTran can be employed as a
preliminary step to improve a state-of-the-art medical image alignment method.
We release our novel model and data set as open source at:
https://github.com/ristea/cycle-transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MMIU: Dataset for Visual Intent Understanding in Multimodal Assistants. (arXiv:2110.06416v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06416">
<div class="article-summary-box-inner">
<span><p>In multimodal assistant, where vision is also one of the input modalities,
the identification of user intent becomes a challenging task as visual input
can influence the outcome. Current digital assistants take spoken input and try
to determine the user intent from conversational or device context. So, a
dataset, which includes visual input (i.e. images or videos for the
corresponding questions targeted for multimodal assistant use cases, is not
readily available. The research in visual question answering (VQA) and visual
question generation (VQG) is a great step forward. However, they do not capture
questions that a visually-abled person would ask multimodal assistants.
Moreover, many times questions do not seek information from external knowledge.
In this paper, we provide a new dataset, MMIU (MultiModal Intent
Understanding), that contains questions and corresponding intents provided by
human annotators while looking at images. We, then, use this dataset for intent
classification task in multimodal digital assistant. We also experiment with
various approaches for combining vision and language features including the use
of multimodal transformer for classification of image-question pairs into 14
intents. We provide the benchmark results and discuss the role of visual and
text features for the intent classification task on our dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dense Uncertainty Estimation. (arXiv:2110.06427v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06427">
<div class="article-summary-box-inner">
<span><p>Deep neural networks can be roughly divided into deterministic neural
networks and stochastic neural networks.The former is usually trained to
achieve a mapping from input space to output space via maximum likelihood
estimation for the weights, which leads to deterministic predictions during
testing. In this way, a specific weights set is estimated while ignoring any
uncertainty that may occur in the proper weight space. The latter introduces
randomness into the framework, either by assuming a prior distribution over
model parameters (i.e. Bayesian Neural Networks) or including latent variables
(i.e. generative models) to explore the contribution of latent variables for
model predictions, leading to stochastic predictions during testing. Different
from the former that achieves point estimation, the latter aims to estimate the
prediction distribution, making it possible to estimate uncertainty,
representing model ignorance about its predictions. We claim that conventional
deterministic neural network based dense prediction tasks are prone to
overfitting, leading to over-confident predictions, which is undesirable for
decision making. In this paper, we investigate stochastic neural networks and
uncertainty estimation techniques to achieve both accurate deterministic
prediction and reliable uncertainty estimation. Specifically, we work on two
types of uncertainty estimations solutions, namely ensemble based methods and
generative model based methods, and explain their pros and cons while using
them in fully/semi/weakly-supervised framework. Due to the close connection
between uncertainty estimation and model calibration, we also introduce how
uncertainty estimation can be used for deep model calibration to achieve
well-calibrated models, namely dense model calibration. Code and data are
available at https://github.com/JingZhang617/UncertaintyEstimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-local Recurrent Regularization Networks for Multi-view Stereo. (arXiv:2110.06436v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06436">
<div class="article-summary-box-inner">
<span><p>In deep multi-view stereo networks, cost regularization is crucial to achieve
accurate depth estimation. Since 3D cost volume filtering is usually
memory-consuming, recurrent 2D cost map regularization has recently become
popular and has shown great potential in reconstructing 3D models of different
scales. However, existing recurrent methods only model the local dependencies
in the depth domain, which greatly limits the capability of capturing the
global scene context along the depth dimension. To tackle this limitation, we
propose a novel non-local recurrent regularization network for multi-view
stereo, named NR2-Net. Specifically, we design a depth attention module to
capture non-local depth interactions within a sliding depth block. Then, the
global scene context between different blocks is modeled in a gated recurrent
manner. This way, the long-range dependencies along the depth dimension are
captured to facilitate the cost regularization. Moreover, we design a dynamic
depth map fusion strategy to improve the algorithm robustness. Our method
achieves state-of-the-art reconstruction results on both DTU and Tanks and
Temples datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Harnessing the Conditioning Sensorium for Improved Image Translation. (arXiv:2110.06443v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06443">
<div class="article-summary-box-inner">
<span><p>Multi-modal domain translation typically refers to synthesizing a novel image
that inherits certain localized attributes from a 'content' image (e.g. layout,
semantics, or geometry), and inherits everything else (e.g. texture, lighting,
sometimes even semantics) from a 'style' image. The dominant approach to this
task is attempting to learn disentangled 'content' and 'style' representations
from scratch. However, this is not only challenging, but ill-posed, as what
users wish to preserve during translation varies depending on their goals.
Motivated by this inherent ambiguity, we define 'content' based on conditioning
information extracted by off-the-shelf pre-trained models. We then train our
style extractor and image decoder with an easy to optimize set of
reconstruction objectives. The wide variety of high-quality pre-trained models
available and simple training procedure makes our approach straightforward to
apply across numerous domains and definitions of 'content'. Additionally it
offers intuitive control over which aspects of 'content' are preserved across
domains. We evaluate our method on traditional, well-aligned, datasets such as
CelebA-HQ, and propose two novel datasets for evaluation on more complex
scenes: ClassicTV and FFHQ-Wild. Our approach, Sensorium, enables higher
quality domain translation for more complex scenes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing the Covariate Shift by Mirror Samples in Cross Domain Alignment. (arXiv:2110.06448v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06448">
<div class="article-summary-box-inner">
<span><p>Eliminating the covariate shift cross domains is one of the common methods to
deal with the issue of domain shift in visual unsupervised domain adaptation.
However, current alignment methods, especially the prototype based or
sample-level based methods neglect the structural properties of the underlying
distribution and even break the condition of covariate shift. To relieve the
limitations and conflicts, we introduce a novel concept named (virtual) mirror,
which represents the equivalent sample in another domain. The equivalent sample
pairs, named mirror pairs reflect the natural correspondence of the empirical
distributions. Then a mirror loss, which aligns the mirror pairs cross domains,
is constructed to enhance the alignment of the domains. The proposed method
does not distort the internal structure of the underlying distribution. We also
provide theoretical proof that the mirror samples and mirror loss have better
asymptotic properties in reducing the domain shift. By applying the virtual
mirror and mirror loss to the generic unsupervised domain adaptation model, we
achieved consistent superior performance on several mainstream benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Updating Street Maps using Changes Detected in Satellite Imagery. (arXiv:2110.06456v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06456">
<div class="article-summary-box-inner">
<span><p>Accurately maintaining digital street maps is labor-intensive. To address
this challenge, much work has studied automatically processing geospatial data
sources such as GPS trajectories and satellite images to reduce the cost of
maintaining digital maps. An end-to-end map update system would first process
geospatial data sources to extract insights, and second leverage those insights
to update and improve the map. However, prior work largely focuses on the first
step of this pipeline: these map extraction methods infer road networks from
scratch given geospatial data sources (in effect creating entirely new maps),
but do not address the second step of leveraging this extracted information to
update the existing digital map data. In this paper, we first explain why
current map extraction techniques yield low accuracy when extended to update
existing maps. We then propose a novel method that leverages the progression of
satellite imagery over time to substantially improve accuracy. Our approach
first compares satellite images captured at different times to identify
portions of the physical road network that have visibly changed, and then
updates the existing map accordingly. We show that our change-based approach
reduces map update error rates four-fold.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breaking the Dilemma of Medical Image-to-image Translation. (arXiv:2110.06465v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06465">
<div class="article-summary-box-inner">
<span><p>Supervised Pix2Pix and unsupervised Cycle-consistency are two modes that
dominate the field of medical image-to-image translation. However, neither
modes are ideal. The Pix2Pix mode has excellent performance. But it requires
paired and well pixel-wise aligned images, which may not always be achievable
due to respiratory motion or anatomy change between times that paired images
are acquired. The Cycle-consistency mode is less stringent with training data
and works well on unpaired or misaligned images. But its performance may not be
optimal. In order to break the dilemma of the existing modes, we propose a new
unsupervised mode called RegGAN for medical image-to-image translation. It is
based on the theory of "loss-correction". In RegGAN, the misaligned target
images are considered as noisy labels and the generator is trained with an
additional registration network to fit the misaligned noise distribution
adaptively. The goal is to search for the common optimal solution to both
image-to-image translation and registration tasks. We incorporated RegGAN into
a few state-of-the-art image-to-image translation methods and demonstrated that
RegGAN could be easily combined with these methods to improve their
performances. Such as a simple CycleGAN in our mode surpasses latest NICEGAN
even though using less network parameters. Based on our results, RegGAN
outperformed both Pix2Pix on aligned data and Cycle-consistency on misaligned
or unpaired data. RegGAN is insensitive to noises which makes it a better
choice for a wide range of scenarios, especially for medical image-to-image
translation tasks in which well pixel-wise aligned data are not available
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Winning the ICCV'2021 VALUE Challenge: Task-aware Ensemble and Transfer Learning with Visual Concepts. (arXiv:2110.06476v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06476">
<div class="article-summary-box-inner">
<span><p>The VALUE (Video-And-Language Understanding Evaluation) benchmark is newly
introduced to evaluate and analyze multi-modal representation learning
algorithms on three video-and-language tasks: Retrieval, QA, and Captioning.
The main objective of the VALUE challenge is to train a task-agnostic model
that is simultaneously applicable for various tasks with different
characteristics. This technical report describes our winning strategies for the
VALUE challenge: 1) single model optimization, 2) transfer learning with visual
concepts, and 3) task-aware ensemble. The first and third strategies are
designed to address heterogeneous characteristics of each task, and the second
one is to leverage rich and fine-grained visual information. We provide a
detailed and comprehensive analysis with extensive experimental results. Based
on our approach, we ranked first place on the VALUE and QA phases for the
competition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptive Semantic Segmentation without Source Data. (arXiv:2110.06484v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06484">
<div class="article-summary-box-inner">
<span><p>Domain adaptive semantic segmentation is recognized as a promising technique
to alleviate the domain shift between the labeled source domain and the
unlabeled target domain in many real-world applications, such as automatic
pilot. However, large amounts of source domain data often introduce significant
costs in storage and training, and sometimes the source data is inaccessible
due to privacy policies. To address these problems, we investigate domain
adaptive semantic segmentation without source data, which assumes that the
model is pre-trained on the source domain, and then adapting to the target
domain without accessing source data anymore. Since there is no supervision
from the source domain data, many self-training methods tend to fall into the
``winner-takes-all'' dilemma, where the {\it majority} classes totally dominate
the segmentation networks and the networks fail to classify the {\it minority}
classes. Consequently, we propose an effective framework for this challenging
problem with two components: positive learning and negative learning. In
positive learning, we select the class-balanced pseudo-labeled pixels with
intra-class threshold, while in negative learning, for each pixel, we
investigate which category the pixel does not belong to with the proposed
heuristic complementary label selection. Notably, our framework can be easily
implemented and incorporated with other methods to further enhance the
performance. Extensive experiments on two widely-used synthetic-to-real
benchmarks demonstrate our claims and the effectiveness of our framework, which
outperforms the baseline with a large margin. Code is available at
\url{https://github.com/fumyou13/LDBE}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding of Emotion Perception from Art. (arXiv:2110.06486v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06486">
<div class="article-summary-box-inner">
<span><p>Computational modeling of the emotions evoked by art in humans is a
challenging problem because of the subjective and nuanced nature of art and
affective signals. In this paper, we consider the above-mentioned problem of
understanding emotions evoked in viewers by artwork using both text and visual
modalities. Specifically, we analyze images and the accompanying text captions
from the viewers expressing emotions as a multimodal classification task. Our
results show that single-stream multimodal transformer-based models like MMBT
and VisualBERT perform better compared to both image-only models and
dual-stream multimodal models having separate pathways for text and image
modalities. We also observe improvements in performance for extreme positive
and negative emotion classes, when a single-stream model like MMBT is compared
with a text-only transformer model like BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Dawn of Quantum Natural Language Processing. (arXiv:2110.06510v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06510">
<div class="article-summary-box-inner">
<span><p>In this paper, we discuss the initial attempts at boosting understanding
human language based on deep-learning models with quantum computing. We
successfully train a quantum-enhanced Long Short-Term Memory network to perform
the parts-of-speech tagging task via numerical simulations. Moreover, a
quantum-enhanced Transformer is proposed to perform the sentiment analysis
based on the existing dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MedNet: Pre-trained Convolutional Neural Network Model for the Medical Imaging Tasks. (arXiv:2110.06512v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06512">
<div class="article-summary-box-inner">
<span><p>Deep Learning (DL) requires a large amount of training data to provide
quality outcomes. However, the field of medical imaging suffers from the lack
of sufficient data for properly training DL models because medical images
require manual labelling carried out by clinical experts thus the process is
time-consuming, expensive, and error-prone. Recently, transfer learning (TL)
was introduced to reduce the need for the annotation procedure by means of
transferring the knowledge performed by a previous task and then fine-tuning
the result using a relatively small dataset. Nowadays, multiple classification
methods from medical imaging make use of TL from general-purpose pre-trained
models, e.g., ImageNet, which has been proven to be ineffective due to the
mismatch between the features learned from natural images (ImageNet) and those
more specific from medical images especially medical gray images such as
X-rays. ImageNet does not have grayscale images such as MRI, CT, and X-ray. In
this paper, we propose a novel DL model to be used for addressing
classification tasks of medical imaging, called MedNet. To do so, we aim to
issue two versions of MedNet. The first one is Gray-MedNet which will be
trained on 3M publicly available gray-scale medical images including MRI, CT,
X-ray, ultrasound, and PET. The second version is Color-MedNet which will be
trained on 3M publicly available color medical images including histopathology,
taken images, and many others. To validate the effectiveness MedNet, both
versions will be fine-tuned to train on the target tasks of a more reduced set
of medical images. MedNet performs as the pre-trained model to tackle any
real-world application from medical imaging and achieve the level of
generalization needed for dealing with medical imaging tasks, e.g.
classification. MedNet would serve the research community as a baseline for
future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking the Robustness of Spatial-Temporal Models Against Corruptions. (arXiv:2110.06513v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06513">
<div class="article-summary-box-inner">
<span><p>The state-of-the-art deep neural networks are vulnerable to common
corruptions (e.g., input data degradations, distortions, and disturbances
caused by weather changes, system error, and processing). While much progress
has been made in analyzing and improving the robustness of models in image
understanding, the robustness in video understanding is largely unexplored. In
this paper, we establish a corruption robustness benchmark, Mini Kinetics-C and
Mini SSV2-C, which considers temporal corruptions beyond spatial corruptions in
images. We make the first attempt to conduct an exhaustive study on the
corruption robustness of established CNN-based and Transformer-based
spatial-temporal models. The study provides some guidance on robust model
design and training: Transformer-based model performs better than CNN-based
models on corruption robustness; the generalization ability of spatial-temporal
models implies robustness against temporal corruptions; model corruption
robustness (especially robustness in the temporal domain) enhances with
computational cost and model capacity, which may contradict the current trend
of improving the computational efficiency of models. Moreover, we find the
robustness intervention for image-related tasks (e.g., training models with
noise) may not work for spatial-temporal models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">2D Multi-Class Model for Gray and White Matter Segmentation of the Cervical Spinal Cord at 7T. (arXiv:2110.06516v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06516">
<div class="article-summary-box-inner">
<span><p>The spinal cord (SC), which conveys information between the brain and the
peripheral nervous system, plays a key role in various neurological disorders
such as multiple sclerosis (MS) and amyotrophic lateral sclerosis (ALS), in
which both gray matter (GM) and white matter (WM) may be impaired. While
automated methods for WM/GM segmentation are now largely available, these
techniques, developed for conventional systems (3T or lower) do not necessarily
perform well on 7T MRI data, which feature finer details, contrasts, but also
different artifacts or signal dropout.
</p>
<p>The primary goal of this study is thus to propose a new deep learning model
that allows robust SC/GM multi-class segmentation based on ultra-high
resolution 7T T2*-w MR images. The second objective is to highlight the
relevance of implementing a specific data augmentation (DA) strategy, in
particular to generate a generic model that could be used for multi-center
studies at 7T.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing Information Bottleneck for Weakly Supervised Semantic Segmentation. (arXiv:2110.06530v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06530">
<div class="article-summary-box-inner">
<span><p>Weakly supervised semantic segmentation produces pixel-level localization
from class labels; however, a classifier trained on such labels is likely to
focus on a small discriminative region of the target object. We interpret this
phenomenon using the information bottleneck principle: the final layer of a
deep neural network, activated by the sigmoid or softmax activation functions,
causes an information bottleneck, and as a result, only a subset of the
task-relevant information is passed on to the output. We first support this
argument through a simulated toy experiment and then propose a method to reduce
the information bottleneck by removing the last activation function. In
addition, we introduce a new pooling method that further encourages the
transmission of information from non-discriminative regions to the
classification. Our experimental evaluations demonstrate that this simple
modification significantly improves the quality of localization maps on both
the PASCAL VOC 2012 and MS COCO 2014 datasets, exhibiting a new
state-of-the-art performance for weakly supervised semantic segmentation. The
code is available at: https://github.com/jbeomlee93/RIB.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Well-classified Examples are Underestimated in Classification with Deep Neural Networks. (arXiv:2110.06537v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06537">
<div class="article-summary-box-inner">
<span><p>The conventional wisdom behind learning deep classification models is to
focus on bad-classified examples and ignore well-classified examples that are
far from the decision boundary. For instance, when training with cross-entropy
loss, examples with higher likelihoods (i.e., well-classified examples)
contribute smaller gradients in back-propagation. However, we theoretically
show that this common practice hinders representation learning, energy
optimization, and the growth of margin. To counteract this deficiency, we
propose to reward well-classified examples with additive bonuses to revive
their contribution to learning. This counterexample theoretically addresses
these three issues. We empirically support this claim by directly verify the
theoretical results or through the significant performance improvement with our
counterexample on diverse tasks, including image classification, graph
classification, and machine translation. Furthermore, this paper shows that
because our idea can solve these three issues, we can deal with complex
scenarios, such as imbalanced classification, OOD detection, and applications
under adversarial attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Saliency Detection via Global Context Enhanced Feature Fusion and Edge Weighted Loss. (arXiv:2110.06550v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06550">
<div class="article-summary-box-inner">
<span><p>UNet-based methods have shown outstanding performance in salient object
detection (SOD), but are problematic in two aspects. 1) Indiscriminately
integrating the encoder feature, which contains spatial information for
multiple objects, and the decoder feature, which contains global information of
the salient object, is likely to convey unnecessary details of non-salient
objects to the decoder, hindering saliency detection. 2) To deal with ambiguous
object boundaries and generate accurate saliency maps, the model needs
additional branches, such as edge reconstructions, which leads to increasing
computational cost. To address the problems, we propose a context fusion
decoder network (CFDN) and near edge weighted loss (NEWLoss) function. The CFDN
creates an accurate saliency map by integrating global context information and
thus suppressing the influence of the unnecessary spatial information. NEWLoss
accelerates learning of obscure boundaries without additional modules by
generating weight maps on object boundaries. Our method is evaluated on four
benchmarks and achieves state-of-the-art performance. We prove the
effectiveness of the proposed method through comparative experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Mixed-Precision Quantization of Neural Networks via Constrained Optimization. (arXiv:2110.06554v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06554">
<div class="article-summary-box-inner">
<span><p>Quantization is a widely used technique to compress and accelerate deep
neural networks. However, conventional quantization methods use the same
bit-width for all (or most of) the layers, which often suffer significant
accuracy degradation in the ultra-low precision regime and ignore the fact that
emergent hardware accelerators begin to support mixed-precision computation.
Consequently, we present a novel and principled framework to solve the
mixed-precision quantization problem in this paper. Briefly speaking, we first
formulate the mixed-precision quantization as a discrete constrained
optimization problem. Then, to make the optimization tractable, we approximate
the objective function with second-order Taylor expansion and propose an
efficient approach to compute its Hessian matrix. Finally, based on the above
simplification, we show that the original problem can be reformulated as a
Multiple-Choice Knapsack Problem (MCKP) and propose a greedy search algorithm
to solve it efficiently. Compared with existing mixed-precision quantization
works, our method is derived in a principled way and much more computationally
efficient. Moreover, extensive experiments conducted on the ImageNet dataset
and various kinds of network architectures also demonstrate its superiority
over existing uniform and mixed-precision quantization approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LENS: Localization enhanced by NeRF synthesis. (arXiv:2110.06558v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06558">
<div class="article-summary-box-inner">
<span><p>Neural Radiance Fields (NeRF) have recently demonstrated photo-realistic
results for the task of novel view synthesis. In this paper, we propose to
apply novel view synthesis to the robot relocalization problem: we demonstrate
improvement of camera pose regression thanks to an additional synthetic dataset
rendered by the NeRF class of algorithm. To avoid spawning novel views in
irrelevant places we selected virtual camera locations from NeRF internal
representation of the 3D geometry of the scene. We further improved
localization accuracy of pose regressors using synthesized realistic and
geometry consistent images as data augmentation during training. At the time of
publication, our approach improved state of the art with a 60% lower error on
Cambridge Landmarks and 7-scenes datasets. Hence, the resulting accuracy
becomes comparable to structure-based methods, without any architecture
modification or domain adaptation constraints. Since our method allows almost
infinite generation of training data, we investigated limitations of camera
pose regression depending on size and distribution of data used for training on
public benchmarks. We concluded that pose regression accuracy is mostly bounded
by relatively small and biased datasets rather than capacity of the pose
regression model to solve the localization task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Object Learning via Common Fate. (arXiv:2110.06562v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06562">
<div class="article-summary-box-inner">
<span><p>Learning generative object models from unlabelled videos is a long standing
problem and required for causal scene modeling. We decompose this problem into
three easier subtasks, and provide candidate solutions for each of them.
Inspired by the Common Fate Principle of Gestalt Psychology, we first extract
(noisy) masks of moving objects via unsupervised motion segmentation. Second,
generative models are trained on the masks of the background and the moving
objects, respectively. Third, background and foreground models are combined in
a conditional "dead leaves" scene model to sample novel scene configurations
where occlusions and depth layering arise naturally. To evaluate the individual
stages, we introduce the Fishbowl dataset positioned between complex real-world
scenes and common object-centric benchmarks of simplistic objects. We show that
our approach allows learning generative models that generalize beyond the
occlusions present in the input videos, and represent scenes in a modular
fashion that allows sampling plausible scenes outside the training distribution
by permitting, for instance, object numbers or densities not observed in the
training set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Superpixel-based Network for Blind Image Quality Assessment. (arXiv:2110.06564v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06564">
<div class="article-summary-box-inner">
<span><p>The goal in a blind image quality assessment (BIQA) model is to simulate the
process of evaluating images by human eyes and accurately assess the quality of
the image. Although many approaches effectively identify degradation, they do
not fully consider the semantic content in images resulting in distortion. In
order to fill this gap, we propose a deep adaptive superpixel-based network,
namely DSN-IQA, to assess the quality of image based on multi-scale and
superpixel segmentation. The DSN-IQA can adaptively accept arbitrary scale
images as input images, making the assessment process similar to human
perception. The network uses two models to extract multi-scale semantic
features and generate a superpixel adjacency map. These two elements are united
together via feature fusion to accurately predict image quality. Experimental
results on different benchmark databases demonstrate that our algorithm is
highly competitive with other approaches when assessing challenging authentic
image databases. Also, due to adaptive deep superpixel-based network, our model
accurately assesses images with complicated distortion, much like the human
eye.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyperspectral 3D Mapping of Underwater Environments. (arXiv:2110.06571v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06571">
<div class="article-summary-box-inner">
<span><p>Hyperspectral imaging has been increasingly used for underwater survey
applications over the past years. As many hyperspectral cameras work as
push-broom scanners, their use is usually limited to the creation of
photo-mosaics based on a flat surface approximation and by interpolating the
camera pose from dead-reckoning navigation. Yet, because of drift in the
navigation and the mostly wrong flat surface assumption, the quality of the
obtained photo-mosaics is often too low to support adequate analysis.In this
paper we present an initial method for creating hyperspectral 3D
reconstructions of underwater environments. By fusing the data gathered by a
classical RGB camera, an inertial navigation system and a hyperspectral
push-broom camera, we show that the proposed method creates highly accurate 3D
reconstructions with hyperspectral textures. We propose to combine techniques
from simultaneous localization and mapping, structure-from-motion and 3D
reconstruction and advantageously use them to create 3D models with
hyperspectral texture, allowing us to overcome the flat surface assumption and
the classical limitation of dead-reckoning navigation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Life is not black and white -- Combining Semi-Supervised Learning with fuzzy labels. (arXiv:2110.06592v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06592">
<div class="article-summary-box-inner">
<span><p>The required amount of labeled data is one of the biggest issues in deep
learning. Semi-Supervised Learning can potentially solve this issue by using
additional unlabeled data. However, many datasets suffer from variability in
the annotations. The aggregated labels from these annotation are not consistent
between different annotators and thus are considered fuzzy. These fuzzy labels
are often not considered by Semi-Supervised Learning. This leads either to an
inferior performance or to higher initial annotation costs in the complete
machine learning development cycle. We envision the incorporation of fuzzy
labels into Semi-Supervised Learning and give a proof-of-concept of the
potential lower costs and higher consistency in the complete development cycle.
As part of our concept, we discuss current limitations, futures research
opportunities and potential broad impacts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling. (arXiv:2110.06607v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06607">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose THOMAS, a joint multi-agent trajectory prediction
framework allowing for efficient and consistent prediction of multi-agent
multi-modal trajectories. We present a unified model architecture for fast and
simultaneous agent future heatmap estimation leveraging hierarchical and sparse
image generation. We demonstrate that heatmap output enables a higher level of
control on the predicted trajectories compared to vanilla multi-modal
trajectory regression, allowing to incorporate additional constraints for
tighter sampling or collision-free predictions in a deterministic way. However,
we also highlight that generating scene-consistent predictions goes beyond the
mere generation of collision-free trajectories. We therefore propose a
learnable trajectory recombination model that takes as input a set of predicted
trajectories for each agent and outputs its consistent reordered recombination.
We report our results on the Interaction multi-agent prediction challenge and
rank $1^{st}$ on the online test leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLIP4Caption: CLIP for Video Caption. (arXiv:2110.06615v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06615">
<div class="article-summary-box-inner">
<span><p>Video captioning is a challenging task since it requires generating sentences
describing various diverse and complex videos. Existing video captioning models
lack adequate visual representation due to the neglect of the existence of gaps
between videos and texts. To bridge this gap, in this paper, we propose a
CLIP4Caption framework that improves video captioning based on a CLIP-enhanced
video-text matching network (VTM). This framework is taking full advantage of
the information from both vision and language and enforcing the model to learn
strongly text-correlated video features for text generation. Besides, unlike
most existing models using LSTM or GRU as the sentence decoder, we adopt a
Transformer structured decoder network to effectively learn the long-range
visual and language dependency. Additionally, we introduce a novel ensemble
strategy for captioning tasks. Experimental results demonstrate the
effectiveness of our method on two datasets: 1) on MSR-VTT dataset, our method
achieved a new state-of-the-art result with a significant gain of up to 10% in
CIDEr; 2) on the private test data, our method ranking 2nd place in the ACM MM
multimedia grand challenge 2021: Pre-training for Video Understanding
Challenge. It is noted that our model is only trained on the MSR-VTT dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Oriented Feature Alignment for Fine-grained Object Recognition in High-Resolution Satellite Imagery. (arXiv:2110.06628v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06628">
<div class="article-summary-box-inner">
<span><p>Oriented object detection in remote sensing images has made great progress in
recent years. However, most of the current methods only focus on detecting
targets, and cannot distinguish fine-grained objects well in complex scenes. In
this technical report, we analyzed the key issues of fine-grained object
recognition, and use an oriented feature alignment network (OFA-Net) to achieve
high-performance fine-grained oriented object recognition in optical remote
sensing images. OFA-Net achieves accurate object localization through a rotated
bounding boxes refinement module. On this basis, the boundary-constrained
rotation feature alignment module is applied to achieve local feature
extraction, which is beneficial to fine-grained object classification. The
single model of our method achieved mAP of 46.51\% in the GaoFen competition
and won 3rd place in the ISPRS benchmark with the mAP of 43.73\%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fuzzy Overclustering: Semi-Supervised Classification of Fuzzy Labels with Overclustering and Inverse Cross-Entropy. (arXiv:2110.06630v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06630">
<div class="article-summary-box-inner">
<span><p>Deep learning has been successfully applied to many classification problems
including underwater challenges. However, a long-standing issue with deep
learning is the need for large and consistently labeled datasets. Although
current approaches in semi-supervised learning can decrease the required amount
of annotated data by a factor of 10 or even more, this line of research still
uses distinct classes. For underwater classification, and uncurated real-world
datasets in general, clean class boundaries can often not be given due to a
limited information content in the images and transitional stages of the
depicted objects. This leads to different experts having different opinions and
thus producing fuzzy labels which could also be considered ambiguous or
divergent. We propose a novel framework for handling semi-supervised
classifications of such fuzzy labels. It is based on the idea of overclustering
to detect substructures in these fuzzy labels. We propose a novel loss to
improve the overclustering capability of our framework and show the benefit of
overclustering for fuzzy labels. We show that our framework is superior to
previous state-of-the-art semi-supervised methods when applied to real-world
plankton data with fuzzy labels. Moreover, we acquire 5 to 10\% more consistent
predictions of substructures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Representation Learning for 3D Point Cloud Data. (arXiv:2110.06632v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06632">
<div class="article-summary-box-inner">
<span><p>Though a number of point cloud learning methods have been proposed to handle
unordered points, most of them are supervised and require labels for training.
By contrast, unsupervised learning of point cloud data has received much less
attention to date. In this paper, we propose a simple yet effective approach
for unsupervised point cloud learning. In particular, we identify a very useful
transformation which generates a good contrastive version of an original point
cloud. They make up a pair. After going through a shared encoder and a shared
head network, the consistency between the output representations are maximized
with introducing two variants of contrastive losses to respectively facilitate
downstream classification and segmentation. To demonstrate the efficacy of our
method, we conduct experiments on three downstream tasks which are 3D object
classification (on ModelNet40 and ModelNet10), shape part segmentation (on
ShapeNet Part dataset) as well as scene segmentation (on S3DIS). Comprehensive
results show that our unsupervised contrastive representation learning enables
impressive outcomes in object classification and semantic segmentation. It
generally outperforms current unsupervised methods, and even achieves
comparable performance to supervised methods. Our source codes will be made
publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ADOP: Approximate Differentiable One-Pixel Point Rendering. (arXiv:2110.06635v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06635">
<div class="article-summary-box-inner">
<span><p>We present a novel point-based, differentiable neural rendering pipeline for
scene refinement and novel view synthesis. The input are an initial estimate of
the point cloud and the camera parameters. The output are synthesized images
from arbitrary camera poses. The point cloud rendering is performed by a
differentiable renderer using multi-resolution one-pixel point rasterization.
Spatial gradients of the discrete rasterization are approximated by the novel
concept of ghost geometry. After rendering, the neural image pyramid is passed
through a deep neural network for shading calculations and hole-filling. A
differentiable, physically-based tonemapper then converts the intermediate
output to the target image. Since all stages of the pipeline are
differentiable, we optimize all of the scene's parameters i.e. camera model,
camera pose, point position, point color, environment map, rendering network
weights, vignetting, camera response function, per image exposure, and per
image white balance. We show that our system is able to synthesize sharper and
more consistent novel views than existing approaches because the initial
reconstruction is refined during training. The efficient one-pixel point
rasterization allows us to use arbitrary camera models and display scenes with
well over 100M points in real time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Slag Formations with Deep Convolutional Neural Networks. (arXiv:2110.06640v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06640">
<div class="article-summary-box-inner">
<span><p>We investigate the ability to detect slag formations in images from inside a
Grate-Kiln system furnace with two deep convolutional neural networks. The
conditions inside the furnace cause occasional obstructions of the camera view.
Our approach suggests dealing with this problem by introducing a convLSTM-layer
in the deep convolutional neural network. The results show that it is possible
to achieve sufficient performance to automate the decision of timely
countermeasures in the industrial operational setting. Furthermore, the
addition of the convLSTM-layer results in fewer outlying predictions and a
lower running variance of the fraction of detected slag in the image time
series.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EditVAE: Unsupervised Part-Aware Controllable 3D Point Cloud Shape Generation. (arXiv:2110.06679v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06679">
<div class="article-summary-box-inner">
<span><p>This paper tackles the problem of parts-aware point cloud generation. Unlike
existing works which require the point cloud to be segmented into parts a
priori, our parts-aware editing and generation is performed in an unsupervised
manner. We achieve this with a simple modification of the Variational
Auto-Encoder which yields a joint model of the point cloud itself along with a
schematic representation of it as a combination of shape primitives. In
particular, we introduce a latent representation of the point cloud which can
be decomposed into a disentangled representation for each part of the shape.
These parts are in turn disentangled into both a shape primitive and a point
cloud representation, along with a standardising transformation to a canonical
coordinate system. The dependencies between our standardising transformations
preserve the spatial dependencies between the parts in a manner which allows
meaningful parts-aware point cloud generation and shape editing. In addition to
the flexibility afforded by our disentangled representation, the inductive bias
introduced by our joint modelling approach yields the state-of-the-art
experimental results on the ShapeNet dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Color Counting for Fashion, Art, and Design. (arXiv:2110.06682v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06682">
<div class="article-summary-box-inner">
<span><p>Color modelling and extraction is an important topic in fashion, art, and
design. Recommender systems, color-based retrieval, decorating, and fashion
design can benefit from color extraction tools. Research has shown that
modeling color so that it can be automatically analyzed and / or extracted is a
difficult task. Unlike machines, color perception, although very subjective, is
much simpler for humans. That being said, the first step in color modeling is
to estimate the number of colors in the item / object. This is because color
models can take advantage of the number of colors as the seed for better
modelling, e.g., to make color extraction further deterministic. We aim in this
work to develop and test models that can count the number of colors of clothing
and other items. We propose a novel color counting method based on cumulative
color histogram, which stands out among other methods. We compare the method we
propose with other methods that utilize exhaustive color search that uses
Gaussian Mixture Models (GMMs) and K-Means as bases for scoring the optimal
number of colors, in addition to another method that relies on deep learning
models. Unfortunately, the GMM, K-Means, and Deep Learning models all fail to
accurately capture the number of colors. Our proposed method can provide the
color baseline that can be used in AI-based fashion applications, and can also
find applications in other areas, for example, interior design. To the best of
our knowledge, this work is the first of its kind that addresses the problem of
color-counting machine.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plugging Self-Supervised Monocular Depth into Unsupervised Domain Adaptation for Semantic Segmentation. (arXiv:2110.06685v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06685">
<div class="article-summary-box-inner">
<span><p>Although recent semantic segmentation methods have made remarkable progress,
they still rely on large amounts of annotated training data, which are often
infeasible to collect in the autonomous driving scenario. Previous works
usually tackle this issue with Unsupervised Domain Adaptation (UDA), which
entails training a network on synthetic images and applying the model to real
ones while minimizing the discrepancy between the two domains. Yet, these
techniques do not consider additional information that may be obtained from
other tasks. Differently, we propose to exploit self-supervised monocular depth
estimation to improve UDA for semantic segmentation. On one hand, we deploy
depth to realize a plug-in component which can inject complementary geometric
cues into any existing UDA method. We further rely on depth to generate a large
and varied set of samples to Self-Train the final model. Our whole proposal
allows for achieving state-of-the-art performance (58.8 mIoU) in the GTA5-&gt;CS
benchmark benchmark. Code is available at
https://github.com/CVLAB-Unibo/d4-dbst.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepVecFont: Synthesizing High-quality Vector Fonts via Dual-modality Learning. (arXiv:2110.06688v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06688">
<div class="article-summary-box-inner">
<span><p>Automatic font generation based on deep learning has aroused a lot of
interest in the last decade. However, only a few recently-reported approaches
are capable of directly generating vector glyphs and their results are still
far from satisfactory. In this paper, we propose a novel method, DeepVecFont,
to effectively resolve this problem. Using our method, for the first time,
visually-pleasing vector glyphs whose quality and compactness are both
comparable to human-designed ones can be automatically generated. The key idea
of our DeepVecFont is to adopt the techniques of image synthesis, sequence
modeling and differentiable rasterization to exhaustively exploit the
dual-modality information (i.e., raster images and vector outlines) of vector
fonts. The highlights of this paper are threefold. First, we design a
dual-modality learning strategy which utilizes both image-aspect and
sequence-aspect features of fonts to synthesize vector glyphs. Second, we
provide a new generative paradigm to handle unstructured data (e.g., vector
glyphs) by randomly sampling plausible synthesis results to get the optimal one
which is further refined under the guidance of generated structured data (e.g.,
glyph images). Finally, qualitative and quantitative experiments conducted on a
publicly-available dataset demonstrate that our method obtains high-quality
synthesis results in the applications of vector font generation and
interpolation, significantly outperforming the state of the art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Image Fusion. (arXiv:2110.06697v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06697">
<div class="article-summary-box-inner">
<span><p>Image fusion methods and metrics for their evaluation have conventionally
used pixel-based or low-level features. However, for many applications, the aim
of image fusion is to effectively combine the semantic content of the input
images. This paper proposes a novel system for the semantic combination of
visual content using pre-trained CNN network architectures. Our proposed
semantic fusion is initiated through the fusion of the top layer feature map
outputs (for each input image)through gradient updating of the fused image
input (so-called image optimisation). Simple "choose maximum" and "local
majority" filter based fusion rules are utilised for feature map fusion. This
provides a simple method to combine layer outputs and thus a unique framework
to fuse single-channel and colour images within a decomposition pre-trained for
classification and therefore aligned with semantic fusion. Furthermore, class
activation mappings of each input image are used to combine semantic
information at a higher level. The developed methods are able to give
equivalent low-level fusion performance to state of the art methods while
providing a unique architecture to combine semantic information from multiple
images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Computerized Classification of Micro-Motions in the Hand using Waveforms from Mobile Phone. (arXiv:2110.06723v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06723">
<div class="article-summary-box-inner">
<span><p>Our hands reveal important information such as the pulsing of our veins which
help us determine the blood pressure, tremors indicative of motor control, or
neurodegenerative disorders such as Essential Tremor or Parkinson's disease.
The Computerized Classification of Micro-Motions in the hand using waveforms
from mobile phone videos is a novel method that uses Eulerian Video
Magnification, Skeletonization, Heatmapping, and the kNN machine learning model
to detect the micro-motions in the human hand, synthesize their waveforms, and
classify these. The pre-processing is achieved by using Eulerian Video
Magnification, Skeletonization, and Heat-mapping to magnify the micro-motions,
landmark essential features of the hand, and determine the extent of motion,
respectively. Following pre-processing, the visible motions are manually
labeled by appropriately grouping pixels to represent a particular label
correctly. These labeled motions of the pixels are converted into waveforms.
Finally, these waveforms are classified into four categories - hand or finger
movements, vein movement, background motion, and movement of the rest of the
body due to respiration using the kNN model. The final accuracy obtained was
around 92 percent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RelationRS: Relationship Representation Network for Object Detection in Aerial Images. (arXiv:2110.06730v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06730">
<div class="article-summary-box-inner">
<span><p>Object detection is a basic and important task in the field of aerial image
processing and has gained much attention in computer vision. However, previous
aerial image object detection approaches have insufficient use of scene
semantic information between different regions of large-scale aerial images. In
addition, complex background and scale changes make it difficult to improve
detection accuracy. To address these issues, we propose a relationship
representation network for object detection in aerial images (RelationRS): 1)
Firstly, multi-scale features are fused and enhanced by a dual relationship
module (DRM) with conditional convolution. The dual relationship module learns
the potential relationship between features of different scales and learns the
relationship between different scenes from different patches in a same
iteration. In addition, the dual relationship module dynamically generates
parameters to guide the fusion of multi-scale features. 2) Secondly, The
bridging visual representations module (BVR) is introduced into the field of
aerial images to improve the object detection effect in images with complex
backgrounds. Experiments with a publicly available object detection dataset for
aerial images demonstrate that the proposed RelationRS achieves a
state-of-the-art detection performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collaborative Semantic Aggregation and Calibration for Separated Domain Generalization. (arXiv:2110.06736v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06736">
<div class="article-summary-box-inner">
<span><p>Domain generalization (DG) aims to learn from multiple known source domains a
model that can generalize well to unknown target domains. The existing DG
methods usually rely on shared multi-source data fusion for generalizable model
training. However, tremendous data is distributed across lots of places
nowadays that can not be shared due to privacy policies, especially in some
crucial areas like finance and medical care. A dilemma is thus raised between
real-world data privacy protection and simultaneous multi-source semantic
learning with the shared data. In this paper, we investigate a separated domain
generalization task with separated source datasets that can only be used
locally, which is vital for real-world privacy protection. We propose a novel
solution called Collaborative Semantic Aggregation and Calibration (CSAC) to
enable this challenging task. To fully absorb multi-source semantic information
while avoiding unsafe data fusion, we first conduct data-free semantic
aggregation by fusing the models trained on the separated domains
layer-by-layer. To address semantic dislocation caused by domain shift, we
further design cross-layer semantic calibration with an attention mechanism to
align each semantic level and enhance domain invariance. We unify multi-source
semantic learning and alignment in a collaborative way by repeating the
semantic aggregation and calibration alternately, keeping each dataset
localized, and privacy is thus carefully protected. Extensive experiments show
the significant performance of our method in addressing this challenging task,
which is even comparable to the previous DG methods with shared data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transform and Bitstream Domain Image Classification. (arXiv:2110.06740v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06740">
<div class="article-summary-box-inner">
<span><p>Classification of images within the compressed domain offers significant
benefits. These benefits include reduced memory and computational requirements
of a classification system. This paper proposes two such methods as a proof of
concept: The first classifies within the JPEG image transform domain (i.e. DCT
transform data); the second classifies the JPEG compressed binary bitstream
directly. These two methods are implemented using Residual Network CNNs and an
adapted Vision Transformer. Top-1 accuracy of approximately 70% and 60% were
achieved using these methods respectively when classifying the Caltech C101
database. Although these results are significantly behind the state of the art
for classification for this database (~95%), it illustrates the first time
direct bitstream image classification has been achieved. This work confirms
that direct bitstream image classification is possible and could be utilised in
a first pass database screening of a raw bitstream (within a wired or wireless
network) or where computational, memory and bandwidth requirements are severely
restricted.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Meta Pattern for Face Anti-Spoofing. (arXiv:2110.06753v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06753">
<div class="article-summary-box-inner">
<span><p>Face Anti-Spoofing (FAS) is essential to secure face recognition systems and
has been extensively studied in recent years. Although deep neural networks
(DNNs) for the FAS task have achieved promising results in intra-dataset
experiments with similar distributions of training and testing data, the DNNs'
generalization ability is limited under the cross-domain scenarios with
different distributions of training and testing data. To improve the
generalization ability, recent hybrid methods have been explored to extract
task-aware handcrafted features (e.g., Local Binary Pattern) as discriminative
information for the input of DNNs. However, the handcrafted feature extraction
relies on experts' domain knowledge, and how to choose appropriate handcrafted
features is underexplored. To this end, we propose a learnable network to
extract Meta Pattern (MP) in our learning-to-learn framework. By replacing
handcrafted features with the MP, the discriminative information from MP is
capable of learning a more generalized model. Moreover, we devise a two-stream
network to hierarchically fuse the input RGB image and the extracted MP by
using our proposed Hierarchical Fusion Module (HFM). We conduct comprehensive
experiments and show that our MP outperforms the compared handcrafted features.
Also, our proposed method with HFM and the MP can achieve state-of-the-art
performance on two different domain generalization evaluation benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optical-Flow-Reuse-Based Bidirectional Recurrent Network for Space-Time Video Super-Resolution. (arXiv:2110.06786v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06786">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider the task of space-time video super-resolution
(ST-VSR), which simultaneously increases the spatial resolution and frame rate
for a given video. However, existing methods typically suffer from difficulties
in how to efficiently leverage information from a large range of neighboring
frames or avoiding the speed degradation in the inference using deformable
ConvLSTM strategies for alignment. % Some recent LSTM-based ST-VSR methods have
achieved promising results. To solve the above problem of the existing methods,
we propose a coarse-to-fine bidirectional recurrent neural network instead of
using ConvLSTM to leverage knowledge between adjacent frames. Specifically, we
first use bi-directional optical flow to update the hidden state and then
employ a Feature Refinement Module (FRM) to refine the result. Since we could
fully utilize a large range of neighboring frames, our method leverages local
and global information more effectively. In addition, we propose an optical
flow-reuse strategy that can reuse the intermediate flow of adjacent frames,
which considerably reduces the computation burden of frame alignment compared
with existing LSTM-based designs. Extensive experiments demonstrate that our
optical-flow-reuse-based bidirectional recurrent network(OFR-BRN) is superior
to the state-of-the-art methods both in terms of accuracy and efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Layout Generation Algorithm of Graphic Design Based on Transformer-CVAE. (arXiv:2110.06794v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06794">
<div class="article-summary-box-inner">
<span><p>Graphic design is ubiquitous in people's daily lives. For graphic design, the
most time-consuming task is laying out various components in the interface.
Repetitive manual layout design will waste a lot of time for professional
graphic designers. Existing templates are usually rudimentary and not suitable
for most designs, reducing efficiency and limiting creativity. This paper
implemented the Transformer model and conditional variational autoencoder
(CVAE) to the graphic design layout generation task. It proposed an end-to-end
graphic design layout generation model named LayoutT-CVAE. We also proposed
element disentanglement and feature-based disentanglement strategies and
introduce new graphic design principles and similarity metrics into the model,
which significantly increased the controllability and interpretability of the
deep model. Compared with the existing state-of-art models, the layout
generated by ours performs better on many metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identification of Attack-Specific Signatures in Adversarial Examples. (arXiv:2110.06802v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06802">
<div class="article-summary-box-inner">
<span><p>The adversarial attack literature contains a myriad of algorithms for
crafting perturbations which yield pathological behavior in neural networks. In
many cases, multiple algorithms target the same tasks and even enforce the same
constraints. In this work, we show that different attack algorithms produce
adversarial examples which are distinct not only in their effectiveness but
also in how they qualitatively affect their victims. We begin by demonstrating
that one can determine the attack algorithm that crafted an adversarial
example. Then, we leverage recent advances in parameter-space saliency maps to
show, both visually and quantitatively, that adversarial attack algorithms
differ in which parts of the network and image they target. Our findings
suggest that prospective adversarial attacks should be compared not only via
their success rates at fooling models but also via deeper downstream effects
they have on victims.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learn to Ignore: Domain Adaptation for Multi-Site MRI Analysis. (arXiv:2110.06803v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06803">
<div class="article-summary-box-inner">
<span><p>Limited availability of large image datasets is a major issue in the
development of accurate and generalizable machine learning methods in medicine.
The limitations in the amount of data are mainly due to the use of different
acquisition protocols, different hardware, and data privacy. At the same time,
training a classification model on a small dataset leads to a poor
generalization quality of the model. To overcome this issue, a combination of
various image datasets of different provenance is often used, e.g., multi-site
studies. However, if an additional dataset does not include all classes of the
task, the learning of the classification model can be biased to the device or
place of acquisition.
</p>
<p>This is especially the case for Magnetic Resonance (MR) images, where
different MR scanners introduce a bias that limits the performance of the
model. In this paper, we present a novel method that learns to ignore the
scanner-related features present in the images, while learning features
relevant for the classification task. We focus on a real-world scenario, where
only a small dataset provides images of all classes. We exploit this
circumstance by introducing specific additional constraints on the latent
space, which lead the focus on disease-related rather than scanner-specific
features. Our method Learn to Ignore outperforms state-of-the-art domain
adaptation methods on a multi-site MRI dataset on a classification task between
Multiple Sclerosis patients and healthy subjects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A comprehensive review of Binary Neural Network. (arXiv:2110.06804v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06804">
<div class="article-summary-box-inner">
<span><p>Binary Neural Network (BNN) method is an extreme application of convolutional
neural network (CNN) parameter quantization. As opposed to the original CNN
methods which employed floating-point computation with full-precision weights
and activations, BBN uses 1-bit activations and weights. With BBNs, a
significant amount of storage, network complexity and energy consumption can be
reduced, and neural networks can be implemented more efficiently in embedded
applications. Unfortunately, binarization causes severe information loss. A gap
still exists between full-precision CNN models and their binarized
counterparts. The recent developments in BNN have led to a lot of algorithms
and solutions that have helped address this issue. This article provides a full
overview of recent developments in BNN. The present paper focuses exclusively
on 1-bit activations and weights networks, as opposed to previous surveys in
which low-bit works are mixed in. In this paper, we conduct a complete
investigation of BNN's development from their predecessors to the latest BNN
algorithms and techniques, presenting a broad design pipeline, and discussing
each module's variants. Along the way, this paper examines BNN (a) purpose:
their early successes and challenges; (b) BNN optimization: selected
representative works that contain key optimization techniques; (c) deployment:
open-source frameworks for BNN modeling and development; (d) terminal:
efficient computing architectures and devices for BNN and (e) applications:
diverse applications with BNN. Moreover, this paper discusses potential
directions and future research opportunities for the latest BNN algorithms and
techniques, presents a broad design pipeline, and discusses each module's
variants.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Framework for Verification of Wasserstein Adversarial Robustness. (arXiv:2110.06816v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06816">
<div class="article-summary-box-inner">
<span><p>Machine learning image classifiers are susceptible to adversarial and
corruption perturbations. Adding imperceptible noise to images can lead to
severe misclassifications of the machine learning model. Using $L_p$-norms for
measuring the size of the noise fails to capture human similarity perception,
which is why optimal transport based distance measures like the Wasserstein
metric are increasingly being used in the field of adversarial robustness.
Verifying the robustness of classifiers using the Wasserstein metric can be
achieved by proving the absence of adversarial examples (certification) or
proving their presence (attack). In this work we present a framework based on
the work by Levine and Feizi, which allows us to transfer existing
certification methods for convex polytopes or $L_1$-balls to the Wasserstein
threat model. The resulting certification can be complete or incomplete,
depending on whether convex polytopes or $L_1$-balls were chosen. Additionally,
we present a new Wasserstein adversarial attack that is projected gradient
descent based and which has a significantly reduced computational burden
compared to existing attack approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optical Character Recognition of 19th Century Classical Commentaries: the Current State of Affairs. (arXiv:2110.06817v1 [cs.DL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06817">
<div class="article-summary-box-inner">
<span><p>Together with critical editions and translations, commentaries are one of the
main genres of publication in literary and textual scholarship, and have a
century-long tradition. Yet, the exploitation of thousands of digitized
historical commentaries was hitherto hindered by the poor quality of Optical
Character Recognition (OCR), especially on commentaries to Greek texts. In this
paper, we evaluate the performances of two pipelines suitable for the OCR of
historical classical commentaries. Our results show that Kraken + Ciaconna
reaches a substantially lower character error rate (CER) than Tesseract/OCR-D
on commentary sections with high density of polytonic Greek text (average CER
7% vs. 13%), while Tesseract/OCR-D is slightly more accurate than Kraken +
Ciaconna on text sections written predominantly in Latin script (average CER
8.2% vs. 8.4%). As part of this paper, we also release GT4HistComment, a small
dataset with OCR ground truth for 19th classical commentaries and Pogretra, a
large collection of training data and pre-trained models for a wide variety of
ancient Greek typefaces.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging redundancy in attention with Reuse Transformers. (arXiv:2110.06821v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06821">
<div class="article-summary-box-inner">
<span><p>Pairwise dot product-based attention allows Transformers to exchange
information between tokens in an input-dependent way, and is key to their
success across diverse applications in language and vision. However, a typical
Transformer model computes such pairwise attention scores repeatedly for the
same sequence, in multiple heads in multiple layers. We systematically analyze
the empirical similarity of these scores across heads and layers and find them
to be considerably redundant, especially adjacent layers showing high
similarity. Motivated by these findings, we propose a novel architecture that
reuses attention scores computed in one layer in multiple subsequent layers.
Experiments on a number of standard benchmarks show that reusing attention
delivers performance equivalent to or better than standard transformers, while
reducing both compute and memory usage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NoisyActions2M: A Multimedia Dataset for Video Understanding from Noisy Labels. (arXiv:2110.06827v1 [cs.MM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06827">
<div class="article-summary-box-inner">
<span><p>Deep learning has shown remarkable progress in a wide range of problems.
However, efficient training of such models requires large-scale datasets, and
getting annotations for such datasets can be challenging and costly. In this
work, we explore the use of user-generated freely available labels from web
videos for video understanding. We create a benchmark dataset consisting of
around 2 million videos with associated user-generated annotations and other
meta information. We utilize the collected dataset for action classification
and demonstrate its usefulness with existing small-scale annotated datasets,
UCF101 and HMDB51. We study different loss functions and two pretraining
strategies, simple and self-supervised learning. We also show how a network
pretrained on the proposed dataset can help against video corruption and label
noise in downstream datasets. We present this as a benchmark dataset in noisy
learning for video understanding. The dataset, code, and trained models will be
publicly available for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CONetV2: Efficient Auto-Channel Size Optimization for CNNs. (arXiv:2110.06830v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06830">
<div class="article-summary-box-inner">
<span><p>Neural Architecture Search (NAS) has been pivotal in finding optimal network
configurations for Convolution Neural Networks (CNNs). While many methods
explore NAS from a global search-space perspective, the employed optimization
schemes typically require heavy computational resources. This work introduces a
method that is efficient in computationally constrained environments by
examining the micro-search space of channel size. In tackling channel-size
optimization, we design an automated algorithm to extract the dependencies
within different connected layers of the network. In addition, we introduce the
idea of knowledge distillation, which enables preservation of trained weights,
admist trials where the channel sizes are changing. Further, since the standard
performance indicators (accuracy, loss) fail to capture the performance of
individual network components (providing an overall network evaluation), we
introduce a novel metric that highly correlates with test accuracy and enables
analysis of individual network layers. Combining dependency extraction,
metrics, and knowledge distillation, we introduce an efficient searching
algorithm, with simulated annealing inspired stochasticity, and demonstrate its
effectiveness in finding optimal architectures that outperform baselines by a
large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting the Certified Robustness of L-infinity Distance Nets. (arXiv:2110.06850v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06850">
<div class="article-summary-box-inner">
<span><p>Recently, Zhang et al. (2021) developed a new neural network architecture
based on $\ell_\infty$-distance functions, which naturally possesses certified
robustness by its construction. Despite the excellent theoretical properties,
the model so far can only achieve comparable performance to conventional
networks. In this paper, we significantly boost the certified robustness of
$\ell_\infty$-distance nets through a careful analysis of its training process.
In particular, we show the $\ell_p$-relaxation, a crucial way to overcome the
non-smoothness of the model, leads to an unexpected large Lipschitz constant at
the early training stage. This makes the optimization insufficient using hinge
loss and produces sub-optimal solutions. Given these findings, we propose a
simple approach to address the issues above by using a novel objective function
that combines a scaled cross-entropy loss with clipped hinge loss. Our
experiments show that using the proposed training strategy, the certified
accuracy of $\ell_\infty$-distance net can be dramatically improved from 33.30%
to 40.06% on CIFAR-10 ($\epsilon=8/255$), meanwhile significantly outperforming
other approaches in this area. Such a result clearly demonstrates the
effectiveness and potential of $\ell_\infty$-distance net for certified
robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attentive and Contrastive Learning for Joint Depth and Motion Field Estimation. (arXiv:2110.06853v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06853">
<div class="article-summary-box-inner">
<span><p>Estimating the motion of the camera together with the 3D structure of the
scene from a monocular vision system is a complex task that often relies on the
so-called scene rigidity assumption. When observing a dynamic environment, this
assumption is violated which leads to an ambiguity between the ego-motion of
the camera and the motion of the objects. To solve this problem, we present a
self-supervised learning framework for 3D object motion field estimation from
monocular videos. Our contributions are two-fold. First, we propose a two-stage
projection pipeline to explicitly disentangle the camera ego-motion and the
object motions with dynamics attention module, called DAM. Specifically, we
design an integrated motion model that estimates the motion of the camera and
object in the first and second warping stages, respectively, controlled by the
attention module through a shared motion encoder. Second, we propose an object
motion field estimation through contrastive sample consensus, called CSAC,
taking advantage of weak semantic prior (bounding box from an object detector)
and geometric constraints (each object respects the rigid body motion model).
Experiments on KITTI, Cityscapes, and Waymo Open Dataset demonstrate the
relevance of our approach and show that our method outperforms state-of-the-art
algorithms for the tasks of self-supervised monocular depth estimation, object
motion segmentation, monocular scene flow estimation, and visual odometry.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Users' Mental Model with Attention-directed Counterfactual Edits. (arXiv:2110.06863v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06863">
<div class="article-summary-box-inner">
<span><p>In the domain of Visual Question Answering (VQA), studies have shown
improvement in users' mental model of the VQA system when they are exposed to
examples of how these systems answer certain Image-Question (IQ) pairs. In this
work, we show that showing controlled counterfactual image-question examples
are more effective at improving the mental model of users as compared to simply
showing random examples. We compare a generative approach and a retrieval-based
approach to show counterfactual examples. We use recent advances in generative
adversarial networks (GANs) to generate counterfactual images by deleting and
inpainting certain regions of interest in the image. We then expose users to
changes in the VQA system's answer on those altered images. To select the
region of interest for inpainting, we experiment with using both
human-annotated attention maps and a fully automatic method that uses the VQA
system's attention values. Finally, we test the user's mental model by asking
them to predict the model's performance on a test counterfactual image. We note
an overall improvement in users' accuracy to predict answer change when shown
counterfactual explanations. While realistic retrieved counterfactuals
obviously are the most effective at improving the mental model, we show that a
generative approach can also be equally effective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ByteTrack: Multi-Object Tracking by Associating Every Detection Box. (arXiv:2110.06864v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06864">
<div class="article-summary-box-inner">
<span><p>Multi-object tracking (MOT) aims at estimating bounding boxes and identities
of objects in videos. Most methods obtain identities by associating detection
boxes whose scores are higher than a threshold. The objects with low detection
scores, e.g. occluded objects, are simply thrown away, which brings
non-negligible true object missing and fragmented trajectories. To solve this
problem, we present a simple, effective and generic association method, called
BYTE, tracking BY associaTing Every detection box instead of only the high
score ones. For the low score detection boxes, we utilize their similarities
with tracklets to recover true objects and filter out the background
detections. We apply BYTE to 9 different state-of-the-art trackers and achieve
consistent improvement on IDF1 score ranging from 1 to 10 points. To put
forwards the state-of-the-art performance of MOT, we design a simple and strong
tracker, named ByteTrack. For the first time, we achieve 80.3 MOTA, 77.3 IDF1
and 63.1 HOTA on the test set of MOT17 with 30 FPS running speed on a single
V100 GPU. The source code, pre-trained models with deploy versions and
tutorials of applying to other trackers are released at
\url{https://github.com/ifzhang/ByteTrack}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Review on Human Pose Estimation. (arXiv:2110.06877v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06877">
<div class="article-summary-box-inner">
<span><p>The phenomenon of Human Pose Estimation (HPE) is a problem that has been
explored over the years, particularly in computer vision. But what exactly is
it? To answer this, the concept of a pose must first be understood. Pose can be
defined as the arrangement of human joints in a specific manner. Therefore, we
can define the problem of Human Pose Estimation as the localization of human
joints or predefined landmarks in images and videos. There are several types of
pose estimation, including body, face, and hand, as well as many aspects to it.
This paper will cover them, starting with the classical approaches to HPE to
the Deep Learning based models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object-Region Video Transformers. (arXiv:2110.06915v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06915">
<div class="article-summary-box-inner">
<span><p>Evidence from cognitive psychology suggests that understanding
spatio-temporal object interactions and dynamics can be essential for
recognizing actions in complex videos. Therefore, action recognition models are
expected to benefit from explicit modeling of objects, including their
appearance, interaction, and dynamics. Recently, video transformers have shown
great success in video understanding, exceeding CNN performance. Yet, existing
video transformer models do not explicitly model objects. In this work, we
present Object-Region Video Transformers (ORViT), an \emph{object-centric}
approach that extends video transformer layers with a block that directly
incorporates object representations. The key idea is to fuse object-centric
spatio-temporal representations throughout multiple transformer layers. Our
ORViT block consists of two object-level streams: appearance and dynamics. In
the appearance stream, an ``Object-Region Attention'' element applies
self-attention over the patches and \emph{object regions}. In this way, visual
object regions interact with uniform patch tokens and enrich them with
contextualized object information. We further model object dynamics via a
separate ``Object-Dynamics Module'', which captures trajectory interactions,
and show how to integrate the two streams. We evaluate our model on standard
and compositional action recognition on Something-Something V2, standard action
recognition on Epic-Kitchen100 and Diving48, and spatio-temporal action
detection on AVA. We show strong improvement in performance across all tasks
and datasets considered, demonstrating the value of a model that incorporates
object representations into a transformer architecture. For code and pretrained
models, visit the project page at https://roeiherz.github.io/ORViT/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries. (arXiv:2110.06922v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06922">
<div class="article-summary-box-inner">
<span><p>We introduce a framework for multi-camera 3D object detection. In contrast to
existing works, which estimate 3D bounding boxes directly from monocular images
or use depth prediction networks to generate input for 3D object detection from
2D information, our method manipulates predictions directly in 3D space. Our
architecture extracts 2D features from multiple camera images and then uses a
sparse set of 3D object queries to index into these 2D features, linking 3D
positions to multi-view images using camera transformation matrices. Finally,
our model makes a bounding box prediction per object query, using a set-to-set
loss to measure the discrepancy between the ground-truth and the prediction.
This top-down approach outperforms its bottom-up counterpart in which object
bounding box prediction follows per-pixel depth estimation, since it does not
suffer from the compounding error introduced by a depth prediction model.
Moreover, our method does not require post-processing such as non-maximum
suppression, dramatically improving inference speed. We achieve
state-of-the-art performance on the nuScenes autonomous driving benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Object DGCNN: 3D Object Detection using Dynamic Graphs. (arXiv:2110.06923v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06923">
<div class="article-summary-box-inner">
<span><p>3D object detection often involves complicated training and testing
pipelines, which require substantial domain knowledge about individual
datasets. Inspired by recent non-maximum suppression-free 2D object detection
models, we propose a 3D object detection architecture on point clouds. Our
method models 3D object detection as message passing on a dynamic graph,
generalizing the DGCNN framework to predict a set of objects. In our
construction, we remove the necessity of post-processing via object confidence
aggregation or non-maximum suppression. To facilitate object detection from
sparse point clouds, we also propose a set-to-set distillation approach
customized to 3D detection. This approach aligns the outputs of the teacher
model and the student model in a permutation-invariant fashion, significantly
simplifying knowledge distillation for the 3D detection task. Our method
achieves state-of-the-art performance on autonomous driving benchmarks. We also
provide abundant analysis of the detection model and distillation framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Graph Data Learning via Latent Graph Convolutional Representation. (arXiv:1904.11883v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.11883">
<div class="article-summary-box-inner">
<span><p>Graph Convolutional Representation (GCR) has achieved impressive performance
for graph data representation. However, existing GCR is generally defined on
the input fixed graph which may restrict the representation capacity and also
be vulnerable to the structural attacks and noises. To address this issue, we
propose a novel Latent Graph Convolutional Representation (LatGCR) for robust
graph data representation and learning. Our LatGCR is derived based on
reformulating graph convolutional representation from the aspect of graph
neighborhood reconstruction. Given an input graph $\textbf{A}$, LatGCR aims to
generate a flexible latent graph $\widetilde{\textbf{A}}$ for graph
convolutional representation which obviously enhances the representation
capacity and also performs robustly w.r.t graph structural attacks and noises.
Moreover, LatGCR is implemented in a self-supervised manner and thus provides a
basic block for both supervised and unsupervised graph learning tasks.
Experiments on several datasets demonstrate the effectiveness and robustness of
LatGCR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Objectness-Aware Few-Shot Semantic Segmentation. (arXiv:2004.02945v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.02945">
<div class="article-summary-box-inner">
<span><p>Few-shot semantic segmentation models aim to segment images after learning
from only a few annotated examples. A key challenge for them is how to avoid
overfitting because limited training data is available. While prior works
usually limited the overall model capacity to alleviate overfitting, this
hampers segmentation accuracy. We demonstrate how to increase overall model
capacity to achieve improved performance, by introducing objectness, which is
class-agnostic and so not prone to overfitting, for complementary use with
class-specific features. Extensive experiments demonstrate the versatility of
our simple approach of introducing objectness for different base architectures
that rely on different data loaders and training schedules (DENet, PFENet) as
well as with different backbone models (ResNet-50, ResNet-101 and HRNetV2-W48).
Given only one annotated example of an unseen category, experiments show that
our method outperforms state-of-art methods with respect to mIoU by at least
4.7% and 1.5% on PASCAL-5i and COCO-20i respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Few-Shot Video Classification with Video Retrieval and Feature Generation. (arXiv:2007.04755v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04755">
<div class="article-summary-box-inner">
<span><p>Few-shot learning aims to recognize novel classes from a few examples.
Although significant progress has been made in the image domain, few-shot video
classification is relatively unexplored. We argue that previous methods
underestimate the importance of video feature learning and propose to learn
spatiotemporal features using a 3D CNN. Proposing a two-stage approach that
learns video features on base classes followed by fine-tuning the classifiers
on novel classes, we show that this simple baseline approach outperforms prior
few-shot video classification methods by over 20 points on existing benchmarks.
To circumvent the need of labeled examples, we present two novel approaches
that yield further improvement. First, we leverage tag-labeled videos from a
large dataset using tag retrieval followed by selecting the best clips with
visual similarities. Second, we learn generative adversarial networks that
generate video features of novel classes from their semantic embeddings.
Moreover, we find existing benchmarks are limited because they only focus on 5
novel classes in each testing episode and introduce more realistic benchmarks
by involving more novel classes, i.e. few-shot learning, as well as a mixture
of novel and base classes, i.e. generalized few-shot learning. The experimental
results show that our retrieval and feature generation approach significantly
outperform the baseline approach on the new benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BSL-1K: Scaling up co-articulated sign language recognition using mouthing cues. (arXiv:2007.12131v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12131">
<div class="article-summary-box-inner">
<span><p>Recent progress in fine-grained gesture and action classification, and
machine translation, point to the possibility of automated sign language
recognition becoming a reality. A key stumbling block in making progress
towards this goal is a lack of appropriate training data, stemming from the
high complexity of sign annotation and a limited supply of qualified
annotators. In this work, we introduce a new scalable approach to data
collection for sign recognition in continuous videos. We make use of
weakly-aligned subtitles for broadcast footage together with a keyword spotting
method to automatically localise sign-instances for a vocabulary of 1,000 signs
in 1,000 hours of video. We make the following contributions: (1) We show how
to use mouthing cues from signers to obtain high-quality annotations from video
data - the result is the BSL-1K dataset, a collection of British Sign Language
(BSL) signs of unprecedented scale; (2) We show that we can use BSL-1K to train
strong sign recognition models for co-articulated signs in BSL and that these
models additionally form excellent pretraining for other sign languages and
benchmarks - we exceed the state of the art on both the MSASL and WLASL
benchmarks. Finally, (3) we propose new large-scale evaluation sets for the
tasks of sign recognition and sign spotting and provide baselines which we hope
will serve to stimulate research in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrating Self-supervised Monocular Depth Estimation. (arXiv:2009.07714v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07714">
<div class="article-summary-box-inner">
<span><p>In the recent years, many methods demonstrated the ability of neural networks
to learn depth and pose changes in a sequence of images, using only
self-supervision as the training signal. Whilst the networks achieve good
performance, the often over-looked detail is that due to the inherent ambiguity
of monocular vision they predict depth up to an unknown scaling factor. The
scaling factor is then typically obtained from the LiDAR ground truth at test
time, which severely limits practical applications of these methods. In this
paper, we show that incorporating prior information about the camera
configuration and the environment, we can remove the scale ambiguity and
predict depth directly, still using the self-supervised formulation and not
relying on any additional sensors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Arbitrary-Oriented Ship Detection through Center-Head Point Extraction. (arXiv:2101.11189v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11189">
<div class="article-summary-box-inner">
<span><p>Ship detection in remote sensing images plays a crucial role in various
applications and has drawn increasing attention in recent years. However,
existing arbitrary-oriented ship detection methods are generally developed on a
set of predefined rotated anchor boxes. These predefined boxes not only lead to
inaccurate angle predictions but also introduce extra hyper-parameters and high
computational cost. Moreover, the prior knowledge of ship size has not been
fully exploited by existing methods, which hinders the improvement of their
detection accuracy. Aiming at solving the above issues, in this paper, we
propose a center-head point extraction based detector (named CHPDet) to achieve
arbitrary-oriented ship detection in remote sensing images. Our CHPDet
formulates arbitrary-oriented ships as rotated boxes with head points which are
used to determine the direction. And rotated Gaussian kernel is used to map the
annotations into target heatmaps. Keypoint estimation is performed to find the
center of ships. Then, the size and head point of the ships are regressed. The
orientation-invariant model (OIM) is also used to produce orientation-invariant
feature maps. Finally, we use the target size as prior to finetune the results.
Moreover, we introduce a new dataset for multi-class arbitrary-oriented ship
detection in remote sensing images at a fixed ground sample distance (GSD)
which is named FGSD2021. Experimental results on FGSD2021 and two other widely
used data sets, i.e., HRSC2016, and UCAS-AOD demonstrate that our CHPDet
achieves state-of-the-art performance and can well distinguish between bow and
stern. Code and FGSD2021 dataset are available at
https://github.com/zf020114/CHPDet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Framing of Science Conspiracy Videos: Integrating Machine Learning with Communication Theories to Study the Use of Color and Brightness. (arXiv:2102.01163v2 [cs.MM] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01163">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed an explosion of science conspiracy videos on the
Internet, challenging science epistemology and public understanding of science.
Scholars have started to examine the persuasion techniques used in conspiracy
messages such as uncertainty and fear yet, little is understood about the
visual narratives, especially how visual narratives differ in videos that
debunk conspiracies versus those that propagate conspiracies. This paper
addresses this gap in understanding visual framing in conspiracy videos through
analyzing millions of frames from conspiracy and counter-conspiracy YouTube
videos using computational methods. We found that conspiracy videos tended to
use lower color variance and brightness, especially in thumbnails and earlier
parts of the videos. This paper also demonstrates how researchers can integrate
textual and visual features in machine learning models to study conspiracies on
social media and discusses the implications of computational modeling for
scholars interested in studying visual manipulation in the digital era. The
analysis of visual and textual features presented in this paper could be useful
for future studies focused on designing systems to identify conspiracy content
on the Internet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cycle Self-Training for Domain Adaptation. (arXiv:2103.03571v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03571">
<div class="article-summary-box-inner">
<span><p>Mainstream approaches for unsupervised domain adaptation (UDA) learn
domain-invariant representations to narrow the domain shift. Recently,
self-training has been gaining momentum in UDA, which exploits unlabeled target
data by training with target pseudo-labels. However, as corroborated in this
work, under distributional shift in UDA, the pseudo-labels can be unreliable in
terms of their large discrepancy from target ground truth. Thereby, we propose
Cycle Self-Training (CST), a principled self-training algorithm that explicitly
enforces pseudo-labels to generalize across domains. CST cycles between a
forward step and a reverse step until convergence. In the forward step, CST
generates target pseudo-labels with a source-trained classifier. In the reverse
step, CST trains a target classifier using target pseudo-labels, and then
updates the shared representations to make the target classifier perform well
on the source data. We introduce the Tsallis entropy as a confidence-friendly
regularization to improve the quality of target pseudo-labels. We analyze CST
theoretically under realistic assumptions, and provide hard cases where CST
recovers target ground truth, while both invariant feature learning and vanilla
self-training fail. Empirical results indicate that CST significantly improves
over the state-of-the-arts on visual recognition and sentiment analysis
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Busy-Quiet Video Disentangling for Video Classification. (arXiv:2103.15584v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15584">
<div class="article-summary-box-inner">
<span><p>In video data, busy motion details from moving regions are conveyed within a
specific frequency bandwidth in the frequency domain. Meanwhile, the rest of
the frequencies of video data are encoded with quiet information with
substantial redundancy, which causes low processing efficiency in existing
video models that take as input raw RGB frames. In this paper, we consider
allocating intenser computation for the processing of the important busy
information and less computation for that of the quiet information. We design a
trainable Motion Band-Pass Module (MBPM) for separating busy information from
quiet information in raw video data. By embedding the MBPM into a two-pathway
CNN architecture, we define a Busy-Quiet Net (BQN). The efficiency of BQN is
determined by avoiding redundancy in the feature space processed by the two
pathways: one operating on Quiet features of low-resolution, while the other
processes Busy features. The proposed BQN outperforms many recent video
processing models on Something-Something V1, Kinetics400, UCF101 and HMDB51
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">von Mises-Fisher Loss: An Exploration of Embedding Geometries for Supervised Learning. (arXiv:2103.15718v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15718">
<div class="article-summary-box-inner">
<span><p>Recent work has argued that classification losses utilizing softmax
cross-entropy are superior not only for fixed-set classification tasks, but
also by outperforming losses developed specifically for open-set tasks
including few-shot learning and retrieval. Softmax classifiers have been
studied using different embedding geometries -- Euclidean, hyperbolic, and
spherical -- and claims have been made about the superiority of one or another,
but they have not been systematically compared with careful controls. We
conduct an empirical investigation of embedding geometry on softmax losses for
a variety of fixed-set classification and image retrieval tasks. An interesting
property observed for the spherical losses lead us to propose a probabilistic
classifier based on the von Mises-Fisher distribution, and we show that it is
competitive with state-of-the-art methods while producing improved
out-of-the-box calibration. We provide guidance regarding the trade-offs
between losses and how to choose among them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Regression on Manifolds: A 3D Rotation Case Study. (arXiv:2103.16317v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16317">
<div class="article-summary-box-inner">
<span><p>Many machine learning problems involve regressing variables on a
non-Euclidean manifold -- e.g. a discrete probability distribution, or the 6D
pose of an object. One way to tackle these problems through gradient-based
learning is to use a differentiable function that maps arbitrary inputs of a
Euclidean space onto the manifold. In this paper, we establish a set of
desirable properties for such mapping, and in particular highlight the
importance of pre-images connectivity/convexity. We illustrate these properties
with a case study regarding 3D rotations. Through theoretical considerations
and methodological experiments on a variety of tasks, we review various
differentiable mappings on the 3D rotation space, and conjecture about the
importance of their local linearity. We show that a mapping based on Procrustes
orthonormalization generally performs best among the mappings considered, but
that a rotation vector representation might also be suitable when restricted to
small angles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OpenGAN: Open-Set Recognition via Open Data Generation. (arXiv:2104.02939v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02939">
<div class="article-summary-box-inner">
<span><p>Real-world machine learning systems need to analyze test data that may differ
from training data. In K-way classification, this is crisply formulated as
open-set recognition, core to which is the ability to discriminate open-set
data outside the K closed-set classes. Two conceptually elegant ideas for
open-set discrimination are: 1) discriminatively learning an open-vs-closed
binary discriminator by exploiting some outlier data as the open-set, and 2)
unsupervised learning the closed-set data distribution with a GAN, using its
discriminator as the open-set likelihood function. However, the former
generalizes poorly to diverse open test data due to overfitting to the training
outliers, which are unlikely to exhaustively span the open-world. The latter
does not work well, presumably due to the instable training of GANs. Motivated
by the above, we propose OpenGAN, which addresses the limitation of each
approach by combining them with several technical insights. First, we show that
a carefully selected GAN-discriminator on some real outlier data already
achieves the state-of-the-art. Second, we augment the available set of real
open training examples with adversarially synthesized "fake" data. Third and
most importantly, we build the discriminator over the features computed by the
closed-world K-way networks. This allows OpenGAN to be implemented via a
lightweight discriminator head built on top of an existing K-way network.
Extensive experiments show that OpenGAN significantly outperforms prior
open-set methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Pedestrian Crossing Intention with Feature Fusion and Spatio-Temporal Attention. (arXiv:2104.05485v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05485">
<div class="article-summary-box-inner">
<span><p>Predicting vulnerable road user behavior is an essential prerequisite for
deploying Automated Driving Systems (ADS) in the real-world. Pedestrian
crossing intention should be recognized in real-time, especially for urban
driving. Recent works have shown the potential of using vision-based deep
neural network models for this task. However, these models are not robust and
certain issues still need to be resolved. First, the global spatio-temproal
context that accounts for the interaction between the target pedestrian and the
scene has not been properly utilized. Second, the optimum strategy for fusing
different sensor data has not been thoroughly investigated. This work addresses
the above limitations by introducing a novel neural network architecture to
fuse inherently different spatio-temporal features for pedestrian crossing
intention prediction. We fuse different phenomena such as sequences of RGB
imagery, semantic segmentation masks, and ego-vehicle speed in an optimum way
using attention mechanisms and a stack of recurrent neural networks. The
optimum architecture was obtained through exhaustive ablation and comparison
studies. Extensive comparative experiments on the JAAD pedestrian action
prediction benchmark demonstrate the effectiveness of the proposed method,
where state-of-the-art performance was achieved. Our code is open-source and
publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep learning representations with expert knowledge graphs: the MonuMAI cultural heritage use case. (arXiv:2104.11914v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11914">
<div class="article-summary-box-inner">
<span><p>The latest Deep Learning (DL) models for detection and classification have
achieved an unprecedented performance over classical machine learning
algorithms. However, DL models are black-box methods hard to debug, interpret,
and certify. DL alone cannot provide explanations that can be validated by a
non technical audience. In contrast, symbolic AI systems that convert concepts
into rules or symbols -- such as knowledge graphs -- are easier to explain.
However, they present lower generalisation and scaling capabilities. A very
important challenge is to fuse DL representations with expert knowledge. One
way to address this challenge, as well as the performance-explainability
trade-off is by leveraging the best of both streams without obviating domain
expert knowledge. We tackle such problem by considering the symbolic knowledge
is expressed in form of a domain expert knowledge graph. We present the
eXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn
both symbolic and deep representations, together with an explainability metric
to assess the level of alignment of machine and human expert explanations. The
ultimate objective is to fuse DL representations with expert domain knowledge
during the learning process to serve as a sound basis for explainability.
X-NeSyL methodology involves the concrete use of two notions of explanation at
inference and training time respectively: 1) EXPLANet: Expert-aligned
eXplainable Part-based cLAssifier NETwork Architecture, a compositional CNN
that makes use of symbolic representations, and 2) SHAP-Backprop, an
explainable AI-informed training procedure that guides the DL process to align
with such symbolic representations in form of knowledge graphs. We showcase
X-NeSyL methodology using MonuMAI dataset for monument facade image
classification, and demonstrate that our approach improves explainability and
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation-Based Bounding Box Generation for Omnidirectional Pedestrian Detection. (arXiv:2104.13764v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13764">
<div class="article-summary-box-inner">
<span><p>We propose a segmentation-based bounding box generation method for
omnidirectional pedestrian detection that enables detectors to tightly fit
bounding boxes to pedestrians without omnidirectional images for training. Due
to the wide angle of view, omnidirectional cameras are more cost-effective than
standard cameras and hence suitable for large-scale monitoring. The problem of
using omnidirectional cameras for pedestrian detection is that the performance
of standard pedestrian detectors is likely to be substantially degraded because
pedestrians' appearance in omnidirectional images may be rotated to any angle.
Existing methods mitigate this issue by transforming images during inference.
However, the transformation substantially degrades the detection accuracy and
speed. A recently proposed method obviates the transformation by training
detectors with omnidirectional images, which instead incurs huge annotation
costs. To obviate both the transformation and annotation works, we leverage an
existing large-scale object detection dataset. We train a detector with rotated
images and tightly fitted bounding box annotations generated from the
segmentation annotations in the dataset, resulting in detecting pedestrians in
omnidirectional images with tightly fitted bounding boxes. We also develop
pseudo-fisheye distortion augmentation, which further enhances the performance.
Extensive analysis shows that our detector successfully fits bounding boxes to
pedestrians and demonstrates substantial performance improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-vocabulary Object Detection via Vision and Language Knowledge Distillation. (arXiv:2104.13921v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13921">
<div class="article-summary-box-inner">
<span><p>We aim at advancing open-vocabulary object detection, which detects objects
described by arbitrary text inputs. The fundamental challenge is the
availability of training data. Existing object detection datasets only contain
hundreds of categories, and it is costly to scale further. To overcome this
challenge, we propose ViLD, a training method via Vision and Language knowledge
Distillation. Our method distills the knowledge from a pretrained
open-vocabulary image classification model (teacher) into a two-stage detector
(student). Specifically, we use the teacher model to encode category texts and
image regions of object proposals. Then we train a student detector, whose
region embeddings of detected boxes are aligned with the text and image
embeddings inferred by the teacher. We benchmark on LVIS by holding out all
rare categories as novel categories not seen during training. ViLD obtains 16.1
mask AP$_r$, even outperforming the supervised counterpart by 3.8 with a
ResNet-50 backbone. The model can directly transfer to other datasets without
finetuning, achieving 72.2 AP$_{50}$, 36.6 AP and 11.8 AP on PASCAL VOC, COCO
and Objects365, respectively. On COCO, ViLD outperforms previous SOTA by 4.8 on
novel AP and 11.4 on overall AP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust joint registration of multiple stains and MRI for multimodal 3D histology reconstruction: Application to the Allen human brain atlas. (arXiv:2104.14873v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14873">
<div class="article-summary-box-inner">
<span><p>Joint registration of a stack of 2D histological sections to recover 3D
structure (``3D histology reconstruction'') finds application in areas such as
atlas building and validation of \emph{in vivo} imaging. Straightforward
pairwise registration of neighbouring sections yields smooth reconstructions
but has well-known problems such as ``banana effect'' (straightening of curved
structures) and ``z-shift'' (drift). While these problems can be alleviated
with an external, linearly aligned reference (e.g., Magnetic Resonance (MR)
images), registration is often inaccurate due to contrast differences and the
strong nonlinear distortion of the tissue, including artefacts such as folds
and tears. In this paper, we present a probabilistic model of spatial
deformation that yields reconstructions for multiple histological stains that
that are jointly smooth, robust to outliers, and follow the reference shape.
The model relies on a spanning tree of latent transforms connecting all the
sections and slices of the reference volume, and assumes that the registration
between any pair of images can be see as a noisy version of the composition of
(possibly inverted) latent transforms connecting the two images. Bayesian
inference is used to compute the most likely latent transforms given a set of
pairwise registrations between image pairs within and across modalities. The
framework is used for accurate 3D reconstruction of two stains (Nissl and
parvalbumin) from the Allen human brain atlas, showing its benefits on real
data with severe distortions. Moreover, we also provide the registration of the
reconstructed volume to MNI space, bridging the gaps between two of the most
widely used atlases in histology and MRI. The 3D reconstructed volumes and
atlas registration can be downloaded from
https://openneuro.org/datasets/ds003590. The code is freely available at
https://github.com/acasamitjana/3dhirest.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GridToPix: Training Embodied Agents with Minimal Supervision. (arXiv:2105.00931v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00931">
<div class="article-summary-box-inner">
<span><p>While deep reinforcement learning (RL) promises freedom from hand-labeled
data, great successes, especially for Embodied AI, require significant work to
create supervision via carefully shaped rewards. Indeed, without shaped
rewards, i.e., with only terminal rewards, present-day Embodied AI results
degrade significantly across Embodied AI problems from single-agent
Habitat-based PointGoal Navigation (SPL drops from 55 to 0) and two-agent
AI2-THOR-based Furniture Moving (success drops from 58% to 1%) to three-agent
Google Football-based 3 vs. 1 with Keeper (game score drops from 0.6 to 0.1).
As training from shaped rewards doesn't scale to more realistic tasks, the
community needs to improve the success of training with terminal rewards. For
this we propose GridToPix: 1) train agents with terminal rewards in gridworlds
that generically mirror Embodied AI environments, i.e., they are independent of
the task; 2) distill the learned policy into agents that reside in complex
visual worlds. Despite learning from only terminal rewards with identical
models and RL algorithms, GridToPix significantly improves results across
tasks: from PointGoal Navigation (SPL improves from 0 to 64) and Furniture
Moving (success improves from 1% to 25%) to football gameplay (game score
improves from 0.1 to 0.6). GridToPix even helps to improve the results of
shaped reward training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimizing Reusable Knowledge for Continual Learning via Metalearning. (arXiv:2106.05390v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05390">
<div class="article-summary-box-inner">
<span><p>When learning tasks over time, artificial neural networks suffer from a
problem known as Catastrophic Forgetting (CF). This happens when the weights of
a network are overwritten during the training of a new task causing forgetting
of old information. To address this issue, we propose MetA Reusable Knowledge
or MARK, a new method that fosters weight reusability instead of overwriting
when learning a new task. Specifically, MARK keeps a set of shared weights
among tasks. We envision these shared weights as a common Knowledge Base (KB)
that is not only used to learn new tasks, but also enriched with new knowledge
as the model learns new tasks. Key components behind MARK are two-fold. On the
one hand, a metalearning approach provides the key mechanism to incrementally
enrich the KB with new knowledge and to foster weight reusability among tasks.
On the other hand, a set of trainable masks provides the key mechanism to
selectively choose from the KB relevant weights to solve each task. By using
MARK, we achieve state of the art results in several popular benchmarks,
surpassing the best performing methods in terms of average accuracy by over 10%
on the 20-Split-MiniImageNet dataset, while achieving almost zero forgetfulness
using 55% of the number of parameters. Furthermore, an ablation study provides
evidence that, indeed, MARK is learning reusable knowledge that is selectively
used by each task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Randomized Smoothing with Variance Reduced Classifiers. (arXiv:2106.06946v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06946">
<div class="article-summary-box-inner">
<span><p>Randomized Smoothing (RS) is a promising method for obtaining robustness
certificates by evaluating a base model under noise. In this work, we: (i)
theoretically motivate why ensembles are a particularly suitable choice as base
models for RS, and (ii) empirically confirm this choice, obtaining
state-of-the-art results in multiple settings. The key insight of our work is
that the reduced variance of ensembles over the perturbations introduced in RS
leads to significantly more consistent classifications for a given input. This,
in turn, leads to substantially increased certifiable radii for samples close
to the decision boundary. Additionally, we introduce key optimizations which
enable an up to 55-fold decrease in sample complexity of RS, thus drastically
reducing its computational overhead. Experimentally, we show that ensembles of
only 3 to 10 classifiers consistently improve on their strongest constituting
model with respect to their average certified radius (ACR) by 5% to 21% on both
CIFAR10 and ImageNet, achieving a new state-of-the-art ACR of 0.86 and 1.11,
respectively. We release all code and models required to reproduce our results
upon publication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">S2C2 -- An orthogonal method for Semi-Supervised Learning on ambiguous labels. (arXiv:2106.16209v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16209">
<div class="article-summary-box-inner">
<span><p>Semi-Supervised Learning (SSL) can decrease the required amount of labeled
image data and thus the cost for deep learning. Most SSL methods assume a clear
distinction between classes, but class boundaries are often ambiguous in
real-world datasets due to intra- or interobserver variability. This ambiguity
of annotations must be addressed as it will otherwise limit the performance of
SSL and deep learning in general due to inconsistent label information. We
propose Semi-Supervised Classification &amp; Clustering (S2C2) which can extend
many deep SSL algorithms. S2C2 automatically estimates the ambiguity of an
image and applies the respective SSL algorithm as a classification to certainly
labeled data while partitioning the ambiguous data into clusters of visual
similar images. We show that S2C2 results in a 7.6% better F1-score for
classifications and 7.9% lower inner distance of clusters on average across
multiple SSL algorithms and datasets. Moreover, the output of S2C2 can be used
to decrease the ambiguity of labels with the help of human experts. Overall, a
combination of Semi-Supervised Learning with our method S2C2 leads to better
handling of ambiguous labels and thus real-world datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A study of CNN capacity applied to Left Venticle Segmentation in Cardiac MRI. (arXiv:2107.01318v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01318">
<div class="article-summary-box-inner">
<span><p>CNN (Convolutional Neural Network) models have been successfully used for
segmentation of the left ventricle (LV) in cardiac MRI (Magnetic Resonance
Imaging), providing clinical measurements. In practice, two questions arise
with deployment of CNNs: 1) when is it better to use a shallow model instead of
a deeper one? 2) how the size of a dataset might change the network
performance? We propose a framework to answer them, by experimenting with deep
and shallow versions of three U-Net families, trained from scratch in six
subsets varying from 100 to 10,000 images, different network sizes, learning
rates and regularization values. 1620 models were evaluated using 5-fold
cross-validation by loss and DICE. The results indicate that: sample size
affects performance more than architecture or hyper-parameters; in small
samples the performance is more sensitive to hyper-parameters than
architecture; the performance difference between shallow and deeper networks is
not the same across families.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-Time Face Recognition System for Remote Employee Tracking. (arXiv:2107.07576v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07576">
<div class="article-summary-box-inner">
<span><p>During the COVID-19 pandemic, most of the human-to-human interactions have
been stopped. To mitigate the spread of deadly coronavirus, many offices took
the initiative so that the employees can work from home. But, tracking the
employees and finding out if they are really performing what they were supposed
to turn out to be a serious challenge for all the companies and organizations
who are facilitating "Work From Home". To deal with the challenge effectively,
we came up with a solution to track the employees with face recognition. We
have been testing this system experimentally for our office. To train the face
recognition module, we used FaceNet with KNN using the Labeled Faces in the
Wild (LFW) dataset and achieved 97.8\% accuracy. We integrated the trained
model into our central system, where the employees log their time. In this
paper, we discuss in brief the system we have been experimenting with and the
pros and cons of the system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mining the Benefits of Two-stage and One-stage HOI Detection. (arXiv:2108.05077v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05077">
<div class="article-summary-box-inner">
<span><p>Two-stage methods have dominated Human-Object Interaction (HOI) detection for
several years. Recently, one-stage HOI detection methods have become popular.
In this paper, we aim to explore the essential pros and cons of two-stage and
one-stage methods. With this as the goal, we find that conventional two-stage
methods mainly suffer from positioning positive interactive human-object pairs,
while one-stage methods are challenging to make an appropriate trade-off on
multi-task learning, i.e., object detection, and interaction classification.
Therefore, a core problem is how to take the essence and discard the dregs from
the conventional two types of methods. To this end, we propose a novel
one-stage framework with disentangling human-object detection and interaction
classification in a cascade manner. In detail, we first design a human-object
pair generator based on a state-of-the-art one-stage HOI detector by removing
the interaction classification module or head and then design a relatively
isolated interaction classifier to classify each human-object pair. Two cascade
decoders in our proposed framework can focus on one specific task, detection or
interaction classification. In terms of the specific implementation, we adopt a
transformer-based HOI detector as our base model. The newly introduced
disentangling paradigm outperforms existing methods by a large margin, with a
significant relative mAP gain of 9.32% on HICO-Det. The source codes are
available at https://github.com/YueLiao/CDN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting socially interacting groups using f-formation: A survey of taxonomy, methods, datasets, applications, challenges, and future research directions. (arXiv:2108.06181v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06181">
<div class="article-summary-box-inner">
<span><p>Robots in our daily surroundings are increasing day by day. Their usability
and acceptability largely depend on their explicit and implicit interaction
capability with fellow human beings. As a result, social behavior is one of the
most sought-after qualities that a robot can possess. However, there is no
specific aspect and/or feature that defines socially acceptable behavior and it
largely depends on the situation, application, and society. In this article, we
investigate one such social behavior for collocated robots. Imagine a group of
people is interacting with each other and we want to join the group. We as
human beings do it in a socially acceptable manner, i.e., within the group, we
do position ourselves in such a way that we can participate in the group
activity without disturbing/obstructing anybody. To possess such a quality,
first, a robot needs to determine the formation of the group and then determine
a position for itself, which we humans do implicitly. The theory of f-formation
can be utilized for this purpose. As the types of formations can be very
diverse, detecting the social groups is not a trivial task. In this article, we
provide a comprehensive survey of the existing work on social interaction and
group detection using f-formation for robotics and other applications. We also
put forward a novel holistic survey framework combining all the possible
concerns and modules relevant to this problem. We define taxonomies based on
methods, camera views, datasets, detection capabilities and scale, evaluation
approaches, and application areas. We discuss certain open challenges and
limitations in current literature along with possible future research
directions based on this framework. In particular, we discuss the existing
methods/techniques and their relative merits and demerits, applications, and
provide a set of unsolved but relevant problems in this domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ARCH++: Animation-Ready Clothed Human Reconstruction Revisited. (arXiv:2108.07845v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07845">
<div class="article-summary-box-inner">
<span><p>We present ARCH++, an image-based method to reconstruct 3D avatars with
arbitrary clothing styles. Our reconstructed avatars are animation-ready and
highly realistic, in both the visible regions from input views and the unseen
regions. While prior work shows great promise of reconstructing animatable
clothed humans with various topologies, we observe that there exist fundamental
limitations resulting in sub-optimal reconstruction quality. In this paper, we
revisit the major steps of image-based avatar reconstruction and address the
limitations with ARCH++. First, we introduce an end-to-end point based geometry
encoder to better describe the semantics of the underlying 3D human body, in
replacement of previous hand-crafted features. Second, in order to address the
occupancy ambiguity caused by topological changes of clothed humans in the
canonical pose, we propose a co-supervising framework with cross-space
consistency to jointly estimate the occupancy in both the posed and canonical
spaces. Last, we use image-to-image translation networks to further refine
detailed geometry and texture on the reconstructed surface, which improves the
fidelity and consistency across arbitrary viewpoints. In the experiments, we
demonstrate improvements over the state of the art on both public benchmarks
and user studies in reconstruction quality and realism.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learned Image Coding for Machines: A Content-Adaptive Approach. (arXiv:2108.09992v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09992">
<div class="article-summary-box-inner">
<span><p>Today, according to the Cisco Annual Internet Report (2018-2023), the
fastest-growing category of Internet traffic is machine-to-machine
communication. In particular, machine-to-machine communication of images and
videos represents a new challenge and opens up new perspectives in the context
of data compression. One possible solution approach consists of adapting
current human-targeted image and video coding standards to the use case of
machine consumption. Another approach consists of developing completely new
compression paradigms and architectures for machine-to-machine communications.
In this paper, we focus on image compression and present an inference-time
content-adaptive finetuning scheme that optimizes the latent representation of
an end-to-end learned image codec, aimed at improving the compression
efficiency for machine-consumption. The conducted experiments show that our
online finetuning brings an average bitrate saving (BD-rate) of -3.66% with
respect to our pretrained image codec. In particular, at low bitrate points,
our proposed method results in a significant bitrate saving of -9.85%. Overall,
our pretrained-and-then-finetuned system achieves -30.54% BD-rate over the
state-of-the-art image/video codec Versatile Video Coding (VVC).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discovering Spatial Relationships by Transformers for Domain Generalization. (arXiv:2108.10046v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10046">
<div class="article-summary-box-inner">
<span><p>Due to the rapid increase in the diversity of image data, the problem of
domain generalization has received increased attention recently. While domain
generalization is a challenging problem, it has achieved great development
thanks to the fast development of AI techniques in computer vision. Most of
these advanced algorithms are proposed with deep architectures based on
convolution neural nets (CNN). However, though CNNs have a strong ability to
find the discriminative features, they do a poor job of modeling the relations
between different locations in the image due to the response to CNN filters are
mostly local. Since these local and global spatial relationships are
characterized to distinguish an object under consideration, they play a
critical role in improving the generalization ability against the domain gap.
In order to get the object parts relationships to gain better domain
generalization, this work proposes to use the self attention model. However,
the attention models are proposed for sequence, which are not expert in
discriminate feature extraction for 2D images. Considering this, we proposed a
hybrid architecture to discover the spatial relationships between these local
features, and derive a composite representation that encodes both the
discriminative features and their relationships to improve the domain
generalization. Evaluation on three well-known benchmarks demonstrates the
benefits of modeling relationships between the features of an image using the
proposed method and achieves state-of-the-art domain generalization
performance. More specifically, the proposed algorithm outperforms the
state-of-the-art by 2.2% and 3.4% on PACS and Office-Home databases,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A realistic approach to generate masked faces applied on two novel masked face recognition data sets. (arXiv:2109.01745v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01745">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic raises the problem of adapting face recognition systems
to the new reality, where people may wear surgical masks to cover their noses
and mouths. Traditional data sets (e.g., CelebA, CASIA-WebFace) used for
training these systems were released before the pandemic, so they now seem
unsuited due to the lack of examples of people wearing masks. We propose a
method for enhancing data sets containing faces without masks by creating
synthetic masks and overlaying them on faces in the original images. Our method
relies on SparkAR Studio, a developer program made by Facebook that is used to
create Instagram face filters. In our approach, we use 9 masks of different
colors, shapes and fabrics. We employ our method to generate a number of
445,446 (90%) samples of masks for the CASIA-WebFace data set and 196,254
(96.8%) masks for the CelebA data set, releasing the mask images at
https://github.com/securifai/masked_faces. We show that our method produces
significantly more realistic training examples of masks overlaid on faces by
asking volunteers to qualitatively compare it to other methods or data sets
designed for the same task. We also demonstrate the usefulness of our method by
evaluating state-of-the-art face recognition systems (FaceNet, VGG-face,
ArcFace) trained on our enhanced data sets and showing that they outperform
equivalent systems trained on original data sets (containing faces without
masks) or competing data sets (containing masks generated by related methods),
when the test benchmarks contain masked faces.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Deep Networks from Zero to Hero: avoiding pitfalls and going beyond. (arXiv:2109.02752v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02752">
<div class="article-summary-box-inner">
<span><p>Training deep neural networks may be challenging in real world data. Using
models as black-boxes, even with transfer learning, can result in poor
generalization or inconclusive results when it comes to small datasets or
specific applications. This tutorial covers the basic steps as well as more
recent options to improve models, in particular, but not restricted to,
supervised learning. It can be particularly useful in datasets that are not as
well-prepared as those in challenges, and also under scarce annotation and/or
small data. We describe basic procedures: as data preparation, optimization and
transfer learning, but also recent architectural choices such as use of
transformer modules, alternative convolutional layers, activation functions,
wide and deep networks, as well as training procedures including as curriculum,
contrastive and self-supervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Captioning for Effective Use of Language Models in Knowledge-Based Visual Question Answering. (arXiv:2109.08029v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08029">
<div class="article-summary-box-inner">
<span><p>Integrating outside knowledge for reasoning in visio-linguistic tasks such as
visual question answering (VQA) is an open problem. Given that pretrained
language models have been shown to include world knowledge, we propose to use a
unimodal (text-only) train and inference procedure based on automatic
off-the-shelf captioning of images and pretrained language models. Our results
on a visual question answering task which requires external knowledge (OK-VQA)
show that our text-only model outperforms pretrained multimodal (image-text)
models of comparable number of parameters. In contrast, our model is less
effective in a standard VQA task (VQA 2.0) confirming that our text-only method
is specially effective for tasks requiring external knowledge. In addition, we
show that our unimodal model is complementary to multimodal models in both
OK-VQA and VQA 2.0, and yield the best result to date in OK-VQA among systems
not using external knowledge graphs, and comparable to systems that do use
them. Our qualitative analysis on OK-VQA reveals that automatic captions often
fail to capture relevant information in the images, which seems to be balanced
by the better inference ability of the text-only language models. Our work
opens up possibilities to further improve inference in visio-linguistic tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Hybrid Transformer: Learning Global-local Context for Urban Scene Segmentation. (arXiv:2109.08937v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08937">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation of fine-resolution urban scene images plays a vital
role in extensive practical applications, such as land cover mapping, urban
change detection, environmental protection and economic assessment. Driven by
rapid developments in deep learning technologies, the convolutional neural
network (CNN) has dominated the semantic segmentation task for many years.
Convolutional neural networks adopt hierarchical feature representation,
demonstrating strong local information extraction. However, the local property
of the convolution layer limits the network from capturing global context that
is crucial for precise segmentation. Recently, Transformer comprise a hot topic
in the computer vision domain. Transformer demonstrates the great capability of
global information modelling, boosting many vision tasks, such as image
classification, object detection and especially semantic segmentation. In this
paper, we propose an efficient hybrid Transformer (EHT) for real-time urban
scene segmentation. The EHT adopts a hybrid structure with and CNN-based
encoder and a transformer-based decoder, learning global-local context with
lower computation. Extensive experiments demonstrate that our EHT has faster
inference speed with competitive accuracy compared with state-of-the-art
lightweight models. Specifically, the proposed EHT achieves a 66.9% mIoU on the
UAVid test set and outperforms other benchmark networks significantly. The code
will be available soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Student Helping Teacher: Teacher Evolution via Self-Knowledge Distillation. (arXiv:2110.00329v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00329">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation usually transfers the knowledge from a pre-trained
cumbersome teacher network to a compact student network, which follows the
classical teacher-teaching-student paradigm. Based on this paradigm, previous
methods mostly focus on how to efficiently train a better student network for
deployment. Different from the existing practices, in this paper, we propose a
novel student-helping-teacher formula, Teacher Evolution via Self-Knowledge
Distillation (TESKD), where the target teacher (for deployment) is learned with
the help of multiple hierarchical students by sharing the structural backbone.
The diverse feedback from multiple students allows the teacher to improve
itself through the shared feature representations. The effectiveness of our
proposed framework is demonstrated by extensive experiments with various
network settings on two standard benchmarks including CIFAR-100 and ImageNet.
Notably, when trained together with our proposed method, ResNet-18 achieves
79.15% and 71.14% accuracy on CIFAR-100 and ImageNet, outperforming the
baseline results by 4.74% and 1.43%, respectively. The code is available at:
https://github.com/zhengli427/TESKD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data. (arXiv:2110.03374v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03374">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation aims to align a labeled source domain and an
unlabeled target domain, but it requires to access the source data which often
raises concerns in data privacy, data portability and data transmission
efficiency. We study unsupervised model adaptation (UMA), or called
Unsupervised Domain Adaptation without Source Data, an alternative setting that
aims to adapt source-trained models towards target distributions without
accessing source data. To this end, we design an innovative historical
contrastive learning (HCL) technique that exploits historical source hypothesis
to make up for the absence of source data in UMA. HCL addresses the UMA
challenge from two perspectives. First, it introduces historical contrastive
instance discrimination (HCID) that learns from target samples by contrasting
their embeddings which are generated by the currently adapted model and the
historical models. With the source-trained and earlier-epoch models as the
historical models, HCID encourages UMA to learn instance-discriminative target
representations while preserving the source hypothesis. Second, it introduces
historical contrastive category discrimination (HCCD) that pseudo-labels target
samples to learn category-discriminative target representations. Instead of
globally thresholding pseudo labels, HCCD re-weights pseudo labels according to
their prediction consistency across the current and historical models.
Extensive experiments show that HCL outperforms and complements
state-of-the-art methods consistently across a variety of visual tasks (e.g.,
segmentation, classification and detection) and setups (e.g., close-set,
open-set and partial adaptation).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QTN-VQC: An End-to-End Learning framework for Quantum Neural Networks. (arXiv:2110.03861v2 [quant-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03861">
<div class="article-summary-box-inner">
<span><p>The advent of noisy intermediate-scale quantum (NISQ) computers raises a
crucial challenge to design quantum neural networks for fully quantum learning
tasks. To bridge the gap, this work proposes an end-to-end learning framework
named QTN-VQC, by introducing a trainable quantum tensor network (QTN) for
quantum embedding on a variational quantum circuit (VQC). The architecture of
QTN is composed of a parametric tensor-train network for feature extraction and
a tensor product encoding for quantum encoding. We highlight the QTN for
quantum embedding in terms of two perspectives: (1) we theoretically
characterize QTN by analyzing its representation power of input features; (2)
QTN enables an end-to-end parametric model pipeline, namely QTN-VQC, from the
generation of quantum embedding to the output measurement. Our experiments on
the MNIST dataset demonstrate the advantages of QTN for quantum embedding over
other quantum embedding approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLIP4Caption ++: Multi-CLIP for Video Caption. (arXiv:2110.05204v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05204">
<div class="article-summary-box-inner">
<span><p>This report describes our solution to the VALUE Challenge 2021 in the
captioning task. Our solution, named CLIP4Caption++, is built on
X-Linear/X-Transformer, which is an advanced model with encoder-decoder
architecture. We make the following improvements on the proposed
CLIP4Caption++: We employ an advanced encoder-decoder model architecture
X-Transformer as our main framework and make the following improvements: 1) we
utilize three strong pre-trained CLIP models to extract the text-related
appearance visual features. 2) we adopt the TSN sampling strategy for data
enhancement. 3) we involve the video subtitle information to provide richer
semantic information. 3) we introduce the subtitle information, which fuses
with the visual features as guidance. 4) we design word-level and
sentence-level ensemble strategies. Our proposed method achieves 86.5, 148.4,
64.5 CIDEr scores on VATEX, YC2C, and TVC datasets, respectively, which shows
the superior performance of our proposed CLIP4Caption++ on all three datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-Autoregressive Image Captioning. (arXiv:2110.05342v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05342">
<div class="article-summary-box-inner">
<span><p>Current state-of-the-art approaches for image captioning typically adopt an
autoregressive manner, i.e., generating descriptions word by word, which
suffers from slow decoding issue and becomes a bottleneck in real-time
applications. Non-autoregressive image captioning with continuous iterative
refinement, which eliminates the sequential dependence in a sentence
generation, can achieve comparable performance to the autoregressive
counterparts with a considerable acceleration. Nevertheless, based on a
well-designed experiment, we empirically proved that iteration times can be
effectively reduced when providing sufficient prior knowledge for the language
decoder. Towards that end, we propose a novel two-stage framework, referred to
as Semi-Autoregressive Image Captioning (SAIC), to make a better trade-off
between performance and speed. The proposed SAIC model maintains autoregressive
property in global but relieves it in local. Specifically, SAIC model first
jumpily generates an intermittent sequence in an autoregressive manner, that
is, it predicts the first word in every word group in order. Then, with the
help of the partially deterministic prior information and image features, SAIC
model non-autoregressively fills all the skipped words with one iteration.
Experimental results on the MS COCO benchmark demonstrate that our SAIC model
outperforms the preceding non-autoregressive image captioning models while
obtaining a competitive inference speedup. Code is available at
https://github.com/feizc/SAIC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rescoring Sequence-to-Sequence Models for Text Line Recognition with CTC-Prefixes. (arXiv:2110.05909v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05909">
<div class="article-summary-box-inner">
<span><p>In contrast to Connectionist Temporal Classification (CTC) approaches,
Sequence-To-Sequence (S2S) models for Handwritten Text Recognition (HTR) suffer
from errors such as skipped or repeated words which often occur at the end of a
sequence. In this paper, to combine the best of both approaches, we propose to
use the CTC-Prefix-Score during S2S decoding. Hereby, during beam search, paths
that are invalid according to the CTC confidence matrix are penalised. Our
network architecture is composed of a Convolutional Neural Network (CNN) as
visual backbone, bidirectional Long-Short-Term-Memory-Cells (LSTMs) as encoder,
and a decoder which is a Transformer with inserted mutual attention layers. The
CTC confidences are computed on the encoder while the Transformer is only used
for character-wise S2S decoding. We evaluate this setup on three HTR data sets:
IAM, Rimes, and StAZH. On IAM, we achieve a competitive Character Error Rate
(CER) of 2.95% when pretraining our model on synthetic data and including a
character-based language model for contemporary English. Compared to other
state-of-the-art approaches, our model requires about 10-20 times less
parameters. Access our shared implementations via this link to GitHub:
https://github.com/Planet-AI-GmbH/tfaip-hybrid-ctc-s2s.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-14 23:02:19.710298348 UTC">2021-10-14 23:02:19 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>