<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-01T01:30:00Z">09-01</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.AI updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Astrocytes mediate analogous memory in a multi-layer neuron-astrocytic network. (arXiv:2108.13414v1 [q-bio.NC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13414">
<div class="article-summary-box-inner">
<span><p>Modeling the neuronal processes underlying short-term working memory remains
the focus of many theoretical studies in neuroscience. Here we propose a
mathematical model of spiking neuron network (SNN) demonstrating how a piece of
information can be maintained as a robust activity pattern for several seconds
then completely disappear if no other stimuli come. Such short-term memory
traces are preserved due to the activation of astrocytes accompanying the SNN.
The astrocytes exhibit calcium transients at a time scale of seconds. These
transients further modulate the efficiency of synaptic transmission and, hence,
the firing rate of neighboring neurons at diverse timescales through
gliotransmitter release. We show how such transients continuously encode
frequencies of neuronal discharges and provide robust short-term storage of
analogous information. This kind of short-term memory can keep operative
information for seconds, then completely forget it to avoid overlapping with
forthcoming patterns. The SNN is inter-connected with the astrocytic layer by
local inter-cellular diffusive connections. The astrocytes are activated only
when the neighboring neurons fire quite synchronously, e.g. when an information
pattern is loaded. For illustration, we took greyscale photos of people's faces
where the grey level encoded the level of applied current stimulating the
neurons. The astrocyte feedback modulates (facilitates) synaptic transmission
by varying the frequency of neuronal firing. We show how arbitrary patterns can
be loaded, then stored for a certain interval of time, and retrieved if the
appropriate clue pattern is applied to the input.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback. (arXiv:2108.13454v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13454">
<div class="article-summary-box-inner">
<span><p>Dense retrieval systems conduct first-stage retrieval using embedded
representations and simple similarity metrics to match a query to documents.
Its effectiveness depends on encoded embeddings to capture the semantics of
queries and documents, a challenging task due to the shortness and ambiguity of
search queries. This paper proposes ANCE-PRF, a new query encoder that uses
pseudo relevance feedback (PRF) to improve query representations for dense
retrieval. ANCE-PRF uses a BERT encoder that consumes the query and the top
retrieved documents from a dense retrieval model, ANCE, and it learns to
produce better query embeddings directly from relevance labels. It also keeps
the document index unchanged to reduce overhead. ANCE-PRF significantly
outperforms ANCE and other recent dense retrieval systems on several datasets.
Analysis shows that the PRF encoder effectively captures the relevant and
complementary information from PRF documents, while ignoring the noise with its
learned attention mechanism.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Want To Reduce Labeling Cost? GPT-3 Can Help. (arXiv:2108.13487v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13487">
<div class="article-summary-box-inner">
<span><p>Data annotation is a time-consuming and labor-intensive process for many NLP
tasks. Although there exist various methods to produce pseudo data labels, they
are often task-specific and require a decent amount of labeled data to start
with. Recently, the immense language model GPT-3 with 175 billion parameters
has achieved tremendous improvement across many few-shot learning tasks. In
this paper, we explore ways to leverage GPT-3 as a low-cost data labeler to
train other models. We find that, to make the downstream model achieve the same
performance on a variety of NLU and NLG tasks, it costs 50% to 96% less to use
labels from GPT-3 than using labels from humans. Furthermore, we propose a
novel framework of combining pseudo labels from GPT-3 with human labels, which
leads to even better performance with limited labeling budget. These results
present a cost-effective data labeling methodology that is generalizable to
many practical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DoWhy: Addressing Challenges in Expressing and Validating Causal Assumptions. (arXiv:2108.13518v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13518">
<div class="article-summary-box-inner">
<span><p>Estimation of causal effects involves crucial assumptions about the
data-generating process, such as directionality of effect, presence of
instrumental variables or mediators, and whether all relevant confounders are
observed. Violation of any of these assumptions leads to significant error in
the effect estimate. However, unlike cross-validation for predictive models,
there is no global validator method for a causal estimate. As a result,
expressing different causal assumptions formally and validating them (to the
extent possible) becomes critical for any analysis. We present DoWhy, a
framework that allows explicit declaration of assumptions through a causal
graph and provides multiple validation tests to check a subset of these
assumptions. Our experience with DoWhy highlights a number of open questions
for future research: developing new ways beyond causal graphs to express
assumptions, the role of causal discovery in learning relevant parts of the
graph, and developing validation tests that can better detect errors, both for
average and conditional treatment effects. DoWhy is available at
https://github.com/microsoft/dowhy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Label Smoothing To Regularize Large-Scale Graph Training. (arXiv:2108.13555v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13555">
<div class="article-summary-box-inner">
<span><p>Graph neural networks (GNNs), which learn the node representations by
recursively aggregating information from its neighbors, have become a
predominant computational tool in many domains. To handle large-scale graphs,
most of the existing methods partition the input graph into multiple sub-graphs
(e.g., through node clustering) and apply batch training to save memory cost.
However, such batch training will lead to label bias within each batch, and
then result in over-confidence in model predictions. Since the connected nodes
with positively related labels tend to be assigned together, the traditional
cross-entropy minimization process will attend on the predictions of biased
classes in the batch, and may intensify the overfitting issue. To overcome the
label bias problem, we propose the adaptive label smoothing (ALS) method to
replace the one-hot hard labels with smoothed ones, which learns to allocate
label confidences from the biased classes to the others. Specifically, ALS
propagates node labels to aggregate the neighborhood label distribution in a
pre-processing step, and then updates the optimal smoothed labels online to
adapt to specific graph structure. Experiments on the real-world datasets
demonstrate that ALS can be generally applied to the main scalable learning
frameworks to calibrate the biased labels and improve generalization
performances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero Shot on the Cold-Start Problem: Model-Agnostic Interest Learning for Recommender Systems. (arXiv:2108.13592v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13592">
<div class="article-summary-box-inner">
<span><p>User behavior has been validated to be effective in revealing personalized
preferences for commercial recommendations. However, few user-item interactions
can be collected for new users, which results in a null space for their
interests, i.e., the cold-start dilemma. In this paper, a two-tower framework,
namely, the model-agnostic interest learning (MAIL) framework, is proposed to
address the cold-start recommendation (CSR) problem for recommender systems. In
MAIL, one unique tower is constructed to tackle the CSR from a zero-shot view,
and the other tower focuses on the general ranking task. Specifically, the
zero-shot tower first performs cross-modal reconstruction with dual
auto-encoders to obtain virtual behavior data from highly aligned hidden
features for new users; and the ranking tower can then output recommendations
for users based on the completed data by the zero-shot tower. Practically, the
ranking tower in MAIL is model-agnostic and can be implemented with any
embedding-based deep models. Based on the co-training of the two towers, the
MAIL presents an end-to-end method for recommender systems that shows an
incremental performance improvement. The proposed method has been successfully
deployed on the live recommendation system of NetEase Cloud Music to achieve a
click-through rate improvement of 13% to 15% for millions of users. Offline
experiments on real-world datasets also show its superior performance in CSR.
Our code is available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-balanced Learning For Domain Generalization. (arXiv:2108.13597v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13597">
<div class="article-summary-box-inner">
<span><p>Domain generalization aims to learn a prediction model on multi-domain source
data such that the model can generalize to a target domain with unknown
statistics. Most existing approaches have been developed under the assumption
that the source data is well-balanced in terms of both domain and class.
However, real-world training data collected with different composition biases
often exhibits severe distribution gaps for domain and class, leading to
substantial performance degradation. In this paper, we propose a self-balanced
domain generalization framework that adaptively learns the weights of losses to
alleviate the bias caused by different distributions of the multi-domain source
data. The self-balanced scheme is based on an auxiliary reweighting network
that iteratively updates the weight of loss conditioned on the domain and class
information by leveraging balanced meta data. Experimental results demonstrate
the effectiveness of our method overwhelming state-of-the-art works for domain
generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Does Adversarial Fine-Tuning Benefit BERT?. (arXiv:2108.13602v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13602">
<div class="article-summary-box-inner">
<span><p>Adversarial training (AT) is one of the most reliable methods for defending
against adversarial attacks in machine learning. Variants of this method have
been used as regularization mechanisms to achieve SOTA results on NLP
benchmarks, and they have been found to be useful for transfer learning and
continual learning. We search for the reasons for the effectiveness of AT by
contrasting vanilla and adversarially fine-tuned BERT models. We identify
partial preservation of BERT's syntactic abilities during fine-tuning as the
key to the success of AT. We observe that adversarially fine-tuned models
remain more faithful to BERT's language modeling behavior and are more
sensitive to the word order. As concrete examples of syntactic abilities, an
adversarially fine-tuned model could have an advantage of up to 38% on anaphora
agreement and up to 11% on dependency parsing. Our analysis demonstrates that
vanilla fine-tuning oversimplifies the sentence representation by focusing
heavily on one or a few label-indicative words. AT, however, moderates the
effect of these influential words and encourages representational diversity.
This allows for a more hierarchical representation of a sentence and leads to
the mitigation of BERT's loss of syntactic abilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation Fault: A Cheap Defense Against Adversarial Machine Learning. (arXiv:2108.13617v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13617">
<div class="article-summary-box-inner">
<span><p>Recently published attacks against deep neural networks (DNNs) have stressed
the importance of methodologies and tools to assess the security risks of using
this technology in critical systems. Efficient techniques for detecting
adversarial machine learning helps establishing trust and boost the adoption of
deep learning in sensitive and security systems. In this paper, we propose a
new technique for defending deep neural network classifiers, and convolutional
ones in particular. Our defense is cheap in the sense that it requires less
computation power despite a small cost to pay in terms of detection accuracy.
The work refers to a recently published technique called ML-LOO. We replace the
costly pixel by pixel leave-one-out approach of ML-LOO by adopting
coarse-grained leave-one-out. We evaluate and compare the efficiency of
different segmentation algorithms for this task. Our results show that a large
gain in efficiency is possible, even though penalized by a marginal decrease in
detection accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spike time displacement based error backpropagation in convolutional spiking neural networks. (arXiv:2108.13621v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13621">
<div class="article-summary-box-inner">
<span><p>We recently proposed the STiDi-BP algorithm, which avoids backward recursive
gradient computation, for training multi-layer spiking neural networks (SNNs)
with single-spike-based temporal coding. The algorithm employs a linear
approximation to compute the derivative of the spike latency with respect to
the membrane potential and it uses spiking neurons with piecewise linear
postsynaptic potential to reduce the computational cost and the complexity of
neural processing. In this paper, we extend the STiDi-BP algorithm to employ it
in deeper and convolutional architectures. The evaluation results on the image
classification task based on two popular benchmarks, MNIST and Fashion-MNIST
datasets with the accuracies of respectively 99.2% and 92.8%, confirm that this
algorithm has been applicable in deep SNNs. Another issue we consider is the
reduction of memory storage and computational cost. To do so, we consider a
convolutional SNN (CSNN) with two sets of weights: real-valued weights that are
updated in the backward pass and their signs, binary weights, that are employed
in the feedforward process. We evaluate the binary CSNN on two datasets of
MNIST and Fashion-MNIST and obtain acceptable performance with a negligible
accuracy drop with respect to real-valued weights (about $0.6%$ and $0.8%$
drops, respectively).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When are Deep Networks really better than Random Forests at small sample sizes?. (arXiv:2108.13637v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13637">
<div class="article-summary-box-inner">
<span><p>Random forests (RF) and deep networks (DN) are two of the most popular
machine learning methods in the current scientific literature and yield
differing levels of performance on different data modalities. We wish to
further explore and establish the conditions and domains in which each approach
excels, particularly in the context of sample size and feature dimension. To
address these issues, we tested the performance of these approaches across
tabular, image, and audio settings using varying model parameters and
architectures. Our focus is on datasets with at most 10,000 samples, which
represent a large fraction of scientific and biomedical datasets. In general,
we found RF to excel at tabular and structured data (image and audio) with
small sample sizes, whereas DN performed better on structured data with larger
sample sizes. Although we plan to continue updating this technical report in
the coming months, we believe the current preliminary results may be of
interest to others.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Synthesize Programs as Interpretable and Generalizable Policies. (arXiv:2108.13643v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13643">
<div class="article-summary-box-inner">
<span><p>Recently, deep reinforcement learning (DRL) methods have achieved impressive
performance on tasks in a variety of domains. However, neural network policies
produced with DRL methods are not human-interpretable and often have difficulty
generalizing to novel scenarios. To address these issues, prior works explore
learning programmatic policies that are more interpretable and structured for
generalization. Yet, these works either employ limited policy representations
(e.g. decision trees, state machines, or predefined program templates) or
require stronger supervision (e.g. input/output state pairs or expert
demonstrations). We present a framework that instead learns to synthesize a
program, which details the procedure to solve a task in a flexible and
expressive manner, solely from reward signals. To alleviate the difficulty of
learning to compose programs to induce the desired agent behavior from scratch,
we propose to first learn a program embedding space that continuously
parameterizes diverse behaviors in an unsupervised manner and then search over
the learned program embedding space to yield a program that maximizes the
return for a given task. Experimental results demonstrate that the proposed
framework not only learns to reliably synthesize task-solving programs but also
outperforms DRL and program synthesis baselines while producing interpretable
and more generalizable policies. We also justify the necessity of the proposed
two-stage learning scheme as well as analyze various methods for learning the
program embedding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Heterogeneous Graph Neural Network with Multi-view Representation Learning. (arXiv:2108.13650v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13650">
<div class="article-summary-box-inner">
<span><p>Graph neural networks for heterogeneous graph embedding is to project nodes
into a low-dimensional space by exploring the heterogeneity and semantics of
the heterogeneous graph. However, on the one hand, most of existing
heterogeneous graph embedding methods either insufficiently model the local
structure under specific semantic, or neglect the heterogeneity when
aggregating information from it. On the other hand, representations from
multiple semantics are not comprehensively integrated to obtain versatile node
embeddings. To address the problem, we propose a Heterogeneous Graph Neural
Network with Multi-View Representation Learning (named MV-HetGNN) for
heterogeneous graph embedding by introducing the idea of multi-view
representation learning. The proposed model consists of node feature
transformation, view-specific ego graph encoding and auto multi-view fusion to
thoroughly learn complex structural and semantic information for generating
comprehensive node representations. Extensive experiments on three real-world
heterogeneous graph datasets show that the proposed MV-HetGNN model
consistently outperforms all the state-of-the-art GNN baselines in various
downstream tasks, e.g., node classification, node clustering, and link
prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining Classes through Word Attribution. (arXiv:2108.13653v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13653">
<div class="article-summary-box-inner">
<span><p>In recent years, several methods have been proposed for explaining individual
predictions of deep learning models, yet there has been little study of how to
aggregate these predictions to explain how such models view classes as a whole
in text classification tasks. In this work, we propose a method for explaining
classes using deep learning models and the Integrated Gradients feature
attribution technique by aggregating explanations of individual examples in
text classification to general descriptions of the classes. We demonstrate the
approach on Web register (genre) classification using the XML-R model and the
Corpus of Online Registers of English (CORE), finding that the method
identifies plausible and discriminative keywords characterizing all but the
smallest class.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-Oriented Dialogue System as Natural Language Generation. (arXiv:2108.13679v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13679">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose to formulate the task-oriented dialogue system as
the purely natural language generation task, so as to fully leverage the
large-scale pre-trained models like GPT-2 and simplify complicated
delexicalization prepossessing. However, directly applying this method heavily
suffers from the dialogue entity inconsistency caused by the removal of
delexicalized tokens, as well as the catastrophic forgetting problem of the
pre-trained model during fine-tuning, leading to unsatisfactory performance. To
alleviate these problems, we design a novel GPT-Adapter-CopyNet network, which
incorporates the lightweight adapter and CopyNet modules into GPT-2 to achieve
better performance on transfer learning and dialogue entity generation.
Experimental results conducted on the DSTC8 Track 1 benchmark and MultiWOZ
dataset demonstrate that our proposed approach significantly outperforms
baseline models with a remarkable performance on automatic and human
evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phy-Q: A Benchmark for Physical Reasoning. (arXiv:2108.13696v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13696">
<div class="article-summary-box-inner">
<span><p>Humans are well-versed in reasoning about the behaviors of physical objects
when choosing actions to accomplish tasks, while it remains a major challenge
for AI. To facilitate research addressing this problem, we propose a new
benchmark that requires an agent to reason about physical scenarios and take an
action accordingly. Inspired by the physical knowledge acquired in infancy and
the capabilities required for robots to operate in real-world environments, we
identify 15 essential physical scenarios. For each scenario, we create a wide
variety of distinct task templates, and we ensure all the task templates within
the same scenario can be solved by using one specific physical rule. By having
such a design, we evaluate two distinct levels of generalization, namely the
local generalization and the broad generalization. We conduct an extensive
evaluation with human players, learning agents with varying input types and
architectures, and heuristic agents with different strategies. The benchmark
gives a Phy-Q (physical reasoning quotient) score that reflects the physical
reasoning ability of the agents. Our evaluation shows that 1) all agents fail
to reach human performance, and 2) learning agents, even with good local
generalization ability, struggle to learn the underlying physical reasoning
rules and fail to generalize broadly. We encourage the development of
intelligent agents with broad generalization abilities in physical domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-based Multi-Reference Learning for Image Super-Resolution. (arXiv:2108.13697v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13697">
<div class="article-summary-box-inner">
<span><p>This paper proposes a novel Attention-based Multi-Reference Super-resolution
network (AMRSR) that, given a low-resolution image, learns to adaptively
transfer the most similar texture from multiple reference images to the
super-resolution output whilst maintaining spatial coherence. The use of
multiple reference images together with attention-based sampling is
demonstrated to achieve significantly improved performance over
state-of-the-art reference super-resolution approaches on multiple benchmark
datasets. Reference super-resolution approaches have recently been proposed to
overcome the ill-posed problem of image super-resolution by providing
additional information from a high-resolution reference image. Multi-reference
super-resolution extends this approach by providing a more diverse pool of
image features to overcome the inherent information deficit whilst maintaining
memory efficiency. A novel hierarchical attention-based sampling approach is
introduced to learn the similarity between low-resolution image features and
multiple reference images based on a perceptual loss. Ablation demonstrates the
contribution of both multi-reference and hierarchical attention-based sampling
to overall performance. Perceptual and quantitative ground-truth evaluation
demonstrates significant improvement in performance even when the reference
images deviate significantly from the target image. The project website can be
found at https://marcopesavento.github.io/AMRSR/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TNNT: The Named Entity Recognition Toolkit. (arXiv:2108.13700v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13700">
<div class="article-summary-box-inner">
<span><p>Extraction of categorised named entities from text is a complex task given
the availability of a variety of Named Entity Recognition (NER) models and the
unstructured information encoded in different source document formats.
Processing the documents to extract text, identifying suitable NER models for a
task, and obtaining statistical information is important in data analysis to
make informed decisions. This paper presents TNNT, a toolkit that automates the
extraction of categorised named entities from unstructured information encoded
in source documents, using diverse state-of-the-art Natural Language Processing
(NLP) tools and NER models. TNNT integrates 21 different NER models as part of
a Knowledge Graph Construction Pipeline (KGCP) that takes a document set as
input and processes it based on the defined settings, applying the selected
blocks of NER models to output the results. The toolkit generates all results
with an integrated summary of the extracted entities, enabling enhanced data
analysis to support the KGCP, and also, to aid further NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemIE: Semantically-aware Image Extrapolation. (arXiv:2108.13702v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13702">
<div class="article-summary-box-inner">
<span><p>We propose a semantically-aware novel paradigm to perform image extrapolation
that enables the addition of new object instances. All previous methods are
limited in their capability of extrapolation to merely extending the already
existing objects in the image. However, our proposed approach focuses not only
on (i) extending the already present objects but also on (ii) adding new
objects in the extended region based on the context. To this end, for a given
image, we first obtain an object segmentation map using a state-of-the-art
semantic segmentation method. The, thus, obtained segmentation map is fed into
a network to compute the extrapolated semantic segmentation and the
corresponding panoptic segmentation maps. The input image and the obtained
segmentation maps are further utilized to generate the final extrapolated
image. We conduct experiments on Cityscapes and ADE20K-bedroom datasets and
show that our method outperforms all baselines in terms of FID, and similarity
in object co-occurrence statistics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Robustness of Off-Policy Evaluation. (arXiv:2108.13703v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13703">
<div class="article-summary-box-inner">
<span><p>Off-policy Evaluation (OPE), or offline evaluation in general, evaluates the
performance of hypothetical policies leveraging only offline log data. It is
particularly useful in applications where the online interaction involves high
stakes and expensive setting such as precision medicine and recommender
systems. Since many OPE estimators have been proposed and some of them have
hyperparameters to be tuned, there is an emerging challenge for practitioners
to select and tune OPE estimators for their specific application.
Unfortunately, identifying a reliable estimator from results reported in
research papers is often difficult because the current experimental procedure
evaluates and compares the estimators' performance on a narrow set of
hyperparameters and evaluation policies. Therefore, it is difficult to know
which estimator is safe and reliable to use. In this work, we develop
Interpretable Evaluation for Offline Evaluation (IEOE), an experimental
procedure to evaluate OPE estimators' robustness to changes in hyperparameters
and/or evaluation policies in an interpretable manner. Then, using the IEOE
procedure, we perform extensive evaluation of a wide variety of existing
estimators on Open Bandit Dataset, a large-scale public real-world dataset for
OPE. We demonstrate that our procedure can evaluate the estimators' robustness
to the hyperparamter choice, helping us avoid using unsafe estimators. Finally,
we apply IEOE to real-world e-commerce platform data and demonstrate how to use
our protocol in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Monolingual versus Multilingual BERTology for Vietnamese Extractive Multi-Document Summarization. (arXiv:2108.13741v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13741">
<div class="article-summary-box-inner">
<span><p>Recent researches have demonstrated that BERT shows potential in a wide range
of natural language processing tasks. It is adopted as an encoder for many
state-of-the-art automatic summarizing systems, which achieve excellent
performance. However, so far, there is not much work done for Vietnamese. In
this paper, we showcase how BERT can be implemented for extractive text
summarization in Vietnamese. We introduce a novel comparison between different
multilingual and monolingual BERT models. The experiment results indicate that
monolingual models produce promising results compared to other multilingual
models and previous text summarizing models for Vietnamese.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Horn Non-Clausal Class and its Polynomiality. (arXiv:2108.13744v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13744">
<div class="article-summary-box-inner">
<span><p>The expressiveness of propositional non-clausal (NC) formulas is
exponentially richer than that of clausal formulas. Yet, clausal efficiency
outperforms non-clausal one. Indeed, a major weakness of the latter is that,
while Horn clausal formulas, along with Horn algorithms, are crucial for the
high efficiency of clausal reasoning, no Horn-like formulas in non-clausal form
had been proposed. To overcome such weakness, we define the hybrid class
$\mathbb{H_{NC}}$ of Horn Non-Clausal (Horn-NC) formulas, by adequately lifting
the Horn pattern to NC form, and argue that $\mathbb{H_{NC}}$, along with
future Horn-NC algorithms, shall increase non-clausal efficiency just as the
Horn class has increased clausal efficiency. Secondly, we: (i) give the
compact, inductive definition of $\mathbb{H_{NC}}$; (ii) prove that
syntactically $\mathbb{H_{NC}}$ subsumes the Horn class but semantically both
classes are equivalent, and (iii) characterize the non-clausal formulas
belonging to $\mathbb{H_{NC}}$. Thirdly, we define the Non-Clausal
Unit-Resolution calculus, $UR_{NC}$, and prove that it checks the
satisfiability of $\mathbb{H_{NC}}$ in polynomial time. This fact, to our
knowledge, makes $\mathbb{H_{NC}}$ the first characterized polynomial class in
NC reasoning. Finally, we prove that $\mathbb{H_{NC}}$ is linearly
recognizable, and also that it is both strictly succincter and exponentially
richer than the Horn class. We discuss that in NC automated reasoning, e.g.
satisfiability solving, theorem proving, logic programming, etc., can directly
benefit from $\mathbb{H_{NC}}$ and $UR_{NC}$ and that, as a by-product of its
proved properties, $\mathbb{H_{NC}}$ arises as a new alternative to analyze
Horn functions and implication systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The five Is: Key principles for interpretable and safe conversational AI. (arXiv:2108.13766v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13766">
<div class="article-summary-box-inner">
<span><p>In this position paper, we present five key principles, namely
interpretability, inherent capability to explain, independent data, interactive
learning, and inquisitiveness, for the development of conversational AI that,
unlike the currently popular black box approaches, is transparent and
accountable. At present, there is a growing concern with the use of black box
statistical language models: While displaying impressive average performance,
such systems are also prone to occasional spectacular failures, for which there
is no clear remedy. In an effort to initiate a discussion on possible
alternatives, we outline and exemplify how our five principles enable the
development of conversational AI systems that are transparent and thus safer
for use. We also present some of the challenges inherent in the implementation
of those principles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Artificial Intelligence Algorithms for Natural Language Processing and the Semantic Web Ontology Learning. (arXiv:2108.13772v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13772">
<div class="article-summary-box-inner">
<span><p>Evolutionary clustering algorithms have considered as the most popular and
widely used evolutionary algorithms for minimising optimisation and practical
problems in nearly all fields. In this thesis, a new evolutionary clustering
algorithm star (ECA*) is proposed. Additionally, a number of experiments were
conducted to evaluate ECA* against five state-of-the-art approaches. For this,
32 heterogeneous and multi-featured datasets were used to examine their
performance using internal and external clustering measures, and to measure the
sensitivity of their performance towards dataset features in the form of
operational framework. The results indicate that ECA* overcomes its competitive
techniques in terms of the ability to find the right clusters. Based on its
superior performance, exploiting and adapting ECA* on the ontology learning had
a vital possibility. In the process of deriving concept hierarchies from
corpora, generating formal context may lead to a time-consuming process.
Therefore, formal context size reduction results in removing uninterested and
erroneous pairs, taking less time to extract the concept lattice and concept
hierarchies accordingly. In this premise, this work aims to propose a framework
to reduce the ambiguity of the formal context of the existing framework using
an adaptive version of ECA*. In turn, an experiment was conducted by applying
385 sample corpora from Wikipedia on the two frameworks to examine the
reduction of formal context size, which leads to yield concept lattice and
concept hierarchy. The resulting lattice of formal context was evaluated to the
original one using concept lattice-invariants. Accordingly, the homomorphic
between the two lattices preserves the quality of resulting concept hierarchies
by 89% in contrast to the basic ones, and the reduced concept lattice inherits
the structural relation of the original one.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Addressing the IEEE AV Test Challenge with Scenic and VerifAI. (arXiv:2108.13796v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13796">
<div class="article-summary-box-inner">
<span><p>This paper summarizes our formal approach to testing autonomous vehicles
(AVs) in simulation for the IEEE AV Test Challenge. We demonstrate a systematic
testing framework leveraging our previous work on formally-driven simulation
for intelligent cyber-physical systems. First, to model and generate
interactive scenarios involving multiple agents, we used Scenic, a
probabilistic programming language for specifying scenarios. A Scenic program
defines an abstract scenario as a distribution over configurations of physical
objects and their behaviors over time. Sampling from an abstract scenario
yields many different concrete scenarios which can be run as test cases for the
AV. Starting from a Scenic program encoding an abstract driving scenario, we
can use the VerifAI toolkit to search within the scenario for failure cases
with respect to multiple AV evaluation metrics. We demonstrate the
effectiveness of our testing framework by identifying concrete failure
scenarios for an open-source autopilot, Apollo, starting from a variety of
realistic traffic scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chi-square Loss for Softmax: an Echo of Neural Network Structure. (arXiv:2108.13822v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13822">
<div class="article-summary-box-inner">
<span><p>Softmax working with cross-entropy is widely used in classification, which
evaluates the similarity between two discrete distribution columns (predictions
and true labels). Inspired by chi-square test, we designed a new loss function
called chi-square loss, which is also works for Softmax. Chi-square loss has a
statistical background. We proved that it is unbiased in optimization, and
clarified its using conditions (its formula determines that it must work with
label smoothing). In addition, we studied the sample distribution of this loss
function by visualization and found that the distribution is related to the
neural network structure, which is distinct compared to cross-entropy. In the
past, the influence of structure was often ignored when visualizing. Chi-square
loss can notice changes in neural network structure because it is very strict,
and we explained the reason for this strictness. We also studied the influence
of label smoothing and discussed the relationship between label smoothing and
training accuracy and stability. Since the chi-square loss is very strict, the
performance will degrade when dealing samples of very many classes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PACE: Posthoc Architecture-Agnostic Concept Extractor for Explaining CNNs. (arXiv:2108.13828v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13828">
<div class="article-summary-box-inner">
<span><p>Deep CNNs, though have achieved the state of the art performance in image
classification tasks, remain a black-box to a human using them. There is a
growing interest in explaining the working of these deep models to improve
their trustworthiness. In this paper, we introduce a Posthoc
Architecture-agnostic Concept Extractor (PACE) that automatically extracts
smaller sub-regions of the image called concepts relevant to the black-box
prediction. PACE tightly integrates the faithfulness of the explanatory
framework to the black-box model. To the best of our knowledge, this is the
first work that extracts class-specific discriminative concepts in a posthoc
manner automatically. The PACE framework is used to generate explanations for
two different CNN architectures trained for classifying the AWA2 and
Imagenet-Birds datasets. Extensive human subject experiments are conducted to
validate the human interpretability and consistency of the explanations
extracted by PACE. The results from these experiments suggest that over 72% of
the concepts extracted by PACE are human interpretable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Common Testing Terminology for Software Engineering and Artificial Intelligence Experts. (arXiv:2108.13837v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13837">
<div class="article-summary-box-inner">
<span><p>Analytical quality assurance, especially testing, is an integral part of
software-intensive system development. With the increased usage of Artificial
Intelligence (AI) and Machine Learning (ML) as part of such systems, this
becomes more difficult as well-understood software testing approaches cannot be
applied directly to the AI-enabled parts of the system. The required adaptation
of classical testing approaches and development of new concepts for AI would
benefit from a deeper understanding and exchange between AI and software
engineering experts. A major obstacle on this way, we see in the different
terminologies used in the two communities. As we consider a mutual
understanding of the testing terminology as a key, this paper contributes a
mapping between the most important concepts from classical software testing and
AI testing. In the mapping, we highlight differences in relevance and naming of
the mapped concepts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fiducial marker recovery and detection from severely truncated data in navigation assisted spine surgery. (arXiv:2108.13844v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13844">
<div class="article-summary-box-inner">
<span><p>Fiducial markers are commonly used in navigation assisted minimally invasive
spine surgery (MISS) and they help transfer image coordinates into real world
coordinates. In practice, these markers might be located outside the
field-of-view (FOV), due to the limited detector sizes of C-arm cone-beam
computed tomography (CBCT) systems used in intraoperative surgeries. As a
consequence, reconstructed markers in CBCT volumes suffer from artifacts and
have distorted shapes, which sets an obstacle for navigation. In this work, we
propose two fiducial marker detection methods: direct detection from distorted
markers (direct method) and detection after marker recovery (recovery method).
For direct detection from distorted markers in reconstructed volumes, an
efficient automatic marker detection method using two neural networks and a
conventional circle detection algorithm is proposed. For marker recovery, a
task-specific learning strategy is proposed to recover markers from severely
truncated data. Afterwards, a conventional marker detection algorithm is
applied for position detection. The two methods are evaluated on simulated data
and real data, both achieving a marker registration error smaller than 0.2 mm.
Our experiments demonstrate that the direct method is capable of detecting
distorted markers accurately and the recovery method with task-specific
learning has high robustness and generalizability on various data sets. In
addition, the task-specific learning is able to reconstruct other structures of
interest accurately, e.g. ribs for image-guided needle biopsy, from severely
truncated data, which empowers CBCT systems with new potential applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Domain Adaptation for Question Answering using Limited Text Corpora. (arXiv:2108.13854v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13854">
<div class="article-summary-box-inner">
<span><p>Question generation has recently shown impressive results in customizing
question answering (QA) systems to new domains. These approaches circumvent the
need for manually annotated training data from the new domain and, instead,
generate synthetic question-answer pairs that are used for training. However,
existing methods for question generation rely on large amounts of synthetically
generated datasets and costly computational resources, which render these
techniques widely inaccessible when the text corpora is of limited size. This
is problematic as many niche domains rely on small text corpora, which
naturally restricts the amount of synthetic data that can be generated. In this
paper, we propose a novel framework for domain adaptation called contrastive
domain adaptation for QA (CAQA). Specifically, CAQA combines techniques from
question generation and domain-invariant learning to answer out-of-domain
questions in settings with limited text corpora. Here, we train a QA system on
both source data and generated data from the target domain with a contrastive
adaptation loss that is incorporated in the training objective. By combining
techniques from question generation and domain-invariant learning, our model
achieved considerable improvements compared to state-of-the-art baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GRP-FED: Addressing Client Imbalance in Federated Learning via Global-Regularized Personalization. (arXiv:2108.13858v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13858">
<div class="article-summary-box-inner">
<span><p>Since data is presented long-tailed in reality, it is challenging for
Federated Learning (FL) to train across decentralized clients as practical
applications. We present Global-Regularized Personalization (GRP-FED) to tackle
the data imbalanced issue by considering a single global model and multiple
local models for each client. With adaptive aggregation, the global model
treats multiple clients fairly and mitigates the global long-tailed issue. Each
local model is learned from the local data and aligns with its distribution for
customization. To prevent the local model from just overfitting, GRP-FED
applies an adversarial discriminator to regularize between the learned
global-local features. Extensive results show that our GRP-FED improves under
both global and local scenarios on real-world MIT-BIH and synthesis CIFAR-10
datasets, achieving comparable performance and addressing client imbalance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InSeGAN: A Generative Approach to Segmenting Identical Instances in Depth Images. (arXiv:2108.13865v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13865">
<div class="article-summary-box-inner">
<span><p>In this paper, we present InSeGAN, an unsupervised 3D generative adversarial
network (GAN) for segmenting (nearly) identical instances of rigid objects in
depth images. Using an analysis-by-synthesis approach, we design a novel GAN
architecture to synthesize a multiple-instance depth image with independent
control over each instance. InSeGAN takes in a set of code vectors (e.g.,
random noise vectors), each encoding the 3D pose of an object that is
represented by a learned implicit object template. The generator has two
distinct modules. The first module, the instance feature generator, uses each
encoded pose to transform the implicit template into a feature map
representation of each object instance. The second module, the depth image
renderer, aggregates all of the single-instance feature maps output by the
first module and generates a multiple-instance depth image. A discriminator
distinguishes the generated multiple-instance depth images from the
distribution of true depth images. To use our model for instance segmentation,
we propose an instance pose encoder that learns to take in a generated depth
image and reproduce the pose code vectors for all of the object instances. To
evaluate our approach, we introduce a new synthetic dataset, "Insta-10",
consisting of 100,000 depth images, each with 5 instances of an object from one
of 10 classes. Our experiments on Insta-10, as well as on real-world noisy
depth images, show that InSeGAN achieves state-of-the-art performance, often
outperforming prior methods by large margins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Retriever-Reader Meets Scenario-Based Multiple-Choice Questions. (arXiv:2108.13875v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13875">
<div class="article-summary-box-inner">
<span><p>Scenario-based question answering (SQA) requires retrieving and reading
paragraphs from a large corpus to answer a question which is contextualized by
a long scenario description. Since a scenario contains both keyphrases for
retrieval and much noise, retrieval for SQA is extremely difficult. Moreover,
it can hardly be supervised due to the lack of relevance labels of paragraphs
for SQA. To meet the challenge, in this paper we propose a joint
retriever-reader model called JEEVES where the retriever is implicitly
supervised only using QA labels via a novel word weighting mechanism. JEEVES
significantly outperforms a variety of strong baselines on multiple-choice
questions in three SQA datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mMARCO: A Multilingual Version of MS MARCO Passage Ranking Dataset. (arXiv:2108.13897v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13897">
<div class="article-summary-box-inner">
<span><p>The MS MARCO ranking dataset has been widely used for training deep learning
models for IR tasks, achieving considerable effectiveness on diverse zero-shot
scenarios. However, this type of resource is scarce in other languages than
English. In this work we present mMARCO, a multilingual version of the MS MARCO
passage ranking dataset comprising 8 languages that was created using machine
translation. We evaluated mMARCO by fine-tuning mono and multilingual
re-ranking models on it. Experimental results demonstrate that multilingual
models fine-tuned on our translated dataset achieve superior effectiveness than
models fine-tuned on the original English version alone. Also, our distilled
multilingual re-ranker is competitive with non-distilled models while having
5.4 times fewer parameters. The translated datasets as well as fine-tuned
models are available at https://github.com/unicamp-dl/mMARCO.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Retrieval Augmented Generation for Zero-shot Slot Filling. (arXiv:2108.13934v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13934">
<div class="article-summary-box-inner">
<span><p>Automatically inducing high quality knowledge graphs from a given collection
of documents still remains a challenging problem in AI. One way to make headway
for this problem is through advancements in a related task known as slot
filling. In this task, given an entity query in form of [Entity, Slot, ?], a
system is asked to fill the slot by generating or extracting the missing value
exploiting evidence extracted from relevant passage(s) in the given document
collection. The recent works in the field try to solve this task in an
end-to-end fashion using retrieval-based language models. In this paper, we
present a novel approach to zero-shot slot filling that extends dense passage
retrieval with hard negatives and robust training procedures for retrieval
augmented generation models. Our model reports large improvements on both T-REx
and zsRE slot filling datasets, improving both passage retrieval and slot value
generation, and ranking at the top-1 position in the KILT leaderboard.
Moreover, we demonstrate the robustness of our system showing its domain
adaptation capability on a new variant of the TACRED dataset for slot filling,
through a combination of zero/few-shot learning. We release the source code and
pre-trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward AI-enhanced online-characterization and shaping of ultrashort X-ray free-electron laser pulses. (arXiv:2108.13979v1 [physics.data-an])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13979">
<div class="article-summary-box-inner">
<span><p>X-ray free-electron lasers (XFELs) as the world`s most brilliant light
sources provide ultrashort X-ray pulses with durations typically on the order
of femtoseconds. Recently, they have approached and entered the attosecond
regime, which holds new promises for single-molecule imaging and studying
nonlinear and ultrafast phenomena like localized electron dynamics. The
technological evolution of XFELs toward well-controllable light sources for
precise metrology of ultrafast processes was, however, hampered by the
diagnostic capabilities for characterizing X-ray pulses at the attosecond
frontier. In this regard, the spectroscopic technique of photoelectron angular
streaking has successfully proven how to non-destructively retrieve the exact
time-energy structure of XFEL pulses on a single-shot basis. By using
artificial intelligence algorithms, in particular convolutional neural
networks, we here show how this technique can be leveraged from its
proof-of-principle stage toward routine diagnostics at XFELs, thus enhancing
and refining their scientific access in all related disciplines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incorporating Deception into CyberBattleSim for Autonomous Defense. (arXiv:2108.13980v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13980">
<div class="article-summary-box-inner">
<span><p>Deceptive elements, including honeypots and decoys, were incorporated into
the Microsoft CyberBattleSim experimentation and research platform. The
defensive capabilities of the deceptive elements were tested using
reinforcement learning based attackers in the provided capture the flag
environment. The attacker's progress was found to be dependent on the number
and location of the deceptive elements. This is a promising step toward
reproducibly testing attack and defense algorithms in a simulated enterprise
network with deceptive defensive elements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Mitosis against Domain Shift using a Fused Detector and Deep Ensemble Classification Model for MIDOG Challenge. (arXiv:2108.13983v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13983">
<div class="article-summary-box-inner">
<span><p>Mitotic figure count is an important marker of tumor proliferation and has
been shown to be associated with patients' prognosis. Deep learning based
mitotic figure detection methods have been utilized to automatically locate the
cell in mitosis using hematoxylin \&amp; eosin (H\&amp;E) stained images. However, the
model performance deteriorates due to the large variation of color tone and
intensity in H\&amp;E images. In this work, we proposed a two stage mitotic figure
detection framework by fusing a detector and a deep ensemble classification
model. To alleviate the impact of color variation in H\&amp;E images, we utilize
both stain normalization and data augmentation, aiding model to learn color
irrelevant features. The proposed model obtains an F1 score of 0.7550 on the
preliminary testing set released by the MIDOG challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Subsampling Based Method for Causal Discovery on Discrete Data. (arXiv:2108.13984v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13984">
<div class="article-summary-box-inner">
<span><p>Inferring causal directions on discrete and categorical data is an important
yet challenging problem. Even though the additive noise models (ANMs) approach
can be adapted to the discrete data, the functional structure assumptions make
it not applicable on categorical data. Inspired by the principle that the cause
and mechanism are independent, various methods have been developed, leveraging
independence tests such as the distance correlation measure. In this work, we
take an alternative perspective and propose a subsampling-based method to test
the independence between the generating schemes of the cause and that of the
mechanism. Our methodology works for both discrete and categorical data and
does not imply any functional model on the data, making it a more flexible
approach. To demonstrate the efficacy of our methodology, we compare it with
existing baselines over various synthetic data and real data experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepTaskAPT: Insider APT detection using Task-tree based Deep Learning. (arXiv:2108.13989v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13989">
<div class="article-summary-box-inner">
<span><p>APT, known as Advanced Persistent Threat, is a difficult challenge for cyber
defence. These threats make many traditional defences ineffective as the
vulnerabilities exploited by these threats are insiders who have access to and
are within the network. This paper proposes DeepTaskAPT, a heterogeneous
task-tree based deep learning method to construct a baseline model based on
sequences of tasks using a Long Short-Term Memory (LSTM) neural network that
can be applied across different users to identify anomalous behaviour. Rather
than applying the model to sequential log entries directly, as most current
approaches do, DeepTaskAPT applies a process tree based task generation method
to generate sequential log entries for the deep learning model. To assess the
performance of DeepTaskAPT, we use a recently released synthetic dataset, DARPA
Operationally Transparent Computing (OpTC) dataset and a real-world dataset,
Los Alamos National Laboratory (LANL) dataset. Both of them are composed of
host-based data collected from sensors. Our results show that DeepTaskAPT
outperforms similar approaches e.g. DeepLog and the DeepTaskAPT baseline model
demonstrate its capability to detect malicious traces in various attack
scenarios while having high accuracy and low false-positive rates. To the best
of knowledge this is the very first attempt of using recently introduced OpTC
dataset for cyber threat detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effective Sequence-to-Sequence Dialogue State Tracking. (arXiv:2108.13990v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13990">
<div class="article-summary-box-inner">
<span><p>Sequence-to-sequence models have been applied to a wide variety of NLP tasks,
but how to properly use them for dialogue state tracking has not been
systematically investigated. In this paper, we study this problem from the
perspectives of pre-training objectives as well as the formats of context
representations. We demonstrate that the choice of pre-training objective makes
a significant difference to the state tracking quality. In particular, we find
that masked span prediction is more effective than auto-regressive language
modeling. We also explore using Pegasus, a span prediction-based pre-training
objective for text summarization, for the state tracking model. We found that
pre-training for the seemingly distant summarization task works surprisingly
well for dialogue state tracking. In addition, we found that while recurrent
state context representation works also reasonably well, the model may have a
hard time recovering from earlier mistakes. We conducted experiments on the
MultiWOZ 2.1-2.4 data sets with consistent observations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantization of Generative Adversarial Networks for Efficient Inference: a Methodological Study. (arXiv:2108.13996v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13996">
<div class="article-summary-box-inner">
<span><p>Generative adversarial networks (GANs) have an enormous potential impact on
digital content creation, e.g., photo-realistic digital avatars, semantic
content editing, and quality enhancement of speech and images. However, the
performance of modern GANs comes together with massive amounts of computations
performed during the inference and high energy consumption. That complicates,
or even makes impossible, their deployment on edge devices. The problem can be
reduced with quantization -- a neural network compression technique that
facilitates hardware-friendly inference by replacing floating-point
computations with low-bit integer ones. While quantization is well established
for discriminative models, the performance of modern quantization techniques in
application to GANs remains unclear. GANs generate content of a more complex
structure than discriminative models, and thus quantization of GANs is
significantly more challenging. To tackle this problem, we perform an extensive
experimental study of state-of-art quantization techniques on three diverse GAN
architectures, namely StyleGAN, Self-Attention GAN, and CycleGAN. As a result,
we discovered practical recipes that allowed us to successfully quantize these
models for inference with 4/8-bit weights and 8-bit activations while
preserving the quality of the original full-precision models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">First return, then explore. (arXiv:2004.12919v5 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.12919">
<div class="article-summary-box-inner">
<span><p>The promise of reinforcement learning is to solve complex sequential decision
problems autonomously by specifying a high-level reward function only. However,
reinforcement learning algorithms struggle when, as is often the case, simple
and intuitive rewards provide sparse and deceptive feedback. Avoiding these
pitfalls requires thoroughly exploring the environment, but creating algorithms
that can do so remains one of the central challenges of the field. We
hypothesise that the main impediment to effective exploration originates from
algorithms forgetting how to reach previously visited states ("detachment") and
from failing to first return to a state before exploring from it
("derailment"). We introduce Go-Explore, a family of algorithms that addresses
these two challenges directly through the simple principles of explicitly
remembering promising states and first returning to such states before
intentionally exploring. Go-Explore solves all heretofore unsolved Atari games
and surpasses the state of the art on all hard-exploration games, with orders
of magnitude improvements on the grand challenges Montezuma's Revenge and
Pitfall. We also demonstrate the practical potential of Go-Explore on a
sparse-reward pick-and-place robotics task. Additionally, we show that adding a
goal-conditioned policy can further improve Go-Explore's exploration efficiency
and enable it to handle stochasticity throughout training. The substantial
performance gains from Go-Explore suggest that the simple principles of
remembering states, returning to them, and exploring from them are a powerful
and general approach to exploration, an insight that may prove critical to the
creation of truly intelligent learning agents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shape Defense Against Adversarial Attacks. (arXiv:2008.13336v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.13336">
<div class="article-summary-box-inner">
<span><p>Humans rely heavily on shape information to recognize objects. Conversely,
convolutional neural networks (CNNs) are biased more towards texture. This is
perhaps the main reason why CNNs are vulnerable to adversarial examples. Here,
we explore how shape bias can be incorporated into CNNs to improve their
robustness. Two algorithms are proposed, based on the observation that edges
are invariant to moderate imperceptible perturbations. In the first one, a
classifier is adversarially trained on images with the edge map as an
additional channel. At inference time, the edge map is recomputed and
concatenated to the image. In the second algorithm, a conditional GAN is
trained to translate the edge maps, from clean and/or perturbed images, into
clean images. Inference is done over the generated image corresponding to the
input's edge map. Extensive experiments over 10 datasets demonstrate the
effectiveness of the proposed algorithms against FGSM and $\ell_\infty$ PGD-40
attacks. Further, we show that a) edge information can also benefit other
adversarial training methods, and b) CNNs trained on edge-augmented inputs are
more robust against natural image corruptions such as motion blur, impulse
noise and JPEG compression, than CNNs trained solely on RGB images. From a
broader perspective, our study suggests that CNNs do not adequately account for
image structures that are crucial for robustness. Code is available
at:~\url{https://github.com/aliborji/Shapedefence.git}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Blindfolded Attackers Still Threatening: Strict Black-Box Adversarial Attacks on Graphs. (arXiv:2012.06757v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06757">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks on graphs have attracted considerable research interests.
Existing works assume the attacker is either (partly) aware of the victim
model, or able to send queries to it. These assumptions are, however,
unrealistic. To bridge the gap between theoretical graph attacks and real-world
scenarios, in this work, we propose a novel and more realistic setting: strict
black-box graph attack, in which the attacker has no knowledge about the victim
model at all and is not allowed to send any queries. To design such an attack
strategy, we first propose a generic graph filter to unify different families
of graph-based models. The strength of attacks can then be quantified by the
change in the graph filter before and after attack. By maximizing this change,
we are able to find an effective attack strategy, regardless of the underlying
model. To solve this optimization problem, we also propose a relaxation
technique and approximation theories to reduce the difficulty as well as the
computational expense. Experiments demonstrate that, even with no exposure to
the model, the Macro-F1 drops 6.4% in node classification and 29.5% in graph
classification, which is a significant result compared with existent works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Ensemble Learning under the Era of Deep Learning. (arXiv:2101.08387v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08387">
<div class="article-summary-box-inner">
<span><p>Due to the dominant position of deep learning (mostly deep neural networks)
in various artificial intelligence applications, recently, ensemble learning
based on deep neural networks (ensemble deep learning) has shown significant
performances in improving the generalization of learning system. However, since
modern deep neural networks usually have millions to billions of parameters,
the time and space overheads for training multiple base deep learners and
testing with the ensemble deep learner are far greater than that of traditional
ensemble learning. Though several algorithms of fast ensemble deep learning
have been proposed to promote the deployment of ensemble deep learning in some
applications, further advances still need to be made for many applications in
specific fields, where the developing time and computing resources are usually
restricted or the data to be processed is of large dimensionality. An urgent
problem needs to be solved is how to take the significant advantages of
ensemble deep learning while reduce the required time and space overheads so
that many more applications in specific fields can benefit from it. For the
alleviation of this problem, it is essential to know about how ensemble
learning has developed under the era of deep learning. Thus, in this article,
we present discussions focusing on data analyses of published works,
methodologies, recent advances and unattainability of traditional ensemble
learning and ensemble deep learning. We hope this article will be helpful to
realize the technical challenges faced by future developments of ensemble
learning under the era of deep learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding self-supervised Learning Dynamics without Contrastive Pairs. (arXiv:2102.06810v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06810">
<div class="article-summary-box-inner">
<span><p>While contrastive approaches of self-supervised learning (SSL) learn
representations by minimizing the distance between two augmented views of the
same data point (positive pairs) and maximizing views from different data
points (negative pairs), recent \emph{non-contrastive} SSL (e.g., BYOL and
SimSiam) show remarkable performance {\it without} negative pairs, with an
extra learnable predictor and a stop-gradient operation. A fundamental question
arises: why do these methods not collapse into trivial representations? We
answer this question via a simple theoretical study and propose a novel
approach, DirectPred, that \emph{directly} sets the linear predictor based on
the statistics of its inputs, without gradient training. On ImageNet, it
performs comparably with more complex two-layer non-linear predictors that
employ BatchNorm and outperforms a linear predictor by $2.5\%$ in 300-epoch
training (and $5\%$ in 60-epoch). DirectPred is motivated by our theoretical
study of the nonlinear learning dynamics of non-contrastive SSL in simple
linear networks. Our study yields conceptual insights into how non-contrastive
SSL methods learn, how they avoid representational collapse, and how multiple
factors, like predictor networks, stop-gradients, exponential moving averages,
and weight decay all come into play. Our simple theory recapitulates the
results of real-world ablation studies in both STL-10 and ImageNet. Code is
released https://github.com/facebookresearch/luckmatters/tree/master/ssl.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dont Just Divide; Polarize and Conquer!. (arXiv:2102.11872v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11872">
<div class="article-summary-box-inner">
<span><p>In data containing heterogeneous subpopulations, classification performance
benefits from incorporating the knowledge of cluster structure in the
classifier. Previous methods for such combined clustering and classification
are either 1) classifier-specific and not generic, or 2) independently perform
clustering and classifier training, which may not form clusters that can
potentially benefit classifier performance. The question of how to perform
clustering to improve the performance of classifiers trained on the clusters
has received scant attention in previous literature, despite its importance in
several real-world applications. In this paper, we design a simple and
efficient classification algorithm called Clustering Aware Classification
(CAC), to find clusters that are well suited for being used as training
datasets by classifiers for each underlying subpopulation. Our experiments on
synthetic and real benchmark datasets demonstrate the efficacy of CAC over
previous methods for combined clustering and classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020. (arXiv:2104.10201v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10201">
<div class="article-summary-box-inner">
<span><p>This paper presents the results and insights from the black-box optimization
(BBO) challenge at NeurIPS 2020 which ran from July-October, 2020. The
challenge emphasized the importance of evaluating derivative-free optimizers
for tuning the hyperparameters of machine learning models. This was the first
black-box optimization challenge with a machine learning emphasis. It was based
on tuning (validation set) performance of standard machine learning models on
real datasets. This competition has widespread impact as black-box optimization
(e.g., Bayesian optimization) is relevant for hyperparameter tuning in almost
every machine learning project as well as many applications outside of machine
learning. The final leaderboard was determined using the optimization
performance on held-out (hidden) objective functions, where the optimizers ran
without human intervention. Baselines were set using the default settings of
several open-source black-box optimization packages as well as random search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Effects of Air Quality on the Spread of the COVID-19 Pandemic in Italy: An Artificial Intelligence Approach. (arXiv:2104.12546v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12546">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic considerably affects public health systems around the
world. The lack of knowledge about the virus, the extension of this phenomenon,
and the speed of the evolution of the infection are all factors that highlight
the necessity of employing new approaches to study these events. Artificial
intelligence techniques may be useful in analyzing data related to areas
affected by the virus. The aim of this work is to investigate any possible
relationships between air quality and confirmed cases of COVID-19 in Italian
districts. Specifically, we report an analysis of the correlation between daily
COVID-19 cases and environmental factors, such as temperature, relative
humidity, and atmospheric pollutants. Our analysis confirms a significant
association of some environmental parameters with the spread of the virus. This
suggests that machine learning models trained on the environmental parameters
to predict the number of future infected cases may be accurate. Predictive
models may be useful for helping institutions in making decisions for
protecting the population and contrasting the pandemic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curious Representation Learning for Embodied Intelligence. (arXiv:2105.01060v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01060">
<div class="article-summary-box-inner">
<span><p>Self-supervised representation learning has achieved remarkable success in
recent years. By subverting the need for supervised labels, such approaches are
able to utilize the numerous unlabeled images that exist on the Internet and in
photographic datasets. Yet to build truly intelligent agents, we must construct
representation learning algorithms that can learn not only from datasets but
also learn from environments. An agent in a natural environment will not
typically be fed curated data. Instead, it must explore its environment to
acquire the data it will learn from. We propose a framework, curious
representation learning (CRL), which jointly learns a reinforcement learning
policy and a visual representation model. The policy is trained to maximize the
error of the representation learner, and in doing so is incentivized to explore
its environment. At the same time, the learned representation becomes stronger
and stronger as the policy feeds it ever harder data to learn from. Our learned
representations enable promising transfer to downstream navigation tasks,
performing better than or comparably to ImageNet pretraining without using any
supervision at all. In addition, despite being trained in simulation, our
learned representations can obtain interpretable results on real images. Code
is available at https://yilundu.github.io/crl/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Entropy Guided Node Embedding Dimension Selection for Graph Neural Networks. (arXiv:2105.03178v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03178">
<div class="article-summary-box-inner">
<span><p>Graph representation learning has achieved great success in many areas,
including e-commerce, chemistry, biology, etc. However, the fundamental problem
of choosing the appropriate dimension of node embedding for a given graph still
remains unsolved. The commonly used strategies for Node Embedding Dimension
Selection (NEDS) based on grid search or empirical knowledge suffer from heavy
computation and poor model performance. In this paper, we revisit NEDS from the
perspective of minimum entropy principle. Subsequently, we propose a novel
Minimum Graph Entropy (MinGE) algorithm for NEDS with graph data. To be
specific, MinGE considers both feature entropy and structure entropy on graphs,
which are carefully designed according to the characteristics of the rich
information in them. The feature entropy, which assumes the embeddings of
adjacent nodes to be more similar, connects node features and link topology on
graphs. The structure entropy takes the normalized degree as basic unit to
further measure the higher-order structure of graphs. Based on them, we design
MinGE to directly calculate the ideal node embedding dimension for any graph.
Finally, comprehensive experiments with popular Graph Neural Networks (GNNs) on
benchmark datasets demonstrate the effectiveness and generalizability of our
proposed MinGE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uniform Convergence, Adversarial Spheres and a Simple Remedy. (arXiv:2105.03491v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03491">
<div class="article-summary-box-inner">
<span><p>Previous work has cast doubt on the general framework of uniform convergence
and its ability to explain generalization in neural networks. By considering a
specific dataset, it was observed that a neural network completely
misclassifies a projection of the training data (adversarial set), rendering
any existing generalization bound based on uniform convergence vacuous. We
provide an extensive theoretical investigation of the previously studied data
setting through the lens of infinitely-wide models. We prove that the Neural
Tangent Kernel (NTK) also suffers from the same phenomenon and we uncover its
origin. We highlight the important role of the output bias and show
theoretically as well as empirically how a sensible choice completely mitigates
the problem. We identify sharp phase transitions in the accuracy on the
adversarial set and study its dependency on the training sample size. As a
result, we are able to characterize critical sample sizes beyond which the
effect disappears. Moreover, we study decompositions of a neural network into a
clean and noisy part by considering its canonical decomposition into its
different eigenfunctions and show empirically that for too small bias the
adversarial phenomenon still persists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Can Robots Trust Each Other For Better Cooperation? A Relative Needs Entropy Based Robot-Robot Trust Assessment Model. (arXiv:2105.07443v2 [cs.MA] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07443">
<div class="article-summary-box-inner">
<span><p>Cooperation in multi-agent and multi-robot systems can help agents build
various formations, shapes, and patterns presenting corresponding functions and
purposes adapting to different situations. Relationships between agents such as
their spatial proximity and functional similarities could play a crucial role
in cooperation between agents. Trust level between agents is an essential
factor in evaluating their relationships' reliability and stability, much as
people do. This paper proposes a new model called Relative Needs Entropy (RNE)
to assess trust between robotic agents. RNE measures the distance of needs
distribution between individual agents or groups of agents. To exemplify its
utility, we implement and demonstrate our trust model through experiments
simulating a heterogeneous multi-robot grouping task in a persistent urban
search and rescue mission consisting of tasks at two levels of difficulty. The
results suggest that RNE trust-Based grouping of robots can achieve better
performance and adaptability for diverse task execution compared to the
state-of-the-art energy-based or distance-based grouping models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Data Augmentation for Text Classification. (arXiv:2107.03158v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03158">
<div class="article-summary-box-inner">
<span><p>Data augmentation, the artificial creation of training data for machine
learning by transformations, is a widely studied research field across machine
learning disciplines. While it is useful for increasing the generalization
capabilities of a model, it can also address many other challenges and
problems, from overcoming a limited amount of training data over regularizing
the objective to limiting the amount data used to protect privacy. Based on a
precise description of the goals and applications of data augmentation (C1) and
a taxonomy for existing works (C2), this survey is concerned with data
augmentation methods for textual classification and aims to achieve a concise
and comprehensive overview for researchers and practitioners (C3). Derived from
the taxonomy, we divided more than 100 methods into 12 different groupings and
provide state-of-the-art references expounding which methods are highly
promising (C4). Finally, research perspectives that may constitute a building
block for future work are given (C5).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mutually improved endoscopic image synthesis and landmark detection in unpaired image-to-image translation. (arXiv:2107.06941v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06941">
<div class="article-summary-box-inner">
<span><p>The CycleGAN framework allows for unsupervised image-to-image translation of
unpaired data. In a scenario of surgical training on a physical surgical
simulator, this method can be used to transform endoscopic images of phantoms
into images which more closely resemble the intra-operative appearance of the
same surgical target structure. This can be viewed as a novel augmented reality
approach, which we coined Hyperrealism in previous work. In this use case, it
is of paramount importance to display objects like needles, sutures or
instruments consistent in both domains while altering the style to a more
tissue-like appearance. Segmentation of these objects would allow for a direct
transfer, however, contouring of these, partly tiny and thin foreground objects
is cumbersome and perhaps inaccurate. Instead, we propose to use landmark
detection on the points when sutures pass into the tissue. This objective is
directly incorporated into a CycleGAN framework by treating the performance of
pre-trained detector models as an additional optimization goal. We show that a
task defined on these sparse landmark labels improves consistency of synthesis
by the generator network in both domains. Comparing a baseline CycleGAN
architecture to our proposed extension (DetCycleGAN), mean precision (PPV)
improved by +61.32, mean sensitivity (TPR) by +37.91, and mean F1 score by
+0.4743. Furthermore, it could be shown that by dataset fusion, generated
intra-operative images can be leveraged as additional training data for the
detection network itself. The data is released within the scope of the AdaptOR
MICCAI Challenge 2021 at https://adaptor2021.github.io/, and code at
https://github.com/Cardio-AI/detcyclegan_pytorch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Argumentative Dialogue System for COVID-19 Vaccine Information. (arXiv:2107.12079v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12079">
<div class="article-summary-box-inner">
<span><p>Dialogue systems are widely used in AI to support timely and interactive
communication with users. We propose a general-purpose dialogue system
architecture that leverages computational argumentation to perform reasoning
and provide consistent and explainable answers. We illustrate the system using
a COVID-19 vaccine information case study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalizing Fairness: Discovery and Mitigation of Unknown Sensitive Attributes. (arXiv:2107.13625v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13625">
<div class="article-summary-box-inner">
<span><p>Ensuring trusted artificial intelligence (AI) in the real world is an
critical challenge. A still largely unexplored task is the determination of the
major factors within the real world that affect the behavior and robustness of
a given AI module (e.g. weather or illumination conditions). Specifically, here
we seek to discover the factors that cause AI systems to fail, and to mitigate
their influence. The identification of these factors usually heavily relies on
the availability of data that is diverse enough to cover numerous combinations
of these factors, but the exhaustive collection of this data is onerous and
sometimes impossible in complex environments. This paper investigates methods
that discover and mitigate the effects of semantic sensitive factors within a
given dataset. We also here generalize the definition of fairness, which
normally only addresses socially relevant factors, and widen it to deal with --
more broadly -- the desensitization of AI systems with regard to all possible
aspects of variation in the domain. The proposed methods which discover these
major factors reduce the potentially onerous demands of collecting a
sufficiently diverse dataset. In experiments using road sign (GTSRB) and facial
imagery (CelebA) datasets, we show the promise of these new methods and show
that they outperform state of the art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Log-based Anomaly Detection Without Log Parsing. (arXiv:2108.01955v3 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01955">
<div class="article-summary-box-inner">
<span><p>Software systems often record important runtime information in system logs
for troubleshooting purposes. There have been many studies that use log data to
construct machine learning models for detecting system anomalies. Through our
empirical study, we find that existing log-based anomaly detection approaches
are significantly affected by log parsing errors that are introduced by 1) OOV
(out-of-vocabulary) words, and 2) semantic misunderstandings. The log parsing
errors could cause the loss of important information for anomaly detection. To
address the limitations of existing methods, we propose NeuralLog, a novel
log-based anomaly detection approach that does not require log parsing.
NeuralLog extracts the semantic meaning of raw log messages and represents them
as semantic vectors. These representation vectors are then used to detect
anomalies through a Transformer-based classification model, which can capture
the contextual information from log sequences. Our experimental results show
that the proposed approach can effectively understand the semantic meaning of
log messages and achieve accurate anomaly detection results. Overall, NeuralLog
achieves F1-scores greater than 0.95 on four public datasets, outperforming the
existing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GENder-IT: An Annotated English-Italian Parallel Challenge Set for Cross-Linguistic Natural Gender Phenomena. (arXiv:2108.02854v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02854">
<div class="article-summary-box-inner">
<span><p>Languages differ in terms of the absence or presence of gender features, the
number of gender classes and whether and where gender features are explicitly
marked. These cross-linguistic differences can lead to ambiguities that are
difficult to resolve, especially for sentence-level MT systems. The
identification of ambiguity and its subsequent resolution is a challenging task
for which currently there aren't any specific resources or challenge sets
available. In this paper, we introduce gENder-IT, an English--Italian challenge
set focusing on the resolution of natural gender phenomena by providing
word-level gender tags on the English source side and multiple gender
alternative translations, where needed, on the Italian target side.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CushLEPOR: Customised hLEPOR Metric Using LABSE Distilled Knowledge Model to Improve Agreement with Human Judgements. (arXiv:2108.09484v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09484">
<div class="article-summary-box-inner">
<span><p>Human evaluation has always been expensive while researchers struggle to
trust the automatic metrics. To address this, we propose to customise
traditional metrics by taking advantages of the pre-trained language models
(PLMs) and the limited available human labelled scores. We first re-introduce
the hLEPOR metric factors, followed by the Python portable version we developed
which achieved the automatic tuning of the weighting parameters in hLEPOR
metric. Then we present the customised hLEPOR (cushLEPOR) which uses LABSE
distilled knowledge model to improve the metric agreement with human judgements
by automatically optimised factor weights regarding the exact MT language pairs
that cushLEPOR is deployed to. We also optimise cushLEPOR towards human
evaluation data based on MQM and pSQM framework on English-German and
Chinese-English language pairs. The experimental investigations show cushLEPOR
boosts hLEPOR performances towards better agreements to PLMs like LABSE with
much lower cost, and better agreements to human evaluations including MQM and
pSQM scores, and yields much better performances than BLEU (data available at
\url{https://github.com/poethan/cushLEPOR}).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bilateral Denoising Diffusion Models. (arXiv:2108.11514v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11514">
<div class="article-summary-box-inner">
<span><p>Denoising diffusion probabilistic models (DDPMs) have emerged as competitive
generative models yet brought challenges to efficient sampling. In this paper,
we propose novel bilateral denoising diffusion models (BDDMs), which take
significantly fewer steps to generate high-quality samples. From a bilateral
modeling objective, BDDMs parameterize the forward and reverse processes with a
score network and a scheduling network, respectively. We show that a new lower
bound tighter than the standard evidence lower bound can be derived as a
surrogate objective for training the two networks. In particular, BDDMs are
efficient, simple-to-train, and capable of further improving any pre-trained
DDPM by optimizing the inference noise schedules. Our experiments demonstrated
that BDDMs can generate high-fidelity samples with as few as 3 sampling steps
and produce comparable or even higher quality samples than DDPMs using 1000
steps with only 16 sampling steps (a 62x speedup).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why and How Governments Should Monitor AI Development. (arXiv:2108.12427v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12427">
<div class="article-summary-box-inner">
<span><p>In this paper we outline a proposal for improving the governance of
artificial intelligence (AI) by investing in government capacity to
systematically measure and monitor the capabilities and impacts of AI systems.
If adopted, this would give governments greater information about the AI
ecosystem, equipping them to more effectively direct AI development and
deployment in the most societally and economically beneficial directions. It
would also create infrastructure that could rapidly identify potential threats
or harms that could occur as a consequence of changes in the AI ecosystem, such
as the emergence of strategically transformative capabilities, or the
deployment of harmful systems.
</p>
<p>We begin by outlining the problem which motivates this proposal: in brief,
traditional governance approaches struggle to keep pace with the speed of
progress in AI. We then present our proposal for addressing this problem:
governments must invest in measurement and monitoring infrastructure. We
discuss this proposal in detail, outlining what specific things governments
could focus on measuring and monitoring, and the kinds of benefits this would
generate for policymaking. Finally, we outline some potential pilot projects
and some considerations for implementing this in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling the Knowledge of Large-scale Generative Models into Retrieval Models for Efficient Open-domain Conversation. (arXiv:2108.12582v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12582">
<div class="article-summary-box-inner">
<span><p>Despite the remarkable performance of large-scale generative models in
open-domain conversation, they are known to be less practical for building
real-time conversation systems due to high latency. On the other hand,
retrieval models could return responses with much lower latency but show
inferior performance to the large-scale generative models since the
conversation quality is bounded by the pre-defined response set. To take
advantage of both approaches, we propose a new training method called G2R
(Generative-to-Retrieval distillation) that preserves the efficiency of a
retrieval model while leveraging the conversational ability of a large-scale
generative model by infusing the knowledge of the generative model into the
retrieval model. G2R consists of two distinct techniques of distillation: the
data-level G2R augments the dialogue dataset with additional responses
generated by the large-scale generative model, and the model-level G2R
transfers the response quality score assessed by the generative model to the
score of the retrieval model by the knowledge distillation loss. Through
extensive experiments including human evaluation, we demonstrate that our
retrieval-based conversation system trained with G2R shows a substantially
improved performance compared to the baseline retrieval model while showing
significantly lower inference latency than the large-scale generative models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Communication-Computation Efficient Device-Edge Co-Inference via AutoML. (arXiv:2108.13009v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13009">
<div class="article-summary-box-inner">
<span><p>Device-edge co-inference, which partitions a deep neural network between a
resource-constrained mobile device and an edge server, recently emerges as a
promising paradigm to support intelligent mobile applications. To accelerate
the inference process, on-device model sparsification and intermediate feature
compression are regarded as two prominent techniques. However, as the on-device
model sparsity level and intermediate feature compression ratio have direct
impacts on computation workload and communication overhead respectively, and
both of them affect the inference accuracy, finding the optimal values of these
hyper-parameters brings a major challenge due to the large search space. In
this paper, we endeavor to develop an efficient algorithm to determine these
hyper-parameters. By selecting a suitable model split point and a pair of
encoder/decoder for the intermediate feature vector, this problem is casted as
a sequential decision problem, for which, a novel automated machine learning
(AutoML) framework is proposed based on deep reinforcement learning (DRL).
Experiment results on an image classification task demonstrate the
effectiveness of the proposed framework in achieving a better
communication-computation trade-off and significant inference speedup against
various baseline schemes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DNNFusion: Accelerating Deep Neural Networks Execution with Advanced Operator Fusion. (arXiv:2108.13342v1 [cs.LG] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13342">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks (DNNs) have emerged as the core enabler of many major
applications on mobile devices. To achieve high accuracy, DNN models have
become increasingly deep with hundreds or even thousands of operator layers,
leading to high memory and computational requirements for inference. Operator
fusion (or kernel/layer fusion) is key optimization in many state-of-the-art
DNN execution frameworks, such as TensorFlow, TVM, and MNN. However, these
frameworks usually adopt fusion approaches based on certain patterns that are
too restrictive to cover the diversity of operators and layer connections.
Polyhedral-based loop fusion techniques, on the other hand, work on a low-level
view of the computation without operator-level information, and can also miss
potential fusion opportunities. To address this challenge, this paper proposes
a novel and extensive loop fusion framework called DNNFusion. The basic idea of
this work is to work at an operator view of DNNs, but expand fusion
opportunities by developing a classification of both individual operators and
their combinations. In addition, DNNFusion includes 1) a novel
mathematical-property-based graph rewriting framework to reduce evaluation
costs and facilitate subsequent operator fusion, 2) an integrated fusion plan
generation that leverages the high-level analysis and accurate light-weight
profiling, and 3) additional optimizations during fusion code generation.
DNNFusion is extensively evaluated on 15 DNN models with varied types of tasks,
model sizes, and layer counts. The evaluation results demonstrate that
DNNFusion finds up to 8.8x higher fusion opportunities, outperforms four
state-of-the-art DNN execution frameworks with 9.3x speedup. The memory
requirement reduction and speedups can enable the execution of many of the
target models on mobile devices and even make them part of a real-time
application.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Want To Reduce Labeling Cost? GPT-3 Can Help. (arXiv:2108.13487v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13487">
<div class="article-summary-box-inner">
<span><p>Data annotation is a time-consuming and labor-intensive process for many NLP
tasks. Although there exist various methods to produce pseudo data labels, they
are often task-specific and require a decent amount of labeled data to start
with. Recently, the immense language model GPT-3 with 175 billion parameters
has achieved tremendous improvement across many few-shot learning tasks. In
this paper, we explore ways to leverage GPT-3 as a low-cost data labeler to
train other models. We find that, to make the downstream model achieve the same
performance on a variety of NLU and NLG tasks, it costs 50% to 96% less to use
labels from GPT-3 than using labels from humans. Furthermore, we propose a
novel framework of combining pseudo labels from GPT-3 with human labels, which
leads to even better performance with limited labeling budget. These results
present a cost-effective data labeling methodology that is generalizable to
many practical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-Supervised Exaggeration Detection of Health Science Press Releases. (arXiv:2108.13493v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13493">
<div class="article-summary-box-inner">
<span><p>Public trust in science depends on honest and factual communication of
scientific papers. However, recent studies have demonstrated a tendency of news
media to misrepresent scientific papers by exaggerating their findings. Given
this, we present a formalization of and study into the problem of exaggeration
detection in science communication. While there are an abundance of scientific
papers and popular media articles written about them, very rarely do the
articles include a direct link to the original paper, making data collection
challenging. We address this by curating a set of labeled press
release/abstract pairs from existing expert annotated studies on exaggeration
in press releases of scientific papers suitable for benchmarking the
performance of machine learning models on the task. Using limited data from
this and previous studies on exaggeration detection in science, we introduce
MT-PET, a multi-task version of Pattern Exploiting Training (PET), which
leverages knowledge from complementary cloze-style QA tasks to improve few-shot
learning. We demonstrate that MT-PET outperforms PET and supervised learning
both when data is limited, as well as when there is an abundance of data for
the main task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConVIScope: Visual Analytics for Exploring Patient Conversations. (arXiv:2108.13514v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13514">
<div class="article-summary-box-inner">
<span><p>The proliferation of text messaging for mobile health is generating a large
amount of patient-doctor conversations that can be extremely valuable to health
care professionals. We present ConVIScope, a visual text analytic system that
tightly integrates interactive visualization with natural language processing
in analyzing patient-doctor conversations. ConVIScope was developed in
collaboration with healthcare professionals following a user-centered iterative
design. Case studies with six domain experts suggest the potential utility of
ConVIScope and reveal lessons for further developments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Consistent Document-level Entity Linking: Joint Models for Entity Linking and Coreference Resolution. (arXiv:2108.13530v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13530">
<div class="article-summary-box-inner">
<span><p>We consider the task of document-level entity linking (EL), where it is
important to make consistent decisions for entity mentions over the full
document jointly. We aim to leverage explicit "connections" among mentions
within the document itself: we propose to join the EL task with that of
coreference resolution (coref). This is complementary to related works that
exploit either (i) implicit document information (e.g., latent relations among
entity mentions, or general language models) or (ii) connections between the
candidate links (e.g, as inferred from the external knowledge base).
Specifically, we cluster mentions that are linked via coreference, and enforce
a single EL for all of the clustered mentions together. The latter constraint
has the added benefit of increased coverage by joining EL candidate lists for
the thus clustered mentions. We formulate the coref+EL problem as a structured
prediction task over directed trees and use a globally normalized model to
solve it. Experimental results on two datasets show a boost of up to +5%
F1-score on both coref and EL tasks, compared to their standalone counterparts.
For a subset of hard cases, with individual mentions lacking the correct EL in
their candidate entity list, we obtain a +50% increase in accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linguistic Characterization of Divisive Topics Online: Case Studies on Contentiousness in Abortion, Climate Change, and Gun Control. (arXiv:2108.13556v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13556">
<div class="article-summary-box-inner">
<span><p>As public discourse continues to move and grow online, conversations about
divisive topics on social media platforms have also increased. These divisive
topics prompt both contentious and non-contentious conversations. Although what
distinguishes these conversations, often framed as what makes these
conversations contentious, is known in broad strokes, much less is known about
the linguistic signature of these conversations. Prior work has shown that
contentious content and structure can be a predictor for this task, however,
most of them have been focused on conversation in general, very specific
events, or complex structural analysis. Additionally, many models used in prior
work have lacked interpret-ability, a key factor in online moderation. Our work
fills these gaps by focusing on conversations from highly divisive topics
(abortion, climate change, and gun control), operationalizing a set of novel
linguistic and conversational characteristics and user factors, and
incorporating them to build interpretable models. We demonstrate that such
characteristics can largely improve the performance of prediction on this task,
and also enable nuanced interpretability. Our case studies on these three
contentious topics suggest that certain generic linguistic characteristics are
highly correlated with contentiousness in conversations while others
demonstrate significant contextual influences on specific divisive topics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">T3-Vis: a visual analytic framework for Training and fine-Tuning Transformers in NLP. (arXiv:2108.13587v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13587">
<div class="article-summary-box-inner">
<span><p>Transformers are the dominant architecture in NLP, but their training and
fine-tuning is still very challenging. In this paper, we present the design and
implementation of a visual analytic framework for assisting researchers in such
process, by providing them with valuable insights about the model's intrinsic
properties and behaviours. Our framework offers an intuitive overview that
allows the user to explore different facets of the model (e.g., hidden states,
attention) through interactive visualization, and allows a suite of built-in
algorithms that compute the importance of model components and different parts
of the input sequence. Case studies and feedback from a user focus group
indicate that the framework is useful, and suggest several improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Does Adversarial Fine-Tuning Benefit BERT?. (arXiv:2108.13602v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13602">
<div class="article-summary-box-inner">
<span><p>Adversarial training (AT) is one of the most reliable methods for defending
against adversarial attacks in machine learning. Variants of this method have
been used as regularization mechanisms to achieve SOTA results on NLP
benchmarks, and they have been found to be useful for transfer learning and
continual learning. We search for the reasons for the effectiveness of AT by
contrasting vanilla and adversarially fine-tuned BERT models. We identify
partial preservation of BERT's syntactic abilities during fine-tuning as the
key to the success of AT. We observe that adversarially fine-tuned models
remain more faithful to BERT's language modeling behavior and are more
sensitive to the word order. As concrete examples of syntactic abilities, an
adversarially fine-tuned model could have an advantage of up to 38% on anaphora
agreement and up to 11% on dependency parsing. Our analysis demonstrates that
vanilla fine-tuning oversimplifies the sentence representation by focusing
heavily on one or a few label-indicative words. AT, however, moderates the
effect of these influential words and encourages representational diversity.
This allows for a more hierarchical representation of a sentence and leads to
the mitigation of BERT's loss of syntactic abilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Lingual Text Classification of Transliterated Hindi and Malayalam. (arXiv:2108.13620v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13620">
<div class="article-summary-box-inner">
<span><p>Transliteration is very common on social media, but transliterated text is
not adequately handled by modern neural models for various NLP tasks. In this
work, we combine data augmentation approaches with a Teacher-Student training
scheme to address this issue in a cross-lingual transfer setting for
fine-tuning state-of-the-art pre-trained multilingual language models such as
mBERT and XLM-R. We evaluate our method on transliterated Hindi and Malayalam,
also introducing new datasets for benchmarking on real-world scenarios: one on
sentiment classification in transliterated Malayalam, and another on crisis
tweet classification in transliterated Hindi and Malayalam (related to the 2013
North India and 2018 Kerala floods). Our method yielded an average improvement
of +5.6% on mBERT and +4.7% on XLM-R in F1 scores over their strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Sliding Window for Meeting Summarization. (arXiv:2108.13629v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13629">
<div class="article-summary-box-inner">
<span><p>Recently abstractive spoken language summarization raises emerging research
interest, and neural sequence-to-sequence approaches have brought significant
performance improvement. However, summarizing long meeting transcripts remains
challenging. Due to the large length of source contents and targeted summaries,
neural models are prone to be distracted on the context, and produce summaries
with degraded quality. Moreover, pre-trained language models with input length
limitations cannot be readily applied to long sequences. In this work, we first
analyze the linguistic characteristics of meeting transcripts on a
representative corpus, and find that the sentences comprising the summary
correlate with the meeting agenda. Based on this observation, we propose a
dynamic sliding window strategy for meeting summarization. Experimental results
show that performance benefit from the proposed method, and outputs obtain
higher factual consistency than the base model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimulLR: Simultaneous Lip Reading Transducer with Attention-Guided Adaptive Memory. (arXiv:2108.13630v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13630">
<div class="article-summary-box-inner">
<span><p>Lip reading, aiming to recognize spoken sentences according to the given
video of lip movements without relying on the audio stream, has attracted great
interest due to its application in many scenarios. Although prior works that
explore lip reading have obtained salient achievements, they are all trained in
a non-simultaneous manner where the predictions are generated requiring access
to the full video. To breakthrough this constraint, we study the task of
simultaneous lip reading and devise SimulLR, a simultaneous lip Reading
transducer with attention-guided adaptive memory from three aspects: (1) To
address the challenge of monotonic alignments while considering the syntactic
structure of the generated sentences under simultaneous setting, we build a
transducer-based model and design several effective training strategies
including CTC pre-training, model warm-up and curriculum learning to promote
the training of the lip reading transducer. (2) To learn better spatio-temporal
representations for simultaneous encoder, we construct a truncated 3D
convolution and time-restricted self-attention layer to perform the
frame-to-frame interaction within a video segment containing fixed number of
frames. (3) The history information is always limited due to the storage in
real-time scenarios, especially for massive video data. Therefore, we devise a
novel attention-guided adaptive memory to organize semantic information of
history segments and enhance the visual representations with acceptable
computation-aware latency. The experiments show that the SimulLR achieves the
translation speedup 9.10$\times$ compared with the state-of-the-art
non-simultaneous methods, and also obtains competitive results, which indicates
the effectiveness of our proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining Classes through Word Attribution. (arXiv:2108.13653v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13653">
<div class="article-summary-box-inner">
<span><p>In recent years, several methods have been proposed for explaining individual
predictions of deep learning models, yet there has been little study of how to
aggregate these predictions to explain how such models view classes as a whole
in text classification tasks. In this work, we propose a method for explaining
classes using deep learning models and the Integrated Gradients feature
attribution technique by aggregating explanations of individual examples in
text classification to general descriptions of the classes. We demonstrate the
approach on Web register (genre) classification using the XML-R model and the
Corpus of Online Registers of English (CORE), finding that the method
identifies plausible and discriminative keywords characterizing all but the
smallest class.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discretized Integrated Gradients for Explaining Language Models. (arXiv:2108.13654v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13654">
<div class="article-summary-box-inner">
<span><p>As a prominent attribution-based explanation algorithm, Integrated Gradients
(IG) is widely adopted due to its desirable explanation axioms and the ease of
gradient computation. It measures feature importance by averaging the model's
output gradient interpolated along a straight-line path in the input data
space. However, such straight-line interpolated points are not representative
of text data due to the inherent discreteness of the word embedding space. This
questions the faithfulness of the gradients computed at the interpolated points
and consequently, the quality of the generated explanations. Here we propose
Discretized Integrated Gradients (DIG), which allows effective attribution
along non-linear interpolation paths. We develop two interpolation strategies
for the discrete word embedding space that generates interpolation points that
lie close to actual words in the embedding space, yielding more faithful
gradient computation. We demonstrate the effectiveness of DIG over IG through
experimental and human evaluations on multiple sentiment classification
datasets. We provide the source code of DIG to encourage reproducible research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MELM: Data Augmentation with Masked Entity Language Modeling for Cross-lingual NER. (arXiv:2108.13655v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13655">
<div class="article-summary-box-inner">
<span><p>Data augmentation for cross-lingual NER requires fine-grained control over
token labels of the augmented text. Existing augmentation approach based on
masked language modeling may replace a labeled entity with words of a different
class, which makes the augmented sentence incompatible with the original label
sequence, and thus hurts the performance.We propose a data augmentation
framework with Masked-Entity Language Modeling (MELM) which effectively ensures
the replacing entities fit the original labels. Specifically, MELM linearizes
NER labels into sentence context, and thus the fine-tuned MELM is able to
predict masked tokens by explicitly conditioning on their labels. Our MELM is
agnostic to the source of data to be augmented. Specifically, when MELM is
applied to augment training data of the source language, it achieves up to 3.5%
F1 score improvement for cross-lingual NER. When unlabeled target data is
available and MELM can be further applied to augment pseudo-labeled target
data, the performance gain reaches 5.7%. Moreover, MELM consistently
outperforms multiple baseline methods for data augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Rule Generation for Time Expression Normalization. (arXiv:2108.13658v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13658">
<div class="article-summary-box-inner">
<span><p>The understanding of time expressions includes two sub-tasks: recognition and
normalization. In recent years, significant progress has been made in the
recognition of time expressions while research on normalization has lagged
behind. Existing SOTA normalization methods highly rely on rules or grammars
designed by experts, which limits their performance on emerging corpora, such
as social media texts. In this paper, we model time expression normalization as
a sequence of operations to construct the normalized temporal value, and we
present a novel method called ARTime, which can automatically generate
normalization rules from training data without expert interventions.
Specifically, ARTime automatically captures possible operation sequences from
annotated data and generates normalization rules on time expressions with
common surface forms. The experimental results show that ARTime can
significantly surpass SOTA methods on the Tweets benchmark, and achieves
competitive results with existing expert-engineered rule methods on the
TempEval-3 benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gray Cycles of Maximum Length Related to k-Character Substitutions. (arXiv:2108.13659v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13659">
<div class="article-summary-box-inner">
<span><p>Given a word binary relation $\tau$ we define a $\tau$-Gray cycle over a
finite language $X$ to be a permutation $\left(w_{[i]}\right)_{0\le i\le
|X|-1}$ of $X$ such that each word $w_i$ is an image of the previous word
$w_{i-1}$ by $\tau$. In that framework, we introduce the complexity measure
$\lambda(n)$, equal to the largest cardinality of a language $X$ having words
of length at most $n$, and such that a $\tau$-Gray cycle over $X$ exists. The
present paper is concerned with the relation $\tau=\sigma_k$, the so-called
$k$-character substitution, where $(u,v)$ belongs to $\sigma_k$ if, and only
if, the Hamming distance of $u$ and $v$ is $k$. We compute the bound
$\lambda(n)$ for all cases of the alphabet cardinality and the argument $n$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-Oriented Dialogue System as Natural Language Generation. (arXiv:2108.13679v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13679">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose to formulate the task-oriented dialogue system as
the purely natural language generation task, so as to fully leverage the
large-scale pre-trained models like GPT-2 and simplify complicated
delexicalization prepossessing. However, directly applying this method heavily
suffers from the dialogue entity inconsistency caused by the removal of
delexicalized tokens, as well as the catastrophic forgetting problem of the
pre-trained model during fine-tuning, leading to unsatisfactory performance. To
alleviate these problems, we design a novel GPT-Adapter-CopyNet network, which
incorporates the lightweight adapter and CopyNet modules into GPT-2 to achieve
better performance on transfer learning and dialogue entity generation.
Experimental results conducted on the DSTC8 Track 1 benchmark and MultiWOZ
dataset demonstrate that our proposed approach significantly outperforms
baseline models with a remarkable performance on automatic and human
evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization. (arXiv:2108.13684v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13684">
<div class="article-summary-box-inner">
<span><p>Despite recent progress in abstractive summarization, systems still suffer
from faithfulness errors. While prior work has proposed models that improve
faithfulness, it is unclear whether the improvement comes from an increased
level of extractiveness of the model outputs as one naive way to improve
faithfulness is to make summarization models more extractive. In this work, we
present a framework for evaluating the effective faithfulness of summarization
systems, by generating a faithfulnessabstractiveness trade-off curve that
serves as a control at different operating points on the abstractiveness
spectrum. We then show that the Maximum Likelihood Estimation (MLE) baseline as
well as a recently proposed method for improving faithfulness, are both worse
than the control at the same level of abstractiveness. Finally, we learn a
selector to identify the most faithful and abstractive summary for a given
document, and show that this system can attain higher faithfulness scores in
human evaluations while being more abstractive than the baseline system on two
datasets. Moreover, we show that our system is able to achieve a better
faithfulness-abstractiveness trade-off than the control at the same level of
abstractiveness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Grounded Dialogue with Reward-Driven Knowledge Selection. (arXiv:2108.13686v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13686">
<div class="article-summary-box-inner">
<span><p>Knowledge-grounded dialogue is a task of generating a fluent and informative
response based on both conversation context and a collection of external
knowledge, in which knowledge selection plays an important role and attracts
more and more research interest. However, most existing models either select
only one knowledge or use all knowledge for responses generation. The former
may lose valuable information in discarded knowledge, while the latter may
bring a lot of noise. At the same time, many approaches need to train the
knowledge selector with knowledge labels that indicate ground-truth knowledge,
but these labels are difficult to obtain and require a large number of manual
annotations. Motivated by these issues, we propose Knoformer, a dialogue
response generation model based on reinforcement learning, which can
automatically select one or more related knowledge from the knowledge pool and
does not need knowledge labels during training. Knoformer is evaluated on two
knowledge-guided conversation datasets, and achieves state-of-the-art
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TNNT: The Named Entity Recognition Toolkit. (arXiv:2108.13700v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13700">
<div class="article-summary-box-inner">
<span><p>Extraction of categorised named entities from text is a complex task given
the availability of a variety of Named Entity Recognition (NER) models and the
unstructured information encoded in different source document formats.
Processing the documents to extract text, identifying suitable NER models for a
task, and obtaining statistical information is important in data analysis to
make informed decisions. This paper presents TNNT, a toolkit that automates the
extraction of categorised named entities from unstructured information encoded
in source documents, using diverse state-of-the-art Natural Language Processing
(NLP) tools and NER models. TNNT integrates 21 different NER models as part of
a Knowledge Graph Construction Pipeline (KGCP) that takes a document set as
input and processes it based on the defined settings, applying the selected
blocks of NER models to output the results. The toolkit generates all results
with an integrated summary of the extracted entities, enabling enhanced data
analysis to support the KGCP, and also, to aid further NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plan-then-Generate: Controlled Data-to-Text Generation via Planning. (arXiv:2108.13740v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13740">
<div class="article-summary-box-inner">
<span><p>Recent developments in neural networks have led to the advance in
data-to-text generation. However, the lack of ability of neural models to
control the structure of generated output can be limiting in certain real-world
applications. In this study, we propose a novel Plan-then-Generate (PlanGen)
framework to improve the controllability of neural data-to-text models.
Extensive experiments and analyses are conducted on two benchmark datasets,
ToTTo and WebNLG. The results show that our model is able to control both the
intra-sentence and inter-sentence structure of the generated output.
Furthermore, empirical comparisons against previous state-of-the-art methods
show that our model improves the generation quality as well as the output
diversity as judged by human and automatic evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Monolingual versus Multilingual BERTology for Vietnamese Extractive Multi-Document Summarization. (arXiv:2108.13741v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13741">
<div class="article-summary-box-inner">
<span><p>Recent researches have demonstrated that BERT shows potential in a wide range
of natural language processing tasks. It is adopted as an encoder for many
state-of-the-art automatic summarizing systems, which achieve excellent
performance. However, so far, there is not much work done for Vietnamese. In
this paper, we showcase how BERT can be implemented for extractive text
summarization in Vietnamese. We introduce a novel comparison between different
multilingual and monolingual BERT models. The experiment results indicate that
monolingual models produce promising results compared to other multilingual
models and previous text summarizing models for Vietnamese.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Search Engine for Discovery of Biomedical Challenges and Directions. (arXiv:2108.13751v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13751">
<div class="article-summary-box-inner">
<span><p>The ability to keep track of scientific challenges, advances and emerging
directions is a fundamental part of research. However, researchers face a flood
of papers that hinders discovery of important knowledge. In biomedicine, this
directly impacts human lives. To address this problem, we present a novel task
of extraction and search of scientific challenges and directions, to facilitate
rapid knowledge discovery. We construct and release an expert-annotated corpus
of texts sampled from full-length papers, labeled with novel semantic
categories that generalize across many types of challenges and directions. We
focus on a large corpus of interdisciplinary work relating to the COVID-19
pandemic, ranging from biomedicine to areas such as AI and economics. We apply
a model trained on our data to identify challenges and directions across the
corpus and build a dedicated search engine for this information. In studies
with researchers, including those working directly on COVID-19, we outperform a
popular scientific search engine in assisting knowledge discovery. Finally, we
show that models trained on our resource generalize to the wider biomedical
domain, highlighting its broad utility. We make our data, model and search
engine publicly available. https://challenges.apps.allenai.org
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enjoy the Salience: Towards Better Transformer-based Faithful Explanations with Word Salience. (arXiv:2108.13759v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13759">
<div class="article-summary-box-inner">
<span><p>Pretrained transformer-based models such as BERT have demonstrated
state-of-the-art predictive performance when adapted into a range of natural
language processing tasks. An open problem is how to improve the faithfulness
of explanations (rationales) for the predictions of these models. In this
paper, we hypothesize that salient information extracted a priori from the
training data can complement the task-specific information learned by the model
during fine-tuning on a downstream task. In this way, we aim to help BERT not
to forget assigning importance to informative input tokens when making
predictions by proposing SaLoss; an auxiliary loss function for guiding the
multi-head attention mechanism during training to be close to salient
information extracted a priori using TextRank. Experiments for explanation
faithfulness across five datasets, show that models trained with SaLoss
consistently provide more faithful explanations across four different feature
attribution methods compared to vanilla BERT. Using the rationales extracted
from vanilla BERT and SaLoss models to train inherently faithful classifiers,
we further show that the latter result in higher predictive performance in
downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The five Is: Key principles for interpretable and safe conversational AI. (arXiv:2108.13766v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13766">
<div class="article-summary-box-inner">
<span><p>In this position paper, we present five key principles, namely
interpretability, inherent capability to explain, independent data, interactive
learning, and inquisitiveness, for the development of conversational AI that,
unlike the currently popular black box approaches, is transparent and
accountable. At present, there is a growing concern with the use of black box
statistical language models: While displaying impressive average performance,
such systems are also prone to occasional spectacular failures, for which there
is no clear remedy. In an effort to initiate a discussion on possible
alternatives, we outline and exemplify how our five principles enable the
development of conversational AI systems that are transparent and thus safer
for use. We also present some of the challenges inherent in the implementation
of those principles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Network psychometrics and cognitive network science open new ways for detecting, understanding and tackling the complexity of math anxiety: A review. (arXiv:2108.13800v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13800">
<div class="article-summary-box-inner">
<span><p>Math anxiety is a clinical pathology impairing cognitive processing in
math-related contexts. Originally thought to affect only inexperienced,
low-achieving students, recent investigations show how math anxiety is vastly
diffused even among high-performing learners. This review of data-informed
studies outlines math anxiety as a complex system that: (i) cripples
well-being, self-confidence and information processing on both conscious and
subconscious levels, (ii) can be transmitted by social interactions, like a
pathogen, and worsened by distorted perceptions, (iii) affects roughly 20% of
students in 63 out of 64 worldwide educational systems but correlates weakly
with academic performance, and (iv) poses a concrete threat to students'
well-being, computational literacy and career prospects in science. These
patterns underline the crucial need to go beyond performance for estimating
math anxiety. Recent advances with network psychometrics and cognitive network
science provide ideal frameworks for detecting, interpreting and intervening
upon such clinical condition. Merging education research, psychology and data
science, the approaches reviewed here reconstruct psychological constructs as
complex systems, represented either as multivariate correlation models (e.g.
graph exploratory analysis) or as cognitive networks of semantic/emotional
associations (e.g. free association networks or forma mentis networks). Not
only can these interconnected networks detect otherwise hidden levels of math
anxiety but - more crucially - they can unveil the specific layout of
interacting factors, e.g. key sources and targets, behind math anxiety in a
given cohort. As discussed here, these network approaches open concrete ways
for unveiling students' perceptions, emotions and mental well-being, and can
enable future powerful data-informed interventions untangling math anxiety.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TREND: Trigger-Enhanced Relation-Extraction Network for Dialogues. (arXiv:2108.13811v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13811">
<div class="article-summary-box-inner">
<span><p>The goal of dialogue relation extraction (DRE) is to identify the relation
between two entities in a given dialogue. During conversations, speakers may
expose their relations to certain entities by some clues, such evidences called
"triggers". However, none of the existing work on DRE tried to detect triggers
and leverage the information for enhancing the performance. This paper proposes
TREND, a multi-tasking BERT-based model which learns to identify triggers for
improving relation extraction. The experimental results show that the proposed
method achieves the state-of-the-art on the benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Open-Domain Question Answering. (arXiv:2108.13817v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13817">
<div class="article-summary-box-inner">
<span><p>Open-domain Question Answering (ODQA) has achieved significant results in
terms of supervised learning manner. However, data annotation cannot also be
irresistible for its huge demand in an open domain. Though unsupervised QA or
unsupervised Machine Reading Comprehension (MRC) has been tried more or less,
unsupervised ODQA has not been touched according to our best knowledge. This
paper thus pioneers the work of unsupervised ODQA by formally introducing the
task and proposing a series of key data construction methods. Our exploration
in this work inspiringly shows unsupervised ODQA can reach up to 86%
performance of supervised ones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Domain Adaptation for Question Answering using Limited Text Corpora. (arXiv:2108.13854v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13854">
<div class="article-summary-box-inner">
<span><p>Question generation has recently shown impressive results in customizing
question answering (QA) systems to new domains. These approaches circumvent the
need for manually annotated training data from the new domain and, instead,
generate synthetic question-answer pairs that are used for training. However,
existing methods for question generation rely on large amounts of synthetically
generated datasets and costly computational resources, which render these
techniques widely inaccessible when the text corpora is of limited size. This
is problematic as many niche domains rely on small text corpora, which
naturally restricts the amount of synthetic data that can be generated. In this
paper, we propose a novel framework for domain adaptation called contrastive
domain adaptation for QA (CAQA). Specifically, CAQA combines techniques from
question generation and domain-invariant learning to answer out-of-domain
questions in settings with limited text corpora. Here, we train a QA system on
both source data and generated data from the target domain with a contrastive
adaptation loss that is incorporated in the training objective. By combining
techniques from question generation and domain-invariant learning, our model
achieved considerable improvements compared to state-of-the-art baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Model Extraction: Imitation Attack for Black-Box NLP APIs. (arXiv:2108.13873v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13873">
<div class="article-summary-box-inner">
<span><p>Machine-learning-as-a-service (MLaaS) has attracted millions of users to
their outperforming sophisticated models. Although published as black-box APIs,
the valuable models behind these services are still vulnerable to imitation
attacks. Recently, a series of works have demonstrated that attackers manage to
steal or extract the victim models. Nonetheless, none of the previous stolen
models can outperform the original black-box APIs. In this work, we take the
first step of showing that attackers could potentially surpass victims via
unsupervised domain adaptation and multi-victim ensemble. Extensive experiments
on benchmark datasets and real-world APIs validate that the imitators can
succeed in outperforming the original black-box models. We consider this as a
milestone in the research of imitation attack, especially on NLP APIs, as the
superior performance could influence the defense or even publishing strategy of
API providers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Retriever-Reader Meets Scenario-Based Multiple-Choice Questions. (arXiv:2108.13875v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13875">
<div class="article-summary-box-inner">
<span><p>Scenario-based question answering (SQA) requires retrieving and reading
paragraphs from a large corpus to answer a question which is contextualized by
a long scenario description. Since a scenario contains both keyphrases for
retrieval and much noise, retrieval for SQA is extremely difficult. Moreover,
it can hardly be supervised due to the lack of relevance labels of paragraphs
for SQA. To meet the challenge, in this paper we propose a joint
retriever-reader model called JEEVES where the retriever is implicitly
supervised only using QA labels via a novel word weighting mechanism. JEEVES
significantly outperforms a variety of strong baselines on multiple-choice
questions in three SQA datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning. (arXiv:2108.13888v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13888">
<div class="article-summary-box-inner">
<span><p>\textbf{P}re-\textbf{T}rained \textbf{M}odel\textbf{s} have been widely
applied and recently proved vulnerable under backdoor attacks: the released
pre-trained weights can be maliciously poisoned with certain triggers. When the
triggers are activated, even the fine-tuned model will predict pre-defined
labels, causing a security threat. These backdoors generated by the poisoning
methods can be erased by changing hyper-parameters during fine-tuning or
detected by finding the triggers. In this paper, we propose a stronger
weight-poisoning attack method that introduces a layerwise weight poisoning
strategy to plant deeper backdoors; we also introduce a combinatorial trigger
that cannot be easily detected. The experiments on text classification tasks
show that previous defense methods cannot resist our weight-poisoning method,
which indicates that our method can be widely applied and may provide hints for
future model robustness studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Like Article, Like Audience: Enforcing Multimodal Correlations for Disinformation Detection. (arXiv:2108.13892v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13892">
<div class="article-summary-box-inner">
<span><p>User-generated content (e.g., tweets and profile descriptions) and shared
content between users (e.g., news articles) reflect a user's online identity.
This paper investigates whether correlations between user-generated and
user-shared content can be leveraged for detecting disinformation in online
news articles. We develop a multimodal learning algorithm for disinformation
detection. The latent representations of news articles and user-generated
content allow that during training the model is guided by the profile of users
who prefer content similar to the news article that is evaluated, and this
effect is reinforced if that content is shared among different users. By only
leveraging user information during model optimization, the model does not rely
on user profiling when predicting an article's veracity. The algorithm is
successfully applied to three widely used neural classifiers, and results are
obtained on different datasets. Visualization techniques show that the proposed
model learns feature representations of unseen news articles that better
discriminate between fake and real news texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mMARCO: A Multilingual Version of MS MARCO Passage Ranking Dataset. (arXiv:2108.13897v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13897">
<div class="article-summary-box-inner">
<span><p>The MS MARCO ranking dataset has been widely used for training deep learning
models for IR tasks, achieving considerable effectiveness on diverse zero-shot
scenarios. However, this type of resource is scarce in other languages than
English. In this work we present mMARCO, a multilingual version of the MS MARCO
passage ranking dataset comprising 8 languages that was created using machine
translation. We evaluated mMARCO by fine-tuning mono and multilingual
re-ranking models on it. Experimental results demonstrate that multilingual
models fine-tuned on our translated dataset achieve superior effectiveness than
models fine-tuned on the original English version alone. Also, our distilled
multilingual re-ranker is competitive with non-distilled models while having
5.4 times fewer parameters. The translated datasets as well as fine-tuned
models are available at https://github.com/unicamp-dl/mMARCO.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The emojification of sentiment on social media: Collection and analysis of a longitudinal Twitter sentiment dataset. (arXiv:2108.13898v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13898">
<div class="article-summary-box-inner">
<span><p>Social media, as a means for computer-mediated communication, has been
extensively used to study the sentiment expressed by users around events or
topics. There is however a gap in the longitudinal study of how sentiment
evolved in social media over the years. To fill this gap, we develop TM-Senti,
a new large-scale, distantly supervised Twitter sentiment dataset with over 184
million tweets and covering a time period of over seven years. We describe and
assess our methodology to put together a large-scale, emoticon- and emoji-based
labelled sentiment analysis dataset, along with an analysis of the resulting
dataset. Our analysis highlights interesting temporal changes, among others in
the increasing use of emojis over emoticons. We publicly release the dataset
for further research in tasks including sentiment analysis and text
classification of tweets. The dataset can be fully rehydrated including tweet
metadata and without missing tweets thanks to the archive of tweets publicly
available on the Internet Archive, which the dataset is based on.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Retrieval Augmented Generation for Zero-shot Slot Filling. (arXiv:2108.13934v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13934">
<div class="article-summary-box-inner">
<span><p>Automatically inducing high quality knowledge graphs from a given collection
of documents still remains a challenging problem in AI. One way to make headway
for this problem is through advancements in a related task known as slot
filling. In this task, given an entity query in form of [Entity, Slot, ?], a
system is asked to fill the slot by generating or extracting the missing value
exploiting evidence extracted from relevant passage(s) in the given document
collection. The recent works in the field try to solve this task in an
end-to-end fashion using retrieval-based language models. In this paper, we
present a novel approach to zero-shot slot filling that extends dense passage
retrieval with hard negatives and robust training procedures for retrieval
augmented generation models. Our model reports large improvements on both T-REx
and zsRE slot filling datasets, improving both passage retrieval and slot value
generation, and ranking at the top-1 position in the KILT leaderboard.
Moreover, we demonstrate the robustness of our system showing its domain
adaptation capability on a new variant of the TACRED dataset for slot filling,
through a combination of zero/few-shot learning. We release the source code and
pre-trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thermostat: A Large Collection of NLP Model Explanations and Analysis Tools. (arXiv:2108.13961v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13961">
<div class="article-summary-box-inner">
<span><p>In the language domain, as in other domains, neural explainability takes an
ever more important role, with feature attribution methods on the forefront.
Many such methods require considerable computational resources and expert
knowledge about implementation details and parameter choices. To facilitate
research, we present Thermostat which consists of a large collection of model
explanations and accompanying analysis tools. Thermostat allows easy access to
over 200k explanations for the decisions of prominent state-of-the-art models
spanning across different NLP tasks, generated with multiple explainers. The
dataset took over 10k GPU hours (&gt; one year) to compile; compute time that the
community now saves. The accompanying software tools allow to analyse
explanations instance-wise but also accumulatively on corpus level. Users can
investigate and compare models, datasets and explainers without the need to
orchestrate implementation details. Thermostat is fully open source,
democratizes explainability research in the language domain, circumvents
redundant computations and increases comparability and replicability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effective Sequence-to-Sequence Dialogue State Tracking. (arXiv:2108.13990v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13990">
<div class="article-summary-box-inner">
<span><p>Sequence-to-sequence models have been applied to a wide variety of NLP tasks,
but how to properly use them for dialogue state tracking has not been
systematically investigated. In this paper, we study this problem from the
perspectives of pre-training objectives as well as the formats of context
representations. We demonstrate that the choice of pre-training objective makes
a significant difference to the state tracking quality. In particular, we find
that masked span prediction is more effective than auto-regressive language
modeling. We also explore using Pegasus, a span prediction-based pre-training
objective for text summarization, for the state tracking model. We found that
pre-training for the seemingly distant summarization task works surprisingly
well for dialogue state tracking. In addition, we found that while recurrent
state context representation works also reasonably well, the model may have a
hard time recovering from earlier mistakes. We conducted experiments on the
MultiWOZ 2.1-2.4 data sets with consistent observations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Generative Approach for Mitigating Structural Biases in Natural Language Inference. (arXiv:2108.14006v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.14006">
<div class="article-summary-box-inner">
<span><p>Many natural language inference (NLI) datasets contain biases that allow
models to perform well by only using a biased subset of the input, without
considering the remainder features. For instance, models are able to make a
classification decision by only using the hypothesis, without learning the true
relationship between it and the premise. These structural biases lead
discriminative models to learn unintended superficial features and to
generalize poorly out of the training distribution. In this work, we
reformulate the NLI task as a generative task, where a model is conditioned on
the biased subset of the input and the label and generates the remaining subset
of the input. We show that by imposing a uniform prior, we obtain a provably
unbiased model. Through synthetic experiments, we find that this approach is
highly robust to large amounts of bias. We then demonstrate empirically on two
types of natural bias that this approach leads to fully unbiased models in
practice. However, we find that generative models are difficult to train and
they generally perform worse than discriminative baselines. We highlight the
difficulty of the generative modeling task in the context of NLI as a cause for
this worse performance. Finally, by fine-tuning the generative model with a
discriminative objective, we reduce the performance gap between the generative
model and the discriminative baseline, while allowing for a small amount of
bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HUMBO: Bridging Response Generation and Facial Expression Synthesis. (arXiv:1905.11240v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.11240">
<div class="article-summary-box-inner">
<span><p>Spoken dialogue systems that assist users to solve complex tasks such as
movie ticket booking have become an emerging research topic in artificial
intelligence and natural language processing areas. With a well-designed
dialogue system as an intelligent personal assistant, people can accomplish
certain tasks more easily via natural language interactions. Today there are
several virtual intelligent assistants in the market; however, most systems
only focus on textual or vocal interaction. In this paper, we present HUMBO, a
system aiming at generating dialogue responses and simultaneously synthesize
corresponding visual expressions on faces for better multimodal interaction.
HUMBO can (1) let users determine the appearances of virtual assistants by a
single image, and (2) generate coherent emotional utterances and facial
expressions on the user-provided image. This is not only a brand new research
direction but more importantly, an ultimate step toward more human-like virtual
assistants.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning Visual Dialog with Sparse Graph Learning and Knowledge Transfer. (arXiv:2004.06698v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.06698">
<div class="article-summary-box-inner">
<span><p>Visual dialog is a task of answering a sequence of questions grounded in an
image using the previous dialog history as context. In this paper, we study how
to address two fundamental challenges for this task: (1) reasoning over
underlying semantic structures among dialog rounds and (2) identifying several
appropriate answers to the given question. To address these challenges, we
propose a Sparse Graph Learning (SGL) method to formulate visual dialog as a
graph structure learning task. SGL infers inherently sparse dialog structures
by incorporating binary and score edges and leveraging a new structural loss
function. Next, we introduce a Knowledge Transfer (KT) method that extracts the
answer predictions from the teacher model and uses them as pseudo labels. We
propose KT to remedy the shortcomings of single ground-truth labels, which
severely limit the ability of a model to obtain multiple reasonable answers. As
a result, our proposed model significantly improves reasoning capability
compared to baseline methods and outperforms the state-of-the-art approaches on
the VisDial v1.0 dataset. The source code is available at
https://github.com/gicheonkang/SGLKT-VisDial.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural CRF Model for Sentence Alignment in Text Simplification. (arXiv:2005.02324v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.02324">
<div class="article-summary-box-inner">
<span><p>The success of a text simplification system heavily depends on the quality
and quantity of complex-simple sentence pairs in the training corpus, which are
extracted by aligning sentences between parallel articles. To evaluate and
improve sentence alignment quality, we create two manually annotated
sentence-aligned datasets from two commonly used text simplification corpora,
Newsela and Wikipedia. We propose a novel neural CRF alignment model which not
only leverages the sequential nature of sentences in parallel documents but
also utilizes a neural sentence pair model to capture semantic similarity.
Experiments demonstrate that our proposed approach outperforms all the previous
work on monolingual sentence alignment task by more than 5 points in F1. We
apply our CRF aligner to construct two new text simplification datasets,
Newsela-Auto and Wiki-Auto, which are much larger and of better quality
compared to the existing datasets. A Transformer-based seq2seq model trained on
our datasets establishes a new state-of-the-art for text simplification in both
automatic and human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dialogue Response Selection with Hierarchical Curriculum Learning. (arXiv:2012.14756v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14756">
<div class="article-summary-box-inner">
<span><p>We study the learning of a matching model for dialogue response selection.
Motivated by the recent finding that models trained with random negative
samples are not ideal in real-world scenarios, we propose a hierarchical
curriculum learning framework that trains the matching model in an
"easy-to-difficult" scheme. Our learning framework consists of two
complementary curricula: (1) corpus-level curriculum (CC); and (2)
instance-level curriculum (IC). In CC, the model gradually increases its
ability in finding the matching clues between the dialogue context and a
response candidate. As for IC, it progressively strengthens the model's ability
in identifying the mismatching information between the dialogue context and a
response candidate. Empirical studies on three benchmark datasets with three
state-of-the-art matching models demonstrate that the proposed learning
framework significantly improves the model performance across various
evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive Transformer-Based Generation of Radiology Reports. (arXiv:2102.09777v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09777">
<div class="article-summary-box-inner">
<span><p>Inspired by Curriculum Learning, we propose a consecutive (i.e.,
image-to-text-to-text) generation framework where we divide the problem of
radiology report generation into two steps. Contrary to generating the full
radiology report from the image at once, the model generates global concepts
from the image in the first step and then reforms them into finer and coherent
texts using a transformer architecture. We follow the transformer-based
sequence-to-sequence paradigm at each step. We improve upon the
state-of-the-art on two benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning. (arXiv:2104.06979v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06979">
<div class="article-summary-box-inner">
<span><p>Learning sentence embeddings often requires a large amount of labeled data.
However, for most tasks and domains, labeled data is seldom available and
creating it is expensive. In this work, we present a new state-of-the-art
unsupervised method based on pre-trained Transformers and Sequential Denoising
Auto-Encoder (TSDAE) which outperforms previous approaches by up to 6.4 points.
It can achieve up to 93.1% of the performance of in-domain supervised
approaches. Further, we show that TSDAE is a strong domain adaptation and
pre-training method for sentence embeddings, significantly outperforming other
approaches like Masked Language Model.
</p>
<p>A crucial shortcoming of previous studies is the narrow evaluation: Most work
mainly evaluates on the single task of Semantic Textual Similarity (STS), which
does not require any domain knowledge. It is unclear if these proposed methods
generalize to other domains and tasks. We fill this gap and evaluate TSDAE and
other recent approaches on four different datasets from heterogeneous domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Surface Form Competition: Why the Highest Probability Answer Isn't Always Right. (arXiv:2104.08315v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08315">
<div class="article-summary-box-inner">
<span><p>Large language models have shown promising results in zero-shot settings
(Brown et al.,2020; Radford et al., 2019). For example, they can perform
multiple choice tasks simply by conditioning on a question and selecting the
answer with the highest probability.
</p>
<p>However, ranking by string probability can be problematic due to surface form
competition-wherein different surface forms compete for probability mass, even
if they represent the same underlying concept, e.g. "computer" and "PC." Since
probability mass is finite, this lowers the probability of the correct answer,
due to competition from other strings that are valid answers (but not one of
the multiple choice options).
</p>
<p>We introduce Domain Conditional Pointwise Mutual Information, an alternative
scoring function that directly compensates for surface form competition by
simply reweighing each option according to a term that is proportional to its a
priori likelihood within the context of the specific zero-shot task. It
achieves consistent gains in zero-shot performance over both calibrated (Zhao
et al., 2021) and uncalibrated scoring functions on all GPT-2 and GPT-3 models
over a variety of multiple choice datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimCSE: Simple Contrastive Learning of Sentence Embeddings. (arXiv:2104.08821v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08821">
<div class="article-summary-box-inner">
<span><p>This paper presents SimCSE, a simple contrastive learning framework that
greatly advances the state-of-the-art sentence embeddings. We first describe an
unsupervised approach, which takes an input sentence and predicts itself in a
contrastive objective, with only standard dropout used as noise. This simple
method works surprisingly well, performing on par with previous supervised
counterparts. We hypothesize that dropout acts as minimal data augmentation and
removing it leads to a representation collapse. Then, we incorporate annotated
pairs from natural language inference datasets into our contrastive learning
framework, by using "entailment" pairs as positives and "contradiction" pairs
as hard negatives. We evaluate SimCSE on standard semantic textual similarity
(STS) tasks, and our unsupervised and supervised models using BERT-base achieve
an average of 76.3% and 81.6% Spearman's correlation respectively, a 4.2 and
2.2 points improvement compared to previous best results. We also show -- both
theoretically and empirically -- that contrastive learning objective
regularizes pre-trained embeddings' anisotropic space to be more uniform, and
it better aligns positive pairs when supervised signals are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniKeyphrase: A Unified Extraction and Generation Framework for Keyphrase Prediction. (arXiv:2106.04847v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04847">
<div class="article-summary-box-inner">
<span><p>Keyphrase Prediction (KP) task aims at predicting several keyphrases that can
summarize the main idea of the given document. Mainstream KP methods can be
categorized into purely generative approaches and integrated models with
extraction and generation. However, these methods either ignore the diversity
among keyphrases or only weakly capture the relation across tasks implicitly.
In this paper, we propose UniKeyphrase, a novel end-to-end learning framework
that jointly learns to extract and generate keyphrases. In UniKeyphrase,
stacked relation layer and bag-of-words constraint are proposed to fully
exploit the latent semantic relation between extraction and generation in the
view of model structure and training process, respectively. Experiments on KP
benchmarks demonstrate that our joint approach outperforms mainstream methods
by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Data Augmentation for Text Classification. (arXiv:2107.03158v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03158">
<div class="article-summary-box-inner">
<span><p>Data augmentation, the artificial creation of training data for machine
learning by transformations, is a widely studied research field across machine
learning disciplines. While it is useful for increasing the generalization
capabilities of a model, it can also address many other challenges and
problems, from overcoming a limited amount of training data over regularizing
the objective to limiting the amount data used to protect privacy. Based on a
precise description of the goals and applications of data augmentation (C1) and
a taxonomy for existing works (C2), this survey is concerned with data
augmentation methods for textual classification and aims to achieve a concise
and comprehensive overview for researchers and practitioners (C3). Derived from
the taxonomy, we divided more than 100 methods into 12 different groupings and
provide state-of-the-art references expounding which methods are highly
promising (C4). Finally, research perspectives that may constitute a building
block for future work are given (C5).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Argumentative Dialogue System for COVID-19 Vaccine Information. (arXiv:2107.12079v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12079">
<div class="article-summary-box-inner">
<span><p>Dialogue systems are widely used in AI to support timely and interactive
communication with users. We propose a general-purpose dialogue system
architecture that leverages computational argumentation to perform reasoning
and provide consistent and explainable answers. We illustrate the system using
a COVID-19 vaccine information case study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Goal-Oriented Script Construction. (arXiv:2107.13189v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13189">
<div class="article-summary-box-inner">
<span><p>The knowledge of scripts, common chains of events in stereotypical scenarios,
is a valuable asset for task-oriented natural language understanding systems.
We propose the Goal-Oriented Script Construction task, where a model produces a
sequence of steps to accomplish a given goal. We pilot our task on the first
multilingual script learning dataset supporting 18 languages collected from
wikiHow, a website containing half a million how-to articles. For baselines, we
consider both a generation-based approach using a language model and a
retrieval-based approach by first retrieving the relevant steps from a large
candidate pool and then ordering them. We show that our task is practical,
feasible but challenging for state-of-the-art Transformer models, and that our
methods can be readily deployed for various other datasets and domains with
decent zero-shot performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GENder-IT: An Annotated English-Italian Parallel Challenge Set for Cross-Linguistic Natural Gender Phenomena. (arXiv:2108.02854v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02854">
<div class="article-summary-box-inner">
<span><p>Languages differ in terms of the absence or presence of gender features, the
number of gender classes and whether and where gender features are explicitly
marked. These cross-linguistic differences can lead to ambiguities that are
difficult to resolve, especially for sentence-level MT systems. The
identification of ambiguity and its subsequent resolution is a challenging task
for which currently there aren't any specific resources or challenge sets
available. In this paper, we introduce gENder-IT, an English--Italian challenge
set focusing on the resolution of natural gender phenomena by providing
word-level gender tags on the English source side and multiple gender
alternative translations, where needed, on the Italian target side.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-based Hate. (arXiv:2108.05921v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05921">
<div class="article-summary-box-inner">
<span><p>Detecting online hate is a complex task, and low-performing models have
harmful consequences when used for sensitive applications such as content
moderation. Emoji-based hate is a key emerging challenge for automated
detection. We present HatemojiCheck, a test suite of 3,930 short-form
statements that allows us to evaluate performance on hateful language expressed
with emoji. Using the test suite, we expose weaknesses in existing hate
detection models. To address these weaknesses, we create the HatemojiTrain
dataset using a human-and-model-in-the-loop approach. Models trained on these
5,912 adversarial examples perform substantially better at detecting
emoji-based hate, while retaining strong performance on text-only hate. Both
HatemojiCheck and HatemojiTrain are made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CushLEPOR: Customised hLEPOR Metric Using LABSE Distilled Knowledge Model to Improve Agreement with Human Judgements. (arXiv:2108.09484v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09484">
<div class="article-summary-box-inner">
<span><p>Human evaluation has always been expensive while researchers struggle to
trust the automatic metrics. To address this, we propose to customise
traditional metrics by taking advantages of the pre-trained language models
(PLMs) and the limited available human labelled scores. We first re-introduce
the hLEPOR metric factors, followed by the Python portable version we developed
which achieved the automatic tuning of the weighting parameters in hLEPOR
metric. Then we present the customised hLEPOR (cushLEPOR) which uses LABSE
distilled knowledge model to improve the metric agreement with human judgements
by automatically optimised factor weights regarding the exact MT language pairs
that cushLEPOR is deployed to. We also optimise cushLEPOR towards human
evaluation data based on MQM and pSQM framework on English-German and
Chinese-English language pairs. The experimental investigations show cushLEPOR
boosts hLEPOR performances towards better agreements to PLMs like LABSE with
much lower cost, and better agreements to human evaluations including MQM and
pSQM scores, and yields much better performances than BLEU (data available at
\url{https://github.com/poethan/cushLEPOR}).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sarcasm Detection in Twitter -- Performance Impact while using Data Augmentation: Word Embeddings. (arXiv:2108.09924v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09924">
<div class="article-summary-box-inner">
<span><p>Sarcasm is the use of words usually used to either mock or annoy someone, or
for humorous purposes. Sarcasm is largely used in social networks and
microblogging websites, where people mock or censure in a way that makes it
difficult even for humans to tell if what is said is what is meant. Failure to
identify sarcastic utterances in Natural Language Processing applications such
as sentiment analysis and opinion mining will confuse classification algorithms
and generate false results. Several studies on sarcasm detection have utilized
different learning algorithms. However, most of these learning models have
always focused on the contents of expression only, leaving the contextual
information in isolation. As a result, they failed to capture the contextual
information in the sarcastic expression. Moreover, some datasets used in
several studies have an unbalanced dataset which impacting the model result. In
this paper, we propose a contextual model for sarcasm identification in twitter
using RoBERTa, and augmenting the dataset by applying Global Vector
representation (GloVe) for the construction of word embedding and context
learning to generate more data and balancing the dataset. The effectiveness of
this technique is tested with various datasets and data augmentation settings.
In particular, we achieve performance gain by 3.2% in the iSarcasm dataset when
using data augmentation to increase 20% of data labeled as sarcastic, resulting
F-score of 40.4% compared to 37.2% without data augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Query-Focused Extractive Summarisation for Finding Ideal Answers to Biomedical and COVID-19 Questions. (arXiv:2108.12189v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12189">
<div class="article-summary-box-inner">
<span><p>This paper presents Macquarie University's participation to the BioASQ
Synergy Task, and BioASQ9b Phase B. In each of these tasks, our participation
focused on the use of query-focused extractive summarisation to obtain the
ideal answers to medical questions. The Synergy Task is an end-to-end question
answering task on COVID-19 where systems are required to return relevant
documents, snippets, and answers to a given question. Given the absence of
training data, we used a query-focused summarisation system that was trained
with the BioASQ8b training data set and we experimented with methods to
retrieve the documents and snippets. Considering the poor quality of the
documents and snippets retrieved by our system, we observed reasonably good
quality in the answers returned. For phase B of the BioASQ9b task, the relevant
documents and snippets were already included in the test data. Our system split
the snippets into candidate sentences and used BERT variants under a sentence
classification setup. The system used the question and candidate sentence as
input and was trained to predict the likelihood of the candidate sentence being
part of the ideal answer. The runs obtained either the best or second best
ROUGE-F1 results of all participants to all batches of BioASQ9b. This shows
that using BERT in a classification setup is a very strong baseline for the
identification of ideal answers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Table-to-Text Generation with Prototype Memory. (arXiv:2108.12516v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12516">
<div class="article-summary-box-inner">
<span><p>Neural table-to-text generation models have achieved remarkable progress on
an array of tasks. However, due to the data-hungry nature of neural models,
their performances strongly rely on large-scale training examples, limiting
their applicability in real-world applications. To address this, we propose a
new framework: Prototype-to-Generate (P2G), for table-to-text generation under
the few-shot scenario. The proposed framework utilizes the retrieved
prototypes, which are jointly selected by an IR system and a novel prototype
selector to help the model bridging the structural gap between tables and
texts. Experimental results on three benchmark datasets with three
state-of-the-art models demonstrate that the proposed framework significantly
improves the model performance across various evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling the Knowledge of Large-scale Generative Models into Retrieval Models for Efficient Open-domain Conversation. (arXiv:2108.12582v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12582">
<div class="article-summary-box-inner">
<span><p>Despite the remarkable performance of large-scale generative models in
open-domain conversation, they are known to be less practical for building
real-time conversation systems due to high latency. On the other hand,
retrieval models could return responses with much lower latency but show
inferior performance to the large-scale generative models since the
conversation quality is bounded by the pre-defined response set. To take
advantage of both approaches, we propose a new training method called G2R
(Generative-to-Retrieval distillation) that preserves the efficiency of a
retrieval model while leveraging the conversational ability of a large-scale
generative model by infusing the knowledge of the generative model into the
retrieval model. G2R consists of two distinct techniques of distillation: the
data-level G2R augments the dialogue dataset with additional responses
generated by the large-scale generative model, and the model-level G2R
transfers the response quality score assessed by the generative model to the
score of the retrieval model by the knowledge distillation loss. Through
extensive experiments including human evaluation, we demonstrate that our
retrieval-based conversation system trained with G2R shows a substantially
improved performance compared to the baseline retrieval model while showing
significantly lower inference latency than the large-scale generative models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scheduled Sampling Based on Decoding Steps for Neural Machine Translation. (arXiv:2108.12963v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12963">
<div class="article-summary-box-inner">
<span><p>Scheduled sampling is widely used to mitigate the exposure bias problem for
neural machine translation. Its core motivation is to simulate the inference
scene during training by replacing ground-truth tokens with predicted tokens,
thus bridging the gap between training and inference. However, vanilla
scheduled sampling is merely based on training steps and equally treats all
decoding steps. Namely, it simulates an inference scene with uniform error
rates, which disobeys the real inference scene, where larger decoding steps
usually have higher error rates due to error accumulations. To alleviate the
above discrepancy, we propose scheduled sampling methods based on decoding
steps, increasing the selection chance of predicted tokens with the growth of
decoding steps. Consequently, we can more realistically simulate the inference
scene during training, thus better bridging the gap between training and
inference. Moreover, we investigate scheduled sampling based on both training
steps and decoding steps for further improvements. Experimentally, our
approaches significantly outperform the Transformer baseline and vanilla
scheduled sampling on three large-scale WMT tasks. Additionally, our approaches
also generalize well to the text summarization task on two popular benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners. (arXiv:2108.13161v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13161">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models have contributed significantly to
natural language processing by demonstrating remarkable abilities as few-shot
learners. However, their effectiveness depends mainly on scaling the model
parameters and prompt design, hindering their implementation in most real-world
applications. This study proposes a novel pluggable, extensible, and efficient
approach named DifferentiAble pRompT (DART), which can convert small language
models into better few-shot learners without any prompt engineering. The main
principle behind this approach involves reformulating potential natural
language processing tasks into the task of a pre-trained language model and
differentially optimizing the prompt template as well as the target label with
backpropagation. Furthermore, the proposed approach can be: (i) Plugged to any
pre-trained language models; (ii) Extended to widespread classification tasks.
A comprehensive evaluation of standard NLP tasks demonstrates that the proposed
approach achieves a better few-shot performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HELMHOLTZ: A Verifier for Tezos Smart Contracts Based on Refinement Types. (arXiv:2108.12971v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12971">
<div class="article-summary-box-inner">
<span><p>A smart contract is a program executed on a blockchain, based on which many
cryptocurrencies are implemented, and is being used for automating
transactions. Due to the large amount of money that smart contracts deal with,
there is a surging demand for a method that can statically and formally verify
them.
</p>
<p>This article describes our type-based static verification tool HELMHOLTZ for
Michelson, which is a statically typed stack-based language for writing smart
contracts that are executed on the blockchain platform Tezos. HELMHOLTZ is
designed on top of our extension of Michelson's type system with refinement
types. HELMHOLTZ takes a Michelson program annotated with a user-defined
specification written in the form of a refinement type as input; it then
typechecks the program against the specification based on the refinement type
system, discharging the generated verification conditions with the SMT solver
Z3. We briefly introduce our refinement type system for the core calculus
Mini-Michelson of Michelson, which incorporates the characteristic features
such as compound datatypes (e.g., lists and pairs), higher-order functions, and
invocation of another contract. \HELMHOLTZ{} successfully verifies several
practical Michelson programs, including one that transfers money to an account
and that checks a digital signature.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">The Application of Convolutional Neural Networks for Tomographic Reconstruction of Hyperspectral Images. (arXiv:2108.13458v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13458">
<div class="article-summary-box-inner">
<span><p>A novel method, utilizing convolutional neural networks (CNNs), is proposed
to reconstruct hyperspectral cubes from computed tomography imaging
spectrometer (CTIS) images. Current reconstruction algorithms are usually
subject to long reconstruction times and mediocre precision in cases of a large
number of spectral channels. The constructed CNNs deliver higher precision and
shorter reconstruction time than a standard expectation maximization algorithm.
In addition, the network can handle two different types of real-world images at
the same time -- specifically ColorChecker and carrot spectral images are
considered. This work paves the way toward real-time reconstruction of
hyperspectral cubes from CTIS images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LSD-StructureNet: Modeling Levels of Structural Detail in 3D Part Hierarchies. (arXiv:2108.13459v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13459">
<div class="article-summary-box-inner">
<span><p>Generative models for 3D shapes represented by hierarchies of parts can
generate realistic and diverse sets of outputs. However, existing models suffer
from the key practical limitation of modelling shapes holistically and thus
cannot perform conditional sampling, i.e. they are not able to generate
variants on individual parts of generated shapes without modifying the rest of
the shape. This is limiting for applications such as 3D CAD design that involve
adjusting created shapes at multiple levels of detail. To address this, we
introduce LSD-StructureNet, an augmentation to the StructureNet architecture
that enables re-generation of parts situated at arbitrary positions in the
hierarchies of its outputs. We achieve this by learning individual,
probabilistic conditional decoders for each hierarchy depth. We evaluate
LSD-StructureNet on the PartNet dataset, the largest dataset of 3D shapes
represented by hierarchies of parts. Our results show that contrarily to
existing methods, LSD-StructureNet can perform conditional sampling without
impacting inference speed or the realism and diversity of its outputs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Full-Cycle Energy Consumption Benchmark for Low-Carbon Computer Vision. (arXiv:2108.13465v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13465">
<div class="article-summary-box-inner">
<span><p>The energy consumption of deep learning models is increasing at a
breathtaking rate, which raises concerns due to potential negative effects on
carbon neutrality in the context of global warming and climate change. With the
progress of efficient deep learning techniques, e.g., model compression,
researchers can obtain efficient models with fewer parameters and smaller
latency. However, most of the existing efficient deep learning methods do not
explicitly consider energy consumption as a key performance indicator.
Furthermore, existing methods mostly focus on the inference costs of the
resulting efficient models, but neglect the notable energy consumption
throughout the entire life cycle of the algorithm. In this paper, we present
the first large-scale energy consumption benchmark for efficient computer
vision models, where a new metric is proposed to explicitly evaluate the
full-cycle energy consumption under different model usage intensity. The
benchmark can provide insights for low carbon emission when selecting efficient
deep learning algorithms in different model usage scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scene Synthesis via Uncertainty-Driven Attribute Synchronization. (arXiv:2108.13499v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13499">
<div class="article-summary-box-inner">
<span><p>Developing deep neural networks to generate 3D scenes is a fundamental
problem in neural synthesis with immediate applications in architectural CAD,
computer graphics, as well as in generating virtual robot training
environments. This task is challenging because 3D scenes exhibit diverse
patterns, ranging from continuous ones, such as object sizes and the relative
poses between pairs of shapes, to discrete patterns, such as occurrence and
co-occurrence of objects with symmetrical relationships. This paper introduces
a novel neural scene synthesis approach that can capture diverse feature
patterns of 3D scenes. Our method combines the strength of both neural
network-based and conventional scene synthesis approaches. We use the
parametric prior distributions learned from training data, which provide
uncertainties of object attributes and relative attributes, to regularize the
outputs of feed-forward neural models. Moreover, instead of merely predicting a
scene layout, our approach predicts an over-complete set of attributes. This
methodology allows us to utilize the underlying consistency constraints among
the predicted attributes to prune infeasible predictions. Experimental results
show that our approach outperforms existing methods considerably. The generated
3D scenes interpolate the training data faithfully while preserving both
continuous and discrete feature patterns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dead Pixel Test Using Effective Receptive Field. (arXiv:2108.13576v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13576">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have been used in various fields, but their internal
behavior is not well known. In this study, we discuss two counterintuitive
behaviors of convolutional neural networks (CNNs). First, we evaluated the size
of the receptive field. Previous studies have attempted to increase or control
the size of the receptive field. However, we observed that the size of the
receptive field does not describe the classification accuracy. The size of the
receptive field would be inappropriate for representing superiority in
performance because it reflects only depth or kernel size and does not reflect
other factors such as width or cardinality. Second, using the effective
receptive field, we examined the pixels contributing to the output.
Intuitively, each pixel is expected to equally contribute to the final output.
However, we found that there exist pixels in a partially dead state with little
contribution to the output. We reveal that the reason for this lies in the
architecture of CNN and discuss solutions to reduce the phenomenon.
Interestingly, for general classification tasks, the existence of dead pixels
improves the training of CNNs. However, in a task that captures small
perturbation, dead pixels degrade the performance. Therefore, the existence of
these dead pixels should be understood and considered in practical applications
of CNN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spectral Splitting and Aggregation Network for Hyperspectral Face Super-Resolution. (arXiv:2108.13584v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13584">
<div class="article-summary-box-inner">
<span><p>High-resolution (HR) hyperspectral face image plays an important role in face
related computer vision tasks under uncontrolled conditions, such as low-light
environment and spoofing attacks. However, the dense spectral bands of
hyperspectral face images come at the cost of limited amount of photons reached
a narrow spectral window on average, which greatly reduces the spatial
resolution of hyperspectral face images. In this paper, we investigate how to
adapt the deep learning techniques to hyperspectral face image super-resolution
(HFSR), especially when the training samples are very limited. Benefiting from
the amount of spectral bands, in which each band can be seen as an image, we
present a spectral splitting and aggregation network (SSANet) for HFSR with
limited training samples. In the shallow layers, we split the hyperspectral
image into different spectral groups and take each of them as an individual
training sample (in the sense that each group will be fed into the same
network). Then, we gradually aggregate the neighbor bands at the deeper layers
to exploit the spectral correlations. By this spectral splitting and
aggregation strategy (SSAS), we can divide the original hyperspectral image
into multiple samples to support the efficient training of the network and
effectively exploit the spectral correlations among spectrum. To cope with the
challenge of small training sample size (S3) problem, we propose to expand the
training samples by a self-representation model and symmetry-induced
augmentation. Experiments show that the introduced SSANet can well model the
joint correlations of spatial and spectral information. By expanding the
training samples, our proposed method can effectively alleviate the S3 problem.
The comparison results demonstrate that our proposed method can outperform the
state-of-the-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMAC-Seg: LiDAR Panoptic Segmentation via Sparse Multi-directional Attention Clustering. (arXiv:2108.13588v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13588">
<div class="article-summary-box-inner">
<span><p>Panoptic segmentation aims to address semantic and instance segmentation
simultaneously in a unified framework. However, an efficient solution of
panoptic segmentation in applications like autonomous driving is still an open
research problem. In this work, we propose a novel LiDAR-based panoptic system,
called SMAC-Seg. We present a learnable sparse multi-directional attention
clustering to segment multi-scale foreground instances. SMAC-Seg is a real-time
clustering-based approach, which removes the complex proposal network to
segment instances. Most existing clustering-based methods use the difference of
the predicted and ground truth center offset as the only loss to supervise the
instance centroid regression. However, this loss function only considers the
centroid of the current object, but its relative position with respect to the
neighbouring objects is not considered when learning to cluster. Thus, we
propose to use a novel centroid-aware repel loss as an additional term to
effectively supervise the network to differentiate each object cluster with its
neighbours. Our experimental results show that SMAC-Seg achieves
state-of-the-art performance among all real-time deployable networks on both
large-scale public SemanticKITTI and nuScenes panoptic segmentation datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AIP: Adversarial Iterative Pruning Based on Knowledge Transfer for Convolutional Neural Networks. (arXiv:2108.13591v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13591">
<div class="article-summary-box-inner">
<span><p>With the increase of structure complexity, convolutional neural networks
(CNNs) take a fair amount of computation cost. Meanwhile, existing research
reveals the salient parameter redundancy in CNNs. The current pruning methods
can compress CNNs with little performance drop, but when the pruning ratio
increases, the accuracy loss is more serious. Moreover, some iterative pruning
methods are difficult to accurately identify and delete unimportant parameters
due to the accuracy drop during pruning. We propose a novel adversarial
iterative pruning method (AIP) for CNNs based on knowledge transfer. The
original network is regarded as the teacher while the compressed network is the
student. We apply attention maps and output features to transfer information
from the teacher to the student. Then, a shallow fully-connected network is
designed as the discriminator to allow the output of two networks to play an
adversarial game, thereby it can quickly recover the pruned accuracy among
pruning intervals. Finally, an iterative pruning scheme based on the importance
of channels is proposed. We conduct extensive experiments on the image
classification tasks CIFAR-10, CIFAR-100, and ILSVRC-2012 to verify our pruning
method can achieve efficient compression for CNNs even without accuracy loss.
On the ILSVRC-2012, when removing 36.78% parameters and 45.55% floating-point
operations (FLOPs) of ResNet-18, the Top-1 accuracy drop are only 0.66%. Our
method is superior to some state-of-the-art pruning schemes in terms of
compressing rate and accuracy. Moreover, we further demonstrate that AIP has
good generalization on the object detection task PASCAL VOC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-balanced Learning For Domain Generalization. (arXiv:2108.13597v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13597">
<div class="article-summary-box-inner">
<span><p>Domain generalization aims to learn a prediction model on multi-domain source
data such that the model can generalize to a target domain with unknown
statistics. Most existing approaches have been developed under the assumption
that the source data is well-balanced in terms of both domain and class.
However, real-world training data collected with different composition biases
often exhibits severe distribution gaps for domain and class, leading to
substantial performance degradation. In this paper, we propose a self-balanced
domain generalization framework that adaptively learns the weights of losses to
alleviate the bias caused by different distributions of the multi-domain source
data. The self-balanced scheme is based on an auxiliary reweighting network
that iteratively updates the weight of loss conditioned on the domain and class
information by leveraging balanced meta data. Experimental results demonstrate
the effectiveness of our method overwhelming state-of-the-art works for domain
generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iterative Filter Adaptive Network for Single Image Defocus Deblurring. (arXiv:2108.13610v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13610">
<div class="article-summary-box-inner">
<span><p>We propose a novel end-to-end learning-based approach for single image
defocus deblurring. The proposed approach is equipped with a novel Iterative
Filter Adaptive Network (IFAN) that is specifically designed to handle
spatially-varying and large defocus blur. For adaptively handling
spatially-varying blur, IFAN predicts pixel-wise deblurring filters, which are
applied to defocused features of an input image to generate deblurred features.
For effectively managing large blur, IFAN models deblurring filters as stacks
of small-sized separable filters. Predicted separable deblurring filters are
applied to defocused features using a novel Iterative Adaptive Convolution
(IAC) layer. We also propose a training scheme based on defocus disparity
estimation and reblurring, which significantly boosts the deblurring quality.
We demonstrate that our method achieves state-of-the-art performance both
quantitatively and qualitatively on real-world images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation Fault: A Cheap Defense Against Adversarial Machine Learning. (arXiv:2108.13617v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13617">
<div class="article-summary-box-inner">
<span><p>Recently published attacks against deep neural networks (DNNs) have stressed
the importance of methodologies and tools to assess the security risks of using
this technology in critical systems. Efficient techniques for detecting
adversarial machine learning helps establishing trust and boost the adoption of
deep learning in sensitive and security systems. In this paper, we propose a
new technique for defending deep neural network classifiers, and convolutional
ones in particular. Our defense is cheap in the sense that it requires less
computation power despite a small cost to pay in terms of detection accuracy.
The work refers to a recently published technique called ML-LOO. We replace the
costly pixel by pixel leave-one-out approach of ML-LOO by adopting
coarse-grained leave-one-out. We evaluate and compare the efficiency of
different segmentation algorithms for this task. Our results show that a large
gain in efficiency is possible, even though penalized by a marginal decrease in
detection accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spike time displacement based error backpropagation in convolutional spiking neural networks. (arXiv:2108.13621v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13621">
<div class="article-summary-box-inner">
<span><p>We recently proposed the STiDi-BP algorithm, which avoids backward recursive
gradient computation, for training multi-layer spiking neural networks (SNNs)
with single-spike-based temporal coding. The algorithm employs a linear
approximation to compute the derivative of the spike latency with respect to
the membrane potential and it uses spiking neurons with piecewise linear
postsynaptic potential to reduce the computational cost and the complexity of
neural processing. In this paper, we extend the STiDi-BP algorithm to employ it
in deeper and convolutional architectures. The evaluation results on the image
classification task based on two popular benchmarks, MNIST and Fashion-MNIST
datasets with the accuracies of respectively 99.2% and 92.8%, confirm that this
algorithm has been applicable in deep SNNs. Another issue we consider is the
reduction of memory storage and computational cost. To do so, we consider a
convolutional SNN (CSNN) with two sets of weights: real-valued weights that are
updated in the backward pass and their signs, binary weights, that are employed
in the feedforward process. We evaluate the binary CSNN on two datasets of
MNIST and Fashion-MNIST and obtain acceptable performance with a negligible
accuracy drop with respect to real-valued weights (about $0.6%$ and $0.8%$
drops, respectively).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimulLR: Simultaneous Lip Reading Transducer with Attention-Guided Adaptive Memory. (arXiv:2108.13630v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13630">
<div class="article-summary-box-inner">
<span><p>Lip reading, aiming to recognize spoken sentences according to the given
video of lip movements without relying on the audio stream, has attracted great
interest due to its application in many scenarios. Although prior works that
explore lip reading have obtained salient achievements, they are all trained in
a non-simultaneous manner where the predictions are generated requiring access
to the full video. To breakthrough this constraint, we study the task of
simultaneous lip reading and devise SimulLR, a simultaneous lip Reading
transducer with attention-guided adaptive memory from three aspects: (1) To
address the challenge of monotonic alignments while considering the syntactic
structure of the generated sentences under simultaneous setting, we build a
transducer-based model and design several effective training strategies
including CTC pre-training, model warm-up and curriculum learning to promote
the training of the lip reading transducer. (2) To learn better spatio-temporal
representations for simultaneous encoder, we construct a truncated 3D
convolution and time-restricted self-attention layer to perform the
frame-to-frame interaction within a video segment containing fixed number of
frames. (3) The history information is always limited due to the storage in
real-time scenarios, especially for massive video data. Therefore, we devise a
novel attention-guided adaptive memory to organize semantic information of
history segments and enhance the visual representations with acceptable
computation-aware latency. The experiments show that the SimulLR achieves the
translation speedup 9.10$\times$ compared with the state-of-the-art
non-simultaneous methods, and also obtains competitive results, which indicates
the effectiveness of our proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Module-Power Prediction from PL Measurements using Deep Learning. (arXiv:2108.13640v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13640">
<div class="article-summary-box-inner">
<span><p>The individual causes for power loss of photovoltaic modules are investigated
for quite some time. Recently, it has been shown that the power loss of a
module is, for example, related to the fraction of inactive areas. While these
areas can be easily identified from electroluminescense (EL) images, this is
much harder for photoluminescence (PL) images. With this work, we close the gap
between power regression from EL and PL images. We apply a deep convolutional
neural network to predict the module power from PL images with a mean absolute
error (MAE) of 4.4% or 11.7WP. Furthermore, we depict that regression maps
computed from the embeddings of the trained network can be used to compute the
localized power loss. Finally, we show that these regression maps can be used
to identify inactive regions in PL images as well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is First Person Vision Challenging for Object Tracking?. (arXiv:2108.13665v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13665">
<div class="article-summary-box-inner">
<span><p>Understanding human-object interactions is fundamental in First Person Vision
(FPV). Tracking algorithms which follow the objects manipulated by the camera
wearer can provide useful cues to effectively model such interactions. Visual
tracking solutions available in the computer vision literature have
significantly improved their performance in the last years for a large variety
of target objects and tracking scenarios. However, despite a few previous
attempts to exploit trackers in FPV applications, a methodical analysis of the
performance of state-of-the-art trackers in this domain is still missing. In
this paper, we fill the gap by presenting the first systematic study of object
tracking in FPV. Our study extensively analyses the performance of recent
visual trackers and baseline FPV trackers with respect to different aspects and
considering a new performance measure. This is achieved through TREK-150, a
novel benchmark dataset composed of 150 densely annotated video sequences. Our
results show that object tracking in FPV is challenging, which suggests that
more research efforts should be devoted to this problem so that tracking could
benefit FPV tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-supervised Image Classification with Grad-CAM Consistency. (arXiv:2108.13673v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13673">
<div class="article-summary-box-inner">
<span><p>Consistency training, which exploits both supervised and unsupervised
learning with different augmentations on image, is an effective method of
utilizing unlabeled data in semi-supervised learning (SSL) manner. Here, we
present another version of the method with Grad-CAM consistency loss, so it can
be utilized in training model with better generalization and adjustability. We
show that our method improved the baseline ResNet model with at most 1.44 % and
0.31 $\pm$ 0.59 %p accuracy improvement on average with CIFAR-10 dataset. We
conducted ablation study comparing to using only psuedo-label for consistency
training. Also, we argue that our method can adjust in different environments
when targeted to different units in the model. The code is available:
https://github.com/gimme1dollar/gradcam-consistency-semi-sup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-based Multi-Reference Learning for Image Super-Resolution. (arXiv:2108.13697v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13697">
<div class="article-summary-box-inner">
<span><p>This paper proposes a novel Attention-based Multi-Reference Super-resolution
network (AMRSR) that, given a low-resolution image, learns to adaptively
transfer the most similar texture from multiple reference images to the
super-resolution output whilst maintaining spatial coherence. The use of
multiple reference images together with attention-based sampling is
demonstrated to achieve significantly improved performance over
state-of-the-art reference super-resolution approaches on multiple benchmark
datasets. Reference super-resolution approaches have recently been proposed to
overcome the ill-posed problem of image super-resolution by providing
additional information from a high-resolution reference image. Multi-reference
super-resolution extends this approach by providing a more diverse pool of
image features to overcome the inherent information deficit whilst maintaining
memory efficiency. A novel hierarchical attention-based sampling approach is
introduced to learn the similarity between low-resolution image features and
multiple reference images based on a perceptual loss. Ablation demonstrates the
contribution of both multi-reference and hierarchical attention-based sampling
to overall performance. Perceptual and quantitative ground-truth evaluation
demonstrates significant improvement in performance even when the reference
images deviate significantly from the target image. The project website can be
found at https://marcopesavento.github.io/AMRSR/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Monocular Vanishing Point Detection Exploiting Lane Annotations. (arXiv:2108.13699v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13699">
<div class="article-summary-box-inner">
<span><p>Vanishing points (VPs) play a vital role in various computer vision tasks,
especially for recognizing the 3D scenes from an image. In the real-world
scenario of automobile applications, it is costly to manually obtain the
external camera parameters when the camera is attached to the vehicle or the
attachment is accidentally perturbed. In this paper we introduce a simple but
effective end-to-end vanishing point detection. By automatically calculating
intersection of the extrapolated lane marker annotations, we obtain
geometrically consistent VP labels and mitigate human annotation errors caused
by manual VP labeling. With the calculated VP labels we train end-to-end VP
Detector via heatmap estimation. The VP Detector realizes higher accuracy than
the methods utilizing manual annotation or lane detection, paving the way for
accurate online camera calibration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemIE: Semantically-aware Image Extrapolation. (arXiv:2108.13702v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13702">
<div class="article-summary-box-inner">
<span><p>We propose a semantically-aware novel paradigm to perform image extrapolation
that enables the addition of new object instances. All previous methods are
limited in their capability of extrapolation to merely extending the already
existing objects in the image. However, our proposed approach focuses not only
on (i) extending the already present objects but also on (ii) adding new
objects in the extended region based on the context. To this end, for a given
image, we first obtain an object segmentation map using a state-of-the-art
semantic segmentation method. The, thus, obtained segmentation map is fed into
a network to compute the extrapolated semantic segmentation and the
corresponding panoptic segmentation maps. The input image and the obtained
segmentation maps are further utilized to generate the final extrapolated
image. We conduct experiments on Cityscapes and ADE20K-bedroom datasets and
show that our method outperforms all baselines in terms of FID, and similarity
in object co-occurrence statistics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pruning with Compensation: Efficient Channel Pruning for Deep Convolutional Neural Networks. (arXiv:2108.13728v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13728">
<div class="article-summary-box-inner">
<span><p>Channel pruning is a promising technique to compress the parameters of deep
convolutional neural networks(DCNN) and to speed up the inference. This paper
aims to address the long-standing inefficiency of channel pruning. Most channel
pruning methods recover the prediction accuracy by re-training the pruned model
from the remaining parameters or random initialization. This re-training
process is heavily dependent on the sufficiency of computational resources,
training data, and human interference(tuning the training strategy). In this
paper, a highly efficient pruning method is proposed to significantly reduce
the cost of pruning DCNN. The main contributions of our method include: 1)
pruning compensation, a fast and data-efficient substitute of re-training to
minimize the post-pruning reconstruction loss of features, 2)
compensation-aware pruning(CaP), a novel pruning algorithm to remove redundant
or less-weighted channels by minimizing the loss of information, and 3) binary
structural search with step constraint to minimize human interference. On
benchmarks including CIFAR-10/100 and ImageNet, our method shows competitive
pruning performance among the state-of-the-art retraining-based pruning methods
and, more importantly, reduces the processing time by 95% and data usage by
90%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning on Edge TPUs. (arXiv:2108.13732v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13732">
<div class="article-summary-box-inner">
<span><p>Computing at the edge is important in remote settings, however, conventional
hardware is not optimized for utilizing deep neural networks. The Google Edge
TPU is an emerging hardware accelerator that is cost, power and speed
efficient, and is available for prototyping and production purposes. Here, I
review the Edge TPU platform, the tasks that have been accomplished using the
Edge TPU, and which steps are necessary to deploy a model to the Edge TPU
hardware. The Edge TPU is not only capable of tackling common computer vision
tasks, but also surpasses other hardware accelerators, especially when the
entire model can be deployed to the Edge TPU. Co-embedding the Edge TPU in
cameras allows a seamless analysis of primary data. In summary, the Edge TPU is
a maturing system that has proven its usability across multiple tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Super-Resolution Appearance Transfer for 4D Human Performances. (arXiv:2108.13739v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13739">
<div class="article-summary-box-inner">
<span><p>A common problem in the 4D reconstruction of people from multi-view video is
the quality of the captured dynamic texture appearance which depends on both
the camera resolution and capture volume. Typically the requirement to frame
cameras to capture the volume of a dynamic performance ($&gt;50m^3$) results in
the person occupying only a small proportion $&lt;$ 10% of the field of view. Even
with ultra high-definition 4k video acquisition this results in sampling the
person at less-than standard definition 0.5k video resolution resulting in
low-quality rendering. In this paper we propose a solution to this problem
through super-resolution appearance transfer from a static high-resolution
appearance capture rig using digital stills cameras ($&gt; 8k$) to capture the
person in a small volume ($&lt;8m^3$). A pipeline is proposed for super-resolution
appearance transfer from high-resolution static capture to dynamic video
performance capture to produce super-resolution dynamic textures. This
addresses two key problems: colour mapping between different camera systems;
and dynamic texture map super-resolution using a learnt model. Comparative
evaluation demonstrates a significant qualitative and quantitative improvement
in rendering the 4D performance capture with super-resolution dynamic texture
appearance. The proposed approach reproduces the high-resolution detail of the
static capture whilst maintaining the appearance dynamics of the captured
video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic labelling of urban point clouds using data fusion. (arXiv:2108.13757v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13757">
<div class="article-summary-box-inner">
<span><p>In this paper we describe an approach to semi-automatically create a labelled
dataset for semantic segmentation of urban street-level point clouds. We use
data fusion techniques using public data sources such as elevation data and
large-scale topographical maps to automatically label parts of the point cloud,
after which only limited human effort is needed to check the results and make
amendments where needed. This drastically limits the time needed to create a
labelled dataset that is extensive enough to train deep semantic segmentation
models. We apply our method to point clouds of the Amsterdam region, and
successfully train a RandLA-Net semantic segmentation model on the labelled
dataset. These results demonstrate the potential of smart data fusion and
semantic segmentation for the future of smart city planning and management.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discriminative Semantic Feature Pyramid Network with Guided Anchoring for Logo Detection. (arXiv:2108.13775v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13775">
<div class="article-summary-box-inner">
<span><p>Recently, logo detection has received more and more attention for its wide
applications in the multimedia field, such as intellectual property protection,
product brand management, and logo duration monitoring. Unlike general object
detection, logo detection is a challenging task, especially for small logo
objects and large aspect ratio logo objects in the real-world scenario. In this
paper, we propose a novel approach, named Discriminative Semantic Feature
Pyramid Network with Guided Anchoring (DSFP-GA), which can address these
challenges via aggregating the semantic information and generating different
aspect ratio anchor boxes. More specifically, our approach mainly consists of
Discriminative Semantic Feature Pyramid (DSFP) and Guided Anchoring (GA).
Considering that low-level feature maps that are used to detect small logo
objects lack semantic information, we propose the DSFP, which can enrich more
discriminative semantic features of low-level feature maps and can achieve
better performance on small logo objects. Furthermore, preset anchor boxes are
less efficient for detecting large aspect ratio logo objects. We therefore
integrate the GA into our method to generate large aspect ratio anchor boxes to
mitigate this issue. Extensive experimental results on four benchmarks
demonstrate the effectiveness of our proposed DSFP-GA. Moreover, we further
conduct visual analysis and ablation studies to illustrate the advantage of our
method in detecting small and large aspect logo objects. The code and models
can be found at https://github.com/Zhangbaisong/DSFP-GA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Calibrating Neural Radiance Fields. (arXiv:2108.13826v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13826">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a camera self-calibration algorithm for generic
cameras with arbitrary non-linear distortions. We jointly learn the geometry of
the scene and the accurate camera parameters without any calibration objects.
Our camera model consists of a pinhole model, a fourth order radial distortion,
and a generic noise model that can learn arbitrary non-linear camera
distortions. While traditional self-calibration algorithms mostly rely on
geometric constraints, we additionally incorporate photometric consistency.
This requires learning the geometry of the scene, and we use Neural Radiance
Fields (NeRF). We also propose a new geometric loss function, viz., projected
ray distance loss, to incorporate geometric consistency for complex non-linear
camera models. We validate our approach on standard real image datasets and
demonstrate that our model can learn the camera intrinsics and extrinsics
(pose) from scratch without COLMAP initialization. Also, we show that learning
accurate camera models in a differentiable manner allows us to improve PSNR
over baselines. Our module is an easy-to-use plugin that can be applied to NeRF
variants to improve performance. The code and data are currently available at
https://github.com/POSTECH-CVLab/SCNeRF
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PACE: Posthoc Architecture-Agnostic Concept Extractor for Explaining CNNs. (arXiv:2108.13828v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13828">
<div class="article-summary-box-inner">
<span><p>Deep CNNs, though have achieved the state of the art performance in image
classification tasks, remain a black-box to a human using them. There is a
growing interest in explaining the working of these deep models to improve
their trustworthiness. In this paper, we introduce a Posthoc
Architecture-agnostic Concept Extractor (PACE) that automatically extracts
smaller sub-regions of the image called concepts relevant to the black-box
prediction. PACE tightly integrates the faithfulness of the explanatory
framework to the black-box model. To the best of our knowledge, this is the
first work that extracts class-specific discriminative concepts in a posthoc
manner automatically. The PACE framework is used to generate explanations for
two different CNN architectures trained for classifying the AWA2 and
Imagenet-Birds datasets. Extensive human subject experiments are conducted to
validate the human interpretability and consistency of the explanations
extracted by PACE. The results from these experiments suggest that over 72% of
the concepts extracted by PACE are human interpretable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fiducial marker recovery and detection from severely truncated data in navigation assisted spine surgery. (arXiv:2108.13844v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13844">
<div class="article-summary-box-inner">
<span><p>Fiducial markers are commonly used in navigation assisted minimally invasive
spine surgery (MISS) and they help transfer image coordinates into real world
coordinates. In practice, these markers might be located outside the
field-of-view (FOV), due to the limited detector sizes of C-arm cone-beam
computed tomography (CBCT) systems used in intraoperative surgeries. As a
consequence, reconstructed markers in CBCT volumes suffer from artifacts and
have distorted shapes, which sets an obstacle for navigation. In this work, we
propose two fiducial marker detection methods: direct detection from distorted
markers (direct method) and detection after marker recovery (recovery method).
For direct detection from distorted markers in reconstructed volumes, an
efficient automatic marker detection method using two neural networks and a
conventional circle detection algorithm is proposed. For marker recovery, a
task-specific learning strategy is proposed to recover markers from severely
truncated data. Afterwards, a conventional marker detection algorithm is
applied for position detection. The two methods are evaluated on simulated data
and real data, both achieving a marker registration error smaller than 0.2 mm.
Our experiments demonstrate that the direct method is capable of detecting
distorted markers accurately and the recovery method with task-specific
learning has high robustness and generalizability on various data sets. In
addition, the task-specific learning is able to reconstruct other structures of
interest accurately, e.g. ribs for image-guided needle biopsy, from severely
truncated data, which empowers CBCT systems with new potential applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InSeGAN: A Generative Approach to Segmenting Identical Instances in Depth Images. (arXiv:2108.13865v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13865">
<div class="article-summary-box-inner">
<span><p>In this paper, we present InSeGAN, an unsupervised 3D generative adversarial
network (GAN) for segmenting (nearly) identical instances of rigid objects in
depth images. Using an analysis-by-synthesis approach, we design a novel GAN
architecture to synthesize a multiple-instance depth image with independent
control over each instance. InSeGAN takes in a set of code vectors (e.g.,
random noise vectors), each encoding the 3D pose of an object that is
represented by a learned implicit object template. The generator has two
distinct modules. The first module, the instance feature generator, uses each
encoded pose to transform the implicit template into a feature map
representation of each object instance. The second module, the depth image
renderer, aggregates all of the single-instance feature maps output by the
first module and generates a multiple-instance depth image. A discriminator
distinguishes the generated multiple-instance depth images from the
distribution of true depth images. To use our model for instance segmentation,
we propose an instance pose encoder that learns to take in a generated depth
image and reproduce the pose code vectors for all of the object instances. To
evaluate our approach, we introduce a new synthetic dataset, "Insta-10",
consisting of 100,000 depth images, each with 5 instances of an object from one
of 10 classes. Our experiments on Insta-10, as well as on real-world noisy
depth images, show that InSeGAN achieves state-of-the-art performance, often
outperforming prior methods by large margins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One-shot domain adaptation for semantic face editing of real world images using StyleALAE. (arXiv:2108.13876v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13876">
<div class="article-summary-box-inner">
<span><p>Semantic face editing of real world facial images is an important application
of generative models. Recently, multiple works have explored possible
techniques to generate such modifications using the latent structure of
pre-trained GAN models. However, such approaches often require training an
encoder network and that is typically a time-consuming and resource intensive
process. A possible alternative to such a GAN-based architecture can be
styleALAE, a latent-space based autoencoder that can generate photo-realistic
images of high quality. Unfortunately, the reconstructed image in styleALAE
does not preserve the identity of the input facial image. This limits the
application of styleALAE for semantic face editing of images with known
identities. In our work, we use a recent advancement in one-shot domain
adaptation to address this problem. Our work ensures that the identity of the
reconstructed image is the same as the given input image. We further generate
semantic modifications over the reconstructed image by using the latent space
of the pre-trained styleALAE model. Results show that our approach can generate
semantic modifications on any real world facial image while preserving the
identity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimation of Air Pollution with Remote Sensing Data: Revealing Greenhouse Gas Emissions from Space. (arXiv:2108.13902v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13902">
<div class="article-summary-box-inner">
<span><p>Air pollution is a major driver of climate change. Anthropogenic emissions
from the burning of fossil fuels for transportation and power generation emit
large amounts of problematic air pollutants, including Greenhouse Gases (GHGs).
Despite the importance of limiting GHG emissions to mitigate climate change,
detailed information about the spatial and temporal distribution of GHG and
other air pollutants is difficult to obtain. Existing models for surface-level
air pollution rely on extensive land-use datasets which are often locally
restricted and temporally static. This work proposes a deep learning approach
for the prediction of ambient air pollution that only relies on remote sensing
data that is globally available and frequently updated. Combining optical
satellite imagery with satellite-based atmospheric column density air pollution
measurements enables the scaling of air pollution estimates (in this case
NO$_2$) to high spatial resolution (up to $\sim$10m) at arbitrary locations and
adds a temporal component to these estimates. The proposed model performs with
high accuracy when evaluated against air quality measurements from ground
stations (mean absolute error $&lt;$6$~\mu g/m^3$). Our results enable the
identification and temporal monitoring of major sources of air pollution and
GHGs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simultaneous Nuclear Instance and Layer Segmentation in Oral Epithelial Dysplasia. (arXiv:2108.13904v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13904">
<div class="article-summary-box-inner">
<span><p>Oral epithelial dysplasia (OED) is a pre-malignant histopathological
diagnosis given to lesions of the oral cavity. Predicting OED grade or whether
a case will transition to malignancy is critical for early detection and
appropriate treatment. OED typically begins in the lower third of the
epithelium before progressing upwards with grade severity, thus we have
suggested that segmenting intra-epithelial layers, in addition to individual
nuclei, may enable researchers to evaluate important layer-specific
morphological features for grade/malignancy prediction. We present HoVer-Net+,
a deep learning framework to simultaneously segment (and classify) nuclei and
(intra-)epithelial layers in H&amp;E stained slides from OED cases. The proposed
architecture consists of an encoder branch and four decoder branches for
simultaneous instance segmentation of nuclei and semantic segmentation of the
epithelial layers. We show that the proposed model achieves the
state-of-the-art (SOTA) performance in both tasks, with no additional costs
when compared to previous SOTA methods for each task. To the best of our
knowledge, ours is the first method for simultaneous nuclear instance
segmentation and semantic tissue segmentation, with potential for use in
computational pathology for other similar simultaneous tasks and for future
studies into malignancy prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic digital twin data model generation of building energy systems from piping and instrumentation diagrams. (arXiv:2108.13912v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13912">
<div class="article-summary-box-inner">
<span><p>Buildings directly and indirectly emit a large share of current CO2
emissions. There is a high potential for CO2 savings through modern control
methods in building automation systems (BAS) like model predictive control
(MPC). For a proper control, MPC needs mathematical models to predict the
future behavior of the controlled system. For this purpose, digital twins of
the building can be used. However, with current methods in existing buildings,
a digital twin set up is usually labor-intensive. Especially connecting the
different components of the technical system to an overall digital twin of the
building is time-consuming. Piping and instrument diagrams (P&amp;ID) can provide
the needed information, but it is necessary to extract the information and
provide it in a standardized format to process it further.
</p>
<p>In this work, we present an approach to recognize symbols and connections of
P&amp;ID from buildings in a completely automated way. There are various standards
for graphical representation of symbols in P&amp;ID of building energy systems.
Therefore, we use different data sources and standards to generate a holistic
training data set. We apply algorithms for symbol recognition, line recognition
and derivation of connections to the data sets. Furthermore, the result is
exported to a format that provides semantics of building energy systems.
</p>
<p>The symbol recognition, line recognition and connection recognition show good
results with an average precision of 93.7%, which can be used in further
processes like control generation, (distributed) model predictive control or
fault detection. Nevertheless, the approach needs further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ScatSimCLR: self-supervised contrastive learning with pretext task regularization for small-scale datasets. (arXiv:2108.13939v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13939">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider a problem of self-supervised learning for
small-scale datasets based on contrastive loss between multiple views of the
data, which demonstrates the state-of-the-art performance in classification
task. Despite the reported results, such factors as the complexity of training
requiring complex architectures, the needed number of views produced by data
augmentation, and their impact on the classification accuracy are understudied
problems. To establish the role of these factors, we consider an architecture
of contrastive loss system such as SimCLR, where baseline model is replaced by
geometrically invariant "hand-crafted" network ScatNet with small trainable
adapter network and argue that the number of parameters of the whole system and
the number of views can be considerably reduced while practically preserving
the same classification accuracy. In addition, we investigate the impact of
regularization strategies using pretext task learning based on an estimation of
parameters of augmentation transform such as rotation and jigsaw permutation
for both traditional baseline models and ScatNet based models. Finally, we
demonstrate that the proposed architecture with pretext task learning
regularization achieves the state-of-the-art classification performance with a
smaller number of trainable parameters and with reduced number of views.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Dataset for Keypoint Detection of quadruped Animals from Images. (arXiv:2108.13958v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13958">
<div class="article-summary-box-inner">
<span><p>In this paper, we studied the problem of localizing a generic set of
keypoints across multiple quadruped or four-legged animal species from images.
Due to the lack of large scale animal keypoint dataset with ground truth
annotations, we developed a novel dataset, AwA Pose, for keypoint detection of
quadruped animals from images. Our dataset contains significantly more
keypoints per animal and has much more diverse animals than the existing
datasets for animal keypoint detection. We benchmarked the dataset with a
state-of-the-art deep learning model for different keypoint detection tasks,
including both seen and unseen animal cases. Experimental results showed the
effectiveness of the dataset. We believe that this dataset will help the
computer vision community in the design and evaluation of improved models for
the generalized quadruped animal keypoint detection problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DepthTrack : Unveiling the Power of RGBD Tracking. (arXiv:2108.13962v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13962">
<div class="article-summary-box-inner">
<span><p>RGBD (RGB plus depth) object tracking is gaining momentum as RGBD sensors
have become popular in many application fields such as robotics.However, the
best RGBD trackers are extensions of the state-of-the-art deep RGB trackers.
They are trained with RGB data and the depth channel is used as a sidekick for
subtleties such as occlusion detection. This can be explained by the fact that
there are no sufficiently large RGBD datasets to 1) train deep depth trackers
and to 2) challenge RGB trackers with sequences for which the depth cue is
essential. This work introduces a new RGBD tracking dataset - Depth-Track -
that has twice as many sequences (200) and scene types (40) than in the largest
existing dataset, and three times more objects (90). In addition, the average
length of the sequences (1473), the number of deformable objects (16) and the
number of annotated tracking attributes (15) have been increased. Furthermore,
by running the SotA RGB and RGBD trackers on DepthTrack, we propose a new RGBD
tracking baseline, namely DeT, which reveals that deep RGBD tracking indeed
benefits from genuine training data. The code and dataset is available at
https://github.com/xiaozai/DeT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">S4-Crowd: Semi-Supervised Learning with Self-Supervised Regularisation for Crowd Counting. (arXiv:2108.13969v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13969">
<div class="article-summary-box-inner">
<span><p>Crowd counting has drawn more attention because of its wide application in
smart cities. Recent works achieved promising performance but relied on the
supervised paradigm with expensive crowd annotations. To alleviate annotation
cost, in this work we proposed a semi-supervised learning framework S4-Crowd,
which can leverage both unlabeled/labeled data for robust crowd modelling. In
the unsupervised pathway, two self-supervised losses were proposed to simulate
the crowd variations such as scale, illumination, etc., based on which and the
supervised information pseudo labels were generated and gradually refined. We
also proposed a crowd-driven recurrent unit Gated-Crowd-Recurrent-Unit (GCRU),
which can preserve discriminant crowd information by extracting second-order
statistics, yielding pseudo labels with improved quality. A joint loss
including both unsupervised/supervised information was proposed, and a dynamic
weighting strategy was employed to balance the importance of the unsupervised
loss and supervised loss at different training stages. We conducted extensive
experiments on four popular crowd counting datasets in semi-supervised
settings. Experimental results suggested the effectiveness of each proposed
component in our S4-Crowd framework. Our method also outperformed other
state-of-the-art semi-supervised learning approaches on these crowd datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Mitosis against Domain Shift using a Fused Detector and Deep Ensemble Classification Model for MIDOG Challenge. (arXiv:2108.13983v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13983">
<div class="article-summary-box-inner">
<span><p>Mitotic figure count is an important marker of tumor proliferation and has
been shown to be associated with patients' prognosis. Deep learning based
mitotic figure detection methods have been utilized to automatically locate the
cell in mitosis using hematoxylin \&amp; eosin (H\&amp;E) stained images. However, the
model performance deteriorates due to the large variation of color tone and
intensity in H\&amp;E images. In this work, we proposed a two stage mitotic figure
detection framework by fusing a detector and a deep ensemble classification
model. To alleviate the impact of color variation in H\&amp;E images, we utilize
both stain normalization and data augmentation, aiding model to learn color
irrelevant features. The proposed model obtains an F1 score of 0.7550 on the
preliminary testing set released by the MIDOG challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OARnet: Automated organs-at-risk delineation in Head and Neck CT images. (arXiv:2108.13987v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13987">
<div class="article-summary-box-inner">
<span><p>A 3D deep learning model (OARnet) is developed and used to delineate 28 H&amp;N
OARs on CT images. OARnet utilizes a densely connected network to detect the
OAR bounding-box, then delineates the OAR within the box. It reuses information
from any layer to subsequent layers and uses skip connections to combine
information from different dense block levels to progressively improve
delineation accuracy. Training uses up to 28 expert manual delineated (MD) OARs
from 165 CTs. Dice similarity coefficient (DSC) and the 95th percentile
Hausdorff distance (HD95) with respect to MD is assessed for 70 other CTs.
Mean, maximum, and root-mean-square dose differences with respect to MD are
assessed for 56 of the 70 CTs. OARnet is compared with UaNet, AnatomyNet, and
Multi-Atlas Segmentation (MAS). Wilcoxon signed-rank tests using 95% confidence
intervals are used to assess significance. Wilcoxon signed ranked tests show
that, compared with UaNet, OARnet improves (p&lt;0.05) the DSC (23/28 OARs) and
HD95 (17/28). OARnet outperforms both AnatomyNet and MAS for DSC (28/28) and
HD95 (27/28). Compared with UaNet, OARnet improves median DSC up to 0.05 and
HD95 up to 1.5mm. Compared with AnatomyNet and MAS, OARnet improves median
(DSC, HD95) by up to (0.08, 2.7mm) and (0.17, 6.3mm). Dosimetrically, OARnet
outperforms UaNet (Dmax 7/28; Dmean 10/28), AnatomyNet (Dmax 21/28; Dmean
24/28), and MAS (Dmax 22/28; Dmean 21/28). The DenseNet architecture is
optimized using a hybrid approach that performs OAR-specific bounding box
detection followed by feature recognition. Compared with other auto-delineation
methods, OARnet is better than or equal to UaNet for all but one geometric
(Temporal Lobe L, HD95) and one dosimetric (Eye L, mean dose) endpoint for the
28 H&amp;N OARs, and is better than or equal to both AnatomyNet and MAS for all
OARs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Realistic Hands: A Hybrid Model for 3D Hand Reconstruction. (arXiv:2108.13995v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13995">
<div class="article-summary-box-inner">
<span><p>Estimating 3D hand meshes from RGB images robustly is a highly desirable
task, made challenging due to the numerous degrees of freedom, and issues such
as self similarity and occlusions. Previous methods generally either use
parametric 3D hand models or follow a model-free approach. While the former can
be considered more robust, e.g. to occlusions, they are less expressive. We
propose a hybrid approach, utilizing a deep neural network and differential
rendering based optimization to demonstrably achieve the best of both worlds.
In addition, we explore Virtual Reality (VR) as an application. Most VR
headsets are nowadays equipped with multiple cameras, which we can leverage by
extending our method to the egocentric stereo domain. This extension proves to
be more resilient to the above mentioned issues. Finally, as a use-case, we
show that the improved image-model alignment can be used to acquire the user's
hand texture, which leads to a more realistic virtual hand representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HUMBO: Bridging Response Generation and Facial Expression Synthesis. (arXiv:1905.11240v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.11240">
<div class="article-summary-box-inner">
<span><p>Spoken dialogue systems that assist users to solve complex tasks such as
movie ticket booking have become an emerging research topic in artificial
intelligence and natural language processing areas. With a well-designed
dialogue system as an intelligent personal assistant, people can accomplish
certain tasks more easily via natural language interactions. Today there are
several virtual intelligent assistants in the market; however, most systems
only focus on textual or vocal interaction. In this paper, we present HUMBO, a
system aiming at generating dialogue responses and simultaneously synthesize
corresponding visual expressions on faces for better multimodal interaction.
HUMBO can (1) let users determine the appearances of virtual assistants by a
single image, and (2) generate coherent emotional utterances and facial
expressions on the user-provided image. This is not only a brand new research
direction but more importantly, an ultimate step toward more human-like virtual
assistants.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal Adversarial Robustness of Texture and Shape-Biased Models. (arXiv:1911.10364v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.10364">
<div class="article-summary-box-inner">
<span><p>Increasing shape-bias in deep neural networks has been shown to improve
robustness to common corruptions and noise. In this paper we analyze the
adversarial robustness of texture and shape-biased models to Universal
Adversarial Perturbations (UAPs). We use UAPs to evaluate the robustness of DNN
models with varying degrees of shape-based training. We find that shape-biased
models do not markedly improve adversarial robustness, and we show that
ensembles of texture and shape-biased models can improve universal adversarial
robustness while maintaining strong performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FASTER: Fast and Safe Trajectory Planner for Navigation in Unknown Environments. (arXiv:2001.04420v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04420">
<div class="article-summary-box-inner">
<span><p>Planning high-speed trajectories for UAVs in unknown environments requires
algorithmic techniques that enable fast reaction times to guarantee safety as
more information about the environment becomes available. The standard
approaches that ensure safety by enforcing a "stop" condition in the free-known
space can severely limit the speed of the vehicle, especially in situations
where much of the world is unknown. Moreover, the ad-hoc time and interval
allocation scheme usually imposed on the trajectory also leads to conservative
and slower trajectories. This work proposes FASTER (Fast and Safe Trajectory
Planner) to ensure safety without sacrificing speed. FASTER obtains high-speed
trajectories by enabling the local planner to optimize in both the free-known
and unknown spaces. Safety is ensured by always having a safe back-up
trajectory in the free-known space. The MIQP formulation proposed also allows
the solver to choose the trajectory interval allocation. FASTER is tested
extensively in simulation and in real hardware, showing flights in unknown
cluttered environments with velocities up to 7.8m/s, and experiments at the
maximum speed of a skid-steer ground robot (2m/s).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalizable Model-agnostic Semantic Segmentation via Target-specific Normalization. (arXiv:2003.12296v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.12296">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation in a supervised learning manner has achieved
significant progress in recent years. However, its performance usually drops
dramatically due to the data-distribution discrepancy between seen and unseen
domains when we directly deploy the trained model to segment the images of
unseen (or new coming) domains. To this end, we propose a novel domain
generalization framework for the generalizable semantic segmentation task,
which enhances the generalization ability of the model from two different
views, including the training paradigm and the test strategy. Concretely, we
exploit the model-agnostic learning to simulate the domain shift problem, which
deals with the domain generalization from the training scheme perspective.
Besides, considering the data-distribution discrepancy between seen source and
unseen target domains, we develop the target-specific normalization scheme to
enhance the generalization ability. Furthermore, when images come one by one in
the test stage, we design the image-based memory bank (Image Bank in short)
with style-based selection policy to select similar images to obtain more
accurate statistics of normalization. Extensive experiments highlight that the
proposed method produces state-of-the-art performance for the domain
generalization of semantic segmentation on multiple benchmark segmentation
datasets, i.e., Cityscapes, Mapillary.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning Visual Dialog with Sparse Graph Learning and Knowledge Transfer. (arXiv:2004.06698v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.06698">
<div class="article-summary-box-inner">
<span><p>Visual dialog is a task of answering a sequence of questions grounded in an
image using the previous dialog history as context. In this paper, we study how
to address two fundamental challenges for this task: (1) reasoning over
underlying semantic structures among dialog rounds and (2) identifying several
appropriate answers to the given question. To address these challenges, we
propose a Sparse Graph Learning (SGL) method to formulate visual dialog as a
graph structure learning task. SGL infers inherently sparse dialog structures
by incorporating binary and score edges and leveraging a new structural loss
function. Next, we introduce a Knowledge Transfer (KT) method that extracts the
answer predictions from the teacher model and uses them as pseudo labels. We
propose KT to remedy the shortcomings of single ground-truth labels, which
severely limit the ability of a model to obtain multiple reasonable answers. As
a result, our proposed model significantly improves reasoning capability
compared to baseline methods and outperforms the state-of-the-art approaches on
the VisDial v1.0 dataset. The source code is available at
https://github.com/gicheonkang/SGLKT-VisDial.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Noticing Motion Patterns: Temporal CNN with a Novel Convolution Operator for Human Trajectory Prediction. (arXiv:2007.00862v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00862">
<div class="article-summary-box-inner">
<span><p>We propose a Convolutional Neural Network-based approach to learn, detect,and
extract patterns in sequential trajectory data, known here as Social Pattern
Extraction Convolution (Social-PEC). A set of experiments carried out on the
human trajectory prediction problem shows that our model performs comparably to
the state of the art and outperforms in some cases. More importantly,the
proposed approach unveils the obscurity in the previous use of pooling layer,
presenting a way to intuitively explain the decision-making process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Protect, Show, Attend and Tell: Empowering Image Captioning Models with Ownership Protection. (arXiv:2008.11009v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11009">
<div class="article-summary-box-inner">
<span><p>By and large, existing Intellectual Property (IP) protection on deep neural
networks typically i) focus on image classification task only, and ii) follow a
standard digital watermarking framework that was conventionally used to protect
the ownership of multimedia and video content. This paper demonstrates that the
current digital watermarking framework is insufficient to protect image
captioning tasks that are often regarded as one of the frontiers AI problems.
As a remedy, this paper studies and proposes two different embedding schemes in
the hidden memory state of a recurrent neural network to protect the image
captioning model. From empirical points, we prove that a forged key will yield
an unusable image captioning model, defeating the purpose of infringement. To
the best of our knowledge, this work is the first to propose ownership
protection on image captioning task. Also, extensive experiments show that the
proposed method does not compromise the original image captioning performance
on all common captioning metrics on Flickr30k and MS-COCO datasets, and at the
same time it is able to withstand both removal and ambiguity attacks. Code is
available at https://github.com/jianhanlim/ipr-imagecaptioning
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shape Defense Against Adversarial Attacks. (arXiv:2008.13336v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.13336">
<div class="article-summary-box-inner">
<span><p>Humans rely heavily on shape information to recognize objects. Conversely,
convolutional neural networks (CNNs) are biased more towards texture. This is
perhaps the main reason why CNNs are vulnerable to adversarial examples. Here,
we explore how shape bias can be incorporated into CNNs to improve their
robustness. Two algorithms are proposed, based on the observation that edges
are invariant to moderate imperceptible perturbations. In the first one, a
classifier is adversarially trained on images with the edge map as an
additional channel. At inference time, the edge map is recomputed and
concatenated to the image. In the second algorithm, a conditional GAN is
trained to translate the edge maps, from clean and/or perturbed images, into
clean images. Inference is done over the generated image corresponding to the
input's edge map. Extensive experiments over 10 datasets demonstrate the
effectiveness of the proposed algorithms against FGSM and $\ell_\infty$ PGD-40
attacks. Further, we show that a) edge information can also benefit other
adversarial training methods, and b) CNNs trained on edge-augmented inputs are
more robust against natural image corruptions such as motion blur, impulse
noise and JPEG compression, than CNNs trained solely on RGB images. From a
broader perspective, our study suggests that CNNs do not adequately account for
image structures that are crucial for robustness. Code is available
at:~\url{https://github.com/aliborji/Shapedefence.git}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuous Conditional Generative Adversarial Networks: Novel Empirical Losses and Label Input Mechanisms. (arXiv:2011.07466v7 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07466">
<div class="article-summary-box-inner">
<span><p>This work proposes the continuous conditional generative adversarial network
(CcGAN), the first generative model for image generation conditional on
continuous, scalar conditions (termed regression labels). Existing conditional
GANs (cGANs) are mainly designed for categorical conditions (eg, class labels);
conditioning on regression labels is mathematically distinct and raises two
fundamental problems:(P1) Since there may be very few (even zero) real images
for some regression labels, minimizing existing empirical versions of cGAN
losses (aka empirical cGAN losses) often fails in practice;(P2) Since
regression labels are scalar and infinitely many, conventional label input
methods are not applicable. The proposed CcGAN solves the above problems,
respectively, by (S1) reformulating existing empirical cGAN losses to be
appropriate for the continuous scenario; and (S2) proposing a naive label input
(NLI) method and an improved label input (ILI) method to incorporate regression
labels into the generator and the discriminator. The reformulation in (S1)
leads to two novel empirical discriminator losses, termed the hard vicinal
discriminator loss (HVDL) and the soft vicinal discriminator loss (SVDL)
respectively, and a novel empirical generator loss. The error bounds of a
discriminator trained with HVDL and SVDL are derived under mild assumptions in
this work. Two new benchmark datasets (RC-49 and Cell-200) and a novel
evaluation metric (Sliding Fr\'echet Inception Distance) are also proposed for
this continuous scenario. Our experiments on the Circular 2-D Gaussians, RC-49,
UTKFace, Cell-200, and Steering Angle datasets show that CcGAN is able to
generate diverse, high-quality samples from the image distribution conditional
on a given regression label. Moreover, in these experiments, CcGAN
substantially outperforms cGAN both visually and quantitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stochastic Image Denoising by Sampling from the Posterior Distribution. (arXiv:2101.09552v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09552">
<div class="article-summary-box-inner">
<span><p>Image denoising is a well-known and well studied problem, commonly targeting
a minimization of the mean squared error (MSE) between the outcome and the
original image. Unfortunately, especially for severe noise levels, such Minimum
MSE (MMSE) solutions may lead to blurry output images. In this work we propose
a novel stochastic denoising approach that produces viable and high perceptual
quality results, while maintaining a small MSE. Our method employs Langevin
dynamics that relies on a repeated application of any given MMSE denoiser,
obtaining the reconstructed image by effectively sampling from the posterior
distribution. Due to its stochasticity, the proposed algorithm can produce a
variety of high-quality outputs for a given noisy input, all shown to be
legitimate denoising results. In addition, we present an extension of our
algorithm for handling the inpainting problem, recovering missing pixels while
removing noise from partially given data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TLRM: Task-level Relation Module for GNN-based Few-Shot Learning. (arXiv:2101.09840v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09840">
<div class="article-summary-box-inner">
<span><p>Recently, graph neural networks (GNNs) have shown powerful ability to handle
few-shot classification problem, which aims at classifying unseen samples when
trained with limited labeled samples per class. GNN-based few-shot learning
architectures mostly replace traditional metric with a learnable GNN. In the
GNN, the nodes are set as the samples embedding, and the relationship between
two connected nodes can be obtained by a network, the input of which is the
difference of their embedding features. We consider this method of measuring
relation of samples only models the sample-to-sample relation, while neglects
the specificity of different tasks. That is, this method of measuring relation
does not take the task-level information into account. To this end, we propose
a new relation measure method, namely the task-level relation module (TLRM), to
explicitly model the task-level relation of one sample to all the others. The
proposed module captures the relation representations between nodes by
considering the sample-to-task instead of sample-to-sample embedding features.
We conducted extensive experiments on four benchmark datasets: mini-ImageNet,
tiered-ImageNet, CUB-$200$-$2011$, and CIFAR-FS. Experimental results
demonstrate that the proposed module is effective for GNN-based few-shot
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding self-supervised Learning Dynamics without Contrastive Pairs. (arXiv:2102.06810v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06810">
<div class="article-summary-box-inner">
<span><p>While contrastive approaches of self-supervised learning (SSL) learn
representations by minimizing the distance between two augmented views of the
same data point (positive pairs) and maximizing views from different data
points (negative pairs), recent \emph{non-contrastive} SSL (e.g., BYOL and
SimSiam) show remarkable performance {\it without} negative pairs, with an
extra learnable predictor and a stop-gradient operation. A fundamental question
arises: why do these methods not collapse into trivial representations? We
answer this question via a simple theoretical study and propose a novel
approach, DirectPred, that \emph{directly} sets the linear predictor based on
the statistics of its inputs, without gradient training. On ImageNet, it
performs comparably with more complex two-layer non-linear predictors that
employ BatchNorm and outperforms a linear predictor by $2.5\%$ in 300-epoch
training (and $5\%$ in 60-epoch). DirectPred is motivated by our theoretical
study of the nonlinear learning dynamics of non-contrastive SSL in simple
linear networks. Our study yields conceptual insights into how non-contrastive
SSL methods learn, how they avoid representational collapse, and how multiple
factors, like predictor networks, stop-gradients, exponential moving averages,
and weight decay all come into play. Our simple theory recapitulates the
results of real-world ablation studies in both STL-10 and ImageNet. Code is
released https://github.com/facebookresearch/luckmatters/tree/master/ssl.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multitask 3D CBCT-to-CT Translation and Organs-at-Risk Segmentation Using Physics-Based Data Augmentation. (arXiv:2103.05690v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05690">
<div class="article-summary-box-inner">
<span><p>In current clinical practice, noisy and artifact-ridden weekly cone-beam
computed tomography (CBCT) images are only used for patient setup during
radiotherapy. Treatment planning is done once at the beginning of the treatment
using high-quality planning CT (pCT) images and manual contours for
organs-at-risk (OARs) structures. If the quality of the weekly CBCT images can
be improved while simultaneously segmenting OAR structures, this can provide
critical information for adapting radiotherapy mid-treatment as well as for
deriving biomarkers for treatment response. Using a novel physics-based data
augmentation strategy, we synthesize a large dataset of perfectly/inherently
registered planning CT and synthetic-CBCT pairs for locally advanced lung
cancer patient cohort, which are then used in a multitask 3D deep learning
framework to simultaneously segment and translate real weekly CBCT images to
high-quality planning CT-like images. We compared the synthetic CT and OAR
segmentations generated by the model to real planning CT and manual OAR
segmentations and showed promising results. The real week 1 (baseline) CBCT
images which had an average MAE of 162.77 HU compared to pCT images are
translated to synthetic CT images that exhibit a drastically improved average
MAE of 29.31 HU and average structural similarity of 92% with the pCT images.
The average DICE scores of the 3D organs-at-risk segmentations are: lungs 0.96,
heart 0.88, spinal cord 0.83 and esophagus 0.66. This approach could allow
clinicians to adjust treatment plans using only the routine low-quality CBCT
images, potentially improving patient outcomes. Our code, data, and pre-trained
models will be made available via our physics-based data augmentation library,
Physics-ArX, at https://github.com/nadeemlab/Physics-ArX.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personalizing image enhancement for critical visual tasks: improved legibility of papyri using color processing and visual illusions. (arXiv:2104.01106v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01106">
<div class="article-summary-box-inner">
<span><p>Purpose: This article develops theoretical, algorithmic, perceptual, and
interaction aspects of script legibility enhancement in the visible light
spectrum for the purpose of scholarly editing of papyri texts. - Methods: Novel
legibility enhancement algorithms based on color processing and visual
illusions are compared to classic methods in a user experience experiment. -
Results: (1) The proposed methods outperformed the comparison methods. (2)
Users exhibited a broad behavioral spectrum, under the influence of factors
such as personality and social conditioning, tasks and application domains,
expertise level and image quality, and affordances of software, hardware, and
interfaces. No single enhancement method satisfied all factor configurations.
Therefore, it is suggested to offer users a broad choice of methods to
facilitate personalization, contextualization, and complementarity. (3) A
distinction is made between casual and critical vision on the basis of signal
ambiguity and error consequences. The criteria of a paradigm for enhancing
images for critical applications comprise: interpreting images skeptically;
approaching enhancement as a system problem; considering all image structures
as potential information; and making uncertainty and alternative
interpretations explicit, both visually and numerically.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">De-rendering the World's Revolutionary Artefacts. (arXiv:2104.03954v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03954">
<div class="article-summary-box-inner">
<span><p>Recent works have shown exciting results in unsupervised image de-rendering
-- learning to decompose 3D shape, appearance, and lighting from single-image
collections without explicit supervision. However, many of these assume
simplistic material and lighting models. We propose a method, termed RADAR,
that can recover environment illumination and surface materials from real
single-image collections, relying neither on explicit 3D supervision, nor on
multi-view or multi-light images. Specifically, we focus on rotationally
symmetric artefacts that exhibit challenging surface properties including
specular reflections, such as vases. We introduce a novel self-supervised
albedo discriminator, which allows the model to recover plausible albedo
without requiring any ground-truth during training. In conjunction with a shape
reconstruction module exploiting rotational symmetry, we present an end-to-end
learning framework that is able to de-render the world's revolutionary
artefacts. We conduct experiments on a real vase dataset and demonstrate
compelling decomposition results, allowing for applications including
free-viewpoint rendering and relighting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dressing in Order: Recurrent Person Image Generation for Pose Transfer, Virtual Try-on and Outfit Editing. (arXiv:2104.07021v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07021">
<div class="article-summary-box-inner">
<span><p>We proposes a flexible person generation framework called Dressing in Order
(DiOr), which supports 2D pose transfer, virtual try-on, and several fashion
editing tasks. The key to DiOr is a novel recurrent generation pipeline to
sequentially put garments on a person, so that trying on the same garments in
different orders will result in different looks. Our system can produce
dressing effects not achievable by existing work, including different
interactions of garments (e.g., wearing a top tucked into the bottom or over
it), as well as layering of multiple garments of the same type (e.g., jacket
over shirt over t-shirt). DiOr explicitly encodes the shape and texture of each
garment, enabling these elements to be edited separately. Joint training on
pose transfer and inpainting helps with detail preservation and coherence of
generated garments. Extensive evaluations show that DiOr outperforms other
recent methods like ADGAN in terms of output quality, and handles a wide range
of editing functions for which there is no direct supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anomaly Detection with Prototype-Guided Discriminative Latent Embeddings. (arXiv:2104.14945v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14945">
<div class="article-summary-box-inner">
<span><p>Recent efforts towards video anomaly detection (VAD) try to learn a deep
autoencoder to describe normal event patterns with small reconstruction errors.
The video inputs with large reconstruction errors are regarded as anomalies at
the test time. However, these methods sometimes reconstruct abnormal inputs
well because of the powerful generalization ability of deep autoencoder. To
address this problem, we present a novel approach for anomaly detection, which
utilizes discriminative prototypes of normal data to reconstruct video frames.
In this way, the model will favor the reconstruction of normal events and
distort the reconstruction of abnormal events. Specifically, we use a
prototype-guided memory module to perform discriminative latent embedding. We
introduce a new discriminative criterion for the memory module, as well as a
loss function correspondingly, which can encourage memory items to record the
representative embeddings of normal data, i.e. prototypes. Besides, we design a
novel two-branch autoencoder, which is composed of a future frame prediction
network and an RGB difference generation network that share the same encoder.
The stacked RGB difference contains motion information just like optical flow,
so our model can learn temporal regularity. We evaluate the effectiveness of
our method on three benchmark datasets and experimental results demonstrate the
proposed method outperforms the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curious Representation Learning for Embodied Intelligence. (arXiv:2105.01060v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01060">
<div class="article-summary-box-inner">
<span><p>Self-supervised representation learning has achieved remarkable success in
recent years. By subverting the need for supervised labels, such approaches are
able to utilize the numerous unlabeled images that exist on the Internet and in
photographic datasets. Yet to build truly intelligent agents, we must construct
representation learning algorithms that can learn not only from datasets but
also learn from environments. An agent in a natural environment will not
typically be fed curated data. Instead, it must explore its environment to
acquire the data it will learn from. We propose a framework, curious
representation learning (CRL), which jointly learns a reinforcement learning
policy and a visual representation model. The policy is trained to maximize the
error of the representation learner, and in doing so is incentivized to explore
its environment. At the same time, the learned representation becomes stronger
and stronger as the policy feeds it ever harder data to learn from. Our learned
representations enable promising transfer to downstream navigation tasks,
performing better than or comparably to ImageNet pretraining without using any
supervision at all. In addition, despite being trained in simulation, our
learned representations can obtain interpretable results on real images. Code
is available at https://yilundu.github.io/crl/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Surveilling Surveillance: Estimating the Prevalence of Surveillance Cameras with Street View Data. (arXiv:2105.01764v3 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01764">
<div class="article-summary-box-inner">
<span><p>The use of video surveillance in public spaces -- both by government agencies
and by private citizens -- has attracted considerable attention in recent
years, particularly in light of rapid advances in face-recognition technology.
But it has been difficult to systematically measure the prevalence and
placement of cameras, hampering efforts to assess the implications of
surveillance on privacy and public safety. Here, we combine computer vision,
human verification, and statistical analysis to estimate the spatial
distribution of surveillance cameras. Specifically, we build a camera detection
model and apply it to 1.6 million street view images sampled from 10 large U.S.
cities and 6 other major cities around the world, with positive model
detections verified by human experts. After adjusting for the estimated recall
of our model, and accounting for the spatial coverage of our sampled images, we
are able to estimate the density of surveillance cameras visible from the road.
Across the 16 cities we consider, the estimated number of surveillance cameras
per linear kilometer ranges from 0.2 (in Los Angeles) to 0.9 (in Seoul). In a
detailed analysis of the 10 U.S. cities, we find that cameras are concentrated
in commercial, industrial, and mixed zones, and in neighborhoods with higher
shares of non-white residents -- a pattern that persists even after adjusting
for land use. These results help inform ongoing discussions on the use of
surveillance technology, including its potential disparate impacts on
communities of color.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-time Deep Dynamic Characters. (arXiv:2105.01794v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01794">
<div class="article-summary-box-inner">
<span><p>We propose a deep videorealistic 3D human character model displaying highly
realistic shape, motion, and dynamic appearance learned in a new weakly
supervised way from multi-view imagery. In contrast to previous work, our
controllable 3D character displays dynamics, e.g., the swing of the skirt,
dependent on skeletal body motion in an efficient data-driven way, without
requiring complex physics simulation. Our character model also features a
learned dynamic texture model that accounts for photo-realistic
motion-dependent appearance details, as well as view-dependent lighting
effects. During training, we do not need to resort to difficult dynamic 3D
capture of the human; instead we can train our model entirely from multi-view
video in a weakly supervised manner. To this end, we propose a parametric and
differentiable character representation which allows us to model coarse and
fine dynamic deformations, e.g., garment wrinkles, as explicit space-time
coherent mesh geometry that is augmented with high-quality dynamic textures
dependent on motion and view point. As input to the model, only an arbitrary 3D
skeleton motion is required, making it directly compatible with the established
3D animation pipeline. We use a novel graph convolutional network architecture
to enable motion-dependent deformation learning of body and clothing, including
dynamics, and a neural generative dynamic texture model creates corresponding
dynamic texture maps. We show that by merely providing new skeletal motions,
our model creates motion-dependent surface deformations, physically plausible
dynamic clothing deformations, as well as video-realistic surface textures at a
much higher level of detail than previous state of the art approaches, and even
in real-time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is cell ratio important in deep learning? A robust comparison of deep learning methods for multi-scale cytopathology cell image classification: from convolutional neural networks to visual transformers. (arXiv:2105.07402v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07402">
<div class="article-summary-box-inner">
<span><p>Cervical cancer is a very common and fatal cancer in women. Cytopathology
images are often used to screen this cancer. Since there is a possibility of a
large number of errors in manual screening, the computer-aided diagnosis system
based on deep learning is developed. The deep learning methods required a fixed
size of input images, but the sizes of the clinical medical images are
inconsistent. The internal cell ratios of the images are suffered while
resizing it directly. Clinically, the ratios of cells inside cytopathological
images provide important information for doctors to diagnose cancer. Therefore,
it is illogical to resize directly. However, many existing studies resized the
images directly and obtained very robust classification results. To find a
reasonable interpretation, we have conducted a series of comparative
experiments. First, the raw data of the SIPaKMeD dataset are preprocessed to
obtain the standard and scaled datasets. Then, the datasets are resized to 224
$\times$ 224 pixels. Finally, twenty-two deep learning models are used to
classify standard and scaled datasets. The conclusion is that the deep learning
models are robust to changes in the internal cell ratio of cervical
cytopathological images. This conclusion is also validated on the Herlev
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deformation Driven Seq2Seq Longitudinal Tumor and Organs-at-Risk Prediction for Radiotherapy. (arXiv:2106.09076v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09076">
<div class="article-summary-box-inner">
<span><p>Purpose: Radiotherapy presents unique challenges and clinical requirements
for longitudinal tumor and organ-at-risk (OAR) prediction during treatment. The
challenges include tumor inflammation/edema and radiation-induced changes in
organ geometry, whereas the clinical requirements demand flexibility in
input/output sequence timepoints to update the predictions on rolling basis and
the grounding of all predictions in relationship to the pre-treatment imaging
information for response and toxicity assessment in adaptive radiotherapy.
Methods: To deal with the aforementioned challenges and to comply with the
clinical requirements, we present a novel 3D sequence-to-sequence model based
on Convolution Long Short Term Memory (ConvLSTM) that makes use of series of
deformation vector fields (DVF) between individual timepoints and reference
pre-treatment/planning CTs to predict future anatomical deformations and
changes in gross tumor volume as well as critical OARs. High-quality DVF
training data is created by employing hyper-parameter optimization on the
subset of the training data with DICE coefficient and mutual information
metric. We validated our model on two radiotherapy datasets: a publicly
available head-and-neck dataset (28 patients with manually contoured pre-,
mid-, and post-treatment CTs), and an internal non-small cell lung cancer
dataset (63 patients with manually contoured planning CT and 6 weekly CBCTs).
Results: The use of DVF representation and skip connections overcomes the
blurring issue of ConvLSTM prediction with the traditional image
representation. The mean and standard deviation of DICE for predictions of lung
GTV at week 4, 5, and 6 were 0.83$\pm$0.09, 0.82$\pm$0.08, and 0.81$\pm$0.10,
respectively, and for post-treatment ipsilateral and contralateral parotids,
were 0.81$\pm$0.06 and 0.85$\pm$0.02.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Single Image Super-resolution Under Complex Noise. (arXiv:2107.00986v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00986">
<div class="article-summary-box-inner">
<span><p>While the researches on single image super-resolution (SISR), especially
equipped with deep neural networks (DNNs), have achieved tremendous successes
recently, they still suffer from two major limitations. Firstly, the real image
degradation is usually unknown and highly variant from one to another, making
it extremely hard to train a single model to handle the general SISR task.
Secondly, most of current methods mainly focus on the downsampling process of
the degradation, but ignore or underestimate the inevitable noise
contamination. For example, the commonly-used independent and identically
distributed (i.i.d.) Gaussian noise distribution always largely deviates from
the real image noise (e.g., camera sensor noise), which limits their
performance in real scenarios. To address these issues, this paper proposes a
model-based unsupervised SISR method to deal with the general SISR task with
unknown degradations. Instead of the traditional i.i.d. Gaussian noise
assumption, a novel patch-based non-i.i.d. noise modeling method is proposed to
fit the complex real noise. Besides, a deep generator parameterized by a DNN is
used to map the latent variable to the high-resolution image, and the
conventional hyper-Laplacian prior is also elaborately embedded into such
generator to further constrain the image gradients. Finally, a Monte Carlo EM
algorithm is designed to solve our model, which provides a general inference
framework to update the image generator both w.r.t. the latent variable and the
network parameters. Comprehensive experiments demonstrate that the proposed
method can evidently surpass the current state of the art (SotA) method (about
1dB PSNR) not only with a slighter model (0.34M vs. 2.40M) but also faster
speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mutually improved endoscopic image synthesis and landmark detection in unpaired image-to-image translation. (arXiv:2107.06941v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06941">
<div class="article-summary-box-inner">
<span><p>The CycleGAN framework allows for unsupervised image-to-image translation of
unpaired data. In a scenario of surgical training on a physical surgical
simulator, this method can be used to transform endoscopic images of phantoms
into images which more closely resemble the intra-operative appearance of the
same surgical target structure. This can be viewed as a novel augmented reality
approach, which we coined Hyperrealism in previous work. In this use case, it
is of paramount importance to display objects like needles, sutures or
instruments consistent in both domains while altering the style to a more
tissue-like appearance. Segmentation of these objects would allow for a direct
transfer, however, contouring of these, partly tiny and thin foreground objects
is cumbersome and perhaps inaccurate. Instead, we propose to use landmark
detection on the points when sutures pass into the tissue. This objective is
directly incorporated into a CycleGAN framework by treating the performance of
pre-trained detector models as an additional optimization goal. We show that a
task defined on these sparse landmark labels improves consistency of synthesis
by the generator network in both domains. Comparing a baseline CycleGAN
architecture to our proposed extension (DetCycleGAN), mean precision (PPV)
improved by +61.32, mean sensitivity (TPR) by +37.91, and mean F1 score by
+0.4743. Furthermore, it could be shown that by dataset fusion, generated
intra-operative images can be leveraged as additional training data for the
detection network itself. The data is released within the scope of the AdaptOR
MICCAI Challenge 2021 at https://adaptor2021.github.io/, and code at
https://github.com/Cardio-AI/detcyclegan_pytorch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Triplet is All You Need with Random Mappings for Unsupervised Visual Representation Learning. (arXiv:2107.10419v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10419">
<div class="article-summary-box-inner">
<span><p>Contrastive self-supervised learning (SSL) has achieved great success in
unsupervised visual representation learning by maximizing the similarity
between two augmented views of the same image (positive pairs) and
simultaneously contrasting other different images (negative pairs). However,
this type of methods, such as SimCLR and MoCo, relies heavily on a large number
of negative pairs and thus requires either large batches or memory banks. In
contrast, some recent non-contrastive SSL methods, such as BYOL and SimSiam,
attempt to discard negative pairs by introducing asymmetry and show remarkable
performance. Unfortunately, to avoid collapsed solutions caused by not using
negative pairs, these methods require sophisticated asymmetry designs. In this
paper, we argue that negative pairs are still necessary but one is sufficient,
i.e., triplet is all you need. A simple triplet-based loss can achieve
surprisingly good performance without requiring large batches or asymmetry.
Moreover, we observe that unsupervised visual representation learning can gain
significantly from randomness. Based on this observation, we propose a simple
plug-in RandOm MApping (ROMA) strategy by randomly mapping samples into other
spaces and enforcing these randomly projected samples to satisfy the same
correlation requirement. The proposed ROMA strategy not only achieves the
state-of-the-art performance in conjunction with the triplet-based loss, but
also can further effectively boost other SSL methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalizing Fairness: Discovery and Mitigation of Unknown Sensitive Attributes. (arXiv:2107.13625v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13625">
<div class="article-summary-box-inner">
<span><p>Ensuring trusted artificial intelligence (AI) in the real world is an
critical challenge. A still largely unexplored task is the determination of the
major factors within the real world that affect the behavior and robustness of
a given AI module (e.g. weather or illumination conditions). Specifically, here
we seek to discover the factors that cause AI systems to fail, and to mitigate
their influence. The identification of these factors usually heavily relies on
the availability of data that is diverse enough to cover numerous combinations
of these factors, but the exhaustive collection of this data is onerous and
sometimes impossible in complex environments. This paper investigates methods
that discover and mitigate the effects of semantic sensitive factors within a
given dataset. We also here generalize the definition of fairness, which
normally only addresses socially relevant factors, and widen it to deal with --
more broadly -- the desensitization of AI systems with regard to all possible
aspects of variation in the domain. The proposed methods which discover these
major factors reduce the potentially onerous demands of collecting a
sufficiently diverse dataset. In experiments using road sign (GTSRB) and facial
imagery (CelebA) datasets, we show the promise of these new methods and show
that they outperform state of the art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds. (arXiv:2108.06455v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06455">
<div class="article-summary-box-inner">
<span><p>3D single object tracking is a key issue for robotics. In this paper, we
propose a transformer module called Point-Track-Transformer (PTT) for point
cloud-based 3D single object tracking. PTT module contains three blocks for
feature embedding, position encoding, and self-attention feature computation.
Feature embedding aims to place features closer in the embedding space if they
have similar semantic information. Position encoding is used to encode
coordinates of point clouds into high dimension distinguishable features.
Self-attention generates refined attention features by computing attention
weights. Besides, we embed the PTT module into the open-source state-of-the-art
method P2B to construct PTT-Net. Experiments on the KITTI dataset reveal that
our PTT-Net surpasses the state-of-the-art by a noticeable margin (~10\%).
Additionally, PTT-Net could achieve real-time performance (~40FPS) on NVIDIA
1080Ti GPU. Our code is open-sourced for the robotics community at
https://github.com/shanjiayao/PTT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Weakly Supervised Amodal Segmenter with Boundary Uncertainty Estimation. (arXiv:2108.09897v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09897">
<div class="article-summary-box-inner">
<span><p>This paper addresses weakly supervised amodal instance segmentation, where
the goal is to segment both visible and occluded (amodal) object parts, while
training provides only ground-truth visible (modal) segmentations. Following
prior work, we use data manipulation to generate occlusions in training images
and thus train a segmenter to predict amodal segmentations of the manipulated
data. The resulting predictions on training images are taken as the
pseudo-ground truth for the standard training of Mask-RCNN, which we use for
amodal instance segmentation of test images. For generating the pseudo-ground
truth, we specify a new Amodal Segmenter based on Boundary Uncertainty
estimation (ASBU) and make two contributions. First, while prior work uses the
occluder's mask, our ASBU uses the occlusion boundary as input. Second, ASBU
estimates an uncertainty map of the prediction. The estimated uncertainty
regularizes learning such that lower segmentation loss is incurred on regions
with high uncertainty. ASBU achieves significant performance improvement
relative to the state of the art on the COCOA and KINS datasets in three tasks:
amodal instance segmentation, amodal completion, and ordering recovery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YOLOP: You Only Look Once for Panoptic Driving Perception. (arXiv:2108.11250v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11250">
<div class="article-summary-box-inner">
<span><p>A panoptic driving perception system is an essential part of autonomous
driving. A high-precision and real-time perception system can assist the
vehicle in making the reasonable decision while driving. We present a panoptic
driving perception network (YOLOP) to perform traffic object detection,
drivable area segmentation and lane detection simultaneously. It is composed of
one encoder for feature extraction and three decoders to handle the specific
tasks. Our model performs extremely well on the challenging BDD100K dataset,
achieving state-of-the-art on all three tasks in terms of accuracy and speed.
Besides, we verify the effectiveness of our multi-task learning model for joint
training via ablative studies. To our best knowledge, this is the first work
that can process these three visual perception tasks simultaneously in
real-time on an embedded device Jetson TX2(23 FPS) and maintain excellent
accuracy. To facilitate further research, the source codes and pre-trained
models will be released at https://github.com/hustvl/YOLOP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image-to-Graph Convolutional Network for Deformable Shape Reconstruction from a Single Projection Image. (arXiv:2108.12533v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12533">
<div class="article-summary-box-inner">
<span><p>Shape reconstruction of deformable organs from two-dimensional X-ray images
is a key technology for image-guided intervention. In this paper, we propose an
image-to-graph convolutional network (IGCN) for deformable shape reconstruction
from a single-viewpoint projection image. The IGCN learns relationship between
shape/deformation variability and the deep image features based on a
deformation mapping scheme. In experiments targeted to the respiratory motion
of abdominal organs, we confirmed the proposed framework with a regularized
loss function can reconstruct liver shapes from a single digitally
reconstructed radiograph with a mean distance error of 3.6mm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual-and-Language Navigation: A Survey and Taxonomy. (arXiv:2108.11544v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11544">
<div class="article-summary-box-inner">
<span><p>An agent that can understand natural-language instruction and carry out
corresponding actions in the visual world is one of the long-term challenges of
Artificial Intelligent (AI). Due to multifarious instructions from humans, it
requires the agent can link natural language to vision and action in
unstructured, previously unseen environments. If the instruction given by human
is a navigation task, this challenge is called Visual-and-Language Navigation
(VLN). It is a booming multi-disciplinary field of increasing importance and
with extraordinary practicality. Instead of focusing on the details of specific
methods, this paper provides a comprehensive survey on VLN tasks and makes a
classification carefully according the different characteristics of language
instructions in these tasks. According to when the instructions are given, the
tasks can be divided into single-turn and multi-turn. For single-turn tasks, we
further divided them into goal-orientation and route-orientation based on
whether the instructions contain a route. For multi-turn tasks, we divided them
into imperative task and interactive task based on whether the agent responses
to the instructions. This taxonomy enable researchers to better grasp the key
point of a specific task and identify directions for future research.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-01 23:02:31.102932227 UTC">2021-09-01 23:02:31 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.1</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>